{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","path":"js/boot.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","path":"js/events.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","path":"js/plugins.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/favicon.png","path":"img/favicon.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","path":"img/default.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","path":"img/loading.gif","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"source/img/about_banner.png","path":"img/about_banner.png","modified":0,"renderable":0},{"_id":"source/img/about_banner.avif","path":"img/about_banner.avif","modified":0,"renderable":0},{"_id":"source/img/avatar.jpeg","path":"img/avatar.jpeg","modified":0,"renderable":0},{"_id":"source/img/article_banner.png","path":"img/article_banner.png","modified":0,"renderable":0},{"_id":"source/img/bg_banner.avif","path":"img/bg_banner.avif","modified":0,"renderable":0},{"_id":"source/img/bg_banner.png","path":"img/bg_banner.png","modified":0,"renderable":0},{"_id":"source/img/article_banner.avif","path":"img/article_banner.avif","modified":0,"renderable":0},{"_id":"source/img/favicon.ico","path":"img/favicon.ico","modified":0,"renderable":0},{"_id":"source/index/Lesson_note_MLFD_models_and_control.jpeg","path":"index/Lesson_note_MLFD_models_and_control.jpeg","modified":0,"renderable":0},{"_id":"source/index/Lesson_note_MLFD_patterns.jpeg","path":"index/Lesson_note_MLFD_patterns.jpeg","modified":0,"renderable":0},{"_id":"source/index/Lesson_note_MLFD_turbulence.jpeg","path":"index/Lesson_note_MLFD_turbulence.jpeg","modified":0,"renderable":0},{"_id":"source/index/Switch-blog-theme-to-FLUID.png","path":"index/Switch-blog-theme-to-FLUID.png","modified":0,"renderable":0},{"_id":"source/index/PINN.png","path":"index/PINN.png","modified":0,"renderable":0},{"_id":"source/index/OpenFOAM.png","path":"index/OpenFOAM.png","modified":0,"renderable":0},{"_id":"source/index/Lesson_note_ML_for_fluid_dynamics.jpeg","path":"index/Lesson_note_ML_for_fluid_dynamics.jpeg","modified":0,"renderable":0},{"_id":"source/index/deriving_NS_again.jpeg","path":"index/deriving_NS_again.jpeg","modified":0,"renderable":0},{"_id":"source/index/deriving_NS_again.png","path":"index/deriving_NS_again.png","modified":0,"renderable":0},{"_id":"source/index/deriving_NS_intergral.png","path":"index/deriving_NS_intergral.png","modified":0,"renderable":0},{"_id":"source/index/fvm_schemes.png","path":"index/fvm_schemes.png","modified":0,"renderable":0},{"_id":"source/index/internal_flow.png","path":"index/internal_flow.png","modified":0,"renderable":0},{"_id":"source/index/external_flow.png","path":"index/external_flow.png","modified":0,"renderable":0},{"_id":"source/index/non-dimensional_NS.png","path":"index/non-dimensional_NS.png","modified":0,"renderable":0},{"_id":"source/index/paper-reading-GNN.png","path":"index/paper-reading-GNN.png","modified":0,"renderable":0},{"_id":"source/index/paper-reading-GPT1-3.png","path":"index/paper-reading-GPT1-3.png","modified":0,"renderable":0},{"_id":"source/index/paper-reading-MAE.png","path":"index/paper-reading-MAE.png","modified":0,"renderable":0},{"_id":"source/index/paper-reading-ResNet.png","path":"index/paper-reading-ResNet.png","modified":0,"renderable":0},{"_id":"source/index/paper-reading-Swin-transformer.png","path":"index/paper-reading-Swin-transformer.png","modified":0,"renderable":0},{"_id":"source/index/paper-reading-bert.png","path":"index/paper-reading-bert.png","modified":0,"renderable":0},{"_id":"source/index/paper-reading-contrastive-learning-review.png","path":"index/paper-reading-contrastive-learning-review.png","modified":0,"renderable":0},{"_id":"source/index/paper-reading-AlexNet.png","path":"index/paper-reading-AlexNet.png","modified":0,"renderable":0},{"_id":"source/index/paper-reading-transformer.png","path":"index/paper-reading-transformer.png","modified":0,"renderable":0},{"_id":"source/index/paper-reading.png","path":"index/paper-reading.png","modified":0,"renderable":0},{"_id":"source/index/paper-reading-ViT.png","path":"index/paper-reading-ViT.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/_posts/Build-OpenFOAM-from-source-on-M1-Mac.md","hash":"f58d20cd351dcbdde2c8d5d4cd8ac21e80ff2a16","modified":1654770051879},{"_id":"source/.DS_Store","hash":"078061506c6bfe842d8e5013977f485508d2a670","modified":1655981143601},{"_id":"source/_posts/Derivation-of-Non-dimensional-NS-Equations.md","hash":"cfba22e09dfd5fd381120dd18784feb74881b044","modified":1653064004229},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia.md","hash":"1426494e411fb6d8cf0d6393b0564150499f64d2","modified":1653709864561},{"_id":"source/_posts/Derive-the-NS-equation-from-scratch-AGAIN.md","hash":"3a4e73776c19794ec6a2b10ed860478a8698a242","modified":1653064006974},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations.md","hash":"900211fc33a0f264d8c5af1ce586b8b7ab988bd8","modified":1653810939096},{"_id":"source/_posts/Hello-ShouRou.md","hash":"8cf8891733c6034afc3d3df3169267f061576911","modified":1654769714480},{"_id":"source/_posts/External-flow-fundamentals.md","hash":"03c0dcece6497a7abfe106d8453d45d4c005de0f","modified":1655365916427},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR.md","hash":"65cd3286c36dd1c721d54d9fc2644dffe2015215","modified":1651484470804},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics.md","hash":"0a0f6341b68fe0238093bd58f612fdb07ff039b3","modified":1654712197950},{"_id":"source/_posts/learning-rate-schedule.md","hash":"c3357777c550c1487e28e9fbbde1aac3e9eac240","modified":1651484495127},{"_id":"source/_posts/Internal-flow-fundamentals.md","hash":"35c436c8a468b5f066a653d4b990fbde112b1d0d","modified":1653706529630},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics.md","hash":"69667341d29834ed7877d58271dcefbed6185c7f","modified":1654712183553},{"_id":"source/_posts/Switch-blog-theme-to-FLUID.md","hash":"1b6040f2fea1f98e64ce30c8c5cd12d19dce2c2d","modified":1653709623981},{"_id":"source/_posts/Review-of-Physical-Informed-Neural-Network.md","hash":"2b0887628472dc8904ab467dc4a3fa1d60b82f97","modified":1655996016396},{"_id":"source/_posts/paper-reading-GPT1-3.md","hash":"6e29c5882d7a82e8371cfef53422de4485332bab","modified":1654770332570},{"_id":"source/_posts/paper-reading-A-gentle-introduction-to-graph-neural-networks.md","hash":"0f2c3e45ea9a38cd4598ec7ba5969bc2c5c2f184","modified":1654770256117},{"_id":"source/_posts/install-d2l-moudule-on-apple-m1-chip-for-deep-learning.md","hash":"f2a84ecc18426960b889ef03659c3b138fdb6e99","modified":1654769686816},{"_id":"source/_posts/paper-reading-ResNet.md","hash":"3e6c61b232e854c9e889d6a4665347c359fbd954","modified":1654770307255},{"_id":"source/_posts/paper-reading-MAE.md","hash":"45e95b5fbaf79974ae06d23d2efa375cf017a91d","modified":1654770303081},{"_id":"source/_posts/paper-reading-AlexNet.md","hash":"ac0b9861611fc9a4da6629f0a5c31be72036d47e","modified":1654770260197},{"_id":"source/_posts/paper-reading-bert.md","hash":"81350ab0cb2a731057d063e506032df1dd09d735","modified":1654770266184},{"_id":"source/_posts/paper-reading-Swin-transformer.md","hash":"8f87ddec88e61ca2db418404706a2f324a75791c","modified":1654770316671},{"_id":"source/_posts/paper-reading-start.md","hash":"121de563d9df3fd3694ba817660e3b0cc5d3b745","modified":1651545227634},{"_id":"source/_posts/paper-reading-transformer.md","hash":"45a4ae4e8eada2ddc21543f35d59941ea0960eee","modified":1654770321668},{"_id":"source/_posts/paper-reading-Vision-Transformer.md","hash":"3b267b515a4164f89ae743b7e1e5677f6b68aee5","modified":1654770325381},{"_id":"source/_posts/paper-reading-contrastive-learning-review.md","hash":"b8364f4c1b6279b7c9f2f6c0feee79ae38c0a083","modified":1654770271969},{"_id":"source/CV/index.md","hash":"ba4e72e1c21eee077df49793fe537e8db92c748e","modified":1651423039323},{"_id":"source/_posts/.DS_Store","hash":"912d5e021d342ab48043764c0d52442a9d6a8035","modified":1655971839555},{"_id":"source/about/index.md","hash":"2b4e8e32707b2dbfecce6aa755651eea170c07a6","modified":1651423170258},{"_id":"source/img/.DS_Store","hash":"4f62a54db3f2f819edef360f23a09d08c0d8045a","modified":1651464621195},{"_id":"source/about/.DS_Store","hash":"25197d3222c56ee90af9f5dfd76962f5d206e9b7","modified":1652518006502},{"_id":"source/img/about_banner.avif","hash":"3a4cf09849f67a526772893a30036ffb15531a25","modified":1651332230077},{"_id":"source/img/bg_banner.png","hash":"2dc2a06dee2495dc9ebefdee7794e637c14ecf0e","modified":1654696513943},{"_id":"source/img/about_banner.png","hash":"7c0f697200eb7da68dbc321c508e57018b1223b1","modified":1651369183036},{"_id":"source/img/bg_banner.avif","hash":"06980e9258fab6a2d68019df1665099c6639a660","modified":1651332307652},{"_id":"source/img/article_banner.avif","hash":"e307fb78545012ac5896ec812c8a128356ab0c35","modified":1651332121630},{"_id":"source/img/favicon.ico","hash":"7e55bf11b25279bbe79d6f9790374a4427e92eb6","modified":1645623605171},{"_id":"source/index/.DS_Store","hash":"e7d8d8fd538a15b45fc460661ea4648acf75c7e6","modified":1654443548900},{"_id":"source/img/avatar.jpeg","hash":"c6575ca36dc695bf8330d6253ebd38e9761a9462","modified":1645526272735},{"_id":"source/index/paper-reading-GNN.png","hash":"c314bc4e98fcfc150d5d633ffc0882a728d691ea","modified":1651486286463},{"_id":"source/index/paper-reading-ResNet.png","hash":"614f16dda779bd39bd868d62fcf64eb99330eacc","modified":1651486345654},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/Google sitemap inspect 3.png","hash":"091b41b10a1cc1c91cb81f48b062d32bc57b79d5","modified":1646148166525},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/bing search console success.png","hash":"03acd2a59a1e8af3276f36039a235c44afa5a218","modified":1646148166528},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/bing sitemap.png","hash":"f8ca2e88f4c6e1969395b7617075010a4a697565","modified":1646148166528},{"_id":"source/_posts/External-flow-fundamentals/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1653874839271},{"_id":"source/_posts/Derive-the-NS-equation-from-scratch-AGAIN/region of significant viscous work.png","hash":"b8c21a3e9b24336097212b8073d7f0e16774743f","modified":1652431584020},{"_id":"source/_posts/External-flow-fundamentals/V formation.jpeg","hash":"e1e1bab1350c1999e7a64c080196c107e4a1584b","modified":1653553200492},{"_id":"source/_posts/FVM-schemes-fundamentals/1D scalar convection.png","hash":"25d87ec24a78e5d1d0092d323540bb3b4d410a86","modified":1655601952604},{"_id":"source/_posts/FVM-schemes-fundamentals/2D scalar convection control volume.png","hash":"d9c5634d8a63f493c51d1b58b98c0be9f1ab64e5","modified":1655630065702},{"_id":"source/_posts/FVM-schemes-fundamentals/Riemann problem illustration.png","hash":"f02ad4756e2dbfb432ae17b6687c869101b918ef","modified":1655823080325},{"_id":"source/_posts/FVM-schemes-fundamentals/shock path control volume.png","hash":"4047c144c3fab96a3c1d852f98eaa2ab9509638c","modified":1655826092006},{"_id":"source/_posts/FVM-schemes-fundamentals/shock wave.png","hash":"ee0363173a5b2829430e98172f7d4922c74e2d04","modified":1655635468019},{"_id":"source/_posts/Internal-flow-fundamentals/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1653565899099},{"_id":"source/_posts/Internal-flow-fundamentals/Channel flow.png","hash":"924d612ebeeca234c1356b04d60dca554ac716ac","modified":1653468890588},{"_id":"source/_posts/Internal-flow-fundamentals/plug flow.png","hash":"52cdee5ee0898c3f34203884862afb0ac8aa0959","modified":1653383656065},{"_id":"source/_posts/Internal-flow-fundamentals/Plane Couette flow.png","hash":"c71e03e79c834ce3e55f5bcce0439eb283dd94a7","modified":1653468874621},{"_id":"source/_posts/Internal-flow-fundamentals/Poiseuille flow.png","hash":"ae89d9ac5833b71fd77f4679c66cbf94fef7ab50","modified":1653361255756},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1654180014346},{"_id":"source/_posts/Internal-flow-fundamentals/Physical interpretation.png","hash":"e84700d43dec0a6e78a38cee9dde109278926447","modified":1653473932441},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/Cross entropy loss function.png","hash":"f39593d083f6b6a97eb20780a4be745e19dd0452","modified":1646740133650},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1654446468596},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/The-von-Karman-vortex-street-generated-by-the-Rishiri-island.jpeg","hash":"10c278cce82c18cf0a29542b7a10dd378d1a0d26","modified":1654443485820},{"_id":"source/_posts/Switch-blog-theme-to-FLUID/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1651472415691},{"_id":"source/_posts/learning-rate-schedule/2d cyclic learning rate schedule.png","hash":"c8123233438e88551c7453ecd19706baa436bc4a","modified":1646740133663},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/.DS_Store","hash":"2b4cda33f9ffb61f8ac5808f100e8901ce20ac1f","modified":1653050244787},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Differential mass conservation.png","hash":"073412f05fad5e3d2c742632e35cee16b3d4fdef","modified":1652692960646},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Material derivatives.png","hash":"089d886f2b3ad1a0ef4824dc9c78b36cd8350b18","modified":1652665627702},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Displacement deformation.png","hash":"f2c1e059d0013e853ec24402ef9d430d8bd8d6e4","modified":1652983411527},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Polar coordinate.png","hash":"217062c7ebe88b088143cb1754d1f894a4787744","modified":1652715638988},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Stream function property.png","hash":"22944b06a1157f33478740222c0ee3c33bae7ee9","modified":1652965601671},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Vortex line example.png","hash":"205735042c50e548198f8acec193753c99a452a2","modified":1652977801648},{"_id":"source/_posts/paper-reading-GPT1-3/.DS_Store","hash":"b2310ad561b7da93c30349f8e95b765fef846416","modified":1651412609141},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Viscous stress on CS.png","hash":"713bb6507fc97200750edaab42ede7884da34ff5","modified":1652837304221},{"_id":"source/_posts/paper-reading-MAE/.DS_Store","hash":"53726100b46699d968c3f266745655dc85f278b6","modified":1651419470682},{"_id":"source/_posts/paper-reading-bert/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1650358481672},{"_id":"source/_posts/paper-reading-Vision-Transformer/.DS_Store","hash":"a6838ca67d58c3de9944aa3aa2cc2795e16e09d5","modified":1650549185032},{"_id":"source/_posts/paper-reading-bert/model size graph.webp","hash":"faed538a605818e2cef417ed29692bf18745daf5","modified":1650268807051},{"_id":"source/_posts/paper-reading-contrastive-learning-review/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1652065124780},{"_id":"source/_posts/paper-reading-transformer/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1649899178188},{"_id":"source/_posts/paper-reading-contrastive-learning-review/surprising_stl10_10e.png","hash":"fa73b9fe4128e8da615a1e276ad4d21bf44ee562","modified":1652021397929},{"_id":"source/index/PINN.png","hash":"e0f47badd91f58aeea1d1f5a1b388cbc47d68fa2","modified":1654712662681},{"_id":"source/index/OpenFOAM.png","hash":"0705d7e64afcc73ab4d1eb42a547c51dc13ee35c","modified":1654770046594},{"_id":"source/index/fvm_schemes.png","hash":"d47553bfc8c6fe84eb5a6a3030a71c925c16c9b3","modified":1655563664734},{"_id":"source/index/Lesson_note_ML_for_fluid_dynamics.jpeg","hash":"ac471e713d0c8746184c21466a59414f621a83bd","modified":1654421306319},{"_id":"source/index/paper-reading-MAE.png","hash":"e2d85b7de3b9801e63012959a582cba4d846bdf4","modified":1651486335513},{"_id":"source/index/deriving_NS_again.jpeg","hash":"7e70b300fa1f1b17af79b393067873d4bce02ab9","modified":1652517990320},{"_id":"source/_posts/Build-OpenFOAM-from-source-on-M1-Mac/Case sensitive volume step two.png","hash":"59e7aa090ada59450c96b690038a0ee7c2f62033","modified":1654767492658},{"_id":"source/index/paper-reading-AlexNet.png","hash":"3cb5a9abe107ce31a070d8e384cf9e9cf507ad1f","modified":1651486182767},{"_id":"source/_posts/Build-OpenFOAM-from-source-on-M1-Mac/Case sensitive volume step three.png","hash":"7730676fb556e026b1ea7c84ba6438aa189d1015","modified":1654767580721},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/being sitemap connect google.png","hash":"2f7067940f7d336d1c87987c26562bb87b4f90bf","modified":1646148166528},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/baidu console sitemap.png","hash":"8ecba7e34a53e980586ae8ab154511d951867aee","modified":1645610381532},{"_id":"source/_posts/External-flow-fundamentals/Boundary layer control volume.png","hash":"d0f0544107480cfc857d590c4c283eecfad7753e","modified":1653720608050},{"_id":"source/_posts/External-flow-fundamentals/displacement thickness.png","hash":"0130b05911aff4534da7bffd85d05813456ad353","modified":1653724466040},{"_id":"source/_posts/External-flow-fundamentals/magnus effect illustration.png","hash":"f937820d76961741c32ce4e8324a285291a85cad","modified":1653702788038},{"_id":"source/_posts/FVM-schemes-fundamentals/Burgers's equation under Riemann Problem with uL = 1, uR=0.png","hash":"50998de5b64f42247b0b3645b4b849f75cb25cf1","modified":1655971978208},{"_id":"source/_posts/Internal-flow-fundamentals/3 flow regimes.png","hash":"c2cb9996083d24ad329a538d7743dbee4703a350","modified":1653289126150},{"_id":"source/_posts/Internal-flow-fundamentals/non-newtonian flow.png","hash":"7c3aa45c54c4b436836440d2c064b68970e1132f","modified":1653293717879},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/POD Analysis of Cylinder Flow.jpeg","hash":"14927089e159da72f6b233d71f125d1ac0d99a1f","modified":1654157762259},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/accuracy curve applying label smoothing.png","hash":"4aeeb4d6d7711a4396e2149e4d1f8130d183edcc","modified":1646740133652},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Aerofoil vortex shedding.png","hash":"242454d3e9d89266efd603b516586036e3fba7a0","modified":1652986094362},{"_id":"source/_posts/learning-rate-schedule/SGD with learning rate decay.png","hash":"83c473cfe0a99facc1b1ab54af01115989e11b0c","modified":1646740133663},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Flow direction based on stream function.png","hash":"6d96a9b4ce409a7bfad612a98026f9f264be8827","modified":1652965820507},{"_id":"source/_posts/learning-rate-schedule/source ppt.pptx","hash":"1cd5b8c2dcc76d002d10173f1c0071bf331898e4","modified":1646837491091},{"_id":"source/_posts/paper-reading-GPT1-3/GPT timeline.png","hash":"109115b9d17368fd43c4c536fe50449deec95fcf","modified":1650290802211},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Surface forces on CS.png","hash":"e1ce7c93c7a04acdd32fe4d6313fa3fb610ecc98","modified":1652843005535},{"_id":"source/_posts/paper-reading-MAE/MAE pixels vs tokens.png","hash":"a1e7a8a133838b07c51f40f5cfbb1c0cfa7fe0ed","modified":1651502570443},{"_id":"source/_posts/paper-reading-MAE/MAE segmentation.png","hash":"3212f43a4fc79d5eb5ba23ff22df7525c3c99953","modified":1651502515895},{"_id":"source/_posts/paper-reading-Vision-Transformer/ViT variants.png","hash":"d4f9886bdfcfd28b0c84ca95cfef3b6982acfa05","modified":1650951107015},{"_id":"source/_posts/FVM-schemes-fundamentals.md","hash":"384cf4b258303ebb93264cac8ed7eaa1a0e7d52d","modified":1655996335347},{"_id":"source/img/article_banner.png","hash":"e24b9d21bd336231d5000a075cb2ea6e4d2c3918","modified":1654696440687},{"_id":"source/index/Lesson_note_MLFD_patterns.jpeg","hash":"5e6cfe46b79784195760a22bb5ba1863499e35d1","modified":1654421607474},{"_id":"source/index/Lesson_note_MLFD_models_and_control.jpeg","hash":"67a405862658b7cae9353482a136a6bc0dcdb3f5","modified":1654421848633},{"_id":"source/index/Lesson_note_MLFD_turbulence.jpeg","hash":"ef5e7cb04145e3b3c954978c2d12e1b14db9e37c","modified":1654421900860},{"_id":"source/index/deriving_NS_intergral.png","hash":"83388688a57ce95b46b2598032bf02c6e9818fa9","modified":1652518140095},{"_id":"source/index/deriving_NS_again.png","hash":"63f6ba11aa53d8843725a4f7dc8df97634ad2a89","modified":1652348818935},{"_id":"source/index/paper-reading-transformer.png","hash":"df4389aa0f63de9f529630eb47949742432cf0a0","modified":1651486356907},{"_id":"source/index/non-dimensional_NS.png","hash":"bd47a0351919010817f02ef656362a591f5c3022","modified":1653047286687},{"_id":"source/_posts/Build-OpenFOAM-from-source-on-M1-Mac/Case sensitive volume finish.png","hash":"73030d9511cb9c48c99b51bc33d1fa6e9aa15860","modified":1654767607810},{"_id":"source/_posts/Build-OpenFOAM-from-source-on-M1-Mac/Case sensitive volume step one.png","hash":"58e720c8331da8d46e4eb52de4d362482e874069","modified":1654767425746},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/can't fetch sitemap.png","hash":"f33cf775460666ebefa5e8aa56b768a1ce4d1af4","modified":1645608343832},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/google console varification.png","hash":"54b854a7bc2152a565ae61ab6f513fe8fad31139","modified":1645606581799},{"_id":"source/_posts/Derive-the-NS-equation-from-scratch-AGAIN/Bernoulli's Equation CV.png","hash":"392bd1dc40696da877107be3657fd502a8b850a5","modified":1652448607238},{"_id":"source/_posts/Derive-the-NS-equation-from-scratch-AGAIN/Reynolds transport theorem proof.png","hash":"cae835617aefc3db40315de5f85ab695dfc9b2e6","modified":1652364560421},{"_id":"source/_posts/Derive-the-NS-equation-from-scratch-AGAIN/Flow_pass_control_surface.png","hash":"b952fe70e8f9d04e2071326755082eb60fe5a591","modified":1652355900577},{"_id":"source/_posts/Internal-flow-fundamentals/puff lifetimes.png","hash":"07853f324dbae9abc6b563bda1969d3ec2be5811","modified":1653291820589},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/parabolic reduced order model.png","hash":"95149c0fdb33f514e7981eecc775fb314030bc8b","modified":1654417356015},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/PCA as auto-encoder.png","hash":"60d29dddd27be9c575657f9536e26e031bdfc497","modified":1654446449221},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/deeper auto-encoder.png","hash":"a76b3f3415396541a0409d356eb5602845c496df","modified":1654450503582},{"_id":"source/_posts/learning-rate-schedule/warmup on large batches.png","hash":"c7c61a90faa6fbe7cbb58f35c651cfacc5357db8","modified":1646740133665},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Fluid particle deformation.png","hash":"fd4fb04c566c5c7ec96d312f0f152f88058047b5","modified":1652966593648},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Fluid partical deformation.png","hash":"0fb36b69430798b6013c53ae72b95ff21e53fd4a","modified":1652893537727},{"_id":"source/_posts/paper-reading-ResNet/ResNet figure 2.png","hash":"4aae59eb537b2676e973e61b714f5e2260592443","modified":1649660775712},{"_id":"source/_posts/paper-reading-bert/BERT learnable paramters.png","hash":"8839786a937ceb1f0a58110f5dc72b06a48024b8","modified":1650129616220},{"_id":"source/index/paper-reading-ViT.png","hash":"e9c0e2dfd591c482c8471cafaaed89b9de3a11ea","modified":1651486365345},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/baidu console.png","hash":"1b21c2b62d1217fc07402a2b5a93ade16b9d06a9","modified":1645608661819},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/check google search.png","hash":"a283f4c31f86a0f29ffc685c572431a00e5199c7","modified":1645604738508},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/typora setting.png","hash":"4bbaf27946caa82912470a69221a7f494b985bf9","modified":1645586028925},{"_id":"source/_posts/External-flow-fundamentals/Similarity solution.png","hash":"bd0923fa18e99f079eee9458a7e64794e7e4451f","modified":1653904151784},{"_id":"source/_posts/FVM-schemes-fundamentals/Expansion shock solution to the Riemann Problem.png","hash":"a7846abc515f61722df6467676dbef2186e6169d","modified":1655974692363},{"_id":"source/_posts/Internal-flow-fundamentals/Pressure drop.png","hash":"39431c9ef9380996a6232e412cb796f0ebcad52d","modified":1653441256597},{"_id":"source/_posts/Internal-flow-fundamentals/inclined pipe.png","hash":"8b936b8634de0e8cf67e7379a43b26a894aa7e07","modified":1653453263341},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/accuracy curve compare label smoothing with hard label.png","hash":"cdae6eacdd69d900057bf680a2d321e58dda17d9","modified":1646740133653},{"_id":"source/_posts/learning-rate-schedule/CLR.png","hash":"e7bbe3fb1a452bf830806ae0dba4ec0eb6ae236b","modified":1646837491081},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/sufficient measurements.png","hash":"db9f4c7b6ad4b4a91d36f53fe164ee35c168526f","modified":1654705652028},{"_id":"source/_posts/learning-rate-schedule/SGDR.png","hash":"ef63d3bb9bf8b0083de55ef9b3c9fc4a0d57608d","modified":1646837491082},{"_id":"source/_posts/paper-reading-GPT1-3/GPT-3 result 2.png","hash":"646a38e14e8bef9fd0f5615acf0cbd43c5042205","modified":1650542544491},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 models.png","hash":"93adbab90cb1e999d9a6969ebfea7b1e82672d68","modified":1650507028352},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 race.png","hash":"3ceb1c3a74634b2c40b608e3c6a9529a141907f1","modified":1650544334100},{"_id":"source/_posts/paper-reading-ResNet/ResNet figure 5.png","hash":"535021caab08b1436c194688c6f15cbbce199308","modified":1649691635486},{"_id":"source/_posts/paper-reading-Vision-Transformer/VIT model overview.png","hash":"25618195462760c8e7bcccf86e02e43cff1ee0c9","modified":1650701858569},{"_id":"source/_posts/paper-reading-Vision-Transformer/VIT positional embedding ablation.png","hash":"774bb656e0f545459f58b0b0b521c1883fe5df01","modified":1650940248041},{"_id":"source/_posts/paper-reading-Vision-Transformer/VIT algorithm.png","hash":"49c6702a90c2be602b51765d7e9824f5aa722522","modified":1650940497282},{"_id":"source/_posts/paper-reading-A-gentle-introduction-to-graph-neural-networks/GNN graph level task.png","hash":"e1af92d12c8f7e0b9943f7ed839198b03088a7e4","modified":1649922057273},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SimCLR projection head.png","hash":"98994ab627d2775b9f7fbc09dd0484d8fb60baff","modified":1651933432169},{"_id":"source/index/external_flow.png","hash":"8e2bfb1db58191d32a7239f26846da9e63899b28","modified":1653543090907},{"_id":"source/index/internal_flow.png","hash":"397089a9217b32fabe31bf9e48f4c55c950322d8","modified":1653288783614},{"_id":"source/index/paper-reading.png","hash":"de515be5fdb766b4a671f1537d536fb8fa096ac8","modified":1651486378127},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/google console.png","hash":"240520671ae14a4db700b002e99ee276bf1fe650","modified":1645605064121},{"_id":"source/_posts/External-flow-fundamentals/Flow past an airfoil.gif","hash":"70ca1917a78a6f5eef087e0e25fa6039e907aaa5","modified":1653550930077},{"_id":"source/_posts/External-flow-fundamentals/Boundary layers.png","hash":"038daca7b54bed2852f950384ed60aedacd82ef1","modified":1653557900815},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/Label smoothing feature norm.png","hash":"47841e9b48ef8aaa61bdedf70b593a1d563840ca","modified":1646740133651},{"_id":"source/_posts/learning-rate-schedule/cyclic learning rate schedule.png","hash":"0c093af7caf829e60f29eea8f72140ba75a85ba3","modified":1646740133664},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/leave class code.png","hash":"224786316ca7dc910a29d3c5acb42f755f3bc662","modified":1646740133655},{"_id":"source/_posts/paper-reading-AlexNet/unsupervise learning cake.png","hash":"adcb79d097ff6fdea2021bb4668f8eeb8a57358d","modified":1649349696051},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 gender.png","hash":"49460dd410dcef903e806afb83aeaa82013049cf","modified":1650544313625},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 training data.png","hash":"d8c11af3e71e7ce5d5aa4cd47e6836d816f04a5b","modified":1650541614411},{"_id":"source/_posts/paper-reading-MAE/MAE classification.png","hash":"1468fc45ed545445d33bce0b4bcd390488c7eb37","modified":1651502545786},{"_id":"source/_posts/paper-reading-MAE/MAE comparison.png","hash":"695e1965c84f6825a38cc65d9b00c45ffff305d9","modified":1651419448338},{"_id":"source/_posts/paper-reading-MAE/MAE mask ratio.png","hash":"75bc0ff014fb48e2e3adff8f2a64298c498ba98d","modified":1651300996771},{"_id":"source/_posts/paper-reading-contrastive-learning-review/CPC illustration.png","hash":"41fb22ea936df830dfa7a4f4416447561777476a","modified":1651758372237},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SimSiam illustration.png","hash":"6571715e1a0e0d5bf5e247d79398e6234ee3df3c","modified":1652024959042},{"_id":"source/index/paper-reading-contrastive-learning-review.png","hash":"87428809714e60703d0ff1bf083d022a75fe23b2","modified":1651512881215},{"_id":"source/_posts/External-flow-fundamentals/Skyscraper wind effect.png","hash":"cf34a00ce5e0c868217ea84aebc3eaaeb405d680","modified":1653553484467},{"_id":"source/_posts/External-flow-fundamentals/Wingtip vortex.jpeg","hash":"3f19811d3158036b3866125cb54c6321a6d973d5","modified":1653552797053},{"_id":"source/_posts/FVM-schemes-fundamentals/Burgers's equation under Riemann Problem with uL = 0, uR=1.png","hash":"45457b245f96b2c08821ae3e8c79b5f703fe075f","modified":1655974375923},{"_id":"source/_posts/FVM-schemes-fundamentals/Burgers's equation under Riemann Problem general solution.png","hash":"efb308531cc8f1c700516ad16defbf3159211880","modified":1655973961643},{"_id":"source/_posts/Internal-flow-fundamentals/puffs.png","hash":"e72e5c0844241c207e9c4265b81885169230c82b","modified":1653291496778},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/Structure of control scheme.png","hash":"2c3b865cb30367c11d9ed32e531ffc60b683c2fa","modified":1654420210898},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/Schematic overview of the proposed sparse modeling procedure.png","hash":"6e6bc08cf1c15f7d36303dd39abbc2dc025125ea","modified":1654419069164},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/RANs modeling with DNN.png","hash":"a431b060e431f81ec868e7fa47cfc8f87d1b385b","modified":1654163620710},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/hard label.png","hash":"8e83c8d43703867f9faf7a1db317fcb040a24045","modified":1646740133654},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/soft label.png","hash":"2d6357cd03c4b4149f5191e91d781cc5a554a897","modified":1646740133657},{"_id":"source/_posts/paper-reading-GPT1-3/GPT-3 approach.png","hash":"21e4e6703fcf07679e8cb6cf42931b444145426b","modified":1650504600314},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 result.png","hash":"3c4192ef7ff33164dba01b3ea9754c3b02011bda","modified":1650542377401},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 result 3.png","hash":"9360c9a0adb1051e96ff62e6273e4ad747297b6b","modified":1650542713778},{"_id":"source/_posts/paper-reading-MAE/MAE ablation.png","hash":"c13294f9565644c4ae0f987cba573fb5cfd44beb","modified":1651413454099},{"_id":"source/_posts/paper-reading-Vision-Transformer/ViT results.png","hash":"5506ce41ac7b84fc8c10ce73c980d169531145ad","modified":1650952271263},{"_id":"source/_posts/paper-reading-contrastive-learning-review/MoCo v3 result.png","hash":"0d7275a1068f23759c68d2b1f0d6fc4c7105546a","modified":1652029619211},{"_id":"source/_posts/paper-reading-transformer/transformer.png","hash":"6eb38ed16fbaf3660d18b4266763411eadc5a452","modified":1649857283101},{"_id":"source/index/paper-reading-Swin-transformer.png","hash":"a6737c655d891aa43c1238a6b6b71240973d5a42","modified":1652069294461},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/Last snapshot.png","hash":"9ccbadb43f29a86f56d4820913b7daaa8d31e211","modified":1651306179573},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/baidu console varification.png","hash":"09c2e3d1f3b52807bf6dd97d8ec42f7cfd1fe1c7","modified":1645609658080},{"_id":"source/_posts/External-flow-fundamentals/Wakes.png","hash":"eeb0084ad1ea902659938b89303648287e5868ca","modified":1653557329055},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/sufficient training data.png","hash":"1b0cc8761ef1a21d2fb415b379d45fa35894dd6d","modified":1654705779743},{"_id":"source/_posts/learning-rate-schedule/SGDR_REsult.png","hash":"f118bc7b7c5ea51afa9ae366f6bce17757963467","modified":1646837491084},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 performance with compute.png","hash":"e39d32f750f4853f15783654367e544c0bd70d50","modified":1650542001278},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 result4.png","hash":"c261a581c8c8f50e1d9ef50b576415c5116e3467","modified":1650542693426},{"_id":"source/_posts/paper-reading-ResNet/ResNet table 1.png","hash":"782d634274c1221c9db07ea5c9367c4fef5fbe4b","modified":1649692137505},{"_id":"source/_posts/paper-reading-bert/BERT alibation study 1.png","hash":"f71b28cdf11f80dcf3fc5b8c89ad2624d6caad1c","modified":1650266735874},{"_id":"source/_posts/paper-reading-A-gentle-introduction-to-graph-neural-networks/GNN interative archtecture.png","hash":"06e8477aee1a6f12385895a4151dea90ca23e382","modified":1649916716129},{"_id":"source/_posts/paper-reading-contrastive-learning-review/BYOL batch norm ablation.png","hash":"347b21239a81e711a311303d6df7c0ed9d90cfc2","modified":1652022873027},{"_id":"source/_posts/paper-reading-transformer/transformer table1.png","hash":"637292c4c8f161ffa35d2b41ebcf1a37019638f3","modified":1649873535743},{"_id":"source/index/paper-reading-GPT1-3.png","hash":"e2d3ed4da740ca7849b5281b937dae81f06aa6af","modified":1651486309470},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/github page.png","hash":"5262aa8e506f60a57b7ddc69a76c860bca21ffce","modified":1645583716321},{"_id":"source/_posts/External-flow-fundamentals/velocity profiles.png","hash":"4d6e73ea8da7a2a90b969cf754e8f36ec9e0551e","modified":1653742957627},{"_id":"source/_posts/Internal-flow-fundamentals/entrance effect.png","hash":"da8a91f9714a646cdcac31964ae701b395cd012c","modified":1653489786142},{"_id":"source/_posts/FVM-schemes-fundamentals/Rarefaction wave solution to the Riemann Problem.png","hash":"97c52435b99908d93d7194158d27c5a69f54cbe2","modified":1655974755914},{"_id":"source/_posts/paper-reading-GPT1-3/GPT objectives.png","hash":"34aa333335dbb1d0292b65258750ac163a03df2f","modified":1650361267165},{"_id":"source/_posts/paper-reading-contrastive-learning-review/MoCo v2 ablation.png","hash":"894c293b4aaa78059dca3b09f8d50ccf7c57ff1b","modified":1651935452551},{"_id":"source/_posts/paper-reading-contrastive-learning-review/contrastive learning illustration.png","hash":"f70921407f7b009a5ebffcf5bae839ffa0fa14f5","modified":1651685255029},{"_id":"source/_posts/paper-reading-transformer/layer norm.png","hash":"9e0a63ba884eb2efa0604a74dedb92d0cad7420b","modified":1649859296148},{"_id":"source/index/Switch-blog-theme-to-FLUID.png","hash":"edcc654e3b720f9cdb74f98ba215d9ab7de9e8da","modified":1651486390968},{"_id":"source/index/paper-reading-bert.png","hash":"a133a110af8e68d025d7717636d2a170a2e11a45","modified":1651486243241},{"_id":"source/_posts/FVM-schemes-fundamentals/Linear Advection Solutions.png","hash":"b9aad6595c0629f9c554cf28c6f00424ec89fa9d","modified":1655652372369},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/super resolution interpolation and extrapolation comparison.png","hash":"89d256eda77e10af1e96152213a983a1e9e78ec5","modified":1654413172725},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/super resolution interpolation and extrapolation comparison.png","hash":"89d256eda77e10af1e96152213a983a1e9e78ec5","modified":1654413172725},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1651305803039},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1651305803051},{"_id":"source/_posts/paper-reading-GPT1-3/BERT result with GPT.png","hash":"a922a5d9ec6bb140b431baa56ec969dc9d019395","modified":1650373672293},{"_id":"source/_posts/paper-reading-GPT1-3/GPT2 performance.png","hash":"ed244f4af159e064c2862a8933cd891754a17b7d","modified":1650389129294},{"_id":"source/_posts/paper-reading-contrastive-learning-review/DINO illustration.png","hash":"7c238c5d64b82d19ad3cf5db356f113c7cd19fb8","modified":1652065109965},{"_id":"source/_posts/paper-reading-contrastive-learning-review/Instdisc method.png","hash":"33a33d9974f58b2741d3d14014cd0af8299bda10","modified":1651676979638},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/Google sitemap inspect.png","hash":"90618421c6cab7c23ef65da92bc0c48090bc93ea","modified":1646148166528},{"_id":"node_modules/hexo-theme-fluid/.editorconfig","hash":"33218fbd623feb43edf5f99f15965392cecc44a6","modified":1651305800213},{"_id":"node_modules/hexo-theme-fluid/LICENSE","hash":"df5b54be535593d5442cebafbea34eb9bd69b987","modified":1651305800214},{"_id":"node_modules/hexo-theme-fluid/.eslintrc","hash":"4bc2b19ce2b8c4d242f97d4ccf2d741e68ab0097","modified":1651305800213},{"_id":"node_modules/hexo-theme-fluid/README.md","hash":"03cfa8e5f149514b57ef80dcb84eb7fea261370d","modified":1651305803030},{"_id":"node_modules/hexo-theme-fluid/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":1651305800213},{"_id":"node_modules/hexo-theme-fluid/README_en.md","hash":"ca8fd19a4948de1f253616a62c0e8a7d81f692f5","modified":1651305803030},{"_id":"node_modules/hexo-theme-fluid/package.json","hash":"4e3992cacd64c6888218b0346283258e8f82a27d","modified":1651305803028},{"_id":"node_modules/hexo-theme-fluid/_config.yml","hash":"8a7f1534c228538e2ab56249d5a65829650170ed","modified":1651305803053},{"_id":"node_modules/hexo-theme-fluid/languages/en.yml","hash":"a85dcc5cc21f9cab50df31e5001b8818ee62d1e2","modified":1651305803054},{"_id":"node_modules/hexo-theme-fluid/languages/de.yml","hash":"13a6a799415fc2f6f69ebd1a399fb44426a5d641","modified":1651305803053},{"_id":"node_modules/hexo-theme-fluid/languages/zh-CN.yml","hash":"21307b4137c3d9b04bb58243747e75af0abc5a71","modified":1651305803054},{"_id":"node_modules/hexo-theme-fluid/languages/eo.yml","hash":"a0c7984495d4f2d33b64adfa33adebbf768a5ac3","modified":1651305803054},{"_id":"node_modules/hexo-theme-fluid/languages/zh-TW.yml","hash":"1a6d415446da11dee5c5f400e7d67544fbe743ea","modified":1651305803055},{"_id":"node_modules/hexo-theme-fluid/languages/ja.yml","hash":"91020031a847c0361a6fd7ab990c7be4bf17529b","modified":1651305803054},{"_id":"node_modules/hexo-theme-fluid/layout/404.ejs","hash":"689d9f4efd2a7f5edfd9b24561a7ade69d46617c","modified":1651305800215},{"_id":"node_modules/hexo-theme-fluid/layout/archive.ejs","hash":"472d0813ca5b88000a7bc6039f33b7e27b5a3216","modified":1651305800815},{"_id":"node_modules/hexo-theme-fluid/layout/category.ejs","hash":"58291dfec65c36889dfce0ddc603540b67e4c598","modified":1651305800817},{"_id":"node_modules/hexo-theme-fluid/layout/about.ejs","hash":"ad6fed7b646d3ca961db83db0fbe020e3a5d42ad","modified":1651305800215},{"_id":"node_modules/hexo-theme-fluid/layout/index.ejs","hash":"f3ae4395e751c4a02d5895e07856b1e8edfdda08","modified":1651305800827},{"_id":"node_modules/hexo-theme-fluid/layout/layout.ejs","hash":"7f566edf750241e62d7c54abfbb0c504fdab850a","modified":1651305800827},{"_id":"node_modules/hexo-theme-fluid/layout/links.ejs","hash":"2a7b49f0f9aecf07550b5a0b99242aab5654cf2b","modified":1651305800828},{"_id":"node_modules/hexo-theme-fluid/layout/page.ejs","hash":"1014b901d396f4fc445cb1ffc938d5380d894d71","modified":1651305802994},{"_id":"node_modules/hexo-theme-fluid/layout/tag.ejs","hash":"0ad89eb7c92a822980fa9a85285e6d94ad845d1d","modified":1651305802999},{"_id":"node_modules/hexo-theme-fluid/layout/post.ejs","hash":"79e3679a7069351a6172c281b9d09f59d7580484","modified":1651305802995},{"_id":"node_modules/hexo-theme-fluid/layout/tags.ejs","hash":"1d06af34b6cf1d8a20d2eb565e309326ceba309f","modified":1651305802999},{"_id":"node_modules/hexo-theme-fluid/layout/categories.ejs","hash":"20c2a195a109d2a263b5fa6e79cbcc62932508ad","modified":1651305800817},{"_id":"node_modules/hexo-theme-fluid/.github/ISSUE_TEMPLATE/feature_request.md","hash":"c134dd57ffd269b93402ccfffe7dbe0f0b583bec","modified":1651305803030},{"_id":"node_modules/hexo-theme-fluid/.github/ISSUE_TEMPLATE/bug_report_zh.md","hash":"af977ed0792508bb0766ea8afe82d34ef1e8fb3c","modified":1651305803029},{"_id":"node_modules/hexo-theme-fluid/.github/ISSUE_TEMPLATE/feature_request_zh.md","hash":"ed08574b196447376dd74411cca664ac9227a5d4","modified":1651305803030},{"_id":"node_modules/hexo-theme-fluid/.github/ISSUE_TEMPLATE/question.md","hash":"ab5eab9e3ff889c4ba7fd82846e7f5b7ae15bebc","modified":1651305803030},{"_id":"node_modules/hexo-theme-fluid/.github/ISSUE_TEMPLATE/question_zh.md","hash":"e24b470f7aa8044499a4f5e39634e5dc43899011","modified":1651305803030},{"_id":"node_modules/hexo-theme-fluid/.github/workflows/limit.yaml","hash":"f8bd2edeb4424ee7a055b31583445d5d5dff91a4","modified":1651305803052},{"_id":"node_modules/hexo-theme-fluid/scripts/events/index.js","hash":"44faef3e77ab08b91e4c5c6f1cd9087a9faff443","modified":1651305803022},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/locals.js","hash":"58d0fec976f6b1d35e7ea03edc45414088acf05c","modified":1651305803026},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/post-filter.js","hash":"6c37e9f1ac1d6d00b3c32794e02e244dba942cd9","modified":1651305803028},{"_id":"node_modules/hexo-theme-fluid/.github/ISSUE_TEMPLATE/bug_report.md","hash":"16d33eb89ecf90f4046720fde5395d972c7ba1fd","modified":1651305803030},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/pages.js","hash":"d9971f15fbb6b775e3d31a1b9b45011959395010","modified":1651305803027},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/page.js","hash":"4607607445233b3029ef20ed5e91de0da0a7f9c5","modified":1651305803027},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/url.js","hash":"2a6a8288176d0e0f6ec008056bf2745a86e8943e","modified":1651305803028},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/button.js","hash":"3eb43a8cdea0a64576ad6b31b4df6c2bf5698d4c","modified":1651305803015},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/wordcount.js","hash":"b917b893b1777e6ffcb53188f9f5644510e5f20d","modified":1651305803028},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/export-config.js","hash":"cde964c8cd3217268a231de5e018a62c53c2e047","modified":1651305803019},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/group-image.js","hash":"4aeebb797026f1df25646a5d69f7fde79b1bcd26","modified":1651305803020},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/label.js","hash":"f05a6d32cca79535b22907dc03edb9d3fa2d8176","modified":1651305803022},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/note.js","hash":"f52f3a005b41f48b4da274ac64710177c8d4502f","modified":1651305803026},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/mermaid.js","hash":"75160561e1ef3603b6d2ad2938464ab1cb77fd38","modified":1651305803026},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/checkbox.js","hash":"63468f7875c09d9557fe8315afc97175745d9087","modified":1651305803016},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/compare-versions.js","hash":"dbbc928c914fc2bd242cd66aa0c45971aec13a5d","modified":1651305803017},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/utils.js","hash":"3aa5b4ea879cd34d3a32468d88da18d72cbcc8e0","modified":1651305803028},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/object.js","hash":"649457796374c79e49a19bd541e4ad8e78fe8995","modified":1651305803026},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/css.ejs","hash":"c363829a4b80f74fc1c565e41f6dab41c95006ea","modified":1651305800818},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/beian.ejs","hash":"58b4bbe36386de4305a8da5ffd7d56802df23049","modified":1651305800816},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/url-join.js","hash":"718aab5e7b2059a06b093ca738de420d9afa44ba","modified":1651305803028},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/local-search.js","hash":"fc2c50405b771b06b7f6cfc4e9de97b992691555","modified":1651305803023},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/footer.ejs","hash":"a62278c38a310da495d96c39abacacef266945cb","modified":1651305800820},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/paginator.ejs","hash":"0f38a2c238169edcb63fc46c23bfc529ff3859b7","modified":1651305802994},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/scripts.ejs","hash":"0ee838b6fcd895d21a29d9d67dbb99b752d623d1","modified":1651305802996},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/post-meta.ejs","hash":"32a17edadeed40da6db21d2d8031bd47d2fc9bf4","modified":1651305802994},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/search.ejs","hash":"cdd7919fa01f6ef7ccc09938d662ff3d77f5d999","modified":1651305802996},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/statistics.ejs","hash":"920bc618d357d48d2b96f8758f6ae8f9488fc4d8","modified":1651305802997},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/toc.ejs","hash":"3d2fb5552f373e5a0c56bc356702d807bcbcb411","modified":1651305802999},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/head.ejs","hash":"f7f3494ed001e8cdcdc3e8a1d2cd1195cff2ded5","modified":1651305800822},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","hash":"3de344ee619da989f6dccf7c2ae459fe91075983","modified":1651305803015},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1651305800214},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/archive-list.ejs","hash":"53a4f6029373a40394a87aba9284696a71610f90","modified":1651305800815},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","hash":"f1fdd512f3ef92ff5db4a49f5a3143d5ddea9858","modified":1651305803016},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","hash":"4b9d2676c9544db9cc40a8c7d18456792299ba86","modified":1651305803019},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1651305803021},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","hash":"d5a8a59c8d1fd17d699a951e59c4ce9ae44c419d","modified":1651305803045},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/nav.ejs","hash":"e71b3c4aa263163597d31b1f91e5a1a877084cfd","modified":1651305802990},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","hash":"53987b7a668ea0623370eb83ed5311766221b557","modified":1651305803022},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","hash":"d058f30bd09b28769c4d8313428ff23dfc8d52dd","modified":1651305803027},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1651305803052},{"_id":"node_modules/hexo-theme-fluid/source/img/favicon.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1651305803033},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1651305803011},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","hash":"633f0142c657805359b0197f287e12ae4bcde731","modified":1651305803024},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1651305803033},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1651305803034},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","hash":"4a43f2700e91937650bef511fd438825b001c4c6","modified":1651305803028},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/hello.js","hash":"28e186c32576eb3d5d923273471a001c47fe8071","modified":1651305803021},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1651305803031},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/highlight.js","hash":"fd5fcb6a61ad865197a778eeae889b80484227dd","modified":1651305803021},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/merge-configs.js","hash":"c1db1a4f9eca6e36b660530641e3a4fb6a30c8d8","modified":1651305803026},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/footnote.js","hash":"3b2abc5f5e3b681874637e98e047dc4969eb1983","modified":1651305803020},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/compatible-configs.js","hash":"b5fd5a2d9c463eb59318af0f47c591c485b6ad27","modified":1651305803018},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/changyan.ejs","hash":"c9b2d68ed3d375f1953e7007307d2a3f75ed6249","modified":1651305800818},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/cusdis.ejs","hash":"5f9dc012be27040bbe874d0c093c0d53958cc987","modified":1651305800819},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/lazyload.js","hash":"9ba0d4bc224e22af8a5a48d6ff13e5a0fcfee2a4","modified":1651305803022},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/livere.ejs","hash":"2264758fed57542a7389c7aa9f00f1aefa17eb87","modified":1651305800828},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/remark42.ejs","hash":"d4e9532feeb02aed61bd15eda536b5b631454dac","modified":1651305802996},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/utterances.ejs","hash":"e1ed6530dfd7310f91060a75766a93ac3c39be3a","modified":1651305803001},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/valine.ejs","hash":"4052ab2a8f78efa92f0fe17abe8f66135943390a","modified":1651305803001},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/disqus.ejs","hash":"aab4a4d24c55231a37db308ae94414319cecdd9b","modified":1651305800820},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/waline.ejs","hash":"21e00443054802e893aac1f668b69d5bb4b39b3a","modified":1651305803001},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/plugins/analytics.ejs","hash":"557077a8825fffc0a2c7fe2b29f319287950244f","modified":1651305800805},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/twikoo.ejs","hash":"1af53bc0be642610a3a4d4e7c05287854a821508","modified":1651305803000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/plugins/math.ejs","hash":"df6941bd3b860180d01fd39ee859ed2d42f4d1f0","modified":1651305802985},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/plugins/mermaid.ejs","hash":"10ed1f9a611449d37736e17c4e251127b38b3772","modified":1651305802990},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/plugins/typed.ejs","hash":"e8e01c5db46b383748855452aecd70fcda99f598","modified":1651305803000},{"_id":"node_modules/hexo-theme-fluid/source/css/_mixins/base.styl","hash":"542e306ee9494e8a78e44d6d7d409605d94caeb3","modified":1651305803036},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/gitalk.ejs","hash":"843bc141a4545eb20d1c92fb63c85d459b4271ec","modified":1651305800821},{"_id":"node_modules/hexo-theme-fluid/source/css/_functions/base.styl","hash":"2e46f3f4e2c9fe34c1ff1c598738fc7349ae8188","modified":1651305803036},{"_id":"node_modules/hexo-theme-fluid/source/css/_variables/base.styl","hash":"08b455b848b21d57e0563b87071c4bae2b63bafe","modified":1651305803037},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/plugins/nprogress.ejs","hash":"4c2d39ce816b8a6dcd6b53113c8695f8bd650a23","modified":1651305802993},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/base.styl","hash":"c2d8bfd04bf0734b387c049402b46a06a05fc582","modified":1651305803036},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/color-schema.styl","hash":"80098e8354069631bde8edcd1181a53091a92949","modified":1651305803041},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/inline.styl","hash":"d547ab0b91f84eb0acd0bc0c5d716ce17c30361a","modified":1651305803044},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/pages.styl","hash":"b8e887bc7fb3b765a1f8ec9448eff8603a41984f","modified":1651305803049},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/keyframes.styl","hash":"94065ea50f5bef7566d184f2422f6ac20866ba22","modified":1651305803044},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/rewrite.styl","hash":"a2993f23701de9a83e3f428300e62c5c52b4ff4b","modified":1651305803051},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/categories.styl","hash":"1ab7db37c2f7dc7ccdb994dcb41c16a4c8920397","modified":1651305803039},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post.styl","hash":"5e86487de0f16c30ca3e16460ab94b57620e31c5","modified":1651305803050},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_index/index.styl","hash":"616c1f7147078c3d532dd1cfd2af09c0c3a816f0","modified":1651305803044},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_archive/archive.styl","hash":"6e6f22b664199772370b59ce1678b0c148b5849f","modified":1651305803035},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_about/about.styl","hash":"97fe42516ea531fdad771489b68aa8b2a7f6ae46","modified":1651305803034},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/board.styl","hash":"32d90bcc8bf2fd5d8d78e86a567973d4b69bcfa1","modified":1651305803037},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_links/links.styl","hash":"7e32a3268accf3d524209c213e15e2d5d5e2e1a6","modified":1651305803045},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footer.styl","hash":"0ce7552dc4993926426019398d73e817cfd841a1","modified":1651305803042},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/tag_plugin.styl","hash":"b89b96c8a6a433a6f372b42710554b05cab85a24","modified":1651305803051},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"ae9289cc89649af2042907f8a003303b987f3404","modified":1651305803042},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"78704a94c0436097abfb0e0a57abeb3429c749b7","modified":1651305803051},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/header.styl","hash":"d8011325756eb6e4ce619b3e7b4d6d80c2de8a57","modified":1651305803043},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tags.styl","hash":"65bfc01c76abc927fa1a23bf2422892b0d566c3f","modified":1651305803051},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"55e10a6965462f8f62f85e75fd5e143af02a4b44","modified":1651305803051},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/search.styl","hash":"10f7e91a91e681fb9fe46f9df7707b9ef78707c8","modified":1651305803051},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/copy-btn.styl","hash":"9f932ca3f9625c13aa5353f58319881e62c0c653","modified":1651305803041},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/banner.styl","hash":"30f8fab95a5214d79df0ccc02b937df8bd885676","modified":1651305803035},{"_id":"source/_posts/paper-reading-A-gentle-introduction-to-graph-neural-networks/GNN graph message passing.png","hash":"46c17f41a8ff34811854ff5c913693d167933833","modified":1649941190066},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/node js install.png","hash":"49b580f0049a4e224ea17cbb30a33dc34e8acc3a","modified":1645586237414},{"_id":"source/_posts/paper-reading-Swin-transformer/CoCo and ADE20K SOTA.png","hash":"a8c59e9135abbd39d05f975ed3051dfa2cbf3707","modified":1652081866222},{"_id":"source/_posts/paper-reading-Vision-Transformer/VIT class token ablation.png","hash":"5c6b482cd85546e81183f7c6090cb110791f8dd4","modified":1650939933644},{"_id":"source/_posts/paper-reading-contrastive-learning-review/CMC illustration.png","hash":"61c9a904bffec4855fb9fc5abb3e1761405f3c39","modified":1651761305228},{"_id":"source/_posts/paper-reading-contrastive-learning-review/BYOL model.png","hash":"4c6daf0b12cf1ba317fe57d6d952e67cfb149599","modified":1651994315570},{"_id":"source/_posts/paper-reading-contrastive-learning-review/Moco v1 illustration.png","hash":"87efead5961b597023bf6578a9cb9a97ace6e009","modified":1651927813760},{"_id":"source/_posts/paper-reading-contrastive-learning-review/MoCo v3 algorithm.png","hash":"49f72c325ab62d3c9a8b399640ec81f401b1edbd","modified":1652027341998},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SimSiam result.png","hash":"489962de2e8b96c7759a3921146f1acdea474f6a","modified":1652025078593},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SimCLR v1 illustration.png","hash":"4ca6529c60e168c88a0258629fcc33e673b29751","modified":1651931926271},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/source ppt.pptx","hash":"4e53421cbb49964ea368ac4c9259914407a20749","modified":1646740133660},{"_id":"source/_posts/paper-reading-GPT1-3/GPT 3 result 5.png","hash":"5bb6e24fd0d52e4153e80828ee9c250d15465c7b","modified":1650542927000},{"_id":"source/_posts/paper-reading-bert/BERT segment embedding.png","hash":"b3916ee35fc24b258adaf99313b3358e0de35510","modified":1650207033624},{"_id":"source/_posts/paper-reading-ResNet/ResNet table 6.png","hash":"61fd7fcd8b823045cedbf6be8a3c91582124ee6f","modified":1649765185869},{"_id":"source/_posts/paper-reading-ResNet/ResNet table 3.png","hash":"62e26b0634b37d7dc652e5b301937fabd7ba69dd","modified":1649691518798},{"_id":"source/_posts/paper-reading-contrastive-learning-review/MoCo v2 result.png","hash":"5af3dc01321424d7320fab395a131f9e0aa17d22","modified":1651936229046},{"_id":"source/_posts/paper-reading-MAE/MAE architecture.png","hash":"bd19b6cb51c6edf1b32eb6ed2ebf9423539e2cc6","modified":1651155594707},{"_id":"source/_posts/Internal-flow-fundamentals/Reynolds experiment.png","hash":"0b6934021eb77581c0f8494ff04061b87b16650a","modified":1653287779577},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/statistical stationarity.png","hash":"dad0d0270e2e91e8489f48e3eff1f7a5f89a2068","modified":1654703285286},{"_id":"source/_posts/paper-reading-MAE/MAE fine tune.png","hash":"5ef4e8a1bbf07ff7dc9694ebf0a5d7d656e66752","modified":1651420182547},{"_id":"source/_posts/paper-reading-Vision-Transformer/ViT inspecting.png","hash":"3da9c71e7aaa955e3ff2ffe75c03fad55ff74004","modified":1650988729775},{"_id":"source/_posts/paper-reading-contrastive-learning-review/InvaSpread illustration.png","hash":"199c4d7eab62b5a8b67b3a85e848ce1688ea6089","modified":1651756621832},{"_id":"source/_posts/paper-reading-contrastive-learning-review/instance discrimination illustration.png","hash":"39ad8af531ab916acc48b7063860b13f41e5093e","modified":1651688022059},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/Google sitemap inspect 2.png","hash":"acaf3254cd16099f517b0f1e1ab58aa89552e6cd","modified":1646148166525},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/Deep autoencoder reconstruction.png","hash":"9cd8a98824eae087b95f8be93451ede5e7764ef4","modified":1654415395951},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/Deep autoencoder reconstruction.png","hash":"9cd8a98824eae087b95f8be93451ede5e7764ef4","modified":1654415395951},{"_id":"source/_posts/paper-reading-ResNet/ResNet figure 4.png","hash":"b3e1f256838b4036e47d0584a8f84f8a7cd7be08","modified":1649658958011},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/Super resolution.png","hash":"35b68583878e0aef8abbd45517327f8dc278f006","modified":1654411368380},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/Super resolution.png","hash":"35b68583878e0aef8abbd45517327f8dc278f006","modified":1654411368380},{"_id":"source/_posts/paper-reading-contrastive-learning-review/Instdisc idea.png","hash":"0206d091b39c96f52e81e3797a9938ecce7e175f","modified":1651685766800},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SwAV multi crop.png","hash":"a4efe48fca22fb519a3a59a066a04b7ac1d0376f","modified":1651992630400},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SwAV illustration.png","hash":"bbfade7f559a35d1927602f428123fa571dd579f","modified":1651940784924},{"_id":"source/_posts/FVM-schemes-fundamentals/Inviscid Burgers' equation Solutions.png","hash":"109e1b98fc3cfda7d1928f3177b77211d52b2f84","modified":1655654815771},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/Removing shadows, specularities and saturations from face images.png","hash":"42dd24b1879a4dad980abc57092caaa7a0661dc4","modified":1654526068675},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 performance.png","hash":"3d82eb6c71f15523cb51c14bf33573debdd38717","modified":1650439746354},{"_id":"source/_posts/paper-reading-ResNet/ResNet figure 1.png","hash":"765c606c3ae4bafcdd03dba4cda928f782204576","modified":1649658733804},{"_id":"source/_posts/paper-reading-Vision-Transformer/CNN first layer filters.png","hash":"b33e246344bda2b7c32f402c7724b6ae07889114","modified":1650988099709},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SimCLR aug result.png","hash":"f03a3e50d470716e7ef4621a6aa646a5c13f59a1","modified":1651933046848},{"_id":"source/_posts/paper-reading-transformer/transformer table 3.png","hash":"f0c745ce7dbb8cbad5628f1a1b7f4ab207a8ebd7","modified":1649874432197},{"_id":"source/_posts/Internal-flow-fundamentals/Moody chart.png","hash":"6955a3b14fbcd52a77d65071b786d6bc80a6a085","modified":1653476121399},{"_id":"source/_posts/paper-reading-Vision-Transformer/VIT properties.png","hash":"f394d65267154e4aacb9329b6a1cd257a3165ddb","modified":1650549232037},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SwAV result.png","hash":"9ee1e27d64697f81bd8c2141f2bce187b81b9280","modified":1651991989010},{"_id":"source/_posts/paper-reading-MAE/MAE result2.png","hash":"65a47208b3ab66a13c5925ce51a1f03906c126c0","modified":1651198712753},{"_id":"source/_posts/paper-reading-Vision-Transformer/ViT ablation 2.png","hash":"8b05e385a40bf6b53c6b2d33f5555d22f845fe19","modified":1650983346443},{"_id":"source/_posts/learning-rate-schedule/experiment.png","hash":"6aebe78be3d9979e72f67b7b044cba9aace879f9","modified":1646837491090},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SimCLR aug.png","hash":"d3babff547342fdf7453ddfab32a53f5fcbc4cb7","modified":1651932824455},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/RPCA for denoising.png","hash":"628325622a918af6e402da49e46adc36084c1836","modified":1654159964847},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/RPCA for denoising.png","hash":"628325622a918af6e402da49e46adc36084c1836","modified":1654159964847},{"_id":"source/_posts/paper-reading-MAE/MAE result.png","hash":"de7915af273cca92a55890508a69dfa41fe81e15","modified":1651198517173},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/flow past a cylinder result.gif","hash":"ea959aeced62fc6605f29fb0391f2b2866646819","modified":1654445080172},{"_id":"source/_posts/paper-reading-AlexNet/alexnet results.png","hash":"69f3bbb71d125bbbf5941a9b01fbe42766b35cc6","modified":1649425379662},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/Cross_Correlation_Animation.gif","hash":"8d102b9eb9730bef4035fec1b6f6b8a061184e30","modified":1654522262361},{"_id":"public/baidusitemap.xml","hash":"819ab262dc9ba2a6b27524e92ef33e0409e05988","modified":1655996445171},{"_id":"public/content.json","hash":"a45850f115939f2f3f21b56d1187e81d61595bb6","modified":1655996445171},{"_id":"public/sitemap.xml","hash":"c75bf7f702c5420c9db6c056fe8d9e0f8b2bd257","modified":1655996445171},{"_id":"public/local-search.xml","hash":"5084e78d0b70921a4284535d704db6cb7873841b","modified":1655996445171},{"_id":"public/about/index.html","hash":"6de81d6a3f7d706ab1c16993a82fbafbc8638504","modified":1655996445171},{"_id":"public/2022/02/22/Hello-ShouRou/index.html","hash":"47ae3f1579b4288c1a119f34b3d77231abf7f68a","modified":1655996445171},{"_id":"public/archives/index.html","hash":"a0ed95a2eab28bb42b497502879d053d7ec0c640","modified":1655996445171},{"_id":"public/archives/page/2/index.html","hash":"4e4c6811f639869e517b6620ea3ad8454aa5ab06","modified":1655996445171},{"_id":"public/archives/2022/page/2/index.html","hash":"b6300a47845b1fbb0179f91bea88faf3de0df824","modified":1655996445171},{"_id":"public/archives/2022/page/3/index.html","hash":"dab5ced8eee8382c33c2304a4edcdc5e2d38340b","modified":1655996445171},{"_id":"public/archives/page/3/index.html","hash":"109ae19dc92ccc66565ca80c21b3b51fbcfff104","modified":1655996445171},{"_id":"public/archives/2022/02/index.html","hash":"dcdb35acc0e213d3ff24a0087b5fb96da2e8ffe9","modified":1655996445171},{"_id":"public/archives/2022/03/index.html","hash":"8e34bfeaaf64c69352b7f3f911aa237962155a3f","modified":1655996445171},{"_id":"public/archives/2022/index.html","hash":"af03a12e61939b5be401db0fc1a27b4f8bd7b770","modified":1655996445171},{"_id":"public/archives/2022/06/index.html","hash":"6e3a767efccfa2423f404837f6936d569e380d87","modified":1655996445171},{"_id":"public/archives/2022/05/index.html","hash":"23e51143bb95b70298b918364d28d997b27f439b","modified":1655996445171},{"_id":"public/archives/2022/04/index.html","hash":"744e4f45cb0c1aea707b38be219a8d52a667a2a0","modified":1655996445171},{"_id":"public/tags/OpenFOAM/index.html","hash":"b7fcc735beefe11e4f50d518abefdb506c982172","modified":1655996445171},{"_id":"public/tags/blog/index.html","hash":"498ddc4624d6385f541ed6f308923ebc87cd4ecf","modified":1655996445171},{"_id":"public/tags/hexo/index.html","hash":"31a1d653e9f4584ab25fedca5d0a0a491ec85c9f","modified":1655996445171},{"_id":"public/tags/deep-learning/index.html","hash":"d22d33091d7377fd5d49cf07f6aa13a16e1a8758","modified":1655996445171},{"_id":"public/tags/deep-learning/page/2/index.html","hash":"9272c4f90806a19ff0978f61382dbc841e3a6fdb","modified":1655996445171},{"_id":"public/tags/mac/index.html","hash":"ff8f33f477acb1c8399fc669d2e534364deba953","modified":1655996445171},{"_id":"public/tags/deep-learning-tricks/index.html","hash":"fb0d0fb5c34dc4eb95546ac160a64d096ba7ded1","modified":1655996445171},{"_id":"public/tags/fluid-dynamics/index.html","hash":"0863aa37409c1d9c2158ae56b54b448d3dc60c2e","modified":1655996445171},{"_id":"public/tags/paper-reading/page/2/index.html","hash":"7de253e3bab2621797a1c788ea04de60e6bb2190","modified":1655996445171},{"_id":"public/404.html","hash":"28f3bcf6858c44b16d3ed6f7ba279a139e1103ee","modified":1655996445171},{"_id":"public/tags/paper-reading/index.html","hash":"36432a1946049b4394d9fa258584ef6376998495","modified":1655996445171},{"_id":"public/tags/index.html","hash":"eddb583b3b7c750cd0fd524b49e6654fd52d78b1","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/index.html","hash":"c0c7a70cc01f6c1a9a9ce1f3c5e7716a8becdea4","modified":1655996445171},{"_id":"public/CV/index.html","hash":"805737ac881daa684369e078f91db5bd985eb536","modified":1655996445171},{"_id":"public/2022/06/09/Build-OpenFOAM-from-source-on-M1-Mac/index.html","hash":"47e8ca83768ec68480388cc90dc9895db475cfa2","modified":1655996445171},{"_id":"public/2022/06/09/Review-of-Physical-Informed-Neural-Network/index.html","hash":"82f8f5a4e993b63b414527cb603984eb39b135d0","modified":1655996445171},{"_id":"public/2022/06/01/Lesson-note-Machine-learning-for-fluids-dynamics/index.html","hash":"e7afd1b380be9088391d5d5efd3c5655a86c475b","modified":1655996445171},{"_id":"public/2022/05/26/External-flow-fundamentals/index.html","hash":"1760c0a87b9dfc299d2fbdacd50bfaa9a5b60a05","modified":1655996445171},{"_id":"public/2022/05/20/Derivation-of-Non-dimensional-NS-Equations/index.html","hash":"86d9ad43e6541cdcba5e8765bb1e6e990eb8e249","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/index.html","hash":"2f48e28476b4463b4c48014395ce458963ea7b7d","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/index.html","hash":"cde2051b26819646a1cbb1c19b4271d658292280","modified":1655996445171},{"_id":"public/2022/05/12/Derive-the-NS-equation-from-scratch-AGAIN/index.html","hash":"eeffce40c8e476cb51e2e7a26f38a7f8f0584f11","modified":1655996445171},{"_id":"public/2022/05/09/paper-reading-Swin-transformer/index.html","hash":"bca65d77012e2e67284bdbf4fc3ec5d56262f369","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/index.html","hash":"7a642b21095c9c4014b3f2bf07589656842da51d","modified":1655996445171},{"_id":"public/2022/04/30/Switch-blog-theme-to-FLUID/index.html","hash":"dafea0b1c032ce65872b25df914c535e490e8b40","modified":1655996445171},{"_id":"public/2022/04/27/paper-reading-MAE/index.html","hash":"2257d336a8420598c186b979bab74009d6c93b19","modified":1655996445171},{"_id":"public/2022/04/21/paper-reading-Vision-Transformer/index.html","hash":"2e7d69fb5c2228529f3d5246dfcc9a540a71c804","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/index.html","hash":"47f6e57a5b446f0d06bc0b824910d104fd082c52","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/index.html","hash":"df78a905d1463d69131987b07a152ca97f73608c","modified":1655996445171},{"_id":"public/2022/04/15/paper-reading-bert/index.html","hash":"34da8f2988e7a5c567368f866926045c1bf54246","modified":1655996445171},{"_id":"public/2022/04/12/paper-reading-transformer/index.html","hash":"c9374f8872e50f6e4564389090baca44fcca732f","modified":1655996445171},{"_id":"public/2022/04/07/paper-reading-AlexNet/index.html","hash":"323f104f5e0c89b6c15cc9040069f458c2efb77f","modified":1655996445171},{"_id":"public/2022/04/02/paper-reading-start/index.html","hash":"663d977fd7b26ee5559a7feec0463c5be7f54799","modified":1655996445171},{"_id":"public/2022/03/08/learning-rate-schedule/index.html","hash":"aea35f62d4aca43f6afd055b072bafda2fa3bed7","modified":1655996445171},{"_id":"public/2022/03/04/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/index.html","hash":"9a8f2fbf23aa24141d1f6a6dd94bcb459ba57cce","modified":1655996445171},{"_id":"public/2022/04/09/paper-reading-ResNet/index.html","hash":"558a37e4be4e264ae27516760023637eb597f25c","modified":1655996445171},{"_id":"public/2022/02/28/install-d2l-moudule-on-apple-m1-chip-for-deep-learning/index.html","hash":"5c3fd9142b2ff95625bd27b3e89408bd4f0a7904","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/index.html","hash":"3358eea38e454240a1b01080c914dc55e6a4e2e6","modified":1655996445171},{"_id":"public/2022/04/14/paper-reading-A-gentle-introduction-to-graph-neural-networks/index.html","hash":"387372762df7caf34a9ab71e9f262110466f6558","modified":1655996445171},{"_id":"public/index.html","hash":"14e6edcf1d6172866cac297dbec4a6d28aa88f5a","modified":1655996445171},{"_id":"public/page/3/index.html","hash":"8d14c44d70eef09f50500c43bf3c5e5d97696b15","modified":1655996445171},{"_id":"public/page/2/index.html","hash":"f884cc6a23652baff312f4a31bfdec51bb435459","modified":1655996445171},{"_id":"public/img/favicon.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1655996445171},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1655996445171},{"_id":"public/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1655996445171},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1655996445171},{"_id":"public/img/about_banner.png","hash":"7c0f697200eb7da68dbc321c508e57018b1223b1","modified":1655996445171},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1655996445171},{"_id":"public/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1655996445171},{"_id":"public/img/bg_banner.avif","hash":"06980e9258fab6a2d68019df1665099c6639a660","modified":1655996445171},{"_id":"public/img/article_banner.avif","hash":"e307fb78545012ac5896ec812c8a128356ab0c35","modified":1655996445171},{"_id":"public/img/avatar.jpeg","hash":"c6575ca36dc695bf8330d6253ebd38e9761a9462","modified":1655996445171},{"_id":"public/img/about_banner.avif","hash":"3a4cf09849f67a526772893a30036ffb15531a25","modified":1655996445171},{"_id":"public/img/bg_banner.png","hash":"2dc2a06dee2495dc9ebefdee7794e637c14ecf0e","modified":1655996445171},{"_id":"public/img/favicon.ico","hash":"7e55bf11b25279bbe79d6f9790374a4427e92eb6","modified":1655996445171},{"_id":"public/index/paper-reading-ResNet.png","hash":"614f16dda779bd39bd868d62fcf64eb99330eacc","modified":1655996445171},{"_id":"public/index/paper-reading-GNN.png","hash":"c314bc4e98fcfc150d5d633ffc0882a728d691ea","modified":1655996445171},{"_id":"public/2022/05/26/External-flow-fundamentals/V formation.jpeg","hash":"e1e1bab1350c1999e7a64c080196c107e4a1584b","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/Displacement deformation.png","hash":"f2c1e059d0013e853ec24402ef9d430d8bd8d6e4","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/Differential mass conservation.png","hash":"073412f05fad5e3d2c742632e35cee16b3d4fdef","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/Polar coordinate.png","hash":"217062c7ebe88b088143cb1754d1f894a4787744","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/Material derivatives.png","hash":"089d886f2b3ad1a0ef4824dc9c78b36cd8350b18","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/Viscous stress on CS.png","hash":"713bb6507fc97200750edaab42ede7884da34ff5","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/Vortex line example.png","hash":"205735042c50e548198f8acec193753c99a452a2","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/Stream function property.png","hash":"22944b06a1157f33478740222c0ee3c33bae7ee9","modified":1655996445171},{"_id":"public/2022/05/12/Derive-the-NS-equation-from-scratch-AGAIN/region of significant viscous work.png","hash":"b8c21a3e9b24336097212b8073d7f0e16774743f","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/Channel flow.png","hash":"924d612ebeeca234c1356b04d60dca554ac716ac","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/Poiseuille flow.png","hash":"ae89d9ac5833b71fd77f4679c66cbf94fef7ab50","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/Physical interpretation.png","hash":"e84700d43dec0a6e78a38cee9dde109278926447","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/Plane Couette flow.png","hash":"c71e03e79c834ce3e55f5bcce0439eb283dd94a7","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/plug flow.png","hash":"52cdee5ee0898c3f34203884862afb0ac8aa0959","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/Google sitemap inspect 3.png","hash":"091b41b10a1cc1c91cb81f48b062d32bc57b79d5","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/bing search console success.png","hash":"03acd2a59a1e8af3276f36039a235c44afa5a218","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/bing sitemap.png","hash":"f8ca2e88f4c6e1969395b7617075010a4a697565","modified":1655996445171},{"_id":"public/2022/03/04/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/Cross entropy loss function.png","hash":"f39593d083f6b6a97eb20780a4be745e19dd0452","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/The-von-Karman-vortex-street-generated-by-the-Rishiri-island.jpeg","hash":"10c278cce82c18cf0a29542b7a10dd378d1a0d26","modified":1655996445171},{"_id":"public/2022/03/08/learning-rate-schedule/2d cyclic learning rate schedule.png","hash":"c8123233438e88551c7453ecd19706baa436bc4a","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/surprising_stl10_10e.png","hash":"fa73b9fe4128e8da615a1e276ad4d21bf44ee562","modified":1655996445171},{"_id":"public/2022/04/15/paper-reading-bert/model size graph.webp","hash":"faed538a605818e2cef417ed29692bf18745daf5","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/1D scalar convection.png","hash":"25d87ec24a78e5d1d0092d323540bb3b4d410a86","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/2D scalar convection control volume.png","hash":"d9c5634d8a63f493c51d1b58b98c0be9f1ab64e5","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/Riemann problem illustration.png","hash":"f02ad4756e2dbfb432ae17b6687c869101b918ef","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/shock path control volume.png","hash":"4047c144c3fab96a3c1d852f98eaa2ab9509638c","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/shock wave.png","hash":"ee0363173a5b2829430e98172f7d4922c74e2d04","modified":1655996445171},{"_id":"public/index/Lesson_note_ML_for_fluid_dynamics.jpeg","hash":"ac471e713d0c8746184c21466a59414f621a83bd","modified":1655996445171},{"_id":"public/index/OpenFOAM.png","hash":"0705d7e64afcc73ab4d1eb42a547c51dc13ee35c","modified":1655996445171},{"_id":"public/index/PINN.png","hash":"e0f47badd91f58aeea1d1f5a1b388cbc47d68fa2","modified":1655996445171},{"_id":"public/index/deriving_NS_again.jpeg","hash":"7e70b300fa1f1b17af79b393067873d4bce02ab9","modified":1655996445171},{"_id":"public/index/fvm_schemes.png","hash":"d47553bfc8c6fe84eb5a6a3030a71c925c16c9b3","modified":1655996445171},{"_id":"public/index/paper-reading-AlexNet.png","hash":"3cb5a9abe107ce31a070d8e384cf9e9cf507ad1f","modified":1655996445171},{"_id":"public/index/paper-reading-MAE.png","hash":"e2d85b7de3b9801e63012959a582cba4d846bdf4","modified":1655996445171},{"_id":"public/2022/06/09/Build-OpenFOAM-from-source-on-M1-Mac/Case sensitive volume step three.png","hash":"7730676fb556e026b1ea7c84ba6438aa189d1015","modified":1655996445171},{"_id":"public/2022/05/26/External-flow-fundamentals/Boundary layer control volume.png","hash":"d0f0544107480cfc857d590c4c283eecfad7753e","modified":1655996445171},{"_id":"public/2022/06/09/Build-OpenFOAM-from-source-on-M1-Mac/Case sensitive volume step two.png","hash":"59e7aa090ada59450c96b690038a0ee7c2f62033","modified":1655996445171},{"_id":"public/2022/05/26/External-flow-fundamentals/magnus effect illustration.png","hash":"f937820d76961741c32ce4e8324a285291a85cad","modified":1655996445171},{"_id":"public/2022/05/26/External-flow-fundamentals/displacement thickness.png","hash":"0130b05911aff4534da7bffd85d05813456ad353","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/Flow direction based on stream function.png","hash":"6d96a9b4ce409a7bfad612a98026f9f264be8827","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/Aerofoil vortex shedding.png","hash":"242454d3e9d89266efd603b516586036e3fba7a0","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/Surface forces on CS.png","hash":"e1ce7c93c7a04acdd32fe4d6313fa3fb610ecc98","modified":1655996445171},{"_id":"public/2022/06/01/Lesson-note-Machine-learning-for-fluids-dynamics/POD Analysis of Cylinder Flow.jpeg","hash":"14927089e159da72f6b233d71f125d1ac0d99a1f","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/3 flow regimes.png","hash":"c2cb9996083d24ad329a538d7743dbee4703a350","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/being sitemap connect google.png","hash":"2f7067940f7d336d1c87987c26562bb87b4f90bf","modified":1655996445171},{"_id":"public/js/boot.js","hash":"3de344ee619da989f6dccf7c2ae459fe91075983","modified":1655996445171},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1655996445171},{"_id":"public/js/events.js","hash":"4b9d2676c9544db9cc40a8c7d18456792299ba86","modified":1655996445171},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1655996445171},{"_id":"public/js/leancloud.js","hash":"53987b7a668ea0623370eb83ed5311766221b557","modified":1655996445171},{"_id":"public/js/plugins.js","hash":"d058f30bd09b28769c4d8313428ff23dfc8d52dd","modified":1655996445171},{"_id":"public/js/local-search.js","hash":"633f0142c657805359b0197f287e12ae4bcde731","modified":1655996445171},{"_id":"public/js/color-schema.js","hash":"f1fdd512f3ef92ff5db4a49f5a3143d5ddea9858","modified":1655996445171},{"_id":"public/js/utils.js","hash":"4a43f2700e91937650bef511fd438825b001c4c6","modified":1655996445171},{"_id":"public/css/main.css","hash":"a9cc4a030eb39f8e560eff091363d227a9bcefc3","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/baidu console sitemap.png","hash":"8ecba7e34a53e980586ae8ab154511d951867aee","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/non-newtonian flow.png","hash":"7c3aa45c54c4b436836440d2c064b68970e1132f","modified":1655996445171},{"_id":"public/2022/03/04/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/accuracy curve applying label smoothing.png","hash":"4aeeb4d6d7711a4396e2149e4d1f8130d183edcc","modified":1655996445171},{"_id":"public/2022/03/08/learning-rate-schedule/SGD with learning rate decay.png","hash":"83c473cfe0a99facc1b1ab54af01115989e11b0c","modified":1655996445171},{"_id":"public/2022/03/08/learning-rate-schedule/source ppt.pptx","hash":"1cd5b8c2dcc76d002d10173f1c0071bf331898e4","modified":1655996445171},{"_id":"public/2022/04/27/paper-reading-MAE/MAE pixels vs tokens.png","hash":"a1e7a8a133838b07c51f40f5cfbb1c0cfa7fe0ed","modified":1655996445171},{"_id":"public/2022/04/27/paper-reading-MAE/MAE segmentation.png","hash":"3212f43a4fc79d5eb5ba23ff22df7525c3c99953","modified":1655996445171},{"_id":"public/2022/04/21/paper-reading-Vision-Transformer/ViT variants.png","hash":"d4f9886bdfcfd28b0c84ca95cfef3b6982acfa05","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT timeline.png","hash":"109115b9d17368fd43c4c536fe50449deec95fcf","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/Burgers's equation under Riemann Problem with uL = 1, uR=0.png","hash":"50998de5b64f42247b0b3645b4b849f75cb25cf1","modified":1655996445171},{"_id":"public/img/article_banner.png","hash":"e24b9d21bd336231d5000a075cb2ea6e4d2c3918","modified":1655996445171},{"_id":"public/index/Lesson_note_MLFD_turbulence.jpeg","hash":"ef5e7cb04145e3b3c954978c2d12e1b14db9e37c","modified":1655996445171},{"_id":"public/index/Lesson_note_MLFD_models_and_control.jpeg","hash":"67a405862658b7cae9353482a136a6bc0dcdb3f5","modified":1655996445171},{"_id":"public/index/deriving_NS_intergral.png","hash":"83388688a57ce95b46b2598032bf02c6e9818fa9","modified":1655996445171},{"_id":"public/index/Lesson_note_MLFD_patterns.jpeg","hash":"5e6cfe46b79784195760a22bb5ba1863499e35d1","modified":1655996445171},{"_id":"public/index/deriving_NS_again.png","hash":"63f6ba11aa53d8843725a4f7dc8df97634ad2a89","modified":1655996445171},{"_id":"public/index/non-dimensional_NS.png","hash":"bd47a0351919010817f02ef656362a591f5c3022","modified":1655996445171},{"_id":"public/index/paper-reading-transformer.png","hash":"df4389aa0f63de9f529630eb47949742432cf0a0","modified":1655996445171},{"_id":"public/2022/06/09/Build-OpenFOAM-from-source-on-M1-Mac/Case sensitive volume finish.png","hash":"73030d9511cb9c48c99b51bc33d1fa6e9aa15860","modified":1655996445171},{"_id":"public/2022/06/09/Build-OpenFOAM-from-source-on-M1-Mac/Case sensitive volume step one.png","hash":"58e720c8331da8d46e4eb52de4d362482e874069","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/Fluid partical deformation.png","hash":"0fb36b69430798b6013c53ae72b95ff21e53fd4a","modified":1655996445171},{"_id":"public/2022/05/14/Derivation-of-Differential-Fluid-Equations/Fluid particle deformation.png","hash":"fd4fb04c566c5c7ec96d312f0f152f88058047b5","modified":1655996445171},{"_id":"public/2022/05/12/Derive-the-NS-equation-from-scratch-AGAIN/Bernoulli's Equation CV.png","hash":"392bd1dc40696da877107be3657fd502a8b850a5","modified":1655996445171},{"_id":"public/2022/05/12/Derive-the-NS-equation-from-scratch-AGAIN/Flow_pass_control_surface.png","hash":"b952fe70e8f9d04e2071326755082eb60fe5a591","modified":1655996445171},{"_id":"public/2022/05/12/Derive-the-NS-equation-from-scratch-AGAIN/Reynolds transport theorem proof.png","hash":"cae835617aefc3db40315de5f85ab695dfc9b2e6","modified":1655996445171},{"_id":"public/2022/06/01/Lesson-note-Machine-learning-for-fluids-dynamics/parabolic reduced order model.png","hash":"95149c0fdb33f514e7981eecc775fb314030bc8b","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/puff lifetimes.png","hash":"07853f324dbae9abc6b563bda1969d3ec2be5811","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/can't fetch sitemap.png","hash":"f33cf775460666ebefa5e8aa56b768a1ce4d1af4","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/google console varification.png","hash":"54b854a7bc2152a565ae61ab6f513fe8fad31139","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/PCA as auto-encoder.png","hash":"60d29dddd27be9c575657f9536e26e031bdfc497","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/deeper auto-encoder.png","hash":"a76b3f3415396541a0409d356eb5602845c496df","modified":1655996445171},{"_id":"public/2022/03/08/learning-rate-schedule/warmup on large batches.png","hash":"c7c61a90faa6fbe7cbb58f35c651cfacc5357db8","modified":1655996445171},{"_id":"public/2022/04/09/paper-reading-ResNet/ResNet figure 2.png","hash":"4aae59eb537b2676e973e61b714f5e2260592443","modified":1655996445171},{"_id":"public/2022/04/15/paper-reading-bert/BERT learnable paramters.png","hash":"8839786a937ceb1f0a58110f5dc72b06a48024b8","modified":1655996445171},{"_id":"public/index/paper-reading-ViT.png","hash":"e9c0e2dfd591c482c8471cafaaed89b9de3a11ea","modified":1655996445171},{"_id":"public/2022/05/26/External-flow-fundamentals/Similarity solution.png","hash":"bd0923fa18e99f079eee9458a7e64794e7e4451f","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/Pressure drop.png","hash":"39431c9ef9380996a6232e412cb796f0ebcad52d","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/inclined pipe.png","hash":"8b936b8634de0e8cf67e7379a43b26a894aa7e07","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/baidu console.png","hash":"1b21c2b62d1217fc07402a2b5a93ade16b9d06a9","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/check google search.png","hash":"a283f4c31f86a0f29ffc685c572431a00e5199c7","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/typora setting.png","hash":"4bbaf27946caa82912470a69221a7f494b985bf9","modified":1655996445171},{"_id":"public/2022/03/04/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/accuracy curve compare label smoothing with hard label.png","hash":"cdae6eacdd69d900057bf680a2d321e58dda17d9","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/sufficient measurements.png","hash":"db9f4c7b6ad4b4a91d36f53fe164ee35c168526f","modified":1655996445171},{"_id":"public/2022/04/14/paper-reading-A-gentle-introduction-to-graph-neural-networks/GNN graph level task.png","hash":"e1af92d12c8f7e0b9943f7ed839198b03088a7e4","modified":1655996445171},{"_id":"public/2022/03/08/learning-rate-schedule/CLR.png","hash":"e7bbe3fb1a452bf830806ae0dba4ec0eb6ae236b","modified":1655996445171},{"_id":"public/2022/03/08/learning-rate-schedule/SGDR.png","hash":"ef63d3bb9bf8b0083de55ef9b3c9fc4a0d57608d","modified":1655996445171},{"_id":"public/2022/04/21/paper-reading-Vision-Transformer/VIT algorithm.png","hash":"49c6702a90c2be602b51765d7e9824f5aa722522","modified":1655996445171},{"_id":"public/2022/04/21/paper-reading-Vision-Transformer/VIT positional embedding ablation.png","hash":"774bb656e0f545459f58b0b0b521c1883fe5df01","modified":1655996445171},{"_id":"public/2022/04/21/paper-reading-Vision-Transformer/VIT model overview.png","hash":"25618195462760c8e7bcccf86e02e43cff1ee0c9","modified":1655996445171},{"_id":"public/2022/04/09/paper-reading-ResNet/ResNet figure 5.png","hash":"535021caab08b1436c194688c6f15cbbce199308","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/SimCLR projection head.png","hash":"98994ab627d2775b9f7fbc09dd0484d8fb60baff","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT-3 result 2.png","hash":"646a38e14e8bef9fd0f5615acf0cbd43c5042205","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT3 race.png","hash":"3ceb1c3a74634b2c40b608e3c6a9529a141907f1","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT3 models.png","hash":"93adbab90cb1e999d9a6969ebfea7b1e82672d68","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/Expansion shock solution to the Riemann Problem.png","hash":"a7846abc515f61722df6467676dbef2186e6169d","modified":1655996445171},{"_id":"public/index/internal_flow.png","hash":"397089a9217b32fabe31bf9e48f4c55c950322d8","modified":1655996445171},{"_id":"public/index/external_flow.png","hash":"8e2bfb1db58191d32a7239f26846da9e63899b28","modified":1655996445171},{"_id":"public/index/paper-reading.png","hash":"de515be5fdb766b4a671f1537d536fb8fa096ac8","modified":1655996445171},{"_id":"public/2022/05/26/External-flow-fundamentals/Boundary layers.png","hash":"038daca7b54bed2852f950384ed60aedacd82ef1","modified":1655996445171},{"_id":"public/2022/05/26/External-flow-fundamentals/Flow past an airfoil.gif","hash":"70ca1917a78a6f5eef087e0e25fa6039e907aaa5","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/google console.png","hash":"240520671ae14a4db700b002e99ee276bf1fe650","modified":1655996445171},{"_id":"public/2022/03/04/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/leave class code.png","hash":"224786316ca7dc910a29d3c5acb42f755f3bc662","modified":1655996445171},{"_id":"public/2022/03/04/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/Label smoothing feature norm.png","hash":"47841e9b48ef8aaa61bdedf70b593a1d563840ca","modified":1655996445171},{"_id":"public/2022/03/08/learning-rate-schedule/cyclic learning rate schedule.png","hash":"0c093af7caf829e60f29eea8f72140ba75a85ba3","modified":1655996445171},{"_id":"public/2022/04/27/paper-reading-MAE/MAE comparison.png","hash":"695e1965c84f6825a38cc65d9b00c45ffff305d9","modified":1655996445171},{"_id":"public/2022/04/27/paper-reading-MAE/MAE mask ratio.png","hash":"75bc0ff014fb48e2e3adff8f2a64298c498ba98d","modified":1655996445171},{"_id":"public/2022/04/07/paper-reading-AlexNet/unsupervise learning cake.png","hash":"adcb79d097ff6fdea2021bb4668f8eeb8a57358d","modified":1655996445171},{"_id":"public/2022/04/27/paper-reading-MAE/MAE classification.png","hash":"1468fc45ed545445d33bce0b4bcd390488c7eb37","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/CPC illustration.png","hash":"41fb22ea936df830dfa7a4f4416447561777476a","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/SimSiam illustration.png","hash":"6571715e1a0e0d5bf5e247d79398e6234ee3df3c","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT3 gender.png","hash":"49460dd410dcef903e806afb83aeaa82013049cf","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT3 training data.png","hash":"d8c11af3e71e7ce5d5aa4cd47e6836d816f04a5b","modified":1655996445171},{"_id":"public/index/paper-reading-contrastive-learning-review.png","hash":"87428809714e60703d0ff1bf083d022a75fe23b2","modified":1655996445171},{"_id":"public/2022/05/26/External-flow-fundamentals/Skyscraper wind effect.png","hash":"cf34a00ce5e0c868217ea84aebc3eaaeb405d680","modified":1655996445171},{"_id":"public/2022/05/26/External-flow-fundamentals/Wingtip vortex.jpeg","hash":"3f19811d3158036b3866125cb54c6321a6d973d5","modified":1655996445171},{"_id":"public/2022/06/01/Lesson-note-Machine-learning-for-fluids-dynamics/RANs modeling with DNN.png","hash":"a431b060e431f81ec868e7fa47cfc8f87d1b385b","modified":1655996445171},{"_id":"public/2022/06/01/Lesson-note-Machine-learning-for-fluids-dynamics/Structure of control scheme.png","hash":"2c3b865cb30367c11d9ed32e531ffc60b683c2fa","modified":1655996445171},{"_id":"public/2022/06/01/Lesson-note-Machine-learning-for-fluids-dynamics/Schematic overview of the proposed sparse modeling procedure.png","hash":"6e6bc08cf1c15f7d36303dd39abbc2dc025125ea","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/puffs.png","hash":"e72e5c0844241c207e9c4265b81885169230c82b","modified":1655996445171},{"_id":"public/2022/03/04/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/hard label.png","hash":"8e83c8d43703867f9faf7a1db317fcb040a24045","modified":1655996445171},{"_id":"public/2022/03/04/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/soft label.png","hash":"2d6357cd03c4b4149f5191e91d781cc5a554a897","modified":1655996445171},{"_id":"public/2022/04/27/paper-reading-MAE/MAE ablation.png","hash":"c13294f9565644c4ae0f987cba573fb5cfd44beb","modified":1655996445171},{"_id":"public/2022/04/21/paper-reading-Vision-Transformer/ViT results.png","hash":"5506ce41ac7b84fc8c10ce73c980d169531145ad","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/MoCo v3 result.png","hash":"0d7275a1068f23759c68d2b1f0d6fc4c7105546a","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT-3 approach.png","hash":"21e4e6703fcf07679e8cb6cf42931b444145426b","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT3 result.png","hash":"3c4192ef7ff33164dba01b3ea9754c3b02011bda","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/Burgers's equation under Riemann Problem general solution.png","hash":"efb308531cc8f1c700516ad16defbf3159211880","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/Burgers's equation under Riemann Problem with uL = 0, uR=1.png","hash":"45457b245f96b2c08821ae3e8c79b5f703fe075f","modified":1655996445171},{"_id":"public/2022/04/12/paper-reading-transformer/transformer.png","hash":"6eb38ed16fbaf3660d18b4266763411eadc5a452","modified":1655996445171},{"_id":"public/index/paper-reading-Swin-transformer.png","hash":"a6737c655d891aa43c1238a6b6b71240973d5a42","modified":1655996445171},{"_id":"public/2022/05/26/External-flow-fundamentals/Wakes.png","hash":"eeb0084ad1ea902659938b89303648287e5868ca","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT3 result 3.png","hash":"9360c9a0adb1051e96ff62e6273e4ad747297b6b","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/baidu console varification.png","hash":"09c2e3d1f3b52807bf6dd97d8ec42f7cfd1fe1c7","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/Last snapshot.png","hash":"9ccbadb43f29a86f56d4820913b7daaa8d31e211","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/sufficient training data.png","hash":"1b0cc8761ef1a21d2fb415b379d45fa35894dd6d","modified":1655996445171},{"_id":"public/2022/04/14/paper-reading-A-gentle-introduction-to-graph-neural-networks/GNN interative archtecture.png","hash":"06e8477aee1a6f12385895a4151dea90ca23e382","modified":1655996445171},{"_id":"public/2022/03/08/learning-rate-schedule/SGDR_REsult.png","hash":"f118bc7b7c5ea51afa9ae366f6bce17757963467","modified":1655996445171},{"_id":"public/2022/04/09/paper-reading-ResNet/ResNet table 1.png","hash":"782d634274c1221c9db07ea5c9367c4fef5fbe4b","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/BYOL batch norm ablation.png","hash":"347b21239a81e711a311303d6df7c0ed9d90cfc2","modified":1655996445171},{"_id":"public/2022/04/15/paper-reading-bert/BERT alibation study 1.png","hash":"f71b28cdf11f80dcf3fc5b8c89ad2624d6caad1c","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT3 performance with compute.png","hash":"e39d32f750f4853f15783654367e544c0bd70d50","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT3 result4.png","hash":"c261a581c8c8f50e1d9ef50b576415c5116e3467","modified":1655996445171},{"_id":"public/2022/04/12/paper-reading-transformer/transformer table1.png","hash":"637292c4c8f161ffa35d2b41ebcf1a37019638f3","modified":1655996445171},{"_id":"public/index/paper-reading-GPT1-3.png","hash":"e2d3ed4da740ca7849b5281b937dae81f06aa6af","modified":1655996445171},{"_id":"public/2022/05/26/External-flow-fundamentals/velocity profiles.png","hash":"4d6e73ea8da7a2a90b969cf754e8f36ec9e0551e","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/entrance effect.png","hash":"da8a91f9714a646cdcac31964ae701b395cd012c","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/github page.png","hash":"5262aa8e506f60a57b7ddc69a76c860bca21ffce","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/MoCo v2 ablation.png","hash":"894c293b4aaa78059dca3b09f8d50ccf7c57ff1b","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/contrastive learning illustration.png","hash":"f70921407f7b009a5ebffcf5bae839ffa0fa14f5","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT objectives.png","hash":"34aa333335dbb1d0292b65258750ac163a03df2f","modified":1655996445171},{"_id":"public/2022/04/12/paper-reading-transformer/layer norm.png","hash":"9e0a63ba884eb2efa0604a74dedb92d0cad7420b","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/Rarefaction wave solution to the Riemann Problem.png","hash":"97c52435b99908d93d7194158d27c5a69f54cbe2","modified":1655996445171},{"_id":"public/index/Switch-blog-theme-to-FLUID.png","hash":"edcc654e3b720f9cdb74f98ba215d9ab7de9e8da","modified":1655996445171},{"_id":"public/index/paper-reading-bert.png","hash":"a133a110af8e68d025d7717636d2a170a2e11a45","modified":1655996445171},{"_id":"public/2022/06/01/Lesson-note-Machine-learning-for-fluids-dynamics/super resolution interpolation and extrapolation comparison.png","hash":"89d256eda77e10af1e96152213a983a1e9e78ec5","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/super resolution interpolation and extrapolation comparison.png","hash":"89d256eda77e10af1e96152213a983a1e9e78ec5","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/DINO illustration.png","hash":"7c238c5d64b82d19ad3cf5db356f113c7cd19fb8","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/Instdisc method.png","hash":"33a33d9974f58b2741d3d14014cd0af8299bda10","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/BERT result with GPT.png","hash":"a922a5d9ec6bb140b431baa56ec969dc9d019395","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT2 performance.png","hash":"ed244f4af159e064c2862a8933cd891754a17b7d","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/Linear Advection Solutions.png","hash":"b9aad6595c0629f9c554cf28c6f00424ec89fa9d","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/Google sitemap inspect.png","hash":"90618421c6cab7c23ef65da92bc0c48090bc93ea","modified":1655996445171},{"_id":"public/2022/04/14/paper-reading-A-gentle-introduction-to-graph-neural-networks/GNN graph message passing.png","hash":"46c17f41a8ff34811854ff5c913693d167933833","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/node js install.png","hash":"49b580f0049a4e224ea17cbb30a33dc34e8acc3a","modified":1655996445171},{"_id":"public/2022/04/21/paper-reading-Vision-Transformer/VIT class token ablation.png","hash":"5c6b482cd85546e81183f7c6090cb110791f8dd4","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/BYOL model.png","hash":"4c6daf0b12cf1ba317fe57d6d952e67cfb149599","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/CMC illustration.png","hash":"61c9a904bffec4855fb9fc5abb3e1761405f3c39","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/MoCo v3 algorithm.png","hash":"49f72c325ab62d3c9a8b399640ec81f401b1edbd","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/Moco v1 illustration.png","hash":"87efead5961b597023bf6578a9cb9a97ace6e009","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/SimCLR v1 illustration.png","hash":"4ca6529c60e168c88a0258629fcc33e673b29751","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/SimSiam result.png","hash":"489962de2e8b96c7759a3921146f1acdea474f6a","modified":1655996445171},{"_id":"public/2022/05/09/paper-reading-Swin-transformer/CoCo and ADE20K SOTA.png","hash":"a8c59e9135abbd39d05f975ed3051dfa2cbf3707","modified":1655996445171},{"_id":"public/2022/03/04/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/source ppt.pptx","hash":"4e53421cbb49964ea368ac4c9259914407a20749","modified":1655996445171},{"_id":"public/2022/04/09/paper-reading-ResNet/ResNet table 3.png","hash":"62e26b0634b37d7dc652e5b301937fabd7ba69dd","modified":1655996445171},{"_id":"public/2022/04/09/paper-reading-ResNet/ResNet table 6.png","hash":"61fd7fcd8b823045cedbf6be8a3c91582124ee6f","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/MoCo v2 result.png","hash":"5af3dc01321424d7320fab395a131f9e0aa17d22","modified":1655996445171},{"_id":"public/2022/04/15/paper-reading-bert/BERT segment embedding.png","hash":"b3916ee35fc24b258adaf99313b3358e0de35510","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT 3 result 5.png","hash":"5bb6e24fd0d52e4153e80828ee9c250d15465c7b","modified":1655996445171},{"_id":"public/2022/04/27/paper-reading-MAE/MAE architecture.png","hash":"bd19b6cb51c6edf1b32eb6ed2ebf9423539e2cc6","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/Reynolds experiment.png","hash":"0b6934021eb77581c0f8494ff04061b87b16650a","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/statistical stationarity.png","hash":"dad0d0270e2e91e8489f48e3eff1f7a5f89a2068","modified":1655996445171},{"_id":"public/2022/04/27/paper-reading-MAE/MAE fine tune.png","hash":"5ef4e8a1bbf07ff7dc9694ebf0a5d7d656e66752","modified":1655996445171},{"_id":"public/2022/04/21/paper-reading-Vision-Transformer/ViT inspecting.png","hash":"3da9c71e7aaa955e3ff2ffe75c03fad55ff74004","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/InvaSpread illustration.png","hash":"199c4d7eab62b5a8b67b3a85e848ce1688ea6089","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/instance discrimination illustration.png","hash":"39ad8af531ab916acc48b7063860b13f41e5093e","modified":1655996445171},{"_id":"public/2022/06/01/Lesson-note-Machine-learning-for-fluids-dynamics/Deep autoencoder reconstruction.png","hash":"9cd8a98824eae087b95f8be93451ede5e7764ef4","modified":1655996445171},{"_id":"public/2022/02/22/Build-and-configure-a-personal-blog-via-hexo-and-yilia/Google sitemap inspect 2.png","hash":"acaf3254cd16099f517b0f1e1ab58aa89552e6cd","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/Deep autoencoder reconstruction.png","hash":"9cd8a98824eae087b95f8be93451ede5e7764ef4","modified":1655996445171},{"_id":"public/2022/04/09/paper-reading-ResNet/ResNet figure 4.png","hash":"b3e1f256838b4036e47d0584a8f84f8a7cd7be08","modified":1655996445171},{"_id":"public/2022/06/01/Lesson-note-Machine-learning-for-fluids-dynamics/Super resolution.png","hash":"35b68583878e0aef8abbd45517327f8dc278f006","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/Super resolution.png","hash":"35b68583878e0aef8abbd45517327f8dc278f006","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/Instdisc idea.png","hash":"0206d091b39c96f52e81e3797a9938ecce7e175f","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/SwAV multi crop.png","hash":"a4efe48fca22fb519a3a59a066a04b7ac1d0376f","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/SwAV illustration.png","hash":"bbfade7f559a35d1927602f428123fa571dd579f","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/Removing shadows, specularities and saturations from face images.png","hash":"42dd24b1879a4dad980abc57092caaa7a0661dc4","modified":1655996445171},{"_id":"public/2022/04/21/paper-reading-Vision-Transformer/CNN first layer filters.png","hash":"b33e246344bda2b7c32f402c7724b6ae07889114","modified":1655996445171},{"_id":"public/2022/04/09/paper-reading-ResNet/ResNet figure 1.png","hash":"765c606c3ae4bafcdd03dba4cda928f782204576","modified":1655996445171},{"_id":"public/2022/04/18/paper-reading-GPT1-3/GPT3 performance.png","hash":"3d82eb6c71f15523cb51c14bf33573debdd38717","modified":1655996445171},{"_id":"public/2022/06/18/FVM-schemes-fundamentals/Inviscid Burgers' equation Solutions.png","hash":"109e1b98fc3cfda7d1928f3177b77211d52b2f84","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/SimCLR aug result.png","hash":"f03a3e50d470716e7ef4621a6aa646a5c13f59a1","modified":1655996445171},{"_id":"public/2022/04/12/paper-reading-transformer/transformer table 3.png","hash":"f0c745ce7dbb8cbad5628f1a1b7f4ab207a8ebd7","modified":1655996445171},{"_id":"public/2022/05/21/Internal-flow-fundamentals/Moody chart.png","hash":"6955a3b14fbcd52a77d65071b786d6bc80a6a085","modified":1655996445171},{"_id":"public/2022/04/21/paper-reading-Vision-Transformer/VIT properties.png","hash":"f394d65267154e4aacb9329b6a1cd257a3165ddb","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/SwAV result.png","hash":"9ee1e27d64697f81bd8c2141f2bce187b81b9280","modified":1655996445171},{"_id":"public/2022/04/27/paper-reading-MAE/MAE result2.png","hash":"65a47208b3ab66a13c5925ce51a1f03906c126c0","modified":1655996445171},{"_id":"public/2022/04/21/paper-reading-Vision-Transformer/ViT ablation 2.png","hash":"8b05e385a40bf6b53c6b2d33f5555d22f845fe19","modified":1655996445171},{"_id":"public/2022/03/08/learning-rate-schedule/experiment.png","hash":"6aebe78be3d9979e72f67b7b044cba9aace879f9","modified":1655996445171},{"_id":"public/2022/05/03/paper-reading-contrastive-learning-review/SimCLR aug.png","hash":"d3babff547342fdf7453ddfab32a53f5fcbc4cb7","modified":1655996445171},{"_id":"public/2022/06/01/Lesson-note-Machine-learning-for-fluids-dynamics/RPCA for denoising.png","hash":"628325622a918af6e402da49e46adc36084c1836","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/RPCA for denoising.png","hash":"628325622a918af6e402da49e46adc36084c1836","modified":1655996445171},{"_id":"public/2022/04/27/paper-reading-MAE/MAE result.png","hash":"de7915af273cca92a55890508a69dfa41fe81e15","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/flow past a cylinder result.gif","hash":"ea959aeced62fc6605f29fb0391f2b2866646819","modified":1655996445171},{"_id":"public/2022/04/07/paper-reading-AlexNet/alexnet results.png","hash":"69f3bbb71d125bbbf5941a9b01fbe42766b35cc6","modified":1655996445171},{"_id":"public/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/Cross_Correlation_Animation.gif","hash":"8d102b9eb9730bef4035fec1b6f6b8a061184e30","modified":1655996445171}],"Category":[],"Data":[],"Page":[{"title":"about","layout":"about","date":"2022-04-30T08:23:48.000Z","_content":"\n## This is\n\nThis is the author of ShouRou, \n\nCurrently an automotive CFD engineer in [Shanghai Volkswagen Automotive Co., Ltd](https://volkswagengroupchina.com.cn/en/partner/saicvolkswagen). \n\nGraduated from [Imperial College London](https://www.imperial.ac.uk/) with a degree in [MSc Advanced Computational Methods for Aeronautics](https://www.imperial.ac.uk/study/pg/aeronautics/computational-methods/)\n\n## Interested in\n\nComputational fluid dynamic\n\nDeep Learning\n\nCoding(Debugging) with Goldberg Variations\n\n###### More on my [CV](/CV/)\n\n","source":"about/index.md","raw":"---\ntitle: about\nlayout: about\ndate: 2022-04-30 16:23:48\n\n---\n\n## This is\n\nThis is the author of ShouRou, \n\nCurrently an automotive CFD engineer in [Shanghai Volkswagen Automotive Co., Ltd](https://volkswagengroupchina.com.cn/en/partner/saicvolkswagen). \n\nGraduated from [Imperial College London](https://www.imperial.ac.uk/) with a degree in [MSc Advanced Computational Methods for Aeronautics](https://www.imperial.ac.uk/study/pg/aeronautics/computational-methods/)\n\n## Interested in\n\nComputational fluid dynamic\n\nDeep Learning\n\nCoding(Debugging) with Goldberg Variations\n\n###### More on my [CV](/CV/)\n\n","updated":"2022-05-01T16:39:30.258Z","path":"about/index.html","comments":1,"_id":"cl4r5iz1u0000l8ybay6bcmp9","content":"<h2 id=\"this-is\">This is</h2>\n<p>This is the author of ShouRou,</p>\n<p>Currently an automotive CFD engineer in <a href=\"https://volkswagengroupchina.com.cn/en/partner/saicvolkswagen\">Shanghai Volkswagen Automotive Co., Ltd</a>.</p>\n<p>Graduated from <a href=\"https://www.imperial.ac.uk/\">Imperial College London</a> with a degree in <a href=\"https://www.imperial.ac.uk/study/pg/aeronautics/computational-methods/\">MSc Advanced Computational Methods for Aeronautics</a></p>\n<h2 id=\"interested-in\">Interested in</h2>\n<p>Computational fluid dynamic</p>\n<p>Deep Learning</p>\n<p>Coding(Debugging) with Goldberg Variations</p>\n<h6 id=\"more-on-my-cv\">More on my <a href=\"/CV/\">CV</a></h6>\n","site":{"data":{}},"wordcount":291,"excerpt":"","more":"<h2 id=\"this-is\">This is</h2>\n<p>This is the author of ShouRou,</p>\n<p>Currently an automotive CFD engineer in <a href=\"https://volkswagengroupchina.com.cn/en/partner/saicvolkswagen\">Shanghai Volkswagen Automotive Co., Ltd</a>.</p>\n<p>Graduated from <a href=\"https://www.imperial.ac.uk/\">Imperial College London</a> with a degree in <a href=\"https://www.imperial.ac.uk/study/pg/aeronautics/computational-methods/\">MSc Advanced Computational Methods for Aeronautics</a></p>\n<h2 id=\"interested-in\">Interested in</h2>\n<p>Computational fluid dynamic</p>\n<p>Deep Learning</p>\n<p>Coding(Debugging) with Goldberg Variations</p>\n<h6 id=\"more-on-my-cv\">More on my <a href=\"/CV/\">CV</a></h6>\n"},{"title":"CV","layout":"about","date":"2022-05-01T08:58:03.000Z","_content":"\n## Work Experience\n\n#### Automotive CFD Engineer \n\n<div style=\"margin-top:-3%; text-align: right\"> 04/2021- present </div> \n\nPre R&D, [Shanghai Volkswagen Automotive Co., Ltd](https://volkswagengroupchina.com.cn/en/partner/saicvolkswagen).\n\n- OpenFOAM developing on automotive aerodynamic\n- Intelligent aided fluid dynamic\n\nEducation Background\n---\n\n#### MSc: [Advanced Computational Methods for Aeronautics, Flow Management and Fluid Structure Interaction](https://www.imperial.ac.uk/study/pg/aeronautics/computational-methods/) \n\n<div style=\"margin-bottom:-2%; text-align: right\"> 09/2019-11/2020 </div> \n\nDepartment of Aeronautics, Imperial college London\n\n- Grade: 74.3/100 (Merit)\n- Modules include: Computational fluid dynamics, High-Performance Computing, Aeroservoelasticity, introduce to flow control, Hydrodynamic Stability, Separated Flows and Fluid Structure Interaction, etc.  \n\n#### BEng: [Flight Vehicle Propulsion Engineering](https://en.nwpu.edu.cn/index.htm)\n\n<div style=\"margin-bottom:-2%; text-align: right\"> 09/2015-07/2019 </div> \n\nSchool of Power and Energy, Northwestern Polytechnical University \n\n- Grade: 86.5/100\n- Modules include: Fundamentals of Gas Dynamics, Fluid Mechanics, Heat Transfer, Mechanical theory, Turbomachinery etc. \n- Exchange student in senior year at Polytechnic University of Madrid\n\n#### Summer school: [Experimental Fluid Mechanics](https://odin.sdu.dk/sitecore/index.php?a=fagbesk&id=79256&lang=en)\n\n<div style=\"margin-bottom:-2%;; text-align: right\"> 8/2018 </div> \n\nFaculty of Mechanical Engineering, University of Southern Denmark\n\n- Performing a team project to optimise a wind turbine airfoil\n- Data analysing of wind tunnel and water channel PIV results\n- Visiting the LM Wind Power Test and Validation Centre\n\n#### Pre-university Qualification: Total Score of NCEE ([GaoKao](https://en.wikipedia.org/wiki/Gaokao)): 619/750\n\nAcademic Projects\n---\n\n#### Bifurcation and Oscillation Effects of Gyrotactic Swimming Microorganism Suspension in Vertical Pipe\n\n<div style=\"margin-bottom:-2%;; text-align: right\"> 05/2020-10/2020 </div> \n\nImperial College London MSc Individual Project\n\nDirector: [Dr. Yongyun Hwang](https://www.imperial.ac.uk/people/y.hwang)\n\n- Learning concepts of bioreactors and behaviours of micro-algae\n- Developing numerical solvers for microorganism suspension\n- Exploring and analysing bifurcations and instabilities under different flow conditions\n\n\n\n#### Flow Field Analysis Based on RANS Solver and BiGlobal Stability Theory\n\n<div style=\"margin-bottom:-2%; text-align: right\"> 02/2019-06/2019 </div> \n\nUndergraduate Graduation Project & [Erasmus+ Scholarship Programme](https://erasmus-plus.ec.europa.eu/)\n\nDirector: [Professor Eusebio Valero Sanchez](http://www.upm.es/observatorio/vi/index.jsp?pageac=investigador.jsp&idInvestigador=5214) & [Associate Professor Yaguo Lyu](https://teacher.nwpu.edu.cn/yaguo)\n\n- Handling of the necessary tool, DLR TAU-Code\n- Performing simulations of non-stationary problems\n- Analysing the stability of the flow fields by POD and DMD\n\n\n\n#### Design Research on Bionic Anti-drag Propeller\n\n<div style=\"margin-bottom:-2%; text-align: right\"> 04/2017-04/2018 </div> \n\n[China college students Internet+ Innovation and Entrepreneurship Competition](https://www.pilcchina.org/?locale=en)\n\nDirector: [Professor Wang yangang](https://teacher.nwpu.edu.cn/wangyg.html)\n\n- Proposing and design a novel drone propeller with serrated leading edge as project manager\n- Carrying out 3D modelling, CFD simulations and data analysis\n\n\n\n#### Starting Test of Pulse Jet Engine\n\n<div style=\"margin-bottom:-2%; text-align: right; font-size:15px; font-size:15px\"> 07/2017-08/2017 </div> \n\nScientific Research Practice Programme\n\nDirector: [Professer Yan Hong](https://teacher.nwpu.edu.cn/m/en/2010010152.html)\n\n- Setting up the experiment platform;\n- Measuring the thrust and pressure pulse frequency of a valveless pulse engine.\n\nProfessional Skills\n---\n\nI.T. SKILLS: Python, C++\n\nRelated software: OpenFOAM, CATIA\n\n","source":"CV/index.md","raw":"---\ntitle: CV\nlayout: about\ndate: 2022-05-01 16:58:03\n---\n\n## Work Experience\n\n#### Automotive CFD Engineer \n\n<div style=\"margin-top:-3%; text-align: right\"> 04/2021- present </div> \n\nPre R&D, [Shanghai Volkswagen Automotive Co., Ltd](https://volkswagengroupchina.com.cn/en/partner/saicvolkswagen).\n\n- OpenFOAM developing on automotive aerodynamic\n- Intelligent aided fluid dynamic\n\nEducation Background\n---\n\n#### MSc: [Advanced Computational Methods for Aeronautics, Flow Management and Fluid Structure Interaction](https://www.imperial.ac.uk/study/pg/aeronautics/computational-methods/) \n\n<div style=\"margin-bottom:-2%; text-align: right\"> 09/2019-11/2020 </div> \n\nDepartment of Aeronautics, Imperial college London\n\n- Grade: 74.3/100 (Merit)\n- Modules include: Computational fluid dynamics, High-Performance Computing, Aeroservoelasticity, introduce to flow control, Hydrodynamic Stability, Separated Flows and Fluid Structure Interaction, etc.  \n\n#### BEng: [Flight Vehicle Propulsion Engineering](https://en.nwpu.edu.cn/index.htm)\n\n<div style=\"margin-bottom:-2%; text-align: right\"> 09/2015-07/2019 </div> \n\nSchool of Power and Energy, Northwestern Polytechnical University \n\n- Grade: 86.5/100\n- Modules include: Fundamentals of Gas Dynamics, Fluid Mechanics, Heat Transfer, Mechanical theory, Turbomachinery etc. \n- Exchange student in senior year at Polytechnic University of Madrid\n\n#### Summer school: [Experimental Fluid Mechanics](https://odin.sdu.dk/sitecore/index.php?a=fagbesk&id=79256&lang=en)\n\n<div style=\"margin-bottom:-2%;; text-align: right\"> 8/2018 </div> \n\nFaculty of Mechanical Engineering, University of Southern Denmark\n\n- Performing a team project to optimise a wind turbine airfoil\n- Data analysing of wind tunnel and water channel PIV results\n- Visiting the LM Wind Power Test and Validation Centre\n\n#### Pre-university Qualification: Total Score of NCEE ([GaoKao](https://en.wikipedia.org/wiki/Gaokao)): 619/750\n\nAcademic Projects\n---\n\n#### Bifurcation and Oscillation Effects of Gyrotactic Swimming Microorganism Suspension in Vertical Pipe\n\n<div style=\"margin-bottom:-2%;; text-align: right\"> 05/2020-10/2020 </div> \n\nImperial College London MSc Individual Project\n\nDirector: [Dr. Yongyun Hwang](https://www.imperial.ac.uk/people/y.hwang)\n\n- Learning concepts of bioreactors and behaviours of micro-algae\n- Developing numerical solvers for microorganism suspension\n- Exploring and analysing bifurcations and instabilities under different flow conditions\n\n\n\n#### Flow Field Analysis Based on RANS Solver and BiGlobal Stability Theory\n\n<div style=\"margin-bottom:-2%; text-align: right\"> 02/2019-06/2019 </div> \n\nUndergraduate Graduation Project & [Erasmus+ Scholarship Programme](https://erasmus-plus.ec.europa.eu/)\n\nDirector: [Professor Eusebio Valero Sanchez](http://www.upm.es/observatorio/vi/index.jsp?pageac=investigador.jsp&idInvestigador=5214) & [Associate Professor Yaguo Lyu](https://teacher.nwpu.edu.cn/yaguo)\n\n- Handling of the necessary tool, DLR TAU-Code\n- Performing simulations of non-stationary problems\n- Analysing the stability of the flow fields by POD and DMD\n\n\n\n#### Design Research on Bionic Anti-drag Propeller\n\n<div style=\"margin-bottom:-2%; text-align: right\"> 04/2017-04/2018 </div> \n\n[China college students Internet+ Innovation and Entrepreneurship Competition](https://www.pilcchina.org/?locale=en)\n\nDirector: [Professor Wang yangang](https://teacher.nwpu.edu.cn/wangyg.html)\n\n- Proposing and design a novel drone propeller with serrated leading edge as project manager\n- Carrying out 3D modelling, CFD simulations and data analysis\n\n\n\n#### Starting Test of Pulse Jet Engine\n\n<div style=\"margin-bottom:-2%; text-align: right; font-size:15px; font-size:15px\"> 07/2017-08/2017 </div> \n\nScientific Research Practice Programme\n\nDirector: [Professer Yan Hong](https://teacher.nwpu.edu.cn/m/en/2010010152.html)\n\n- Setting up the experiment platform;\n- Measuring the thrust and pressure pulse frequency of a valveless pulse engine.\n\nProfessional Skills\n---\n\nI.T. SKILLS: Python, C++\n\nRelated software: OpenFOAM, CATIA\n\n","updated":"2022-05-01T16:37:19.323Z","path":"CV/index.html","comments":1,"_id":"cl4r5iz1x0002l8yb3akrh75t","content":"<h2 id=\"work-experience\">Work Experience</h2>\n<h4 id=\"automotive-cfd-engineer\">Automotive CFD Engineer</h4>\n<div style=\"margin-top:-3%; text-align: right\">\n04/2021- present\n</div>\n<p>Pre R&amp;D, <a href=\"https://volkswagengroupchina.com.cn/en/partner/saicvolkswagen\">Shanghai Volkswagen Automotive Co., Ltd</a>.</p>\n<ul>\n<li>OpenFOAM developing on automotive aerodynamic</li>\n<li>Intelligent aided fluid dynamic</li>\n</ul>\n<h2 id=\"education-background\">Education Background</h2>\n<h4 id=\"msc-advanced-computational-methods-for-aeronautics-flow-management-and-fluid-structure-interaction\">MSc: <a href=\"https://www.imperial.ac.uk/study/pg/aeronautics/computational-methods/\">Advanced Computational Methods for Aeronautics, Flow Management and Fluid Structure Interaction</a></h4>\n<div style=\"margin-bottom:-2%; text-align: right\">\n09/2019-11/2020\n</div>\n<p>Department of Aeronautics, Imperial college London</p>\n<ul>\n<li>Grade: 74.3/100 (Merit)</li>\n<li>Modules include: Computational fluid dynamics, High-Performance Computing, Aeroservoelasticity, introduce to flow control, Hydrodynamic Stability, Separated Flows and Fluid Structure Interaction, etc.</li>\n</ul>\n<h4 id=\"beng-flight-vehicle-propulsion-engineering\">BEng: <a href=\"https://en.nwpu.edu.cn/index.htm\">Flight Vehicle Propulsion Engineering</a></h4>\n<div style=\"margin-bottom:-2%; text-align: right\">\n09/2015-07/2019\n</div>\n<p>School of Power and Energy, Northwestern Polytechnical University</p>\n<ul>\n<li>Grade: 86.5/100</li>\n<li>Modules include: Fundamentals of Gas Dynamics, Fluid Mechanics, Heat Transfer, Mechanical theory, Turbomachinery etc.</li>\n<li>Exchange student in senior year at Polytechnic University of Madrid</li>\n</ul>\n<h4 id=\"summer-school-experimental-fluid-mechanics\">Summer school: <a href=\"https://odin.sdu.dk/sitecore/index.php?a=fagbesk&amp;id=79256&amp;lang=en\">Experimental Fluid Mechanics</a></h4>\n<div style=\"margin-bottom:-2%;; text-align: right\">\n8/2018\n</div>\n<p>Faculty of Mechanical Engineering, University of Southern Denmark</p>\n<ul>\n<li>Performing a team project to optimise a wind turbine airfoil</li>\n<li>Data analysing of wind tunnel and water channel PIV results</li>\n<li>Visiting the LM Wind Power Test and Validation Centre</li>\n</ul>\n<h4 id=\"pre-university-qualification-total-score-of-ncee-gaokao-619750\">Pre-university Qualification: Total Score of NCEE (<a href=\"https://en.wikipedia.org/wiki/Gaokao\">GaoKao</a>): 619/750</h4>\n<h2 id=\"academic-projects\">Academic Projects</h2>\n<h4 id=\"bifurcation-and-oscillation-effects-of-gyrotactic-swimming-microorganism-suspension-in-vertical-pipe\">Bifurcation and Oscillation Effects of Gyrotactic Swimming Microorganism Suspension in Vertical Pipe</h4>\n<div style=\"margin-bottom:-2%;; text-align: right\">\n05/2020-10/2020\n</div>\n<p>Imperial College London MSc Individual Project</p>\n<p>Director: <a href=\"https://www.imperial.ac.uk/people/y.hwang\">Dr. Yongyun Hwang</a></p>\n<ul>\n<li>Learning concepts of bioreactors and behaviours of micro-algae</li>\n<li>Developing numerical solvers for microorganism suspension</li>\n<li>Exploring and analysing bifurcations and instabilities under different flow conditions</li>\n</ul>\n<h4 id=\"flow-field-analysis-based-on-rans-solver-and-biglobal-stability-theory\">Flow Field Analysis Based on RANS Solver and BiGlobal Stability Theory</h4>\n<div style=\"margin-bottom:-2%; text-align: right\">\n02/2019-06/2019\n</div>\n<p>Undergraduate Graduation Project &amp; <a href=\"https://erasmus-plus.ec.europa.eu/\">Erasmus+ Scholarship Programme</a></p>\n<p>Director: <a href=\"http://www.upm.es/observatorio/vi/index.jsp?pageac=investigador.jsp&amp;idInvestigador=5214\">Professor Eusebio Valero Sanchez</a> &amp; <a href=\"https://teacher.nwpu.edu.cn/yaguo\">Associate Professor Yaguo Lyu</a></p>\n<ul>\n<li>Handling of the necessary tool, DLR TAU-Code</li>\n<li>Performing simulations of non-stationary problems</li>\n<li>Analysing the stability of the flow fields by POD and DMD</li>\n</ul>\n<h4 id=\"design-research-on-bionic-anti-drag-propeller\">Design Research on Bionic Anti-drag Propeller</h4>\n<div style=\"margin-bottom:-2%; text-align: right\">\n04/2017-04/2018\n</div>\n<p><a href=\"https://www.pilcchina.org/?locale=en\">China college students Internet+ Innovation and Entrepreneurship Competition</a></p>\n<p>Director: <a href=\"https://teacher.nwpu.edu.cn/wangyg.html\">Professor Wang yangang</a></p>\n<ul>\n<li>Proposing and design a novel drone propeller with serrated leading edge as project manager</li>\n<li>Carrying out 3D modelling, CFD simulations and data analysis</li>\n</ul>\n<h4 id=\"starting-test-of-pulse-jet-engine\">Starting Test of Pulse Jet Engine</h4>\n<div style=\"margin-bottom:-2%; text-align: right; font-size:15px; font-size:15px\">\n07/2017-08/2017\n</div>\n<p>Scientific Research Practice Programme</p>\n<p>Director: <a href=\"https://teacher.nwpu.edu.cn/m/en/2010010152.html\">Professer Yan Hong</a></p>\n<ul>\n<li>Setting up the experiment platform;</li>\n<li>Measuring the thrust and pressure pulse frequency of a valveless pulse engine.</li>\n</ul>\n<h2 id=\"professional-skills\">Professional Skills</h2>\n<p>I.T. SKILLS: Python, C++</p>\n<p>Related software: OpenFOAM, CATIA</p>\n","site":{"data":{}},"wordcount":2392,"excerpt":"","more":"<h2 id=\"work-experience\">Work Experience</h2>\n<h4 id=\"automotive-cfd-engineer\">Automotive CFD Engineer</h4>\n<div style=\"margin-top:-3%; text-align: right\">\n04/2021- present\n</div>\n<p>Pre R&amp;D, <a href=\"https://volkswagengroupchina.com.cn/en/partner/saicvolkswagen\">Shanghai Volkswagen Automotive Co., Ltd</a>.</p>\n<ul>\n<li>OpenFOAM developing on automotive aerodynamic</li>\n<li>Intelligent aided fluid dynamic</li>\n</ul>\n<h2 id=\"education-background\">Education Background</h2>\n<h4 id=\"msc-advanced-computational-methods-for-aeronautics-flow-management-and-fluid-structure-interaction\">MSc: <a href=\"https://www.imperial.ac.uk/study/pg/aeronautics/computational-methods/\">Advanced Computational Methods for Aeronautics, Flow Management and Fluid Structure Interaction</a></h4>\n<div style=\"margin-bottom:-2%; text-align: right\">\n09/2019-11/2020\n</div>\n<p>Department of Aeronautics, Imperial college London</p>\n<ul>\n<li>Grade: 74.3/100 (Merit)</li>\n<li>Modules include: Computational fluid dynamics, High-Performance Computing, Aeroservoelasticity, introduce to flow control, Hydrodynamic Stability, Separated Flows and Fluid Structure Interaction, etc.</li>\n</ul>\n<h4 id=\"beng-flight-vehicle-propulsion-engineering\">BEng: <a href=\"https://en.nwpu.edu.cn/index.htm\">Flight Vehicle Propulsion Engineering</a></h4>\n<div style=\"margin-bottom:-2%; text-align: right\">\n09/2015-07/2019\n</div>\n<p>School of Power and Energy, Northwestern Polytechnical University</p>\n<ul>\n<li>Grade: 86.5/100</li>\n<li>Modules include: Fundamentals of Gas Dynamics, Fluid Mechanics, Heat Transfer, Mechanical theory, Turbomachinery etc.</li>\n<li>Exchange student in senior year at Polytechnic University of Madrid</li>\n</ul>\n<h4 id=\"summer-school-experimental-fluid-mechanics\">Summer school: <a href=\"https://odin.sdu.dk/sitecore/index.php?a=fagbesk&amp;id=79256&amp;lang=en\">Experimental Fluid Mechanics</a></h4>\n<div style=\"margin-bottom:-2%;; text-align: right\">\n8/2018\n</div>\n<p>Faculty of Mechanical Engineering, University of Southern Denmark</p>\n<ul>\n<li>Performing a team project to optimise a wind turbine airfoil</li>\n<li>Data analysing of wind tunnel and water channel PIV results</li>\n<li>Visiting the LM Wind Power Test and Validation Centre</li>\n</ul>\n<h4 id=\"pre-university-qualification-total-score-of-ncee-gaokao-619750\">Pre-university Qualification: Total Score of NCEE (<a href=\"https://en.wikipedia.org/wiki/Gaokao\">GaoKao</a>): 619/750</h4>\n<h2 id=\"academic-projects\">Academic Projects</h2>\n<h4 id=\"bifurcation-and-oscillation-effects-of-gyrotactic-swimming-microorganism-suspension-in-vertical-pipe\">Bifurcation and Oscillation Effects of Gyrotactic Swimming Microorganism Suspension in Vertical Pipe</h4>\n<div style=\"margin-bottom:-2%;; text-align: right\">\n05/2020-10/2020\n</div>\n<p>Imperial College London MSc Individual Project</p>\n<p>Director: <a href=\"https://www.imperial.ac.uk/people/y.hwang\">Dr. Yongyun Hwang</a></p>\n<ul>\n<li>Learning concepts of bioreactors and behaviours of micro-algae</li>\n<li>Developing numerical solvers for microorganism suspension</li>\n<li>Exploring and analysing bifurcations and instabilities under different flow conditions</li>\n</ul>\n<h4 id=\"flow-field-analysis-based-on-rans-solver-and-biglobal-stability-theory\">Flow Field Analysis Based on RANS Solver and BiGlobal Stability Theory</h4>\n<div style=\"margin-bottom:-2%; text-align: right\">\n02/2019-06/2019\n</div>\n<p>Undergraduate Graduation Project &amp; <a href=\"https://erasmus-plus.ec.europa.eu/\">Erasmus+ Scholarship Programme</a></p>\n<p>Director: <a href=\"http://www.upm.es/observatorio/vi/index.jsp?pageac=investigador.jsp&amp;idInvestigador=5214\">Professor Eusebio Valero Sanchez</a> &amp; <a href=\"https://teacher.nwpu.edu.cn/yaguo\">Associate Professor Yaguo Lyu</a></p>\n<ul>\n<li>Handling of the necessary tool, DLR TAU-Code</li>\n<li>Performing simulations of non-stationary problems</li>\n<li>Analysing the stability of the flow fields by POD and DMD</li>\n</ul>\n<h4 id=\"design-research-on-bionic-anti-drag-propeller\">Design Research on Bionic Anti-drag Propeller</h4>\n<div style=\"margin-bottom:-2%; text-align: right\">\n04/2017-04/2018\n</div>\n<p><a href=\"https://www.pilcchina.org/?locale=en\">China college students Internet+ Innovation and Entrepreneurship Competition</a></p>\n<p>Director: <a href=\"https://teacher.nwpu.edu.cn/wangyg.html\">Professor Wang yangang</a></p>\n<ul>\n<li>Proposing and design a novel drone propeller with serrated leading edge as project manager</li>\n<li>Carrying out 3D modelling, CFD simulations and data analysis</li>\n</ul>\n<h4 id=\"starting-test-of-pulse-jet-engine\">Starting Test of Pulse Jet Engine</h4>\n<div style=\"margin-bottom:-2%; text-align: right; font-size:15px; font-size:15px\">\n07/2017-08/2017\n</div>\n<p>Scientific Research Practice Programme</p>\n<p>Director: <a href=\"https://teacher.nwpu.edu.cn/m/en/2010010152.html\">Professer Yan Hong</a></p>\n<ul>\n<li>Setting up the experiment platform;</li>\n<li>Measuring the thrust and pressure pulse frequency of a valveless pulse engine.</li>\n</ul>\n<h2 id=\"professional-skills\">Professional Skills</h2>\n<p>I.T. SKILLS: Python, C++</p>\n<p>Related software: OpenFOAM, CATIA</p>\n"}],"Post":[{"title":"Compile OpenFOAM from source on M1 Mac","author":"Ryan LI","toc":true,"declare":true,"index_img":"/index/OpenFOAM.png","date":"2022-06-09T09:11:13.000Z","_content":"\n{% note primary %}\n\nI just spent 3 hours building **ESI OpenFOAM-v2112** from source code **locally**(no need docker) on my m1 MacBook air. This blog is to record the process.\n\n{% endnote %}\n\n<!-- more -->\n\nAlthough here is a very convenient already-built source for mac: [gerlero](https://github.com/gerlero)/**[openfoam2112-app](https://github.com/gerlero/openfoam2112-app)**. I still chose to build it from the source on my own mac. \n\n{% note secondary %}\n\nHelpful resources:\n\n- [OpenFOAM v2112 source code](https://dl.openfoam.com/source/v2112/OpenFOAM-v2112.tgz)\n\n- [BrushXue](https://github.com/BrushXue)/**[OpenFOAM-AppleM1](https://github.com/BrushXue/OpenFOAM-AppleM1)**\n\n- [OpenFOAM installation on Mac.pdf](https://www.researchgate.net/publication/357395955_OpenFOAM_installation_on_Mac)\n\n- [OpenFOAM wiki](https://develop.openfoam.com/Development/openfoam/-/wikis/building#darwin-mac-os)\n\n- [OpenFOAM doc](https://develop.openfoam.com/Development/openfoam/-/blob/master/doc/Build.md)\n\n{% endnote %}\n\n### Preliminaries\n\n[Command line tools:](https://mac.install.guide/commandlinetools/4.html)\n\n```shell\nxcode-select --install\n```\n\n[Homebrew](https://brew.sh/):\n\n```shell\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n```\n\n### Procedures\n\n1. Create a case-sensitive volume on mac. OpenFOAM requires a case-sensitive volume to build and run, yet mac does not support it by default. \n\n   Open `disk utility.app` and follow these settings:\n\n   <img src=\"Case sensitive volume step one.png\" style=\"zoom:50%;\" />\n\n   <img src=\"Case sensitive volume step two.png\" style=\"zoom:50%;\" />\n\n   <img src=\"Case sensitive volume step three.png\"  style=\"zoom:50%;\" />\n\n   <img src=\"Case sensitive volume finish.png\"  style=\"zoom:50%;\" />\n\n2. Go to `/Volumes/OpenFOAMs/`, download and extract the [source code](https://dl.openfoam.com/source/v2112/OpenFOAM-v2112.tgz) and the [patches for mac](https://github.com/BrushXue/OpenFOAM-AppleM1) (thanks to [BrushXue](https://github.com/BrushXue)) to the same directory. \n\n3. Install dependencies with homebrew:\n\n   ```shell\n   brew install cmake open-mpi libomp adios2 boost fftw kahip metis \n   ```\n\n4. Install modifiled `scotch` and `CGAL@4` (Thanks to [gerlero](https://github.com/gerlero) for creating this [tap](https://github.com/gerlero/homebrew-openfoam/tree/main/Formula))\n\n   ```shell\n   brew tap gerlero/openfoam\n   brew install scotch-no-pthread cgal@4\n   ```\n   \n\n5. And you probably need to add the following:\n\n   ```shell\n   export CPATH=/opt/homebrew/include\n   export LIBRARY_PATH=/opt/homebrew/lib\n   ```\n\n6. Source OpenFOAM's environment bashrc:\n\n   ```shell\n   source etc/bashrc  \n   ```\n\n7. Check the system and build (about 1 hour on MacBook Air)\n\n   ```shell\n   foamSystemCheck\n   ./Allwmake -j -s -l\n   ```\n\n8. Install `paraview` from Homebrew\n\n   ```shell\n   brew install --cask paraview\n   ```\n\n9. Add alias to `$home/.zshrc`\n\n   ``` shell\n   alias of=\"source /Volumes/OpenFOAMs/OpenFOAM-v2112/etc/bashrc\"\n   ```\n\n   \n\n","source":"_posts/Build-OpenFOAM-from-source-on-M1-Mac.md","raw":"---\ntitle: Compile OpenFOAM from source on M1 Mac\nauthor: Ryan LI\ntoc: true\ndeclare: true\nindex_img: /index/OpenFOAM.png\ntags:\n  - OpenFOAM\n  - mac\ndate: 2022-06-09 17:11:13\n---\n\n{% note primary %}\n\nI just spent 3 hours building **ESI OpenFOAM-v2112** from source code **locally**(no need docker) on my m1 MacBook air. This blog is to record the process.\n\n{% endnote %}\n\n<!-- more -->\n\nAlthough here is a very convenient already-built source for mac: [gerlero](https://github.com/gerlero)/**[openfoam2112-app](https://github.com/gerlero/openfoam2112-app)**. I still chose to build it from the source on my own mac. \n\n{% note secondary %}\n\nHelpful resources:\n\n- [OpenFOAM v2112 source code](https://dl.openfoam.com/source/v2112/OpenFOAM-v2112.tgz)\n\n- [BrushXue](https://github.com/BrushXue)/**[OpenFOAM-AppleM1](https://github.com/BrushXue/OpenFOAM-AppleM1)**\n\n- [OpenFOAM installation on Mac.pdf](https://www.researchgate.net/publication/357395955_OpenFOAM_installation_on_Mac)\n\n- [OpenFOAM wiki](https://develop.openfoam.com/Development/openfoam/-/wikis/building#darwin-mac-os)\n\n- [OpenFOAM doc](https://develop.openfoam.com/Development/openfoam/-/blob/master/doc/Build.md)\n\n{% endnote %}\n\n### Preliminaries\n\n[Command line tools:](https://mac.install.guide/commandlinetools/4.html)\n\n```shell\nxcode-select --install\n```\n\n[Homebrew](https://brew.sh/):\n\n```shell\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n```\n\n### Procedures\n\n1. Create a case-sensitive volume on mac. OpenFOAM requires a case-sensitive volume to build and run, yet mac does not support it by default. \n\n   Open `disk utility.app` and follow these settings:\n\n   <img src=\"Case sensitive volume step one.png\" style=\"zoom:50%;\" />\n\n   <img src=\"Case sensitive volume step two.png\" style=\"zoom:50%;\" />\n\n   <img src=\"Case sensitive volume step three.png\"  style=\"zoom:50%;\" />\n\n   <img src=\"Case sensitive volume finish.png\"  style=\"zoom:50%;\" />\n\n2. Go to `/Volumes/OpenFOAMs/`, download and extract the [source code](https://dl.openfoam.com/source/v2112/OpenFOAM-v2112.tgz) and the [patches for mac](https://github.com/BrushXue/OpenFOAM-AppleM1) (thanks to [BrushXue](https://github.com/BrushXue)) to the same directory. \n\n3. Install dependencies with homebrew:\n\n   ```shell\n   brew install cmake open-mpi libomp adios2 boost fftw kahip metis \n   ```\n\n4. Install modifiled `scotch` and `CGAL@4` (Thanks to [gerlero](https://github.com/gerlero) for creating this [tap](https://github.com/gerlero/homebrew-openfoam/tree/main/Formula))\n\n   ```shell\n   brew tap gerlero/openfoam\n   brew install scotch-no-pthread cgal@4\n   ```\n   \n\n5. And you probably need to add the following:\n\n   ```shell\n   export CPATH=/opt/homebrew/include\n   export LIBRARY_PATH=/opt/homebrew/lib\n   ```\n\n6. Source OpenFOAM's environment bashrc:\n\n   ```shell\n   source etc/bashrc  \n   ```\n\n7. Check the system and build (about 1 hour on MacBook Air)\n\n   ```shell\n   foamSystemCheck\n   ./Allwmake -j -s -l\n   ```\n\n8. Install `paraview` from Homebrew\n\n   ```shell\n   brew install --cask paraview\n   ```\n\n9. Add alias to `$home/.zshrc`\n\n   ``` shell\n   alias of=\"source /Volumes/OpenFOAMs/OpenFOAM-v2112/etc/bashrc\"\n   ```\n\n   \n\n","slug":"Build-OpenFOAM-from-source-on-M1-Mac","published":1,"updated":"2022-06-09T10:20:51.879Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz1v0001l8yb28rdcy4x","content":"<div class=\"note note-primary\">\n            <p>I just spent 3 hours building <strong>ESI OpenFOAM-v2112</strong> from source code <strong>locally</strong>(no need docker) on my m1 MacBook air. This blog is to record the process.</p>\n          </div>\n<span id=\"more\"></span>\n<p>Although here is a very convenient already-built source for mac: <a href=\"https://github.com/gerlero\">gerlero</a>/<strong><a href=\"https://github.com/gerlero/openfoam2112-app\">openfoam2112-app</a></strong>. I still chose to build it from the source on my own mac.</p>\n<div class=\"note note-secondary\">\n            <p>Helpful resources:</p><ul><li><p><a href=\"https://dl.openfoam.com/source/v2112/OpenFOAM-v2112.tgz\">OpenFOAM v2112 source code</a></p></li><li><p><a href=\"https://github.com/BrushXue\">BrushXue</a>/<strong><a href=\"https://github.com/BrushXue/OpenFOAM-AppleM1\">OpenFOAM-AppleM1</a></strong></p></li><li><p><a href=\"https://www.researchgate.net/publication/357395955_OpenFOAM_installation_on_Mac\">OpenFOAM installation on Mac.pdf</a></p></li><li><p><a href=\"https://develop.openfoam.com/Development/openfoam/-/wikis/building#darwin-mac-os\">OpenFOAM wiki</a></p></li><li><p><a href=\"https://develop.openfoam.com/Development/openfoam/-/blob/master/doc/Build.md\">OpenFOAM doc</a></p></li></ul>\n          </div>\n<h3 id=\"preliminaries\">Preliminaries</h3>\n<p><a href=\"https://mac.install.guide/commandlinetools/4.html\">Command line tools:</a></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">xcode-select --install</code></pre></div>\n<p><a href=\"https://brew.sh/\">Homebrew</a>:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;</code></pre></div>\n<h3 id=\"procedures\">Procedures</h3>\n<ol type=\"1\">\n<li><p>Create a case-sensitive volume on mac. OpenFOAM requires a case-sensitive volume to build and run, yet mac does not support it by default.</p>\n<p>Open <code>disk utility.app</code> and follow these settings:</p>\n<p><img src=\"Case sensitive volume step one.png\" srcset=\"/img/loading.gif\" lazyload style=\"zoom:50%;\" /></p>\n<p><img src=\"Case sensitive volume step two.png\" srcset=\"/img/loading.gif\" lazyload style=\"zoom:50%;\" /></p>\n<p><img src=\"Case sensitive volume step three.png\" srcset=\"/img/loading.gif\" lazyload  style=\"zoom:50%;\" /></p>\n<p><img src=\"Case sensitive volume finish.png\" srcset=\"/img/loading.gif\" lazyload  style=\"zoom:50%;\" /></p></li>\n<li><p>Go to <code>/Volumes/OpenFOAMs/</code>, download and extract the <a href=\"https://dl.openfoam.com/source/v2112/OpenFOAM-v2112.tgz\">source code</a> and the <a href=\"https://github.com/BrushXue/OpenFOAM-AppleM1\">patches for mac</a> (thanks to <a href=\"https://github.com/BrushXue\">BrushXue</a>) to the same directory.</p></li>\n<li><p>Install dependencies with homebrew:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">brew install cmake open-mpi libomp adios2 boost fftw kahip metis</code></pre></div></li>\n<li><p>Install modifiled <code>scotch</code> and <code>CGAL@4</code> (Thanks to <a href=\"https://github.com/gerlero\">gerlero</a> for creating this <a href=\"https://github.com/gerlero/homebrew-openfoam/tree/main/Formula\">tap</a>)</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">brew tap gerlero/openfoam\nbrew install scotch-no-pthread cgal@4</code></pre></div></li>\n<li><p>And you probably need to add the following:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">export CPATH=/opt/homebrew/include\nexport LIBRARY_PATH=/opt/homebrew/lib</code></pre></div></li>\n<li><p>Source OpenFOAM's environment bashrc:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">source etc/bashrc</code></pre></div></li>\n<li><p>Check the system and build (about 1 hour on MacBook Air)</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">foamSystemCheck\n./Allwmake -j -s -l</code></pre></div></li>\n<li><p>Install <code>paraview</code> from Homebrew</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">brew install --cask paraview</code></pre></div></li>\n<li><p>Add alias to <code>$home/.zshrc</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">alias of=&quot;source /Volumes/OpenFOAMs/OpenFOAM-v2112/etc/bashrc&quot;</code></pre></div></li>\n</ol>\n","site":{"data":{}},"wordcount":1389,"excerpt":"<div class=\"note note-primary\">\n            <p>I just spent 3 hours building <strong>ESI OpenFOAM-v2112</strong> from source code <strong>locally</strong>(no need docker) on my m1 MacBook air. This blog is to record the process.</p>\n          </div>","more":"<p>Although here is a very convenient already-built source for mac: <a href=\"https://github.com/gerlero\">gerlero</a>/<strong><a href=\"https://github.com/gerlero/openfoam2112-app\">openfoam2112-app</a></strong>. I still chose to build it from the source on my own mac.</p>\n<div class=\"note note-secondary\">\n            <p>Helpful resources:</p><ul><li><p><a href=\"https://dl.openfoam.com/source/v2112/OpenFOAM-v2112.tgz\">OpenFOAM v2112 source code</a></p></li><li><p><a href=\"https://github.com/BrushXue\">BrushXue</a>/<strong><a href=\"https://github.com/BrushXue/OpenFOAM-AppleM1\">OpenFOAM-AppleM1</a></strong></p></li><li><p><a href=\"https://www.researchgate.net/publication/357395955_OpenFOAM_installation_on_Mac\">OpenFOAM installation on Mac.pdf</a></p></li><li><p><a href=\"https://develop.openfoam.com/Development/openfoam/-/wikis/building#darwin-mac-os\">OpenFOAM wiki</a></p></li><li><p><a href=\"https://develop.openfoam.com/Development/openfoam/-/blob/master/doc/Build.md\">OpenFOAM doc</a></p></li></ul>\n          </div>\n<h3 id=\"preliminaries\">Preliminaries</h3>\n<p><a href=\"https://mac.install.guide/commandlinetools/4.html\">Command line tools:</a></p>\n<pre><code class=\"hljs shell\">xcode-select --install</code></pre>\n<p><a href=\"https://brew.sh/\">Homebrew</a>:</p>\n<pre><code class=\"hljs shell\">/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;</code></pre>\n<h3 id=\"procedures\">Procedures</h3>\n<ol type=\"1\">\n<li><p>Create a case-sensitive volume on mac. OpenFOAM requires a case-sensitive volume to build and run, yet mac does not support it by default.</p>\n<p>Open <code>disk utility.app</code> and follow these settings:</p>\n<p><img src=\"Case sensitive volume step one.png\" style=\"zoom:50%;\" /></p>\n<p><img src=\"Case sensitive volume step two.png\" style=\"zoom:50%;\" /></p>\n<p><img src=\"Case sensitive volume step three.png\"  style=\"zoom:50%;\" /></p>\n<p><img src=\"Case sensitive volume finish.png\"  style=\"zoom:50%;\" /></p></li>\n<li><p>Go to <code>/Volumes/OpenFOAMs/</code>, download and extract the <a href=\"https://dl.openfoam.com/source/v2112/OpenFOAM-v2112.tgz\">source code</a> and the <a href=\"https://github.com/BrushXue/OpenFOAM-AppleM1\">patches for mac</a> (thanks to <a href=\"https://github.com/BrushXue\">BrushXue</a>) to the same directory.</p></li>\n<li><p>Install dependencies with homebrew:</p>\n<pre><code class=\"hljs shell\">brew install cmake open-mpi libomp adios2 boost fftw kahip metis</code></pre></li>\n<li><p>Install modifiled <code>scotch</code> and <code>CGAL@4</code> (Thanks to <a href=\"https://github.com/gerlero\">gerlero</a> for creating this <a href=\"https://github.com/gerlero/homebrew-openfoam/tree/main/Formula\">tap</a>)</p>\n<pre><code class=\"hljs shell\">brew tap gerlero/openfoam\nbrew install scotch-no-pthread cgal@4</code></pre></li>\n<li><p>And you probably need to add the following:</p>\n<pre><code class=\"hljs shell\">export CPATH=/opt/homebrew/include\nexport LIBRARY_PATH=/opt/homebrew/lib</code></pre></li>\n<li><p>Source OpenFOAM's environment bashrc:</p>\n<pre><code class=\"hljs shell\">source etc/bashrc</code></pre></li>\n<li><p>Check the system and build (about 1 hour on MacBook Air)</p>\n<pre><code class=\"hljs shell\">foamSystemCheck\n./Allwmake -j -s -l</code></pre></li>\n<li><p>Install <code>paraview</code> from Homebrew</p>\n<pre><code class=\"hljs shell\">brew install --cask paraview</code></pre></li>\n<li><p>Add alias to <code>$home/.zshrc</code></p>\n<pre><code class=\"hljs shell\">alias of=&quot;source /Volumes/OpenFOAMs/OpenFOAM-v2112/etc/bashrc&quot;</code></pre></li>\n</ol>"},{"title":"Derivation of Differential Fluid Equations","author":"Ryan LI","toc":true,"declare":true,"index_img":"/index/deriving_NS_again.png","date":"2022-05-14T08:54:02.000Z","_content":"\n{% note primary %}\n\nFeeling unsafe when deploying CFD algorithms, the best way to alleviate the anxiety is to derive the fundamentals again.\n\n{% endnote%}\n\n<!-- more -->\n\n## 1 Acceleration and Mass Conservation\n\n### 1.1 Acceleration field of a fluid\n\n#### 1.1.1 Material / substantial / convective derivatives\n\n<img src=\"Material derivatives.png\" alt=\"Material derivatives\" style=\"zoom:50%;\" />\n\nGiven a spatial-temporal property $f(x,y,z,t)$ of a fluid particle in the Eulerian coordinate. After an infinitesimal period, the change in $f$ , is therefore:\n$$\n\\begin{aligned}\n\\Delta f = f(x+\\Delta x,y+\\delta x,z+\\delta z,t+\\Delta t)- f(x,y,z,t) \n\\end{aligned}\n$$\nset the position and time change tend to 0, \n$$\n\\Delta f = \\frac{\\partial f}{\\partial x}\\Delta x+\\frac{\\partial f}{\\partial y}\\Delta y+\\frac{\\partial f}{\\partial z}\\Delta z+\\frac{\\partial f}{\\partial t}\\Delta t\n$$\nconsidering:\n$$\n\\Delta x = u \\Delta t, \\Delta y = v \\Delta t, \\Delta z = w \\Delta t\n$$\nthen \n$$\n\\frac{\\Delta f }{\\Delta t}=\\frac{\\partial f}{\\partial t} + \\frac{\\partial f}{\\partial x}u+\\frac{\\partial f}{\\partial y}v+\\frac{\\partial f}{\\partial z}w\n$$\nIn the limit as $\\Delta t \\rightarrow 0$, \n$$\n\\frac{D f }{D t}=\\frac{\\partial f}{\\partial t} + \\frac{\\partial f}{\\partial x}u+\\frac{\\partial f}{\\partial y}v+\\frac{\\partial f}{\\partial z}w\n$$\nor in a vector form:\n$$\n\\color{purple}\n\\frac{D f }{D t}=\\frac{\\partial f}{\\partial t} + \\mathbf{V} \\cdot \\boldsymbol{\\nabla} f\n$$\nIn the scalar case $\\boldsymbol{\\nabla} f$ is simply the gradient of a scalar, while in the vector case,  $\\boldsymbol{\\nabla} \\mathbf{f}$ is the covariant derivative of the vector.\n\n{% note info %}\n\nLike the Reynolds Transport Theorem in the integral part, the material derivative connects the Lagrangian and Eulerian frame of references.\n\n{% endnote %}\n\n#### 1.1.2 Material derivative of velocity\n\nSet $f$ as $\\mathbf{V}$ and the fluid acceleration as $\\mathbf{a}$, substitute to the formula above:\n$$\n\\mathbf{a} = \\frac{D \\mathbf{V} }{D t}=\\underbrace{\\frac{\\partial \\mathbf{V}}{\\partial t}}_{\\text {local}} + \\underbrace{\\mathbf{V} \\cdot \\boldsymbol{\\nabla} \\mathbf{V}}_{\\text {convective}}\n$$\nwhere $\\frac{\\partial \\mathbf{V}}{\\partial t}$  is called **local acceleration** while $(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}$ is the **convective acceleration**.\n\n{% note info %}\n\nIt is also written as $\\mathbf{a} = \\frac{D \\mathbf{V} }{D t}=\\frac{\\partial \\mathbf{V}}{\\partial t} + (\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}$, but it's equivalent. \n\n{% endnote %}\n\n### 1.2 Differential equation of mass conservation\n\nTake an infinitesimally small cubic control volume as below.\n\n<img src=\"Differential mass conservation.png\" alt=\"Differential mass conservation\" style=\"zoom:50%;\" />\n\nWith the integral form with one-dimensional assumption: \n$$\n\\int_{C V} \\frac{\\partial \\rho}{\\partial t} d \\mathcal{V}+\\sum_{i}\\left(\\rho_{i} A_{i} V_{i}\\right)_{o u t}-\\sum_{i}\\left(\\rho_{i} A_{i} V_{i}\\right)_{i n}=0\n$$\n\n1. Density can be considered uniform in the CV,\n   $$\n   \\int_{C V} \\frac{\\partial \\rho}{\\partial t} d \\mathcal{V} = \\frac{\\partial \\rho}{\\partial t} dxdydz\n   $$\n\n2. Inlet mass flow in 3 directions\n   $$\n   \\dot{m}_{x} = \\rho udydz, \\dot{m}_{y} = \\rho vdxdz, \\dot{m}_{z} = \\rho udxdy\n   $$\n   \n3. Outlet mass flow in x direction particular\n   $$\n   \\dot{m}_{x+dx} = \\left(\\rho u+\\frac{\\partial \\rho u}{\\partial x }dx\\right)dydz\n   $$\n\n4. Substitute all in the continuous function\n   $$\n   \\frac{\\partial \\rho}{\\partial t} dxdydz +\\frac{\\partial \\rho u}{\\partial x}dxdydz +\\frac{\\partial \\rho v}{\\partial y}dxdydz +\\frac{\\partial \\rho w}{\\partial z}dxdydz  = 0\n   $$\n   simplify:\n   $$\n   \\frac{\\partial \\rho}{\\partial t}  +\\frac{\\partial \\rho u}{\\partial x} +\\frac{\\partial \\rho v}{\\partial y} +\\frac{\\partial \\rho w}{\\partial z}  = 0\n   $$\n   or in the vector form:\n   $$\n   \\color{purple}\n   \\frac{\\partial \\rho}{\\partial t}+\\boldsymbol{\\nabla} \\cdot(\\rho\\mathbf{V})=0\n   $$\n    {% note info %}\n\n   The only requirements of this equation are the density $\\rho$ and velocity $\\mathbf{V}$ are continuous in time and space. As a result, this equation is always called the *equation of continuity*.\n\n   {% endnote %}\n\n#### 1.2.1 Simplifications\n\n- steady flow: $\\partial/\\partial t = 0$, \n  $$\n  \\boldsymbol{\\nabla} \\cdot(\\rho\\mathbf{V})=0\n  $$\n\n- Incompressible flow: $\\rho = Const$ spacial and temporal:\n\n$$\n\\boldsymbol{\\nabla} \\cdot\\mathbf{V}=0\n$$\n\n{% note info %}\n\nIt makes the equation linear and much more tractable to solving analytically.\n\n{% endnote %}\n\n### 1.3 Cylindrical coordinates\n\n<img src=\"Polar coordinate.png\" alt=\"Polar coordinate\" style=\"zoom:50%;\" />\n\n#### 1.3.1 Transformation of coordinates\n\nFrom cartesian to cylindrical:\n$$\nr=\\sqrt{x^{2}+y^{2}} \\quad \\theta=\\tan ^{-1} \\frac{y}{x} \\quad z=z\n$$\n\nFrom cylindrical to cartesian:\n$$\nx=r \\cos \\theta \\quad y=r \\sin \\theta \\quad z=z\n$$\n\n#### 1.3.2 Differential operators\n\nTwo differential operators in polar coordinate:\n$$\n\\begin{aligned}\n\\boldsymbol{\\nabla} f &=\\frac{\\partial f}{\\partial r} \\hat{\\boldsymbol{r}}+\\frac{1}{r} \\frac{\\partial f}{\\partial \\theta} \\hat{\\boldsymbol{\\theta}}+\\frac{\\partial f}{\\partial z} \\hat{\\boldsymbol{z}}\\\\\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} &=\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r V_{r}\\right)+\\frac{1}{r} \\frac{\\partial}{\\partial \\theta}\\left(V_{\\theta}\\right)+\\frac{\\partial}{\\partial z}\\left(V_{z}\\right)\n\\end{aligned}\n$$\n\n#### 6.3.3 Continuous function in cylindrical coordinates\n\nIt is easy to substitute the equation of divergence into the continuous function,\n$$\n\\frac{\\partial \\rho}{\\partial t}+\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\rho V_{r}\\right)+\\frac{1}{r} \\frac{\\partial}{\\partial \\theta}\\left(\\rho V_{\\theta}\\right)+\\frac{\\partial}{\\partial z}\\left(\\rho V_{z}\\right)=0\n$$\n\n## 2 Linear Momentum and Energy\n\n### 2.1 Conservation laws from differential Reynolds transport theorem\n\nRecall RTT on a fixed control volume $\\Omega$:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(B_{s}\\right)=\\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}+\\int_{\\partial \\Omega} \\beta \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n$$\nwhere \n$$\n\\beta=\\frac{\\partial B}{\\partial m} \\quad \\Rightarrow \\quad B=\\int_{\\bar{\\Omega}} \\beta \\rho d \\mathcal{V}\n$$\n$\\bar{\\Omega}$ denotes the control volume in a Lagrangian frame of reference (close system), while $\\Omega$ denotes the control volume in an Eulerian frame of reference (open system).\n\n{% note info %}\n\nOpen system: matter and energy goes in and out\n\nClose system: energy goes in and out while matter cannot\n\nIsolated system: matter and energy cannot go in and out\n\n{% endnote %}\n\nIn the Lagrangian frame of reference,\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d} t}(B)=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{\\bar{\\Omega}} \\beta \\rho d \\mathcal{V}\\right)\\underbrace{=}_{Leibniz's Rule}\\int_{\\bar{\\Omega}} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}=\\int_{\\bar{\\Omega}} s d \\mathcal{V}\n$$\n{% note info %}\n\nLeibniz's rule: the derivative moves into the integral symbol: \n$$\n\\frac{d}{d x}\\left(\\int_{a}^{b} f(x, t) d t\\right)=\\int_{a}^{b} \\frac{\\partial}{\\partial x} f(x, t) d t\n$$\n{% endnote %}\n\nWhere $s$ denotes the \"rate of change of $B$ per unit volume\"\n\nThen the RTT is instead:\n$$\n\\int_{\\bar{\\Omega}} s d \\mathcal{V} = \\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}+\\int_{\\partial \\Omega} \\beta \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n$$\nUse divergence theorem, drop the bar notation with $\\Delta t \\rightarrow 0$, and arrive a differential form:\n$$\n\\begin{array}{r}\n\\int_{\\Omega} s d \\mathcal{V}=\\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}+\\int_{\\Omega} \\boldsymbol{\\nabla}  \\cdot(\\beta \\rho \\mathbf{V}) d \\mathcal{V} \\\\\n\\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\beta \\rho \\mathbf{V})-s d \\mathcal{V}=0 \\\\\n\\Leftrightarrow \\color{purple}{\\frac{\\partial(\\beta \\rho)}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\beta \\rho \\mathbf{V})-s=0}\n\\end{array}\n$$\n{% note info %}\n\nDivergence theorem: \n$$\n\\int_{S} \\boldsymbol{\\nabla}  \\cdot \\mathbf{F} d A=\\int_{\\partial S} \\mathbf{F} \\cdot \\hat{\\mathbf{n}} d s\n$$\n{% endnote %}\n\n#### 2.1.1 Continuity equation for mass\n\nSubstitute $\\beta = 1$ and $s=0$ (mass created = 0) into the differential RTT:\n$$\n\\frac{\\partial(\\rho)}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V})=0\n$$\nand for incompressible flow:\n$$\n\\boldsymbol{\\nabla}  \\cdot \\mathbf{V}=0\n$$\n\n#### 2.1.2 Continuity equation for linear momentum\n\nSubstitute $\\beta =\\mathbf{V}$ into the differential RTT:\n$$\n\\frac{\\partial(\\rho \\mathbf{V})}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V}\\otimes \\mathbf{V}) -\\mathbf{s} =0\n$$\n $\\mathbf{s}$ denotes the force per unit volume, and $\\otimes $ denotes the outer product.\n\n{% note info %}\n\nOuter product or dyadic product follows:\n$$\n\\left[\\begin{array}{c}\nu_{1} \\\\\nu_{2} \\\\\n\\vdots \\\\\nu_{m}\n\\end{array}\\right]\n \\otimes \n\\left[\\begin{array}{c}\nv_{1} \\\\\nv_{2} \\\\\n\\vdots \\\\\nv_{n}\n\\end{array}\\right]=\n\\left[\\begin{array}{cccc}\nu_{1} v_{1} & u_{1} v_{2} & \\ldots & u_{1} v_{n} \\\\\nu_{2} v_{1} & u_{2} v_{2} & \\ldots & u_{2} v_{n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nu_{m} v_{1} & u_{m} v_{2} & \\ldots & u_{m} v_{n}\n\\end{array}\\right]\n$$\nThe divergence of a dyad follows this formula:\n$$\n\\begin{aligned}\n&\\boldsymbol{\\nabla}  \\cdot(f \\mathbf{a})=(\\boldsymbol{\\nabla}  f) \\cdot \\mathbf{a}+(\\boldsymbol{\\nabla}  \\cdot \\mathbf{a}) f \\\\\n&\\boldsymbol{\\nabla}  \\cdot(\\mathbf{a b})=(\\boldsymbol{\\nabla}  \\cdot \\mathbf{a}) \\mathbf{b}+\\mathbf{a} \\cdot \\boldsymbol{\\nabla}  \\mathbf{b}\n\\end{aligned}\n$$\n{% endnote %}\n\nExpand the equation:\n$$\n\\begin{aligned}\n\\rho \\frac{\\partial \\mathbf{V}}{\\partial t}+\\mathbf{V} \\frac{\\partial \\rho}{\\partial t}+\\mathbf{V V} \\cdot \\boldsymbol{\\nabla}  \\rho+\\rho \\mathbf{V} \\cdot \\boldsymbol{\\nabla}  \\mathbf{V}+\\rho \\mathbf{V} \\boldsymbol{\\nabla}  \\cdot \\mathbf{V} &=\\mathbf{s} \\\\\n\\Leftrightarrow \\mathbf{V}\\left(\\frac{\\partial \\rho}{\\partial t}+\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  \\rho+\\rho(\\boldsymbol{\\nabla}  \\cdot \\mathbf{V})\\right)+\\rho\\left(\\frac{\\partial \\mathbf{V}}{\\partial t}+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla} ) \\mathbf{V}\\right) &=\\mathbf{s}\n\\end{aligned}\n$$\nWith $\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  \\rho+\\rho(\\boldsymbol{\\nabla}  \\cdot \\mathbf{V})=\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V})$, we have the first left term a continuity equation. Drop it we have:\n$$\n\\mathbf{V}\\underbrace{\\left(\\frac{\\partial \\rho}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V})\\right)}_{0}+\n\\rho\\underbrace{\\left(\\frac{\\partial \\mathbf{V}}{\\partial t}+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla} ) \\mathbf{V}\\right)}_{\\mathrm{material~derivative}} =\\mathbf{s}\n$$\nWith the definition of material derivative,\n$$\n\\color{purple}\n\\rho\\left(\\frac{D \\mathbf{V}}{D t}\\right) =\\mathbf{s}\n$$\nWithout source or sink, the quantity $\\mathbf{s}$ therefore represents **force per unit volume** $\\mathbf{s}=\\frac{\\mathrm{d} \\mathbf{F}}{\\mathrm{d} \\mathcal{V}}$.\n\n### 2.2 Forces\n\nThe forces contain *body forces* and *surface forces* $\\mathbf{F}=\\mathbf{F_b}+\\mathbf{F_s}$,\n\n- Body forces are due to external fields, take gravitational force as an example,\n  $$\n  d \\mathbf{F}_{g}=\\rho \\mathbf{g} d x d y d z \\quad \\mathbf{g}=-g \\mathbf{k}\n  $$\n  Consider the only body force in fluid dynamic is the gravity:\n  $$\n  \\color{purple}\n  \\frac{\\mathrm{d}\\mathbf{F_b}}{\\mathrm{d}\\mathcal{V}} = \\rho\\mathbf{g}\n  $$\n\n- Surface forces are due to hydrostatic pressure and viscous stresses on the *CS*:\n  $$\n  \\sigma_{i j}=\\left|\\begin{array}{ccc}\n  -p+\\tau_{x x} & \\tau_{y x} & \\tau_{z x} \\\\\n  \\tau_{x y} & -p+\\tau_{yy} & \\tau_{z y} \\\\\n  \\tau_{x z} & \\tau_{y z} & -p+\\tau_{z z}\n  \\end{array}\\right|\n  $$\n  <img src=\"Viscous stress on CS.png\" alt=\"Stress on CS\" style=\"zoom:50%;\" />\n\n  Similar to what we do in the [Mass Conservation](#differential-equation-of-mass-conservation), the force is due to the stress change in each direction, for instance:\n  $$\n  dF{s,xx} = \\left(\\sigma_{xx}+\\frac{\\partial\\sigma_{xx}}{\\partial x}dx\\right)dydz-\\sigma_{xx}dydz = \\frac{\\partial\\sigma_{xx}}{\\partial x}d\\mathcal{V}\n  $$\n  <img src=\"Surface forces on CS.png\" alt=\"Surface forces on CS\" style=\"zoom:50%;\" />\n\n  as a result:\n  $$\n  \\begin{aligned}\n  &\\frac{\\mathrm{d} F_{x}}{\\mathrm{~d} \\mathcal{V}}=-\\frac{\\partial p}{\\partial x}+\\frac{\\partial \\tau_{x x}}{\\partial x}+\\frac{\\partial \\tau_{y x}}{\\partial y}+\\frac{\\partial \\tau_{z x}}{\\partial z} \\\\\n  &\\frac{\\mathrm{d} F_{y}}{\\mathrm{~d} \\mathcal{V}}=-\\frac{\\partial p}{\\partial y}+\\frac{\\partial \\tau_{x y}}{\\partial x}+\\frac{\\partial \\tau_{y y}}{\\partial y}+\\frac{\\partial \\tau_{z y}}{\\partial z} \\\\\n  &\\frac{\\mathrm{d} F_{z}}{\\mathrm{~d} \\mathcal{V}}=-\\frac{\\partial p}{\\partial z}+\\frac{\\partial \\tau_{x z}}{\\partial x}+\\frac{\\partial \\tau_{y z}}{\\partial y}+\\frac{\\partial \\tau_{z z}}{\\partial z}\n  \\end{aligned}\n  $$\n  surface force in vector form:\n  $$\n  \\color{purple}\n  \\frac{\\mathrm{d} \\mathbf{F_s}}{\\mathrm{d} \\mathcal{V}}=- \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}}\n  $$\n  $\\frac{\\mathrm{d} \\mathbf{F_s}}{\\mathrm{d} \\mathcal{V}}$ also represents the Cauchy stress tensor:\n\n### 2.3 General differential linear momentum equation\n\nSubstitute force terms into earlier momentum conservation expression,\n$$\n\\color{purple}\n\\rho\\frac{D \\mathbf{V}}{D t} = \\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\mathbf{\\tau_{ij}}\n$$\n\n$$\n\\mathrm{density  acceleration = (Gravity + Pressure + Viscous) ~forces~per~unit~volume}\n$$\n\nThese equations are valid for any fluid in general motion, particularly those which include viscous stresses. The non-linear convective terms on the left-hand side also complicates direct mathematical analysis.\n\n### 2.4 Differential energy equations\n\nSimilar to earlier routes, we arrive energy conservation equation:\n$$\n\\dot{Q}-\\dot{W}_{v}=\\left(\\rho \\frac{D e}{D t}+\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  p+p \\boldsymbol{\\nabla}  \\cdot \\mathbf{V}\\right) \\mathrm{d}\\mathcal{V}\n$$\nNote that $\\dot{W}_{s} = 0$ since there is no shaft work in an infinitesimal CV, as a result, similar CV flux analysis can be done to $\\dot{Q}$ and $\\dot{W}_{v}$:\n\n- Heat conduction $\\dot{Q}$ is regulated by **Fourier's law** stating that the heat flux is proportional to the gradient of the temperature, $\\mathbf{q} = K\\boldsymbol{\\nabla}T$, using similar flux analysis to infinitesimal CV\n  $$\n  \\dot{Q}=\\boldsymbol{\\nabla}  \\cdot(k \\boldsymbol{\\nabla}   T)\\mathrm{d}\\mathcal{V}\n  $$\n\n- Similarly, the rate of work due to viscous stresses can be expanded to give:\n  $$\n  \\dot{W}_{v}=-\\boldsymbol{\\nabla} \\cdot\\left(\\mathbf{V} \\cdot \\boldsymbol{\\tau}_{i j}\\right)\\mathrm{d}\\mathcal{V}\n  $$\n\nSubstitute into energy conservation equation to give:\n$$\n\\rho \\frac{D e}{D t}+\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  p+p \\boldsymbol{\\nabla}  \\cdot \\mathbf{V}\n=\n\\boldsymbol{\\nabla}  \\cdot(k \\boldsymbol{\\nabla}   T)\n+\\boldsymbol{\\nabla} \\cdot\\left(\\mathbf{V} \\cdot \\boldsymbol{\\tau}_{i j}\\right)\n$$\n\n#### 2.4.1 General energy equation\n\nSplitting the viscous work term:\n$$\n\\boldsymbol{\\nabla} \\cdot\\left(\\mathbf{V} \\cdot \\boldsymbol{\\tau}_{i j}\\right) \\equiv \\mathbf{V} \\cdot \\left( \\boldsymbol{\\nabla} \\cdot \\boldsymbol{\\tau_{ij}} \\right) + \\underbrace{\\boldsymbol{\\tau_{ij}} : \\left( \\boldsymbol{\\nabla}\\mathbf{V} \\right)}_{\\boldsymbol{\\Phi}}\n$$\nwhere $\\boldsymbol{\\Phi}$ denotes the **viscous-dissipation function**, representing the dissipation of energy due to viscous effects. For **Newtonian flow in a Cartesian coordinates**: \n$$\n\\boldsymbol{\\Phi}=\\mu\\left[2\\left(\\frac{\\partial u}{\\partial x}\\right)^{2}+2\\left(\\frac{\\partial v}{\\partial y}\\right)^{2}+2\\left(\\frac{\\partial w}{\\partial z}\\right)^{2}+\\left(\\frac{\\partial v}{\\partial x}+\\frac{\\partial u}{\\partial y}\\right)^{2}+\\left(\\frac{\\partial w}{\\partial y}+\\frac{\\partial v}{\\partial z}\\right)^{2}+\\left(\\frac{\\partial u}{\\partial z}+\\frac{\\partial w}{\\partial x}\\right)^{2}\\right]\n$$\n{%  note info %}\n\nDissipated energy means during the flow, it is converted into the internal energy of the material. Note $\\boldsymbol{\\Phi}$ is always positive, implying that viscous flow always loses energy.\n\n{% endnote %}\n\nExpanding $e = \\hat{u}+\\frac{1}{2}V^{2}+gz$, the general differential energy equation is :\n$$\n\\color{purple}\n\\rho \\frac{D \\hat{u}}{D t}+p(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})=\\boldsymbol{\\nabla} \\cdot(k \\boldsymbol{\\nabla} T)+\\mathbf{\\Phi}\n$$\nwith further assumptions:\n$$\n\\begin{aligned}\nd \\hat{u} & \\approx c_{v} d T \\\\\nc_{v}, \\mu, k, \\rho & \\approx \\mathrm{const}\n\\end{aligned}\n$$\nfor incompressible flow, we have:\n$$\n\\color{purple}{\\rho c_{v} \\frac{\\partial T}{\\partial t} =\\cdot(k \\boldsymbol{\\nabla}^2 T)+\\mathbf{\\Phi}}\n$$\n\n## 3 Euler and Navier-Stokes Equations\n\nRecall [differential linear momentum equation](#general-differential-linear-momentum-equation):\n$$\n\\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}} = \\rho\\frac{D \\mathbf{V}}{D t}\n$$\nEquations of motion of $\\boldsymbol{\\tau_{ij}}$ is still needed, and its different depending on types of fluid\n\n### 3.1 Euler equations (frictionless flow)\n\nUse the inviscid flow assumption, that is $\\boldsymbol{\\tau_{ij}}=0$, the momentum equation reduces to:\n$$\n\\color{purple}\n\\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}} = \\rho\\frac{D \\mathbf{V}}{D t}\n$$\n{% note info %}\n\nFluids with low viscosity can be reasonably modelled as inviscid, except near boundaries.\n\n{% endnote %}\n\n### 3.2 Newtonian fluid\n\n#### 3.2.1 Strain\n\nStrains of a fluid particle evaluate the deformation due to an applied *shear stress*.\n\n<img src=\"Fluid partical deformation.png\" alt=\"Fluid partical deformation\" style=\"zoom:50%;\" />\n\nand strain is defined as (anticlockwise positive):\n$$\n\\mathrm{strain_{xy}} = \\Delta\\theta_x-(-\\Delta\\theta_y)\n$$\nIn a continuous system, the rate of strain is then:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}(\\mathrm{strain_{xy}}) = \\epsilon_{xy} = \\frac{\\partial v}{\\partial x} + \\frac{\\partial u}{\\partial y}\n$$\nor in vector form:\n$$\n\\boldsymbol{\\epsilon} = \\nabla \\mathbf{V}+(\\nabla \\mathbf{V}^{\\top})\n$$\n\n#### 3.2.2 Viscosity\n\nNewton defined a **newtonian fluid** by a fluid in which the *viscous stresses* are linearly proportional to the local *strain rates*.\n$$\n\\boldsymbol{\\tau_{ij}} \\propto \\boldsymbol{\\epsilon_{ij}}\n$$\nIn order to apply this to the NaiverStokes equations, three assumptions were made by Stokes:\n\n- The stress tensor is a linear function of the strain rate tensor or equivalently the velocity gradient.\n- The fluid is isotropic.\n- For a fluid at rest,  $\\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}} = 0$  (so that hydrostatic pressure results).\n\nAnd it leads to:\n$$\n\\color{purple}\n\\boldsymbol{\\tau}=\\mu\\left(\\nabla \\mathbf{u}+\\nabla \\mathbf{u}^{\\top}\\right)+\\lambda(\\nabla \\cdot \\mathbf{u}) \\mathbf{I}\n$$\nor\n$$\n\\boldsymbol{\\tau_{ij}}=\\mu\\left(\\frac{\\partial u_{i}}{\\partial x_{j}}+\\frac{\\partial u_{j}}{\\partial x_{i}}\\right)+\\delta_{i j} \\lambda \\frac{\\partial u_{k}}{\\partial x_{k}} \\\\\n$$\nwhere,\n$$\n\\delta_{i j}= \\begin{cases}0 & \\text { if } i \\neq j \\\\ 1 & \\text { if } i=j\\end{cases}\n$$\nAs a result, expand the formula:\n$$\n\\boldsymbol{\\tau_{ij}}=\\left|\\begin{array}{ccc}\n2 \\mu \\frac{\\partial u}{\\partial x}+\\lambda \\frac{\\partial u_{}}{\\partial x_{k}} & \\mu\\left(\\frac{\\partial u}{\\partial y}+\\frac{\\partial v}{\\partial x}\\right) & \\mu\\left(\\frac{\\partial u}{\\partial z}+\\frac{\\partial w}{\\partial x}\\right) \\\\\n\\mu\\left(\\frac{\\partial v}{\\partial x}+\\frac{\\partial u}{\\partial y}\\right) & 2 \\mu \\frac{\\partial v}{\\partial y}+\\lambda \\frac{\\partial v}{\\partial y} & \\mu\\left(\\frac{\\partial v}{\\partial z}+\\frac{\\partial w}{\\partial y}\\right) \\\\\n\\mu\\left(\\frac{\\partial w}{\\partial x}+\\frac{\\partial u}{\\partial z}\\right) & \\mu\\left(\\frac{\\partial w}{\\partial y}+\\frac{\\partial v}{\\partial z}\\right) & 2 \\mu \\frac{\\partial w}{\\partial z}+\\lambda \\frac{\\partial w}{\\partial z}\n\\end{array}\\right|\n$$\nAnd $\\mu$ and $\\lambda$ represents the **shear/dynamic viscosity** and **volume/bulk viscosity** respectively,\n\n>The value of **, which produces a viscous effect associated with volume change, is very difficult to determine, not even its sign is known with absolute certainty. Even in compressible flows, the term involving ** is often negligible; however it can occasionally be important even in nearly incompressible flows and is a matter of controversy. When taken nonzero, the most common approximation is ****  2/3****.\n\n### 3.3 Navier-Stokes equations\n\nSubstitute the stress representation into the linear momentum equation:\n$$\n\\rho\\frac{D \\mathbf{V}}{D t} = \\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot \\mu\\left( \\left(\\boldsymbol{\\nabla} \\mathbf{V}+\\boldsymbol{\\nabla} \\mathbf{V}^{\\top}\\right)-\\frac{2}{3}(\\nabla \\cdot \\mathbf{V}) \\mathbf{I}\\right)\n$$\nwith further simplification we have:\n$$\n\\color{purple}\n\\rho \\frac{\\mathrm{D} \\mathbf{V}}{\\mathrm{D} t}=\\rho\\left(\\frac{\\partial \\mathbf{V}}{\\partial t}+\\mathbf{V} \\cdot \\nabla \\mathbf{V}\\right)=-\\nabla p+\\mu \\nabla^{2} \\mathbf{V}+\\frac{1}{3} \\mu \\nabla(\\nabla \\cdot \\mathbf{V})+\\rho \\mathbf{g}\n$$\n\n#### 3.3.1 Incompressible Navier-Stokes equations\n\nWith incompressible flow we have no bulk viscosity so:\n$$\n\\boldsymbol{\\tau}=\\mu\\left(\\nabla \\mathbf{u}+\\nabla \\mathbf{u}^{\\top}\\right)\n$$\nAnd the Incompressible Navier-Stokes equations is therefore:\n$$\n\\rho\\frac{D \\mathbf{V}}{D t} = \\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot \\mu\\left( \\boldsymbol{\\nabla} \\mathbf{V}+\\boldsymbol{\\nabla} \\mathbf{V}^{\\top}\\right)\n$$\nwith  $\\boldsymbol{\\nabla} \\cdot \\mathbf{V}=0$ for incompressible flow:\n$$\n\\boldsymbol{\\nabla} \\cdot \\mu\\left( \\boldsymbol{\\nabla} \\mathbf{V}+\\boldsymbol{\\nabla} \\mathbf{V}^{\\top}\\right) = \\mu\\boldsymbol{\\nabla}^2\\mathbf{V}\n$$\nas a result:\n$$\n\\color{purple}\n\\frac{\\partial\\mathbf{V}}{\\partial t} +  \\mathbf{V} \\cdot \\nabla \\mathbf{V}= \\mathbf{g} - \\boldsymbol{\\nabla}\\frac{p}{\\rho} +  \\nu\\boldsymbol{\\nabla}^2\\mathbf{V}\n$$\nwhere $\\nu = \\frac{\\mu}{\\rho}$, called **kinetic viscosity**\n\n{% note info %}\n\nMeaning of each term:\n$$\n\\overbrace{\\underbrace{\\frac{\\partial \\mathbf{V}}{\\partial t}}_{\\text {Variation }}+\\underbrace{(\\mathbf{V} \\cdot \\nabla) \\mathbf{V}}_{\\text {Convection }}}^{\\text {Inertia (per volume) }}= \\overbrace{\\underbrace{\\nu \\nabla^{2} \\mathbf{V}}_{\\text {Diffusion }}\\underbrace{-\\nabla w}_{\\begin{array}{c}\n\\text { Internal } \\\\\n\\text { source }\n\\end{array}}}^{\\text {Divergence of stress }}+\\underbrace{\\mathbf{g}}_{\\begin{array}{c}\n\\text { External } \\\\\n\\text { source }\n\\end{array}} .\n$$\n{% endnote %}\n\nExpanding along every coordinates gives that:\n$$\n\\begin{align}\n\\frac{\\partial u}{\\partial t} +  u \\frac{\\partial u}{\\partial x} + v\\frac{\\partial u}{\\partial y} + w \\frac{\\partial u}{\\partial z}&= g_x - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial x} +  \\nu\\left(\\frac{\\partial^2u}{\\partial^2x}+\\frac{\\partial^2u}{\\partial^2y}+\\frac{\\partial^2u}{\\partial^2z}\\right) \\\\\n\\frac{\\partial v}{\\partial t} +  u \\frac{\\partial v}{\\partial x} + v\\frac{\\partial v}{\\partial y} + w \\frac{\\partial v}{\\partial z}&= g_y - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial y} +  \\nu\\left(\\frac{\\partial^2v}{\\partial^2x}+\\frac{\\partial^2v}{\\partial^2y}+\\frac{\\partial^2v}{\\partial^2z}\\right) \\\\\n\\frac{\\partial w}{\\partial t} +  u \\frac{\\partial w}{\\partial x} + v\\frac{\\partial w}{\\partial y} + w \\frac{\\partial w}{\\partial z}&= g_z - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial z} +  \\nu\\left(\\frac{\\partial^2w}{\\partial^2x}+\\frac{\\partial^2w}{\\partial^2y}+\\frac{\\partial^2w}{\\partial^2z}\\right)\n\\end{align}\n$$\n\n#### 3.3.2 Cylindrical coordinates\n\nRecall the coordinates transformation:\n$$\nr=\\sqrt{x^{2}+y^{2}} \\quad \\theta=\\tan ^{-1} \\frac{y}{x} \\quad z=z\n$$\nand the differential operators:\n$$\n\\begin{aligned}\n\\boldsymbol{\\nabla} f &=\\frac{\\partial f}{\\partial r} \\hat{\\boldsymbol{r}}+\\frac{1}{r} \\frac{\\partial f}{\\partial \\theta} \\hat{\\boldsymbol{\\theta}}+\\frac{\\partial f}{\\partial z} \\hat{\\boldsymbol{z}}\\\\\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} &=\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r V_{r}\\right)+\\frac{1}{r} \\frac{\\partial}{\\partial \\theta}\\left(V_{\\theta}\\right)+\\frac{\\partial}{\\partial z}\\left(V_{z}\\right)\\\\\n\\boldsymbol{\\nabla}^2f &= \\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial f}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} f}{\\partial \\theta^{2}}+\\frac{\\partial^{2} f}{\\partial z^{2}}\\right)\n\\end{aligned}\n$$\nAnd in z direction\n$$\n\\begin{align}\n\\frac{\\partial V_r}{\\partial t} +  V_r \\frac{\\partial V_r}{\\partial r} + V_\\theta\\frac{1}{r}\\frac{\\partial V_r}{\\partial \\theta} + V_z \\frac{\\partial V_r}{\\partial z}&= g_r - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial r} +  \\nu\\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial V_{r}}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} V_{r}}{\\partial \\theta^{2}}+\\frac{\\partial^{2} V_{r}}{\\partial z^{2}}\\right) \\\\\n\\frac{\\partial V_\\theta}{\\partial t} +  V_r \\frac{\\partial  V_\\theta}{\\partial r} + V_\\theta\\frac{1}{r}\\frac{\\partial  V_\\theta}{\\partial \\theta} + V_z \\frac{\\partial  V_\\theta}{\\partial z}&= g_\\theta - \\frac{1}{\\rho r}\\frac{\\partial p}{\\partial \\theta} +    \\nu\\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial V_{\\theta}}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} V_{\\theta}}{\\partial \\theta^{2}}+\\frac{\\partial^{2} V_{\\theta}}{\\partial z^{2}}\\right) \\\\\n\\frac{\\partial V_z}{\\partial t} +  V_r \\frac{\\partial V_r}{\\partial r} + V_\\theta\\frac{1}{r}\\frac{\\partial V_z}{\\partial \\theta} + V_z \\frac{\\partial V_z}{\\partial z}&= g_z - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial z} +  \\nu\\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial V_{z}}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} V_{z}}{\\partial \\theta^{2}}+\\frac{\\partial^{2} V_{z}}{\\partial z^{2}}\\right)\n\\end{align}\n$$\n\n### 3.3 Closing the system\n\nTo summarise, the 3 main functions are:\n$$\n\\begin{aligned} \\frac{\\partial \\rho}{\\partial t}+\\nabla \\cdot(\\rho\\mathbf{V}) &=0 & & \\text { continuity } \\\\ \\rho \\mathbf{g}-\\nabla p+\\boldsymbol{\\nabla} \\cdot \\boldsymbol{\\tau}_{i j} &=\\rho \\frac{D \\mathbf{V}}{D t} & & \\text { momentum } \\\\ \\rho \\frac{D \\hat{u}}{D t}=p(\\boldsymbol{\\nabla} \\cdot \\mathbf{V}) &=\\boldsymbol{\\nabla} \\cdot(k \\boldsymbol{\\nabla} T)+\\mathbf{\\Phi} & & \\text { energy } \\end{aligned}\n$$\nNote that there are five unknowns $\\rho,\\mathbf{V}, p, \\hat{u},T$, but only three equations. Additional equations are state relations for the thermodynamic properties of the fluid. For example for perfect gas:\n$$\n\\rho=\\frac{p}{R T} \\quad \\hat{u}=\\int c_{v} d T\n$$\nThe system of equations is now well-posed and can be solved, subject to *boundary conditions.*\n\n#### 3.3.1 Incompressible system\n\nWe have:\n$$\n\\begin{aligned}\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} &=0 \\\\\n\\rho \\frac{D \\mathbf{V}}{D t} &=\\rho \\boldsymbol{g}-\\nabla p+\\mu \\nabla^{2} \\mathbf{V} \\\\\n\\rho c_{p} \\frac{D T}{D t} &=k \\nabla^{2} T+\\mathbf{\\Phi}\n\\end{aligned}\n$$\nNote that for incompressible flow, $\\rho,\\mu,k$ are constants, only 3 unknowns are left $p, \\mathbf{V}, T$. So the incompressible system is already closed. Besides, continuity and momentum equations are independent of the $T$, thus decouple from the energy equation.\n\n### 3.4 Boundary conditions\n\n- Wall: these are typically solid, impermeable and there is a no-slip condition at the wall.\n- Inlet: known velocity $\\mathbf{V}$ and pressure $p$ (and temperature $T$)\n\n### 3.5 Stream function\n\nStream function provides a mathematical tool to automatically satisfy the continuity constraint, after which we can then solve the momentum equation.\n\n{% note info %}\n\nIt is only applicable to flows which are **steady**, **incompressible** and **two-dimensional**.\n\n{% endnote %}\n\nWith continuity equation:\n$$\n\\boldsymbol{\\nabla}\\cdot\\mathbf{V} = 0 \\Leftrightarrow \\frac{\\partial u }{\\partial x} + \\frac{\\partial v}{\\partial y} = 0\n$$\nWe seek to replace the velocity components $u$ and $v$ with a scalar function $\\psi(x,y)$, which satisfies the above constraint:\n$$\n\\frac{\\partial}{\\partial x}\\left(\\frac{\\partial \\psi}{\\partial y}\\right)  + \\frac{\\partial}{\\partial y}\\left(-\\frac{\\partial \\psi}{\\partial x}\\right) \\equiv 0\n$$\nAs a result:\n$$\nu=\\frac{\\partial \\psi}{\\partial y} \\qquad v=-\\frac{\\partial \\psi}{\\partial x}\n$$\n\n#### 3.5.1 Properties of stream function\n\n- Recall the definition of a streamline:\n\n$$\n\\begin{align}\n& \\frac{dy}{v} = \\frac{dx}{u} \\\\\n\\Leftrightarrow\\quad & \\frac{\\partial \\psi}{\\partial y}u+\\frac{\\partial \\psi}{\\partial x}v=0 \\\\\n\\Leftrightarrow\\quad & d\\psi=0 \\\\\n\\Leftrightarrow\\quad & \\psi=Const\n\\end{align}\n$$\n\n- The change of $\\psi$ across a control surface of unit depth is equal to the volume flow through the surface\n\n   <img src=\"Stream function property.png\" alt=\"Stream function property\" style=\"zoom:50%;\" />\n  $$\n  \\begin{aligned}\n  d Q &=(\\mathbf{V} \\cdot \\boldsymbol{n}) d A \\\\\n  &=\\left(\\boldsymbol{i} \\frac{\\partial \\psi}{\\partial y}-\\boldsymbol{j} \\frac{\\partial \\psi}{\\partial x}\\right) \\cdot\\left(\\boldsymbol{i} \\frac{\\mathrm{d} y}{\\mathrm{~d} s}-\\boldsymbol{j} \\frac{\\mathrm{d} x}{\\mathrm{~d} s}\\right) d s \\\\\n  &=\\frac{\\partial \\psi}{\\partial x} d x+\\frac{\\partial \\psi}{\\partial y} d y \\\\\n  &=d \\psi\n  \\end{aligned}\n  $$\n\n- The flow direction can be determined by observing whether $\\psi$ increases or decreases\n\n  <img src=\"Flow direction based on stream function.png\" alt=\"Flow direction based on stream function\" style=\"zoom:50%;\" />\n\n## 4 Vorticity and Irrotationality\n\n### 4.1 Vorticity\n\nRecall how a fluid particle deforms under shear stresses:\n\n<img src=\"Fluid particle deformation.png\" alt=\"Fluid particle deformation\" style=\"zoom:50%;\" />\n\nThe angular velocity $\\omega_z$ is defined as the average rate of counter-clockwise turning of the two sides:\n$$\n\\omega_z = \\frac{1}{2}\\left(\\frac{\\mathrm{d}(\\Delta\\theta_x)}{\\mathrm{d}t}+\\frac{\\mathrm{d}(\\Delta\\theta_y)}{\\mathrm{d}t}\\right) =\\frac{1}{2}\\left(\\frac{\\partial v}{\\partial x}-\\frac{\\partial u}{\\partial y}\\right)\n$$\nSimilarly, \n$$\n\\omega_{x}=\\frac{1}{2}\\left(\\frac{\\partial w}{\\partial y}-\\frac{\\partial v}{\\partial z}\\right) \\quad \\omega_{y}=\\frac{1}{2}\\left(\\frac{\\partial u}{\\partial z}-\\frac{\\partial w}{\\partial x}\\right)\n$$\nCombine together the angular velocity:\n$$\n\\boldsymbol{\\omega}=\\frac{1}{2}(\\underbrace{\\boldsymbol{\\nabla} \\times \\mathbf{V}}_{\\text {curl } \\mathbf{V}})=\\frac{1}{2}\\left|\\begin{array}{ccc}\n\\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\\n\\frac{\\partial}{\\partial x} & \\frac{\\partial}{\\partial y} & \\frac{\\partial}{\\partial z} \\\\\nu & v & w\n\\end{array}\\right|\n$$\nAnd the vorticity is defined as twice the angular velocity i.e. curl of velocity:\n$$\n\\boldsymbol{\\xi}=2 \\boldsymbol{\\omega}=\\operatorname{curl} \\mathbf{V}=\\boldsymbol{\\nabla} \\times \\mathbf{V}\n$$\n\n### 4.2 Vorticity function for two-dimensional incompressible flow\n\nFirst some math:\n$$\n\\begin{aligned}\n\\boldsymbol{\\nabla} \\times \\boldsymbol{\\nabla} \\phi & \\equiv 0 \\qquad\\qquad&(4.1) \\\\\n\\boldsymbol{\\nabla} \\times\\left(\\boldsymbol{\\nabla}^{2} \\mathbf{V}\\right) &=\\boldsymbol{\\nabla}^{2}(\\boldsymbol{\\nabla} \\times \\mathbf{V}) \\qquad\\qquad&(4.2) \\\\\n(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V} &=\\boldsymbol{\\nabla}\\left(\\frac{1}{2} \\mathbf{V} \\cdot \\mathbf{V}\\right)-\\mathbf{V} \\times \\boldsymbol{\\xi} \\qquad\\qquad&(4.3) \\\\\n\\boldsymbol{\\nabla} \\times(\\mathbf{V} \\times \\boldsymbol{\\xi}) &=-\\boldsymbol{\\xi}(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})+(\\boldsymbol{\\xi} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}-(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi} \\qquad\\qquad&(4.4) \n\\end{aligned}\n$$\nRecall the [incompressible momentum equation](#incompressible-navier-stokes-equations):\n$$\n\\frac{\\partial\\mathbf{V}}{\\partial t} + \\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V} = \\mathbf{g} -\\boldsymbol{\\nabla}\\left(\\frac{p}{\\rho}\\right) + \\nu\\boldsymbol{\\nabla}^2\\mathbf{V}\n$$\nTake the curl for each term:\n$$\n\\underbrace{\\boldsymbol{\\nabla} \\times\\frac{\\partial\\mathbf{V}}{\\partial t} }_{\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}}+ \\boldsymbol{\\nabla} \\times\n\\underbrace{\\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V}}_{\\boldsymbol{\\nabla}\\left(\\frac{1}{2} \\mathbf{V} \\cdot \\mathbf{V}\\right)-\\mathbf{V} \\times \\boldsymbol{\\xi},~\\mathrm{by}(4.3)} = \n\\underbrace{\\boldsymbol{\\nabla} \\times\\mathbf{g}}_{0} -\n\\underbrace{\\boldsymbol{\\nabla} \\times\\boldsymbol{\\nabla}\\left(\\frac{p}{\\rho}\\right)}_{0,~\\mathrm{by} (4.1)}+ \n\\nu\\underbrace{\\boldsymbol{\\nabla} \\times\\boldsymbol{\\nabla}^2\\mathbf{V}}_{\\boldsymbol{\\nabla}^{2}(\\boldsymbol{\\nabla} \\times \\mathbf{V}),~ \\mathrm{by} (4.2)}\n$$\nAs a result:\n$$\n\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}+ \\underbrace{\\boldsymbol{\\nabla} \\times\\boldsymbol{\\nabla}\\left(\\frac{1}{2} \\mathbf{V} \\cdot \\mathbf{V}\\right)}_{0,~\\mathrm{by} (4.1)}-\\boldsymbol{\\nabla} \\times\\mathbf{V} \\times \\boldsymbol{\\xi}= \\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\n$$\nApply $(4.4)$ cancel terms due to assumptions:\n$$\n\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}\n+\\underbrace{\\boldsymbol{\\xi}(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})}_{0,~\\mathrm{steady~incompressible}}\n-\\underbrace{(\\boldsymbol{\\xi} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}}_{0,~\\mathrm{2D~flow}}\n+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi}= \\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\n$$\nFinally, the vorticity function for 2D incompressible flow is:\n$$\n\\color{purple}\n\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}\n+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi}= \n\\frac{D\\boldsymbol{\\xi}}{D t}=\n\\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\n$$\n{% note info %}\n\nSome of the terms have specific physical interpretations:\n\n- $(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi}$ is *convection* \n- $(\\boldsymbol{\\xi} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}$ is *stretching* \n- $\\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}$ is *diffusion*\n\n{% endnote %}\n\n{% note info %}\n\nNote that there is no pressure term in the vorticity equation, implying that vorticity dynamics are localised in space.\n\n{% endnote %}\n\n#### 4.2.1 Combine with continuity equation\n\nRecall the definition of the [stream function](#stream-function) and take the curl:\n$$\n\\begin{aligned}\n\\mathbf{V} &= \\mathbf{i}\\frac{\\partial\\psi}{\\partial y}-\\mathbf{j}\\frac{\\partial\\psi}{\\partial x} \\\\\n\\boldsymbol{\\nabla}\\times\\mathbf{V} &= -\\mathbf{k}\\boldsymbol{\\nabla}^2\\psi = -\\mathbf{k}\\left( \\frac{\\partial^2\\psi}{\\partial x^2} + \\frac{\\partial^2\\psi}{\\partial y^2} \\right)\n\\end{aligned}\n$$\nSubstitute these into the vorticity equation, a 4th-order single equation in $\\psi$ arrived:\n$$\n\\color{purple}\n\\frac{\\partial \\psi}{\\partial y} \\frac{\\partial}{\\partial x}\\left(\\nabla^{2} \\psi\\right)-\\frac{\\partial \\psi}{\\partial x} \\frac{\\partial}{\\partial y}\\left(\\nabla^{2} \\psi\\right)=\\nu \\nabla^{2}\\left(\\nabla^{2} \\psi\\right)\n$$\n{% note info %}\n\nAssumptions made:\n\n- Steady flow\n- Incompressible\n- Two dimensional\n\n{% endnote %}\n\nOne important special case is when  \n$$\n\\boldsymbol{\\nabla}^2\\psi = \\frac{\\partial^2\\psi}{\\partial x^2} + \\frac{\\partial^2\\psi}{\\partial y^2} = 0\n$$\nThe flow is **irrotational**.\n\n### 4.3 Full Bernoulli equations\n\nWe now consider a flow which is **inviscid** (although may still be **compressible**).\n\nRecall [Euler's equation](#euler-equations-frictionless-flow):\n$$\n\\frac{\\partial\\mathbf{V}}{\\partial t} + \\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V} = \\mathbf{g} -\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)\n$$\nExpand the convection term by $(4.3)$:\n$$\n\\frac{\\partial\\mathbf{V}}{\\partial t} + \\boldsymbol{\\nabla}\\left(\\frac{1}{2} V^2\\right)+\n\\underbrace{\\boldsymbol{\\xi}\\times\\mathbf{V}}_{\\mathbf{a}\\times\\mathbf{b}=-\\mathbf{b}\\times\\mathbf{a}}- \\mathbf{g} +\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)=0\n$$\nTry to integrate it along an arbitrary trajectory in the flow, dot with a small displacement vector $d\\mathbf{r}$:\n$$\n\\left[\\frac{\\partial\\mathbf{V}}{\\partial t} + \\boldsymbol{\\nabla}\\left(\\frac{1}{2} V^2\\right)+\n\\boldsymbol{\\xi}\\times\\mathbf{V}- \\mathbf{g} +\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)\\right]d\\mathbf{r}=0\n$$\nThe 3<sup>rd</sup> term equals 0 when:\n\n- Irrotational flow: $\\mathbf{\\xi}\\equiv0$\n\n- No flow: $\\mathbf{V}\\equiv0$, not possible\n\n- $d\\mathbf{r}$ is parallel to $\\mathbf{V}$, $\\mathbf{V} \\times d \\boldsymbol{r} \\equiv 0$\n\n  since $(\\boldsymbol{\\xi} \\times \\mathbf{V}) \\cdot d \\boldsymbol{r} \\equiv(\\mathbf{V} \\times d \\boldsymbol{r}) \\cdot \\boldsymbol{\\xi}$\n\n  our path is a streamline\n\nIn order to eliminate the 3<sup>rd</sup> term while keeping the flow rotational, we integrate the equation along the streamline segment $ds$,\n$$\n\\begin{aligned}\n\\int_1^2\\left[\\frac{\\partial\\mathbf{V}}{\\partial t} + \\boldsymbol{\\nabla}\\left(\\frac{1}{2} V^2\\right)-\n\\mathbf{g} +\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)\\right]ds=0 \\\\\n\\int_1^2\\frac{\\partial\\mathbf{V}}{\\partial t}ds + \\left(\\frac{1}{2} V_2^2-\\frac{1}{2} V_1^2\\right) + g(z_2-z_1) +\\int_1^2\\frac{1}{\\rho}\\left(dp\\right)=0\n\\end{aligned}\n$$\nRearrange to get the **unsteady Bernoulli equation for compressible flow**:\n$$\n\\color{purple}\\int_1^2\\frac{\\partial\\mathbf{V}}{\\partial t}ds+\\int_1^2\\frac{1}{\\rho}\\left(dp\\right)+ \\left(\\frac{1}{2} V_2^2-\\frac{1}{2} V_1^2\\right) + g(z_2-z_1)=0\n$$\nPlus the **steady and incompressible** conditions, the function reduced to the familiar expression:\n$$\n\\color{purple}\n\\frac{p}{\\rho}+\\frac{1}{2}V^2+gz = Const,~\\mathrm{~along~a~streamline}\n$$\nPlus the **irrotational** condition, the 3rd term remains 0 regardless the trajectory, the function becomes:\n$$\n\\color{purple}\n\\frac{p}{\\rho}+\\frac{1}{2}V^2+gz = Const,~\\mathrm{~everywhere}\n$$\n\n### 4.4 Velocity potential\n\nVector analysis tells us that if the curl of a vector field is zero then that vector field must itself be the gradient of a scalar function. That is,\n\nThe function $\\phi$ is called a potential function.\n$$\n\\boldsymbol{\\nabla} \\times \\mathbf{V} \\equiv 0 \\quad \\Rightarrow \\quad \\mathbf{V}=\\boldsymbol{\\nabla} \\phi\n$$\n{% note info %}\n\nVelocity potential $\\phi$ is another scalar function, a complementary to the [stream function](#stream-function) $\\psi$.\n\nIt is applicable only in **irrotational** flow.\n\n{% endnote %}\n\nSome useful properties:\n\n- In Cartesian coordinate, it reduce the 3 velocity components $u$, $v$, $w$ into a single scalar:\n  $$\n  u=\\frac{\\partial \\phi}{\\partial x} \\quad v=\\frac{\\partial \\phi}{\\partial y} \\quad w=\\frac{\\partial \\phi}{\\partial z}\n  $$\n\n- Line of constant $\\phi$ is called *potential lines*.\n\n  In **two-dimensional flow**, potential lines are everywhere orthogonal to the streamlines, because:\n  $$\n  u=\\frac{\\partial \\psi}{\\partial y}=\\frac{\\partial \\phi}{\\partial x} \\quad v=-\\frac{\\partial \\psi}{\\partial x}=\\frac{\\partial \\phi}{\\partial y}\n  $$\n  The dot-product of their gradients are:\n  $$\n  \\left[\\frac{\\partial \\psi}{\\partial x} \\mathbf{i}+\\frac{\\partial \\psi}{\\partial y} \\mathbf{j}\\right] \\cdot\\left[\\frac{\\partial \\phi}{\\partial x} \\mathbf{i}+\\frac{\\partial \\phi}{\\partial y} \\mathbf{j}\\right]=u(-v)+u v \\equiv 0\n  $$\n\n- If $\\phi$ exists, substitute the definition into the unsteady Bernoulli equation,\n  $$\n  \\frac{\\partial \\phi}{\\partial t}+\\int \\frac{d p}{\\rho}+\\frac{1}{2}|\\boldsymbol{\\nabla} \\phi|^{2}+g z=\\mathrm{const}\n  $$\n  {% note info %}\n\n  It is an equation between just two scalar quantities, $\\phi$ and $p$.\n\n  {% endnote %}\n\n## 5 Vortex Motion and Applications\n\nVortices are structures within the flow in which fluid is rotating about an axis line (which may be straight or curved). A **vortex line** is therefore defined as a line which is always in the same direction as the local vorticity vector $\\boldsymbol{\\xi}$.\n\n<img src=\"Vortex line example.png\" alt=\"Vortex line example (red line) from physics.stackexchange.com\" style=\"zoom:100%;\" />\n\nSimilar to streamline, vortex lines $(x, y, z) = (x(s), y(s), z(s))$ are obtained by solving:\n$$\n\\frac{dx/ds}{d\\xi_x}=\\frac{dy/ds}{d\\xi_y}=\\frac{dz/ds}{d\\xi_z}\n$$\nSimilar to steam tube, vertex lines which pass through a closed curve in space form a **vortex tube**.\n\n### 5.1 Circulation\n\n**Fluid circulation** describes the strength of rotation, or strength of fluid swirling, within a closed contour $C(t)$. Mathematically it is defined as the integral of velocity along the contour curve:\n$$\n\\Gamma=\\oint_{C(t)} \\mathbf{V} d s=\\int_{S} \\boldsymbol{\\xi} \\cdot \\boldsymbol{n} d S\n$$\n\n#### 5.1.1 Material elements and its motion\n\nConsider how a infinitesimal displacement $d\\mathbf{s}$ deforms over a small time $dt$, illustrated in the diagram below.\n\n<img src=\"Displacement deformation.png\" alt=\"Displacement deformation\" style=\"zoom:50%;\" />\n\nWe have $d(d\\mathbf{s})$ the **material line element**:\n$$\n\\begin{aligned}\nd(d \\boldsymbol{s})=d \\boldsymbol{s}_{1}-d \\boldsymbol{s}_{0} &=\\left(\\boldsymbol{x}+d \\boldsymbol{s}_{0}+\\mathbf{V}\\left(\\boldsymbol{x}+d \\boldsymbol{s}_{0}\\right) d t\\right)-(\\boldsymbol{x}+\\mathbf{V}(\\boldsymbol{x}) d t)-d \\boldsymbol{s}_{0} \\\\\n&=\\left(\\mathbf{V}\\left(\\boldsymbol{x}+d \\boldsymbol{s}_{0}\\right)-\\mathbf{V}(\\boldsymbol{x})\\right) d t \\\\\n&=d \\boldsymbol{s}_{0} \\frac{\\partial \\mathbf{V}}{\\partial\\left(d \\boldsymbol{s}_{0}\\right)} d t \\\\\n&=d \\boldsymbol{s}_{0} \\cdot \\boldsymbol{\\nabla} \\mathbf{V} d t\n\\end{aligned}\n$$\nTherefore:\n$$\n\\frac{D(d\\mathbf{s})}{Dt} = (ds\\cdot\\boldsymbol{\\nabla})\\mathbf{V}\n$$\n\n### 5.2 Kelvins Circulation Theorem\n\n> Kelvins Circulation Theorem status the expression of the rate of change of the circulation $\\frac{D\\Gamma}{Dt}$ and determine how a circulation around a fluid loop varies as the loop moves with the flow. ([reference](https://youtu.be/q4xSUYZCj84))\n\nApply material derivative to circulation we have:\n$$\n\\begin{aligned}\n\\frac{D}{Dt}\\Gamma&=\\frac{D}{Dt}\\oint_{C(t)} \\mathbf{V} d \\mathbf{s}\t\\\\\n&= \\oint_{C(t)}\\frac{D}{Dt}(\\mathbf{V} d \\mathbf{s}\t) \\\\\n&= \\oint_{C(t)}\\frac{D\\mathbf{V}}{Dt}\\cdot d \\mathbf{s}\t + \\oint_{C(t)}\\mathbf{V}\\cdot \\frac{D(d \\mathbf{s})}{Dt}\t\t\\\\\n\\end{aligned}\n$$\nSubstitute material line element into the last term to get a scalar inside the loop integration, then we have:\n$$\n\\frac{D}{Dt}\\Gamma = \\oint_{C(t)}\\frac{D\\mathbf{V}}{Dt}d \\mathbf{s}\n$$\nRecall the [general linear momentum equation](#general-differential-linear-momentum-equation) and substitute the material derivative of velocity:\n$$\n\\begin{aligned}\n\\frac{D}{Dt}\\Gamma &= \\oint_{C(t)}\\left(\\mathbf{g} - \\frac{\\boldsymbol{\\nabla}p}{\\rho} + \\frac{\\boldsymbol{\\boldsymbol{\\nabla}\\cdot\\tau_{ij}}}{\\rho}\\right)d \\mathbf{s} \\\\\n&= \\oint_{C(t)}\\mathbf{g}d \\mathbf{s}  - \\oint_{C(t)}\\frac{\\boldsymbol{\\nabla}p}{\\rho} d\\mathbf{s}   + \\oint_{C(t)}\\frac{\\boldsymbol{\\nabla}\\cdot\\boldsymbol{\\tau_{ij}}}{\\rho}d \\mathbf{s} \n\\end{aligned}\n$$\nThis function is not zero unless:\n\n- 1<sup>st</sup> term: body force torque is zero, body force is **irrotational**, $\\mathbf{g} = \\nabla\\phi$, $\\phi$ is a scalar.\n- 2<sup>nd</sup> term: $p = p(\\rho)$ or $\\rho = const.$(**incompressible and isotropic**)\n- 3<sup>rd</sup> term: **inviscid**, $\\boldsymbol{\\tau_{ij}}=0$\n\n#### 5.2.1 Aerofoil lift and Kutta-Joukowski Theorem\n\nOne application of the Kelvin Circulation Theorem is in explaining the lift attained by an aerofoil during the shedding of the starting vortex.\n\nConsider a stationary aerofoil shown in the diagram below.\n\n<img src=\"Aerofoil vortex shedding.png\" alt=\"Aerofoil vortex shedding\" style=\"zoom:50%;\" />\n\nAt time $t = 0$, the aerofoil is stationary, there is no vorticity and around the path $C(t)$ the circulation is $\\Gamma = 0$. As the flow velocity increases, vorticity is shed behind the aerofoil leading to positive $\\Gamma$.\n\nBy Kelvins circulation theorem, the circulation $\\Gamma_0$ around $C(t)$ is independent of time. Therefore, there must be negative $\\Gamma_1$ around the aerofoil, which leads to lift by the Kutta-Joukowski theorem ($L' = \\rho u\\Gamma$).\n\n### 5.3 Helmholtz Theorems\n\nSuppose we have an **inviscid**, **incompressible** fluid of **constant density** moving under a **conservative body force**, then\n\n1. The quantity\n   $$\n   \\Gamma=\\int_{S} \\boldsymbol{\\xi} \\cdot \\boldsymbol{n} d S\n   $$\n   is the same for all cross-sections $S$ of a vortex tube. i.e. the strength of a vortex is constant along the length of the vortex.\n\n2. A vortex filament cannot end in the fluid; it must extend to the boundaries of the fluid, infinity, or form a closed loop\n\n3. If fluid is initially irrotational, in the absense of rotational forces, it remains irrotational indefinitely.\n\n#### 5.3.1 Vortex rings\n\nA vivid example of Helmholtzs theorems can be seen in vortex (smoke) rings. These are vortices in which the core vortex line forms a closed loop (theorem #2).\n\nSuch vortices can retain their strength (theorem #1) and travel significant distances (the smoke is carried in the vortex).\n\n","source":"_posts/Derivation-of-Differential-Fluid-Equations.md","raw":"---\ntitle: Derivation of Differential Fluid Equations\nauthor: Ryan LI\ntoc: true\ndeclare: true\nindex_img: /index/deriving_NS_again.png\ntags:\n  - fluid dynamics\ndate: 2022-05-14 16:54:02\n---\n\n{% note primary %}\n\nFeeling unsafe when deploying CFD algorithms, the best way to alleviate the anxiety is to derive the fundamentals again.\n\n{% endnote%}\n\n<!-- more -->\n\n## 1 Acceleration and Mass Conservation\n\n### 1.1 Acceleration field of a fluid\n\n#### 1.1.1 Material / substantial / convective derivatives\n\n<img src=\"Material derivatives.png\" alt=\"Material derivatives\" style=\"zoom:50%;\" />\n\nGiven a spatial-temporal property $f(x,y,z,t)$ of a fluid particle in the Eulerian coordinate. After an infinitesimal period, the change in $f$ , is therefore:\n$$\n\\begin{aligned}\n\\Delta f = f(x+\\Delta x,y+\\delta x,z+\\delta z,t+\\Delta t)- f(x,y,z,t) \n\\end{aligned}\n$$\nset the position and time change tend to 0, \n$$\n\\Delta f = \\frac{\\partial f}{\\partial x}\\Delta x+\\frac{\\partial f}{\\partial y}\\Delta y+\\frac{\\partial f}{\\partial z}\\Delta z+\\frac{\\partial f}{\\partial t}\\Delta t\n$$\nconsidering:\n$$\n\\Delta x = u \\Delta t, \\Delta y = v \\Delta t, \\Delta z = w \\Delta t\n$$\nthen \n$$\n\\frac{\\Delta f }{\\Delta t}=\\frac{\\partial f}{\\partial t} + \\frac{\\partial f}{\\partial x}u+\\frac{\\partial f}{\\partial y}v+\\frac{\\partial f}{\\partial z}w\n$$\nIn the limit as $\\Delta t \\rightarrow 0$, \n$$\n\\frac{D f }{D t}=\\frac{\\partial f}{\\partial t} + \\frac{\\partial f}{\\partial x}u+\\frac{\\partial f}{\\partial y}v+\\frac{\\partial f}{\\partial z}w\n$$\nor in a vector form:\n$$\n\\color{purple}\n\\frac{D f }{D t}=\\frac{\\partial f}{\\partial t} + \\mathbf{V} \\cdot \\boldsymbol{\\nabla} f\n$$\nIn the scalar case $\\boldsymbol{\\nabla} f$ is simply the gradient of a scalar, while in the vector case,  $\\boldsymbol{\\nabla} \\mathbf{f}$ is the covariant derivative of the vector.\n\n{% note info %}\n\nLike the Reynolds Transport Theorem in the integral part, the material derivative connects the Lagrangian and Eulerian frame of references.\n\n{% endnote %}\n\n#### 1.1.2 Material derivative of velocity\n\nSet $f$ as $\\mathbf{V}$ and the fluid acceleration as $\\mathbf{a}$, substitute to the formula above:\n$$\n\\mathbf{a} = \\frac{D \\mathbf{V} }{D t}=\\underbrace{\\frac{\\partial \\mathbf{V}}{\\partial t}}_{\\text {local}} + \\underbrace{\\mathbf{V} \\cdot \\boldsymbol{\\nabla} \\mathbf{V}}_{\\text {convective}}\n$$\nwhere $\\frac{\\partial \\mathbf{V}}{\\partial t}$  is called **local acceleration** while $(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}$ is the **convective acceleration**.\n\n{% note info %}\n\nIt is also written as $\\mathbf{a} = \\frac{D \\mathbf{V} }{D t}=\\frac{\\partial \\mathbf{V}}{\\partial t} + (\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}$, but it's equivalent. \n\n{% endnote %}\n\n### 1.2 Differential equation of mass conservation\n\nTake an infinitesimally small cubic control volume as below.\n\n<img src=\"Differential mass conservation.png\" alt=\"Differential mass conservation\" style=\"zoom:50%;\" />\n\nWith the integral form with one-dimensional assumption: \n$$\n\\int_{C V} \\frac{\\partial \\rho}{\\partial t} d \\mathcal{V}+\\sum_{i}\\left(\\rho_{i} A_{i} V_{i}\\right)_{o u t}-\\sum_{i}\\left(\\rho_{i} A_{i} V_{i}\\right)_{i n}=0\n$$\n\n1. Density can be considered uniform in the CV,\n   $$\n   \\int_{C V} \\frac{\\partial \\rho}{\\partial t} d \\mathcal{V} = \\frac{\\partial \\rho}{\\partial t} dxdydz\n   $$\n\n2. Inlet mass flow in 3 directions\n   $$\n   \\dot{m}_{x} = \\rho udydz, \\dot{m}_{y} = \\rho vdxdz, \\dot{m}_{z} = \\rho udxdy\n   $$\n   \n3. Outlet mass flow in x direction particular\n   $$\n   \\dot{m}_{x+dx} = \\left(\\rho u+\\frac{\\partial \\rho u}{\\partial x }dx\\right)dydz\n   $$\n\n4. Substitute all in the continuous function\n   $$\n   \\frac{\\partial \\rho}{\\partial t} dxdydz +\\frac{\\partial \\rho u}{\\partial x}dxdydz +\\frac{\\partial \\rho v}{\\partial y}dxdydz +\\frac{\\partial \\rho w}{\\partial z}dxdydz  = 0\n   $$\n   simplify:\n   $$\n   \\frac{\\partial \\rho}{\\partial t}  +\\frac{\\partial \\rho u}{\\partial x} +\\frac{\\partial \\rho v}{\\partial y} +\\frac{\\partial \\rho w}{\\partial z}  = 0\n   $$\n   or in the vector form:\n   $$\n   \\color{purple}\n   \\frac{\\partial \\rho}{\\partial t}+\\boldsymbol{\\nabla} \\cdot(\\rho\\mathbf{V})=0\n   $$\n    {% note info %}\n\n   The only requirements of this equation are the density $\\rho$ and velocity $\\mathbf{V}$ are continuous in time and space. As a result, this equation is always called the *equation of continuity*.\n\n   {% endnote %}\n\n#### 1.2.1 Simplifications\n\n- steady flow: $\\partial/\\partial t = 0$, \n  $$\n  \\boldsymbol{\\nabla} \\cdot(\\rho\\mathbf{V})=0\n  $$\n\n- Incompressible flow: $\\rho = Const$ spacial and temporal:\n\n$$\n\\boldsymbol{\\nabla} \\cdot\\mathbf{V}=0\n$$\n\n{% note info %}\n\nIt makes the equation linear and much more tractable to solving analytically.\n\n{% endnote %}\n\n### 1.3 Cylindrical coordinates\n\n<img src=\"Polar coordinate.png\" alt=\"Polar coordinate\" style=\"zoom:50%;\" />\n\n#### 1.3.1 Transformation of coordinates\n\nFrom cartesian to cylindrical:\n$$\nr=\\sqrt{x^{2}+y^{2}} \\quad \\theta=\\tan ^{-1} \\frac{y}{x} \\quad z=z\n$$\n\nFrom cylindrical to cartesian:\n$$\nx=r \\cos \\theta \\quad y=r \\sin \\theta \\quad z=z\n$$\n\n#### 1.3.2 Differential operators\n\nTwo differential operators in polar coordinate:\n$$\n\\begin{aligned}\n\\boldsymbol{\\nabla} f &=\\frac{\\partial f}{\\partial r} \\hat{\\boldsymbol{r}}+\\frac{1}{r} \\frac{\\partial f}{\\partial \\theta} \\hat{\\boldsymbol{\\theta}}+\\frac{\\partial f}{\\partial z} \\hat{\\boldsymbol{z}}\\\\\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} &=\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r V_{r}\\right)+\\frac{1}{r} \\frac{\\partial}{\\partial \\theta}\\left(V_{\\theta}\\right)+\\frac{\\partial}{\\partial z}\\left(V_{z}\\right)\n\\end{aligned}\n$$\n\n#### 6.3.3 Continuous function in cylindrical coordinates\n\nIt is easy to substitute the equation of divergence into the continuous function,\n$$\n\\frac{\\partial \\rho}{\\partial t}+\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\rho V_{r}\\right)+\\frac{1}{r} \\frac{\\partial}{\\partial \\theta}\\left(\\rho V_{\\theta}\\right)+\\frac{\\partial}{\\partial z}\\left(\\rho V_{z}\\right)=0\n$$\n\n## 2 Linear Momentum and Energy\n\n### 2.1 Conservation laws from differential Reynolds transport theorem\n\nRecall RTT on a fixed control volume $\\Omega$:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(B_{s}\\right)=\\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}+\\int_{\\partial \\Omega} \\beta \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n$$\nwhere \n$$\n\\beta=\\frac{\\partial B}{\\partial m} \\quad \\Rightarrow \\quad B=\\int_{\\bar{\\Omega}} \\beta \\rho d \\mathcal{V}\n$$\n$\\bar{\\Omega}$ denotes the control volume in a Lagrangian frame of reference (close system), while $\\Omega$ denotes the control volume in an Eulerian frame of reference (open system).\n\n{% note info %}\n\nOpen system: matter and energy goes in and out\n\nClose system: energy goes in and out while matter cannot\n\nIsolated system: matter and energy cannot go in and out\n\n{% endnote %}\n\nIn the Lagrangian frame of reference,\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d} t}(B)=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{\\bar{\\Omega}} \\beta \\rho d \\mathcal{V}\\right)\\underbrace{=}_{Leibniz's Rule}\\int_{\\bar{\\Omega}} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}=\\int_{\\bar{\\Omega}} s d \\mathcal{V}\n$$\n{% note info %}\n\nLeibniz's rule: the derivative moves into the integral symbol: \n$$\n\\frac{d}{d x}\\left(\\int_{a}^{b} f(x, t) d t\\right)=\\int_{a}^{b} \\frac{\\partial}{\\partial x} f(x, t) d t\n$$\n{% endnote %}\n\nWhere $s$ denotes the \"rate of change of $B$ per unit volume\"\n\nThen the RTT is instead:\n$$\n\\int_{\\bar{\\Omega}} s d \\mathcal{V} = \\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}+\\int_{\\partial \\Omega} \\beta \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n$$\nUse divergence theorem, drop the bar notation with $\\Delta t \\rightarrow 0$, and arrive a differential form:\n$$\n\\begin{array}{r}\n\\int_{\\Omega} s d \\mathcal{V}=\\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}+\\int_{\\Omega} \\boldsymbol{\\nabla}  \\cdot(\\beta \\rho \\mathbf{V}) d \\mathcal{V} \\\\\n\\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\beta \\rho \\mathbf{V})-s d \\mathcal{V}=0 \\\\\n\\Leftrightarrow \\color{purple}{\\frac{\\partial(\\beta \\rho)}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\beta \\rho \\mathbf{V})-s=0}\n\\end{array}\n$$\n{% note info %}\n\nDivergence theorem: \n$$\n\\int_{S} \\boldsymbol{\\nabla}  \\cdot \\mathbf{F} d A=\\int_{\\partial S} \\mathbf{F} \\cdot \\hat{\\mathbf{n}} d s\n$$\n{% endnote %}\n\n#### 2.1.1 Continuity equation for mass\n\nSubstitute $\\beta = 1$ and $s=0$ (mass created = 0) into the differential RTT:\n$$\n\\frac{\\partial(\\rho)}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V})=0\n$$\nand for incompressible flow:\n$$\n\\boldsymbol{\\nabla}  \\cdot \\mathbf{V}=0\n$$\n\n#### 2.1.2 Continuity equation for linear momentum\n\nSubstitute $\\beta =\\mathbf{V}$ into the differential RTT:\n$$\n\\frac{\\partial(\\rho \\mathbf{V})}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V}\\otimes \\mathbf{V}) -\\mathbf{s} =0\n$$\n $\\mathbf{s}$ denotes the force per unit volume, and $\\otimes $ denotes the outer product.\n\n{% note info %}\n\nOuter product or dyadic product follows:\n$$\n\\left[\\begin{array}{c}\nu_{1} \\\\\nu_{2} \\\\\n\\vdots \\\\\nu_{m}\n\\end{array}\\right]\n \\otimes \n\\left[\\begin{array}{c}\nv_{1} \\\\\nv_{2} \\\\\n\\vdots \\\\\nv_{n}\n\\end{array}\\right]=\n\\left[\\begin{array}{cccc}\nu_{1} v_{1} & u_{1} v_{2} & \\ldots & u_{1} v_{n} \\\\\nu_{2} v_{1} & u_{2} v_{2} & \\ldots & u_{2} v_{n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nu_{m} v_{1} & u_{m} v_{2} & \\ldots & u_{m} v_{n}\n\\end{array}\\right]\n$$\nThe divergence of a dyad follows this formula:\n$$\n\\begin{aligned}\n&\\boldsymbol{\\nabla}  \\cdot(f \\mathbf{a})=(\\boldsymbol{\\nabla}  f) \\cdot \\mathbf{a}+(\\boldsymbol{\\nabla}  \\cdot \\mathbf{a}) f \\\\\n&\\boldsymbol{\\nabla}  \\cdot(\\mathbf{a b})=(\\boldsymbol{\\nabla}  \\cdot \\mathbf{a}) \\mathbf{b}+\\mathbf{a} \\cdot \\boldsymbol{\\nabla}  \\mathbf{b}\n\\end{aligned}\n$$\n{% endnote %}\n\nExpand the equation:\n$$\n\\begin{aligned}\n\\rho \\frac{\\partial \\mathbf{V}}{\\partial t}+\\mathbf{V} \\frac{\\partial \\rho}{\\partial t}+\\mathbf{V V} \\cdot \\boldsymbol{\\nabla}  \\rho+\\rho \\mathbf{V} \\cdot \\boldsymbol{\\nabla}  \\mathbf{V}+\\rho \\mathbf{V} \\boldsymbol{\\nabla}  \\cdot \\mathbf{V} &=\\mathbf{s} \\\\\n\\Leftrightarrow \\mathbf{V}\\left(\\frac{\\partial \\rho}{\\partial t}+\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  \\rho+\\rho(\\boldsymbol{\\nabla}  \\cdot \\mathbf{V})\\right)+\\rho\\left(\\frac{\\partial \\mathbf{V}}{\\partial t}+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla} ) \\mathbf{V}\\right) &=\\mathbf{s}\n\\end{aligned}\n$$\nWith $\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  \\rho+\\rho(\\boldsymbol{\\nabla}  \\cdot \\mathbf{V})=\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V})$, we have the first left term a continuity equation. Drop it we have:\n$$\n\\mathbf{V}\\underbrace{\\left(\\frac{\\partial \\rho}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V})\\right)}_{0}+\n\\rho\\underbrace{\\left(\\frac{\\partial \\mathbf{V}}{\\partial t}+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla} ) \\mathbf{V}\\right)}_{\\mathrm{material~derivative}} =\\mathbf{s}\n$$\nWith the definition of material derivative,\n$$\n\\color{purple}\n\\rho\\left(\\frac{D \\mathbf{V}}{D t}\\right) =\\mathbf{s}\n$$\nWithout source or sink, the quantity $\\mathbf{s}$ therefore represents **force per unit volume** $\\mathbf{s}=\\frac{\\mathrm{d} \\mathbf{F}}{\\mathrm{d} \\mathcal{V}}$.\n\n### 2.2 Forces\n\nThe forces contain *body forces* and *surface forces* $\\mathbf{F}=\\mathbf{F_b}+\\mathbf{F_s}$,\n\n- Body forces are due to external fields, take gravitational force as an example,\n  $$\n  d \\mathbf{F}_{g}=\\rho \\mathbf{g} d x d y d z \\quad \\mathbf{g}=-g \\mathbf{k}\n  $$\n  Consider the only body force in fluid dynamic is the gravity:\n  $$\n  \\color{purple}\n  \\frac{\\mathrm{d}\\mathbf{F_b}}{\\mathrm{d}\\mathcal{V}} = \\rho\\mathbf{g}\n  $$\n\n- Surface forces are due to hydrostatic pressure and viscous stresses on the *CS*:\n  $$\n  \\sigma_{i j}=\\left|\\begin{array}{ccc}\n  -p+\\tau_{x x} & \\tau_{y x} & \\tau_{z x} \\\\\n  \\tau_{x y} & -p+\\tau_{yy} & \\tau_{z y} \\\\\n  \\tau_{x z} & \\tau_{y z} & -p+\\tau_{z z}\n  \\end{array}\\right|\n  $$\n  <img src=\"Viscous stress on CS.png\" alt=\"Stress on CS\" style=\"zoom:50%;\" />\n\n  Similar to what we do in the [Mass Conservation](#differential-equation-of-mass-conservation), the force is due to the stress change in each direction, for instance:\n  $$\n  dF{s,xx} = \\left(\\sigma_{xx}+\\frac{\\partial\\sigma_{xx}}{\\partial x}dx\\right)dydz-\\sigma_{xx}dydz = \\frac{\\partial\\sigma_{xx}}{\\partial x}d\\mathcal{V}\n  $$\n  <img src=\"Surface forces on CS.png\" alt=\"Surface forces on CS\" style=\"zoom:50%;\" />\n\n  as a result:\n  $$\n  \\begin{aligned}\n  &\\frac{\\mathrm{d} F_{x}}{\\mathrm{~d} \\mathcal{V}}=-\\frac{\\partial p}{\\partial x}+\\frac{\\partial \\tau_{x x}}{\\partial x}+\\frac{\\partial \\tau_{y x}}{\\partial y}+\\frac{\\partial \\tau_{z x}}{\\partial z} \\\\\n  &\\frac{\\mathrm{d} F_{y}}{\\mathrm{~d} \\mathcal{V}}=-\\frac{\\partial p}{\\partial y}+\\frac{\\partial \\tau_{x y}}{\\partial x}+\\frac{\\partial \\tau_{y y}}{\\partial y}+\\frac{\\partial \\tau_{z y}}{\\partial z} \\\\\n  &\\frac{\\mathrm{d} F_{z}}{\\mathrm{~d} \\mathcal{V}}=-\\frac{\\partial p}{\\partial z}+\\frac{\\partial \\tau_{x z}}{\\partial x}+\\frac{\\partial \\tau_{y z}}{\\partial y}+\\frac{\\partial \\tau_{z z}}{\\partial z}\n  \\end{aligned}\n  $$\n  surface force in vector form:\n  $$\n  \\color{purple}\n  \\frac{\\mathrm{d} \\mathbf{F_s}}{\\mathrm{d} \\mathcal{V}}=- \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}}\n  $$\n  $\\frac{\\mathrm{d} \\mathbf{F_s}}{\\mathrm{d} \\mathcal{V}}$ also represents the Cauchy stress tensor:\n\n### 2.3 General differential linear momentum equation\n\nSubstitute force terms into earlier momentum conservation expression,\n$$\n\\color{purple}\n\\rho\\frac{D \\mathbf{V}}{D t} = \\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\mathbf{\\tau_{ij}}\n$$\n\n$$\n\\mathrm{density  acceleration = (Gravity + Pressure + Viscous) ~forces~per~unit~volume}\n$$\n\nThese equations are valid for any fluid in general motion, particularly those which include viscous stresses. The non-linear convective terms on the left-hand side also complicates direct mathematical analysis.\n\n### 2.4 Differential energy equations\n\nSimilar to earlier routes, we arrive energy conservation equation:\n$$\n\\dot{Q}-\\dot{W}_{v}=\\left(\\rho \\frac{D e}{D t}+\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  p+p \\boldsymbol{\\nabla}  \\cdot \\mathbf{V}\\right) \\mathrm{d}\\mathcal{V}\n$$\nNote that $\\dot{W}_{s} = 0$ since there is no shaft work in an infinitesimal CV, as a result, similar CV flux analysis can be done to $\\dot{Q}$ and $\\dot{W}_{v}$:\n\n- Heat conduction $\\dot{Q}$ is regulated by **Fourier's law** stating that the heat flux is proportional to the gradient of the temperature, $\\mathbf{q} = K\\boldsymbol{\\nabla}T$, using similar flux analysis to infinitesimal CV\n  $$\n  \\dot{Q}=\\boldsymbol{\\nabla}  \\cdot(k \\boldsymbol{\\nabla}   T)\\mathrm{d}\\mathcal{V}\n  $$\n\n- Similarly, the rate of work due to viscous stresses can be expanded to give:\n  $$\n  \\dot{W}_{v}=-\\boldsymbol{\\nabla} \\cdot\\left(\\mathbf{V} \\cdot \\boldsymbol{\\tau}_{i j}\\right)\\mathrm{d}\\mathcal{V}\n  $$\n\nSubstitute into energy conservation equation to give:\n$$\n\\rho \\frac{D e}{D t}+\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  p+p \\boldsymbol{\\nabla}  \\cdot \\mathbf{V}\n=\n\\boldsymbol{\\nabla}  \\cdot(k \\boldsymbol{\\nabla}   T)\n+\\boldsymbol{\\nabla} \\cdot\\left(\\mathbf{V} \\cdot \\boldsymbol{\\tau}_{i j}\\right)\n$$\n\n#### 2.4.1 General energy equation\n\nSplitting the viscous work term:\n$$\n\\boldsymbol{\\nabla} \\cdot\\left(\\mathbf{V} \\cdot \\boldsymbol{\\tau}_{i j}\\right) \\equiv \\mathbf{V} \\cdot \\left( \\boldsymbol{\\nabla} \\cdot \\boldsymbol{\\tau_{ij}} \\right) + \\underbrace{\\boldsymbol{\\tau_{ij}} : \\left( \\boldsymbol{\\nabla}\\mathbf{V} \\right)}_{\\boldsymbol{\\Phi}}\n$$\nwhere $\\boldsymbol{\\Phi}$ denotes the **viscous-dissipation function**, representing the dissipation of energy due to viscous effects. For **Newtonian flow in a Cartesian coordinates**: \n$$\n\\boldsymbol{\\Phi}=\\mu\\left[2\\left(\\frac{\\partial u}{\\partial x}\\right)^{2}+2\\left(\\frac{\\partial v}{\\partial y}\\right)^{2}+2\\left(\\frac{\\partial w}{\\partial z}\\right)^{2}+\\left(\\frac{\\partial v}{\\partial x}+\\frac{\\partial u}{\\partial y}\\right)^{2}+\\left(\\frac{\\partial w}{\\partial y}+\\frac{\\partial v}{\\partial z}\\right)^{2}+\\left(\\frac{\\partial u}{\\partial z}+\\frac{\\partial w}{\\partial x}\\right)^{2}\\right]\n$$\n{%  note info %}\n\nDissipated energy means during the flow, it is converted into the internal energy of the material. Note $\\boldsymbol{\\Phi}$ is always positive, implying that viscous flow always loses energy.\n\n{% endnote %}\n\nExpanding $e = \\hat{u}+\\frac{1}{2}V^{2}+gz$, the general differential energy equation is :\n$$\n\\color{purple}\n\\rho \\frac{D \\hat{u}}{D t}+p(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})=\\boldsymbol{\\nabla} \\cdot(k \\boldsymbol{\\nabla} T)+\\mathbf{\\Phi}\n$$\nwith further assumptions:\n$$\n\\begin{aligned}\nd \\hat{u} & \\approx c_{v} d T \\\\\nc_{v}, \\mu, k, \\rho & \\approx \\mathrm{const}\n\\end{aligned}\n$$\nfor incompressible flow, we have:\n$$\n\\color{purple}{\\rho c_{v} \\frac{\\partial T}{\\partial t} =\\cdot(k \\boldsymbol{\\nabla}^2 T)+\\mathbf{\\Phi}}\n$$\n\n## 3 Euler and Navier-Stokes Equations\n\nRecall [differential linear momentum equation](#general-differential-linear-momentum-equation):\n$$\n\\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}} = \\rho\\frac{D \\mathbf{V}}{D t}\n$$\nEquations of motion of $\\boldsymbol{\\tau_{ij}}$ is still needed, and its different depending on types of fluid\n\n### 3.1 Euler equations (frictionless flow)\n\nUse the inviscid flow assumption, that is $\\boldsymbol{\\tau_{ij}}=0$, the momentum equation reduces to:\n$$\n\\color{purple}\n\\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}} = \\rho\\frac{D \\mathbf{V}}{D t}\n$$\n{% note info %}\n\nFluids with low viscosity can be reasonably modelled as inviscid, except near boundaries.\n\n{% endnote %}\n\n### 3.2 Newtonian fluid\n\n#### 3.2.1 Strain\n\nStrains of a fluid particle evaluate the deformation due to an applied *shear stress*.\n\n<img src=\"Fluid partical deformation.png\" alt=\"Fluid partical deformation\" style=\"zoom:50%;\" />\n\nand strain is defined as (anticlockwise positive):\n$$\n\\mathrm{strain_{xy}} = \\Delta\\theta_x-(-\\Delta\\theta_y)\n$$\nIn a continuous system, the rate of strain is then:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}(\\mathrm{strain_{xy}}) = \\epsilon_{xy} = \\frac{\\partial v}{\\partial x} + \\frac{\\partial u}{\\partial y}\n$$\nor in vector form:\n$$\n\\boldsymbol{\\epsilon} = \\nabla \\mathbf{V}+(\\nabla \\mathbf{V}^{\\top})\n$$\n\n#### 3.2.2 Viscosity\n\nNewton defined a **newtonian fluid** by a fluid in which the *viscous stresses* are linearly proportional to the local *strain rates*.\n$$\n\\boldsymbol{\\tau_{ij}} \\propto \\boldsymbol{\\epsilon_{ij}}\n$$\nIn order to apply this to the NaiverStokes equations, three assumptions were made by Stokes:\n\n- The stress tensor is a linear function of the strain rate tensor or equivalently the velocity gradient.\n- The fluid is isotropic.\n- For a fluid at rest,  $\\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}} = 0$  (so that hydrostatic pressure results).\n\nAnd it leads to:\n$$\n\\color{purple}\n\\boldsymbol{\\tau}=\\mu\\left(\\nabla \\mathbf{u}+\\nabla \\mathbf{u}^{\\top}\\right)+\\lambda(\\nabla \\cdot \\mathbf{u}) \\mathbf{I}\n$$\nor\n$$\n\\boldsymbol{\\tau_{ij}}=\\mu\\left(\\frac{\\partial u_{i}}{\\partial x_{j}}+\\frac{\\partial u_{j}}{\\partial x_{i}}\\right)+\\delta_{i j} \\lambda \\frac{\\partial u_{k}}{\\partial x_{k}} \\\\\n$$\nwhere,\n$$\n\\delta_{i j}= \\begin{cases}0 & \\text { if } i \\neq j \\\\ 1 & \\text { if } i=j\\end{cases}\n$$\nAs a result, expand the formula:\n$$\n\\boldsymbol{\\tau_{ij}}=\\left|\\begin{array}{ccc}\n2 \\mu \\frac{\\partial u}{\\partial x}+\\lambda \\frac{\\partial u_{}}{\\partial x_{k}} & \\mu\\left(\\frac{\\partial u}{\\partial y}+\\frac{\\partial v}{\\partial x}\\right) & \\mu\\left(\\frac{\\partial u}{\\partial z}+\\frac{\\partial w}{\\partial x}\\right) \\\\\n\\mu\\left(\\frac{\\partial v}{\\partial x}+\\frac{\\partial u}{\\partial y}\\right) & 2 \\mu \\frac{\\partial v}{\\partial y}+\\lambda \\frac{\\partial v}{\\partial y} & \\mu\\left(\\frac{\\partial v}{\\partial z}+\\frac{\\partial w}{\\partial y}\\right) \\\\\n\\mu\\left(\\frac{\\partial w}{\\partial x}+\\frac{\\partial u}{\\partial z}\\right) & \\mu\\left(\\frac{\\partial w}{\\partial y}+\\frac{\\partial v}{\\partial z}\\right) & 2 \\mu \\frac{\\partial w}{\\partial z}+\\lambda \\frac{\\partial w}{\\partial z}\n\\end{array}\\right|\n$$\nAnd $\\mu$ and $\\lambda$ represents the **shear/dynamic viscosity** and **volume/bulk viscosity** respectively,\n\n>The value of **, which produces a viscous effect associated with volume change, is very difficult to determine, not even its sign is known with absolute certainty. Even in compressible flows, the term involving ** is often negligible; however it can occasionally be important even in nearly incompressible flows and is a matter of controversy. When taken nonzero, the most common approximation is ****  2/3****.\n\n### 3.3 Navier-Stokes equations\n\nSubstitute the stress representation into the linear momentum equation:\n$$\n\\rho\\frac{D \\mathbf{V}}{D t} = \\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot \\mu\\left( \\left(\\boldsymbol{\\nabla} \\mathbf{V}+\\boldsymbol{\\nabla} \\mathbf{V}^{\\top}\\right)-\\frac{2}{3}(\\nabla \\cdot \\mathbf{V}) \\mathbf{I}\\right)\n$$\nwith further simplification we have:\n$$\n\\color{purple}\n\\rho \\frac{\\mathrm{D} \\mathbf{V}}{\\mathrm{D} t}=\\rho\\left(\\frac{\\partial \\mathbf{V}}{\\partial t}+\\mathbf{V} \\cdot \\nabla \\mathbf{V}\\right)=-\\nabla p+\\mu \\nabla^{2} \\mathbf{V}+\\frac{1}{3} \\mu \\nabla(\\nabla \\cdot \\mathbf{V})+\\rho \\mathbf{g}\n$$\n\n#### 3.3.1 Incompressible Navier-Stokes equations\n\nWith incompressible flow we have no bulk viscosity so:\n$$\n\\boldsymbol{\\tau}=\\mu\\left(\\nabla \\mathbf{u}+\\nabla \\mathbf{u}^{\\top}\\right)\n$$\nAnd the Incompressible Navier-Stokes equations is therefore:\n$$\n\\rho\\frac{D \\mathbf{V}}{D t} = \\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot \\mu\\left( \\boldsymbol{\\nabla} \\mathbf{V}+\\boldsymbol{\\nabla} \\mathbf{V}^{\\top}\\right)\n$$\nwith  $\\boldsymbol{\\nabla} \\cdot \\mathbf{V}=0$ for incompressible flow:\n$$\n\\boldsymbol{\\nabla} \\cdot \\mu\\left( \\boldsymbol{\\nabla} \\mathbf{V}+\\boldsymbol{\\nabla} \\mathbf{V}^{\\top}\\right) = \\mu\\boldsymbol{\\nabla}^2\\mathbf{V}\n$$\nas a result:\n$$\n\\color{purple}\n\\frac{\\partial\\mathbf{V}}{\\partial t} +  \\mathbf{V} \\cdot \\nabla \\mathbf{V}= \\mathbf{g} - \\boldsymbol{\\nabla}\\frac{p}{\\rho} +  \\nu\\boldsymbol{\\nabla}^2\\mathbf{V}\n$$\nwhere $\\nu = \\frac{\\mu}{\\rho}$, called **kinetic viscosity**\n\n{% note info %}\n\nMeaning of each term:\n$$\n\\overbrace{\\underbrace{\\frac{\\partial \\mathbf{V}}{\\partial t}}_{\\text {Variation }}+\\underbrace{(\\mathbf{V} \\cdot \\nabla) \\mathbf{V}}_{\\text {Convection }}}^{\\text {Inertia (per volume) }}= \\overbrace{\\underbrace{\\nu \\nabla^{2} \\mathbf{V}}_{\\text {Diffusion }}\\underbrace{-\\nabla w}_{\\begin{array}{c}\n\\text { Internal } \\\\\n\\text { source }\n\\end{array}}}^{\\text {Divergence of stress }}+\\underbrace{\\mathbf{g}}_{\\begin{array}{c}\n\\text { External } \\\\\n\\text { source }\n\\end{array}} .\n$$\n{% endnote %}\n\nExpanding along every coordinates gives that:\n$$\n\\begin{align}\n\\frac{\\partial u}{\\partial t} +  u \\frac{\\partial u}{\\partial x} + v\\frac{\\partial u}{\\partial y} + w \\frac{\\partial u}{\\partial z}&= g_x - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial x} +  \\nu\\left(\\frac{\\partial^2u}{\\partial^2x}+\\frac{\\partial^2u}{\\partial^2y}+\\frac{\\partial^2u}{\\partial^2z}\\right) \\\\\n\\frac{\\partial v}{\\partial t} +  u \\frac{\\partial v}{\\partial x} + v\\frac{\\partial v}{\\partial y} + w \\frac{\\partial v}{\\partial z}&= g_y - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial y} +  \\nu\\left(\\frac{\\partial^2v}{\\partial^2x}+\\frac{\\partial^2v}{\\partial^2y}+\\frac{\\partial^2v}{\\partial^2z}\\right) \\\\\n\\frac{\\partial w}{\\partial t} +  u \\frac{\\partial w}{\\partial x} + v\\frac{\\partial w}{\\partial y} + w \\frac{\\partial w}{\\partial z}&= g_z - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial z} +  \\nu\\left(\\frac{\\partial^2w}{\\partial^2x}+\\frac{\\partial^2w}{\\partial^2y}+\\frac{\\partial^2w}{\\partial^2z}\\right)\n\\end{align}\n$$\n\n#### 3.3.2 Cylindrical coordinates\n\nRecall the coordinates transformation:\n$$\nr=\\sqrt{x^{2}+y^{2}} \\quad \\theta=\\tan ^{-1} \\frac{y}{x} \\quad z=z\n$$\nand the differential operators:\n$$\n\\begin{aligned}\n\\boldsymbol{\\nabla} f &=\\frac{\\partial f}{\\partial r} \\hat{\\boldsymbol{r}}+\\frac{1}{r} \\frac{\\partial f}{\\partial \\theta} \\hat{\\boldsymbol{\\theta}}+\\frac{\\partial f}{\\partial z} \\hat{\\boldsymbol{z}}\\\\\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} &=\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r V_{r}\\right)+\\frac{1}{r} \\frac{\\partial}{\\partial \\theta}\\left(V_{\\theta}\\right)+\\frac{\\partial}{\\partial z}\\left(V_{z}\\right)\\\\\n\\boldsymbol{\\nabla}^2f &= \\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial f}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} f}{\\partial \\theta^{2}}+\\frac{\\partial^{2} f}{\\partial z^{2}}\\right)\n\\end{aligned}\n$$\nAnd in z direction\n$$\n\\begin{align}\n\\frac{\\partial V_r}{\\partial t} +  V_r \\frac{\\partial V_r}{\\partial r} + V_\\theta\\frac{1}{r}\\frac{\\partial V_r}{\\partial \\theta} + V_z \\frac{\\partial V_r}{\\partial z}&= g_r - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial r} +  \\nu\\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial V_{r}}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} V_{r}}{\\partial \\theta^{2}}+\\frac{\\partial^{2} V_{r}}{\\partial z^{2}}\\right) \\\\\n\\frac{\\partial V_\\theta}{\\partial t} +  V_r \\frac{\\partial  V_\\theta}{\\partial r} + V_\\theta\\frac{1}{r}\\frac{\\partial  V_\\theta}{\\partial \\theta} + V_z \\frac{\\partial  V_\\theta}{\\partial z}&= g_\\theta - \\frac{1}{\\rho r}\\frac{\\partial p}{\\partial \\theta} +    \\nu\\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial V_{\\theta}}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} V_{\\theta}}{\\partial \\theta^{2}}+\\frac{\\partial^{2} V_{\\theta}}{\\partial z^{2}}\\right) \\\\\n\\frac{\\partial V_z}{\\partial t} +  V_r \\frac{\\partial V_r}{\\partial r} + V_\\theta\\frac{1}{r}\\frac{\\partial V_z}{\\partial \\theta} + V_z \\frac{\\partial V_z}{\\partial z}&= g_z - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial z} +  \\nu\\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial V_{z}}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} V_{z}}{\\partial \\theta^{2}}+\\frac{\\partial^{2} V_{z}}{\\partial z^{2}}\\right)\n\\end{align}\n$$\n\n### 3.3 Closing the system\n\nTo summarise, the 3 main functions are:\n$$\n\\begin{aligned} \\frac{\\partial \\rho}{\\partial t}+\\nabla \\cdot(\\rho\\mathbf{V}) &=0 & & \\text { continuity } \\\\ \\rho \\mathbf{g}-\\nabla p+\\boldsymbol{\\nabla} \\cdot \\boldsymbol{\\tau}_{i j} &=\\rho \\frac{D \\mathbf{V}}{D t} & & \\text { momentum } \\\\ \\rho \\frac{D \\hat{u}}{D t}=p(\\boldsymbol{\\nabla} \\cdot \\mathbf{V}) &=\\boldsymbol{\\nabla} \\cdot(k \\boldsymbol{\\nabla} T)+\\mathbf{\\Phi} & & \\text { energy } \\end{aligned}\n$$\nNote that there are five unknowns $\\rho,\\mathbf{V}, p, \\hat{u},T$, but only three equations. Additional equations are state relations for the thermodynamic properties of the fluid. For example for perfect gas:\n$$\n\\rho=\\frac{p}{R T} \\quad \\hat{u}=\\int c_{v} d T\n$$\nThe system of equations is now well-posed and can be solved, subject to *boundary conditions.*\n\n#### 3.3.1 Incompressible system\n\nWe have:\n$$\n\\begin{aligned}\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} &=0 \\\\\n\\rho \\frac{D \\mathbf{V}}{D t} &=\\rho \\boldsymbol{g}-\\nabla p+\\mu \\nabla^{2} \\mathbf{V} \\\\\n\\rho c_{p} \\frac{D T}{D t} &=k \\nabla^{2} T+\\mathbf{\\Phi}\n\\end{aligned}\n$$\nNote that for incompressible flow, $\\rho,\\mu,k$ are constants, only 3 unknowns are left $p, \\mathbf{V}, T$. So the incompressible system is already closed. Besides, continuity and momentum equations are independent of the $T$, thus decouple from the energy equation.\n\n### 3.4 Boundary conditions\n\n- Wall: these are typically solid, impermeable and there is a no-slip condition at the wall.\n- Inlet: known velocity $\\mathbf{V}$ and pressure $p$ (and temperature $T$)\n\n### 3.5 Stream function\n\nStream function provides a mathematical tool to automatically satisfy the continuity constraint, after which we can then solve the momentum equation.\n\n{% note info %}\n\nIt is only applicable to flows which are **steady**, **incompressible** and **two-dimensional**.\n\n{% endnote %}\n\nWith continuity equation:\n$$\n\\boldsymbol{\\nabla}\\cdot\\mathbf{V} = 0 \\Leftrightarrow \\frac{\\partial u }{\\partial x} + \\frac{\\partial v}{\\partial y} = 0\n$$\nWe seek to replace the velocity components $u$ and $v$ with a scalar function $\\psi(x,y)$, which satisfies the above constraint:\n$$\n\\frac{\\partial}{\\partial x}\\left(\\frac{\\partial \\psi}{\\partial y}\\right)  + \\frac{\\partial}{\\partial y}\\left(-\\frac{\\partial \\psi}{\\partial x}\\right) \\equiv 0\n$$\nAs a result:\n$$\nu=\\frac{\\partial \\psi}{\\partial y} \\qquad v=-\\frac{\\partial \\psi}{\\partial x}\n$$\n\n#### 3.5.1 Properties of stream function\n\n- Recall the definition of a streamline:\n\n$$\n\\begin{align}\n& \\frac{dy}{v} = \\frac{dx}{u} \\\\\n\\Leftrightarrow\\quad & \\frac{\\partial \\psi}{\\partial y}u+\\frac{\\partial \\psi}{\\partial x}v=0 \\\\\n\\Leftrightarrow\\quad & d\\psi=0 \\\\\n\\Leftrightarrow\\quad & \\psi=Const\n\\end{align}\n$$\n\n- The change of $\\psi$ across a control surface of unit depth is equal to the volume flow through the surface\n\n   <img src=\"Stream function property.png\" alt=\"Stream function property\" style=\"zoom:50%;\" />\n  $$\n  \\begin{aligned}\n  d Q &=(\\mathbf{V} \\cdot \\boldsymbol{n}) d A \\\\\n  &=\\left(\\boldsymbol{i} \\frac{\\partial \\psi}{\\partial y}-\\boldsymbol{j} \\frac{\\partial \\psi}{\\partial x}\\right) \\cdot\\left(\\boldsymbol{i} \\frac{\\mathrm{d} y}{\\mathrm{~d} s}-\\boldsymbol{j} \\frac{\\mathrm{d} x}{\\mathrm{~d} s}\\right) d s \\\\\n  &=\\frac{\\partial \\psi}{\\partial x} d x+\\frac{\\partial \\psi}{\\partial y} d y \\\\\n  &=d \\psi\n  \\end{aligned}\n  $$\n\n- The flow direction can be determined by observing whether $\\psi$ increases or decreases\n\n  <img src=\"Flow direction based on stream function.png\" alt=\"Flow direction based on stream function\" style=\"zoom:50%;\" />\n\n## 4 Vorticity and Irrotationality\n\n### 4.1 Vorticity\n\nRecall how a fluid particle deforms under shear stresses:\n\n<img src=\"Fluid particle deformation.png\" alt=\"Fluid particle deformation\" style=\"zoom:50%;\" />\n\nThe angular velocity $\\omega_z$ is defined as the average rate of counter-clockwise turning of the two sides:\n$$\n\\omega_z = \\frac{1}{2}\\left(\\frac{\\mathrm{d}(\\Delta\\theta_x)}{\\mathrm{d}t}+\\frac{\\mathrm{d}(\\Delta\\theta_y)}{\\mathrm{d}t}\\right) =\\frac{1}{2}\\left(\\frac{\\partial v}{\\partial x}-\\frac{\\partial u}{\\partial y}\\right)\n$$\nSimilarly, \n$$\n\\omega_{x}=\\frac{1}{2}\\left(\\frac{\\partial w}{\\partial y}-\\frac{\\partial v}{\\partial z}\\right) \\quad \\omega_{y}=\\frac{1}{2}\\left(\\frac{\\partial u}{\\partial z}-\\frac{\\partial w}{\\partial x}\\right)\n$$\nCombine together the angular velocity:\n$$\n\\boldsymbol{\\omega}=\\frac{1}{2}(\\underbrace{\\boldsymbol{\\nabla} \\times \\mathbf{V}}_{\\text {curl } \\mathbf{V}})=\\frac{1}{2}\\left|\\begin{array}{ccc}\n\\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\\n\\frac{\\partial}{\\partial x} & \\frac{\\partial}{\\partial y} & \\frac{\\partial}{\\partial z} \\\\\nu & v & w\n\\end{array}\\right|\n$$\nAnd the vorticity is defined as twice the angular velocity i.e. curl of velocity:\n$$\n\\boldsymbol{\\xi}=2 \\boldsymbol{\\omega}=\\operatorname{curl} \\mathbf{V}=\\boldsymbol{\\nabla} \\times \\mathbf{V}\n$$\n\n### 4.2 Vorticity function for two-dimensional incompressible flow\n\nFirst some math:\n$$\n\\begin{aligned}\n\\boldsymbol{\\nabla} \\times \\boldsymbol{\\nabla} \\phi & \\equiv 0 \\qquad\\qquad&(4.1) \\\\\n\\boldsymbol{\\nabla} \\times\\left(\\boldsymbol{\\nabla}^{2} \\mathbf{V}\\right) &=\\boldsymbol{\\nabla}^{2}(\\boldsymbol{\\nabla} \\times \\mathbf{V}) \\qquad\\qquad&(4.2) \\\\\n(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V} &=\\boldsymbol{\\nabla}\\left(\\frac{1}{2} \\mathbf{V} \\cdot \\mathbf{V}\\right)-\\mathbf{V} \\times \\boldsymbol{\\xi} \\qquad\\qquad&(4.3) \\\\\n\\boldsymbol{\\nabla} \\times(\\mathbf{V} \\times \\boldsymbol{\\xi}) &=-\\boldsymbol{\\xi}(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})+(\\boldsymbol{\\xi} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}-(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi} \\qquad\\qquad&(4.4) \n\\end{aligned}\n$$\nRecall the [incompressible momentum equation](#incompressible-navier-stokes-equations):\n$$\n\\frac{\\partial\\mathbf{V}}{\\partial t} + \\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V} = \\mathbf{g} -\\boldsymbol{\\nabla}\\left(\\frac{p}{\\rho}\\right) + \\nu\\boldsymbol{\\nabla}^2\\mathbf{V}\n$$\nTake the curl for each term:\n$$\n\\underbrace{\\boldsymbol{\\nabla} \\times\\frac{\\partial\\mathbf{V}}{\\partial t} }_{\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}}+ \\boldsymbol{\\nabla} \\times\n\\underbrace{\\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V}}_{\\boldsymbol{\\nabla}\\left(\\frac{1}{2} \\mathbf{V} \\cdot \\mathbf{V}\\right)-\\mathbf{V} \\times \\boldsymbol{\\xi},~\\mathrm{by}(4.3)} = \n\\underbrace{\\boldsymbol{\\nabla} \\times\\mathbf{g}}_{0} -\n\\underbrace{\\boldsymbol{\\nabla} \\times\\boldsymbol{\\nabla}\\left(\\frac{p}{\\rho}\\right)}_{0,~\\mathrm{by} (4.1)}+ \n\\nu\\underbrace{\\boldsymbol{\\nabla} \\times\\boldsymbol{\\nabla}^2\\mathbf{V}}_{\\boldsymbol{\\nabla}^{2}(\\boldsymbol{\\nabla} \\times \\mathbf{V}),~ \\mathrm{by} (4.2)}\n$$\nAs a result:\n$$\n\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}+ \\underbrace{\\boldsymbol{\\nabla} \\times\\boldsymbol{\\nabla}\\left(\\frac{1}{2} \\mathbf{V} \\cdot \\mathbf{V}\\right)}_{0,~\\mathrm{by} (4.1)}-\\boldsymbol{\\nabla} \\times\\mathbf{V} \\times \\boldsymbol{\\xi}= \\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\n$$\nApply $(4.4)$ cancel terms due to assumptions:\n$$\n\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}\n+\\underbrace{\\boldsymbol{\\xi}(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})}_{0,~\\mathrm{steady~incompressible}}\n-\\underbrace{(\\boldsymbol{\\xi} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}}_{0,~\\mathrm{2D~flow}}\n+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi}= \\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\n$$\nFinally, the vorticity function for 2D incompressible flow is:\n$$\n\\color{purple}\n\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}\n+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi}= \n\\frac{D\\boldsymbol{\\xi}}{D t}=\n\\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\n$$\n{% note info %}\n\nSome of the terms have specific physical interpretations:\n\n- $(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi}$ is *convection* \n- $(\\boldsymbol{\\xi} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}$ is *stretching* \n- $\\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}$ is *diffusion*\n\n{% endnote %}\n\n{% note info %}\n\nNote that there is no pressure term in the vorticity equation, implying that vorticity dynamics are localised in space.\n\n{% endnote %}\n\n#### 4.2.1 Combine with continuity equation\n\nRecall the definition of the [stream function](#stream-function) and take the curl:\n$$\n\\begin{aligned}\n\\mathbf{V} &= \\mathbf{i}\\frac{\\partial\\psi}{\\partial y}-\\mathbf{j}\\frac{\\partial\\psi}{\\partial x} \\\\\n\\boldsymbol{\\nabla}\\times\\mathbf{V} &= -\\mathbf{k}\\boldsymbol{\\nabla}^2\\psi = -\\mathbf{k}\\left( \\frac{\\partial^2\\psi}{\\partial x^2} + \\frac{\\partial^2\\psi}{\\partial y^2} \\right)\n\\end{aligned}\n$$\nSubstitute these into the vorticity equation, a 4th-order single equation in $\\psi$ arrived:\n$$\n\\color{purple}\n\\frac{\\partial \\psi}{\\partial y} \\frac{\\partial}{\\partial x}\\left(\\nabla^{2} \\psi\\right)-\\frac{\\partial \\psi}{\\partial x} \\frac{\\partial}{\\partial y}\\left(\\nabla^{2} \\psi\\right)=\\nu \\nabla^{2}\\left(\\nabla^{2} \\psi\\right)\n$$\n{% note info %}\n\nAssumptions made:\n\n- Steady flow\n- Incompressible\n- Two dimensional\n\n{% endnote %}\n\nOne important special case is when  \n$$\n\\boldsymbol{\\nabla}^2\\psi = \\frac{\\partial^2\\psi}{\\partial x^2} + \\frac{\\partial^2\\psi}{\\partial y^2} = 0\n$$\nThe flow is **irrotational**.\n\n### 4.3 Full Bernoulli equations\n\nWe now consider a flow which is **inviscid** (although may still be **compressible**).\n\nRecall [Euler's equation](#euler-equations-frictionless-flow):\n$$\n\\frac{\\partial\\mathbf{V}}{\\partial t} + \\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V} = \\mathbf{g} -\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)\n$$\nExpand the convection term by $(4.3)$:\n$$\n\\frac{\\partial\\mathbf{V}}{\\partial t} + \\boldsymbol{\\nabla}\\left(\\frac{1}{2} V^2\\right)+\n\\underbrace{\\boldsymbol{\\xi}\\times\\mathbf{V}}_{\\mathbf{a}\\times\\mathbf{b}=-\\mathbf{b}\\times\\mathbf{a}}- \\mathbf{g} +\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)=0\n$$\nTry to integrate it along an arbitrary trajectory in the flow, dot with a small displacement vector $d\\mathbf{r}$:\n$$\n\\left[\\frac{\\partial\\mathbf{V}}{\\partial t} + \\boldsymbol{\\nabla}\\left(\\frac{1}{2} V^2\\right)+\n\\boldsymbol{\\xi}\\times\\mathbf{V}- \\mathbf{g} +\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)\\right]d\\mathbf{r}=0\n$$\nThe 3<sup>rd</sup> term equals 0 when:\n\n- Irrotational flow: $\\mathbf{\\xi}\\equiv0$\n\n- No flow: $\\mathbf{V}\\equiv0$, not possible\n\n- $d\\mathbf{r}$ is parallel to $\\mathbf{V}$, $\\mathbf{V} \\times d \\boldsymbol{r} \\equiv 0$\n\n  since $(\\boldsymbol{\\xi} \\times \\mathbf{V}) \\cdot d \\boldsymbol{r} \\equiv(\\mathbf{V} \\times d \\boldsymbol{r}) \\cdot \\boldsymbol{\\xi}$\n\n  our path is a streamline\n\nIn order to eliminate the 3<sup>rd</sup> term while keeping the flow rotational, we integrate the equation along the streamline segment $ds$,\n$$\n\\begin{aligned}\n\\int_1^2\\left[\\frac{\\partial\\mathbf{V}}{\\partial t} + \\boldsymbol{\\nabla}\\left(\\frac{1}{2} V^2\\right)-\n\\mathbf{g} +\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)\\right]ds=0 \\\\\n\\int_1^2\\frac{\\partial\\mathbf{V}}{\\partial t}ds + \\left(\\frac{1}{2} V_2^2-\\frac{1}{2} V_1^2\\right) + g(z_2-z_1) +\\int_1^2\\frac{1}{\\rho}\\left(dp\\right)=0\n\\end{aligned}\n$$\nRearrange to get the **unsteady Bernoulli equation for compressible flow**:\n$$\n\\color{purple}\\int_1^2\\frac{\\partial\\mathbf{V}}{\\partial t}ds+\\int_1^2\\frac{1}{\\rho}\\left(dp\\right)+ \\left(\\frac{1}{2} V_2^2-\\frac{1}{2} V_1^2\\right) + g(z_2-z_1)=0\n$$\nPlus the **steady and incompressible** conditions, the function reduced to the familiar expression:\n$$\n\\color{purple}\n\\frac{p}{\\rho}+\\frac{1}{2}V^2+gz = Const,~\\mathrm{~along~a~streamline}\n$$\nPlus the **irrotational** condition, the 3rd term remains 0 regardless the trajectory, the function becomes:\n$$\n\\color{purple}\n\\frac{p}{\\rho}+\\frac{1}{2}V^2+gz = Const,~\\mathrm{~everywhere}\n$$\n\n### 4.4 Velocity potential\n\nVector analysis tells us that if the curl of a vector field is zero then that vector field must itself be the gradient of a scalar function. That is,\n\nThe function $\\phi$ is called a potential function.\n$$\n\\boldsymbol{\\nabla} \\times \\mathbf{V} \\equiv 0 \\quad \\Rightarrow \\quad \\mathbf{V}=\\boldsymbol{\\nabla} \\phi\n$$\n{% note info %}\n\nVelocity potential $\\phi$ is another scalar function, a complementary to the [stream function](#stream-function) $\\psi$.\n\nIt is applicable only in **irrotational** flow.\n\n{% endnote %}\n\nSome useful properties:\n\n- In Cartesian coordinate, it reduce the 3 velocity components $u$, $v$, $w$ into a single scalar:\n  $$\n  u=\\frac{\\partial \\phi}{\\partial x} \\quad v=\\frac{\\partial \\phi}{\\partial y} \\quad w=\\frac{\\partial \\phi}{\\partial z}\n  $$\n\n- Line of constant $\\phi$ is called *potential lines*.\n\n  In **two-dimensional flow**, potential lines are everywhere orthogonal to the streamlines, because:\n  $$\n  u=\\frac{\\partial \\psi}{\\partial y}=\\frac{\\partial \\phi}{\\partial x} \\quad v=-\\frac{\\partial \\psi}{\\partial x}=\\frac{\\partial \\phi}{\\partial y}\n  $$\n  The dot-product of their gradients are:\n  $$\n  \\left[\\frac{\\partial \\psi}{\\partial x} \\mathbf{i}+\\frac{\\partial \\psi}{\\partial y} \\mathbf{j}\\right] \\cdot\\left[\\frac{\\partial \\phi}{\\partial x} \\mathbf{i}+\\frac{\\partial \\phi}{\\partial y} \\mathbf{j}\\right]=u(-v)+u v \\equiv 0\n  $$\n\n- If $\\phi$ exists, substitute the definition into the unsteady Bernoulli equation,\n  $$\n  \\frac{\\partial \\phi}{\\partial t}+\\int \\frac{d p}{\\rho}+\\frac{1}{2}|\\boldsymbol{\\nabla} \\phi|^{2}+g z=\\mathrm{const}\n  $$\n  {% note info %}\n\n  It is an equation between just two scalar quantities, $\\phi$ and $p$.\n\n  {% endnote %}\n\n## 5 Vortex Motion and Applications\n\nVortices are structures within the flow in which fluid is rotating about an axis line (which may be straight or curved). A **vortex line** is therefore defined as a line which is always in the same direction as the local vorticity vector $\\boldsymbol{\\xi}$.\n\n<img src=\"Vortex line example.png\" alt=\"Vortex line example (red line) from physics.stackexchange.com\" style=\"zoom:100%;\" />\n\nSimilar to streamline, vortex lines $(x, y, z) = (x(s), y(s), z(s))$ are obtained by solving:\n$$\n\\frac{dx/ds}{d\\xi_x}=\\frac{dy/ds}{d\\xi_y}=\\frac{dz/ds}{d\\xi_z}\n$$\nSimilar to steam tube, vertex lines which pass through a closed curve in space form a **vortex tube**.\n\n### 5.1 Circulation\n\n**Fluid circulation** describes the strength of rotation, or strength of fluid swirling, within a closed contour $C(t)$. Mathematically it is defined as the integral of velocity along the contour curve:\n$$\n\\Gamma=\\oint_{C(t)} \\mathbf{V} d s=\\int_{S} \\boldsymbol{\\xi} \\cdot \\boldsymbol{n} d S\n$$\n\n#### 5.1.1 Material elements and its motion\n\nConsider how a infinitesimal displacement $d\\mathbf{s}$ deforms over a small time $dt$, illustrated in the diagram below.\n\n<img src=\"Displacement deformation.png\" alt=\"Displacement deformation\" style=\"zoom:50%;\" />\n\nWe have $d(d\\mathbf{s})$ the **material line element**:\n$$\n\\begin{aligned}\nd(d \\boldsymbol{s})=d \\boldsymbol{s}_{1}-d \\boldsymbol{s}_{0} &=\\left(\\boldsymbol{x}+d \\boldsymbol{s}_{0}+\\mathbf{V}\\left(\\boldsymbol{x}+d \\boldsymbol{s}_{0}\\right) d t\\right)-(\\boldsymbol{x}+\\mathbf{V}(\\boldsymbol{x}) d t)-d \\boldsymbol{s}_{0} \\\\\n&=\\left(\\mathbf{V}\\left(\\boldsymbol{x}+d \\boldsymbol{s}_{0}\\right)-\\mathbf{V}(\\boldsymbol{x})\\right) d t \\\\\n&=d \\boldsymbol{s}_{0} \\frac{\\partial \\mathbf{V}}{\\partial\\left(d \\boldsymbol{s}_{0}\\right)} d t \\\\\n&=d \\boldsymbol{s}_{0} \\cdot \\boldsymbol{\\nabla} \\mathbf{V} d t\n\\end{aligned}\n$$\nTherefore:\n$$\n\\frac{D(d\\mathbf{s})}{Dt} = (ds\\cdot\\boldsymbol{\\nabla})\\mathbf{V}\n$$\n\n### 5.2 Kelvins Circulation Theorem\n\n> Kelvins Circulation Theorem status the expression of the rate of change of the circulation $\\frac{D\\Gamma}{Dt}$ and determine how a circulation around a fluid loop varies as the loop moves with the flow. ([reference](https://youtu.be/q4xSUYZCj84))\n\nApply material derivative to circulation we have:\n$$\n\\begin{aligned}\n\\frac{D}{Dt}\\Gamma&=\\frac{D}{Dt}\\oint_{C(t)} \\mathbf{V} d \\mathbf{s}\t\\\\\n&= \\oint_{C(t)}\\frac{D}{Dt}(\\mathbf{V} d \\mathbf{s}\t) \\\\\n&= \\oint_{C(t)}\\frac{D\\mathbf{V}}{Dt}\\cdot d \\mathbf{s}\t + \\oint_{C(t)}\\mathbf{V}\\cdot \\frac{D(d \\mathbf{s})}{Dt}\t\t\\\\\n\\end{aligned}\n$$\nSubstitute material line element into the last term to get a scalar inside the loop integration, then we have:\n$$\n\\frac{D}{Dt}\\Gamma = \\oint_{C(t)}\\frac{D\\mathbf{V}}{Dt}d \\mathbf{s}\n$$\nRecall the [general linear momentum equation](#general-differential-linear-momentum-equation) and substitute the material derivative of velocity:\n$$\n\\begin{aligned}\n\\frac{D}{Dt}\\Gamma &= \\oint_{C(t)}\\left(\\mathbf{g} - \\frac{\\boldsymbol{\\nabla}p}{\\rho} + \\frac{\\boldsymbol{\\boldsymbol{\\nabla}\\cdot\\tau_{ij}}}{\\rho}\\right)d \\mathbf{s} \\\\\n&= \\oint_{C(t)}\\mathbf{g}d \\mathbf{s}  - \\oint_{C(t)}\\frac{\\boldsymbol{\\nabla}p}{\\rho} d\\mathbf{s}   + \\oint_{C(t)}\\frac{\\boldsymbol{\\nabla}\\cdot\\boldsymbol{\\tau_{ij}}}{\\rho}d \\mathbf{s} \n\\end{aligned}\n$$\nThis function is not zero unless:\n\n- 1<sup>st</sup> term: body force torque is zero, body force is **irrotational**, $\\mathbf{g} = \\nabla\\phi$, $\\phi$ is a scalar.\n- 2<sup>nd</sup> term: $p = p(\\rho)$ or $\\rho = const.$(**incompressible and isotropic**)\n- 3<sup>rd</sup> term: **inviscid**, $\\boldsymbol{\\tau_{ij}}=0$\n\n#### 5.2.1 Aerofoil lift and Kutta-Joukowski Theorem\n\nOne application of the Kelvin Circulation Theorem is in explaining the lift attained by an aerofoil during the shedding of the starting vortex.\n\nConsider a stationary aerofoil shown in the diagram below.\n\n<img src=\"Aerofoil vortex shedding.png\" alt=\"Aerofoil vortex shedding\" style=\"zoom:50%;\" />\n\nAt time $t = 0$, the aerofoil is stationary, there is no vorticity and around the path $C(t)$ the circulation is $\\Gamma = 0$. As the flow velocity increases, vorticity is shed behind the aerofoil leading to positive $\\Gamma$.\n\nBy Kelvins circulation theorem, the circulation $\\Gamma_0$ around $C(t)$ is independent of time. Therefore, there must be negative $\\Gamma_1$ around the aerofoil, which leads to lift by the Kutta-Joukowski theorem ($L' = \\rho u\\Gamma$).\n\n### 5.3 Helmholtz Theorems\n\nSuppose we have an **inviscid**, **incompressible** fluid of **constant density** moving under a **conservative body force**, then\n\n1. The quantity\n   $$\n   \\Gamma=\\int_{S} \\boldsymbol{\\xi} \\cdot \\boldsymbol{n} d S\n   $$\n   is the same for all cross-sections $S$ of a vortex tube. i.e. the strength of a vortex is constant along the length of the vortex.\n\n2. A vortex filament cannot end in the fluid; it must extend to the boundaries of the fluid, infinity, or form a closed loop\n\n3. If fluid is initially irrotational, in the absense of rotational forces, it remains irrotational indefinitely.\n\n#### 5.3.1 Vortex rings\n\nA vivid example of Helmholtzs theorems can be seen in vortex (smoke) rings. These are vortices in which the core vortex line forms a closed loop (theorem #2).\n\nSuch vortices can retain their strength (theorem #1) and travel significant distances (the smoke is carried in the vortex).\n\n","slug":"Derivation-of-Differential-Fluid-Equations","published":1,"updated":"2022-05-29T07:55:39.096Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz1x0003l8yb9a2a57q3","content":"<div class=\"note note-primary\">\n            <p>Feeling unsafe when deploying CFD algorithms, the best way to alleviate the anxiety is to derive the fundamentals again.</p>\n          </div>\n<span id=\"more\"></span>\n<h2 id=\"acceleration-and-mass-conservation\">1 Acceleration and Mass Conservation</h2>\n<h3 id=\"acceleration-field-of-a-fluid\">1.1 Acceleration field of a fluid</h3>\n<h4 id=\"material-substantial-convective-derivatives\">1.1.1 Material / substantial / convective derivatives</h4>\n<p><img src=\"Material derivatives.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Material derivatives\" style=\"zoom:50%;\" /></p>\n<p>Given a spatial-temporal property <span class=\"math inline\">\\(f(x,y,z,t)\\)</span> of a fluid particle in the Eulerian coordinate. After an infinitesimal period, the change in <span class=\"math inline\">\\(f\\)</span> , is therefore: <span class=\"math display\">\\[\n\\begin{aligned}\n\\Delta f = f(x+\\Delta x,y+\\delta x,z+\\delta z,t+\\Delta t)- f(x,y,z,t) \n\\end{aligned}\n\\]</span> set the position and time change tend to 0, <span class=\"math display\">\\[\n\\Delta f = \\frac{\\partial f}{\\partial x}\\Delta x+\\frac{\\partial f}{\\partial y}\\Delta y+\\frac{\\partial f}{\\partial z}\\Delta z+\\frac{\\partial f}{\\partial t}\\Delta t\n\\]</span> considering: <span class=\"math display\">\\[\n\\Delta x = u \\Delta t, \\Delta y = v \\Delta t, \\Delta z = w \\Delta t\n\\]</span> then <span class=\"math display\">\\[\n\\frac{\\Delta f }{\\Delta t}=\\frac{\\partial f}{\\partial t} + \\frac{\\partial f}{\\partial x}u+\\frac{\\partial f}{\\partial y}v+\\frac{\\partial f}{\\partial z}w\n\\]</span> In the limit as <span class=\"math inline\">\\(\\Delta t \\rightarrow 0\\)</span>, <span class=\"math display\">\\[\n\\frac{D f }{D t}=\\frac{\\partial f}{\\partial t} + \\frac{\\partial f}{\\partial x}u+\\frac{\\partial f}{\\partial y}v+\\frac{\\partial f}{\\partial z}w\n\\]</span> or in a vector form: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{D f }{D t}=\\frac{\\partial f}{\\partial t} + \\mathbf{V} \\cdot \\boldsymbol{\\nabla} f\n\\]</span> In the scalar case <span class=\"math inline\">\\(\\boldsymbol{\\nabla} f\\)</span> is simply the gradient of a scalar, while in the vector case, <span class=\"math inline\">\\(\\boldsymbol{\\nabla} \\mathbf{f}\\)</span> is the covariant derivative of the vector.</p>\n<div class=\"note note-info\">\n            <p>Like the Reynolds Transport Theorem in the integral part, the material derivative connects the Lagrangian and Eulerian frame of references.</p>\n          </div>\n<h4 id=\"material-derivative-of-velocity\">1.1.2 Material derivative of velocity</h4>\n<p>Set <span class=\"math inline\">\\(f\\)</span> as <span class=\"math inline\">\\(\\mathbf{V}\\)</span> and the fluid acceleration as <span class=\"math inline\">\\(\\mathbf{a}\\)</span>, substitute to the formula above: <span class=\"math display\">\\[\n\\mathbf{a} = \\frac{D \\mathbf{V} }{D t}=\\underbrace{\\frac{\\partial \\mathbf{V}}{\\partial t}}_{\\text {local}} + \\underbrace{\\mathbf{V} \\cdot \\boldsymbol{\\nabla} \\mathbf{V}}_{\\text {convective}}\n\\]</span> where <span class=\"math inline\">\\(\\frac{\\partial \\mathbf{V}}{\\partial t}\\)</span> is called <strong>local acceleration</strong> while <span class=\"math inline\">\\((\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}\\)</span> is the <strong>convective acceleration</strong>.</p>\n<div class=\"note note-info\">\n            <p>It is also written as <span class=\"math inline\">\\(\\mathbf{a} = \\frac{D \\mathbf{V} }{D t}=\\frac{\\partial \\mathbf{V}}{\\partial t} + (\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}\\)</span>, but it's equivalent.</p>\n          </div>\n<h3 id=\"differential-equation-of-mass-conservation\">1.2 Differential equation of mass conservation</h3>\n<p>Take an infinitesimally small cubic control volume as below.</p>\n<p><img src=\"Differential mass conservation.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Differential mass conservation\" style=\"zoom:50%;\" /></p>\n<p>With the integral form with one-dimensional assumption: <span class=\"math display\">\\[\n\\int_{C V} \\frac{\\partial \\rho}{\\partial t} d \\mathcal{V}+\\sum_{i}\\left(\\rho_{i} A_{i} V_{i}\\right)_{o u t}-\\sum_{i}\\left(\\rho_{i} A_{i} V_{i}\\right)_{i n}=0\n\\]</span></p>\n<ol type=\"1\">\n<li><p>Density can be considered uniform in the CV, <span class=\"math display\">\\[\n\\int_{C V} \\frac{\\partial \\rho}{\\partial t} d \\mathcal{V} = \\frac{\\partial \\rho}{\\partial t} dxdydz\n\\]</span></p></li>\n<li><p>Inlet mass flow in 3 directions <span class=\"math display\">\\[\n\\dot{m}_{x} = \\rho udydz, \\dot{m}_{y} = \\rho vdxdz, \\dot{m}_{z} = \\rho udxdy\n\\]</span></p></li>\n<li><p>Outlet mass flow in x direction particular <span class=\"math display\">\\[\n\\dot{m}_{x+dx} = \\left(\\rho u+\\frac{\\partial \\rho u}{\\partial x }dx\\right)dydz\n\\]</span></p></li>\n<li><p>Substitute all in the continuous function <span class=\"math display\">\\[\n\\frac{\\partial \\rho}{\\partial t} dxdydz +\\frac{\\partial \\rho u}{\\partial x}dxdydz +\\frac{\\partial \\rho v}{\\partial y}dxdydz +\\frac{\\partial \\rho w}{\\partial z}dxdydz  = 0\n\\]</span> simplify: <span class=\"math display\">\\[\n\\frac{\\partial \\rho}{\\partial t}  +\\frac{\\partial \\rho u}{\\partial x} +\\frac{\\partial \\rho v}{\\partial y} +\\frac{\\partial \\rho w}{\\partial z}  = 0\n\\]</span> or in the vector form: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial \\rho}{\\partial t}+\\boldsymbol{\\nabla} \\cdot(\\rho\\mathbf{V})=0\n\\]</span> <div class=\"note note-info\">\n            <p>The only requirements of this equation are the density <span class=\"math inline\">\\(\\rho\\)</span> and velocity <span class=\"math inline\">\\(\\mathbf{V}\\)</span> are continuous in time and space. As a result, this equation is always called the <em>equation of continuity</em>.</p>\n          </div></p></li>\n</ol>\n<h4 id=\"simplifications\">1.2.1 Simplifications</h4>\n<ul>\n<li><p>steady flow: <span class=\"math inline\">\\(\\partial/\\partial t = 0\\)</span>, <span class=\"math display\">\\[\n\\boldsymbol{\\nabla} \\cdot(\\rho\\mathbf{V})=0\n\\]</span></p></li>\n<li><p>Incompressible flow: <span class=\"math inline\">\\(\\rho = Const\\)</span> spacial and temporal:</p></li>\n</ul>\n<p><span class=\"math display\">\\[\n\\boldsymbol{\\nabla} \\cdot\\mathbf{V}=0\n\\]</span></p>\n<div class=\"note note-info\">\n            <p>It makes the equation linear and much more tractable to solving analytically.</p>\n          </div>\n<h3 id=\"cylindrical-coordinates\">1.3 Cylindrical coordinates</h3>\n<p><img src=\"Polar coordinate.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Polar coordinate\" style=\"zoom:50%;\" /></p>\n<h4 id=\"transformation-of-coordinates\">1.3.1 Transformation of coordinates</h4>\n<p>From cartesian to cylindrical: <span class=\"math display\">\\[\nr=\\sqrt{x^{2}+y^{2}} \\quad \\theta=\\tan ^{-1} \\frac{y}{x} \\quad z=z\n\\]</span></p>\n<p>From cylindrical to cartesian: <span class=\"math display\">\\[\nx=r \\cos \\theta \\quad y=r \\sin \\theta \\quad z=z\n\\]</span></p>\n<h4 id=\"differential-operators\">1.3.2 Differential operators</h4>\n<p>Two differential operators in polar coordinate: <span class=\"math display\">\\[\n\\begin{aligned}\n\\boldsymbol{\\nabla} f &amp;=\\frac{\\partial f}{\\partial r} \\hat{\\boldsymbol{r}}+\\frac{1}{r} \\frac{\\partial f}{\\partial \\theta} \\hat{\\boldsymbol{\\theta}}+\\frac{\\partial f}{\\partial z} \\hat{\\boldsymbol{z}}\\\\\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} &amp;=\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r V_{r}\\right)+\\frac{1}{r} \\frac{\\partial}{\\partial \\theta}\\left(V_{\\theta}\\right)+\\frac{\\partial}{\\partial z}\\left(V_{z}\\right)\n\\end{aligned}\n\\]</span></p>\n<h4 id=\"continuous-function-in-cylindrical-coordinates\">6.3.3 Continuous function in cylindrical coordinates</h4>\n<p>It is easy to substitute the equation of divergence into the continuous function, <span class=\"math display\">\\[\n\\frac{\\partial \\rho}{\\partial t}+\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\rho V_{r}\\right)+\\frac{1}{r} \\frac{\\partial}{\\partial \\theta}\\left(\\rho V_{\\theta}\\right)+\\frac{\\partial}{\\partial z}\\left(\\rho V_{z}\\right)=0\n\\]</span></p>\n<h2 id=\"linear-momentum-and-energy\">2 Linear Momentum and Energy</h2>\n<h3 id=\"conservation-laws-from-differential-reynolds-transport-theorem\">2.1 Conservation laws from differential Reynolds transport theorem</h3>\n<p>Recall RTT on a fixed control volume <span class=\"math inline\">\\(\\Omega\\)</span>: <span class=\"math display\">\\[\n\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(B_{s}\\right)=\\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}+\\int_{\\partial \\Omega} \\beta \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> where <span class=\"math display\">\\[\n\\beta=\\frac{\\partial B}{\\partial m} \\quad \\Rightarrow \\quad B=\\int_{\\bar{\\Omega}} \\beta \\rho d \\mathcal{V}\n\\]</span> <span class=\"math inline\">\\(\\bar{\\Omega}\\)</span> denotes the control volume in a Lagrangian frame of reference (close system), while <span class=\"math inline\">\\(\\Omega\\)</span> denotes the control volume in an Eulerian frame of reference (open system).</p>\n<div class=\"note note-info\">\n            <p>Open system: matter and energy goes in and out</p><p>Close system: energy goes in and out while matter cannot</p><p>Isolated system: matter and energy cannot go in and out</p>\n          </div>\n<p>In the Lagrangian frame of reference, <span class=\"math display\">\\[\n\\frac{\\mathrm{d}}{\\mathrm{d} t}(B)=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{\\bar{\\Omega}} \\beta \\rho d \\mathcal{V}\\right)\\underbrace{=}_{Leibniz&#39;s Rule}\\int_{\\bar{\\Omega}} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}=\\int_{\\bar{\\Omega}} s d \\mathcal{V}\n\\]</span> <div class=\"note note-info\">\n            <p>Leibniz's rule: the derivative moves into the integral symbol: <span class=\"math display\">\\[\\frac{d}{d x}\\left(\\int_{a}^{b} f(x, t) d t\\right)=\\int_{a}^{b} \\frac{\\partial}{\\partial x} f(x, t) d t\\]</span></p>\n          </div></p>\n<p>Where <span class=\"math inline\">\\(s\\)</span> denotes the \"rate of change of <span class=\"math inline\">\\(B\\)</span> per unit volume\"</p>\n<p>Then the RTT is instead: <span class=\"math display\">\\[\n\\int_{\\bar{\\Omega}} s d \\mathcal{V} = \\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}+\\int_{\\partial \\Omega} \\beta \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> Use divergence theorem, drop the bar notation with <span class=\"math inline\">\\(\\Delta t \\rightarrow 0\\)</span>, and arrive a differential form: <span class=\"math display\">\\[\n\\begin{array}{r}\n\\int_{\\Omega} s d \\mathcal{V}=\\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}+\\int_{\\Omega} \\boldsymbol{\\nabla}  \\cdot(\\beta \\rho \\mathbf{V}) d \\mathcal{V} \\\\\n\\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\beta \\rho \\mathbf{V})-s d \\mathcal{V}=0 \\\\\n\\Leftrightarrow \\color{purple}{\\frac{\\partial(\\beta \\rho)}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\beta \\rho \\mathbf{V})-s=0}\n\\end{array}\n\\]</span> <div class=\"note note-info\">\n            <p>Divergence theorem: <span class=\"math display\">\\[\\int_{S} \\boldsymbol{\\nabla}  \\cdot \\mathbf{F} d A=\\int_{\\partial S} \\mathbf{F} \\cdot \\hat{\\mathbf{n}} d s\\]</span></p>\n          </div></p>\n<h4 id=\"continuity-equation-for-mass\">2.1.1 Continuity equation for mass</h4>\n<p>Substitute <span class=\"math inline\">\\(\\beta = 1\\)</span> and <span class=\"math inline\">\\(s=0\\)</span> (mass created = 0) into the differential RTT: <span class=\"math display\">\\[\n\\frac{\\partial(\\rho)}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V})=0\n\\]</span> and for incompressible flow: <span class=\"math display\">\\[\n\\boldsymbol{\\nabla}  \\cdot \\mathbf{V}=0\n\\]</span></p>\n<h4 id=\"continuity-equation-for-linear-momentum\">2.1.2 Continuity equation for linear momentum</h4>\n<p>Substitute <span class=\"math inline\">\\(\\beta =\\mathbf{V}\\)</span> into the differential RTT: <span class=\"math display\">\\[\n\\frac{\\partial(\\rho \\mathbf{V})}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V}\\otimes \\mathbf{V}) -\\mathbf{s} =0\n\\]</span> <span class=\"math inline\">\\(\\mathbf{s}\\)</span> denotes the force per unit volume, and $$ denotes the outer product.</p>\n<div class=\"note note-info\">\n            <p>Outer product or dyadic product follows: <span class=\"math display\">\\[\\left[\\begin{array}{c}u_{1} \\\\u_{2} \\\\\\vdots \\\\u_{m}\\end{array}\\right] \\otimes \\left[\\begin{array}{c}v_{1} \\\\v_{2} \\\\\\vdots \\\\v_{n}\\end{array}\\right]=\\left[\\begin{array}{cccc}u_{1} v_{1} &amp; u_{1} v_{2} &amp; \\ldots &amp; u_{1} v_{n} \\\\u_{2} v_{1} &amp; u_{2} v_{2} &amp; \\ldots &amp; u_{2} v_{n} \\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\u_{m} v_{1} &amp; u_{m} v_{2} &amp; \\ldots &amp; u_{m} v_{n}\\end{array}\\right]\\]</span> The divergence of a dyad follows this formula: <span class=\"math display\">\\[\\begin{aligned}&amp;\\boldsymbol{\\nabla}  \\cdot(f \\mathbf{a})=(\\boldsymbol{\\nabla}  f) \\cdot \\mathbf{a}+(\\boldsymbol{\\nabla}  \\cdot \\mathbf{a}) f \\\\&amp;\\boldsymbol{\\nabla}  \\cdot(\\mathbf{a b})=(\\boldsymbol{\\nabla}  \\cdot \\mathbf{a}) \\mathbf{b}+\\mathbf{a} \\cdot \\boldsymbol{\\nabla}  \\mathbf{b}\\end{aligned}\\]</span></p>\n          </div>\n<p>Expand the equation: <span class=\"math display\">\\[\n\\begin{aligned}\n\\rho \\frac{\\partial \\mathbf{V}}{\\partial t}+\\mathbf{V} \\frac{\\partial \\rho}{\\partial t}+\\mathbf{V V} \\cdot \\boldsymbol{\\nabla}  \\rho+\\rho \\mathbf{V} \\cdot \\boldsymbol{\\nabla}  \\mathbf{V}+\\rho \\mathbf{V} \\boldsymbol{\\nabla}  \\cdot \\mathbf{V} &amp;=\\mathbf{s} \\\\\n\\Leftrightarrow \\mathbf{V}\\left(\\frac{\\partial \\rho}{\\partial t}+\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  \\rho+\\rho(\\boldsymbol{\\nabla}  \\cdot \\mathbf{V})\\right)+\\rho\\left(\\frac{\\partial \\mathbf{V}}{\\partial t}+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla} ) \\mathbf{V}\\right) &amp;=\\mathbf{s}\n\\end{aligned}\n\\]</span> With <span class=\"math inline\">\\(\\mathbf{V} \\cdot \\boldsymbol{\\nabla} \\rho+\\rho(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})=\\boldsymbol{\\nabla} \\cdot(\\rho \\mathbf{V})\\)</span>, we have the first left term a continuity equation. Drop it we have: <span class=\"math display\">\\[\n\\mathbf{V}\\underbrace{\\left(\\frac{\\partial \\rho}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V})\\right)}_{0}+\n\\rho\\underbrace{\\left(\\frac{\\partial \\mathbf{V}}{\\partial t}+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla} ) \\mathbf{V}\\right)}_{\\mathrm{material~derivative}} =\\mathbf{s}\n\\]</span> With the definition of material derivative, <span class=\"math display\">\\[\n\\color{purple}\n\\rho\\left(\\frac{D \\mathbf{V}}{D t}\\right) =\\mathbf{s}\n\\]</span> Without source or sink, the quantity <span class=\"math inline\">\\(\\mathbf{s}\\)</span> therefore represents <strong>force per unit volume</strong> <span class=\"math inline\">\\(\\mathbf{s}=\\frac{\\mathrm{d} \\mathbf{F}}{\\mathrm{d} \\mathcal{V}}\\)</span>.</p>\n<h3 id=\"forces\">2.2 Forces</h3>\n<p>The forces contain <em>body forces</em> and <em>surface forces</em> <span class=\"math inline\">\\(\\mathbf{F}=\\mathbf{F_b}+\\mathbf{F_s}\\)</span>,</p>\n<ul>\n<li><p>Body forces are due to external fields, take gravitational force as an example, <span class=\"math display\">\\[\nd \\mathbf{F}_{g}=\\rho \\mathbf{g} d x d y d z \\quad \\mathbf{g}=-g \\mathbf{k}\n\\]</span> Consider the only body force in fluid dynamic is the gravity: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\mathrm{d}\\mathbf{F_b}}{\\mathrm{d}\\mathcal{V}} = \\rho\\mathbf{g}\n\\]</span></p></li>\n<li><p>Surface forces are due to hydrostatic pressure and viscous stresses on the <em>CS</em>: <span class=\"math display\">\\[\n\\sigma_{i j}=\\left|\\begin{array}{ccc}\n-p+\\tau_{x x} &amp; \\tau_{y x} &amp; \\tau_{z x} \\\\\n\\tau_{x y} &amp; -p+\\tau_{yy} &amp; \\tau_{z y} \\\\\n\\tau_{x z} &amp; \\tau_{y z} &amp; -p+\\tau_{z z}\n\\end{array}\\right|\n\\]</span> <img src=\"Viscous stress on CS.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Stress on CS\" style=\"zoom:50%;\" /></p>\n<p>Similar to what we do in the <a href=\"#differential-equation-of-mass-conservation\">Mass Conservation</a>, the force is due to the stress change in each direction, for instance: <span class=\"math display\">\\[\ndF{s,xx} = \\left(\\sigma_{xx}+\\frac{\\partial\\sigma_{xx}}{\\partial x}dx\\right)dydz-\\sigma_{xx}dydz = \\frac{\\partial\\sigma_{xx}}{\\partial x}d\\mathcal{V}\n\\]</span> <img src=\"Surface forces on CS.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Surface forces on CS\" style=\"zoom:50%;\" /></p>\n<p>as a result: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\frac{\\mathrm{d} F_{x}}{\\mathrm{~d} \\mathcal{V}}=-\\frac{\\partial p}{\\partial x}+\\frac{\\partial \\tau_{x x}}{\\partial x}+\\frac{\\partial \\tau_{y x}}{\\partial y}+\\frac{\\partial \\tau_{z x}}{\\partial z} \\\\\n&amp;\\frac{\\mathrm{d} F_{y}}{\\mathrm{~d} \\mathcal{V}}=-\\frac{\\partial p}{\\partial y}+\\frac{\\partial \\tau_{x y}}{\\partial x}+\\frac{\\partial \\tau_{y y}}{\\partial y}+\\frac{\\partial \\tau_{z y}}{\\partial z} \\\\\n&amp;\\frac{\\mathrm{d} F_{z}}{\\mathrm{~d} \\mathcal{V}}=-\\frac{\\partial p}{\\partial z}+\\frac{\\partial \\tau_{x z}}{\\partial x}+\\frac{\\partial \\tau_{y z}}{\\partial y}+\\frac{\\partial \\tau_{z z}}{\\partial z}\n\\end{aligned}\n\\]</span> surface force in vector form: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\mathrm{d} \\mathbf{F_s}}{\\mathrm{d} \\mathcal{V}}=- \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}}\n\\]</span> <span class=\"math inline\">\\(\\frac{\\mathrm{d} \\mathbf{F_s}}{\\mathrm{d} \\mathcal{V}}\\)</span> also represents the Cauchy stress tensor:</p></li>\n</ul>\n<h3 id=\"general-differential-linear-momentum-equation\">2.3 General differential linear momentum equation</h3>\n<p>Substitute force terms into earlier momentum conservation expression, <span class=\"math display\">\\[\n\\color{purple}\n\\rho\\frac{D \\mathbf{V}}{D t} = \\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\mathbf{\\tau_{ij}}\n\\]</span></p>\n<p><span class=\"math display\">\\[\n\\mathrm{density  acceleration = (Gravity + Pressure + Viscous) ~forces~per~unit~volume}\n\\]</span></p>\n<p>These equations are valid for any fluid in general motion, particularly those which include viscous stresses. The non-linear convective terms on the left-hand side also complicates direct mathematical analysis.</p>\n<h3 id=\"differential-energy-equations\">2.4 Differential energy equations</h3>\n<p>Similar to earlier routes, we arrive energy conservation equation: <span class=\"math display\">\\[\n\\dot{Q}-\\dot{W}_{v}=\\left(\\rho \\frac{D e}{D t}+\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  p+p \\boldsymbol{\\nabla}  \\cdot \\mathbf{V}\\right) \\mathrm{d}\\mathcal{V}\n\\]</span> Note that <span class=\"math inline\">\\(\\dot{W}_{s} = 0\\)</span> since there is no shaft work in an infinitesimal CV, as a result, similar CV flux analysis can be done to <span class=\"math inline\">\\(\\dot{Q}\\)</span> and <span class=\"math inline\">\\(\\dot{W}_{v}\\)</span>:</p>\n<ul>\n<li><p>Heat conduction <span class=\"math inline\">\\(\\dot{Q}\\)</span> is regulated by <strong>Fourier's law</strong> stating that the heat flux is proportional to the gradient of the temperature, <span class=\"math inline\">\\(\\mathbf{q} = K\\boldsymbol{\\nabla}T\\)</span>, using similar flux analysis to infinitesimal CV <span class=\"math display\">\\[\n\\dot{Q}=\\boldsymbol{\\nabla}  \\cdot(k \\boldsymbol{\\nabla}   T)\\mathrm{d}\\mathcal{V}\n\\]</span></p></li>\n<li><p>Similarly, the rate of work due to viscous stresses can be expanded to give: <span class=\"math display\">\\[\n\\dot{W}_{v}=-\\boldsymbol{\\nabla} \\cdot\\left(\\mathbf{V} \\cdot \\boldsymbol{\\tau}_{i j}\\right)\\mathrm{d}\\mathcal{V}\n\\]</span></p></li>\n</ul>\n<p>Substitute into energy conservation equation to give: <span class=\"math display\">\\[\n\\rho \\frac{D e}{D t}+\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  p+p \\boldsymbol{\\nabla}  \\cdot \\mathbf{V}\n=\n\\boldsymbol{\\nabla}  \\cdot(k \\boldsymbol{\\nabla}   T)\n+\\boldsymbol{\\nabla} \\cdot\\left(\\mathbf{V} \\cdot \\boldsymbol{\\tau}_{i j}\\right)\n\\]</span></p>\n<h4 id=\"general-energy-equation\">2.4.1 General energy equation</h4>\n<p>Splitting the viscous work term: <span class=\"math display\">\\[\n\\boldsymbol{\\nabla} \\cdot\\left(\\mathbf{V} \\cdot \\boldsymbol{\\tau}_{i j}\\right) \\equiv \\mathbf{V} \\cdot \\left( \\boldsymbol{\\nabla} \\cdot \\boldsymbol{\\tau_{ij}} \\right) + \\underbrace{\\boldsymbol{\\tau_{ij}} : \\left( \\boldsymbol{\\nabla}\\mathbf{V} \\right)}_{\\boldsymbol{\\Phi}}\n\\]</span> where <span class=\"math inline\">\\(\\boldsymbol{\\Phi}\\)</span> denotes the <strong>viscous-dissipation function</strong>, representing the dissipation of energy due to viscous effects. For <strong>Newtonian flow in a Cartesian coordinates</strong>: <span class=\"math display\">\\[\n\\boldsymbol{\\Phi}=\\mu\\left[2\\left(\\frac{\\partial u}{\\partial x}\\right)^{2}+2\\left(\\frac{\\partial v}{\\partial y}\\right)^{2}+2\\left(\\frac{\\partial w}{\\partial z}\\right)^{2}+\\left(\\frac{\\partial v}{\\partial x}+\\frac{\\partial u}{\\partial y}\\right)^{2}+\\left(\\frac{\\partial w}{\\partial y}+\\frac{\\partial v}{\\partial z}\\right)^{2}+\\left(\\frac{\\partial u}{\\partial z}+\\frac{\\partial w}{\\partial x}\\right)^{2}\\right]\n\\]</span> <div class=\"note note-info\">\n            <p>Dissipated energy means during the flow, it is converted into the internal energy of the material. Note <span class=\"math inline\">\\(\\boldsymbol{\\Phi}\\)</span> is always positive, implying that viscous flow always loses energy.</p>\n          </div></p>\n<p>Expanding <span class=\"math inline\">\\(e = \\hat{u}+\\frac{1}{2}V^{2}+gz\\)</span>, the general differential energy equation is : <span class=\"math display\">\\[\n\\color{purple}\n\\rho \\frac{D \\hat{u}}{D t}+p(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})=\\boldsymbol{\\nabla} \\cdot(k \\boldsymbol{\\nabla} T)+\\mathbf{\\Phi}\n\\]</span> with further assumptions: <span class=\"math display\">\\[\n\\begin{aligned}\nd \\hat{u} &amp; \\approx c_{v} d T \\\\\nc_{v}, \\mu, k, \\rho &amp; \\approx \\mathrm{const}\n\\end{aligned}\n\\]</span> for incompressible flow, we have: <span class=\"math display\">\\[\n\\color{purple}{\\rho c_{v} \\frac{\\partial T}{\\partial t} =\\cdot(k \\boldsymbol{\\nabla}^2 T)+\\mathbf{\\Phi}}\n\\]</span></p>\n<h2 id=\"euler-and-navier-stokes-equations\">3 Euler and Navier-Stokes Equations</h2>\n<p>Recall <a href=\"#general-differential-linear-momentum-equation\">differential linear momentum equation</a>: <span class=\"math display\">\\[\n\\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}} = \\rho\\frac{D \\mathbf{V}}{D t}\n\\]</span> Equations of motion of <span class=\"math inline\">\\(\\boldsymbol{\\tau_{ij}}\\)</span> is still needed, and its different depending on types of fluid</p>\n<h3 id=\"euler-equations-frictionless-flow\">3.1 Euler equations (frictionless flow)</h3>\n<p>Use the inviscid flow assumption, that is <span class=\"math inline\">\\(\\boldsymbol{\\tau_{ij}}=0\\)</span>, the momentum equation reduces to: <span class=\"math display\">\\[\n\\color{purple}\n\\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}} = \\rho\\frac{D \\mathbf{V}}{D t}\n\\]</span> <div class=\"note note-info\">\n            <p>Fluids with low viscosity can be reasonably modelled as inviscid, except near boundaries.</p>\n          </div></p>\n<h3 id=\"newtonian-fluid\">3.2 Newtonian fluid</h3>\n<h4 id=\"strain\">3.2.1 Strain</h4>\n<p>Strains of a fluid particle evaluate the deformation due to an applied <em>shear stress</em>.</p>\n<p><img src=\"Fluid partical deformation.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Fluid partical deformation\" style=\"zoom:50%;\" /></p>\n<p>and strain is defined as (anticlockwise positive): <span class=\"math display\">\\[\n\\mathrm{strain_{xy}} = \\Delta\\theta_x-(-\\Delta\\theta_y)\n\\]</span> In a continuous system, the rate of strain is then: <span class=\"math display\">\\[\n\\frac{\\mathrm{d}}{\\mathrm{d}t}(\\mathrm{strain_{xy}}) = \\epsilon_{xy} = \\frac{\\partial v}{\\partial x} + \\frac{\\partial u}{\\partial y}\n\\]</span> or in vector form: <span class=\"math display\">\\[\n\\boldsymbol{\\epsilon} = \\nabla \\mathbf{V}+(\\nabla \\mathbf{V}^{\\top})\n\\]</span></p>\n<h4 id=\"viscosity\">3.2.2 Viscosity</h4>\n<p>Newton defined a <strong>newtonian fluid</strong> by a fluid in which the <em>viscous stresses</em> are linearly proportional to the local <em>strain rates</em>. <span class=\"math display\">\\[\n\\boldsymbol{\\tau_{ij}} \\propto \\boldsymbol{\\epsilon_{ij}}\n\\]</span> In order to apply this to the NaiverStokes equations, three assumptions were made by Stokes:</p>\n<ul>\n<li>The stress tensor is a linear function of the strain rate tensor or equivalently the velocity gradient.</li>\n<li>The fluid is isotropic.</li>\n<li>For a fluid at rest, <span class=\"math inline\">\\(\\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}} = 0\\)</span> (so that hydrostatic pressure results).</li>\n</ul>\n<p>And it leads to: <span class=\"math display\">\\[\n\\color{purple}\n\\boldsymbol{\\tau}=\\mu\\left(\\nabla \\mathbf{u}+\\nabla \\mathbf{u}^{\\top}\\right)+\\lambda(\\nabla \\cdot \\mathbf{u}) \\mathbf{I}\n\\]</span> or <span class=\"math display\">\\[\n\\boldsymbol{\\tau_{ij}}=\\mu\\left(\\frac{\\partial u_{i}}{\\partial x_{j}}+\\frac{\\partial u_{j}}{\\partial x_{i}}\\right)+\\delta_{i j} \\lambda \\frac{\\partial u_{k}}{\\partial x_{k}} \\\\\n\\]</span> where, <span class=\"math display\">\\[\n\\delta_{i j}= \\begin{cases}0 &amp; \\text { if } i \\neq j \\\\ 1 &amp; \\text { if } i=j\\end{cases}\n\\]</span> As a result, expand the formula: <span class=\"math display\">\\[\n\\boldsymbol{\\tau_{ij}}=\\left|\\begin{array}{ccc}\n2 \\mu \\frac{\\partial u}{\\partial x}+\\lambda \\frac{\\partial u_{}}{\\partial x_{k}} &amp; \\mu\\left(\\frac{\\partial u}{\\partial y}+\\frac{\\partial v}{\\partial x}\\right) &amp; \\mu\\left(\\frac{\\partial u}{\\partial z}+\\frac{\\partial w}{\\partial x}\\right) \\\\\n\\mu\\left(\\frac{\\partial v}{\\partial x}+\\frac{\\partial u}{\\partial y}\\right) &amp; 2 \\mu \\frac{\\partial v}{\\partial y}+\\lambda \\frac{\\partial v}{\\partial y} &amp; \\mu\\left(\\frac{\\partial v}{\\partial z}+\\frac{\\partial w}{\\partial y}\\right) \\\\\n\\mu\\left(\\frac{\\partial w}{\\partial x}+\\frac{\\partial u}{\\partial z}\\right) &amp; \\mu\\left(\\frac{\\partial w}{\\partial y}+\\frac{\\partial v}{\\partial z}\\right) &amp; 2 \\mu \\frac{\\partial w}{\\partial z}+\\lambda \\frac{\\partial w}{\\partial z}\n\\end{array}\\right|\n\\]</span> And <span class=\"math inline\">\\(\\mu\\)</span> and <span class=\"math inline\">\\(\\lambda\\)</span> represents the <strong>shear/dynamic viscosity</strong> and <strong>volume/bulk viscosity</strong> respectively,</p>\n<blockquote>\n<p>The value of <em></em>, which produces a viscous effect associated with volume change, is very difficult to determine, not even its sign is known with absolute certainty. Even in compressible flows, the term involving <em></em> is often negligible; however it can occasionally be important even in nearly incompressible flows and is a matter of controversy. When taken nonzero, the most common approximation is <strong><em></em>  2/3<em></em></strong>.</p>\n</blockquote>\n<h3 id=\"navier-stokes-equations\">3.3 Navier-Stokes equations</h3>\n<p>Substitute the stress representation into the linear momentum equation: <span class=\"math display\">\\[\n\\rho\\frac{D \\mathbf{V}}{D t} = \\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot \\mu\\left( \\left(\\boldsymbol{\\nabla} \\mathbf{V}+\\boldsymbol{\\nabla} \\mathbf{V}^{\\top}\\right)-\\frac{2}{3}(\\nabla \\cdot \\mathbf{V}) \\mathbf{I}\\right)\n\\]</span> with further simplification we have: <span class=\"math display\">\\[\n\\color{purple}\n\\rho \\frac{\\mathrm{D} \\mathbf{V}}{\\mathrm{D} t}=\\rho\\left(\\frac{\\partial \\mathbf{V}}{\\partial t}+\\mathbf{V} \\cdot \\nabla \\mathbf{V}\\right)=-\\nabla p+\\mu \\nabla^{2} \\mathbf{V}+\\frac{1}{3} \\mu \\nabla(\\nabla \\cdot \\mathbf{V})+\\rho \\mathbf{g}\n\\]</span></p>\n<h4 id=\"incompressible-navier-stokes-equations\">3.3.1 Incompressible Navier-Stokes equations</h4>\n<p>With incompressible flow we have no bulk viscosity so: <span class=\"math display\">\\[\n\\boldsymbol{\\tau}=\\mu\\left(\\nabla \\mathbf{u}+\\nabla \\mathbf{u}^{\\top}\\right)\n\\]</span> And the Incompressible Navier-Stokes equations is therefore: <span class=\"math display\">\\[\n\\rho\\frac{D \\mathbf{V}}{D t} = \\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot \\mu\\left( \\boldsymbol{\\nabla} \\mathbf{V}+\\boldsymbol{\\nabla} \\mathbf{V}^{\\top}\\right)\n\\]</span> with <span class=\"math inline\">\\(\\boldsymbol{\\nabla} \\cdot \\mathbf{V}=0\\)</span> for incompressible flow: <span class=\"math display\">\\[\n\\boldsymbol{\\nabla} \\cdot \\mu\\left( \\boldsymbol{\\nabla} \\mathbf{V}+\\boldsymbol{\\nabla} \\mathbf{V}^{\\top}\\right) = \\mu\\boldsymbol{\\nabla}^2\\mathbf{V}\n\\]</span> as a result: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial\\mathbf{V}}{\\partial t} +  \\mathbf{V} \\cdot \\nabla \\mathbf{V}= \\mathbf{g} - \\boldsymbol{\\nabla}\\frac{p}{\\rho} +  \\nu\\boldsymbol{\\nabla}^2\\mathbf{V}\n\\]</span> where <span class=\"math inline\">\\(\\nu = \\frac{\\mu}{\\rho}\\)</span>, called <strong>kinetic viscosity</strong></p>\n<div class=\"note note-info\">\n            <p>Meaning of each term: <span class=\"math display\">\\[\\overbrace{\\underbrace{\\frac{\\partial \\mathbf{V}}{\\partial t}}_{\\text {Variation }}+\\underbrace{(\\mathbf{V} \\cdot \\nabla) \\mathbf{V}}_{\\text {Convection }}}^{\\text {Inertia (per volume) }}= \\overbrace{\\underbrace{\\nu \\nabla^{2} \\mathbf{V}}_{\\text {Diffusion }}\\underbrace{-\\nabla w}_{\\begin{array}{c}\\text { Internal } \\\\\\text { source }\\end{array}}}^{\\text {Divergence of stress }}+\\underbrace{\\mathbf{g}}_{\\begin{array}{c}\\text { External } \\\\\\text { source }\\end{array}} .\\]</span></p>\n          </div>\n<p>Expanding along every coordinates gives that: <span class=\"math display\">\\[\n\\begin{align}\n\\frac{\\partial u}{\\partial t} +  u \\frac{\\partial u}{\\partial x} + v\\frac{\\partial u}{\\partial y} + w \\frac{\\partial u}{\\partial z}&amp;= g_x - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial x} +  \\nu\\left(\\frac{\\partial^2u}{\\partial^2x}+\\frac{\\partial^2u}{\\partial^2y}+\\frac{\\partial^2u}{\\partial^2z}\\right) \\\\\n\\frac{\\partial v}{\\partial t} +  u \\frac{\\partial v}{\\partial x} + v\\frac{\\partial v}{\\partial y} + w \\frac{\\partial v}{\\partial z}&amp;= g_y - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial y} +  \\nu\\left(\\frac{\\partial^2v}{\\partial^2x}+\\frac{\\partial^2v}{\\partial^2y}+\\frac{\\partial^2v}{\\partial^2z}\\right) \\\\\n\\frac{\\partial w}{\\partial t} +  u \\frac{\\partial w}{\\partial x} + v\\frac{\\partial w}{\\partial y} + w \\frac{\\partial w}{\\partial z}&amp;= g_z - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial z} +  \\nu\\left(\\frac{\\partial^2w}{\\partial^2x}+\\frac{\\partial^2w}{\\partial^2y}+\\frac{\\partial^2w}{\\partial^2z}\\right)\n\\end{align}\n\\]</span></p>\n<h4 id=\"cylindrical-coordinates-1\">3.3.2 Cylindrical coordinates</h4>\n<p>Recall the coordinates transformation: <span class=\"math display\">\\[\nr=\\sqrt{x^{2}+y^{2}} \\quad \\theta=\\tan ^{-1} \\frac{y}{x} \\quad z=z\n\\]</span> and the differential operators: <span class=\"math display\">\\[\n\\begin{aligned}\n\\boldsymbol{\\nabla} f &amp;=\\frac{\\partial f}{\\partial r} \\hat{\\boldsymbol{r}}+\\frac{1}{r} \\frac{\\partial f}{\\partial \\theta} \\hat{\\boldsymbol{\\theta}}+\\frac{\\partial f}{\\partial z} \\hat{\\boldsymbol{z}}\\\\\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} &amp;=\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r V_{r}\\right)+\\frac{1}{r} \\frac{\\partial}{\\partial \\theta}\\left(V_{\\theta}\\right)+\\frac{\\partial}{\\partial z}\\left(V_{z}\\right)\\\\\n\\boldsymbol{\\nabla}^2f &amp;= \\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial f}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} f}{\\partial \\theta^{2}}+\\frac{\\partial^{2} f}{\\partial z^{2}}\\right)\n\\end{aligned}\n\\]</span> And in z direction <span class=\"math display\">\\[\n\\begin{align}\n\\frac{\\partial V_r}{\\partial t} +  V_r \\frac{\\partial V_r}{\\partial r} + V_\\theta\\frac{1}{r}\\frac{\\partial V_r}{\\partial \\theta} + V_z \\frac{\\partial V_r}{\\partial z}&amp;= g_r - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial r} +  \\nu\\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial V_{r}}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} V_{r}}{\\partial \\theta^{2}}+\\frac{\\partial^{2} V_{r}}{\\partial z^{2}}\\right) \\\\\n\\frac{\\partial V_\\theta}{\\partial t} +  V_r \\frac{\\partial  V_\\theta}{\\partial r} + V_\\theta\\frac{1}{r}\\frac{\\partial  V_\\theta}{\\partial \\theta} + V_z \\frac{\\partial  V_\\theta}{\\partial z}&amp;= g_\\theta - \\frac{1}{\\rho r}\\frac{\\partial p}{\\partial \\theta} +    \\nu\\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial V_{\\theta}}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} V_{\\theta}}{\\partial \\theta^{2}}+\\frac{\\partial^{2} V_{\\theta}}{\\partial z^{2}}\\right) \\\\\n\\frac{\\partial V_z}{\\partial t} +  V_r \\frac{\\partial V_r}{\\partial r} + V_\\theta\\frac{1}{r}\\frac{\\partial V_z}{\\partial \\theta} + V_z \\frac{\\partial V_z}{\\partial z}&amp;= g_z - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial z} +  \\nu\\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial V_{z}}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} V_{z}}{\\partial \\theta^{2}}+\\frac{\\partial^{2} V_{z}}{\\partial z^{2}}\\right)\n\\end{align}\n\\]</span></p>\n<h3 id=\"closing-the-system\">3.3 Closing the system</h3>\n<p>To summarise, the 3 main functions are: <span class=\"math display\">\\[\n\\begin{aligned} \\frac{\\partial \\rho}{\\partial t}+\\nabla \\cdot(\\rho\\mathbf{V}) &amp;=0 &amp; &amp; \\text { continuity } \\\\ \\rho \\mathbf{g}-\\nabla p+\\boldsymbol{\\nabla} \\cdot \\boldsymbol{\\tau}_{i j} &amp;=\\rho \\frac{D \\mathbf{V}}{D t} &amp; &amp; \\text { momentum } \\\\ \\rho \\frac{D \\hat{u}}{D t}=p(\\boldsymbol{\\nabla} \\cdot \\mathbf{V}) &amp;=\\boldsymbol{\\nabla} \\cdot(k \\boldsymbol{\\nabla} T)+\\mathbf{\\Phi} &amp; &amp; \\text { energy } \\end{aligned}\n\\]</span> Note that there are five unknowns <span class=\"math inline\">\\(\\rho,\\mathbf{V}, p, \\hat{u},T\\)</span>, but only three equations. Additional equations are state relations for the thermodynamic properties of the fluid. For example for perfect gas: <span class=\"math display\">\\[\n\\rho=\\frac{p}{R T} \\quad \\hat{u}=\\int c_{v} d T\n\\]</span> The system of equations is now well-posed and can be solved, subject to <em>boundary conditions.</em></p>\n<h4 id=\"incompressible-system\">3.3.1 Incompressible system</h4>\n<p>We have: <span class=\"math display\">\\[\n\\begin{aligned}\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} &amp;=0 \\\\\n\\rho \\frac{D \\mathbf{V}}{D t} &amp;=\\rho \\boldsymbol{g}-\\nabla p+\\mu \\nabla^{2} \\mathbf{V} \\\\\n\\rho c_{p} \\frac{D T}{D t} &amp;=k \\nabla^{2} T+\\mathbf{\\Phi}\n\\end{aligned}\n\\]</span> Note that for incompressible flow, <span class=\"math inline\">\\(\\rho,\\mu,k\\)</span> are constants, only 3 unknowns are left <span class=\"math inline\">\\(p, \\mathbf{V}, T\\)</span>. So the incompressible system is already closed. Besides, continuity and momentum equations are independent of the <span class=\"math inline\">\\(T\\)</span>, thus decouple from the energy equation.</p>\n<h3 id=\"boundary-conditions\">3.4 Boundary conditions</h3>\n<ul>\n<li>Wall: these are typically solid, impermeable and there is a no-slip condition at the wall.</li>\n<li>Inlet: known velocity <span class=\"math inline\">\\(\\mathbf{V}\\)</span> and pressure <span class=\"math inline\">\\(p\\)</span> (and temperature <span class=\"math inline\">\\(T\\)</span>)</li>\n</ul>\n<h3 id=\"stream-function\">3.5 Stream function</h3>\n<p>Stream function provides a mathematical tool to automatically satisfy the continuity constraint, after which we can then solve the momentum equation.</p>\n<div class=\"note note-info\">\n            <p>It is only applicable to flows which are <strong>steady</strong>, <strong>incompressible</strong> and <strong>two-dimensional</strong>.</p>\n          </div>\n<p>With continuity equation: <span class=\"math display\">\\[\n\\boldsymbol{\\nabla}\\cdot\\mathbf{V} = 0 \\Leftrightarrow \\frac{\\partial u }{\\partial x} + \\frac{\\partial v}{\\partial y} = 0\n\\]</span> We seek to replace the velocity components <span class=\"math inline\">\\(u\\)</span> and <span class=\"math inline\">\\(v\\)</span> with a scalar function <span class=\"math inline\">\\(\\psi(x,y)\\)</span>, which satisfies the above constraint: <span class=\"math display\">\\[\n\\frac{\\partial}{\\partial x}\\left(\\frac{\\partial \\psi}{\\partial y}\\right)  + \\frac{\\partial}{\\partial y}\\left(-\\frac{\\partial \\psi}{\\partial x}\\right) \\equiv 0\n\\]</span> As a result: <span class=\"math display\">\\[\nu=\\frac{\\partial \\psi}{\\partial y} \\qquad v=-\\frac{\\partial \\psi}{\\partial x}\n\\]</span></p>\n<h4 id=\"properties-of-stream-function\">3.5.1 Properties of stream function</h4>\n<ul>\n<li>Recall the definition of a streamline:</li>\n</ul>\n<p><span class=\"math display\">\\[\n\\begin{align}\n&amp; \\frac{dy}{v} = \\frac{dx}{u} \\\\\n\\Leftrightarrow\\quad &amp; \\frac{\\partial \\psi}{\\partial y}u+\\frac{\\partial \\psi}{\\partial x}v=0 \\\\\n\\Leftrightarrow\\quad &amp; d\\psi=0 \\\\\n\\Leftrightarrow\\quad &amp; \\psi=Const\n\\end{align}\n\\]</span></p>\n<ul>\n<li><p>The change of <span class=\"math inline\">\\(\\psi\\)</span> across a control surface of unit depth is equal to the volume flow through the surface</p>\n<p><img src=\"Stream function property.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Stream function property\" style=\"zoom:50%;\" /> <span class=\"math display\">\\[\n\\begin{aligned}\nd Q &amp;=(\\mathbf{V} \\cdot \\boldsymbol{n}) d A \\\\\n&amp;=\\left(\\boldsymbol{i} \\frac{\\partial \\psi}{\\partial y}-\\boldsymbol{j} \\frac{\\partial \\psi}{\\partial x}\\right) \\cdot\\left(\\boldsymbol{i} \\frac{\\mathrm{d} y}{\\mathrm{~d} s}-\\boldsymbol{j} \\frac{\\mathrm{d} x}{\\mathrm{~d} s}\\right) d s \\\\\n&amp;=\\frac{\\partial \\psi}{\\partial x} d x+\\frac{\\partial \\psi}{\\partial y} d y \\\\\n&amp;=d \\psi\n\\end{aligned}\n\\]</span></p></li>\n<li><p>The flow direction can be determined by observing whether <span class=\"math inline\">\\(\\psi\\)</span> increases or decreases</p>\n<p><img src=\"Flow direction based on stream function.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Flow direction based on stream function\" style=\"zoom:50%;\" /></p></li>\n</ul>\n<h2 id=\"vorticity-and-irrotationality\">4 Vorticity and Irrotationality</h2>\n<h3 id=\"vorticity\">4.1 Vorticity</h3>\n<p>Recall how a fluid particle deforms under shear stresses:</p>\n<p><img src=\"Fluid particle deformation.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Fluid particle deformation\" style=\"zoom:50%;\" /></p>\n<p>The angular velocity <span class=\"math inline\">\\(\\omega_z\\)</span> is defined as the average rate of counter-clockwise turning of the two sides: <span class=\"math display\">\\[\n\\omega_z = \\frac{1}{2}\\left(\\frac{\\mathrm{d}(\\Delta\\theta_x)}{\\mathrm{d}t}+\\frac{\\mathrm{d}(\\Delta\\theta_y)}{\\mathrm{d}t}\\right) =\\frac{1}{2}\\left(\\frac{\\partial v}{\\partial x}-\\frac{\\partial u}{\\partial y}\\right)\n\\]</span> Similarly, <span class=\"math display\">\\[\n\\omega_{x}=\\frac{1}{2}\\left(\\frac{\\partial w}{\\partial y}-\\frac{\\partial v}{\\partial z}\\right) \\quad \\omega_{y}=\\frac{1}{2}\\left(\\frac{\\partial u}{\\partial z}-\\frac{\\partial w}{\\partial x}\\right)\n\\]</span> Combine together the angular velocity: <span class=\"math display\">\\[\n\\boldsymbol{\\omega}=\\frac{1}{2}(\\underbrace{\\boldsymbol{\\nabla} \\times \\mathbf{V}}_{\\text {curl } \\mathbf{V}})=\\frac{1}{2}\\left|\\begin{array}{ccc}\n\\mathbf{i} &amp; \\mathbf{j} &amp; \\mathbf{k} \\\\\n\\frac{\\partial}{\\partial x} &amp; \\frac{\\partial}{\\partial y} &amp; \\frac{\\partial}{\\partial z} \\\\\nu &amp; v &amp; w\n\\end{array}\\right|\n\\]</span> And the vorticity is defined as twice the angular velocity i.e. curl of velocity: <span class=\"math display\">\\[\n\\boldsymbol{\\xi}=2 \\boldsymbol{\\omega}=\\operatorname{curl} \\mathbf{V}=\\boldsymbol{\\nabla} \\times \\mathbf{V}\n\\]</span></p>\n<h3 id=\"vorticity-function-for-two-dimensional-incompressible-flow\">4.2 Vorticity function for two-dimensional incompressible flow</h3>\n<p>First some math: <span class=\"math display\">\\[\n\\begin{aligned}\n\\boldsymbol{\\nabla} \\times \\boldsymbol{\\nabla} \\phi &amp; \\equiv 0 \\qquad\\qquad&amp;(4.1) \\\\\n\\boldsymbol{\\nabla} \\times\\left(\\boldsymbol{\\nabla}^{2} \\mathbf{V}\\right) &amp;=\\boldsymbol{\\nabla}^{2}(\\boldsymbol{\\nabla} \\times \\mathbf{V}) \\qquad\\qquad&amp;(4.2) \\\\\n(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V} &amp;=\\boldsymbol{\\nabla}\\left(\\frac{1}{2} \\mathbf{V} \\cdot \\mathbf{V}\\right)-\\mathbf{V} \\times \\boldsymbol{\\xi} \\qquad\\qquad&amp;(4.3) \\\\\n\\boldsymbol{\\nabla} \\times(\\mathbf{V} \\times \\boldsymbol{\\xi}) &amp;=-\\boldsymbol{\\xi}(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})+(\\boldsymbol{\\xi} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}-(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi} \\qquad\\qquad&amp;(4.4) \n\\end{aligned}\n\\]</span> Recall the <a href=\"#incompressible-navier-stokes-equations\">incompressible momentum equation</a>: <span class=\"math display\">\\[\n\\frac{\\partial\\mathbf{V}}{\\partial t} + \\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V} = \\mathbf{g} -\\boldsymbol{\\nabla}\\left(\\frac{p}{\\rho}\\right) + \\nu\\boldsymbol{\\nabla}^2\\mathbf{V}\n\\]</span> Take the curl for each term: <span class=\"math display\">\\[\n\\underbrace{\\boldsymbol{\\nabla} \\times\\frac{\\partial\\mathbf{V}}{\\partial t} }_{\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}}+ \\boldsymbol{\\nabla} \\times\n\\underbrace{\\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V}}_{\\boldsymbol{\\nabla}\\left(\\frac{1}{2} \\mathbf{V} \\cdot \\mathbf{V}\\right)-\\mathbf{V} \\times \\boldsymbol{\\xi},~\\mathrm{by}(4.3)} = \n\\underbrace{\\boldsymbol{\\nabla} \\times\\mathbf{g}}_{0} -\n\\underbrace{\\boldsymbol{\\nabla} \\times\\boldsymbol{\\nabla}\\left(\\frac{p}{\\rho}\\right)}_{0,~\\mathrm{by} (4.1)}+ \n\\nu\\underbrace{\\boldsymbol{\\nabla} \\times\\boldsymbol{\\nabla}^2\\mathbf{V}}_{\\boldsymbol{\\nabla}^{2}(\\boldsymbol{\\nabla} \\times \\mathbf{V}),~ \\mathrm{by} (4.2)}\n\\]</span> As a result: <span class=\"math display\">\\[\n\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}+ \\underbrace{\\boldsymbol{\\nabla} \\times\\boldsymbol{\\nabla}\\left(\\frac{1}{2} \\mathbf{V} \\cdot \\mathbf{V}\\right)}_{0,~\\mathrm{by} (4.1)}-\\boldsymbol{\\nabla} \\times\\mathbf{V} \\times \\boldsymbol{\\xi}= \\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\n\\]</span> Apply <span class=\"math inline\">\\((4.4)\\)</span> cancel terms due to assumptions: <span class=\"math display\">\\[\n\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}\n+\\underbrace{\\boldsymbol{\\xi}(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})}_{0,~\\mathrm{steady~incompressible}}\n-\\underbrace{(\\boldsymbol{\\xi} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}}_{0,~\\mathrm{2D~flow}}\n+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi}= \\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\n\\]</span> Finally, the vorticity function for 2D incompressible flow is: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}\n+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi}= \n\\frac{D\\boldsymbol{\\xi}}{D t}=\n\\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\n\\]</span> <div class=\"note note-info\">\n            <p>Some of the terms have specific physical interpretations:</p><ul><li><span class=\"math inline\">\\((\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi}\\)</span> is <em>convection</em></li><li><span class=\"math inline\">\\((\\boldsymbol{\\xi} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}\\)</span> is <em>stretching</em></li><li><span class=\"math inline\">\\(\\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\\)</span> is <em>diffusion</em></li></ul>\n          </div></p>\n<div class=\"note note-info\">\n            <p>Note that there is no pressure term in the vorticity equation, implying that vorticity dynamics are localised in space.</p>\n          </div>\n<h4 id=\"combine-with-continuity-equation\">4.2.1 Combine with continuity equation</h4>\n<p>Recall the definition of the <a href=\"#stream-function\">stream function</a> and take the curl: <span class=\"math display\">\\[\n\\begin{aligned}\n\\mathbf{V} &amp;= \\mathbf{i}\\frac{\\partial\\psi}{\\partial y}-\\mathbf{j}\\frac{\\partial\\psi}{\\partial x} \\\\\n\\boldsymbol{\\nabla}\\times\\mathbf{V} &amp;= -\\mathbf{k}\\boldsymbol{\\nabla}^2\\psi = -\\mathbf{k}\\left( \\frac{\\partial^2\\psi}{\\partial x^2} + \\frac{\\partial^2\\psi}{\\partial y^2} \\right)\n\\end{aligned}\n\\]</span> Substitute these into the vorticity equation, a 4th-order single equation in <span class=\"math inline\">\\(\\psi\\)</span> arrived: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial \\psi}{\\partial y} \\frac{\\partial}{\\partial x}\\left(\\nabla^{2} \\psi\\right)-\\frac{\\partial \\psi}{\\partial x} \\frac{\\partial}{\\partial y}\\left(\\nabla^{2} \\psi\\right)=\\nu \\nabla^{2}\\left(\\nabla^{2} \\psi\\right)\n\\]</span> <div class=\"note note-info\">\n            <p>Assumptions made:</p><ul><li>Steady flow</li><li>Incompressible</li><li>Two dimensional</li></ul>\n          </div></p>\n<p>One important special case is when<br />\n<span class=\"math display\">\\[\n\\boldsymbol{\\nabla}^2\\psi = \\frac{\\partial^2\\psi}{\\partial x^2} + \\frac{\\partial^2\\psi}{\\partial y^2} = 0\n\\]</span> The flow is <strong>irrotational</strong>.</p>\n<h3 id=\"full-bernoulli-equations\">4.3 Full Bernoulli equations</h3>\n<p>We now consider a flow which is <strong>inviscid</strong> (although may still be <strong>compressible</strong>).</p>\n<p>Recall <a href=\"#euler-equations-frictionless-flow\">Euler's equation</a>: <span class=\"math display\">\\[\n\\frac{\\partial\\mathbf{V}}{\\partial t} + \\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V} = \\mathbf{g} -\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)\n\\]</span> Expand the convection term by <span class=\"math inline\">\\((4.3)\\)</span>: <span class=\"math display\">\\[\n\\frac{\\partial\\mathbf{V}}{\\partial t} + \\boldsymbol{\\nabla}\\left(\\frac{1}{2} V^2\\right)+\n\\underbrace{\\boldsymbol{\\xi}\\times\\mathbf{V}}_{\\mathbf{a}\\times\\mathbf{b}=-\\mathbf{b}\\times\\mathbf{a}}- \\mathbf{g} +\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)=0\n\\]</span> Try to integrate it along an arbitrary trajectory in the flow, dot with a small displacement vector <span class=\"math inline\">\\(d\\mathbf{r}\\)</span>: <span class=\"math display\">\\[\n\\left[\\frac{\\partial\\mathbf{V}}{\\partial t} + \\boldsymbol{\\nabla}\\left(\\frac{1}{2} V^2\\right)+\n\\boldsymbol{\\xi}\\times\\mathbf{V}- \\mathbf{g} +\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)\\right]d\\mathbf{r}=0\n\\]</span> The 3<sup>rd</sup> term equals 0 when:</p>\n<ul>\n<li><p>Irrotational flow: <span class=\"math inline\">\\(\\mathbf{\\xi}\\equiv0\\)</span></p></li>\n<li><p>No flow: <span class=\"math inline\">\\(\\mathbf{V}\\equiv0\\)</span>, not possible</p></li>\n<li><p><span class=\"math inline\">\\(d\\mathbf{r}\\)</span> is parallel to <span class=\"math inline\">\\(\\mathbf{V}\\)</span>, <span class=\"math inline\">\\(\\mathbf{V} \\times d \\boldsymbol{r} \\equiv 0\\)</span></p>\n<p>since <span class=\"math inline\">\\((\\boldsymbol{\\xi} \\times \\mathbf{V}) \\cdot d \\boldsymbol{r} \\equiv(\\mathbf{V} \\times d \\boldsymbol{r}) \\cdot \\boldsymbol{\\xi}\\)</span></p>\n<p>our path is a streamline</p></li>\n</ul>\n<p>In order to eliminate the 3<sup>rd</sup> term while keeping the flow rotational, we integrate the equation along the streamline segment <span class=\"math inline\">\\(ds\\)</span>, <span class=\"math display\">\\[\n\\begin{aligned}\n\\int_1^2\\left[\\frac{\\partial\\mathbf{V}}{\\partial t} + \\boldsymbol{\\nabla}\\left(\\frac{1}{2} V^2\\right)-\n\\mathbf{g} +\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)\\right]ds=0 \\\\\n\\int_1^2\\frac{\\partial\\mathbf{V}}{\\partial t}ds + \\left(\\frac{1}{2} V_2^2-\\frac{1}{2} V_1^2\\right) + g(z_2-z_1) +\\int_1^2\\frac{1}{\\rho}\\left(dp\\right)=0\n\\end{aligned}\n\\]</span> Rearrange to get the <strong>unsteady Bernoulli equation for compressible flow</strong>: <span class=\"math display\">\\[\n\\color{purple}\\int_1^2\\frac{\\partial\\mathbf{V}}{\\partial t}ds+\\int_1^2\\frac{1}{\\rho}\\left(dp\\right)+ \\left(\\frac{1}{2} V_2^2-\\frac{1}{2} V_1^2\\right) + g(z_2-z_1)=0\n\\]</span> Plus the <strong>steady and incompressible</strong> conditions, the function reduced to the familiar expression: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{p}{\\rho}+\\frac{1}{2}V^2+gz = Const,~\\mathrm{~along~a~streamline}\n\\]</span> Plus the <strong>irrotational</strong> condition, the 3rd term remains 0 regardless the trajectory, the function becomes: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{p}{\\rho}+\\frac{1}{2}V^2+gz = Const,~\\mathrm{~everywhere}\n\\]</span></p>\n<h3 id=\"velocity-potential\">4.4 Velocity potential</h3>\n<p>Vector analysis tells us that if the curl of a vector field is zero then that vector field must itself be the gradient of a scalar function. That is,</p>\n<p>The function <span class=\"math inline\">\\(\\phi\\)</span> is called a potential function. <span class=\"math display\">\\[\n\\boldsymbol{\\nabla} \\times \\mathbf{V} \\equiv 0 \\quad \\Rightarrow \\quad \\mathbf{V}=\\boldsymbol{\\nabla} \\phi\n\\]</span> <div class=\"note note-info\">\n            <p>Velocity potential <span class=\"math inline\">\\(\\phi\\)</span> is another scalar function, a complementary to the <a href=\"#stream-function\">stream function</a> <span class=\"math inline\">\\(\\psi\\)</span>.</p><p>It is applicable only in <strong>irrotational</strong> flow.</p>\n          </div></p>\n<p>Some useful properties:</p>\n<ul>\n<li><p>In Cartesian coordinate, it reduce the 3 velocity components <span class=\"math inline\">\\(u\\)</span>, <span class=\"math inline\">\\(v\\)</span>, <span class=\"math inline\">\\(w\\)</span> into a single scalar: <span class=\"math display\">\\[\nu=\\frac{\\partial \\phi}{\\partial x} \\quad v=\\frac{\\partial \\phi}{\\partial y} \\quad w=\\frac{\\partial \\phi}{\\partial z}\n\\]</span></p></li>\n<li><p>Line of constant <span class=\"math inline\">\\(\\phi\\)</span> is called <em>potential lines</em>.</p>\n<p>In <strong>two-dimensional flow</strong>, potential lines are everywhere orthogonal to the streamlines, because: <span class=\"math display\">\\[\nu=\\frac{\\partial \\psi}{\\partial y}=\\frac{\\partial \\phi}{\\partial x} \\quad v=-\\frac{\\partial \\psi}{\\partial x}=\\frac{\\partial \\phi}{\\partial y}\n\\]</span> The dot-product of their gradients are: <span class=\"math display\">\\[\n\\left[\\frac{\\partial \\psi}{\\partial x} \\mathbf{i}+\\frac{\\partial \\psi}{\\partial y} \\mathbf{j}\\right] \\cdot\\left[\\frac{\\partial \\phi}{\\partial x} \\mathbf{i}+\\frac{\\partial \\phi}{\\partial y} \\mathbf{j}\\right]=u(-v)+u v \\equiv 0\n\\]</span></p></li>\n<li><p>If <span class=\"math inline\">\\(\\phi\\)</span> exists, substitute the definition into the unsteady Bernoulli equation, <span class=\"math display\">\\[\n\\frac{\\partial \\phi}{\\partial t}+\\int \\frac{d p}{\\rho}+\\frac{1}{2}|\\boldsymbol{\\nabla} \\phi|^{2}+g z=\\mathrm{const}\n\\]</span> <div class=\"note note-info\">\n            <p>It is an equation between just two scalar quantities, <span class=\"math inline\">\\(\\phi\\)</span> and <span class=\"math inline\">\\(p\\)</span>.</p>\n          </div></p></li>\n</ul>\n<h2 id=\"vortex-motion-and-applications\">5 Vortex Motion and Applications</h2>\n<p>Vortices are structures within the flow in which fluid is rotating about an axis line (which may be straight or curved). A <strong>vortex line</strong> is therefore defined as a line which is always in the same direction as the local vorticity vector <span class=\"math inline\">\\(\\boldsymbol{\\xi}\\)</span>.</p>\n<p><img src=\"Vortex line example.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Vortex line example (red line) from physics.stackexchange.com\" style=\"zoom:100%;\" /></p>\n<p>Similar to streamline, vortex lines <span class=\"math inline\">\\((x, y, z) = (x(s), y(s), z(s))\\)</span> are obtained by solving: <span class=\"math display\">\\[\n\\frac{dx/ds}{d\\xi_x}=\\frac{dy/ds}{d\\xi_y}=\\frac{dz/ds}{d\\xi_z}\n\\]</span> Similar to steam tube, vertex lines which pass through a closed curve in space form a <strong>vortex tube</strong>.</p>\n<h3 id=\"circulation\">5.1 Circulation</h3>\n<p><strong>Fluid circulation</strong> describes the strength of rotation, or strength of fluid swirling, within a closed contour <span class=\"math inline\">\\(C(t)\\)</span>. Mathematically it is defined as the integral of velocity along the contour curve: <span class=\"math display\">\\[\n\\Gamma=\\oint_{C(t)} \\mathbf{V} d s=\\int_{S} \\boldsymbol{\\xi} \\cdot \\boldsymbol{n} d S\n\\]</span></p>\n<h4 id=\"material-elements-and-its-motion\">5.1.1 Material elements and its motion</h4>\n<p>Consider how a infinitesimal displacement <span class=\"math inline\">\\(d\\mathbf{s}\\)</span> deforms over a small time <span class=\"math inline\">\\(dt\\)</span>, illustrated in the diagram below.</p>\n<p><img src=\"Displacement deformation.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Displacement deformation\" style=\"zoom:50%;\" /></p>\n<p>We have <span class=\"math inline\">\\(d(d\\mathbf{s})\\)</span> the <strong>material line element</strong>: <span class=\"math display\">\\[\n\\begin{aligned}\nd(d \\boldsymbol{s})=d \\boldsymbol{s}_{1}-d \\boldsymbol{s}_{0} &amp;=\\left(\\boldsymbol{x}+d \\boldsymbol{s}_{0}+\\mathbf{V}\\left(\\boldsymbol{x}+d \\boldsymbol{s}_{0}\\right) d t\\right)-(\\boldsymbol{x}+\\mathbf{V}(\\boldsymbol{x}) d t)-d \\boldsymbol{s}_{0} \\\\\n&amp;=\\left(\\mathbf{V}\\left(\\boldsymbol{x}+d \\boldsymbol{s}_{0}\\right)-\\mathbf{V}(\\boldsymbol{x})\\right) d t \\\\\n&amp;=d \\boldsymbol{s}_{0} \\frac{\\partial \\mathbf{V}}{\\partial\\left(d \\boldsymbol{s}_{0}\\right)} d t \\\\\n&amp;=d \\boldsymbol{s}_{0} \\cdot \\boldsymbol{\\nabla} \\mathbf{V} d t\n\\end{aligned}\n\\]</span> Therefore: <span class=\"math display\">\\[\n\\frac{D(d\\mathbf{s})}{Dt} = (ds\\cdot\\boldsymbol{\\nabla})\\mathbf{V}\n\\]</span></p>\n<h3 id=\"kelvins-circulation-theorem\">5.2 Kelvins Circulation Theorem</h3>\n<blockquote>\n<p>Kelvins Circulation Theorem status the expression of the rate of change of the circulation <span class=\"math inline\">\\(\\frac{D\\Gamma}{Dt}\\)</span> and determine how a circulation around a fluid loop varies as the loop moves with the flow. (<a href=\"https://youtu.be/q4xSUYZCj84\">reference</a>)</p>\n</blockquote>\n<p>Apply material derivative to circulation we have: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{D}{Dt}\\Gamma&amp;=\\frac{D}{Dt}\\oint_{C(t)} \\mathbf{V} d \\mathbf{s}    \\\\\n&amp;= \\oint_{C(t)}\\frac{D}{Dt}(\\mathbf{V} d \\mathbf{s} ) \\\\\n&amp;= \\oint_{C(t)}\\frac{D\\mathbf{V}}{Dt}\\cdot d \\mathbf{s}  + \\oint_{C(t)}\\mathbf{V}\\cdot \\frac{D(d \\mathbf{s})}{Dt}       \\\\\n\\end{aligned}\n\\]</span> Substitute material line element into the last term to get a scalar inside the loop integration, then we have: <span class=\"math display\">\\[\n\\frac{D}{Dt}\\Gamma = \\oint_{C(t)}\\frac{D\\mathbf{V}}{Dt}d \\mathbf{s}\n\\]</span> Recall the <a href=\"#general-differential-linear-momentum-equation\">general linear momentum equation</a> and substitute the material derivative of velocity: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{D}{Dt}\\Gamma &amp;= \\oint_{C(t)}\\left(\\mathbf{g} - \\frac{\\boldsymbol{\\nabla}p}{\\rho} + \\frac{\\boldsymbol{\\boldsymbol{\\nabla}\\cdot\\tau_{ij}}}{\\rho}\\right)d \\mathbf{s} \\\\\n&amp;= \\oint_{C(t)}\\mathbf{g}d \\mathbf{s}  - \\oint_{C(t)}\\frac{\\boldsymbol{\\nabla}p}{\\rho} d\\mathbf{s}   + \\oint_{C(t)}\\frac{\\boldsymbol{\\nabla}\\cdot\\boldsymbol{\\tau_{ij}}}{\\rho}d \\mathbf{s} \n\\end{aligned}\n\\]</span> This function is not zero unless:</p>\n<ul>\n<li>1<sup>st</sup> term: body force torque is zero, body force is <strong>irrotational</strong>, <span class=\"math inline\">\\(\\mathbf{g} = \\nabla\\phi\\)</span>, <span class=\"math inline\">\\(\\phi\\)</span> is a scalar.</li>\n<li>2<sup>nd</sup> term: <span class=\"math inline\">\\(p = p(\\rho)\\)</span> or <span class=\"math inline\">\\(\\rho = const.\\)</span>(<strong>incompressible and isotropic</strong>)</li>\n<li>3<sup>rd</sup> term: <strong>inviscid</strong>, <span class=\"math inline\">\\(\\boldsymbol{\\tau_{ij}}=0\\)</span></li>\n</ul>\n<h4 id=\"aerofoil-lift-and-kutta-joukowski-theorem\">5.2.1 Aerofoil lift and Kutta-Joukowski Theorem</h4>\n<p>One application of the Kelvin Circulation Theorem is in explaining the lift attained by an aerofoil during the shedding of the starting vortex.</p>\n<p>Consider a stationary aerofoil shown in the diagram below.</p>\n<p><img src=\"Aerofoil vortex shedding.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Aerofoil vortex shedding\" style=\"zoom:50%;\" /></p>\n<p>At time <span class=\"math inline\">\\(t = 0\\)</span>, the aerofoil is stationary, there is no vorticity and around the path <span class=\"math inline\">\\(C(t)\\)</span> the circulation is <span class=\"math inline\">\\(\\Gamma = 0\\)</span>. As the flow velocity increases, vorticity is shed behind the aerofoil leading to positive <span class=\"math inline\">\\(\\Gamma\\)</span>.</p>\n<p>By Kelvins circulation theorem, the circulation <span class=\"math inline\">\\(\\Gamma_0\\)</span> around <span class=\"math inline\">\\(C(t)\\)</span> is independent of time. Therefore, there must be negative <span class=\"math inline\">\\(\\Gamma_1\\)</span> around the aerofoil, which leads to lift by the Kutta-Joukowski theorem (<span class=\"math inline\">\\(L&#39; = \\rho u\\Gamma\\)</span>).</p>\n<h3 id=\"helmholtz-theorems\">5.3 Helmholtz Theorems</h3>\n<p>Suppose we have an <strong>inviscid</strong>, <strong>incompressible</strong> fluid of <strong>constant density</strong> moving under a <strong>conservative body force</strong>, then</p>\n<ol type=\"1\">\n<li><p>The quantity <span class=\"math display\">\\[\n\\Gamma=\\int_{S} \\boldsymbol{\\xi} \\cdot \\boldsymbol{n} d S\n\\]</span> is the same for all cross-sections <span class=\"math inline\">\\(S\\)</span> of a vortex tube. i.e. the strength of a vortex is constant along the length of the vortex.</p></li>\n<li><p>A vortex filament cannot end in the fluid; it must extend to the boundaries of the fluid, infinity, or form a closed loop</p></li>\n<li><p>If fluid is initially irrotational, in the absense of rotational forces, it remains irrotational indefinitely.</p></li>\n</ol>\n<h4 id=\"vortex-rings\">5.3.1 Vortex rings</h4>\n<p>A vivid example of Helmholtzs theorems can be seen in vortex (smoke) rings. These are vortices in which the core vortex line forms a closed loop (theorem #2).</p>\n<p>Such vortices can retain their strength (theorem #1) and travel significant distances (the smoke is carried in the vortex).</p>\n","site":{"data":{}},"wordcount":37631,"excerpt":"<div class=\"note note-primary\">\n            <p>Feeling unsafe when deploying CFD algorithms, the best way to alleviate the anxiety is to derive the fundamentals again.</p>\n          </div>","more":"<h2 id=\"acceleration-and-mass-conservation\">1 Acceleration and Mass Conservation</h2>\n<h3 id=\"acceleration-field-of-a-fluid\">1.1 Acceleration field of a fluid</h3>\n<h4 id=\"material-substantial-convective-derivatives\">1.1.1 Material / substantial / convective derivatives</h4>\n<p><img src=\"Material derivatives.png\" alt=\"Material derivatives\" style=\"zoom:50%;\" /></p>\n<p>Given a spatial-temporal property <span class=\"math inline\">\\(f(x,y,z,t)\\)</span> of a fluid particle in the Eulerian coordinate. After an infinitesimal period, the change in <span class=\"math inline\">\\(f\\)</span> , is therefore: <span class=\"math display\">\\[\n\\begin{aligned}\n\\Delta f = f(x+\\Delta x,y+\\delta x,z+\\delta z,t+\\Delta t)- f(x,y,z,t) \n\\end{aligned}\n\\]</span> set the position and time change tend to 0, <span class=\"math display\">\\[\n\\Delta f = \\frac{\\partial f}{\\partial x}\\Delta x+\\frac{\\partial f}{\\partial y}\\Delta y+\\frac{\\partial f}{\\partial z}\\Delta z+\\frac{\\partial f}{\\partial t}\\Delta t\n\\]</span> considering: <span class=\"math display\">\\[\n\\Delta x = u \\Delta t, \\Delta y = v \\Delta t, \\Delta z = w \\Delta t\n\\]</span> then <span class=\"math display\">\\[\n\\frac{\\Delta f }{\\Delta t}=\\frac{\\partial f}{\\partial t} + \\frac{\\partial f}{\\partial x}u+\\frac{\\partial f}{\\partial y}v+\\frac{\\partial f}{\\partial z}w\n\\]</span> In the limit as <span class=\"math inline\">\\(\\Delta t \\rightarrow 0\\)</span>, <span class=\"math display\">\\[\n\\frac{D f }{D t}=\\frac{\\partial f}{\\partial t} + \\frac{\\partial f}{\\partial x}u+\\frac{\\partial f}{\\partial y}v+\\frac{\\partial f}{\\partial z}w\n\\]</span> or in a vector form: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{D f }{D t}=\\frac{\\partial f}{\\partial t} + \\mathbf{V} \\cdot \\boldsymbol{\\nabla} f\n\\]</span> In the scalar case <span class=\"math inline\">\\(\\boldsymbol{\\nabla} f\\)</span> is simply the gradient of a scalar, while in the vector case, <span class=\"math inline\">\\(\\boldsymbol{\\nabla} \\mathbf{f}\\)</span> is the covariant derivative of the vector.</p>\n<div class=\"note note-info\">\n            <p>Like the Reynolds Transport Theorem in the integral part, the material derivative connects the Lagrangian and Eulerian frame of references.</p>\n          </div>\n<h4 id=\"material-derivative-of-velocity\">1.1.2 Material derivative of velocity</h4>\n<p>Set <span class=\"math inline\">\\(f\\)</span> as <span class=\"math inline\">\\(\\mathbf{V}\\)</span> and the fluid acceleration as <span class=\"math inline\">\\(\\mathbf{a}\\)</span>, substitute to the formula above: <span class=\"math display\">\\[\n\\mathbf{a} = \\frac{D \\mathbf{V} }{D t}=\\underbrace{\\frac{\\partial \\mathbf{V}}{\\partial t}}_{\\text {local}} + \\underbrace{\\mathbf{V} \\cdot \\boldsymbol{\\nabla} \\mathbf{V}}_{\\text {convective}}\n\\]</span> where <span class=\"math inline\">\\(\\frac{\\partial \\mathbf{V}}{\\partial t}\\)</span> is called <strong>local acceleration</strong> while <span class=\"math inline\">\\((\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}\\)</span> is the <strong>convective acceleration</strong>.</p>\n<div class=\"note note-info\">\n            <p>It is also written as <span class=\"math inline\">\\(\\mathbf{a} = \\frac{D \\mathbf{V} }{D t}=\\frac{\\partial \\mathbf{V}}{\\partial t} + (\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}\\)</span>, but it's equivalent.</p>\n          </div>\n<h3 id=\"differential-equation-of-mass-conservation\">1.2 Differential equation of mass conservation</h3>\n<p>Take an infinitesimally small cubic control volume as below.</p>\n<p><img src=\"Differential mass conservation.png\" alt=\"Differential mass conservation\" style=\"zoom:50%;\" /></p>\n<p>With the integral form with one-dimensional assumption: <span class=\"math display\">\\[\n\\int_{C V} \\frac{\\partial \\rho}{\\partial t} d \\mathcal{V}+\\sum_{i}\\left(\\rho_{i} A_{i} V_{i}\\right)_{o u t}-\\sum_{i}\\left(\\rho_{i} A_{i} V_{i}\\right)_{i n}=0\n\\]</span></p>\n<ol type=\"1\">\n<li><p>Density can be considered uniform in the CV, <span class=\"math display\">\\[\n\\int_{C V} \\frac{\\partial \\rho}{\\partial t} d \\mathcal{V} = \\frac{\\partial \\rho}{\\partial t} dxdydz\n\\]</span></p></li>\n<li><p>Inlet mass flow in 3 directions <span class=\"math display\">\\[\n\\dot{m}_{x} = \\rho udydz, \\dot{m}_{y} = \\rho vdxdz, \\dot{m}_{z} = \\rho udxdy\n\\]</span></p></li>\n<li><p>Outlet mass flow in x direction particular <span class=\"math display\">\\[\n\\dot{m}_{x+dx} = \\left(\\rho u+\\frac{\\partial \\rho u}{\\partial x }dx\\right)dydz\n\\]</span></p></li>\n<li><p>Substitute all in the continuous function <span class=\"math display\">\\[\n\\frac{\\partial \\rho}{\\partial t} dxdydz +\\frac{\\partial \\rho u}{\\partial x}dxdydz +\\frac{\\partial \\rho v}{\\partial y}dxdydz +\\frac{\\partial \\rho w}{\\partial z}dxdydz  = 0\n\\]</span> simplify: <span class=\"math display\">\\[\n\\frac{\\partial \\rho}{\\partial t}  +\\frac{\\partial \\rho u}{\\partial x} +\\frac{\\partial \\rho v}{\\partial y} +\\frac{\\partial \\rho w}{\\partial z}  = 0\n\\]</span> or in the vector form: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial \\rho}{\\partial t}+\\boldsymbol{\\nabla} \\cdot(\\rho\\mathbf{V})=0\n\\]</span> <div class=\"note note-info\">\n            <p>The only requirements of this equation are the density <span class=\"math inline\">\\(\\rho\\)</span> and velocity <span class=\"math inline\">\\(\\mathbf{V}\\)</span> are continuous in time and space. As a result, this equation is always called the <em>equation of continuity</em>.</p>\n          </div></p></li>\n</ol>\n<h4 id=\"simplifications\">1.2.1 Simplifications</h4>\n<ul>\n<li><p>steady flow: <span class=\"math inline\">\\(\\partial/\\partial t = 0\\)</span>, <span class=\"math display\">\\[\n\\boldsymbol{\\nabla} \\cdot(\\rho\\mathbf{V})=0\n\\]</span></p></li>\n<li><p>Incompressible flow: <span class=\"math inline\">\\(\\rho = Const\\)</span> spacial and temporal:</p></li>\n</ul>\n<p><span class=\"math display\">\\[\n\\boldsymbol{\\nabla} \\cdot\\mathbf{V}=0\n\\]</span></p>\n<div class=\"note note-info\">\n            <p>It makes the equation linear and much more tractable to solving analytically.</p>\n          </div>\n<h3 id=\"cylindrical-coordinates\">1.3 Cylindrical coordinates</h3>\n<p><img src=\"Polar coordinate.png\" alt=\"Polar coordinate\" style=\"zoom:50%;\" /></p>\n<h4 id=\"transformation-of-coordinates\">1.3.1 Transformation of coordinates</h4>\n<p>From cartesian to cylindrical: <span class=\"math display\">\\[\nr=\\sqrt{x^{2}+y^{2}} \\quad \\theta=\\tan ^{-1} \\frac{y}{x} \\quad z=z\n\\]</span></p>\n<p>From cylindrical to cartesian: <span class=\"math display\">\\[\nx=r \\cos \\theta \\quad y=r \\sin \\theta \\quad z=z\n\\]</span></p>\n<h4 id=\"differential-operators\">1.3.2 Differential operators</h4>\n<p>Two differential operators in polar coordinate: <span class=\"math display\">\\[\n\\begin{aligned}\n\\boldsymbol{\\nabla} f &amp;=\\frac{\\partial f}{\\partial r} \\hat{\\boldsymbol{r}}+\\frac{1}{r} \\frac{\\partial f}{\\partial \\theta} \\hat{\\boldsymbol{\\theta}}+\\frac{\\partial f}{\\partial z} \\hat{\\boldsymbol{z}}\\\\\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} &amp;=\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r V_{r}\\right)+\\frac{1}{r} \\frac{\\partial}{\\partial \\theta}\\left(V_{\\theta}\\right)+\\frac{\\partial}{\\partial z}\\left(V_{z}\\right)\n\\end{aligned}\n\\]</span></p>\n<h4 id=\"continuous-function-in-cylindrical-coordinates\">6.3.3 Continuous function in cylindrical coordinates</h4>\n<p>It is easy to substitute the equation of divergence into the continuous function, <span class=\"math display\">\\[\n\\frac{\\partial \\rho}{\\partial t}+\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\rho V_{r}\\right)+\\frac{1}{r} \\frac{\\partial}{\\partial \\theta}\\left(\\rho V_{\\theta}\\right)+\\frac{\\partial}{\\partial z}\\left(\\rho V_{z}\\right)=0\n\\]</span></p>\n<h2 id=\"linear-momentum-and-energy\">2 Linear Momentum and Energy</h2>\n<h3 id=\"conservation-laws-from-differential-reynolds-transport-theorem\">2.1 Conservation laws from differential Reynolds transport theorem</h3>\n<p>Recall RTT on a fixed control volume <span class=\"math inline\">\\(\\Omega\\)</span>: <span class=\"math display\">\\[\n\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(B_{s}\\right)=\\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}+\\int_{\\partial \\Omega} \\beta \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> where <span class=\"math display\">\\[\n\\beta=\\frac{\\partial B}{\\partial m} \\quad \\Rightarrow \\quad B=\\int_{\\bar{\\Omega}} \\beta \\rho d \\mathcal{V}\n\\]</span> <span class=\"math inline\">\\(\\bar{\\Omega}\\)</span> denotes the control volume in a Lagrangian frame of reference (close system), while <span class=\"math inline\">\\(\\Omega\\)</span> denotes the control volume in an Eulerian frame of reference (open system).</p>\n<div class=\"note note-info\">\n            <p>Open system: matter and energy goes in and out</p><p>Close system: energy goes in and out while matter cannot</p><p>Isolated system: matter and energy cannot go in and out</p>\n          </div>\n<p>In the Lagrangian frame of reference, <span class=\"math display\">\\[\n\\frac{\\mathrm{d}}{\\mathrm{d} t}(B)=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{\\bar{\\Omega}} \\beta \\rho d \\mathcal{V}\\right)\\underbrace{=}_{Leibniz&#39;s Rule}\\int_{\\bar{\\Omega}} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}=\\int_{\\bar{\\Omega}} s d \\mathcal{V}\n\\]</span> <div class=\"note note-info\">\n            <p>Leibniz's rule: the derivative moves into the integral symbol: <span class=\"math display\">\\[\\frac{d}{d x}\\left(\\int_{a}^{b} f(x, t) d t\\right)=\\int_{a}^{b} \\frac{\\partial}{\\partial x} f(x, t) d t\\]</span></p>\n          </div></p>\n<p>Where <span class=\"math inline\">\\(s\\)</span> denotes the \"rate of change of <span class=\"math inline\">\\(B\\)</span> per unit volume\"</p>\n<p>Then the RTT is instead: <span class=\"math display\">\\[\n\\int_{\\bar{\\Omega}} s d \\mathcal{V} = \\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}+\\int_{\\partial \\Omega} \\beta \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> Use divergence theorem, drop the bar notation with <span class=\"math inline\">\\(\\Delta t \\rightarrow 0\\)</span>, and arrive a differential form: <span class=\"math display\">\\[\n\\begin{array}{r}\n\\int_{\\Omega} s d \\mathcal{V}=\\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t} d \\mathcal{V}+\\int_{\\Omega} \\boldsymbol{\\nabla}  \\cdot(\\beta \\rho \\mathbf{V}) d \\mathcal{V} \\\\\n\\int_{\\Omega} \\frac{\\partial(\\beta \\rho)}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\beta \\rho \\mathbf{V})-s d \\mathcal{V}=0 \\\\\n\\Leftrightarrow \\color{purple}{\\frac{\\partial(\\beta \\rho)}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\beta \\rho \\mathbf{V})-s=0}\n\\end{array}\n\\]</span> <div class=\"note note-info\">\n            <p>Divergence theorem: <span class=\"math display\">\\[\\int_{S} \\boldsymbol{\\nabla}  \\cdot \\mathbf{F} d A=\\int_{\\partial S} \\mathbf{F} \\cdot \\hat{\\mathbf{n}} d s\\]</span></p>\n          </div></p>\n<h4 id=\"continuity-equation-for-mass\">2.1.1 Continuity equation for mass</h4>\n<p>Substitute <span class=\"math inline\">\\(\\beta = 1\\)</span> and <span class=\"math inline\">\\(s=0\\)</span> (mass created = 0) into the differential RTT: <span class=\"math display\">\\[\n\\frac{\\partial(\\rho)}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V})=0\n\\]</span> and for incompressible flow: <span class=\"math display\">\\[\n\\boldsymbol{\\nabla}  \\cdot \\mathbf{V}=0\n\\]</span></p>\n<h4 id=\"continuity-equation-for-linear-momentum\">2.1.2 Continuity equation for linear momentum</h4>\n<p>Substitute <span class=\"math inline\">\\(\\beta =\\mathbf{V}\\)</span> into the differential RTT: <span class=\"math display\">\\[\n\\frac{\\partial(\\rho \\mathbf{V})}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V}\\otimes \\mathbf{V}) -\\mathbf{s} =0\n\\]</span> <span class=\"math inline\">\\(\\mathbf{s}\\)</span> denotes the force per unit volume, and $$ denotes the outer product.</p>\n<div class=\"note note-info\">\n            <p>Outer product or dyadic product follows: <span class=\"math display\">\\[\\left[\\begin{array}{c}u_{1} \\\\u_{2} \\\\\\vdots \\\\u_{m}\\end{array}\\right] \\otimes \\left[\\begin{array}{c}v_{1} \\\\v_{2} \\\\\\vdots \\\\v_{n}\\end{array}\\right]=\\left[\\begin{array}{cccc}u_{1} v_{1} &amp; u_{1} v_{2} &amp; \\ldots &amp; u_{1} v_{n} \\\\u_{2} v_{1} &amp; u_{2} v_{2} &amp; \\ldots &amp; u_{2} v_{n} \\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\u_{m} v_{1} &amp; u_{m} v_{2} &amp; \\ldots &amp; u_{m} v_{n}\\end{array}\\right]\\]</span> The divergence of a dyad follows this formula: <span class=\"math display\">\\[\\begin{aligned}&amp;\\boldsymbol{\\nabla}  \\cdot(f \\mathbf{a})=(\\boldsymbol{\\nabla}  f) \\cdot \\mathbf{a}+(\\boldsymbol{\\nabla}  \\cdot \\mathbf{a}) f \\\\&amp;\\boldsymbol{\\nabla}  \\cdot(\\mathbf{a b})=(\\boldsymbol{\\nabla}  \\cdot \\mathbf{a}) \\mathbf{b}+\\mathbf{a} \\cdot \\boldsymbol{\\nabla}  \\mathbf{b}\\end{aligned}\\]</span></p>\n          </div>\n<p>Expand the equation: <span class=\"math display\">\\[\n\\begin{aligned}\n\\rho \\frac{\\partial \\mathbf{V}}{\\partial t}+\\mathbf{V} \\frac{\\partial \\rho}{\\partial t}+\\mathbf{V V} \\cdot \\boldsymbol{\\nabla}  \\rho+\\rho \\mathbf{V} \\cdot \\boldsymbol{\\nabla}  \\mathbf{V}+\\rho \\mathbf{V} \\boldsymbol{\\nabla}  \\cdot \\mathbf{V} &amp;=\\mathbf{s} \\\\\n\\Leftrightarrow \\mathbf{V}\\left(\\frac{\\partial \\rho}{\\partial t}+\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  \\rho+\\rho(\\boldsymbol{\\nabla}  \\cdot \\mathbf{V})\\right)+\\rho\\left(\\frac{\\partial \\mathbf{V}}{\\partial t}+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla} ) \\mathbf{V}\\right) &amp;=\\mathbf{s}\n\\end{aligned}\n\\]</span> With <span class=\"math inline\">\\(\\mathbf{V} \\cdot \\boldsymbol{\\nabla} \\rho+\\rho(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})=\\boldsymbol{\\nabla} \\cdot(\\rho \\mathbf{V})\\)</span>, we have the first left term a continuity equation. Drop it we have: <span class=\"math display\">\\[\n\\mathbf{V}\\underbrace{\\left(\\frac{\\partial \\rho}{\\partial t}+\\boldsymbol{\\nabla}  \\cdot(\\rho \\mathbf{V})\\right)}_{0}+\n\\rho\\underbrace{\\left(\\frac{\\partial \\mathbf{V}}{\\partial t}+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla} ) \\mathbf{V}\\right)}_{\\mathrm{material~derivative}} =\\mathbf{s}\n\\]</span> With the definition of material derivative, <span class=\"math display\">\\[\n\\color{purple}\n\\rho\\left(\\frac{D \\mathbf{V}}{D t}\\right) =\\mathbf{s}\n\\]</span> Without source or sink, the quantity <span class=\"math inline\">\\(\\mathbf{s}\\)</span> therefore represents <strong>force per unit volume</strong> <span class=\"math inline\">\\(\\mathbf{s}=\\frac{\\mathrm{d} \\mathbf{F}}{\\mathrm{d} \\mathcal{V}}\\)</span>.</p>\n<h3 id=\"forces\">2.2 Forces</h3>\n<p>The forces contain <em>body forces</em> and <em>surface forces</em> <span class=\"math inline\">\\(\\mathbf{F}=\\mathbf{F_b}+\\mathbf{F_s}\\)</span>,</p>\n<ul>\n<li><p>Body forces are due to external fields, take gravitational force as an example, <span class=\"math display\">\\[\nd \\mathbf{F}_{g}=\\rho \\mathbf{g} d x d y d z \\quad \\mathbf{g}=-g \\mathbf{k}\n\\]</span> Consider the only body force in fluid dynamic is the gravity: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\mathrm{d}\\mathbf{F_b}}{\\mathrm{d}\\mathcal{V}} = \\rho\\mathbf{g}\n\\]</span></p></li>\n<li><p>Surface forces are due to hydrostatic pressure and viscous stresses on the <em>CS</em>: <span class=\"math display\">\\[\n\\sigma_{i j}=\\left|\\begin{array}{ccc}\n-p+\\tau_{x x} &amp; \\tau_{y x} &amp; \\tau_{z x} \\\\\n\\tau_{x y} &amp; -p+\\tau_{yy} &amp; \\tau_{z y} \\\\\n\\tau_{x z} &amp; \\tau_{y z} &amp; -p+\\tau_{z z}\n\\end{array}\\right|\n\\]</span> <img src=\"Viscous stress on CS.png\" alt=\"Stress on CS\" style=\"zoom:50%;\" /></p>\n<p>Similar to what we do in the <a href=\"#differential-equation-of-mass-conservation\">Mass Conservation</a>, the force is due to the stress change in each direction, for instance: <span class=\"math display\">\\[\ndF{s,xx} = \\left(\\sigma_{xx}+\\frac{\\partial\\sigma_{xx}}{\\partial x}dx\\right)dydz-\\sigma_{xx}dydz = \\frac{\\partial\\sigma_{xx}}{\\partial x}d\\mathcal{V}\n\\]</span> <img src=\"Surface forces on CS.png\" alt=\"Surface forces on CS\" style=\"zoom:50%;\" /></p>\n<p>as a result: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\frac{\\mathrm{d} F_{x}}{\\mathrm{~d} \\mathcal{V}}=-\\frac{\\partial p}{\\partial x}+\\frac{\\partial \\tau_{x x}}{\\partial x}+\\frac{\\partial \\tau_{y x}}{\\partial y}+\\frac{\\partial \\tau_{z x}}{\\partial z} \\\\\n&amp;\\frac{\\mathrm{d} F_{y}}{\\mathrm{~d} \\mathcal{V}}=-\\frac{\\partial p}{\\partial y}+\\frac{\\partial \\tau_{x y}}{\\partial x}+\\frac{\\partial \\tau_{y y}}{\\partial y}+\\frac{\\partial \\tau_{z y}}{\\partial z} \\\\\n&amp;\\frac{\\mathrm{d} F_{z}}{\\mathrm{~d} \\mathcal{V}}=-\\frac{\\partial p}{\\partial z}+\\frac{\\partial \\tau_{x z}}{\\partial x}+\\frac{\\partial \\tau_{y z}}{\\partial y}+\\frac{\\partial \\tau_{z z}}{\\partial z}\n\\end{aligned}\n\\]</span> surface force in vector form: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\mathrm{d} \\mathbf{F_s}}{\\mathrm{d} \\mathcal{V}}=- \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}}\n\\]</span> <span class=\"math inline\">\\(\\frac{\\mathrm{d} \\mathbf{F_s}}{\\mathrm{d} \\mathcal{V}}\\)</span> also represents the Cauchy stress tensor:</p></li>\n</ul>\n<h3 id=\"general-differential-linear-momentum-equation\">2.3 General differential linear momentum equation</h3>\n<p>Substitute force terms into earlier momentum conservation expression, <span class=\"math display\">\\[\n\\color{purple}\n\\rho\\frac{D \\mathbf{V}}{D t} = \\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\mathbf{\\tau_{ij}}\n\\]</span></p>\n<p><span class=\"math display\">\\[\n\\mathrm{density  acceleration = (Gravity + Pressure + Viscous) ~forces~per~unit~volume}\n\\]</span></p>\n<p>These equations are valid for any fluid in general motion, particularly those which include viscous stresses. The non-linear convective terms on the left-hand side also complicates direct mathematical analysis.</p>\n<h3 id=\"differential-energy-equations\">2.4 Differential energy equations</h3>\n<p>Similar to earlier routes, we arrive energy conservation equation: <span class=\"math display\">\\[\n\\dot{Q}-\\dot{W}_{v}=\\left(\\rho \\frac{D e}{D t}+\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  p+p \\boldsymbol{\\nabla}  \\cdot \\mathbf{V}\\right) \\mathrm{d}\\mathcal{V}\n\\]</span> Note that <span class=\"math inline\">\\(\\dot{W}_{s} = 0\\)</span> since there is no shaft work in an infinitesimal CV, as a result, similar CV flux analysis can be done to <span class=\"math inline\">\\(\\dot{Q}\\)</span> and <span class=\"math inline\">\\(\\dot{W}_{v}\\)</span>:</p>\n<ul>\n<li><p>Heat conduction <span class=\"math inline\">\\(\\dot{Q}\\)</span> is regulated by <strong>Fourier's law</strong> stating that the heat flux is proportional to the gradient of the temperature, <span class=\"math inline\">\\(\\mathbf{q} = K\\boldsymbol{\\nabla}T\\)</span>, using similar flux analysis to infinitesimal CV <span class=\"math display\">\\[\n\\dot{Q}=\\boldsymbol{\\nabla}  \\cdot(k \\boldsymbol{\\nabla}   T)\\mathrm{d}\\mathcal{V}\n\\]</span></p></li>\n<li><p>Similarly, the rate of work due to viscous stresses can be expanded to give: <span class=\"math display\">\\[\n\\dot{W}_{v}=-\\boldsymbol{\\nabla} \\cdot\\left(\\mathbf{V} \\cdot \\boldsymbol{\\tau}_{i j}\\right)\\mathrm{d}\\mathcal{V}\n\\]</span></p></li>\n</ul>\n<p>Substitute into energy conservation equation to give: <span class=\"math display\">\\[\n\\rho \\frac{D e}{D t}+\\mathbf{V} \\cdot \\boldsymbol{\\nabla}  p+p \\boldsymbol{\\nabla}  \\cdot \\mathbf{V}\n=\n\\boldsymbol{\\nabla}  \\cdot(k \\boldsymbol{\\nabla}   T)\n+\\boldsymbol{\\nabla} \\cdot\\left(\\mathbf{V} \\cdot \\boldsymbol{\\tau}_{i j}\\right)\n\\]</span></p>\n<h4 id=\"general-energy-equation\">2.4.1 General energy equation</h4>\n<p>Splitting the viscous work term: <span class=\"math display\">\\[\n\\boldsymbol{\\nabla} \\cdot\\left(\\mathbf{V} \\cdot \\boldsymbol{\\tau}_{i j}\\right) \\equiv \\mathbf{V} \\cdot \\left( \\boldsymbol{\\nabla} \\cdot \\boldsymbol{\\tau_{ij}} \\right) + \\underbrace{\\boldsymbol{\\tau_{ij}} : \\left( \\boldsymbol{\\nabla}\\mathbf{V} \\right)}_{\\boldsymbol{\\Phi}}\n\\]</span> where <span class=\"math inline\">\\(\\boldsymbol{\\Phi}\\)</span> denotes the <strong>viscous-dissipation function</strong>, representing the dissipation of energy due to viscous effects. For <strong>Newtonian flow in a Cartesian coordinates</strong>: <span class=\"math display\">\\[\n\\boldsymbol{\\Phi}=\\mu\\left[2\\left(\\frac{\\partial u}{\\partial x}\\right)^{2}+2\\left(\\frac{\\partial v}{\\partial y}\\right)^{2}+2\\left(\\frac{\\partial w}{\\partial z}\\right)^{2}+\\left(\\frac{\\partial v}{\\partial x}+\\frac{\\partial u}{\\partial y}\\right)^{2}+\\left(\\frac{\\partial w}{\\partial y}+\\frac{\\partial v}{\\partial z}\\right)^{2}+\\left(\\frac{\\partial u}{\\partial z}+\\frac{\\partial w}{\\partial x}\\right)^{2}\\right]\n\\]</span> <div class=\"note note-info\">\n            <p>Dissipated energy means during the flow, it is converted into the internal energy of the material. Note <span class=\"math inline\">\\(\\boldsymbol{\\Phi}\\)</span> is always positive, implying that viscous flow always loses energy.</p>\n          </div></p>\n<p>Expanding <span class=\"math inline\">\\(e = \\hat{u}+\\frac{1}{2}V^{2}+gz\\)</span>, the general differential energy equation is : <span class=\"math display\">\\[\n\\color{purple}\n\\rho \\frac{D \\hat{u}}{D t}+p(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})=\\boldsymbol{\\nabla} \\cdot(k \\boldsymbol{\\nabla} T)+\\mathbf{\\Phi}\n\\]</span> with further assumptions: <span class=\"math display\">\\[\n\\begin{aligned}\nd \\hat{u} &amp; \\approx c_{v} d T \\\\\nc_{v}, \\mu, k, \\rho &amp; \\approx \\mathrm{const}\n\\end{aligned}\n\\]</span> for incompressible flow, we have: <span class=\"math display\">\\[\n\\color{purple}{\\rho c_{v} \\frac{\\partial T}{\\partial t} =\\cdot(k \\boldsymbol{\\nabla}^2 T)+\\mathbf{\\Phi}}\n\\]</span></p>\n<h2 id=\"euler-and-navier-stokes-equations\">3 Euler and Navier-Stokes Equations</h2>\n<p>Recall <a href=\"#general-differential-linear-momentum-equation\">differential linear momentum equation</a>: <span class=\"math display\">\\[\n\\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}} = \\rho\\frac{D \\mathbf{V}}{D t}\n\\]</span> Equations of motion of <span class=\"math inline\">\\(\\boldsymbol{\\tau_{ij}}\\)</span> is still needed, and its different depending on types of fluid</p>\n<h3 id=\"euler-equations-frictionless-flow\">3.1 Euler equations (frictionless flow)</h3>\n<p>Use the inviscid flow assumption, that is <span class=\"math inline\">\\(\\boldsymbol{\\tau_{ij}}=0\\)</span>, the momentum equation reduces to: <span class=\"math display\">\\[\n\\color{purple}\n\\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}} = \\rho\\frac{D \\mathbf{V}}{D t}\n\\]</span> <div class=\"note note-info\">\n            <p>Fluids with low viscosity can be reasonably modelled as inviscid, except near boundaries.</p>\n          </div></p>\n<h3 id=\"newtonian-fluid\">3.2 Newtonian fluid</h3>\n<h4 id=\"strain\">3.2.1 Strain</h4>\n<p>Strains of a fluid particle evaluate the deformation due to an applied <em>shear stress</em>.</p>\n<p><img src=\"Fluid partical deformation.png\" alt=\"Fluid partical deformation\" style=\"zoom:50%;\" /></p>\n<p>and strain is defined as (anticlockwise positive): <span class=\"math display\">\\[\n\\mathrm{strain_{xy}} = \\Delta\\theta_x-(-\\Delta\\theta_y)\n\\]</span> In a continuous system, the rate of strain is then: <span class=\"math display\">\\[\n\\frac{\\mathrm{d}}{\\mathrm{d}t}(\\mathrm{strain_{xy}}) = \\epsilon_{xy} = \\frac{\\partial v}{\\partial x} + \\frac{\\partial u}{\\partial y}\n\\]</span> or in vector form: <span class=\"math display\">\\[\n\\boldsymbol{\\epsilon} = \\nabla \\mathbf{V}+(\\nabla \\mathbf{V}^{\\top})\n\\]</span></p>\n<h4 id=\"viscosity\">3.2.2 Viscosity</h4>\n<p>Newton defined a <strong>newtonian fluid</strong> by a fluid in which the <em>viscous stresses</em> are linearly proportional to the local <em>strain rates</em>. <span class=\"math display\">\\[\n\\boldsymbol{\\tau_{ij}} \\propto \\boldsymbol{\\epsilon_{ij}}\n\\]</span> In order to apply this to the NaiverStokes equations, three assumptions were made by Stokes:</p>\n<ul>\n<li>The stress tensor is a linear function of the strain rate tensor or equivalently the velocity gradient.</li>\n<li>The fluid is isotropic.</li>\n<li>For a fluid at rest, <span class=\"math inline\">\\(\\boldsymbol{\\nabla} \\cdot\\boldsymbol{\\tau_{ij}} = 0\\)</span> (so that hydrostatic pressure results).</li>\n</ul>\n<p>And it leads to: <span class=\"math display\">\\[\n\\color{purple}\n\\boldsymbol{\\tau}=\\mu\\left(\\nabla \\mathbf{u}+\\nabla \\mathbf{u}^{\\top}\\right)+\\lambda(\\nabla \\cdot \\mathbf{u}) \\mathbf{I}\n\\]</span> or <span class=\"math display\">\\[\n\\boldsymbol{\\tau_{ij}}=\\mu\\left(\\frac{\\partial u_{i}}{\\partial x_{j}}+\\frac{\\partial u_{j}}{\\partial x_{i}}\\right)+\\delta_{i j} \\lambda \\frac{\\partial u_{k}}{\\partial x_{k}} \\\\\n\\]</span> where, <span class=\"math display\">\\[\n\\delta_{i j}= \\begin{cases}0 &amp; \\text { if } i \\neq j \\\\ 1 &amp; \\text { if } i=j\\end{cases}\n\\]</span> As a result, expand the formula: <span class=\"math display\">\\[\n\\boldsymbol{\\tau_{ij}}=\\left|\\begin{array}{ccc}\n2 \\mu \\frac{\\partial u}{\\partial x}+\\lambda \\frac{\\partial u_{}}{\\partial x_{k}} &amp; \\mu\\left(\\frac{\\partial u}{\\partial y}+\\frac{\\partial v}{\\partial x}\\right) &amp; \\mu\\left(\\frac{\\partial u}{\\partial z}+\\frac{\\partial w}{\\partial x}\\right) \\\\\n\\mu\\left(\\frac{\\partial v}{\\partial x}+\\frac{\\partial u}{\\partial y}\\right) &amp; 2 \\mu \\frac{\\partial v}{\\partial y}+\\lambda \\frac{\\partial v}{\\partial y} &amp; \\mu\\left(\\frac{\\partial v}{\\partial z}+\\frac{\\partial w}{\\partial y}\\right) \\\\\n\\mu\\left(\\frac{\\partial w}{\\partial x}+\\frac{\\partial u}{\\partial z}\\right) &amp; \\mu\\left(\\frac{\\partial w}{\\partial y}+\\frac{\\partial v}{\\partial z}\\right) &amp; 2 \\mu \\frac{\\partial w}{\\partial z}+\\lambda \\frac{\\partial w}{\\partial z}\n\\end{array}\\right|\n\\]</span> And <span class=\"math inline\">\\(\\mu\\)</span> and <span class=\"math inline\">\\(\\lambda\\)</span> represents the <strong>shear/dynamic viscosity</strong> and <strong>volume/bulk viscosity</strong> respectively,</p>\n<blockquote>\n<p>The value of <em></em>, which produces a viscous effect associated with volume change, is very difficult to determine, not even its sign is known with absolute certainty. Even in compressible flows, the term involving <em></em> is often negligible; however it can occasionally be important even in nearly incompressible flows and is a matter of controversy. When taken nonzero, the most common approximation is <strong><em></em>  2/3<em></em></strong>.</p>\n</blockquote>\n<h3 id=\"navier-stokes-equations\">3.3 Navier-Stokes equations</h3>\n<p>Substitute the stress representation into the linear momentum equation: <span class=\"math display\">\\[\n\\rho\\frac{D \\mathbf{V}}{D t} = \\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot \\mu\\left( \\left(\\boldsymbol{\\nabla} \\mathbf{V}+\\boldsymbol{\\nabla} \\mathbf{V}^{\\top}\\right)-\\frac{2}{3}(\\nabla \\cdot \\mathbf{V}) \\mathbf{I}\\right)\n\\]</span> with further simplification we have: <span class=\"math display\">\\[\n\\color{purple}\n\\rho \\frac{\\mathrm{D} \\mathbf{V}}{\\mathrm{D} t}=\\rho\\left(\\frac{\\partial \\mathbf{V}}{\\partial t}+\\mathbf{V} \\cdot \\nabla \\mathbf{V}\\right)=-\\nabla p+\\mu \\nabla^{2} \\mathbf{V}+\\frac{1}{3} \\mu \\nabla(\\nabla \\cdot \\mathbf{V})+\\rho \\mathbf{g}\n\\]</span></p>\n<h4 id=\"incompressible-navier-stokes-equations\">3.3.1 Incompressible Navier-Stokes equations</h4>\n<p>With incompressible flow we have no bulk viscosity so: <span class=\"math display\">\\[\n\\boldsymbol{\\tau}=\\mu\\left(\\nabla \\mathbf{u}+\\nabla \\mathbf{u}^{\\top}\\right)\n\\]</span> And the Incompressible Navier-Stokes equations is therefore: <span class=\"math display\">\\[\n\\rho\\frac{D \\mathbf{V}}{D t} = \\rho\\mathbf{g} - \\boldsymbol{\\nabla}  p+ \\boldsymbol{\\nabla} \\cdot \\mu\\left( \\boldsymbol{\\nabla} \\mathbf{V}+\\boldsymbol{\\nabla} \\mathbf{V}^{\\top}\\right)\n\\]</span> with <span class=\"math inline\">\\(\\boldsymbol{\\nabla} \\cdot \\mathbf{V}=0\\)</span> for incompressible flow: <span class=\"math display\">\\[\n\\boldsymbol{\\nabla} \\cdot \\mu\\left( \\boldsymbol{\\nabla} \\mathbf{V}+\\boldsymbol{\\nabla} \\mathbf{V}^{\\top}\\right) = \\mu\\boldsymbol{\\nabla}^2\\mathbf{V}\n\\]</span> as a result: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial\\mathbf{V}}{\\partial t} +  \\mathbf{V} \\cdot \\nabla \\mathbf{V}= \\mathbf{g} - \\boldsymbol{\\nabla}\\frac{p}{\\rho} +  \\nu\\boldsymbol{\\nabla}^2\\mathbf{V}\n\\]</span> where <span class=\"math inline\">\\(\\nu = \\frac{\\mu}{\\rho}\\)</span>, called <strong>kinetic viscosity</strong></p>\n<div class=\"note note-info\">\n            <p>Meaning of each term: <span class=\"math display\">\\[\\overbrace{\\underbrace{\\frac{\\partial \\mathbf{V}}{\\partial t}}_{\\text {Variation }}+\\underbrace{(\\mathbf{V} \\cdot \\nabla) \\mathbf{V}}_{\\text {Convection }}}^{\\text {Inertia (per volume) }}= \\overbrace{\\underbrace{\\nu \\nabla^{2} \\mathbf{V}}_{\\text {Diffusion }}\\underbrace{-\\nabla w}_{\\begin{array}{c}\\text { Internal } \\\\\\text { source }\\end{array}}}^{\\text {Divergence of stress }}+\\underbrace{\\mathbf{g}}_{\\begin{array}{c}\\text { External } \\\\\\text { source }\\end{array}} .\\]</span></p>\n          </div>\n<p>Expanding along every coordinates gives that: <span class=\"math display\">\\[\n\\begin{align}\n\\frac{\\partial u}{\\partial t} +  u \\frac{\\partial u}{\\partial x} + v\\frac{\\partial u}{\\partial y} + w \\frac{\\partial u}{\\partial z}&amp;= g_x - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial x} +  \\nu\\left(\\frac{\\partial^2u}{\\partial^2x}+\\frac{\\partial^2u}{\\partial^2y}+\\frac{\\partial^2u}{\\partial^2z}\\right) \\\\\n\\frac{\\partial v}{\\partial t} +  u \\frac{\\partial v}{\\partial x} + v\\frac{\\partial v}{\\partial y} + w \\frac{\\partial v}{\\partial z}&amp;= g_y - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial y} +  \\nu\\left(\\frac{\\partial^2v}{\\partial^2x}+\\frac{\\partial^2v}{\\partial^2y}+\\frac{\\partial^2v}{\\partial^2z}\\right) \\\\\n\\frac{\\partial w}{\\partial t} +  u \\frac{\\partial w}{\\partial x} + v\\frac{\\partial w}{\\partial y} + w \\frac{\\partial w}{\\partial z}&amp;= g_z - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial z} +  \\nu\\left(\\frac{\\partial^2w}{\\partial^2x}+\\frac{\\partial^2w}{\\partial^2y}+\\frac{\\partial^2w}{\\partial^2z}\\right)\n\\end{align}\n\\]</span></p>\n<h4 id=\"cylindrical-coordinates-1\">3.3.2 Cylindrical coordinates</h4>\n<p>Recall the coordinates transformation: <span class=\"math display\">\\[\nr=\\sqrt{x^{2}+y^{2}} \\quad \\theta=\\tan ^{-1} \\frac{y}{x} \\quad z=z\n\\]</span> and the differential operators: <span class=\"math display\">\\[\n\\begin{aligned}\n\\boldsymbol{\\nabla} f &amp;=\\frac{\\partial f}{\\partial r} \\hat{\\boldsymbol{r}}+\\frac{1}{r} \\frac{\\partial f}{\\partial \\theta} \\hat{\\boldsymbol{\\theta}}+\\frac{\\partial f}{\\partial z} \\hat{\\boldsymbol{z}}\\\\\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} &amp;=\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r V_{r}\\right)+\\frac{1}{r} \\frac{\\partial}{\\partial \\theta}\\left(V_{\\theta}\\right)+\\frac{\\partial}{\\partial z}\\left(V_{z}\\right)\\\\\n\\boldsymbol{\\nabla}^2f &amp;= \\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial f}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} f}{\\partial \\theta^{2}}+\\frac{\\partial^{2} f}{\\partial z^{2}}\\right)\n\\end{aligned}\n\\]</span> And in z direction <span class=\"math display\">\\[\n\\begin{align}\n\\frac{\\partial V_r}{\\partial t} +  V_r \\frac{\\partial V_r}{\\partial r} + V_\\theta\\frac{1}{r}\\frac{\\partial V_r}{\\partial \\theta} + V_z \\frac{\\partial V_r}{\\partial z}&amp;= g_r - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial r} +  \\nu\\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial V_{r}}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} V_{r}}{\\partial \\theta^{2}}+\\frac{\\partial^{2} V_{r}}{\\partial z^{2}}\\right) \\\\\n\\frac{\\partial V_\\theta}{\\partial t} +  V_r \\frac{\\partial  V_\\theta}{\\partial r} + V_\\theta\\frac{1}{r}\\frac{\\partial  V_\\theta}{\\partial \\theta} + V_z \\frac{\\partial  V_\\theta}{\\partial z}&amp;= g_\\theta - \\frac{1}{\\rho r}\\frac{\\partial p}{\\partial \\theta} +    \\nu\\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial V_{\\theta}}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} V_{\\theta}}{\\partial \\theta^{2}}+\\frac{\\partial^{2} V_{\\theta}}{\\partial z^{2}}\\right) \\\\\n\\frac{\\partial V_z}{\\partial t} +  V_r \\frac{\\partial V_r}{\\partial r} + V_\\theta\\frac{1}{r}\\frac{\\partial V_z}{\\partial \\theta} + V_z \\frac{\\partial V_z}{\\partial z}&amp;= g_z - \\frac{1}{\\rho}\\frac{\\partial p}{\\partial z} +  \\nu\\left(\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial V_{z}}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} V_{z}}{\\partial \\theta^{2}}+\\frac{\\partial^{2} V_{z}}{\\partial z^{2}}\\right)\n\\end{align}\n\\]</span></p>\n<h3 id=\"closing-the-system\">3.3 Closing the system</h3>\n<p>To summarise, the 3 main functions are: <span class=\"math display\">\\[\n\\begin{aligned} \\frac{\\partial \\rho}{\\partial t}+\\nabla \\cdot(\\rho\\mathbf{V}) &amp;=0 &amp; &amp; \\text { continuity } \\\\ \\rho \\mathbf{g}-\\nabla p+\\boldsymbol{\\nabla} \\cdot \\boldsymbol{\\tau}_{i j} &amp;=\\rho \\frac{D \\mathbf{V}}{D t} &amp; &amp; \\text { momentum } \\\\ \\rho \\frac{D \\hat{u}}{D t}=p(\\boldsymbol{\\nabla} \\cdot \\mathbf{V}) &amp;=\\boldsymbol{\\nabla} \\cdot(k \\boldsymbol{\\nabla} T)+\\mathbf{\\Phi} &amp; &amp; \\text { energy } \\end{aligned}\n\\]</span> Note that there are five unknowns <span class=\"math inline\">\\(\\rho,\\mathbf{V}, p, \\hat{u},T\\)</span>, but only three equations. Additional equations are state relations for the thermodynamic properties of the fluid. For example for perfect gas: <span class=\"math display\">\\[\n\\rho=\\frac{p}{R T} \\quad \\hat{u}=\\int c_{v} d T\n\\]</span> The system of equations is now well-posed and can be solved, subject to <em>boundary conditions.</em></p>\n<h4 id=\"incompressible-system\">3.3.1 Incompressible system</h4>\n<p>We have: <span class=\"math display\">\\[\n\\begin{aligned}\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} &amp;=0 \\\\\n\\rho \\frac{D \\mathbf{V}}{D t} &amp;=\\rho \\boldsymbol{g}-\\nabla p+\\mu \\nabla^{2} \\mathbf{V} \\\\\n\\rho c_{p} \\frac{D T}{D t} &amp;=k \\nabla^{2} T+\\mathbf{\\Phi}\n\\end{aligned}\n\\]</span> Note that for incompressible flow, <span class=\"math inline\">\\(\\rho,\\mu,k\\)</span> are constants, only 3 unknowns are left <span class=\"math inline\">\\(p, \\mathbf{V}, T\\)</span>. So the incompressible system is already closed. Besides, continuity and momentum equations are independent of the <span class=\"math inline\">\\(T\\)</span>, thus decouple from the energy equation.</p>\n<h3 id=\"boundary-conditions\">3.4 Boundary conditions</h3>\n<ul>\n<li>Wall: these are typically solid, impermeable and there is a no-slip condition at the wall.</li>\n<li>Inlet: known velocity <span class=\"math inline\">\\(\\mathbf{V}\\)</span> and pressure <span class=\"math inline\">\\(p\\)</span> (and temperature <span class=\"math inline\">\\(T\\)</span>)</li>\n</ul>\n<h3 id=\"stream-function\">3.5 Stream function</h3>\n<p>Stream function provides a mathematical tool to automatically satisfy the continuity constraint, after which we can then solve the momentum equation.</p>\n<div class=\"note note-info\">\n            <p>It is only applicable to flows which are <strong>steady</strong>, <strong>incompressible</strong> and <strong>two-dimensional</strong>.</p>\n          </div>\n<p>With continuity equation: <span class=\"math display\">\\[\n\\boldsymbol{\\nabla}\\cdot\\mathbf{V} = 0 \\Leftrightarrow \\frac{\\partial u }{\\partial x} + \\frac{\\partial v}{\\partial y} = 0\n\\]</span> We seek to replace the velocity components <span class=\"math inline\">\\(u\\)</span> and <span class=\"math inline\">\\(v\\)</span> with a scalar function <span class=\"math inline\">\\(\\psi(x,y)\\)</span>, which satisfies the above constraint: <span class=\"math display\">\\[\n\\frac{\\partial}{\\partial x}\\left(\\frac{\\partial \\psi}{\\partial y}\\right)  + \\frac{\\partial}{\\partial y}\\left(-\\frac{\\partial \\psi}{\\partial x}\\right) \\equiv 0\n\\]</span> As a result: <span class=\"math display\">\\[\nu=\\frac{\\partial \\psi}{\\partial y} \\qquad v=-\\frac{\\partial \\psi}{\\partial x}\n\\]</span></p>\n<h4 id=\"properties-of-stream-function\">3.5.1 Properties of stream function</h4>\n<ul>\n<li>Recall the definition of a streamline:</li>\n</ul>\n<p><span class=\"math display\">\\[\n\\begin{align}\n&amp; \\frac{dy}{v} = \\frac{dx}{u} \\\\\n\\Leftrightarrow\\quad &amp; \\frac{\\partial \\psi}{\\partial y}u+\\frac{\\partial \\psi}{\\partial x}v=0 \\\\\n\\Leftrightarrow\\quad &amp; d\\psi=0 \\\\\n\\Leftrightarrow\\quad &amp; \\psi=Const\n\\end{align}\n\\]</span></p>\n<ul>\n<li><p>The change of <span class=\"math inline\">\\(\\psi\\)</span> across a control surface of unit depth is equal to the volume flow through the surface</p>\n<p><img src=\"Stream function property.png\" alt=\"Stream function property\" style=\"zoom:50%;\" /> <span class=\"math display\">\\[\n\\begin{aligned}\nd Q &amp;=(\\mathbf{V} \\cdot \\boldsymbol{n}) d A \\\\\n&amp;=\\left(\\boldsymbol{i} \\frac{\\partial \\psi}{\\partial y}-\\boldsymbol{j} \\frac{\\partial \\psi}{\\partial x}\\right) \\cdot\\left(\\boldsymbol{i} \\frac{\\mathrm{d} y}{\\mathrm{~d} s}-\\boldsymbol{j} \\frac{\\mathrm{d} x}{\\mathrm{~d} s}\\right) d s \\\\\n&amp;=\\frac{\\partial \\psi}{\\partial x} d x+\\frac{\\partial \\psi}{\\partial y} d y \\\\\n&amp;=d \\psi\n\\end{aligned}\n\\]</span></p></li>\n<li><p>The flow direction can be determined by observing whether <span class=\"math inline\">\\(\\psi\\)</span> increases or decreases</p>\n<p><img src=\"Flow direction based on stream function.png\" alt=\"Flow direction based on stream function\" style=\"zoom:50%;\" /></p></li>\n</ul>\n<h2 id=\"vorticity-and-irrotationality\">4 Vorticity and Irrotationality</h2>\n<h3 id=\"vorticity\">4.1 Vorticity</h3>\n<p>Recall how a fluid particle deforms under shear stresses:</p>\n<p><img src=\"Fluid particle deformation.png\" alt=\"Fluid particle deformation\" style=\"zoom:50%;\" /></p>\n<p>The angular velocity <span class=\"math inline\">\\(\\omega_z\\)</span> is defined as the average rate of counter-clockwise turning of the two sides: <span class=\"math display\">\\[\n\\omega_z = \\frac{1}{2}\\left(\\frac{\\mathrm{d}(\\Delta\\theta_x)}{\\mathrm{d}t}+\\frac{\\mathrm{d}(\\Delta\\theta_y)}{\\mathrm{d}t}\\right) =\\frac{1}{2}\\left(\\frac{\\partial v}{\\partial x}-\\frac{\\partial u}{\\partial y}\\right)\n\\]</span> Similarly, <span class=\"math display\">\\[\n\\omega_{x}=\\frac{1}{2}\\left(\\frac{\\partial w}{\\partial y}-\\frac{\\partial v}{\\partial z}\\right) \\quad \\omega_{y}=\\frac{1}{2}\\left(\\frac{\\partial u}{\\partial z}-\\frac{\\partial w}{\\partial x}\\right)\n\\]</span> Combine together the angular velocity: <span class=\"math display\">\\[\n\\boldsymbol{\\omega}=\\frac{1}{2}(\\underbrace{\\boldsymbol{\\nabla} \\times \\mathbf{V}}_{\\text {curl } \\mathbf{V}})=\\frac{1}{2}\\left|\\begin{array}{ccc}\n\\mathbf{i} &amp; \\mathbf{j} &amp; \\mathbf{k} \\\\\n\\frac{\\partial}{\\partial x} &amp; \\frac{\\partial}{\\partial y} &amp; \\frac{\\partial}{\\partial z} \\\\\nu &amp; v &amp; w\n\\end{array}\\right|\n\\]</span> And the vorticity is defined as twice the angular velocity i.e. curl of velocity: <span class=\"math display\">\\[\n\\boldsymbol{\\xi}=2 \\boldsymbol{\\omega}=\\operatorname{curl} \\mathbf{V}=\\boldsymbol{\\nabla} \\times \\mathbf{V}\n\\]</span></p>\n<h3 id=\"vorticity-function-for-two-dimensional-incompressible-flow\">4.2 Vorticity function for two-dimensional incompressible flow</h3>\n<p>First some math: <span class=\"math display\">\\[\n\\begin{aligned}\n\\boldsymbol{\\nabla} \\times \\boldsymbol{\\nabla} \\phi &amp; \\equiv 0 \\qquad\\qquad&amp;(4.1) \\\\\n\\boldsymbol{\\nabla} \\times\\left(\\boldsymbol{\\nabla}^{2} \\mathbf{V}\\right) &amp;=\\boldsymbol{\\nabla}^{2}(\\boldsymbol{\\nabla} \\times \\mathbf{V}) \\qquad\\qquad&amp;(4.2) \\\\\n(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V} &amp;=\\boldsymbol{\\nabla}\\left(\\frac{1}{2} \\mathbf{V} \\cdot \\mathbf{V}\\right)-\\mathbf{V} \\times \\boldsymbol{\\xi} \\qquad\\qquad&amp;(4.3) \\\\\n\\boldsymbol{\\nabla} \\times(\\mathbf{V} \\times \\boldsymbol{\\xi}) &amp;=-\\boldsymbol{\\xi}(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})+(\\boldsymbol{\\xi} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}-(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi} \\qquad\\qquad&amp;(4.4) \n\\end{aligned}\n\\]</span> Recall the <a href=\"#incompressible-navier-stokes-equations\">incompressible momentum equation</a>: <span class=\"math display\">\\[\n\\frac{\\partial\\mathbf{V}}{\\partial t} + \\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V} = \\mathbf{g} -\\boldsymbol{\\nabla}\\left(\\frac{p}{\\rho}\\right) + \\nu\\boldsymbol{\\nabla}^2\\mathbf{V}\n\\]</span> Take the curl for each term: <span class=\"math display\">\\[\n\\underbrace{\\boldsymbol{\\nabla} \\times\\frac{\\partial\\mathbf{V}}{\\partial t} }_{\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}}+ \\boldsymbol{\\nabla} \\times\n\\underbrace{\\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V}}_{\\boldsymbol{\\nabla}\\left(\\frac{1}{2} \\mathbf{V} \\cdot \\mathbf{V}\\right)-\\mathbf{V} \\times \\boldsymbol{\\xi},~\\mathrm{by}(4.3)} = \n\\underbrace{\\boldsymbol{\\nabla} \\times\\mathbf{g}}_{0} -\n\\underbrace{\\boldsymbol{\\nabla} \\times\\boldsymbol{\\nabla}\\left(\\frac{p}{\\rho}\\right)}_{0,~\\mathrm{by} (4.1)}+ \n\\nu\\underbrace{\\boldsymbol{\\nabla} \\times\\boldsymbol{\\nabla}^2\\mathbf{V}}_{\\boldsymbol{\\nabla}^{2}(\\boldsymbol{\\nabla} \\times \\mathbf{V}),~ \\mathrm{by} (4.2)}\n\\]</span> As a result: <span class=\"math display\">\\[\n\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}+ \\underbrace{\\boldsymbol{\\nabla} \\times\\boldsymbol{\\nabla}\\left(\\frac{1}{2} \\mathbf{V} \\cdot \\mathbf{V}\\right)}_{0,~\\mathrm{by} (4.1)}-\\boldsymbol{\\nabla} \\times\\mathbf{V} \\times \\boldsymbol{\\xi}= \\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\n\\]</span> Apply <span class=\"math inline\">\\((4.4)\\)</span> cancel terms due to assumptions: <span class=\"math display\">\\[\n\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}\n+\\underbrace{\\boldsymbol{\\xi}(\\boldsymbol{\\nabla} \\cdot \\mathbf{V})}_{0,~\\mathrm{steady~incompressible}}\n-\\underbrace{(\\boldsymbol{\\xi} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}}_{0,~\\mathrm{2D~flow}}\n+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi}= \\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\n\\]</span> Finally, the vorticity function for 2D incompressible flow is: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial\\boldsymbol{\\xi}}{\\partial t}\n+(\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi}= \n\\frac{D\\boldsymbol{\\xi}}{D t}=\n\\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\n\\]</span> <div class=\"note note-info\">\n            <p>Some of the terms have specific physical interpretations:</p><ul><li><span class=\"math inline\">\\((\\mathbf{V} \\cdot \\boldsymbol{\\nabla}) \\boldsymbol{\\xi}\\)</span> is <em>convection</em></li><li><span class=\"math inline\">\\((\\boldsymbol{\\xi} \\cdot \\boldsymbol{\\nabla}) \\mathbf{V}\\)</span> is <em>stretching</em></li><li><span class=\"math inline\">\\(\\nu\\boldsymbol{\\nabla}^2\\boldsymbol{\\xi}\\)</span> is <em>diffusion</em></li></ul>\n          </div></p>\n<div class=\"note note-info\">\n            <p>Note that there is no pressure term in the vorticity equation, implying that vorticity dynamics are localised in space.</p>\n          </div>\n<h4 id=\"combine-with-continuity-equation\">4.2.1 Combine with continuity equation</h4>\n<p>Recall the definition of the <a href=\"#stream-function\">stream function</a> and take the curl: <span class=\"math display\">\\[\n\\begin{aligned}\n\\mathbf{V} &amp;= \\mathbf{i}\\frac{\\partial\\psi}{\\partial y}-\\mathbf{j}\\frac{\\partial\\psi}{\\partial x} \\\\\n\\boldsymbol{\\nabla}\\times\\mathbf{V} &amp;= -\\mathbf{k}\\boldsymbol{\\nabla}^2\\psi = -\\mathbf{k}\\left( \\frac{\\partial^2\\psi}{\\partial x^2} + \\frac{\\partial^2\\psi}{\\partial y^2} \\right)\n\\end{aligned}\n\\]</span> Substitute these into the vorticity equation, a 4th-order single equation in <span class=\"math inline\">\\(\\psi\\)</span> arrived: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial \\psi}{\\partial y} \\frac{\\partial}{\\partial x}\\left(\\nabla^{2} \\psi\\right)-\\frac{\\partial \\psi}{\\partial x} \\frac{\\partial}{\\partial y}\\left(\\nabla^{2} \\psi\\right)=\\nu \\nabla^{2}\\left(\\nabla^{2} \\psi\\right)\n\\]</span> <div class=\"note note-info\">\n            <p>Assumptions made:</p><ul><li>Steady flow</li><li>Incompressible</li><li>Two dimensional</li></ul>\n          </div></p>\n<p>One important special case is when<br />\n<span class=\"math display\">\\[\n\\boldsymbol{\\nabla}^2\\psi = \\frac{\\partial^2\\psi}{\\partial x^2} + \\frac{\\partial^2\\psi}{\\partial y^2} = 0\n\\]</span> The flow is <strong>irrotational</strong>.</p>\n<h3 id=\"full-bernoulli-equations\">4.3 Full Bernoulli equations</h3>\n<p>We now consider a flow which is <strong>inviscid</strong> (although may still be <strong>compressible</strong>).</p>\n<p>Recall <a href=\"#euler-equations-frictionless-flow\">Euler's equation</a>: <span class=\"math display\">\\[\n\\frac{\\partial\\mathbf{V}}{\\partial t} + \\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V} = \\mathbf{g} -\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)\n\\]</span> Expand the convection term by <span class=\"math inline\">\\((4.3)\\)</span>: <span class=\"math display\">\\[\n\\frac{\\partial\\mathbf{V}}{\\partial t} + \\boldsymbol{\\nabla}\\left(\\frac{1}{2} V^2\\right)+\n\\underbrace{\\boldsymbol{\\xi}\\times\\mathbf{V}}_{\\mathbf{a}\\times\\mathbf{b}=-\\mathbf{b}\\times\\mathbf{a}}- \\mathbf{g} +\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)=0\n\\]</span> Try to integrate it along an arbitrary trajectory in the flow, dot with a small displacement vector <span class=\"math inline\">\\(d\\mathbf{r}\\)</span>: <span class=\"math display\">\\[\n\\left[\\frac{\\partial\\mathbf{V}}{\\partial t} + \\boldsymbol{\\nabla}\\left(\\frac{1}{2} V^2\\right)+\n\\boldsymbol{\\xi}\\times\\mathbf{V}- \\mathbf{g} +\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)\\right]d\\mathbf{r}=0\n\\]</span> The 3<sup>rd</sup> term equals 0 when:</p>\n<ul>\n<li><p>Irrotational flow: <span class=\"math inline\">\\(\\mathbf{\\xi}\\equiv0\\)</span></p></li>\n<li><p>No flow: <span class=\"math inline\">\\(\\mathbf{V}\\equiv0\\)</span>, not possible</p></li>\n<li><p><span class=\"math inline\">\\(d\\mathbf{r}\\)</span> is parallel to <span class=\"math inline\">\\(\\mathbf{V}\\)</span>, <span class=\"math inline\">\\(\\mathbf{V} \\times d \\boldsymbol{r} \\equiv 0\\)</span></p>\n<p>since <span class=\"math inline\">\\((\\boldsymbol{\\xi} \\times \\mathbf{V}) \\cdot d \\boldsymbol{r} \\equiv(\\mathbf{V} \\times d \\boldsymbol{r}) \\cdot \\boldsymbol{\\xi}\\)</span></p>\n<p>our path is a streamline</p></li>\n</ul>\n<p>In order to eliminate the 3<sup>rd</sup> term while keeping the flow rotational, we integrate the equation along the streamline segment <span class=\"math inline\">\\(ds\\)</span>, <span class=\"math display\">\\[\n\\begin{aligned}\n\\int_1^2\\left[\\frac{\\partial\\mathbf{V}}{\\partial t} + \\boldsymbol{\\nabla}\\left(\\frac{1}{2} V^2\\right)-\n\\mathbf{g} +\\frac{1}{\\rho}\\boldsymbol{\\nabla}\\left(p\\right)\\right]ds=0 \\\\\n\\int_1^2\\frac{\\partial\\mathbf{V}}{\\partial t}ds + \\left(\\frac{1}{2} V_2^2-\\frac{1}{2} V_1^2\\right) + g(z_2-z_1) +\\int_1^2\\frac{1}{\\rho}\\left(dp\\right)=0\n\\end{aligned}\n\\]</span> Rearrange to get the <strong>unsteady Bernoulli equation for compressible flow</strong>: <span class=\"math display\">\\[\n\\color{purple}\\int_1^2\\frac{\\partial\\mathbf{V}}{\\partial t}ds+\\int_1^2\\frac{1}{\\rho}\\left(dp\\right)+ \\left(\\frac{1}{2} V_2^2-\\frac{1}{2} V_1^2\\right) + g(z_2-z_1)=0\n\\]</span> Plus the <strong>steady and incompressible</strong> conditions, the function reduced to the familiar expression: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{p}{\\rho}+\\frac{1}{2}V^2+gz = Const,~\\mathrm{~along~a~streamline}\n\\]</span> Plus the <strong>irrotational</strong> condition, the 3rd term remains 0 regardless the trajectory, the function becomes: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{p}{\\rho}+\\frac{1}{2}V^2+gz = Const,~\\mathrm{~everywhere}\n\\]</span></p>\n<h3 id=\"velocity-potential\">4.4 Velocity potential</h3>\n<p>Vector analysis tells us that if the curl of a vector field is zero then that vector field must itself be the gradient of a scalar function. That is,</p>\n<p>The function <span class=\"math inline\">\\(\\phi\\)</span> is called a potential function. <span class=\"math display\">\\[\n\\boldsymbol{\\nabla} \\times \\mathbf{V} \\equiv 0 \\quad \\Rightarrow \\quad \\mathbf{V}=\\boldsymbol{\\nabla} \\phi\n\\]</span> <div class=\"note note-info\">\n            <p>Velocity potential <span class=\"math inline\">\\(\\phi\\)</span> is another scalar function, a complementary to the <a href=\"#stream-function\">stream function</a> <span class=\"math inline\">\\(\\psi\\)</span>.</p><p>It is applicable only in <strong>irrotational</strong> flow.</p>\n          </div></p>\n<p>Some useful properties:</p>\n<ul>\n<li><p>In Cartesian coordinate, it reduce the 3 velocity components <span class=\"math inline\">\\(u\\)</span>, <span class=\"math inline\">\\(v\\)</span>, <span class=\"math inline\">\\(w\\)</span> into a single scalar: <span class=\"math display\">\\[\nu=\\frac{\\partial \\phi}{\\partial x} \\quad v=\\frac{\\partial \\phi}{\\partial y} \\quad w=\\frac{\\partial \\phi}{\\partial z}\n\\]</span></p></li>\n<li><p>Line of constant <span class=\"math inline\">\\(\\phi\\)</span> is called <em>potential lines</em>.</p>\n<p>In <strong>two-dimensional flow</strong>, potential lines are everywhere orthogonal to the streamlines, because: <span class=\"math display\">\\[\nu=\\frac{\\partial \\psi}{\\partial y}=\\frac{\\partial \\phi}{\\partial x} \\quad v=-\\frac{\\partial \\psi}{\\partial x}=\\frac{\\partial \\phi}{\\partial y}\n\\]</span> The dot-product of their gradients are: <span class=\"math display\">\\[\n\\left[\\frac{\\partial \\psi}{\\partial x} \\mathbf{i}+\\frac{\\partial \\psi}{\\partial y} \\mathbf{j}\\right] \\cdot\\left[\\frac{\\partial \\phi}{\\partial x} \\mathbf{i}+\\frac{\\partial \\phi}{\\partial y} \\mathbf{j}\\right]=u(-v)+u v \\equiv 0\n\\]</span></p></li>\n<li><p>If <span class=\"math inline\">\\(\\phi\\)</span> exists, substitute the definition into the unsteady Bernoulli equation, <span class=\"math display\">\\[\n\\frac{\\partial \\phi}{\\partial t}+\\int \\frac{d p}{\\rho}+\\frac{1}{2}|\\boldsymbol{\\nabla} \\phi|^{2}+g z=\\mathrm{const}\n\\]</span> <div class=\"note note-info\">\n            <p>It is an equation between just two scalar quantities, <span class=\"math inline\">\\(\\phi\\)</span> and <span class=\"math inline\">\\(p\\)</span>.</p>\n          </div></p></li>\n</ul>\n<h2 id=\"vortex-motion-and-applications\">5 Vortex Motion and Applications</h2>\n<p>Vortices are structures within the flow in which fluid is rotating about an axis line (which may be straight or curved). A <strong>vortex line</strong> is therefore defined as a line which is always in the same direction as the local vorticity vector <span class=\"math inline\">\\(\\boldsymbol{\\xi}\\)</span>.</p>\n<p><img src=\"Vortex line example.png\" alt=\"Vortex line example (red line) from physics.stackexchange.com\" style=\"zoom:100%;\" /></p>\n<p>Similar to streamline, vortex lines <span class=\"math inline\">\\((x, y, z) = (x(s), y(s), z(s))\\)</span> are obtained by solving: <span class=\"math display\">\\[\n\\frac{dx/ds}{d\\xi_x}=\\frac{dy/ds}{d\\xi_y}=\\frac{dz/ds}{d\\xi_z}\n\\]</span> Similar to steam tube, vertex lines which pass through a closed curve in space form a <strong>vortex tube</strong>.</p>\n<h3 id=\"circulation\">5.1 Circulation</h3>\n<p><strong>Fluid circulation</strong> describes the strength of rotation, or strength of fluid swirling, within a closed contour <span class=\"math inline\">\\(C(t)\\)</span>. Mathematically it is defined as the integral of velocity along the contour curve: <span class=\"math display\">\\[\n\\Gamma=\\oint_{C(t)} \\mathbf{V} d s=\\int_{S} \\boldsymbol{\\xi} \\cdot \\boldsymbol{n} d S\n\\]</span></p>\n<h4 id=\"material-elements-and-its-motion\">5.1.1 Material elements and its motion</h4>\n<p>Consider how a infinitesimal displacement <span class=\"math inline\">\\(d\\mathbf{s}\\)</span> deforms over a small time <span class=\"math inline\">\\(dt\\)</span>, illustrated in the diagram below.</p>\n<p><img src=\"Displacement deformation.png\" alt=\"Displacement deformation\" style=\"zoom:50%;\" /></p>\n<p>We have <span class=\"math inline\">\\(d(d\\mathbf{s})\\)</span> the <strong>material line element</strong>: <span class=\"math display\">\\[\n\\begin{aligned}\nd(d \\boldsymbol{s})=d \\boldsymbol{s}_{1}-d \\boldsymbol{s}_{0} &amp;=\\left(\\boldsymbol{x}+d \\boldsymbol{s}_{0}+\\mathbf{V}\\left(\\boldsymbol{x}+d \\boldsymbol{s}_{0}\\right) d t\\right)-(\\boldsymbol{x}+\\mathbf{V}(\\boldsymbol{x}) d t)-d \\boldsymbol{s}_{0} \\\\\n&amp;=\\left(\\mathbf{V}\\left(\\boldsymbol{x}+d \\boldsymbol{s}_{0}\\right)-\\mathbf{V}(\\boldsymbol{x})\\right) d t \\\\\n&amp;=d \\boldsymbol{s}_{0} \\frac{\\partial \\mathbf{V}}{\\partial\\left(d \\boldsymbol{s}_{0}\\right)} d t \\\\\n&amp;=d \\boldsymbol{s}_{0} \\cdot \\boldsymbol{\\nabla} \\mathbf{V} d t\n\\end{aligned}\n\\]</span> Therefore: <span class=\"math display\">\\[\n\\frac{D(d\\mathbf{s})}{Dt} = (ds\\cdot\\boldsymbol{\\nabla})\\mathbf{V}\n\\]</span></p>\n<h3 id=\"kelvins-circulation-theorem\">5.2 Kelvins Circulation Theorem</h3>\n<blockquote>\n<p>Kelvins Circulation Theorem status the expression of the rate of change of the circulation <span class=\"math inline\">\\(\\frac{D\\Gamma}{Dt}\\)</span> and determine how a circulation around a fluid loop varies as the loop moves with the flow. (<a href=\"https://youtu.be/q4xSUYZCj84\">reference</a>)</p>\n</blockquote>\n<p>Apply material derivative to circulation we have: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{D}{Dt}\\Gamma&amp;=\\frac{D}{Dt}\\oint_{C(t)} \\mathbf{V} d \\mathbf{s}    \\\\\n&amp;= \\oint_{C(t)}\\frac{D}{Dt}(\\mathbf{V} d \\mathbf{s} ) \\\\\n&amp;= \\oint_{C(t)}\\frac{D\\mathbf{V}}{Dt}\\cdot d \\mathbf{s}  + \\oint_{C(t)}\\mathbf{V}\\cdot \\frac{D(d \\mathbf{s})}{Dt}       \\\\\n\\end{aligned}\n\\]</span> Substitute material line element into the last term to get a scalar inside the loop integration, then we have: <span class=\"math display\">\\[\n\\frac{D}{Dt}\\Gamma = \\oint_{C(t)}\\frac{D\\mathbf{V}}{Dt}d \\mathbf{s}\n\\]</span> Recall the <a href=\"#general-differential-linear-momentum-equation\">general linear momentum equation</a> and substitute the material derivative of velocity: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{D}{Dt}\\Gamma &amp;= \\oint_{C(t)}\\left(\\mathbf{g} - \\frac{\\boldsymbol{\\nabla}p}{\\rho} + \\frac{\\boldsymbol{\\boldsymbol{\\nabla}\\cdot\\tau_{ij}}}{\\rho}\\right)d \\mathbf{s} \\\\\n&amp;= \\oint_{C(t)}\\mathbf{g}d \\mathbf{s}  - \\oint_{C(t)}\\frac{\\boldsymbol{\\nabla}p}{\\rho} d\\mathbf{s}   + \\oint_{C(t)}\\frac{\\boldsymbol{\\nabla}\\cdot\\boldsymbol{\\tau_{ij}}}{\\rho}d \\mathbf{s} \n\\end{aligned}\n\\]</span> This function is not zero unless:</p>\n<ul>\n<li>1<sup>st</sup> term: body force torque is zero, body force is <strong>irrotational</strong>, <span class=\"math inline\">\\(\\mathbf{g} = \\nabla\\phi\\)</span>, <span class=\"math inline\">\\(\\phi\\)</span> is a scalar.</li>\n<li>2<sup>nd</sup> term: <span class=\"math inline\">\\(p = p(\\rho)\\)</span> or <span class=\"math inline\">\\(\\rho = const.\\)</span>(<strong>incompressible and isotropic</strong>)</li>\n<li>3<sup>rd</sup> term: <strong>inviscid</strong>, <span class=\"math inline\">\\(\\boldsymbol{\\tau_{ij}}=0\\)</span></li>\n</ul>\n<h4 id=\"aerofoil-lift-and-kutta-joukowski-theorem\">5.2.1 Aerofoil lift and Kutta-Joukowski Theorem</h4>\n<p>One application of the Kelvin Circulation Theorem is in explaining the lift attained by an aerofoil during the shedding of the starting vortex.</p>\n<p>Consider a stationary aerofoil shown in the diagram below.</p>\n<p><img src=\"Aerofoil vortex shedding.png\" alt=\"Aerofoil vortex shedding\" style=\"zoom:50%;\" /></p>\n<p>At time <span class=\"math inline\">\\(t = 0\\)</span>, the aerofoil is stationary, there is no vorticity and around the path <span class=\"math inline\">\\(C(t)\\)</span> the circulation is <span class=\"math inline\">\\(\\Gamma = 0\\)</span>. As the flow velocity increases, vorticity is shed behind the aerofoil leading to positive <span class=\"math inline\">\\(\\Gamma\\)</span>.</p>\n<p>By Kelvins circulation theorem, the circulation <span class=\"math inline\">\\(\\Gamma_0\\)</span> around <span class=\"math inline\">\\(C(t)\\)</span> is independent of time. Therefore, there must be negative <span class=\"math inline\">\\(\\Gamma_1\\)</span> around the aerofoil, which leads to lift by the Kutta-Joukowski theorem (<span class=\"math inline\">\\(L&#39; = \\rho u\\Gamma\\)</span>).</p>\n<h3 id=\"helmholtz-theorems\">5.3 Helmholtz Theorems</h3>\n<p>Suppose we have an <strong>inviscid</strong>, <strong>incompressible</strong> fluid of <strong>constant density</strong> moving under a <strong>conservative body force</strong>, then</p>\n<ol type=\"1\">\n<li><p>The quantity <span class=\"math display\">\\[\n\\Gamma=\\int_{S} \\boldsymbol{\\xi} \\cdot \\boldsymbol{n} d S\n\\]</span> is the same for all cross-sections <span class=\"math inline\">\\(S\\)</span> of a vortex tube. i.e. the strength of a vortex is constant along the length of the vortex.</p></li>\n<li><p>A vortex filament cannot end in the fluid; it must extend to the boundaries of the fluid, infinity, or form a closed loop</p></li>\n<li><p>If fluid is initially irrotational, in the absense of rotational forces, it remains irrotational indefinitely.</p></li>\n</ol>\n<h4 id=\"vortex-rings\">5.3.1 Vortex rings</h4>\n<p>A vivid example of Helmholtzs theorems can be seen in vortex (smoke) rings. These are vortices in which the core vortex line forms a closed loop (theorem #2).</p>\n<p>Such vortices can retain their strength (theorem #1) and travel significant distances (the smoke is carried in the vortex).</p>"},{"title":"External flow fundamentals","author":"Ryan LI","toc":true,"declare":true,"index_img":"/index/external_flow.png","date":"2022-05-26T05:15:15.000Z","_content":"\n{% note primary %}\n\nInternal pipe flow is not enough for me, continue to review the tricky part.\n\n{% endnote%}\n\n<!-- more -->\n\n## 4 Fluid-structure interaction\n\nWhen an unbounded homogeneous flow approaches an obstacle, viscous effects become important and substantially deform the flow profile. The resulting boundary layers and wakes are responsible for generating forces and moments on the obstacle.\n\n### 4.1 Examples\n\n#### 4.1.1 Lift generation\n\nHere comes the most popular question: how does an aircraft fly?\n\nThe basic answer is that \n\n> The airfoil is shaped so that its upper surface is longer than its lower surface. A parcel of fluid arriving at the leading edge then splits into two parcels, one following the upper surface and the other the lower surface. As the fluid has more distance to travel on the upper surface than on the lower surface, it goes faster to have the **same transit time**. The Bernoulli effect follows: the higher velocity on the upper surface yields a lower pressure and an ascending force is created: the lift.\n\nThe use of Bernoulli effect is, to some extent, correct. However, based on experiment findings shown below, the same transit time assumption is not quite right. \n\nI\\bar{t}s clear the upper flow is accelerated compared to the lower flow. This happens already at the leading edge, but the lower flow never catches up with the upper one. As a result, the upper flow possesses a shorter transit time.\n\n<img src=\"Flow past an airfoil.gif\" alt=\"Flow past an airfoil visualised through the trajectory of one pulse of smoke. After Babinsky (http://www.cam.ac.uk/research/news/how-wings-really-work).\" style=\"zoom:100%;\" />\n\nAs a consequence, the physical mechanism behind lift is not so simple. A plausible answer is twofolds. \n\n- On the one hand, the fluid is accelerated on the upper surface and slowed down on the lower surface, creating a descending pressure gradient, hence lift.\n- On the other hand, the fluid trajectory is overall deflected downwards when passing the airfoil. This implies that the airfoil creates a descending force onto the fluid, and, by Newtons third law, that the fluid generates an ascending force onto the airfoil.\n\n#### 4.1.2 Wingtip vortices\n\nAt the tip of the wing, when the lower pressure upper surface meets the higher pressure lower surface, wingtip vortices are generated. These vortices are generally strong, long-lived and consequently dangerous, as shown below:\n\n<img src=\"Wingtip vortex.jpeg\" alt=\"Wingtip vortex behind a plane visualised with red smoke.\" style=\"zoom:50%;\" />\n\nFlying through such a vortex will create a rolling moment that can destabilize the flight.\nMany such incidents have happened during takeoff and landing. As a result, airports have decided on quiet periods of one to two minutes between two successive takeoffs or landings to allow for these vortices to dissipate to a less dangerous strength.\n\n<img src=\"V formation.jpeg\" alt=\"Birds flying in V-formation.\" style=\"zoom:50%\" />\n\nYet the wingtip vortices are leveraged perfectly by the nature, the V-formation. When one bird follows another bird, it places itself a little bit on the side to benefit from the lift generated by the wingtip vortices of its leader.\n\n#### 4.1.3 Others\n\nWind and ocean engineering also present important challenges in the area of fluid-structure interaction. \n\nThe construction of tall building is necessary to accommodate large professional centres and these tall buildings interact strongly with the wind. Similar issues arise with bridges. Serious oscillation would be generated due to the \"wind load\". \n\n<p align=\"center\">\n  <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/tHMPR7flpf4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></p>\n\nIn water, it is important to understand fluid-structure interactions to design efficient breakwaters and protect constructions on the shore or beaches. Pier piles are also good examples of structures interacting with water and that have to be designed carefully.\n\nLastly, we can take advantage of natural phenomena such as wind and currents by designing structures that will store such energy like wind and water turbines.\n\n### 4.2 Effect of a structure on the fluid\n\nWhen an external flow goes past an obstacle, boundary layer and wake effects occur on the walls and after the obstacle respectively. \n\n#### 4.2.1 Boundary layers\n\n<img src=\"Boundary layers.png\" alt=\"Sketch of the flow past a sharp flat plate oriented in the direction of the flow.\nTwo situations are shown: a low-Re flow (ReL= 10) and a high-Re flow (ReL= 107) and the associated boundary layers depicted. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" />\n\n**Convenient definition**: a region where the fluids velocity parallel to the wall is smaller or equal to 99% of the external velocity.\n\n- Inside the boundary layer, the flow feels the effect of the wall and is gradually slowed down as we approach the wall. The presence of these velocity gradients is a consequence of **viscous dissipation**.\n- Outside the boundary layer, the flow does not feel the presence of the walls. It remains homogeneous and is considered **inviscid**.\n\n{% note info %}\n\nNote that this is only an assumption, the interaction between the boundary layer and the outer pressure distribution is neglected. For slender bodies at large $Re$, such as airfoils, when placed parallel to the flow, this assumption provides good results due to the thin and weak boundary layer.\n\n{% endnote %}\n\nThere are **two types** of the boundary layers defined by the Reynolds number:\n\n- Low $Re$, laminar boundary layer. Because spatial variations are slow, the laminar boundary layer occupies a large spatial region.\n- High $Re$, two distinct regions in the boundary layer:\n  - laminar boundary layer similar to that of low-Re flows but much thinner \n  - turbulent boundary layer that occurs further away in the streamwise direction and is larger than the laminar boundary layer. \n\nThe **viscous displacement effect** describes the non-zero velocity in the direction orthogonal to the wall because the velocity parallel to the wall varies in the direction orthogonal to the wall.\n\n- For low $Re$ laminar boundary layers, this effect is important\n- For high $Re$ boundary layers, these boundary layers are so thin that this effect is negligible.\n\n#### 4.2.2 Wakes\n\n<img src=\"Wakes.png\" alt=\"Sketch of the wake past a cylinder and the different regimes observed as a function of the Reynolds number Re = UR/, where U is the velocity of the fluid infinitely far away from the cylinder, R the cylinder radius and  the fluids kinematic viscosity. After Middleton & Southard, Mechanics of Sediment Movement, SEPM Short Course Notes, Vol. 3 (1984).\" style=\"zoom:50%;\" />\n\nWhen the inertia is non-trivial (equivalently viscous effects are not overwhelmingly dominant), the gradients of velocity induced by the boundary layer are advected downstream and create a **wake** past the obstacle. This region can display dramatic departures from the established flow infinitely far away from the obstacle.\n\nThe sketch above shows how several typical regimes of the wake past a cylinder in different $Re$s:\n\n- Low $Re$: steady and symmetric flow\n- $Re=\\mathcal{O}(10)$: \n  - the upstream-downstream symmetry is broken\n  - flow separation occurs. The boundary layers separate from the wall and a recirculation zone is created where two counter-rotating vortices live. \n  - wake remains stationary\n  - the up-down symmetry is still preserved\n- $Re=\\mathcal{O}(100)$: \n  - the up-down symmetry is broken \n  - flow separation developed\n  - wake is now periodic in time, vortices periodically break away from the back of the cylinder in an alternate fashion and are advected downstream\n  - This type of wake is called **Von Krmn streets**.\n- $Re>\\mathcal{O}(1000)$: any simple time-dependence in the wake is lost and it is now turbulent.\n\nNote that as the Reynolds number is increased, different types of turbulent wakes can be observed.\n\n- At $Re = 5\\times10^3$, the turbulent wake is detached from the wall and a laminar bubble is observed at the back of the cylinder.\n- As the Reynolds number is increased, this bubble shrinks\n- At $Re = 10^5$, the back of the cylinder has become fully turbulent\n- As Re is further increased, the turbulent wake becomes thinner and thinner and the influence of the cylinder on the flow decreases. This is the result of the fact that the characteristic length for advection becomes incomparably larger than the diameter of the cylinder\n\n### 4.3 Effect of the fluid on a structure\n\nIn this section, we look at the opposite interaction: the impact of boundary layers and wakes on the structures.\n\n#### 4.3.1 Free kick like Cristiano Ronaldo\n\n<p align=\"center\">\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MscZ_pd7iAM?start=12\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</p>\n\nPersonally, I'm not a big fan of football. The only football game I watch is FIFA. And I happened to watch this legendary game on live. I remember it was 3 o'clock in the morning and I barely held my scream. \n\n<img src=\"magnus effect illustration.png\" alt=\"Illustration of the Magnus effect using a downward flow past an anti-clockwise rotating sphere. The flow is slowed down on the right as opposed to the left. The pressure is then greater on the right of the sphere and a leftward force is generated.\" style=\"zoom:50%;\" />\n\nThe explanation of such a trajectory lies in the **Magnus effect** which describes a spinning object moving through a fluid. Rotating the ball accelerates the flow on one side while slowing it down on the other. This difference of velocity breaks the symmetry of the flow and creates a difference of pressure. And this results in an additional force that bends the trajectory of the ball.\n\n#### 4.3.2 The Tacoma Narrows bridge\n\n<p align=\"center\"> <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XggxeuFDaDU?start=15\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe> </p>\n\nAnother famous aeroelastic failure is this 1.8km long bridge in the state of Washington. The 6 million dollar bridge collapsed in a steady standard wind in November, 1940, only 3 months after its opening date. Back then this wind interacted in an unexpected manner with the bridge and created a positive feedback loop called **aeroelastic flutter**. A oscillating wake  due to the periodic vortex shedding excited a **second torsional mode**: the midpoint of the bridge remained motionless while the two opposite halves twisted in opposite directions. This torsion further enhanced the strength of the wake, which in turn enhanced the torsion until the bridge collapsed.\n\n## 5 Boundary layer theory  Integral approach\n\nFirst, a control volume is defined as blow:\n\n- Boundary : the segment $(0, 0)$ to $(0, h)$, where $\\mathbf{u} = U\\mathbf{\\hat{x}}$.\n- Boundary : the streamline $(0, h)$ to $(L, \\delta)$, where $\\mathbf{u}\\cdot \\mathbf{n} = 0$.\n- Boundary : the segment $(L, \\delta)$ to $(L, 0)$, where $ \\mathbf{u}= u(x, y)\\mathbf{\\hat{x}} + v(x, y)\\mathbf{\\hat{y}}$.\n- Boundary : the plate surface and streamline $(L, 0)$ to $(0, 0)$, where $u = 0$.\n\n<img src=\"Boundary layer control volume.png\" alt=\"Sketch of a developing boundary layer on a flat plate. The control volume used is delimited by the boundaries labeled , ,  and .\" style=\"zoom:30%;\" />\n\n### 5.1 Viscous displacement\n\n#### 5.1.1 Physical origin\n\nThe viscous displacement determines the upstream streamlines parallel to the wall to move away from the wall i.e. boundary  to tilt upward. It can be explained by the 2D compressible continuity equation:\n$$\n\\partial_x u+\\partial_y v=0\n$$\nNear the boundary , the no-slip condition gives $\\partial_xu<0$, to compensate for it, $\\partial_yv>0$, and the consequence of this is the viscous displacement.\n\n#### 5.1.2 Displacement thickness\n\n<img src=\"displacement thickness.png\" alt=\"Actual viscous boundary layer vs analogy with an inviscid flow displaying the same flow rate. The wall-normal delay * necessary to obtain the same flow rate is called displacement thickness.\" style=\"zoom:30%;\" />\n\nThe quantity $\\delta^*$ is called **displacement thickness** and represents the distance by which the wall would have to be moved in the wall normal direction to **obtain the same flow rate** in an inviscid flow. i.e. the additional blockage/deflection due to viscosity.\n\nBy definition, it is easy to conclude that $\\delta = \\delta^*+h$. And by mass conservation between the inlet and the outlet, the displacement thickness can be described:\n$$\n\\begin{aligned}\n\\rho\\int_1(\\mathbf{u}\\cdot\\mathbf{n})ds&+\\rho\\int_3(\\mathbf{u}\\cdot\\mathbf{n})ds =0 \\\\\n\\int^{\\delta-\\delta^*}_0(-U&)dy+\\int^\\delta_0udy=0 \\\\\nUh&= \\int^\\delta_0udy \\\\\n\\end{aligned}\n$$\nSubstitute $h$ with $\\delta-\\delta^*$ :\n$$\n\\begin{aligned}\nU(\\delta-\\delta^*) &= \\int^\\delta_0udy \\\\\nU(\\delta-\\delta^*) &= \\int^\\delta_0\\left(u+U-U\\right)dy \\\\\nU(\\delta-\\delta^*) &= U\\delta+\\int^\\delta_0\\left(u-U\\right)dy \\\\\n\\Rightarrow \\quad\\delta^* = \\int_0^\\delta&\\left(1-\\frac uU\\right)dy\\\\\n\\Rightarrow \\quad\\color{purple}{\\frac{\\delta^*}{\\delta} = \\int_0^1}&\\color{purple}{\\left(1-\\frac uU\\right)d\\eta}, \\quad\\mathrm{where~}\\eta=\\frac{y}{\\delta}\\\\\n\\end{aligned}\n$$\n\n### 5.2 Friction drag\n\n#### 5.2.1 Drag as a boundary layer effect\n\nAssume a constant pressure throughout the domain, and a steady flow. The conservation of momentum in $\\mathbf{\\hat{x}}$ writes:\n$$\n\\begin{aligned}\n\\rho\\int_1u(0,y)(\\mathbf{u}\\cdot\\mathbf{n})ds + \n\\underbrace{\\rho\\int_2u(x,y)(\\mathbf{u}\\cdot\\mathbf{n})ds+}_{\\mathrm{streamline:~}\\mathbf{u}\\cdot\\mathbf{n}=0} ...\\\\\n\\rho\\int_3u(L,y)(\\mathbf{u}\\cdot\\mathbf{n})ds+\n\\underbrace{\\rho\\int_4u(x,0)(\\mathbf{u}\\cdot\\mathbf{n})ds}_{\\mathrm{wall:~}u=0}=\n\\Sigma F_x = -D\\mathbf{\\hat{x}}\n\\end{aligned}\n$$\nThe equation simplifies into:\n$$\n\\begin{aligned}\n\\rho\\int_0^hU(-U)dy + \\rho\\int_0^\\delta u^2dy=-D \\\\\n\\Rightarrow\\qquad D = \\rho hU^2 -\\rho\\int_0^\\delta u^2dy\n\\end{aligned}\n$$\nCombine with the **mass conservation** result $Uh= \\int^\\delta_0udy$:\n$$\n\\begin{aligned}\nD &= \\rho \\int_0^\\delta Uudy-\\rho\\int_0^\\delta u^2dy \\\\\n\\color{purple}{D }&\\color{purple}{= \\rho \\int_0^\\delta \\frac{u}{U}\\left(1-\\frac{u}{U}\\right) dy}\n\\end{aligned}\n$$\n\n#### 5.2.2 Momentum thickness\n\nThe quantity $\\theta$ is called **momentum thickness** and represents the distance by which the wall would have to be moved in the wall normal direction to **obtain the same momentum** in an inviscid flow. \n$$\n\\color{purple}\\frac{\\theta}{\\delta} = \\frac{D}{\\rho U^2\\delta} = \\int_0^1 \\frac{u}{U}\\left(1-\\frac{u}{U}\\right) d\\eta, \\quad \\mathrm{where~}\\eta = \\frac{y}{\\delta}\n$$\ni.e. the **momentum deficit** can be determined by:\n$$\n\\rho U^2\\theta = \\rho \\int_0^\\delta \\frac{u}{U}\\left(1-\\frac{u}{U}\\right)dy\n$$\n{% note info %}\n\nThere is another **Energy thickness** writes:\n$$\n\\color{purple}\\frac{\\theta'}{\\delta} = \\int_0^1 \\frac{u}{U}\\left(1-\\frac{u^2}{U^2}\\right) d\\eta, \\quad \\mathrm{where~}\\eta = \\frac{y}{\\delta}\n$$\n{% endnote %}\n\nWe can then define the **shape factor**:\n$$\nH = \\frac{\\delta^*}{\\theta}\n$$\n{% note info %}\n\nShape factor indicates the wall-normal distance on which the fluid is deflected from the plate compared to that on which gradients of streamwise velocities are felt.A large shape factor indicates a flow near separation.\n\n{% endnote %}\n\n#### 5.2.3 Relation to wall shear stress\n\nThe drag force is the integration of wall shear stress $\\tau_w$ along the plate:\n$$\nD = \\int_0^L\\tau_wdx\n$$\nOr in differential form:\n$$\n\\tau_w = \\partial_xD\n$$\nDifferentiate the momentum thickness representation:\n$$\n\\partial_x\\theta = \\frac{\\partial_xD}{\\rho U^2}=\\frac{\\tau_w}{\\rho U^2}\n$$\nAs a result, the wall shear:\n$$\n\\color{purple}\\tau_w = \\rho U^2\\partial_x\\theta\n$$\n\n### 5.3 Velocity profile approximations\n\nFor *laminar* boundary layers,  Von Krmn assumed that the velocity profile ($\\frac{u}{U}$) within the boundary layer had a parabolic shape:\n\nGiven:\n$$\n\\eta = \\frac{y}{\\delta(x)}\n$$\nThe velocity profile ($\\frac{u}{U}$) writes:\n$$\n\\frac{u}{U}\\approx 2\\eta -\\eta^2, \\qquad 0\\leq \\eta\\leq 1\n$$\nFor *turbulent* boundary layers, Prandtl highlighted a one-seventh power velocity profile:\n$$\n\\frac{u}{U}\\approx\\eta^\\frac{1}{7}, \\qquad 0\\leq \\eta\\leq 1\n$$\nThese first order approximations are very close to the reality as shown below:\n\n<img src=\"velocity profiles.png\" alt=\"Comparison of velocity profiles u/U in the boundary layer y/ < 1 between the Von Krmn and Prandtls approximations and the actual laminar and turbulent flows. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" />\n\n### 5.4 Laminar results (Von Krmn results)\n\nBased on Von Krmn's approximation, $\\frac{u}{U}\\approx \\frac{2y}{\\delta} -\\left(\\frac{y}{\\delta}\\right)^2$. It is easy to get:\n\n- Boundary thickness:\n\n  The key point is that the wall shear stress can be expressed in two ways, \n\n  - by definition:\n    $$\n    \\begin{aligned}\n    \\tau_w &= \\mu \\partial_yu|_{y=0} \\\\\n    \\Rightarrow \\quad \\tau_{w} &\\approx \\mu \\partial_{y}\\left.\\left(\\frac{2 y}{\\delta}-\\frac{y^{2}}{\\delta^{2}}\\right)\\right|_{y=0} \\\\\n    \\Rightarrow \\quad \\tau_{w} &\\approx \\mu \\frac{2 U}{\\delta}\\\\\n    \\end{aligned}\n    $$\n\n  - and by the derivative of drag:\n    $$\n    \\begin{aligned}\n    \\tau_w &= \\rho U^2\\partial_x\\theta \\\\\n    \\Rightarrow \\quad \\tau_{w} &\\approx \\rho U^2\\partial_x\\left[\\int_{0}^{\\delta}\\left(\\frac{2 y}{\\delta}-\\frac{y^{2}}{\\delta^{2}}\\right)\\left(1-\\frac{2 y}{\\delta}+\\frac{y^{2}}{\\delta^{2}}\\right) d y \\right] \\\\\n    \\Rightarrow \\quad \\tau_{w} &\\approx \\frac{2\\rho U^2}{15}\\partial_x\\delta\n    \\end{aligned}\n    $$\n\n  As a result, connect these expressions:\n  $$\n  \\begin{aligned}\n  &\\mu \\frac{2 U}{\\delta} \\approx \\frac{2\\rho U^2}{15}\\partial_x\\delta \\\\\n  \\Rightarrow \\quad &\\int_0^x dx \\approx \\int_0^\\delta \\frac{\\rho U}{15}\\delta d\\delta \\\\\n  \\Rightarrow \\quad &x \\approx \\frac{\\rho U \\delta^2}{30\\mu} \\\\\n  \\Rightarrow \\quad & \\left(\\frac{\\delta}{x}\\right)^2 \\approx \\frac{30\\mu}{\\rho U x} \\\\\n  \\Rightarrow \\quad & \\color{purple}{\\frac{\\delta}{x}  \\approx 5.5 Re_x^{-1/2}} \\\\\n  \\end{aligned}\n  $$\n  where $\\color{purple}Re_x= Ux/\\nu$ as the **streamwise Reynold**.\n\n- the displacement thickness:\n  $$\n  \\begin{aligned}\n  \\delta^* &= \\int_0^\\delta\\left(1-\\frac{u}{U}\\right)dy \\\\\n  &\\approx \\int_0^\\delta\\left(1-\\frac{2y}{\\delta}+\\left(\\frac{y}{\\delta}\\right)^2\\right)dy \\\\\n  \\Rightarrow \\quad \\delta^*&\\approx \\frac{1}{3}\\delta\\\\\n  \\end{aligned}\n  $$\n  with the boundary thickness expression:\n  $$\n  \\begin{aligned}\n  \\color{purple}\\frac{\\delta^*}{x}\\approx 1.83 Re_x^{-1/2}\n  \\end{aligned}\n  $$\n\n- the momentum displacement and the factor of friction:\n  $$\n  \\begin{aligned}\n  \\theta &= \\int_{0}^{\\delta}\\left(\\frac{2 y}{\\delta}-\\frac{y^{2}}{\\delta^{2}}\\right)\\left(1-\\frac{2 y}{\\delta}+\\frac{y^{2}}{\\delta^{2}}\\right) d y \\\\\n  \\Rightarrow \\quad & \\theta \\approx \\frac{2}{15}\\delta \\\\\n  \\Rightarrow \\quad & \\color{purple}{\\frac{\\theta}{x}  \\approx 0.73 Re_x^{-1/2}} \n  \\end{aligned}\n  $$\n  The factor of friction has the same order with the momentum displacement, as\n  $$\n  \\color{purple}{C_f   \\approx 0.73 Re_x^{-1/2}}\n  $$\n\n- the shape factor:\n  $$\n  \\color{purple}\n  H = \\frac{\\delta^*}{\\theta} \\approx 2.5\n  $$\n\n### 5.5 Laminar results (Blasius results)\n\nReference to [MIT's note](https://web.mit.edu/fluids-modules/www/highspeed_flows/ver2/bl_Chap2.pdf), [MECH 346  Heat Transfer's Youtube channel](https://youtu.be/Lw6aQJGD3FU)\n\n#### 5.5.1 Governing equations\n\nConditions:\n\n- 2D\n\n- Steady\n\n- Incompressible\n\n- Neglect viscous dissipation, gravity and thermal dissipation\n\n- Plus the **thin layer assumption ($L\\gg\\delta$)** for boundary layer (Obtained by non-dimensional scaling analysis, Full deriving on [Appendix A.1](#a.1-governing-equation-of-boundary-layers)): \n  $$\n  \\begin{aligned}\n  u&\\gg v \\\\\n  \\frac{\\partial}{\\partial y}&\\gg\\frac{\\partial}{\\partial x}\n  \\end{aligned}\n  $$\n\nThe mass and momentum conservation equations reduces to: \n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} &= 0 \\\\\nu\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y}&=-\\frac{1}{\\rho}\\frac{\\partial p}{\\partial x}+\n\\nu\\left(\\overbrace{\\frac{\\partial^2u}{\\partial x^2}}^{\\mathrm{0}}+\\frac{\\partial^2u}{\\partial y^2}\\right) \\\\\nu\\frac{\\partial v}{\\partial x}+v\\frac{\\partial v}{\\partial y}&=\n\\underbrace{-\\frac{1}{\\rho}\\frac{\\partial p}{\\partial y}}_{\\text{principle order}}+\\nu\\left(\\frac{\\partial^2v}{\\partial x^2}+\\frac{\\partial^2v}{\\partial y^2}\\right)\n\\end{aligned}\n$$\nas a result:\n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} &= 0 \\\\\nu\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y}&=-\\frac{1}{\\rho}\\frac{\\partial p}{\\partial x}+\\nu\\frac{\\partial^2u}{\\partial y^2} \\\\\n\\frac{1}{\\rho}\\frac{\\partial p}{\\partial y}&=0\n\\end{aligned}\n$$\n\nFor the flat plate boundary layer, it is easy to get $\\frac{\\partial p}{\\partial x}=0$ because the free stream pressure gradient in the $x$ direction is $0$, so as in the boundary layer given the $\\frac{\\partial p}{\\partial y}=0$. As a consequence there is no pressure gradient within the flat plate boundary layer. The final governing equation writes:\n\n$$\n\\color{purple}\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} &= 0 \\\\\nu\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y}&=\\nu\\frac{\\partial^2u}{\\partial y^2} \\\\\n\\end{aligned}\n$$\n\nAnd the boundary conditions are:\n\n$$\n\\color{purple}\n\\begin{aligned}\nu=v = 0\\quad&\\mathrm{at}\\quad y = 0\\\\\nu = U\\quad&\\mathrm{at}\\quad x = 0 \\\\\nu \\rightarrow U\\quad&\\mathrm{as}\\quad y \\rightarrow \\infty \\\\\n\\end{aligned}\n$$\n\n{% note info %}\n\nThese conditions demand an *infinite gradient* in speed at the leading edge $x = y = 0$, which implies a singularity in the mathematical solution there. The solution given by the boundary layer approximation is not valid at the leading edge. \n\n{% endnote %}\n\nDefine a stream function so that the continuity equation will be automatically included:\n$$\n\\begin{aligned}\n\\psi &= \\int u dy \\\\\nu = \\frac{\\partial\\psi}{\\partial y}&, \\quad v = -\\frac{\\partial \\psi}{\\partial x}\n\\end{aligned}\n$$\nSubscribe into the momentum equation to get an single variable equation:\n$$\n\\color{purple}\n\\frac{\\partial\\psi}{\\partial y} \\frac{\\partial^2\\psi}{\\partial x \\partial y}- \\frac{\\partial\\psi}{\\partial x} \\frac{\\partial^2\\psi}{\\partial y^2} = \\nu\\frac{\\partial^3\\psi}{\\partial y^3}\n$$\nwith boundary conditions:\n$$\n\\color{purple}\n\\begin{aligned}\n\\frac{\\partial\\psi}{\\partial y}=\\frac{\\partial\\psi}{\\partial x} = 0\\quad&\\mathrm{at}\\quad y = 0\\\\\n\\frac{\\partial\\psi}{\\partial y} = U\\quad&\\mathrm{at}\\quad x = 0 \\\\\n\\frac{\\partial\\psi}{\\partial y} \\rightarrow U\\quad&\\mathrm{as}\\quad y \\rightarrow \\infty \\\\\n\\end{aligned}\n$$\nThrough a coordinate transformation([similarity solution](https://en.wikipedia.org/wiki/Self-similar_solution)), this PDE can be transferred into an ODE and thus be solved easily.\n\n#### 5.5.2 Similarity solution\n\n> In the study of partial differential equations, particularly in fluid dynamics, a **self-similar solution** is a form of solution which is similar to itself if the independent and dependent variables are appropriately scaled. \n\nIn contrast to the most frequently used method of \"separation variables\", the similarity solution involves combining the variables in a special way. Another example of using similarity to solve Heat diffusion equation lies on the [Appendix A.2](#a.2-solving-the-heat-equation-using-similarity-solution).\n\nA self-similar equation doesn't change regardless how the variables scale. So assume a transformation:\n$$\n\\begin{aligned}\ny = \\lambda^a\\bar{y}\\\\\nx = \\lambda^b\\bar{x}\\\\\n\\psi = \\lambda^c\\bar{\\psi}\\\\\n\\end{aligned}\n$$\nThe resulting scaled function and writes:\n$$\n\\begin{aligned}\n\\lambda^{3c-2a-b}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{y}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{x} \\partial \\bar{y}}- \n\\lambda^{3c-2a-b}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{x}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{y}^2} =\n\\lambda^{3c-3a}\\nu\\frac{\\partial^3\\bar{\\psi}}{\\partial \\bar{y}^3} \\\\\n\\Leftrightarrow\\quad\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{y}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{x} \\partial \\bar{y}}- \n\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{x}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{y}^2} =\n\\lambda^{-3c-a+b}\\nu\\frac{\\partial^3\\bar{\\psi}}{\\partial \\bar{y}^3}\n\\end{aligned}\n$$\nAnd the scaled boundary conditions gives:\n$$\n\\begin{aligned}\n\\lambda^{c-a}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{y}}=\\lambda^{c-b}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{x}} = 0\\quad&\\mathrm{at}\\quad \\lambda^{a}\\bar{y} = 0\\\\\n\\end{aligned}\n$$\nAs a result, all the powers should be 0:\n$$\n\\left.\\begin{array}{c}\n\\left.\\begin{array}{c}\n-c-a+b=0 \\\\\nc-a=0\n\\end{array}\\right\\} \\quad b=a / 2 \\\\\nc-b=0 \\qquad \\qquad  \\quad\n\\end{array}\\quad\\right\\} \\quad c=a / 2\n$$\nHere I need to put my derivation here:\n\n> Similar to [Appendix A.2](#a.2-solving-the-heat-equation-using-similarity-solution), we can construct an expression of $\\psi$ as:\n> $$\n> \\psi(x,y)= x^{1/2}f^\\dagger(\\eta^\\dagger), \\quad \\eta^\\dagger = yx^{-1/2}\n> $$\n> {% note danger %}\n>\n> **Personal comment:** I still don't know how to construct this kinda thing or why it work. The formula in Appendix gives me some idea but following it I got $\\psi(x,y)= x^{1}f^\\dagger(\\eta^\\dagger)$, $\\eta^\\dagger = yx^{-1/2}$ instead...\n>\n> {% endnote %}\n>\n> Substitute the expression of $\\psi$ into the equation with $f^{\\dagger'} = \\partial_{\\eta^{\\dagger}}f^{\\dagger}$:\n> $$\n> \\begin{aligned}\n> \\frac{\\partial\\psi}{\\partial y} &= f^{\\dagger'} \\\\\n> \\frac{\\partial^2\\psi}{\\partial y^2} &= x^{-1/2}f^{\\dagger''} \\\\\n> \\frac{\\partial^3\\psi}{\\partial y^3}&= x^{-1}f^{\\dagger'''}\\\\\n> \\frac{\\partial\\psi}{\\partial x} &= \\frac{1}{2}x^{-1/2}f^{\\dagger}-\\frac{1}{2}x^{-1}f^{\\dagger'}y \\\\\n> &= \\frac{1}{2}x^{-1/2}(f^{\\dagger} -\\eta^{\\dagger} f^{\\dagger'}) \\\\\n> \\frac{\\partial^2\\psi}{\\partial x \\partial y} &= \\frac{1}{2}x^{-1/2}(x^{-1/2}f^{\\dagger'} -x^{-1/2}\\eta^{\\dagger} f^{\\dagger''} - x^{-1/2}f^{\\dagger'}) \\\\\n> &=-\\frac{1}{2}x^{-1}\\eta^{\\dagger} f^{\\dagger''}\\\\ \n> \\frac{\\partial\\psi}{\\partial y}\\frac{\\partial^2\\psi}{\\partial x \\partial y} &= f^{\\dagger'}\\left[-\\frac{1}{2}x^{-1}\\eta^{\\dagger} f^{\\dagger''}\\right] \\\\\n> &= -\\frac{1}{2}x^{-1} \\eta^{\\dagger}f^{\\dagger'}f^{\\dagger''} \\\\\n> -\\frac{\\partial\\psi}{\\partial x}\\frac{\\partial^2\\psi}{\\partial y^2} &=\\frac{1}{2}x^{-1/2}(f^{\\dagger} -\\eta^{\\dagger} f^{\\dagger'})\\left[x^{-1/2}f^{\\dagger''}\\right] \\\\\n> &= \\frac{1}{2}x^{-1}(f^{\\dagger} +\\eta^{\\dagger} f^{\\dagger'})f^{\\dagger''}\\\\\n> \\end{aligned}\n> $$\n> As a result:\n> $$\n> \\begin{aligned}\n> -\\frac{1}{2}x^{-1}\\eta^{\\dagger} f^{\\dagger'}f^{\\dagger''}+ \\frac{1}{2}x^{-1}(f^{\\dagger} &+\\eta^{\\dagger} f^{\\dagger'})f^{\\dagger''} = \\nu x^{-1}f^{\\dagger'''}\\\\\n> \\Leftrightarrow \\qquad \\nu f^{\\dagger'''} - &\\frac{1}{2} f^{\\dagger}f^{\\dagger''} = 0\n> \\end{aligned}\n> $$\n\nOk.. above is what I derived, it's still an ODE but normally we want a cleaner result.\n\nSo Blasius construct $\\psi$ and $\\eta$ with physical meaningful non-dimensional parameters to get (reference to [MECH 346  Heat Transfer's Youtube channel](https://youtu.be/Lw6aQJGD3FU)):\n$$\n\\color{purple}\n\\psi(x,y)= (\\nu Ux)^{1/2}f(\\eta), \\quad \\eta = \\left(\\frac{U}{\\nu x}\\right)^{1/2}y\n$$\nSo that:\n$$\n\\begin{aligned}\n\\eta = \\sqrt{\\frac{U}{\\nu x}}y,& \\quad\\mathrm{dimensionless~wall~normal~coordinate}\\\\\nf = \\frac{\\psi}{\\sqrt{\\nu Ux}},& \\quad\\mathrm{dimensionless~stream~function}\\\\\nf' = \\frac{u}{U},& \\quad\\mathrm{dimensionless~velocity~profile} \\\\\nf'' = \\frac{\\sqrt{\\nu Ux}}{U^2}\\partial_yu, &\\quad\\mathrm{related~to~shear~stress} \\\\\n\\end{aligned}\n$$\nAnd terms of the governing equation becomes:\n$$\n\\begin{aligned}\n\\frac{\\partial\\psi}{\\partial y} &= Uf' \\\\\n\\frac{\\partial^2\\psi}{\\partial y^2} &= {(U\\nu x)}^{-1/2}f'' \\\\\n\\frac{\\partial^3\\psi}{\\partial y^3}&= U^2x^{-1}f'''\\\\\n\\frac{\\partial\\psi}{\\partial x} &= \\frac{1}{2}(\\nu U/x)^{1/2}(f -\\eta f')\\\\\n\\frac{\\partial^2\\psi}{\\partial x \\partial y} &=-\\frac{1}{2}Ux^{-1}\\eta f''\n\\\\ \n\\frac{\\partial\\psi}{\\partial y}\\frac{\\partial^2\\psi}{\\partial x \\partial y} &= -\\frac{1}{2}U^2x^{-1}\\eta f'f''\\\\\n-\\frac{\\partial\\psi}{\\partial x}\\frac{\\partial^2\\psi}{\\partial y^2}\n&= \\frac{1}{2}U^2x^{-1}(f +\\eta f')f''\\\\\n\\end{aligned}\n$$\nAnd the ODE turns out to be:\n$$\n\\color{purple}\n2f''' +ff'' = 0\n$$\nResulting boundary condition is:\n$$\n\\color{purple}\n\\begin{aligned}\nf' = 0\\quad &at\\quad \\eta=0  \t\\quad\\mathrm{(no~slip)}\\\\\nf = 0\\quad &at\\quad \\eta=0 \t\t\\quad\\mathrm{(impenetrability)} \\\\\nf' = 1\\quad &at\\quad \\eta\\rightarrow\\infty \\quad(u = U\\mathrm{~free stream}) \\\\\nf'' = 0\\quad &at\\quad \\eta\\rightarrow\\infty \\quad(\\partial_yu=0,\\mathrm{unnecessary}) \\\\\n\\end{aligned}\n$$\n\n#### 5.5.3 Solving the similarity solution \n\nSplit the 3-order ODE into a set of 3 first order ODEs:\n$$\n\\left\\{\\begin{array}{l}\n\tf_p  = f' \\\\\n\tf_{pp} = f_p' \\\\\n\t2f'_{pp} +ff_{pp}  = 0\n\\end{array}\\right.\n$$\nwith boundary conditions:\n$$\n\\begin{aligned}\nf_p = 0\\quad &at\\quad \\eta=0  \t\\\\\nf = 0\\quad &at\\quad \\eta=0 \t\t\\\\\nf_p = 1\\quad &at\\quad \\eta\\rightarrow\\infty \\\\\nf_{pp} = 0\\quad &at\\quad \\eta\\rightarrow\\infty,\\mathrm{unnecessary} \\\\\n\\end{aligned}\n$$\nThe third boundary condition has no closed form solution, so we need to solve it numerically. \n\n1. One method of doing it is guessing another initial condition $f_{pp} = ?$ at  $\\eta=0$, integrating the equation from $\\eta=0$ with Runge-Kutta method to meet the 3rd boundary condition i.e. **transfer the boundary condition to the initial condition**.\n\n   {% note info %}\n\n   RungeKutta method is an effective and widely used numerical method for solving the initial-value problems of differential equations. It integrated the function discretely from zero in small steps ($h$) in an order of 4 (more on [LearnChemE's Youtube](https://youtu.be/kUcc8vAgoQ0)).\n   $$\n   \\left\\{\\begin{array}{l}\n   y_{n+1}=y_{n}+\\frac{1}{6}\\left(K_{1}+2 K_{2}+2 K_{3}+K_{4}\\right) \\\\\n   K_{1}=h f\\left(x_{n}, y_{n}\\right) \\\\\n   K_{2}=h f\\left(x_{n}+\\frac{1}{2} h, y_{n}+\\frac{1}{2} K_{1}\\right) \\\\\n   K_{3}=h f\\left(x_{n}+\\frac{1}{2} h, y_{n}+\\frac{1}{2} K_{2}\\right) \\\\\n   K_{4}=h f\\left(x_{n}+h, y_{n}+K_{3}\\right)\n   \\end{array}\\right.\n   $$\n   {% endnote %}\n\n   It turns out it meets the 3<sup>rd</sup> boundary condition when:\n   $$\n   f_{pp} = 0.332~at~ \\eta=0\n   $$\n   And the function looks like below:\n\n   <img src=\"Similarity solution.png\" alt=\"Numerical solution to the similarity solution, the 4 boundary conditions are fitted. After MECH 346  Heat Transfer's Youtube channel(https://youtu.be/Lw6aQJGD3FU)\" style=\"zoom:40%;\" />\n\n   From the solution, we can see the stream function $f$ first increases with a decreasing slop then approaches to a linear increase line. While the velocity profile $f'$ and shear stress $f''$ approach the 1 and 0 at the free stream respectively,\n\n2. Another method is solve $f_{pp}~at~ \\eta=0$ directly numerically. And the solution is:\n   $$\n   f_{pp} = 0.332096~at~ \\eta=0\n   $$\n   More on [MECH 346  Heat Transfer's Youtube channel](https://youtu.be/Lw6aQJGD3FU) and [MIT's note](https://web.mit.edu/fluids-modules/www/highspeed_flows/ver2/bl_Chap2.pdf).\n\n#### 5.5.4 Blasius results\n\nAs a consequence, similar to what we do based on the [Von Krmn results result](#laminar-results-von-k%C3%A1rm%C3%A1n-results), recall the definition of the boundary layer:\n$$\nf_p = \\frac{u|_\\delta}{U} =  0.99\n$$\nIt is easy to get \n\n- the boundary layer thickness:\n  $$\n  \\begin{aligned}\n  \\eta_1&=\\sqrt{\\frac{U}{\\nu x}}\\delta\\approx5.0 \\\\\n  \\Rightarrow \\delta &\\approx 5.0 \\sqrt{\\frac{\\nu x}{U}} \\\\\n  \\Rightarrow \\frac{\\delta}{x} &\\approx 5.0 \\sqrt{\\frac{\\nu}{Ux}} \\\\\n  \\color{purple}{\\frac{\\delta}{x} }&\\color{purple}{\\approx 5 Re_x^{-1/2}}\\\\\n  \\end{aligned}\n  $$\n  with $\\color{purple}Re_x= Ux/\\nu$ as the **streamwise Reynolds number**.\n\n- the thickness displacement:\n  $$\n  \\begin{aligned}\n  \\delta^* &= \\int_0^\\delta\\left(1-\\frac{u}{U}\\right)dy \\\\\n  &= \\sqrt{\\frac{\\nu x}{U}}\\int_0^{\\eta_1\\approx5.0 }\\left(1-f'\\right)d\\eta \\\\\n  &= \\sqrt{\\frac{\\nu x}{U}}\\left[\\eta_1 - f_1\\right]\\\\\n  \\end{aligned}\n  $$\n  with $f_1 \\approx 3.283$:\n  $$\n  \\begin{aligned}\n  \\color{purple}\\frac{\\delta^*}{x}\\approx 1.721 Re_x^{-1/2}\n  \\end{aligned}\n  $$\n  \n- the momentum displacement and the factor of friction:\n  $$\n  \\tau_w = \\rho\\nu\\frac{\\partial u}{\\partial y}|_{y=0} = \\rho\\nu U\\sqrt{\\frac{U}{\\nu x}}f''(0)\n  $$\n  with $f''(0) \\approx 0.332$:\n  $$\n  C_f = \\frac{\\tau_w}{1/2\\rho U^2} \\approx 0.664Re_x^{-1/2}\n  $$\n\n  $$\n  \\color{purple}\n  \\frac{\\theta}{x} \\approx 0.664Re_x^{-1/2}\n  $$\n\n- the shape factor:\n  $$\n  \\color{purple}\n  H = \\frac{\\delta^*}{\\theta} \\approx 2.59\n  $$\n\n### 5.6 Validity of the laminar results\n\nThe above results are based on the hypothesis that the boundary layer is thin enough so that the coupling with the outer flow is negligible. This theory breaks down as soon as $\\frac{\\delta}{x}=\\mathcal{O}(1)$ i.e. $\\frac{\\delta}{x}<0.1$. As a result, based on the Blasius result, the upper limit of the streamwise Reynolds number depends on transition to turbulence writes\n$$\n5Re_x^{-1/2}<0.1\\\\\n\\Rightarrow Re_{x,min} > 2500\n$$\nFor smaller $Re_x$, the interaction with the outer flow is important and leads to departures from these results.\n\nBesides, at a threshold Reynolds number, the boundary layer becomes **turbulent** and the results above do not hold. This critical value of the Reynolds number is $Re_c\\approx 3  10^6$. Usually, the surfaces are not smooth and transition occurs earlier, sometimes at Reynolds numbers as low as $10^5$.\n\n### 5.7 Comparison of the results\n\nSimilar to what we do based on the [Von Krmn results result](#laminar-results-von-k%C3%A1rm%C3%A1n-results), based on the Prandtl one-seventh power law, the turbulence results can be derived easily, here is the table of all results:\n\n| Results            | $\\delta/x$        | $\\delta^*/x$      | $H$    | $c_f$              |\n| ------------------ | ----------------- | ----------------- | ------ | ------------------ |\n| Blasius laminar    | $5.0Re_x^{-1/2}$  | $1.72Re_x^{-1/2}$ | $2.59$ | $0.664Re_x^{-1/2}$ |\n| Integral laminar   | $5.5Re_x^{-1/2}$  | $1.83Re_x^{-1/2}$ | $2.5$  | $0.73Re_x^{-1/2}$  |\n| Error              | $10\\%$            | $6\\%$             | $3\\%$  | $10\\%$             |\n| Integral turbulent | $0.16Re_x^{-1/7}$ | $0.02Re_x^{-1/7}$ | $1.3$  | $0.027Re_x^{-1/7}$ |\n\nSeveral points:\n\n- There is an error of less than 10% between integral and Blasius results.\n- The boundary layer thickness $\\delta$ grows like $x^{6/7}$ for turbulent flows, which represents a faster growth than the $x^{1/2}$ law for the laminar boundary layer.\n- The viscous displacement thickness $\\delta^*$  and the shape factor $H=\\delta^*/\\theta$ for turbulent boundary layers is very small.\n- The skin friction coefficient $c_f$ is greater for turbulent boundary layers than for the laminar ones.\n\n## Appendix\n\n### A.1 Governing equation of boundary layers\n\n#### A.1.1 Scalings\n\nStarted by scaling the spatial derivatives:\n$$\n\\partial_x \\sim \\frac{1}{L} \\qquad \\partial_y \\sim \\frac{1}{\\delta}\n$$\nBy the thin-layer condition: $L\\gg\\delta$, we can introduce a small parameter $\\epsilon \\ll 1$ as:\n$$\n\\frac{\\delta}{L} = \\epsilon\n$$\nAs a result, introduce the stream function $\\psi$ under the conditions of 2D and incompressibility. The proportion of the streamwise and normal streamwise velocities $u, v$ can be expressed as:\n$$\n\\frac{u}{v} = \\frac{\\partial_y\\psi}{-\\partial_x\\psi}\\sim\\frac{L}{\\delta}\n$$\nwhich gives:\n$$\n\\Rightarrow \\quad v\\sim\\epsilon u\n$$\nimplying that the $v$ is much smaller than $u$.\n\nThen rescale the wall normal quantities according to the streamwise quantities:\n$$\n\\begin{aligned}\nx^* &= \\frac{x}{L} \\\\\ny^* &= \\frac{y}{\\delta} = \\frac{y}{\\epsilon L}\\\\\nu^* &= \\frac{u}{U} \\\\\nv^* &= \\frac{v}{\\epsilon U} \\\\\np^* &= \\frac{p}{\\rho U^2}\n\\end{aligned}\n$$\n{% note info %}\n\nIn this case, $p^*$ can be thought of as a mathematical function to ensure incompressibility of the scaled function.\n\n{% endnote %}\n\n#### A.1.2 Asymptotic derivation\n\nSubstitute the scaled variables into the governing equations:\n$$\n\\begin{aligned}\n\\frac{U}{L} \\partial_{x^{*}} u^{*}+\\frac{\\epsilon U}{\\epsilon L} \\partial_{y^{*}} v^{*} &= 0 \\\\\n\\frac{U^{2}}{L} u^{*} \\partial_{x^{*}} u^{*}+\\frac{U^{2}}{L} v^{*} \\partial_{y^{*}} u^{*}&=-\\frac{ U^{2}}{L} \\partial_{x^{*}} p^{*}+\\nu\\left(\\frac{U}{L^{2}} \\partial_{x^{*}}^{2} u^{*}+\\frac{U}{\\epsilon^{2} L^{2}} \\partial_{y^{*}}^{2} u^{*}\\right) \\\\\n\\frac{\\epsilon U^{2}}{L} u^{*} \\partial_{x^{*}} v^{*}+\\frac{\\epsilon U^{2}}{L} v^{*} \\partial_{y^{*}} v^{*} &=-\\frac{ U^{2}}{\\epsilon L} \\partial_{y^{*}} p^{*}+\\nu\\left(\\frac{\\epsilon U}{L^{2}} \\partial_{x^{*}}^{2} v^{*}+\\frac{U}{\\epsilon L^{2}} \\partial_{y^{*}}^{2} v^{*}\\right)\n\\end{aligned}\n$$\nCan be simplified into:\n$$\n\\begin{aligned}\n\\partial_{x^{*}} u^{*}+\\partial_{y^{*}} v^{*} &= 0 \\\\\nu^{*} \\partial_{x^{*}} u^{*}+v^{*} \\partial_{y^{*}} u^{*} &=-\\partial_{x^{*}} p^{*}+\\frac{1}{Re_{L}} \\partial_{x^{*}}^{2} u^{*}+\\frac{1}{\\epsilon^{2} Re_{L}} \\partial_{y^{*}}^{2} u^{*} \\\\\nu^{*} \\partial_{x^{*}} v^{*}+v^{*} \\partial_{y^{*}} v^{*} &=-\\frac{1}{\\epsilon^{2}} \\partial_{y^{*}} p^{*}+\\frac{1}{Re_{L}} \\partial_{x^{*}}^{2} v^{*}+\\frac{1}{\\epsilon^{2} Re_{L}} \\partial_{y^{*}}^{2} v^{*}\n\\end{aligned}\n$$\nwhere $Re_L = UL/\\nu$\n\nTo keep a balance between the advection(LHS) and diffusion (RHS), impose:\n$$\n\\epsilon^2Re_L=1 \\\\\n\\Rightarrow \\epsilon = \\frac{\\delta}{L}=Re_L^{-1/2}\n$$\nAs a result, the leading order of the system is:\n$$\n\\begin{aligned}\n\\partial_{x^{*}} u^{*}+\\partial_{y^{*}} v^{*} &= 0 \\\\\nu^{*} \\partial_{x^{*}} u^{*}+v^{*} \\partial_{y^{*}} u^{*} &=-\\partial_{x^{*}} p^{*}+\\partial_{y^{*}}^{2} u^{*} \\\\\n0&=\\partial_{y^{*}} p^{*}\n\\end{aligned}\n$$\n\n### A.2 Solving the heat equation using similarity solution\n\nReferences[Dr Chris Tisdell's Youtube](https://youtu.be/dNLmvhZWEq8), [UCL's class note](https://www.ucl.ac.uk/~ucahhwi/LTCC/sectionB-similarity.pdf).\n\nGiven PDE with boundary and initial conditions:\n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} =& k\\frac{\\partial^2 u}{\\partial x^2}\\\\\nu(x,0)=0, &\\quad x>0\\\\\nu(x,t)\\rightarrow0, &\\quad x\\rightarrow\\infty \\\\\n\\partial_x u(0,t)=N, &\\quad t>0\n\\end{aligned}\n$$\n\n1. Determine a set of transformations:\n   $$\n   \\begin{aligned}\n   x &= \\lambda^a\\bar{x}\\\\\n   t &= \\lambda^b\\bar{t}\\\\\n   u &= \\lambda^c\\bar{u}\\\\\n   \\end{aligned}\n   $$\n   Substitute into the equation:\n   $$\n   \\begin{aligned}\n   \\lambda^{c-b}\\frac{\\partial \\bar{u}}{\\partial \\bar{t}} = \\lambda^{c-2a}k\\frac{\\partial^2 \\bar{u}}{\\partial \\bar{x}^2} \\\\\n   \\frac{\\partial \\bar{u}}{\\partial \\bar{t}} = \\lambda^{-2a+b}k\\frac{\\partial^2 \\bar{u}}{\\partial \\bar{x}^2}\n   \\end{aligned}\n   $$\n   Boundary condition:\n   $$\n   \\begin{aligned}\n   \\frac{\\partial u}{\\partial x} =N, \\quad t>0 \\\\\n   \\lambda^{c-a}\\frac{\\partial \\bar{u}}{\\partial \\bar{x}}=N\n   \\end{aligned}\n   $$\n   \n\n   As a result:\n   $$\n   \\begin{aligned}\n   -2a+b &= 0 \\\\\n   c-a&=0\n   \\end{aligned}\n   $$\n\n2. Determin $s$ and $r$ such that:\n   $$\n   \\bar{x\\vphantom{t}}\\bar{t}^s=xt^s\\qquad \\bar{u\\vphantom{t}}\\bar{t}^r = ut^r\n   $$\n   Substitute we have:\n   $$\n   \\begin{aligned}\n   \\bar{x\\vphantom{t}}\\bar{t}^s&=xt^s \\\\\n   \\bar{x\\vphantom{t}}\\bar{t}^s &= \\lambda^{a+sb}\\bar{x\\vphantom{t}}\\bar{t}^s  \\\\\n   \\Rightarrow \\quad s &= -a/b =  -1/2\n   \\end{aligned}\n   $$\n   and\n   $$\n   \\begin{aligned}\n   \\bar{u\\vphantom{t}}\\bar{t}^r&=ut^r \\\\\n   \\bar{u\\vphantom{t}}\\bar{t}^r &= \\lambda^{c+rb}\\bar{x\\vphantom{t}}\\bar{t}^r = \\lambda^{(c+2ar)}\\bar{x\\vphantom{t}}\\bar{t}^r\\\\\n   \\Rightarrow \\quad r &= -c/b = -1/2\n   \\end{aligned}\n   $$\n\n3. With two terms unchanged by the transformation. A solution combines these two terms can be constructed as $u(x,t) = t^{-r}f(xt^s) = t^{-r}f(\\eta)$:\n   $$\n   \\begin{aligned}\n   u(x,t) = t^{c/b}f(\\eta), \\quad\\mathrm{where~}\\eta = xt^{-a/b} \\\\\n   \\Leftrightarrow\\quad u(x,t) = t^{1/2}f(\\eta),\\quad\\mathrm{where~}\\eta = \\frac{x}{t^{1/2}}\n   \\end{aligned}\n   $$\n   {% note info %}\n   \n   Note that $u(x,t) = t^{c/b}f(\\eta), \\quad \\eta = xt^{-a/b}$ is a general solution and it suits for every conditions.\n   \n   {% endnote %}\n   \n4. Substitute into the original function to get a ODE:\n   $$\n   \\begin{aligned}\n   \\frac{\\partial u}{\\partial t} &= \\frac{1}{2}t^{-1/2}f - \\frac{1}{2}t^{-1}xf' \\\\ &= \\frac{1}{2}t^{-1/2}f - \\frac{1}{2}t^{-1/2}\\eta f'\\\\&=\\frac{1}{2}t^{-1/2}\\left(f-\\eta f'\\right)\\\\\n   \\frac{\\partial^2 u}{\\partial x^2} &= t^{-1/2}f''\\\\\n   \\end{aligned}\n   $$\n   The resulting equation is therefore:\n   $$\n   \\begin{aligned}\n   &\\frac{1}{2}t^{-1/2}\\left(f-\\eta f'\\right)= kt^{-1/2}f'' \\\\\n   \\Leftrightarrow\\quad& \\frac{1}{2}\\left(f-\\eta f'\\right)= kf'' \\\\\n   \\Leftrightarrow\\quad& 2kf''+\\eta f'-f = 0\n   \\end{aligned}\n   $$\n   \n   The following work is solving this ODE, which is illustrated more on [UCL's class note](https://www.ucl.ac.uk/~ucahhwi/LTCC/sectionB-similarity.pdf).\n\n","source":"_posts/External-flow-fundamentals.md","raw":"---\ntitle: External flow fundamentals\nauthor: Ryan LI\ntoc: true\ndeclare: true\nindex_img: /index/external_flow.png\ntags:\n  - fluid dynamics\ndate: 2022-05-26 13:15:15\n---\n\n{% note primary %}\n\nInternal pipe flow is not enough for me, continue to review the tricky part.\n\n{% endnote%}\n\n<!-- more -->\n\n## 4 Fluid-structure interaction\n\nWhen an unbounded homogeneous flow approaches an obstacle, viscous effects become important and substantially deform the flow profile. The resulting boundary layers and wakes are responsible for generating forces and moments on the obstacle.\n\n### 4.1 Examples\n\n#### 4.1.1 Lift generation\n\nHere comes the most popular question: how does an aircraft fly?\n\nThe basic answer is that \n\n> The airfoil is shaped so that its upper surface is longer than its lower surface. A parcel of fluid arriving at the leading edge then splits into two parcels, one following the upper surface and the other the lower surface. As the fluid has more distance to travel on the upper surface than on the lower surface, it goes faster to have the **same transit time**. The Bernoulli effect follows: the higher velocity on the upper surface yields a lower pressure and an ascending force is created: the lift.\n\nThe use of Bernoulli effect is, to some extent, correct. However, based on experiment findings shown below, the same transit time assumption is not quite right. \n\nI\\bar{t}s clear the upper flow is accelerated compared to the lower flow. This happens already at the leading edge, but the lower flow never catches up with the upper one. As a result, the upper flow possesses a shorter transit time.\n\n<img src=\"Flow past an airfoil.gif\" alt=\"Flow past an airfoil visualised through the trajectory of one pulse of smoke. After Babinsky (http://www.cam.ac.uk/research/news/how-wings-really-work).\" style=\"zoom:100%;\" />\n\nAs a consequence, the physical mechanism behind lift is not so simple. A plausible answer is twofolds. \n\n- On the one hand, the fluid is accelerated on the upper surface and slowed down on the lower surface, creating a descending pressure gradient, hence lift.\n- On the other hand, the fluid trajectory is overall deflected downwards when passing the airfoil. This implies that the airfoil creates a descending force onto the fluid, and, by Newtons third law, that the fluid generates an ascending force onto the airfoil.\n\n#### 4.1.2 Wingtip vortices\n\nAt the tip of the wing, when the lower pressure upper surface meets the higher pressure lower surface, wingtip vortices are generated. These vortices are generally strong, long-lived and consequently dangerous, as shown below:\n\n<img src=\"Wingtip vortex.jpeg\" alt=\"Wingtip vortex behind a plane visualised with red smoke.\" style=\"zoom:50%;\" />\n\nFlying through such a vortex will create a rolling moment that can destabilize the flight.\nMany such incidents have happened during takeoff and landing. As a result, airports have decided on quiet periods of one to two minutes between two successive takeoffs or landings to allow for these vortices to dissipate to a less dangerous strength.\n\n<img src=\"V formation.jpeg\" alt=\"Birds flying in V-formation.\" style=\"zoom:50%\" />\n\nYet the wingtip vortices are leveraged perfectly by the nature, the V-formation. When one bird follows another bird, it places itself a little bit on the side to benefit from the lift generated by the wingtip vortices of its leader.\n\n#### 4.1.3 Others\n\nWind and ocean engineering also present important challenges in the area of fluid-structure interaction. \n\nThe construction of tall building is necessary to accommodate large professional centres and these tall buildings interact strongly with the wind. Similar issues arise with bridges. Serious oscillation would be generated due to the \"wind load\". \n\n<p align=\"center\">\n  <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/tHMPR7flpf4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></p>\n\nIn water, it is important to understand fluid-structure interactions to design efficient breakwaters and protect constructions on the shore or beaches. Pier piles are also good examples of structures interacting with water and that have to be designed carefully.\n\nLastly, we can take advantage of natural phenomena such as wind and currents by designing structures that will store such energy like wind and water turbines.\n\n### 4.2 Effect of a structure on the fluid\n\nWhen an external flow goes past an obstacle, boundary layer and wake effects occur on the walls and after the obstacle respectively. \n\n#### 4.2.1 Boundary layers\n\n<img src=\"Boundary layers.png\" alt=\"Sketch of the flow past a sharp flat plate oriented in the direction of the flow.\nTwo situations are shown: a low-Re flow (ReL= 10) and a high-Re flow (ReL= 107) and the associated boundary layers depicted. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" />\n\n**Convenient definition**: a region where the fluids velocity parallel to the wall is smaller or equal to 99% of the external velocity.\n\n- Inside the boundary layer, the flow feels the effect of the wall and is gradually slowed down as we approach the wall. The presence of these velocity gradients is a consequence of **viscous dissipation**.\n- Outside the boundary layer, the flow does not feel the presence of the walls. It remains homogeneous and is considered **inviscid**.\n\n{% note info %}\n\nNote that this is only an assumption, the interaction between the boundary layer and the outer pressure distribution is neglected. For slender bodies at large $Re$, such as airfoils, when placed parallel to the flow, this assumption provides good results due to the thin and weak boundary layer.\n\n{% endnote %}\n\nThere are **two types** of the boundary layers defined by the Reynolds number:\n\n- Low $Re$, laminar boundary layer. Because spatial variations are slow, the laminar boundary layer occupies a large spatial region.\n- High $Re$, two distinct regions in the boundary layer:\n  - laminar boundary layer similar to that of low-Re flows but much thinner \n  - turbulent boundary layer that occurs further away in the streamwise direction and is larger than the laminar boundary layer. \n\nThe **viscous displacement effect** describes the non-zero velocity in the direction orthogonal to the wall because the velocity parallel to the wall varies in the direction orthogonal to the wall.\n\n- For low $Re$ laminar boundary layers, this effect is important\n- For high $Re$ boundary layers, these boundary layers are so thin that this effect is negligible.\n\n#### 4.2.2 Wakes\n\n<img src=\"Wakes.png\" alt=\"Sketch of the wake past a cylinder and the different regimes observed as a function of the Reynolds number Re = UR/, where U is the velocity of the fluid infinitely far away from the cylinder, R the cylinder radius and  the fluids kinematic viscosity. After Middleton & Southard, Mechanics of Sediment Movement, SEPM Short Course Notes, Vol. 3 (1984).\" style=\"zoom:50%;\" />\n\nWhen the inertia is non-trivial (equivalently viscous effects are not overwhelmingly dominant), the gradients of velocity induced by the boundary layer are advected downstream and create a **wake** past the obstacle. This region can display dramatic departures from the established flow infinitely far away from the obstacle.\n\nThe sketch above shows how several typical regimes of the wake past a cylinder in different $Re$s:\n\n- Low $Re$: steady and symmetric flow\n- $Re=\\mathcal{O}(10)$: \n  - the upstream-downstream symmetry is broken\n  - flow separation occurs. The boundary layers separate from the wall and a recirculation zone is created where two counter-rotating vortices live. \n  - wake remains stationary\n  - the up-down symmetry is still preserved\n- $Re=\\mathcal{O}(100)$: \n  - the up-down symmetry is broken \n  - flow separation developed\n  - wake is now periodic in time, vortices periodically break away from the back of the cylinder in an alternate fashion and are advected downstream\n  - This type of wake is called **Von Krmn streets**.\n- $Re>\\mathcal{O}(1000)$: any simple time-dependence in the wake is lost and it is now turbulent.\n\nNote that as the Reynolds number is increased, different types of turbulent wakes can be observed.\n\n- At $Re = 5\\times10^3$, the turbulent wake is detached from the wall and a laminar bubble is observed at the back of the cylinder.\n- As the Reynolds number is increased, this bubble shrinks\n- At $Re = 10^5$, the back of the cylinder has become fully turbulent\n- As Re is further increased, the turbulent wake becomes thinner and thinner and the influence of the cylinder on the flow decreases. This is the result of the fact that the characteristic length for advection becomes incomparably larger than the diameter of the cylinder\n\n### 4.3 Effect of the fluid on a structure\n\nIn this section, we look at the opposite interaction: the impact of boundary layers and wakes on the structures.\n\n#### 4.3.1 Free kick like Cristiano Ronaldo\n\n<p align=\"center\">\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MscZ_pd7iAM?start=12\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</p>\n\nPersonally, I'm not a big fan of football. The only football game I watch is FIFA. And I happened to watch this legendary game on live. I remember it was 3 o'clock in the morning and I barely held my scream. \n\n<img src=\"magnus effect illustration.png\" alt=\"Illustration of the Magnus effect using a downward flow past an anti-clockwise rotating sphere. The flow is slowed down on the right as opposed to the left. The pressure is then greater on the right of the sphere and a leftward force is generated.\" style=\"zoom:50%;\" />\n\nThe explanation of such a trajectory lies in the **Magnus effect** which describes a spinning object moving through a fluid. Rotating the ball accelerates the flow on one side while slowing it down on the other. This difference of velocity breaks the symmetry of the flow and creates a difference of pressure. And this results in an additional force that bends the trajectory of the ball.\n\n#### 4.3.2 The Tacoma Narrows bridge\n\n<p align=\"center\"> <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XggxeuFDaDU?start=15\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe> </p>\n\nAnother famous aeroelastic failure is this 1.8km long bridge in the state of Washington. The 6 million dollar bridge collapsed in a steady standard wind in November, 1940, only 3 months after its opening date. Back then this wind interacted in an unexpected manner with the bridge and created a positive feedback loop called **aeroelastic flutter**. A oscillating wake  due to the periodic vortex shedding excited a **second torsional mode**: the midpoint of the bridge remained motionless while the two opposite halves twisted in opposite directions. This torsion further enhanced the strength of the wake, which in turn enhanced the torsion until the bridge collapsed.\n\n## 5 Boundary layer theory  Integral approach\n\nFirst, a control volume is defined as blow:\n\n- Boundary : the segment $(0, 0)$ to $(0, h)$, where $\\mathbf{u} = U\\mathbf{\\hat{x}}$.\n- Boundary : the streamline $(0, h)$ to $(L, \\delta)$, where $\\mathbf{u}\\cdot \\mathbf{n} = 0$.\n- Boundary : the segment $(L, \\delta)$ to $(L, 0)$, where $ \\mathbf{u}= u(x, y)\\mathbf{\\hat{x}} + v(x, y)\\mathbf{\\hat{y}}$.\n- Boundary : the plate surface and streamline $(L, 0)$ to $(0, 0)$, where $u = 0$.\n\n<img src=\"Boundary layer control volume.png\" alt=\"Sketch of a developing boundary layer on a flat plate. The control volume used is delimited by the boundaries labeled , ,  and .\" style=\"zoom:30%;\" />\n\n### 5.1 Viscous displacement\n\n#### 5.1.1 Physical origin\n\nThe viscous displacement determines the upstream streamlines parallel to the wall to move away from the wall i.e. boundary  to tilt upward. It can be explained by the 2D compressible continuity equation:\n$$\n\\partial_x u+\\partial_y v=0\n$$\nNear the boundary , the no-slip condition gives $\\partial_xu<0$, to compensate for it, $\\partial_yv>0$, and the consequence of this is the viscous displacement.\n\n#### 5.1.2 Displacement thickness\n\n<img src=\"displacement thickness.png\" alt=\"Actual viscous boundary layer vs analogy with an inviscid flow displaying the same flow rate. The wall-normal delay * necessary to obtain the same flow rate is called displacement thickness.\" style=\"zoom:30%;\" />\n\nThe quantity $\\delta^*$ is called **displacement thickness** and represents the distance by which the wall would have to be moved in the wall normal direction to **obtain the same flow rate** in an inviscid flow. i.e. the additional blockage/deflection due to viscosity.\n\nBy definition, it is easy to conclude that $\\delta = \\delta^*+h$. And by mass conservation between the inlet and the outlet, the displacement thickness can be described:\n$$\n\\begin{aligned}\n\\rho\\int_1(\\mathbf{u}\\cdot\\mathbf{n})ds&+\\rho\\int_3(\\mathbf{u}\\cdot\\mathbf{n})ds =0 \\\\\n\\int^{\\delta-\\delta^*}_0(-U&)dy+\\int^\\delta_0udy=0 \\\\\nUh&= \\int^\\delta_0udy \\\\\n\\end{aligned}\n$$\nSubstitute $h$ with $\\delta-\\delta^*$ :\n$$\n\\begin{aligned}\nU(\\delta-\\delta^*) &= \\int^\\delta_0udy \\\\\nU(\\delta-\\delta^*) &= \\int^\\delta_0\\left(u+U-U\\right)dy \\\\\nU(\\delta-\\delta^*) &= U\\delta+\\int^\\delta_0\\left(u-U\\right)dy \\\\\n\\Rightarrow \\quad\\delta^* = \\int_0^\\delta&\\left(1-\\frac uU\\right)dy\\\\\n\\Rightarrow \\quad\\color{purple}{\\frac{\\delta^*}{\\delta} = \\int_0^1}&\\color{purple}{\\left(1-\\frac uU\\right)d\\eta}, \\quad\\mathrm{where~}\\eta=\\frac{y}{\\delta}\\\\\n\\end{aligned}\n$$\n\n### 5.2 Friction drag\n\n#### 5.2.1 Drag as a boundary layer effect\n\nAssume a constant pressure throughout the domain, and a steady flow. The conservation of momentum in $\\mathbf{\\hat{x}}$ writes:\n$$\n\\begin{aligned}\n\\rho\\int_1u(0,y)(\\mathbf{u}\\cdot\\mathbf{n})ds + \n\\underbrace{\\rho\\int_2u(x,y)(\\mathbf{u}\\cdot\\mathbf{n})ds+}_{\\mathrm{streamline:~}\\mathbf{u}\\cdot\\mathbf{n}=0} ...\\\\\n\\rho\\int_3u(L,y)(\\mathbf{u}\\cdot\\mathbf{n})ds+\n\\underbrace{\\rho\\int_4u(x,0)(\\mathbf{u}\\cdot\\mathbf{n})ds}_{\\mathrm{wall:~}u=0}=\n\\Sigma F_x = -D\\mathbf{\\hat{x}}\n\\end{aligned}\n$$\nThe equation simplifies into:\n$$\n\\begin{aligned}\n\\rho\\int_0^hU(-U)dy + \\rho\\int_0^\\delta u^2dy=-D \\\\\n\\Rightarrow\\qquad D = \\rho hU^2 -\\rho\\int_0^\\delta u^2dy\n\\end{aligned}\n$$\nCombine with the **mass conservation** result $Uh= \\int^\\delta_0udy$:\n$$\n\\begin{aligned}\nD &= \\rho \\int_0^\\delta Uudy-\\rho\\int_0^\\delta u^2dy \\\\\n\\color{purple}{D }&\\color{purple}{= \\rho \\int_0^\\delta \\frac{u}{U}\\left(1-\\frac{u}{U}\\right) dy}\n\\end{aligned}\n$$\n\n#### 5.2.2 Momentum thickness\n\nThe quantity $\\theta$ is called **momentum thickness** and represents the distance by which the wall would have to be moved in the wall normal direction to **obtain the same momentum** in an inviscid flow. \n$$\n\\color{purple}\\frac{\\theta}{\\delta} = \\frac{D}{\\rho U^2\\delta} = \\int_0^1 \\frac{u}{U}\\left(1-\\frac{u}{U}\\right) d\\eta, \\quad \\mathrm{where~}\\eta = \\frac{y}{\\delta}\n$$\ni.e. the **momentum deficit** can be determined by:\n$$\n\\rho U^2\\theta = \\rho \\int_0^\\delta \\frac{u}{U}\\left(1-\\frac{u}{U}\\right)dy\n$$\n{% note info %}\n\nThere is another **Energy thickness** writes:\n$$\n\\color{purple}\\frac{\\theta'}{\\delta} = \\int_0^1 \\frac{u}{U}\\left(1-\\frac{u^2}{U^2}\\right) d\\eta, \\quad \\mathrm{where~}\\eta = \\frac{y}{\\delta}\n$$\n{% endnote %}\n\nWe can then define the **shape factor**:\n$$\nH = \\frac{\\delta^*}{\\theta}\n$$\n{% note info %}\n\nShape factor indicates the wall-normal distance on which the fluid is deflected from the plate compared to that on which gradients of streamwise velocities are felt.A large shape factor indicates a flow near separation.\n\n{% endnote %}\n\n#### 5.2.3 Relation to wall shear stress\n\nThe drag force is the integration of wall shear stress $\\tau_w$ along the plate:\n$$\nD = \\int_0^L\\tau_wdx\n$$\nOr in differential form:\n$$\n\\tau_w = \\partial_xD\n$$\nDifferentiate the momentum thickness representation:\n$$\n\\partial_x\\theta = \\frac{\\partial_xD}{\\rho U^2}=\\frac{\\tau_w}{\\rho U^2}\n$$\nAs a result, the wall shear:\n$$\n\\color{purple}\\tau_w = \\rho U^2\\partial_x\\theta\n$$\n\n### 5.3 Velocity profile approximations\n\nFor *laminar* boundary layers,  Von Krmn assumed that the velocity profile ($\\frac{u}{U}$) within the boundary layer had a parabolic shape:\n\nGiven:\n$$\n\\eta = \\frac{y}{\\delta(x)}\n$$\nThe velocity profile ($\\frac{u}{U}$) writes:\n$$\n\\frac{u}{U}\\approx 2\\eta -\\eta^2, \\qquad 0\\leq \\eta\\leq 1\n$$\nFor *turbulent* boundary layers, Prandtl highlighted a one-seventh power velocity profile:\n$$\n\\frac{u}{U}\\approx\\eta^\\frac{1}{7}, \\qquad 0\\leq \\eta\\leq 1\n$$\nThese first order approximations are very close to the reality as shown below:\n\n<img src=\"velocity profiles.png\" alt=\"Comparison of velocity profiles u/U in the boundary layer y/ < 1 between the Von Krmn and Prandtls approximations and the actual laminar and turbulent flows. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" />\n\n### 5.4 Laminar results (Von Krmn results)\n\nBased on Von Krmn's approximation, $\\frac{u}{U}\\approx \\frac{2y}{\\delta} -\\left(\\frac{y}{\\delta}\\right)^2$. It is easy to get:\n\n- Boundary thickness:\n\n  The key point is that the wall shear stress can be expressed in two ways, \n\n  - by definition:\n    $$\n    \\begin{aligned}\n    \\tau_w &= \\mu \\partial_yu|_{y=0} \\\\\n    \\Rightarrow \\quad \\tau_{w} &\\approx \\mu \\partial_{y}\\left.\\left(\\frac{2 y}{\\delta}-\\frac{y^{2}}{\\delta^{2}}\\right)\\right|_{y=0} \\\\\n    \\Rightarrow \\quad \\tau_{w} &\\approx \\mu \\frac{2 U}{\\delta}\\\\\n    \\end{aligned}\n    $$\n\n  - and by the derivative of drag:\n    $$\n    \\begin{aligned}\n    \\tau_w &= \\rho U^2\\partial_x\\theta \\\\\n    \\Rightarrow \\quad \\tau_{w} &\\approx \\rho U^2\\partial_x\\left[\\int_{0}^{\\delta}\\left(\\frac{2 y}{\\delta}-\\frac{y^{2}}{\\delta^{2}}\\right)\\left(1-\\frac{2 y}{\\delta}+\\frac{y^{2}}{\\delta^{2}}\\right) d y \\right] \\\\\n    \\Rightarrow \\quad \\tau_{w} &\\approx \\frac{2\\rho U^2}{15}\\partial_x\\delta\n    \\end{aligned}\n    $$\n\n  As a result, connect these expressions:\n  $$\n  \\begin{aligned}\n  &\\mu \\frac{2 U}{\\delta} \\approx \\frac{2\\rho U^2}{15}\\partial_x\\delta \\\\\n  \\Rightarrow \\quad &\\int_0^x dx \\approx \\int_0^\\delta \\frac{\\rho U}{15}\\delta d\\delta \\\\\n  \\Rightarrow \\quad &x \\approx \\frac{\\rho U \\delta^2}{30\\mu} \\\\\n  \\Rightarrow \\quad & \\left(\\frac{\\delta}{x}\\right)^2 \\approx \\frac{30\\mu}{\\rho U x} \\\\\n  \\Rightarrow \\quad & \\color{purple}{\\frac{\\delta}{x}  \\approx 5.5 Re_x^{-1/2}} \\\\\n  \\end{aligned}\n  $$\n  where $\\color{purple}Re_x= Ux/\\nu$ as the **streamwise Reynold**.\n\n- the displacement thickness:\n  $$\n  \\begin{aligned}\n  \\delta^* &= \\int_0^\\delta\\left(1-\\frac{u}{U}\\right)dy \\\\\n  &\\approx \\int_0^\\delta\\left(1-\\frac{2y}{\\delta}+\\left(\\frac{y}{\\delta}\\right)^2\\right)dy \\\\\n  \\Rightarrow \\quad \\delta^*&\\approx \\frac{1}{3}\\delta\\\\\n  \\end{aligned}\n  $$\n  with the boundary thickness expression:\n  $$\n  \\begin{aligned}\n  \\color{purple}\\frac{\\delta^*}{x}\\approx 1.83 Re_x^{-1/2}\n  \\end{aligned}\n  $$\n\n- the momentum displacement and the factor of friction:\n  $$\n  \\begin{aligned}\n  \\theta &= \\int_{0}^{\\delta}\\left(\\frac{2 y}{\\delta}-\\frac{y^{2}}{\\delta^{2}}\\right)\\left(1-\\frac{2 y}{\\delta}+\\frac{y^{2}}{\\delta^{2}}\\right) d y \\\\\n  \\Rightarrow \\quad & \\theta \\approx \\frac{2}{15}\\delta \\\\\n  \\Rightarrow \\quad & \\color{purple}{\\frac{\\theta}{x}  \\approx 0.73 Re_x^{-1/2}} \n  \\end{aligned}\n  $$\n  The factor of friction has the same order with the momentum displacement, as\n  $$\n  \\color{purple}{C_f   \\approx 0.73 Re_x^{-1/2}}\n  $$\n\n- the shape factor:\n  $$\n  \\color{purple}\n  H = \\frac{\\delta^*}{\\theta} \\approx 2.5\n  $$\n\n### 5.5 Laminar results (Blasius results)\n\nReference to [MIT's note](https://web.mit.edu/fluids-modules/www/highspeed_flows/ver2/bl_Chap2.pdf), [MECH 346  Heat Transfer's Youtube channel](https://youtu.be/Lw6aQJGD3FU)\n\n#### 5.5.1 Governing equations\n\nConditions:\n\n- 2D\n\n- Steady\n\n- Incompressible\n\n- Neglect viscous dissipation, gravity and thermal dissipation\n\n- Plus the **thin layer assumption ($L\\gg\\delta$)** for boundary layer (Obtained by non-dimensional scaling analysis, Full deriving on [Appendix A.1](#a.1-governing-equation-of-boundary-layers)): \n  $$\n  \\begin{aligned}\n  u&\\gg v \\\\\n  \\frac{\\partial}{\\partial y}&\\gg\\frac{\\partial}{\\partial x}\n  \\end{aligned}\n  $$\n\nThe mass and momentum conservation equations reduces to: \n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} &= 0 \\\\\nu\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y}&=-\\frac{1}{\\rho}\\frac{\\partial p}{\\partial x}+\n\\nu\\left(\\overbrace{\\frac{\\partial^2u}{\\partial x^2}}^{\\mathrm{0}}+\\frac{\\partial^2u}{\\partial y^2}\\right) \\\\\nu\\frac{\\partial v}{\\partial x}+v\\frac{\\partial v}{\\partial y}&=\n\\underbrace{-\\frac{1}{\\rho}\\frac{\\partial p}{\\partial y}}_{\\text{principle order}}+\\nu\\left(\\frac{\\partial^2v}{\\partial x^2}+\\frac{\\partial^2v}{\\partial y^2}\\right)\n\\end{aligned}\n$$\nas a result:\n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} &= 0 \\\\\nu\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y}&=-\\frac{1}{\\rho}\\frac{\\partial p}{\\partial x}+\\nu\\frac{\\partial^2u}{\\partial y^2} \\\\\n\\frac{1}{\\rho}\\frac{\\partial p}{\\partial y}&=0\n\\end{aligned}\n$$\n\nFor the flat plate boundary layer, it is easy to get $\\frac{\\partial p}{\\partial x}=0$ because the free stream pressure gradient in the $x$ direction is $0$, so as in the boundary layer given the $\\frac{\\partial p}{\\partial y}=0$. As a consequence there is no pressure gradient within the flat plate boundary layer. The final governing equation writes:\n\n$$\n\\color{purple}\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} &= 0 \\\\\nu\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y}&=\\nu\\frac{\\partial^2u}{\\partial y^2} \\\\\n\\end{aligned}\n$$\n\nAnd the boundary conditions are:\n\n$$\n\\color{purple}\n\\begin{aligned}\nu=v = 0\\quad&\\mathrm{at}\\quad y = 0\\\\\nu = U\\quad&\\mathrm{at}\\quad x = 0 \\\\\nu \\rightarrow U\\quad&\\mathrm{as}\\quad y \\rightarrow \\infty \\\\\n\\end{aligned}\n$$\n\n{% note info %}\n\nThese conditions demand an *infinite gradient* in speed at the leading edge $x = y = 0$, which implies a singularity in the mathematical solution there. The solution given by the boundary layer approximation is not valid at the leading edge. \n\n{% endnote %}\n\nDefine a stream function so that the continuity equation will be automatically included:\n$$\n\\begin{aligned}\n\\psi &= \\int u dy \\\\\nu = \\frac{\\partial\\psi}{\\partial y}&, \\quad v = -\\frac{\\partial \\psi}{\\partial x}\n\\end{aligned}\n$$\nSubscribe into the momentum equation to get an single variable equation:\n$$\n\\color{purple}\n\\frac{\\partial\\psi}{\\partial y} \\frac{\\partial^2\\psi}{\\partial x \\partial y}- \\frac{\\partial\\psi}{\\partial x} \\frac{\\partial^2\\psi}{\\partial y^2} = \\nu\\frac{\\partial^3\\psi}{\\partial y^3}\n$$\nwith boundary conditions:\n$$\n\\color{purple}\n\\begin{aligned}\n\\frac{\\partial\\psi}{\\partial y}=\\frac{\\partial\\psi}{\\partial x} = 0\\quad&\\mathrm{at}\\quad y = 0\\\\\n\\frac{\\partial\\psi}{\\partial y} = U\\quad&\\mathrm{at}\\quad x = 0 \\\\\n\\frac{\\partial\\psi}{\\partial y} \\rightarrow U\\quad&\\mathrm{as}\\quad y \\rightarrow \\infty \\\\\n\\end{aligned}\n$$\nThrough a coordinate transformation([similarity solution](https://en.wikipedia.org/wiki/Self-similar_solution)), this PDE can be transferred into an ODE and thus be solved easily.\n\n#### 5.5.2 Similarity solution\n\n> In the study of partial differential equations, particularly in fluid dynamics, a **self-similar solution** is a form of solution which is similar to itself if the independent and dependent variables are appropriately scaled. \n\nIn contrast to the most frequently used method of \"separation variables\", the similarity solution involves combining the variables in a special way. Another example of using similarity to solve Heat diffusion equation lies on the [Appendix A.2](#a.2-solving-the-heat-equation-using-similarity-solution).\n\nA self-similar equation doesn't change regardless how the variables scale. So assume a transformation:\n$$\n\\begin{aligned}\ny = \\lambda^a\\bar{y}\\\\\nx = \\lambda^b\\bar{x}\\\\\n\\psi = \\lambda^c\\bar{\\psi}\\\\\n\\end{aligned}\n$$\nThe resulting scaled function and writes:\n$$\n\\begin{aligned}\n\\lambda^{3c-2a-b}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{y}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{x} \\partial \\bar{y}}- \n\\lambda^{3c-2a-b}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{x}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{y}^2} =\n\\lambda^{3c-3a}\\nu\\frac{\\partial^3\\bar{\\psi}}{\\partial \\bar{y}^3} \\\\\n\\Leftrightarrow\\quad\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{y}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{x} \\partial \\bar{y}}- \n\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{x}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{y}^2} =\n\\lambda^{-3c-a+b}\\nu\\frac{\\partial^3\\bar{\\psi}}{\\partial \\bar{y}^3}\n\\end{aligned}\n$$\nAnd the scaled boundary conditions gives:\n$$\n\\begin{aligned}\n\\lambda^{c-a}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{y}}=\\lambda^{c-b}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{x}} = 0\\quad&\\mathrm{at}\\quad \\lambda^{a}\\bar{y} = 0\\\\\n\\end{aligned}\n$$\nAs a result, all the powers should be 0:\n$$\n\\left.\\begin{array}{c}\n\\left.\\begin{array}{c}\n-c-a+b=0 \\\\\nc-a=0\n\\end{array}\\right\\} \\quad b=a / 2 \\\\\nc-b=0 \\qquad \\qquad  \\quad\n\\end{array}\\quad\\right\\} \\quad c=a / 2\n$$\nHere I need to put my derivation here:\n\n> Similar to [Appendix A.2](#a.2-solving-the-heat-equation-using-similarity-solution), we can construct an expression of $\\psi$ as:\n> $$\n> \\psi(x,y)= x^{1/2}f^\\dagger(\\eta^\\dagger), \\quad \\eta^\\dagger = yx^{-1/2}\n> $$\n> {% note danger %}\n>\n> **Personal comment:** I still don't know how to construct this kinda thing or why it work. The formula in Appendix gives me some idea but following it I got $\\psi(x,y)= x^{1}f^\\dagger(\\eta^\\dagger)$, $\\eta^\\dagger = yx^{-1/2}$ instead...\n>\n> {% endnote %}\n>\n> Substitute the expression of $\\psi$ into the equation with $f^{\\dagger'} = \\partial_{\\eta^{\\dagger}}f^{\\dagger}$:\n> $$\n> \\begin{aligned}\n> \\frac{\\partial\\psi}{\\partial y} &= f^{\\dagger'} \\\\\n> \\frac{\\partial^2\\psi}{\\partial y^2} &= x^{-1/2}f^{\\dagger''} \\\\\n> \\frac{\\partial^3\\psi}{\\partial y^3}&= x^{-1}f^{\\dagger'''}\\\\\n> \\frac{\\partial\\psi}{\\partial x} &= \\frac{1}{2}x^{-1/2}f^{\\dagger}-\\frac{1}{2}x^{-1}f^{\\dagger'}y \\\\\n> &= \\frac{1}{2}x^{-1/2}(f^{\\dagger} -\\eta^{\\dagger} f^{\\dagger'}) \\\\\n> \\frac{\\partial^2\\psi}{\\partial x \\partial y} &= \\frac{1}{2}x^{-1/2}(x^{-1/2}f^{\\dagger'} -x^{-1/2}\\eta^{\\dagger} f^{\\dagger''} - x^{-1/2}f^{\\dagger'}) \\\\\n> &=-\\frac{1}{2}x^{-1}\\eta^{\\dagger} f^{\\dagger''}\\\\ \n> \\frac{\\partial\\psi}{\\partial y}\\frac{\\partial^2\\psi}{\\partial x \\partial y} &= f^{\\dagger'}\\left[-\\frac{1}{2}x^{-1}\\eta^{\\dagger} f^{\\dagger''}\\right] \\\\\n> &= -\\frac{1}{2}x^{-1} \\eta^{\\dagger}f^{\\dagger'}f^{\\dagger''} \\\\\n> -\\frac{\\partial\\psi}{\\partial x}\\frac{\\partial^2\\psi}{\\partial y^2} &=\\frac{1}{2}x^{-1/2}(f^{\\dagger} -\\eta^{\\dagger} f^{\\dagger'})\\left[x^{-1/2}f^{\\dagger''}\\right] \\\\\n> &= \\frac{1}{2}x^{-1}(f^{\\dagger} +\\eta^{\\dagger} f^{\\dagger'})f^{\\dagger''}\\\\\n> \\end{aligned}\n> $$\n> As a result:\n> $$\n> \\begin{aligned}\n> -\\frac{1}{2}x^{-1}\\eta^{\\dagger} f^{\\dagger'}f^{\\dagger''}+ \\frac{1}{2}x^{-1}(f^{\\dagger} &+\\eta^{\\dagger} f^{\\dagger'})f^{\\dagger''} = \\nu x^{-1}f^{\\dagger'''}\\\\\n> \\Leftrightarrow \\qquad \\nu f^{\\dagger'''} - &\\frac{1}{2} f^{\\dagger}f^{\\dagger''} = 0\n> \\end{aligned}\n> $$\n\nOk.. above is what I derived, it's still an ODE but normally we want a cleaner result.\n\nSo Blasius construct $\\psi$ and $\\eta$ with physical meaningful non-dimensional parameters to get (reference to [MECH 346  Heat Transfer's Youtube channel](https://youtu.be/Lw6aQJGD3FU)):\n$$\n\\color{purple}\n\\psi(x,y)= (\\nu Ux)^{1/2}f(\\eta), \\quad \\eta = \\left(\\frac{U}{\\nu x}\\right)^{1/2}y\n$$\nSo that:\n$$\n\\begin{aligned}\n\\eta = \\sqrt{\\frac{U}{\\nu x}}y,& \\quad\\mathrm{dimensionless~wall~normal~coordinate}\\\\\nf = \\frac{\\psi}{\\sqrt{\\nu Ux}},& \\quad\\mathrm{dimensionless~stream~function}\\\\\nf' = \\frac{u}{U},& \\quad\\mathrm{dimensionless~velocity~profile} \\\\\nf'' = \\frac{\\sqrt{\\nu Ux}}{U^2}\\partial_yu, &\\quad\\mathrm{related~to~shear~stress} \\\\\n\\end{aligned}\n$$\nAnd terms of the governing equation becomes:\n$$\n\\begin{aligned}\n\\frac{\\partial\\psi}{\\partial y} &= Uf' \\\\\n\\frac{\\partial^2\\psi}{\\partial y^2} &= {(U\\nu x)}^{-1/2}f'' \\\\\n\\frac{\\partial^3\\psi}{\\partial y^3}&= U^2x^{-1}f'''\\\\\n\\frac{\\partial\\psi}{\\partial x} &= \\frac{1}{2}(\\nu U/x)^{1/2}(f -\\eta f')\\\\\n\\frac{\\partial^2\\psi}{\\partial x \\partial y} &=-\\frac{1}{2}Ux^{-1}\\eta f''\n\\\\ \n\\frac{\\partial\\psi}{\\partial y}\\frac{\\partial^2\\psi}{\\partial x \\partial y} &= -\\frac{1}{2}U^2x^{-1}\\eta f'f''\\\\\n-\\frac{\\partial\\psi}{\\partial x}\\frac{\\partial^2\\psi}{\\partial y^2}\n&= \\frac{1}{2}U^2x^{-1}(f +\\eta f')f''\\\\\n\\end{aligned}\n$$\nAnd the ODE turns out to be:\n$$\n\\color{purple}\n2f''' +ff'' = 0\n$$\nResulting boundary condition is:\n$$\n\\color{purple}\n\\begin{aligned}\nf' = 0\\quad &at\\quad \\eta=0  \t\\quad\\mathrm{(no~slip)}\\\\\nf = 0\\quad &at\\quad \\eta=0 \t\t\\quad\\mathrm{(impenetrability)} \\\\\nf' = 1\\quad &at\\quad \\eta\\rightarrow\\infty \\quad(u = U\\mathrm{~free stream}) \\\\\nf'' = 0\\quad &at\\quad \\eta\\rightarrow\\infty \\quad(\\partial_yu=0,\\mathrm{unnecessary}) \\\\\n\\end{aligned}\n$$\n\n#### 5.5.3 Solving the similarity solution \n\nSplit the 3-order ODE into a set of 3 first order ODEs:\n$$\n\\left\\{\\begin{array}{l}\n\tf_p  = f' \\\\\n\tf_{pp} = f_p' \\\\\n\t2f'_{pp} +ff_{pp}  = 0\n\\end{array}\\right.\n$$\nwith boundary conditions:\n$$\n\\begin{aligned}\nf_p = 0\\quad &at\\quad \\eta=0  \t\\\\\nf = 0\\quad &at\\quad \\eta=0 \t\t\\\\\nf_p = 1\\quad &at\\quad \\eta\\rightarrow\\infty \\\\\nf_{pp} = 0\\quad &at\\quad \\eta\\rightarrow\\infty,\\mathrm{unnecessary} \\\\\n\\end{aligned}\n$$\nThe third boundary condition has no closed form solution, so we need to solve it numerically. \n\n1. One method of doing it is guessing another initial condition $f_{pp} = ?$ at  $\\eta=0$, integrating the equation from $\\eta=0$ with Runge-Kutta method to meet the 3rd boundary condition i.e. **transfer the boundary condition to the initial condition**.\n\n   {% note info %}\n\n   RungeKutta method is an effective and widely used numerical method for solving the initial-value problems of differential equations. It integrated the function discretely from zero in small steps ($h$) in an order of 4 (more on [LearnChemE's Youtube](https://youtu.be/kUcc8vAgoQ0)).\n   $$\n   \\left\\{\\begin{array}{l}\n   y_{n+1}=y_{n}+\\frac{1}{6}\\left(K_{1}+2 K_{2}+2 K_{3}+K_{4}\\right) \\\\\n   K_{1}=h f\\left(x_{n}, y_{n}\\right) \\\\\n   K_{2}=h f\\left(x_{n}+\\frac{1}{2} h, y_{n}+\\frac{1}{2} K_{1}\\right) \\\\\n   K_{3}=h f\\left(x_{n}+\\frac{1}{2} h, y_{n}+\\frac{1}{2} K_{2}\\right) \\\\\n   K_{4}=h f\\left(x_{n}+h, y_{n}+K_{3}\\right)\n   \\end{array}\\right.\n   $$\n   {% endnote %}\n\n   It turns out it meets the 3<sup>rd</sup> boundary condition when:\n   $$\n   f_{pp} = 0.332~at~ \\eta=0\n   $$\n   And the function looks like below:\n\n   <img src=\"Similarity solution.png\" alt=\"Numerical solution to the similarity solution, the 4 boundary conditions are fitted. After MECH 346  Heat Transfer's Youtube channel(https://youtu.be/Lw6aQJGD3FU)\" style=\"zoom:40%;\" />\n\n   From the solution, we can see the stream function $f$ first increases with a decreasing slop then approaches to a linear increase line. While the velocity profile $f'$ and shear stress $f''$ approach the 1 and 0 at the free stream respectively,\n\n2. Another method is solve $f_{pp}~at~ \\eta=0$ directly numerically. And the solution is:\n   $$\n   f_{pp} = 0.332096~at~ \\eta=0\n   $$\n   More on [MECH 346  Heat Transfer's Youtube channel](https://youtu.be/Lw6aQJGD3FU) and [MIT's note](https://web.mit.edu/fluids-modules/www/highspeed_flows/ver2/bl_Chap2.pdf).\n\n#### 5.5.4 Blasius results\n\nAs a consequence, similar to what we do based on the [Von Krmn results result](#laminar-results-von-k%C3%A1rm%C3%A1n-results), recall the definition of the boundary layer:\n$$\nf_p = \\frac{u|_\\delta}{U} =  0.99\n$$\nIt is easy to get \n\n- the boundary layer thickness:\n  $$\n  \\begin{aligned}\n  \\eta_1&=\\sqrt{\\frac{U}{\\nu x}}\\delta\\approx5.0 \\\\\n  \\Rightarrow \\delta &\\approx 5.0 \\sqrt{\\frac{\\nu x}{U}} \\\\\n  \\Rightarrow \\frac{\\delta}{x} &\\approx 5.0 \\sqrt{\\frac{\\nu}{Ux}} \\\\\n  \\color{purple}{\\frac{\\delta}{x} }&\\color{purple}{\\approx 5 Re_x^{-1/2}}\\\\\n  \\end{aligned}\n  $$\n  with $\\color{purple}Re_x= Ux/\\nu$ as the **streamwise Reynolds number**.\n\n- the thickness displacement:\n  $$\n  \\begin{aligned}\n  \\delta^* &= \\int_0^\\delta\\left(1-\\frac{u}{U}\\right)dy \\\\\n  &= \\sqrt{\\frac{\\nu x}{U}}\\int_0^{\\eta_1\\approx5.0 }\\left(1-f'\\right)d\\eta \\\\\n  &= \\sqrt{\\frac{\\nu x}{U}}\\left[\\eta_1 - f_1\\right]\\\\\n  \\end{aligned}\n  $$\n  with $f_1 \\approx 3.283$:\n  $$\n  \\begin{aligned}\n  \\color{purple}\\frac{\\delta^*}{x}\\approx 1.721 Re_x^{-1/2}\n  \\end{aligned}\n  $$\n  \n- the momentum displacement and the factor of friction:\n  $$\n  \\tau_w = \\rho\\nu\\frac{\\partial u}{\\partial y}|_{y=0} = \\rho\\nu U\\sqrt{\\frac{U}{\\nu x}}f''(0)\n  $$\n  with $f''(0) \\approx 0.332$:\n  $$\n  C_f = \\frac{\\tau_w}{1/2\\rho U^2} \\approx 0.664Re_x^{-1/2}\n  $$\n\n  $$\n  \\color{purple}\n  \\frac{\\theta}{x} \\approx 0.664Re_x^{-1/2}\n  $$\n\n- the shape factor:\n  $$\n  \\color{purple}\n  H = \\frac{\\delta^*}{\\theta} \\approx 2.59\n  $$\n\n### 5.6 Validity of the laminar results\n\nThe above results are based on the hypothesis that the boundary layer is thin enough so that the coupling with the outer flow is negligible. This theory breaks down as soon as $\\frac{\\delta}{x}=\\mathcal{O}(1)$ i.e. $\\frac{\\delta}{x}<0.1$. As a result, based on the Blasius result, the upper limit of the streamwise Reynolds number depends on transition to turbulence writes\n$$\n5Re_x^{-1/2}<0.1\\\\\n\\Rightarrow Re_{x,min} > 2500\n$$\nFor smaller $Re_x$, the interaction with the outer flow is important and leads to departures from these results.\n\nBesides, at a threshold Reynolds number, the boundary layer becomes **turbulent** and the results above do not hold. This critical value of the Reynolds number is $Re_c\\approx 3  10^6$. Usually, the surfaces are not smooth and transition occurs earlier, sometimes at Reynolds numbers as low as $10^5$.\n\n### 5.7 Comparison of the results\n\nSimilar to what we do based on the [Von Krmn results result](#laminar-results-von-k%C3%A1rm%C3%A1n-results), based on the Prandtl one-seventh power law, the turbulence results can be derived easily, here is the table of all results:\n\n| Results            | $\\delta/x$        | $\\delta^*/x$      | $H$    | $c_f$              |\n| ------------------ | ----------------- | ----------------- | ------ | ------------------ |\n| Blasius laminar    | $5.0Re_x^{-1/2}$  | $1.72Re_x^{-1/2}$ | $2.59$ | $0.664Re_x^{-1/2}$ |\n| Integral laminar   | $5.5Re_x^{-1/2}$  | $1.83Re_x^{-1/2}$ | $2.5$  | $0.73Re_x^{-1/2}$  |\n| Error              | $10\\%$            | $6\\%$             | $3\\%$  | $10\\%$             |\n| Integral turbulent | $0.16Re_x^{-1/7}$ | $0.02Re_x^{-1/7}$ | $1.3$  | $0.027Re_x^{-1/7}$ |\n\nSeveral points:\n\n- There is an error of less than 10% between integral and Blasius results.\n- The boundary layer thickness $\\delta$ grows like $x^{6/7}$ for turbulent flows, which represents a faster growth than the $x^{1/2}$ law for the laminar boundary layer.\n- The viscous displacement thickness $\\delta^*$  and the shape factor $H=\\delta^*/\\theta$ for turbulent boundary layers is very small.\n- The skin friction coefficient $c_f$ is greater for turbulent boundary layers than for the laminar ones.\n\n## Appendix\n\n### A.1 Governing equation of boundary layers\n\n#### A.1.1 Scalings\n\nStarted by scaling the spatial derivatives:\n$$\n\\partial_x \\sim \\frac{1}{L} \\qquad \\partial_y \\sim \\frac{1}{\\delta}\n$$\nBy the thin-layer condition: $L\\gg\\delta$, we can introduce a small parameter $\\epsilon \\ll 1$ as:\n$$\n\\frac{\\delta}{L} = \\epsilon\n$$\nAs a result, introduce the stream function $\\psi$ under the conditions of 2D and incompressibility. The proportion of the streamwise and normal streamwise velocities $u, v$ can be expressed as:\n$$\n\\frac{u}{v} = \\frac{\\partial_y\\psi}{-\\partial_x\\psi}\\sim\\frac{L}{\\delta}\n$$\nwhich gives:\n$$\n\\Rightarrow \\quad v\\sim\\epsilon u\n$$\nimplying that the $v$ is much smaller than $u$.\n\nThen rescale the wall normal quantities according to the streamwise quantities:\n$$\n\\begin{aligned}\nx^* &= \\frac{x}{L} \\\\\ny^* &= \\frac{y}{\\delta} = \\frac{y}{\\epsilon L}\\\\\nu^* &= \\frac{u}{U} \\\\\nv^* &= \\frac{v}{\\epsilon U} \\\\\np^* &= \\frac{p}{\\rho U^2}\n\\end{aligned}\n$$\n{% note info %}\n\nIn this case, $p^*$ can be thought of as a mathematical function to ensure incompressibility of the scaled function.\n\n{% endnote %}\n\n#### A.1.2 Asymptotic derivation\n\nSubstitute the scaled variables into the governing equations:\n$$\n\\begin{aligned}\n\\frac{U}{L} \\partial_{x^{*}} u^{*}+\\frac{\\epsilon U}{\\epsilon L} \\partial_{y^{*}} v^{*} &= 0 \\\\\n\\frac{U^{2}}{L} u^{*} \\partial_{x^{*}} u^{*}+\\frac{U^{2}}{L} v^{*} \\partial_{y^{*}} u^{*}&=-\\frac{ U^{2}}{L} \\partial_{x^{*}} p^{*}+\\nu\\left(\\frac{U}{L^{2}} \\partial_{x^{*}}^{2} u^{*}+\\frac{U}{\\epsilon^{2} L^{2}} \\partial_{y^{*}}^{2} u^{*}\\right) \\\\\n\\frac{\\epsilon U^{2}}{L} u^{*} \\partial_{x^{*}} v^{*}+\\frac{\\epsilon U^{2}}{L} v^{*} \\partial_{y^{*}} v^{*} &=-\\frac{ U^{2}}{\\epsilon L} \\partial_{y^{*}} p^{*}+\\nu\\left(\\frac{\\epsilon U}{L^{2}} \\partial_{x^{*}}^{2} v^{*}+\\frac{U}{\\epsilon L^{2}} \\partial_{y^{*}}^{2} v^{*}\\right)\n\\end{aligned}\n$$\nCan be simplified into:\n$$\n\\begin{aligned}\n\\partial_{x^{*}} u^{*}+\\partial_{y^{*}} v^{*} &= 0 \\\\\nu^{*} \\partial_{x^{*}} u^{*}+v^{*} \\partial_{y^{*}} u^{*} &=-\\partial_{x^{*}} p^{*}+\\frac{1}{Re_{L}} \\partial_{x^{*}}^{2} u^{*}+\\frac{1}{\\epsilon^{2} Re_{L}} \\partial_{y^{*}}^{2} u^{*} \\\\\nu^{*} \\partial_{x^{*}} v^{*}+v^{*} \\partial_{y^{*}} v^{*} &=-\\frac{1}{\\epsilon^{2}} \\partial_{y^{*}} p^{*}+\\frac{1}{Re_{L}} \\partial_{x^{*}}^{2} v^{*}+\\frac{1}{\\epsilon^{2} Re_{L}} \\partial_{y^{*}}^{2} v^{*}\n\\end{aligned}\n$$\nwhere $Re_L = UL/\\nu$\n\nTo keep a balance between the advection(LHS) and diffusion (RHS), impose:\n$$\n\\epsilon^2Re_L=1 \\\\\n\\Rightarrow \\epsilon = \\frac{\\delta}{L}=Re_L^{-1/2}\n$$\nAs a result, the leading order of the system is:\n$$\n\\begin{aligned}\n\\partial_{x^{*}} u^{*}+\\partial_{y^{*}} v^{*} &= 0 \\\\\nu^{*} \\partial_{x^{*}} u^{*}+v^{*} \\partial_{y^{*}} u^{*} &=-\\partial_{x^{*}} p^{*}+\\partial_{y^{*}}^{2} u^{*} \\\\\n0&=\\partial_{y^{*}} p^{*}\n\\end{aligned}\n$$\n\n### A.2 Solving the heat equation using similarity solution\n\nReferences[Dr Chris Tisdell's Youtube](https://youtu.be/dNLmvhZWEq8), [UCL's class note](https://www.ucl.ac.uk/~ucahhwi/LTCC/sectionB-similarity.pdf).\n\nGiven PDE with boundary and initial conditions:\n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} =& k\\frac{\\partial^2 u}{\\partial x^2}\\\\\nu(x,0)=0, &\\quad x>0\\\\\nu(x,t)\\rightarrow0, &\\quad x\\rightarrow\\infty \\\\\n\\partial_x u(0,t)=N, &\\quad t>0\n\\end{aligned}\n$$\n\n1. Determine a set of transformations:\n   $$\n   \\begin{aligned}\n   x &= \\lambda^a\\bar{x}\\\\\n   t &= \\lambda^b\\bar{t}\\\\\n   u &= \\lambda^c\\bar{u}\\\\\n   \\end{aligned}\n   $$\n   Substitute into the equation:\n   $$\n   \\begin{aligned}\n   \\lambda^{c-b}\\frac{\\partial \\bar{u}}{\\partial \\bar{t}} = \\lambda^{c-2a}k\\frac{\\partial^2 \\bar{u}}{\\partial \\bar{x}^2} \\\\\n   \\frac{\\partial \\bar{u}}{\\partial \\bar{t}} = \\lambda^{-2a+b}k\\frac{\\partial^2 \\bar{u}}{\\partial \\bar{x}^2}\n   \\end{aligned}\n   $$\n   Boundary condition:\n   $$\n   \\begin{aligned}\n   \\frac{\\partial u}{\\partial x} =N, \\quad t>0 \\\\\n   \\lambda^{c-a}\\frac{\\partial \\bar{u}}{\\partial \\bar{x}}=N\n   \\end{aligned}\n   $$\n   \n\n   As a result:\n   $$\n   \\begin{aligned}\n   -2a+b &= 0 \\\\\n   c-a&=0\n   \\end{aligned}\n   $$\n\n2. Determin $s$ and $r$ such that:\n   $$\n   \\bar{x\\vphantom{t}}\\bar{t}^s=xt^s\\qquad \\bar{u\\vphantom{t}}\\bar{t}^r = ut^r\n   $$\n   Substitute we have:\n   $$\n   \\begin{aligned}\n   \\bar{x\\vphantom{t}}\\bar{t}^s&=xt^s \\\\\n   \\bar{x\\vphantom{t}}\\bar{t}^s &= \\lambda^{a+sb}\\bar{x\\vphantom{t}}\\bar{t}^s  \\\\\n   \\Rightarrow \\quad s &= -a/b =  -1/2\n   \\end{aligned}\n   $$\n   and\n   $$\n   \\begin{aligned}\n   \\bar{u\\vphantom{t}}\\bar{t}^r&=ut^r \\\\\n   \\bar{u\\vphantom{t}}\\bar{t}^r &= \\lambda^{c+rb}\\bar{x\\vphantom{t}}\\bar{t}^r = \\lambda^{(c+2ar)}\\bar{x\\vphantom{t}}\\bar{t}^r\\\\\n   \\Rightarrow \\quad r &= -c/b = -1/2\n   \\end{aligned}\n   $$\n\n3. With two terms unchanged by the transformation. A solution combines these two terms can be constructed as $u(x,t) = t^{-r}f(xt^s) = t^{-r}f(\\eta)$:\n   $$\n   \\begin{aligned}\n   u(x,t) = t^{c/b}f(\\eta), \\quad\\mathrm{where~}\\eta = xt^{-a/b} \\\\\n   \\Leftrightarrow\\quad u(x,t) = t^{1/2}f(\\eta),\\quad\\mathrm{where~}\\eta = \\frac{x}{t^{1/2}}\n   \\end{aligned}\n   $$\n   {% note info %}\n   \n   Note that $u(x,t) = t^{c/b}f(\\eta), \\quad \\eta = xt^{-a/b}$ is a general solution and it suits for every conditions.\n   \n   {% endnote %}\n   \n4. Substitute into the original function to get a ODE:\n   $$\n   \\begin{aligned}\n   \\frac{\\partial u}{\\partial t} &= \\frac{1}{2}t^{-1/2}f - \\frac{1}{2}t^{-1}xf' \\\\ &= \\frac{1}{2}t^{-1/2}f - \\frac{1}{2}t^{-1/2}\\eta f'\\\\&=\\frac{1}{2}t^{-1/2}\\left(f-\\eta f'\\right)\\\\\n   \\frac{\\partial^2 u}{\\partial x^2} &= t^{-1/2}f''\\\\\n   \\end{aligned}\n   $$\n   The resulting equation is therefore:\n   $$\n   \\begin{aligned}\n   &\\frac{1}{2}t^{-1/2}\\left(f-\\eta f'\\right)= kt^{-1/2}f'' \\\\\n   \\Leftrightarrow\\quad& \\frac{1}{2}\\left(f-\\eta f'\\right)= kf'' \\\\\n   \\Leftrightarrow\\quad& 2kf''+\\eta f'-f = 0\n   \\end{aligned}\n   $$\n   \n   The following work is solving this ODE, which is illustrated more on [UCL's class note](https://www.ucl.ac.uk/~ucahhwi/LTCC/sectionB-similarity.pdf).\n\n","slug":"External-flow-fundamentals","published":1,"updated":"2022-06-16T07:51:56.427Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz1y0005l8yb7wmb74f6","content":"<div class=\"note note-primary\">\n            <p>Internal pipe flow is not enough for me, continue to review the tricky part.</p>\n          </div>\n<span id=\"more\"></span>\n<h2 id=\"fluid-structure-interaction\">4 Fluid-structure interaction</h2>\n<p>When an unbounded homogeneous flow approaches an obstacle, viscous effects become important and substantially deform the flow profile. The resulting boundary layers and wakes are responsible for generating forces and moments on the obstacle.</p>\n<h3 id=\"examples\">4.1 Examples</h3>\n<h4 id=\"lift-generation\">4.1.1 Lift generation</h4>\n<p>Here comes the most popular question: how does an aircraft fly?</p>\n<p>The basic answer is that</p>\n<blockquote>\n<p>The airfoil is shaped so that its upper surface is longer than its lower surface. A parcel of fluid arriving at the leading edge then splits into two parcels, one following the upper surface and the other the lower surface. As the fluid has more distance to travel on the upper surface than on the lower surface, it goes faster to have the <strong>same transit time</strong>. The Bernoulli effect follows: the higher velocity on the upper surface yields a lower pressure and an ascending force is created: the lift.</p>\n</blockquote>\n<p>The use of Bernoulli effect is, to some extent, correct. However, based on experiment findings shown below, the same transit time assumption is not quite right.</p>\n<p>I{t}s clear the upper flow is accelerated compared to the lower flow. This happens already at the leading edge, but the lower flow never catches up with the upper one. As a result, the upper flow possesses a shorter transit time.</p>\n<p><img src=\"Flow past an airfoil.gif\" srcset=\"/img/loading.gif\" lazyload alt=\"Flow past an airfoil visualised through the trajectory of one pulse of smoke. After Babinsky (http://www.cam.ac.uk/research/news/how-wings-really-work).\" style=\"zoom:100%;\" /></p>\n<p>As a consequence, the physical mechanism behind lift is not so simple. A plausible answer is twofolds.</p>\n<ul>\n<li>On the one hand, the fluid is accelerated on the upper surface and slowed down on the lower surface, creating a descending pressure gradient, hence lift.</li>\n<li>On the other hand, the fluid trajectory is overall deflected downwards when passing the airfoil. This implies that the airfoil creates a descending force onto the fluid, and, by Newtons third law, that the fluid generates an ascending force onto the airfoil.</li>\n</ul>\n<h4 id=\"wingtip-vortices\">4.1.2 Wingtip vortices</h4>\n<p>At the tip of the wing, when the lower pressure upper surface meets the higher pressure lower surface, wingtip vortices are generated. These vortices are generally strong, long-lived and consequently dangerous, as shown below:</p>\n<p><img src=\"Wingtip vortex.jpeg\" srcset=\"/img/loading.gif\" lazyload alt=\"Wingtip vortex behind a plane visualised with red smoke.\" style=\"zoom:50%;\" /></p>\n<p>Flying through such a vortex will create a rolling moment that can destabilize the flight. Many such incidents have happened during takeoff and landing. As a result, airports have decided on quiet periods of one to two minutes between two successive takeoffs or landings to allow for these vortices to dissipate to a less dangerous strength.</p>\n<p><img src=\"V formation.jpeg\" srcset=\"/img/loading.gif\" lazyload alt=\"Birds flying in V-formation.\" style=\"zoom:50%\" /></p>\n<p>Yet the wingtip vortices are leveraged perfectly by the nature, the V-formation. When one bird follows another bird, it places itself a little bit on the side to benefit from the lift generated by the wingtip vortices of its leader.</p>\n<h4 id=\"others\">4.1.3 Others</h4>\n<p>Wind and ocean engineering also present important challenges in the area of fluid-structure interaction.</p>\n<p>The construction of tall building is necessary to accommodate large professional centres and these tall buildings interact strongly with the wind. Similar issues arise with bridges. Serious oscillation would be generated due to the \"wind load\".</p>\n<p align=\"center\">\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/tHMPR7flpf4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n</iframe>\n</p>\n<p>In water, it is important to understand fluid-structure interactions to design efficient breakwaters and protect constructions on the shore or beaches. Pier piles are also good examples of structures interacting with water and that have to be designed carefully.</p>\n<p>Lastly, we can take advantage of natural phenomena such as wind and currents by designing structures that will store such energy like wind and water turbines.</p>\n<h3 id=\"effect-of-a-structure-on-the-fluid\">4.2 Effect of a structure on the fluid</h3>\n<p>When an external flow goes past an obstacle, boundary layer and wake effects occur on the walls and after the obstacle respectively.</p>\n<h4 id=\"boundary-layers\">4.2.1 Boundary layers</h4>\n<p><img src=\"Boundary layers.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Sketch of the flow past a sharp flat plate oriented in the direction of the flow.\nTwo situations are shown: a low-Re flow (ReL= 10) and a high-Re flow (ReL= 107) and the associated boundary layers depicted. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" /></p>\n<p><strong>Convenient definition</strong>: a region where the fluids velocity parallel to the wall is smaller or equal to 99% of the external velocity.</p>\n<ul>\n<li>Inside the boundary layer, the flow feels the effect of the wall and is gradually slowed down as we approach the wall. The presence of these velocity gradients is a consequence of <strong>viscous dissipation</strong>.</li>\n<li>Outside the boundary layer, the flow does not feel the presence of the walls. It remains homogeneous and is considered <strong>inviscid</strong>.</li>\n</ul>\n<div class=\"note note-info\">\n            <p>Note that this is only an assumption, the interaction between the boundary layer and the outer pressure distribution is neglected. For slender bodies at large <span class=\"math inline\">\\(Re\\)</span>, such as airfoils, when placed parallel to the flow, this assumption provides good results due to the thin and weak boundary layer.</p>\n          </div>\n<p>There are <strong>two types</strong> of the boundary layers defined by the Reynolds number:</p>\n<ul>\n<li>Low <span class=\"math inline\">\\(Re\\)</span>, laminar boundary layer. Because spatial variations are slow, the laminar boundary layer occupies a large spatial region.</li>\n<li>High <span class=\"math inline\">\\(Re\\)</span>, two distinct regions in the boundary layer:\n<ul>\n<li>laminar boundary layer similar to that of low-Re flows but much thinner</li>\n<li>turbulent boundary layer that occurs further away in the streamwise direction and is larger than the laminar boundary layer.</li>\n</ul></li>\n</ul>\n<p>The <strong>viscous displacement effect</strong> describes the non-zero velocity in the direction orthogonal to the wall because the velocity parallel to the wall varies in the direction orthogonal to the wall.</p>\n<ul>\n<li>For low <span class=\"math inline\">\\(Re\\)</span> laminar boundary layers, this effect is important</li>\n<li>For high <span class=\"math inline\">\\(Re\\)</span> boundary layers, these boundary layers are so thin that this effect is negligible.</li>\n</ul>\n<h4 id=\"wakes\">4.2.2 Wakes</h4>\n<p><img src=\"Wakes.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Sketch of the wake past a cylinder and the different regimes observed as a function of the Reynolds number Re = UR/, where U is the velocity of the fluid infinitely far away from the cylinder, R the cylinder radius and  the fluids kinematic viscosity. After Middleton & Southard, Mechanics of Sediment Movement, SEPM Short Course Notes, Vol. 3 (1984).\" style=\"zoom:50%;\" /></p>\n<p>When the inertia is non-trivial (equivalently viscous effects are not overwhelmingly dominant), the gradients of velocity induced by the boundary layer are advected downstream and create a <strong>wake</strong> past the obstacle. This region can display dramatic departures from the established flow infinitely far away from the obstacle.</p>\n<p>The sketch above shows how several typical regimes of the wake past a cylinder in different <span class=\"math inline\">\\(Re\\)</span>s:</p>\n<ul>\n<li>Low <span class=\"math inline\">\\(Re\\)</span>: steady and symmetric flow</li>\n<li><span class=\"math inline\">\\(Re=\\mathcal{O}(10)\\)</span>:\n<ul>\n<li>the upstream-downstream symmetry is broken</li>\n<li>flow separation occurs. The boundary layers separate from the wall and a recirculation zone is created where two counter-rotating vortices live.</li>\n<li>wake remains stationary</li>\n<li>the up-down symmetry is still preserved</li>\n</ul></li>\n<li><span class=\"math inline\">\\(Re=\\mathcal{O}(100)\\)</span>:\n<ul>\n<li>the up-down symmetry is broken</li>\n<li>flow separation developed</li>\n<li>wake is now periodic in time, vortices periodically break away from the back of the cylinder in an alternate fashion and are advected downstream</li>\n<li>This type of wake is called <strong>Von Krmn streets</strong>.</li>\n</ul></li>\n<li><span class=\"math inline\">\\(Re&gt;\\mathcal{O}(1000)\\)</span>: any simple time-dependence in the wake is lost and it is now turbulent.</li>\n</ul>\n<p>Note that as the Reynolds number is increased, different types of turbulent wakes can be observed.</p>\n<ul>\n<li>At <span class=\"math inline\">\\(Re = 5\\times10^3\\)</span>, the turbulent wake is detached from the wall and a laminar bubble is observed at the back of the cylinder.</li>\n<li>As the Reynolds number is increased, this bubble shrinks</li>\n<li>At <span class=\"math inline\">\\(Re = 10^5\\)</span>, the back of the cylinder has become fully turbulent</li>\n<li>As Re is further increased, the turbulent wake becomes thinner and thinner and the influence of the cylinder on the flow decreases. This is the result of the fact that the characteristic length for advection becomes incomparably larger than the diameter of the cylinder</li>\n</ul>\n<h3 id=\"effect-of-the-fluid-on-a-structure\">4.3 Effect of the fluid on a structure</h3>\n<p>In this section, we look at the opposite interaction: the impact of boundary layers and wakes on the structures.</p>\n<h4 id=\"free-kick-like-cristiano-ronaldo\">4.3.1 Free kick like Cristiano Ronaldo</h4>\n<p align=\"center\">\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MscZ_pd7iAM?start=12\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n</iframe>\n</p>\n<p>Personally, I'm not a big fan of football. The only football game I watch is FIFA. And I happened to watch this legendary game on live. I remember it was 3 o'clock in the morning and I barely held my scream.</p>\n<p><img src=\"magnus effect illustration.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Illustration of the Magnus effect using a downward flow past an anti-clockwise rotating sphere. The flow is slowed down on the right as opposed to the left. The pressure is then greater on the right of the sphere and a leftward force is generated.\" style=\"zoom:50%;\" /></p>\n<p>The explanation of such a trajectory lies in the <strong>Magnus effect</strong> which describes a spinning object moving through a fluid. Rotating the ball accelerates the flow on one side while slowing it down on the other. This difference of velocity breaks the symmetry of the flow and creates a difference of pressure. And this results in an additional force that bends the trajectory of the ball.</p>\n<h4 id=\"the-tacoma-narrows-bridge\">4.3.2 The Tacoma Narrows bridge</h4>\n<p align=\"center\">\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XggxeuFDaDU?start=15\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n</iframe>\n</p>\n<p>Another famous aeroelastic failure is this 1.8km long bridge in the state of Washington. The 6 million dollar bridge collapsed in a steady standard wind in November, 1940, only 3 months after its opening date. Back then this wind interacted in an unexpected manner with the bridge and created a positive feedback loop called <strong>aeroelastic flutter</strong>. A oscillating wake due to the periodic vortex shedding excited a <strong>second torsional mode</strong>: the midpoint of the bridge remained motionless while the two opposite halves twisted in opposite directions. This torsion further enhanced the strength of the wake, which in turn enhanced the torsion until the bridge collapsed.</p>\n<h2 id=\"boundary-layer-theory-integral-approach\">5 Boundary layer theory  Integral approach</h2>\n<p>First, a control volume is defined as blow:</p>\n<ul>\n<li>Boundary : the segment <span class=\"math inline\">\\((0, 0)\\)</span> to <span class=\"math inline\">\\((0, h)\\)</span>, where <span class=\"math inline\">\\(\\mathbf{u} = U\\mathbf{\\hat{x}}\\)</span>.</li>\n<li>Boundary : the streamline <span class=\"math inline\">\\((0, h)\\)</span> to <span class=\"math inline\">\\((L, \\delta)\\)</span>, where <span class=\"math inline\">\\(\\mathbf{u}\\cdot \\mathbf{n} = 0\\)</span>.</li>\n<li>Boundary : the segment <span class=\"math inline\">\\((L, \\delta)\\)</span> to <span class=\"math inline\">\\((L, 0)\\)</span>, where $ = u(x, y) + v(x, y)$.</li>\n<li>Boundary : the plate surface and streamline <span class=\"math inline\">\\((L, 0)\\)</span> to <span class=\"math inline\">\\((0, 0)\\)</span>, where <span class=\"math inline\">\\(u = 0\\)</span>.</li>\n</ul>\n<p><img src=\"Boundary layer control volume.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Sketch of a developing boundary layer on a flat plate. The control volume used is delimited by the boundaries labeled , ,  and .\" style=\"zoom:30%;\" /></p>\n<h3 id=\"viscous-displacement\">5.1 Viscous displacement</h3>\n<h4 id=\"physical-origin\">5.1.1 Physical origin</h4>\n<p>The viscous displacement determines the upstream streamlines parallel to the wall to move away from the wall i.e. boundary  to tilt upward. It can be explained by the 2D compressible continuity equation: <span class=\"math display\">\\[\n\\partial_x u+\\partial_y v=0\n\\]</span> Near the boundary , the no-slip condition gives <span class=\"math inline\">\\(\\partial_xu&lt;0\\)</span>, to compensate for it, <span class=\"math inline\">\\(\\partial_yv&gt;0\\)</span>, and the consequence of this is the viscous displacement.</p>\n<h4 id=\"displacement-thickness\">5.1.2 Displacement thickness</h4>\n<p><img src=\"displacement thickness.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Actual viscous boundary layer vs analogy with an inviscid flow displaying the same flow rate. The wall-normal delay * necessary to obtain the same flow rate is called displacement thickness.\" style=\"zoom:30%;\" /></p>\n<p>The quantity <span class=\"math inline\">\\(\\delta^*\\)</span> is called <strong>displacement thickness</strong> and represents the distance by which the wall would have to be moved in the wall normal direction to <strong>obtain the same flow rate</strong> in an inviscid flow. i.e. the additional blockage/deflection due to viscosity.</p>\n<p>By definition, it is easy to conclude that <span class=\"math inline\">\\(\\delta = \\delta^*+h\\)</span>. And by mass conservation between the inlet and the outlet, the displacement thickness can be described: <span class=\"math display\">\\[\n\\begin{aligned}\n\\rho\\int_1(\\mathbf{u}\\cdot\\mathbf{n})ds&amp;+\\rho\\int_3(\\mathbf{u}\\cdot\\mathbf{n})ds =0 \\\\\n\\int^{\\delta-\\delta^*}_0(-U&amp;)dy+\\int^\\delta_0udy=0 \\\\\nUh&amp;= \\int^\\delta_0udy \\\\\n\\end{aligned}\n\\]</span> Substitute <span class=\"math inline\">\\(h\\)</span> with <span class=\"math inline\">\\(\\delta-\\delta^*\\)</span> : <span class=\"math display\">\\[\n\\begin{aligned}\nU(\\delta-\\delta^*) &amp;= \\int^\\delta_0udy \\\\\nU(\\delta-\\delta^*) &amp;= \\int^\\delta_0\\left(u+U-U\\right)dy \\\\\nU(\\delta-\\delta^*) &amp;= U\\delta+\\int^\\delta_0\\left(u-U\\right)dy \\\\\n\\Rightarrow \\quad\\delta^* = \\int_0^\\delta&amp;\\left(1-\\frac uU\\right)dy\\\\\n\\Rightarrow \\quad\\color{purple}{\\frac{\\delta^*}{\\delta} = \\int_0^1}&amp;\\color{purple}{\\left(1-\\frac uU\\right)d\\eta}, \\quad\\mathrm{where~}\\eta=\\frac{y}{\\delta}\\\\\n\\end{aligned}\n\\]</span></p>\n<h3 id=\"friction-drag\">5.2 Friction drag</h3>\n<h4 id=\"drag-as-a-boundary-layer-effect\">5.2.1 Drag as a boundary layer effect</h4>\n<p>Assume a constant pressure throughout the domain, and a steady flow. The conservation of momentum in <span class=\"math inline\">\\(\\mathbf{\\hat{x}}\\)</span> writes: <span class=\"math display\">\\[\n\\begin{aligned}\n\\rho\\int_1u(0,y)(\\mathbf{u}\\cdot\\mathbf{n})ds + \n\\underbrace{\\rho\\int_2u(x,y)(\\mathbf{u}\\cdot\\mathbf{n})ds+}_{\\mathrm{streamline:~}\\mathbf{u}\\cdot\\mathbf{n}=0} ...\\\\\n\\rho\\int_3u(L,y)(\\mathbf{u}\\cdot\\mathbf{n})ds+\n\\underbrace{\\rho\\int_4u(x,0)(\\mathbf{u}\\cdot\\mathbf{n})ds}_{\\mathrm{wall:~}u=0}=\n\\Sigma F_x = -D\\mathbf{\\hat{x}}\n\\end{aligned}\n\\]</span> The equation simplifies into: <span class=\"math display\">\\[\n\\begin{aligned}\n\\rho\\int_0^hU(-U)dy + \\rho\\int_0^\\delta u^2dy=-D \\\\\n\\Rightarrow\\qquad D = \\rho hU^2 -\\rho\\int_0^\\delta u^2dy\n\\end{aligned}\n\\]</span> Combine with the <strong>mass conservation</strong> result <span class=\"math inline\">\\(Uh= \\int^\\delta_0udy\\)</span>: <span class=\"math display\">\\[\n\\begin{aligned}\nD &amp;= \\rho \\int_0^\\delta Uudy-\\rho\\int_0^\\delta u^2dy \\\\\n\\color{purple}{D }&amp;\\color{purple}{= \\rho \\int_0^\\delta \\frac{u}{U}\\left(1-\\frac{u}{U}\\right) dy}\n\\end{aligned}\n\\]</span></p>\n<h4 id=\"momentum-thickness\">5.2.2 Momentum thickness</h4>\n<p>The quantity <span class=\"math inline\">\\(\\theta\\)</span> is called <strong>momentum thickness</strong> and represents the distance by which the wall would have to be moved in the wall normal direction to <strong>obtain the same momentum</strong> in an inviscid flow. <span class=\"math display\">\\[\n\\color{purple}\\frac{\\theta}{\\delta} = \\frac{D}{\\rho U^2\\delta} = \\int_0^1 \\frac{u}{U}\\left(1-\\frac{u}{U}\\right) d\\eta, \\quad \\mathrm{where~}\\eta = \\frac{y}{\\delta}\n\\]</span> i.e. the <strong>momentum deficit</strong> can be determined by: <span class=\"math display\">\\[\n\\rho U^2\\theta = \\rho \\int_0^\\delta \\frac{u}{U}\\left(1-\\frac{u}{U}\\right)dy\n\\]</span> <div class=\"note note-info\">\n            <p>There is another <strong>Energy thickness</strong> writes: <span class=\"math display\">\\[\\color{purple}\\frac{\\theta&#39;}{\\delta} = \\int_0^1 \\frac{u}{U}\\left(1-\\frac{u^2}{U^2}\\right) d\\eta, \\quad \\mathrm{where~}\\eta = \\frac{y}{\\delta}\\]</span></p>\n          </div></p>\n<p>We can then define the <strong>shape factor</strong>: <span class=\"math display\">\\[\nH = \\frac{\\delta^*}{\\theta}\n\\]</span> <div class=\"note note-info\">\n            <p>Shape factor indicates the wall-normal distance on which the fluid is deflected from the plate compared to that on which gradients of streamwise velocities are felt.A large shape factor indicates a flow near separation.</p>\n          </div></p>\n<h4 id=\"relation-to-wall-shear-stress\">5.2.3 Relation to wall shear stress</h4>\n<p>The drag force is the integration of wall shear stress <span class=\"math inline\">\\(\\tau_w\\)</span> along the plate: <span class=\"math display\">\\[\nD = \\int_0^L\\tau_wdx\n\\]</span> Or in differential form: <span class=\"math display\">\\[\n\\tau_w = \\partial_xD\n\\]</span> Differentiate the momentum thickness representation: <span class=\"math display\">\\[\n\\partial_x\\theta = \\frac{\\partial_xD}{\\rho U^2}=\\frac{\\tau_w}{\\rho U^2}\n\\]</span> As a result, the wall shear: <span class=\"math display\">\\[\n\\color{purple}\\tau_w = \\rho U^2\\partial_x\\theta\n\\]</span></p>\n<h3 id=\"velocity-profile-approximations\">5.3 Velocity profile approximations</h3>\n<p>For <em>laminar</em> boundary layers, Von Krmn assumed that the velocity profile (<span class=\"math inline\">\\(\\frac{u}{U}\\)</span>) within the boundary layer had a parabolic shape:</p>\n<p>Given: <span class=\"math display\">\\[\n\\eta = \\frac{y}{\\delta(x)}\n\\]</span> The velocity profile (<span class=\"math inline\">\\(\\frac{u}{U}\\)</span>) writes: <span class=\"math display\">\\[\n\\frac{u}{U}\\approx 2\\eta -\\eta^2, \\qquad 0\\leq \\eta\\leq 1\n\\]</span> For <em>turbulent</em> boundary layers, Prandtl highlighted a one-seventh power velocity profile: <span class=\"math display\">\\[\n\\frac{u}{U}\\approx\\eta^\\frac{1}{7}, \\qquad 0\\leq \\eta\\leq 1\n\\]</span> These first order approximations are very close to the reality as shown below:</p>\n<p><img src=\"velocity profiles.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Comparison of velocity profiles u/U in the boundary layer y/ < 1 between the Von Krmn and Prandtls approximations and the actual laminar and turbulent flows. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" /></p>\n<h3 id=\"laminar-results-von-krmn-results\">5.4 Laminar results (Von Krmn results)</h3>\n<p>Based on Von Krmn's approximation, <span class=\"math inline\">\\(\\frac{u}{U}\\approx \\frac{2y}{\\delta} -\\left(\\frac{y}{\\delta}\\right)^2\\)</span>. It is easy to get:</p>\n<ul>\n<li><p>Boundary thickness:</p>\n<p>The key point is that the wall shear stress can be expressed in two ways,</p>\n<ul>\n<li><p>by definition: <span class=\"math display\">\\[\n\\begin{aligned}\n\\tau_w &amp;= \\mu \\partial_yu|_{y=0} \\\\\n\\Rightarrow \\quad \\tau_{w} &amp;\\approx \\mu \\partial_{y}\\left.\\left(\\frac{2 y}{\\delta}-\\frac{y^{2}}{\\delta^{2}}\\right)\\right|_{y=0} \\\\\n\\Rightarrow \\quad \\tau_{w} &amp;\\approx \\mu \\frac{2 U}{\\delta}\\\\\n\\end{aligned}\n\\]</span></p></li>\n<li><p>and by the derivative of drag: <span class=\"math display\">\\[\n\\begin{aligned}\n\\tau_w &amp;= \\rho U^2\\partial_x\\theta \\\\\n\\Rightarrow \\quad \\tau_{w} &amp;\\approx \\rho U^2\\partial_x\\left[\\int_{0}^{\\delta}\\left(\\frac{2 y}{\\delta}-\\frac{y^{2}}{\\delta^{2}}\\right)\\left(1-\\frac{2 y}{\\delta}+\\frac{y^{2}}{\\delta^{2}}\\right) d y \\right] \\\\\n\\Rightarrow \\quad \\tau_{w} &amp;\\approx \\frac{2\\rho U^2}{15}\\partial_x\\delta\n\\end{aligned}\n\\]</span></p></li>\n</ul>\n<p>As a result, connect these expressions: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\mu \\frac{2 U}{\\delta} \\approx \\frac{2\\rho U^2}{15}\\partial_x\\delta \\\\\n\\Rightarrow \\quad &amp;\\int_0^x dx \\approx \\int_0^\\delta \\frac{\\rho U}{15}\\delta d\\delta \\\\\n\\Rightarrow \\quad &amp;x \\approx \\frac{\\rho U \\delta^2}{30\\mu} \\\\\n\\Rightarrow \\quad &amp; \\left(\\frac{\\delta}{x}\\right)^2 \\approx \\frac{30\\mu}{\\rho U x} \\\\\n\\Rightarrow \\quad &amp; \\color{purple}{\\frac{\\delta}{x}  \\approx 5.5 Re_x^{-1/2}} \\\\\n\\end{aligned}\n\\]</span> where <span class=\"math inline\">\\(\\color{purple}Re_x= Ux/\\nu\\)</span> as the <strong>streamwise Reynold</strong>.</p></li>\n<li><p>the displacement thickness: <span class=\"math display\">\\[\n\\begin{aligned}\n\\delta^* &amp;= \\int_0^\\delta\\left(1-\\frac{u}{U}\\right)dy \\\\\n&amp;\\approx \\int_0^\\delta\\left(1-\\frac{2y}{\\delta}+\\left(\\frac{y}{\\delta}\\right)^2\\right)dy \\\\\n\\Rightarrow \\quad \\delta^*&amp;\\approx \\frac{1}{3}\\delta\\\\\n\\end{aligned}\n\\]</span> with the boundary thickness expression: <span class=\"math display\">\\[\n\\begin{aligned}\n\\color{purple}\\frac{\\delta^*}{x}\\approx 1.83 Re_x^{-1/2}\n\\end{aligned}\n\\]</span></p></li>\n<li><p>the momentum displacement and the factor of friction: <span class=\"math display\">\\[\n\\begin{aligned}\n\\theta &amp;= \\int_{0}^{\\delta}\\left(\\frac{2 y}{\\delta}-\\frac{y^{2}}{\\delta^{2}}\\right)\\left(1-\\frac{2 y}{\\delta}+\\frac{y^{2}}{\\delta^{2}}\\right) d y \\\\\n\\Rightarrow \\quad &amp; \\theta \\approx \\frac{2}{15}\\delta \\\\\n\\Rightarrow \\quad &amp; \\color{purple}{\\frac{\\theta}{x}  \\approx 0.73 Re_x^{-1/2}} \n\\end{aligned}\n\\]</span> The factor of friction has the same order with the momentum displacement, as <span class=\"math display\">\\[\n\\color{purple}{C_f   \\approx 0.73 Re_x^{-1/2}}\n\\]</span></p></li>\n<li><p>the shape factor: <span class=\"math display\">\\[\n\\color{purple}\nH = \\frac{\\delta^*}{\\theta} \\approx 2.5\n\\]</span></p></li>\n</ul>\n<h3 id=\"laminar-results-blasius-results\">5.5 Laminar results (Blasius results)</h3>\n<p>Reference to <a href=\"https://web.mit.edu/fluids-modules/www/highspeed_flows/ver2/bl_Chap2.pdf\">MIT's note</a>, <a href=\"https://youtu.be/Lw6aQJGD3FU\">MECH 346  Heat Transfer's Youtube channel</a></p>\n<h4 id=\"governing-equations\">5.5.1 Governing equations</h4>\n<p>Conditions:</p>\n<ul>\n<li><p>2D</p></li>\n<li><p>Steady</p></li>\n<li><p>Incompressible</p></li>\n<li><p>Neglect viscous dissipation, gravity and thermal dissipation</p></li>\n<li><p>Plus the <strong>thin layer assumption (<span class=\"math inline\">\\(L\\gg\\delta\\)</span>)</strong> for boundary layer (Obtained by non-dimensional scaling analysis, Full deriving on <a href=\"#a.1-governing-equation-of-boundary-layers\">Appendix A.1</a>): <span class=\"math display\">\\[\n\\begin{aligned}\nu&amp;\\gg v \\\\\n\\frac{\\partial}{\\partial y}&amp;\\gg\\frac{\\partial}{\\partial x}\n\\end{aligned}\n\\]</span></p></li>\n</ul>\n<p>The mass and momentum conservation equations reduces to: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} &amp;= 0 \\\\\nu\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y}&amp;=-\\frac{1}{\\rho}\\frac{\\partial p}{\\partial x}+\n\\nu\\left(\\overbrace{\\frac{\\partial^2u}{\\partial x^2}}^{\\mathrm{0}}+\\frac{\\partial^2u}{\\partial y^2}\\right) \\\\\nu\\frac{\\partial v}{\\partial x}+v\\frac{\\partial v}{\\partial y}&amp;=\n\\underbrace{-\\frac{1}{\\rho}\\frac{\\partial p}{\\partial y}}_{\\text{principle order}}+\\nu\\left(\\frac{\\partial^2v}{\\partial x^2}+\\frac{\\partial^2v}{\\partial y^2}\\right)\n\\end{aligned}\n\\]</span> as a result: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} &amp;= 0 \\\\\nu\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y}&amp;=-\\frac{1}{\\rho}\\frac{\\partial p}{\\partial x}+\\nu\\frac{\\partial^2u}{\\partial y^2} \\\\\n\\frac{1}{\\rho}\\frac{\\partial p}{\\partial y}&amp;=0\n\\end{aligned}\n\\]</span></p>\n<p>For the flat plate boundary layer, it is easy to get <span class=\"math inline\">\\(\\frac{\\partial p}{\\partial x}=0\\)</span> because the free stream pressure gradient in the <span class=\"math inline\">\\(x\\)</span> direction is <span class=\"math inline\">\\(0\\)</span>, so as in the boundary layer given the <span class=\"math inline\">\\(\\frac{\\partial p}{\\partial y}=0\\)</span>. As a consequence there is no pressure gradient within the flat plate boundary layer. The final governing equation writes:</p>\n<p><span class=\"math display\">\\[\n\\color{purple}\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} &amp;= 0 \\\\\nu\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y}&amp;=\\nu\\frac{\\partial^2u}{\\partial y^2} \\\\\n\\end{aligned}\n\\]</span></p>\n<p>And the boundary conditions are:</p>\n<p><span class=\"math display\">\\[\n\\color{purple}\n\\begin{aligned}\nu=v = 0\\quad&amp;\\mathrm{at}\\quad y = 0\\\\\nu = U\\quad&amp;\\mathrm{at}\\quad x = 0 \\\\\nu \\rightarrow U\\quad&amp;\\mathrm{as}\\quad y \\rightarrow \\infty \\\\\n\\end{aligned}\n\\]</span></p>\n<div class=\"note note-info\">\n            <p>These conditions demand an <em>infinite gradient</em> in speed at the leading edge <span class=\"math inline\">\\(x = y = 0\\)</span>, which implies a singularity in the mathematical solution there. The solution given by the boundary layer approximation is not valid at the leading edge.</p>\n          </div>\n<p>Define a stream function so that the continuity equation will be automatically included: <span class=\"math display\">\\[\n\\begin{aligned}\n\\psi &amp;= \\int u dy \\\\\nu = \\frac{\\partial\\psi}{\\partial y}&amp;, \\quad v = -\\frac{\\partial \\psi}{\\partial x}\n\\end{aligned}\n\\]</span> Subscribe into the momentum equation to get an single variable equation: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial\\psi}{\\partial y} \\frac{\\partial^2\\psi}{\\partial x \\partial y}- \\frac{\\partial\\psi}{\\partial x} \\frac{\\partial^2\\psi}{\\partial y^2} = \\nu\\frac{\\partial^3\\psi}{\\partial y^3}\n\\]</span> with boundary conditions: <span class=\"math display\">\\[\n\\color{purple}\n\\begin{aligned}\n\\frac{\\partial\\psi}{\\partial y}=\\frac{\\partial\\psi}{\\partial x} = 0\\quad&amp;\\mathrm{at}\\quad y = 0\\\\\n\\frac{\\partial\\psi}{\\partial y} = U\\quad&amp;\\mathrm{at}\\quad x = 0 \\\\\n\\frac{\\partial\\psi}{\\partial y} \\rightarrow U\\quad&amp;\\mathrm{as}\\quad y \\rightarrow \\infty \\\\\n\\end{aligned}\n\\]</span> Through a coordinate transformation(<a href=\"https://en.wikipedia.org/wiki/Self-similar_solution\">similarity solution</a>), this PDE can be transferred into an ODE and thus be solved easily.</p>\n<h4 id=\"similarity-solution\">5.5.2 Similarity solution</h4>\n<blockquote>\n<p>In the study of partial differential equations, particularly in fluid dynamics, a <strong>self-similar solution</strong> is a form of solution which is similar to itself if the independent and dependent variables are appropriately scaled.</p>\n</blockquote>\n<p>In contrast to the most frequently used method of \"separation variables\", the similarity solution involves combining the variables in a special way. Another example of using similarity to solve Heat diffusion equation lies on the <a href=\"#a.2-solving-the-heat-equation-using-similarity-solution\">Appendix A.2</a>.</p>\n<p>A self-similar equation doesn't change regardless how the variables scale. So assume a transformation: <span class=\"math display\">\\[\n\\begin{aligned}\ny = \\lambda^a\\bar{y}\\\\\nx = \\lambda^b\\bar{x}\\\\\n\\psi = \\lambda^c\\bar{\\psi}\\\\\n\\end{aligned}\n\\]</span> The resulting scaled function and writes: <span class=\"math display\">\\[\n\\begin{aligned}\n\\lambda^{3c-2a-b}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{y}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{x} \\partial \\bar{y}}- \n\\lambda^{3c-2a-b}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{x}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{y}^2} =\n\\lambda^{3c-3a}\\nu\\frac{\\partial^3\\bar{\\psi}}{\\partial \\bar{y}^3} \\\\\n\\Leftrightarrow\\quad\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{y}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{x} \\partial \\bar{y}}- \n\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{x}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{y}^2} =\n\\lambda^{-3c-a+b}\\nu\\frac{\\partial^3\\bar{\\psi}}{\\partial \\bar{y}^3}\n\\end{aligned}\n\\]</span> And the scaled boundary conditions gives: <span class=\"math display\">\\[\n\\begin{aligned}\n\\lambda^{c-a}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{y}}=\\lambda^{c-b}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{x}} = 0\\quad&amp;\\mathrm{at}\\quad \\lambda^{a}\\bar{y} = 0\\\\\n\\end{aligned}\n\\]</span> As a result, all the powers should be 0: <span class=\"math display\">\\[\n\\left.\\begin{array}{c}\n\\left.\\begin{array}{c}\n-c-a+b=0 \\\\\nc-a=0\n\\end{array}\\right\\} \\quad b=a / 2 \\\\\nc-b=0 \\qquad \\qquad  \\quad\n\\end{array}\\quad\\right\\} \\quad c=a / 2\n\\]</span> Here I need to put my derivation here:</p>\n<blockquote>\n<p>Similar to <a href=\"#a.2-solving-the-heat-equation-using-similarity-solution\">Appendix A.2</a>, we can construct an expression of <span class=\"math inline\">\\(\\psi\\)</span> as: <span class=\"math display\">\\[\n\\psi(x,y)= x^{1/2}f^\\dagger(\\eta^\\dagger), \\quad \\eta^\\dagger = yx^{-1/2}\n\\]</span> <div class=\"note note-danger\">\n            <blockquote><p><strong>Personal comment:</strong> I still don't know how to construct this kinda thing or why it work. The formula in Appendix gives me some idea but following it I got <span class=\"math inline\">\\(\\psi(x,y)= x^{1}f^\\dagger(\\eta^\\dagger)\\)</span>, <span class=\"math inline\">\\(\\eta^\\dagger = yx^{-1/2}\\)</span> instead...</p></blockquote>\n          </div></p>\n<p>Substitute the expression of <span class=\"math inline\">\\(\\psi\\)</span> into the equation with <span class=\"math inline\">\\(f^{\\dagger&#39;} = \\partial_{\\eta^{\\dagger}}f^{\\dagger}\\)</span>: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial\\psi}{\\partial y} &amp;= f^{\\dagger&#39;} \\\\\n\\frac{\\partial^2\\psi}{\\partial y^2} &amp;= x^{-1/2}f^{\\dagger&#39;&#39;} \\\\\n\\frac{\\partial^3\\psi}{\\partial y^3}&amp;= x^{-1}f^{\\dagger&#39;&#39;&#39;}\\\\\n\\frac{\\partial\\psi}{\\partial x} &amp;= \\frac{1}{2}x^{-1/2}f^{\\dagger}-\\frac{1}{2}x^{-1}f^{\\dagger&#39;}y \\\\\n&amp;= \\frac{1}{2}x^{-1/2}(f^{\\dagger} -\\eta^{\\dagger} f^{\\dagger&#39;}) \\\\\n\\frac{\\partial^2\\psi}{\\partial x \\partial y} &amp;= \\frac{1}{2}x^{-1/2}(x^{-1/2}f^{\\dagger&#39;} -x^{-1/2}\\eta^{\\dagger} f^{\\dagger&#39;&#39;} - x^{-1/2}f^{\\dagger&#39;}) \\\\\n&amp;=-\\frac{1}{2}x^{-1}\\eta^{\\dagger} f^{\\dagger&#39;&#39;}\\\\ \n\\frac{\\partial\\psi}{\\partial y}\\frac{\\partial^2\\psi}{\\partial x \\partial y} &amp;= f^{\\dagger&#39;}\\left[-\\frac{1}{2}x^{-1}\\eta^{\\dagger} f^{\\dagger&#39;&#39;}\\right] \\\\\n&amp;= -\\frac{1}{2}x^{-1} \\eta^{\\dagger}f^{\\dagger&#39;}f^{\\dagger&#39;&#39;} \\\\\n-\\frac{\\partial\\psi}{\\partial x}\\frac{\\partial^2\\psi}{\\partial y^2} &amp;=\\frac{1}{2}x^{-1/2}(f^{\\dagger} -\\eta^{\\dagger} f^{\\dagger&#39;})\\left[x^{-1/2}f^{\\dagger&#39;&#39;}\\right] \\\\\n&amp;= \\frac{1}{2}x^{-1}(f^{\\dagger} +\\eta^{\\dagger} f^{\\dagger&#39;})f^{\\dagger&#39;&#39;}\\\\\n\\end{aligned}\n\\]</span> As a result: <span class=\"math display\">\\[\n\\begin{aligned}\n-\\frac{1}{2}x^{-1}\\eta^{\\dagger} f^{\\dagger&#39;}f^{\\dagger&#39;&#39;}+ \\frac{1}{2}x^{-1}(f^{\\dagger} &amp;+\\eta^{\\dagger} f^{\\dagger&#39;})f^{\\dagger&#39;&#39;} = \\nu x^{-1}f^{\\dagger&#39;&#39;&#39;}\\\\\n\\Leftrightarrow \\qquad \\nu f^{\\dagger&#39;&#39;&#39;} - &amp;\\frac{1}{2} f^{\\dagger}f^{\\dagger&#39;&#39;} = 0\n\\end{aligned}\n\\]</span></p>\n</blockquote>\n<p>Ok.. above is what I derived, it's still an ODE but normally we want a cleaner result.</p>\n<p>So Blasius construct <span class=\"math inline\">\\(\\psi\\)</span> and <span class=\"math inline\">\\(\\eta\\)</span> with physical meaningful non-dimensional parameters to get (reference to <a href=\"https://youtu.be/Lw6aQJGD3FU\">MECH 346  Heat Transfer's Youtube channel</a>): <span class=\"math display\">\\[\n\\color{purple}\n\\psi(x,y)= (\\nu Ux)^{1/2}f(\\eta), \\quad \\eta = \\left(\\frac{U}{\\nu x}\\right)^{1/2}y\n\\]</span> So that: <span class=\"math display\">\\[\n\\begin{aligned}\n\\eta = \\sqrt{\\frac{U}{\\nu x}}y,&amp; \\quad\\mathrm{dimensionless~wall~normal~coordinate}\\\\\nf = \\frac{\\psi}{\\sqrt{\\nu Ux}},&amp; \\quad\\mathrm{dimensionless~stream~function}\\\\\nf&#39; = \\frac{u}{U},&amp; \\quad\\mathrm{dimensionless~velocity~profile} \\\\\nf&#39;&#39; = \\frac{\\sqrt{\\nu Ux}}{U^2}\\partial_yu, &amp;\\quad\\mathrm{related~to~shear~stress} \\\\\n\\end{aligned}\n\\]</span> And terms of the governing equation becomes: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial\\psi}{\\partial y} &amp;= Uf&#39; \\\\\n\\frac{\\partial^2\\psi}{\\partial y^2} &amp;= {(U\\nu x)}^{-1/2}f&#39;&#39; \\\\\n\\frac{\\partial^3\\psi}{\\partial y^3}&amp;= U^2x^{-1}f&#39;&#39;&#39;\\\\\n\\frac{\\partial\\psi}{\\partial x} &amp;= \\frac{1}{2}(\\nu U/x)^{1/2}(f -\\eta f&#39;)\\\\\n\\frac{\\partial^2\\psi}{\\partial x \\partial y} &amp;=-\\frac{1}{2}Ux^{-1}\\eta f&#39;&#39;\n\\\\ \n\\frac{\\partial\\psi}{\\partial y}\\frac{\\partial^2\\psi}{\\partial x \\partial y} &amp;= -\\frac{1}{2}U^2x^{-1}\\eta f&#39;f&#39;&#39;\\\\\n-\\frac{\\partial\\psi}{\\partial x}\\frac{\\partial^2\\psi}{\\partial y^2}\n&amp;= \\frac{1}{2}U^2x^{-1}(f +\\eta f&#39;)f&#39;&#39;\\\\\n\\end{aligned}\n\\]</span> And the ODE turns out to be: <span class=\"math display\">\\[\n\\color{purple}\n2f&#39;&#39;&#39; +ff&#39;&#39; = 0\n\\]</span> Resulting boundary condition is: <span class=\"math display\">\\[\n\\color{purple}\n\\begin{aligned}\nf&#39; = 0\\quad &amp;at\\quad \\eta=0     \\quad\\mathrm{(no~slip)}\\\\\nf = 0\\quad &amp;at\\quad \\eta=0      \\quad\\mathrm{(impenetrability)} \\\\\nf&#39; = 1\\quad &amp;at\\quad \\eta\\rightarrow\\infty \\quad(u = U\\mathrm{~free stream}) \\\\\nf&#39;&#39; = 0\\quad &amp;at\\quad \\eta\\rightarrow\\infty \\quad(\\partial_yu=0,\\mathrm{unnecessary}) \\\\\n\\end{aligned}\n\\]</span></p>\n<h4 id=\"solving-the-similarity-solution\">5.5.3 Solving the similarity solution</h4>\n<p>Split the 3-order ODE into a set of 3 first order ODEs: <span class=\"math display\">\\[\n\\left\\{\\begin{array}{l}\n    f_p  = f&#39; \\\\\n    f_{pp} = f_p&#39; \\\\\n    2f&#39;_{pp} +ff_{pp}  = 0\n\\end{array}\\right.\n\\]</span> with boundary conditions: <span class=\"math display\">\\[\n\\begin{aligned}\nf_p = 0\\quad &amp;at\\quad \\eta=0    \\\\\nf = 0\\quad &amp;at\\quad \\eta=0      \\\\\nf_p = 1\\quad &amp;at\\quad \\eta\\rightarrow\\infty \\\\\nf_{pp} = 0\\quad &amp;at\\quad \\eta\\rightarrow\\infty,\\mathrm{unnecessary} \\\\\n\\end{aligned}\n\\]</span> The third boundary condition has no closed form solution, so we need to solve it numerically.</p>\n<ol type=\"1\">\n<li><p>One method of doing it is guessing another initial condition <span class=\"math inline\">\\(f_{pp} = ?\\)</span> at <span class=\"math inline\">\\(\\eta=0\\)</span>, integrating the equation from <span class=\"math inline\">\\(\\eta=0\\)</span> with Runge-Kutta method to meet the 3rd boundary condition i.e. <strong>transfer the boundary condition to the initial condition</strong>.</p>\n<div class=\"note note-info\">\n            <p>RungeKutta method is an effective and widely used numerical method for solving the initial-value problems of differential equations. It integrated the function discretely from zero in small steps (<span class=\"math inline\">\\(h\\)</span>) in an order of 4 (more on <a href=\"https://youtu.be/kUcc8vAgoQ0\">LearnChemE's Youtube</a>). <span class=\"math display\">\\[\\left\\{\\begin{array}{l}y_{n+1}=y_{n}+\\frac{1}{6}\\left(K_{1}+2 K_{2}+2 K_{3}+K_{4}\\right) \\\\K_{1}=h f\\left(x_{n}, y_{n}\\right) \\\\K_{2}=h f\\left(x_{n}+\\frac{1}{2} h, y_{n}+\\frac{1}{2} K_{1}\\right) \\\\K_{3}=h f\\left(x_{n}+\\frac{1}{2} h, y_{n}+\\frac{1}{2} K_{2}\\right) \\\\K_{4}=h f\\left(x_{n}+h, y_{n}+K_{3}\\right)\\end{array}\\right.\\]</span></p>\n          </div>\n<p>It turns out it meets the 3<sup>rd</sup> boundary condition when: <span class=\"math display\">\\[\nf_{pp} = 0.332~at~ \\eta=0\n\\]</span> And the function looks like below:</p>\n<p><img src=\"Similarity solution.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Numerical solution to the similarity solution, the 4 boundary conditions are fitted. After MECH 346  Heat Transfer's Youtube channel(https://youtu.be/Lw6aQJGD3FU)\" style=\"zoom:40%;\" /></p>\n<p>From the solution, we can see the stream function <span class=\"math inline\">\\(f\\)</span> first increases with a decreasing slop then approaches to a linear increase line. While the velocity profile <span class=\"math inline\">\\(f&#39;\\)</span> and shear stress <span class=\"math inline\">\\(f&#39;&#39;\\)</span> approach the 1 and 0 at the free stream respectively,</p></li>\n<li><p>Another method is solve <span class=\"math inline\">\\(f_{pp}~at~ \\eta=0\\)</span> directly numerically. And the solution is: <span class=\"math display\">\\[\nf_{pp} = 0.332096~at~ \\eta=0\n\\]</span> More on <a href=\"https://youtu.be/Lw6aQJGD3FU\">MECH 346  Heat Transfer's Youtube channel</a> and <a href=\"https://web.mit.edu/fluids-modules/www/highspeed_flows/ver2/bl_Chap2.pdf\">MIT's note</a>.</p></li>\n</ol>\n<h4 id=\"blasius-results\">5.5.4 Blasius results</h4>\n<p>As a consequence, similar to what we do based on the <a href=\"#laminar-results-von-k%C3%A1rm%C3%A1n-results\">Von Krmn results result</a>, recall the definition of the boundary layer: <span class=\"math display\">\\[\nf_p = \\frac{u|_\\delta}{U} =  0.99\n\\]</span> It is easy to get</p>\n<ul>\n<li><p>the boundary layer thickness: <span class=\"math display\">\\[\n\\begin{aligned}\n\\eta_1&amp;=\\sqrt{\\frac{U}{\\nu x}}\\delta\\approx5.0 \\\\\n\\Rightarrow \\delta &amp;\\approx 5.0 \\sqrt{\\frac{\\nu x}{U}} \\\\\n\\Rightarrow \\frac{\\delta}{x} &amp;\\approx 5.0 \\sqrt{\\frac{\\nu}{Ux}} \\\\\n\\color{purple}{\\frac{\\delta}{x} }&amp;\\color{purple}{\\approx 5 Re_x^{-1/2}}\\\\\n\\end{aligned}\n\\]</span> with <span class=\"math inline\">\\(\\color{purple}Re_x= Ux/\\nu\\)</span> as the <strong>streamwise Reynolds number</strong>.</p></li>\n<li><p>the thickness displacement: <span class=\"math display\">\\[\n\\begin{aligned}\n\\delta^* &amp;= \\int_0^\\delta\\left(1-\\frac{u}{U}\\right)dy \\\\\n&amp;= \\sqrt{\\frac{\\nu x}{U}}\\int_0^{\\eta_1\\approx5.0 }\\left(1-f&#39;\\right)d\\eta \\\\\n&amp;= \\sqrt{\\frac{\\nu x}{U}}\\left[\\eta_1 - f_1\\right]\\\\\n\\end{aligned}\n\\]</span> with <span class=\"math inline\">\\(f_1 \\approx 3.283\\)</span>: <span class=\"math display\">\\[\n\\begin{aligned}\n\\color{purple}\\frac{\\delta^*}{x}\\approx 1.721 Re_x^{-1/2}\n\\end{aligned}\n\\]</span></p></li>\n<li><p>the momentum displacement and the factor of friction: <span class=\"math display\">\\[\n\\tau_w = \\rho\\nu\\frac{\\partial u}{\\partial y}|_{y=0} = \\rho\\nu U\\sqrt{\\frac{U}{\\nu x}}f&#39;&#39;(0)\n\\]</span> with <span class=\"math inline\">\\(f&#39;&#39;(0) \\approx 0.332\\)</span>: <span class=\"math display\">\\[\nC_f = \\frac{\\tau_w}{1/2\\rho U^2} \\approx 0.664Re_x^{-1/2}\n\\]</span></p>\n<p><span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\theta}{x} \\approx 0.664Re_x^{-1/2}\n\\]</span></p></li>\n<li><p>the shape factor: <span class=\"math display\">\\[\n\\color{purple}\nH = \\frac{\\delta^*}{\\theta} \\approx 2.59\n\\]</span></p></li>\n</ul>\n<h3 id=\"validity-of-the-laminar-results\">5.6 Validity of the laminar results</h3>\n<p>The above results are based on the hypothesis that the boundary layer is thin enough so that the coupling with the outer flow is negligible. This theory breaks down as soon as <span class=\"math inline\">\\(\\frac{\\delta}{x}=\\mathcal{O}(1)\\)</span> i.e. <span class=\"math inline\">\\(\\frac{\\delta}{x}&lt;0.1\\)</span>. As a result, based on the Blasius result, the upper limit of the streamwise Reynolds number depends on transition to turbulence writes <span class=\"math display\">\\[\n5Re_x^{-1/2}&lt;0.1\\\\\n\\Rightarrow Re_{x,min} &gt; 2500\n\\]</span> For smaller <span class=\"math inline\">\\(Re_x\\)</span>, the interaction with the outer flow is important and leads to departures from these results.</p>\n<p>Besides, at a threshold Reynolds number, the boundary layer becomes <strong>turbulent</strong> and the results above do not hold. This critical value of the Reynolds number is <span class=\"math inline\">\\(Re_c\\approx 3  10^6\\)</span>. Usually, the surfaces are not smooth and transition occurs earlier, sometimes at Reynolds numbers as low as <span class=\"math inline\">\\(10^5\\)</span>.</p>\n<h3 id=\"comparison-of-the-results\">5.7 Comparison of the results</h3>\n<p>Similar to what we do based on the <a href=\"#laminar-results-von-k%C3%A1rm%C3%A1n-results\">Von Krmn results result</a>, based on the Prandtl one-seventh power law, the turbulence results can be derived easily, here is the table of all results:</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th>Results</th>\n<th><span class=\"math inline\">\\(\\delta/x\\)</span></th>\n<th><span class=\"math inline\">\\(\\delta^*/x\\)</span></th>\n<th><span class=\"math inline\">\\(H\\)</span></th>\n<th><span class=\"math inline\">\\(c_f\\)</span></th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>Blasius laminar</td>\n<td><span class=\"math inline\">\\(5.0Re_x^{-1/2}\\)</span></td>\n<td><span class=\"math inline\">\\(1.72Re_x^{-1/2}\\)</span></td>\n<td><span class=\"math inline\">\\(2.59\\)</span></td>\n<td><span class=\"math inline\">\\(0.664Re_x^{-1/2}\\)</span></td>\n</tr>\n<tr class=\"even\">\n<td>Integral laminar</td>\n<td><span class=\"math inline\">\\(5.5Re_x^{-1/2}\\)</span></td>\n<td><span class=\"math inline\">\\(1.83Re_x^{-1/2}\\)</span></td>\n<td><span class=\"math inline\">\\(2.5\\)</span></td>\n<td><span class=\"math inline\">\\(0.73Re_x^{-1/2}\\)</span></td>\n</tr>\n<tr class=\"odd\">\n<td>Error</td>\n<td><span class=\"math inline\">\\(10\\%\\)</span></td>\n<td><span class=\"math inline\">\\(6\\%\\)</span></td>\n<td><span class=\"math inline\">\\(3\\%\\)</span></td>\n<td><span class=\"math inline\">\\(10\\%\\)</span></td>\n</tr>\n<tr class=\"even\">\n<td>Integral turbulent</td>\n<td><span class=\"math inline\">\\(0.16Re_x^{-1/7}\\)</span></td>\n<td><span class=\"math inline\">\\(0.02Re_x^{-1/7}\\)</span></td>\n<td><span class=\"math inline\">\\(1.3\\)</span></td>\n<td><span class=\"math inline\">\\(0.027Re_x^{-1/7}\\)</span></td>\n</tr>\n</tbody>\n</table>\n<p>Several points:</p>\n<ul>\n<li>There is an error of less than 10% between integral and Blasius results.</li>\n<li>The boundary layer thickness <span class=\"math inline\">\\(\\delta\\)</span> grows like <span class=\"math inline\">\\(x^{6/7}\\)</span> for turbulent flows, which represents a faster growth than the <span class=\"math inline\">\\(x^{1/2}\\)</span> law for the laminar boundary layer.</li>\n<li>The viscous displacement thickness <span class=\"math inline\">\\(\\delta^*\\)</span> and the shape factor <span class=\"math inline\">\\(H=\\delta^*/\\theta\\)</span> for turbulent boundary layers is very small.</li>\n<li>The skin friction coefficient <span class=\"math inline\">\\(c_f\\)</span> is greater for turbulent boundary layers than for the laminar ones.</li>\n</ul>\n<h2 id=\"appendix\">Appendix</h2>\n<h3 id=\"a.1-governing-equation-of-boundary-layers\">A.1 Governing equation of boundary layers</h3>\n<h4 id=\"a.1.1-scalings\">A.1.1 Scalings</h4>\n<p>Started by scaling the spatial derivatives: <span class=\"math display\">\\[\n\\partial_x \\sim \\frac{1}{L} \\qquad \\partial_y \\sim \\frac{1}{\\delta}\n\\]</span> By the thin-layer condition: <span class=\"math inline\">\\(L\\gg\\delta\\)</span>, we can introduce a small parameter <span class=\"math inline\">\\(\\epsilon \\ll 1\\)</span> as: <span class=\"math display\">\\[\n\\frac{\\delta}{L} = \\epsilon\n\\]</span> As a result, introduce the stream function <span class=\"math inline\">\\(\\psi\\)</span> under the conditions of 2D and incompressibility. The proportion of the streamwise and normal streamwise velocities <span class=\"math inline\">\\(u, v\\)</span> can be expressed as: <span class=\"math display\">\\[\n\\frac{u}{v} = \\frac{\\partial_y\\psi}{-\\partial_x\\psi}\\sim\\frac{L}{\\delta}\n\\]</span> which gives: <span class=\"math display\">\\[\n\\Rightarrow \\quad v\\sim\\epsilon u\n\\]</span> implying that the <span class=\"math inline\">\\(v\\)</span> is much smaller than <span class=\"math inline\">\\(u\\)</span>.</p>\n<p>Then rescale the wall normal quantities according to the streamwise quantities: <span class=\"math display\">\\[\n\\begin{aligned}\nx^* &amp;= \\frac{x}{L} \\\\\ny^* &amp;= \\frac{y}{\\delta} = \\frac{y}{\\epsilon L}\\\\\nu^* &amp;= \\frac{u}{U} \\\\\nv^* &amp;= \\frac{v}{\\epsilon U} \\\\\np^* &amp;= \\frac{p}{\\rho U^2}\n\\end{aligned}\n\\]</span> <div class=\"note note-info\">\n            <p>In this case, <span class=\"math inline\">\\(p^*\\)</span> can be thought of as a mathematical function to ensure incompressibility of the scaled function.</p>\n          </div></p>\n<h4 id=\"a.1.2-asymptotic-derivation\">A.1.2 Asymptotic derivation</h4>\n<p>Substitute the scaled variables into the governing equations: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{U}{L} \\partial_{x^{*}} u^{*}+\\frac{\\epsilon U}{\\epsilon L} \\partial_{y^{*}} v^{*} &amp;= 0 \\\\\n\\frac{U^{2}}{L} u^{*} \\partial_{x^{*}} u^{*}+\\frac{U^{2}}{L} v^{*} \\partial_{y^{*}} u^{*}&amp;=-\\frac{ U^{2}}{L} \\partial_{x^{*}} p^{*}+\\nu\\left(\\frac{U}{L^{2}} \\partial_{x^{*}}^{2} u^{*}+\\frac{U}{\\epsilon^{2} L^{2}} \\partial_{y^{*}}^{2} u^{*}\\right) \\\\\n\\frac{\\epsilon U^{2}}{L} u^{*} \\partial_{x^{*}} v^{*}+\\frac{\\epsilon U^{2}}{L} v^{*} \\partial_{y^{*}} v^{*} &amp;=-\\frac{ U^{2}}{\\epsilon L} \\partial_{y^{*}} p^{*}+\\nu\\left(\\frac{\\epsilon U}{L^{2}} \\partial_{x^{*}}^{2} v^{*}+\\frac{U}{\\epsilon L^{2}} \\partial_{y^{*}}^{2} v^{*}\\right)\n\\end{aligned}\n\\]</span> Can be simplified into: <span class=\"math display\">\\[\n\\begin{aligned}\n\\partial_{x^{*}} u^{*}+\\partial_{y^{*}} v^{*} &amp;= 0 \\\\\nu^{*} \\partial_{x^{*}} u^{*}+v^{*} \\partial_{y^{*}} u^{*} &amp;=-\\partial_{x^{*}} p^{*}+\\frac{1}{Re_{L}} \\partial_{x^{*}}^{2} u^{*}+\\frac{1}{\\epsilon^{2} Re_{L}} \\partial_{y^{*}}^{2} u^{*} \\\\\nu^{*} \\partial_{x^{*}} v^{*}+v^{*} \\partial_{y^{*}} v^{*} &amp;=-\\frac{1}{\\epsilon^{2}} \\partial_{y^{*}} p^{*}+\\frac{1}{Re_{L}} \\partial_{x^{*}}^{2} v^{*}+\\frac{1}{\\epsilon^{2} Re_{L}} \\partial_{y^{*}}^{2} v^{*}\n\\end{aligned}\n\\]</span> where <span class=\"math inline\">\\(Re_L = UL/\\nu\\)</span></p>\n<p>To keep a balance between the advection(LHS) and diffusion (RHS), impose: <span class=\"math display\">\\[\n\\epsilon^2Re_L=1 \\\\\n\\Rightarrow \\epsilon = \\frac{\\delta}{L}=Re_L^{-1/2}\n\\]</span> As a result, the leading order of the system is: <span class=\"math display\">\\[\n\\begin{aligned}\n\\partial_{x^{*}} u^{*}+\\partial_{y^{*}} v^{*} &amp;= 0 \\\\\nu^{*} \\partial_{x^{*}} u^{*}+v^{*} \\partial_{y^{*}} u^{*} &amp;=-\\partial_{x^{*}} p^{*}+\\partial_{y^{*}}^{2} u^{*} \\\\\n0&amp;=\\partial_{y^{*}} p^{*}\n\\end{aligned}\n\\]</span></p>\n<h3 id=\"a.2-solving-the-heat-equation-using-similarity-solution\">A.2 Solving the heat equation using similarity solution</h3>\n<p>References<a href=\"https://youtu.be/dNLmvhZWEq8\">Dr Chris Tisdell's Youtube</a>, <a href=\"https://www.ucl.ac.uk/~ucahhwi/LTCC/sectionB-similarity.pdf\">UCL's class note</a>.</p>\n<p>Given PDE with boundary and initial conditions: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} =&amp; k\\frac{\\partial^2 u}{\\partial x^2}\\\\\nu(x,0)=0, &amp;\\quad x&gt;0\\\\\nu(x,t)\\rightarrow0, &amp;\\quad x\\rightarrow\\infty \\\\\n\\partial_x u(0,t)=N, &amp;\\quad t&gt;0\n\\end{aligned}\n\\]</span></p>\n<ol type=\"1\">\n<li><p>Determine a set of transformations: <span class=\"math display\">\\[\n\\begin{aligned}\nx &amp;= \\lambda^a\\bar{x}\\\\\nt &amp;= \\lambda^b\\bar{t}\\\\\nu &amp;= \\lambda^c\\bar{u}\\\\\n\\end{aligned}\n\\]</span> Substitute into the equation: <span class=\"math display\">\\[\n\\begin{aligned}\n\\lambda^{c-b}\\frac{\\partial \\bar{u}}{\\partial \\bar{t}} = \\lambda^{c-2a}k\\frac{\\partial^2 \\bar{u}}{\\partial \\bar{x}^2} \\\\\n\\frac{\\partial \\bar{u}}{\\partial \\bar{t}} = \\lambda^{-2a+b}k\\frac{\\partial^2 \\bar{u}}{\\partial \\bar{x}^2}\n\\end{aligned}\n\\]</span> Boundary condition: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x} =N, \\quad t&gt;0 \\\\\n\\lambda^{c-a}\\frac{\\partial \\bar{u}}{\\partial \\bar{x}}=N\n\\end{aligned}\n\\]</span></p>\n<p>As a result: <span class=\"math display\">\\[\n\\begin{aligned}\n-2a+b &amp;= 0 \\\\\nc-a&amp;=0\n\\end{aligned}\n\\]</span></p></li>\n<li><p>Determin <span class=\"math inline\">\\(s\\)</span> and <span class=\"math inline\">\\(r\\)</span> such that: <span class=\"math display\">\\[\n\\bar{x\\vphantom{t}}\\bar{t}^s=xt^s\\qquad \\bar{u\\vphantom{t}}\\bar{t}^r = ut^r\n\\]</span> Substitute we have: <span class=\"math display\">\\[\n\\begin{aligned}\n\\bar{x\\vphantom{t}}\\bar{t}^s&amp;=xt^s \\\\\n\\bar{x\\vphantom{t}}\\bar{t}^s &amp;= \\lambda^{a+sb}\\bar{x\\vphantom{t}}\\bar{t}^s  \\\\\n\\Rightarrow \\quad s &amp;= -a/b =  -1/2\n\\end{aligned}\n\\]</span> and <span class=\"math display\">\\[\n\\begin{aligned}\n\\bar{u\\vphantom{t}}\\bar{t}^r&amp;=ut^r \\\\\n\\bar{u\\vphantom{t}}\\bar{t}^r &amp;= \\lambda^{c+rb}\\bar{x\\vphantom{t}}\\bar{t}^r = \\lambda^{(c+2ar)}\\bar{x\\vphantom{t}}\\bar{t}^r\\\\\n\\Rightarrow \\quad r &amp;= -c/b = -1/2\n\\end{aligned}\n\\]</span></p></li>\n<li><p>With two terms unchanged by the transformation. A solution combines these two terms can be constructed as <span class=\"math inline\">\\(u(x,t) = t^{-r}f(xt^s) = t^{-r}f(\\eta)\\)</span>: <span class=\"math display\">\\[\n\\begin{aligned}\nu(x,t) = t^{c/b}f(\\eta), \\quad\\mathrm{where~}\\eta = xt^{-a/b} \\\\\n\\Leftrightarrow\\quad u(x,t) = t^{1/2}f(\\eta),\\quad\\mathrm{where~}\\eta = \\frac{x}{t^{1/2}}\n\\end{aligned}\n\\]</span> <div class=\"note note-info\">\n            <p>Note that <span class=\"math inline\">\\(u(x,t) = t^{c/b}f(\\eta), \\quad \\eta = xt^{-a/b}\\)</span> is a general solution and it suits for every conditions.</p>\n          </div></p></li>\n<li><p>Substitute into the original function to get a ODE: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} &amp;= \\frac{1}{2}t^{-1/2}f - \\frac{1}{2}t^{-1}xf&#39; \\\\ &amp;= \\frac{1}{2}t^{-1/2}f - \\frac{1}{2}t^{-1/2}\\eta f&#39;\\\\&amp;=\\frac{1}{2}t^{-1/2}\\left(f-\\eta f&#39;\\right)\\\\\n\\frac{\\partial^2 u}{\\partial x^2} &amp;= t^{-1/2}f&#39;&#39;\\\\\n\\end{aligned}\n\\]</span> The resulting equation is therefore: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\frac{1}{2}t^{-1/2}\\left(f-\\eta f&#39;\\right)= kt^{-1/2}f&#39;&#39; \\\\\n\\Leftrightarrow\\quad&amp; \\frac{1}{2}\\left(f-\\eta f&#39;\\right)= kf&#39;&#39; \\\\\n\\Leftrightarrow\\quad&amp; 2kf&#39;&#39;+\\eta f&#39;-f = 0\n\\end{aligned}\n\\]</span></p>\n<p>The following work is solving this ODE, which is illustrated more on <a href=\"https://www.ucl.ac.uk/~ucahhwi/LTCC/sectionB-similarity.pdf\">UCL's class note</a>.</p></li>\n</ol>\n","site":{"data":{}},"wordcount":32054,"excerpt":"<div class=\"note note-primary\">\n            <p>Internal pipe flow is not enough for me, continue to review the tricky part.</p>\n          </div>","more":"<h2 id=\"fluid-structure-interaction\">4 Fluid-structure interaction</h2>\n<p>When an unbounded homogeneous flow approaches an obstacle, viscous effects become important and substantially deform the flow profile. The resulting boundary layers and wakes are responsible for generating forces and moments on the obstacle.</p>\n<h3 id=\"examples\">4.1 Examples</h3>\n<h4 id=\"lift-generation\">4.1.1 Lift generation</h4>\n<p>Here comes the most popular question: how does an aircraft fly?</p>\n<p>The basic answer is that</p>\n<blockquote>\n<p>The airfoil is shaped so that its upper surface is longer than its lower surface. A parcel of fluid arriving at the leading edge then splits into two parcels, one following the upper surface and the other the lower surface. As the fluid has more distance to travel on the upper surface than on the lower surface, it goes faster to have the <strong>same transit time</strong>. The Bernoulli effect follows: the higher velocity on the upper surface yields a lower pressure and an ascending force is created: the lift.</p>\n</blockquote>\n<p>The use of Bernoulli effect is, to some extent, correct. However, based on experiment findings shown below, the same transit time assumption is not quite right.</p>\n<p>I{t}s clear the upper flow is accelerated compared to the lower flow. This happens already at the leading edge, but the lower flow never catches up with the upper one. As a result, the upper flow possesses a shorter transit time.</p>\n<p><img src=\"Flow past an airfoil.gif\" alt=\"Flow past an airfoil visualised through the trajectory of one pulse of smoke. After Babinsky (http://www.cam.ac.uk/research/news/how-wings-really-work).\" style=\"zoom:100%;\" /></p>\n<p>As a consequence, the physical mechanism behind lift is not so simple. A plausible answer is twofolds.</p>\n<ul>\n<li>On the one hand, the fluid is accelerated on the upper surface and slowed down on the lower surface, creating a descending pressure gradient, hence lift.</li>\n<li>On the other hand, the fluid trajectory is overall deflected downwards when passing the airfoil. This implies that the airfoil creates a descending force onto the fluid, and, by Newtons third law, that the fluid generates an ascending force onto the airfoil.</li>\n</ul>\n<h4 id=\"wingtip-vortices\">4.1.2 Wingtip vortices</h4>\n<p>At the tip of the wing, when the lower pressure upper surface meets the higher pressure lower surface, wingtip vortices are generated. These vortices are generally strong, long-lived and consequently dangerous, as shown below:</p>\n<p><img src=\"Wingtip vortex.jpeg\" alt=\"Wingtip vortex behind a plane visualised with red smoke.\" style=\"zoom:50%;\" /></p>\n<p>Flying through such a vortex will create a rolling moment that can destabilize the flight. Many such incidents have happened during takeoff and landing. As a result, airports have decided on quiet periods of one to two minutes between two successive takeoffs or landings to allow for these vortices to dissipate to a less dangerous strength.</p>\n<p><img src=\"V formation.jpeg\" alt=\"Birds flying in V-formation.\" style=\"zoom:50%\" /></p>\n<p>Yet the wingtip vortices are leveraged perfectly by the nature, the V-formation. When one bird follows another bird, it places itself a little bit on the side to benefit from the lift generated by the wingtip vortices of its leader.</p>\n<h4 id=\"others\">4.1.3 Others</h4>\n<p>Wind and ocean engineering also present important challenges in the area of fluid-structure interaction.</p>\n<p>The construction of tall building is necessary to accommodate large professional centres and these tall buildings interact strongly with the wind. Similar issues arise with bridges. Serious oscillation would be generated due to the \"wind load\".</p>\n<p align=\"center\">\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/tHMPR7flpf4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n</iframe>\n</p>\n<p>In water, it is important to understand fluid-structure interactions to design efficient breakwaters and protect constructions on the shore or beaches. Pier piles are also good examples of structures interacting with water and that have to be designed carefully.</p>\n<p>Lastly, we can take advantage of natural phenomena such as wind and currents by designing structures that will store such energy like wind and water turbines.</p>\n<h3 id=\"effect-of-a-structure-on-the-fluid\">4.2 Effect of a structure on the fluid</h3>\n<p>When an external flow goes past an obstacle, boundary layer and wake effects occur on the walls and after the obstacle respectively.</p>\n<h4 id=\"boundary-layers\">4.2.1 Boundary layers</h4>\n<p><img src=\"Boundary layers.png\" alt=\"Sketch of the flow past a sharp flat plate oriented in the direction of the flow.\nTwo situations are shown: a low-Re flow (ReL= 10) and a high-Re flow (ReL= 107) and the associated boundary layers depicted. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" /></p>\n<p><strong>Convenient definition</strong>: a region where the fluids velocity parallel to the wall is smaller or equal to 99% of the external velocity.</p>\n<ul>\n<li>Inside the boundary layer, the flow feels the effect of the wall and is gradually slowed down as we approach the wall. The presence of these velocity gradients is a consequence of <strong>viscous dissipation</strong>.</li>\n<li>Outside the boundary layer, the flow does not feel the presence of the walls. It remains homogeneous and is considered <strong>inviscid</strong>.</li>\n</ul>\n<div class=\"note note-info\">\n            <p>Note that this is only an assumption, the interaction between the boundary layer and the outer pressure distribution is neglected. For slender bodies at large <span class=\"math inline\">\\(Re\\)</span>, such as airfoils, when placed parallel to the flow, this assumption provides good results due to the thin and weak boundary layer.</p>\n          </div>\n<p>There are <strong>two types</strong> of the boundary layers defined by the Reynolds number:</p>\n<ul>\n<li>Low <span class=\"math inline\">\\(Re\\)</span>, laminar boundary layer. Because spatial variations are slow, the laminar boundary layer occupies a large spatial region.</li>\n<li>High <span class=\"math inline\">\\(Re\\)</span>, two distinct regions in the boundary layer:\n<ul>\n<li>laminar boundary layer similar to that of low-Re flows but much thinner</li>\n<li>turbulent boundary layer that occurs further away in the streamwise direction and is larger than the laminar boundary layer.</li>\n</ul></li>\n</ul>\n<p>The <strong>viscous displacement effect</strong> describes the non-zero velocity in the direction orthogonal to the wall because the velocity parallel to the wall varies in the direction orthogonal to the wall.</p>\n<ul>\n<li>For low <span class=\"math inline\">\\(Re\\)</span> laminar boundary layers, this effect is important</li>\n<li>For high <span class=\"math inline\">\\(Re\\)</span> boundary layers, these boundary layers are so thin that this effect is negligible.</li>\n</ul>\n<h4 id=\"wakes\">4.2.2 Wakes</h4>\n<p><img src=\"Wakes.png\" alt=\"Sketch of the wake past a cylinder and the different regimes observed as a function of the Reynolds number Re = UR/, where U is the velocity of the fluid infinitely far away from the cylinder, R the cylinder radius and  the fluids kinematic viscosity. After Middleton & Southard, Mechanics of Sediment Movement, SEPM Short Course Notes, Vol. 3 (1984).\" style=\"zoom:50%;\" /></p>\n<p>When the inertia is non-trivial (equivalently viscous effects are not overwhelmingly dominant), the gradients of velocity induced by the boundary layer are advected downstream and create a <strong>wake</strong> past the obstacle. This region can display dramatic departures from the established flow infinitely far away from the obstacle.</p>\n<p>The sketch above shows how several typical regimes of the wake past a cylinder in different <span class=\"math inline\">\\(Re\\)</span>s:</p>\n<ul>\n<li>Low <span class=\"math inline\">\\(Re\\)</span>: steady and symmetric flow</li>\n<li><span class=\"math inline\">\\(Re=\\mathcal{O}(10)\\)</span>:\n<ul>\n<li>the upstream-downstream symmetry is broken</li>\n<li>flow separation occurs. The boundary layers separate from the wall and a recirculation zone is created where two counter-rotating vortices live.</li>\n<li>wake remains stationary</li>\n<li>the up-down symmetry is still preserved</li>\n</ul></li>\n<li><span class=\"math inline\">\\(Re=\\mathcal{O}(100)\\)</span>:\n<ul>\n<li>the up-down symmetry is broken</li>\n<li>flow separation developed</li>\n<li>wake is now periodic in time, vortices periodically break away from the back of the cylinder in an alternate fashion and are advected downstream</li>\n<li>This type of wake is called <strong>Von Krmn streets</strong>.</li>\n</ul></li>\n<li><span class=\"math inline\">\\(Re&gt;\\mathcal{O}(1000)\\)</span>: any simple time-dependence in the wake is lost and it is now turbulent.</li>\n</ul>\n<p>Note that as the Reynolds number is increased, different types of turbulent wakes can be observed.</p>\n<ul>\n<li>At <span class=\"math inline\">\\(Re = 5\\times10^3\\)</span>, the turbulent wake is detached from the wall and a laminar bubble is observed at the back of the cylinder.</li>\n<li>As the Reynolds number is increased, this bubble shrinks</li>\n<li>At <span class=\"math inline\">\\(Re = 10^5\\)</span>, the back of the cylinder has become fully turbulent</li>\n<li>As Re is further increased, the turbulent wake becomes thinner and thinner and the influence of the cylinder on the flow decreases. This is the result of the fact that the characteristic length for advection becomes incomparably larger than the diameter of the cylinder</li>\n</ul>\n<h3 id=\"effect-of-the-fluid-on-a-structure\">4.3 Effect of the fluid on a structure</h3>\n<p>In this section, we look at the opposite interaction: the impact of boundary layers and wakes on the structures.</p>\n<h4 id=\"free-kick-like-cristiano-ronaldo\">4.3.1 Free kick like Cristiano Ronaldo</h4>\n<p align=\"center\">\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MscZ_pd7iAM?start=12\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n</iframe>\n</p>\n<p>Personally, I'm not a big fan of football. The only football game I watch is FIFA. And I happened to watch this legendary game on live. I remember it was 3 o'clock in the morning and I barely held my scream.</p>\n<p><img src=\"magnus effect illustration.png\" alt=\"Illustration of the Magnus effect using a downward flow past an anti-clockwise rotating sphere. The flow is slowed down on the right as opposed to the left. The pressure is then greater on the right of the sphere and a leftward force is generated.\" style=\"zoom:50%;\" /></p>\n<p>The explanation of such a trajectory lies in the <strong>Magnus effect</strong> which describes a spinning object moving through a fluid. Rotating the ball accelerates the flow on one side while slowing it down on the other. This difference of velocity breaks the symmetry of the flow and creates a difference of pressure. And this results in an additional force that bends the trajectory of the ball.</p>\n<h4 id=\"the-tacoma-narrows-bridge\">4.3.2 The Tacoma Narrows bridge</h4>\n<p align=\"center\">\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XggxeuFDaDU?start=15\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n</iframe>\n</p>\n<p>Another famous aeroelastic failure is this 1.8km long bridge in the state of Washington. The 6 million dollar bridge collapsed in a steady standard wind in November, 1940, only 3 months after its opening date. Back then this wind interacted in an unexpected manner with the bridge and created a positive feedback loop called <strong>aeroelastic flutter</strong>. A oscillating wake due to the periodic vortex shedding excited a <strong>second torsional mode</strong>: the midpoint of the bridge remained motionless while the two opposite halves twisted in opposite directions. This torsion further enhanced the strength of the wake, which in turn enhanced the torsion until the bridge collapsed.</p>\n<h2 id=\"boundary-layer-theory-integral-approach\">5 Boundary layer theory  Integral approach</h2>\n<p>First, a control volume is defined as blow:</p>\n<ul>\n<li>Boundary : the segment <span class=\"math inline\">\\((0, 0)\\)</span> to <span class=\"math inline\">\\((0, h)\\)</span>, where <span class=\"math inline\">\\(\\mathbf{u} = U\\mathbf{\\hat{x}}\\)</span>.</li>\n<li>Boundary : the streamline <span class=\"math inline\">\\((0, h)\\)</span> to <span class=\"math inline\">\\((L, \\delta)\\)</span>, where <span class=\"math inline\">\\(\\mathbf{u}\\cdot \\mathbf{n} = 0\\)</span>.</li>\n<li>Boundary : the segment <span class=\"math inline\">\\((L, \\delta)\\)</span> to <span class=\"math inline\">\\((L, 0)\\)</span>, where $ = u(x, y) + v(x, y)$.</li>\n<li>Boundary : the plate surface and streamline <span class=\"math inline\">\\((L, 0)\\)</span> to <span class=\"math inline\">\\((0, 0)\\)</span>, where <span class=\"math inline\">\\(u = 0\\)</span>.</li>\n</ul>\n<p><img src=\"Boundary layer control volume.png\" alt=\"Sketch of a developing boundary layer on a flat plate. The control volume used is delimited by the boundaries labeled , ,  and .\" style=\"zoom:30%;\" /></p>\n<h3 id=\"viscous-displacement\">5.1 Viscous displacement</h3>\n<h4 id=\"physical-origin\">5.1.1 Physical origin</h4>\n<p>The viscous displacement determines the upstream streamlines parallel to the wall to move away from the wall i.e. boundary  to tilt upward. It can be explained by the 2D compressible continuity equation: <span class=\"math display\">\\[\n\\partial_x u+\\partial_y v=0\n\\]</span> Near the boundary , the no-slip condition gives <span class=\"math inline\">\\(\\partial_xu&lt;0\\)</span>, to compensate for it, <span class=\"math inline\">\\(\\partial_yv&gt;0\\)</span>, and the consequence of this is the viscous displacement.</p>\n<h4 id=\"displacement-thickness\">5.1.2 Displacement thickness</h4>\n<p><img src=\"displacement thickness.png\" alt=\"Actual viscous boundary layer vs analogy with an inviscid flow displaying the same flow rate. The wall-normal delay * necessary to obtain the same flow rate is called displacement thickness.\" style=\"zoom:30%;\" /></p>\n<p>The quantity <span class=\"math inline\">\\(\\delta^*\\)</span> is called <strong>displacement thickness</strong> and represents the distance by which the wall would have to be moved in the wall normal direction to <strong>obtain the same flow rate</strong> in an inviscid flow. i.e. the additional blockage/deflection due to viscosity.</p>\n<p>By definition, it is easy to conclude that <span class=\"math inline\">\\(\\delta = \\delta^*+h\\)</span>. And by mass conservation between the inlet and the outlet, the displacement thickness can be described: <span class=\"math display\">\\[\n\\begin{aligned}\n\\rho\\int_1(\\mathbf{u}\\cdot\\mathbf{n})ds&amp;+\\rho\\int_3(\\mathbf{u}\\cdot\\mathbf{n})ds =0 \\\\\n\\int^{\\delta-\\delta^*}_0(-U&amp;)dy+\\int^\\delta_0udy=0 \\\\\nUh&amp;= \\int^\\delta_0udy \\\\\n\\end{aligned}\n\\]</span> Substitute <span class=\"math inline\">\\(h\\)</span> with <span class=\"math inline\">\\(\\delta-\\delta^*\\)</span> : <span class=\"math display\">\\[\n\\begin{aligned}\nU(\\delta-\\delta^*) &amp;= \\int^\\delta_0udy \\\\\nU(\\delta-\\delta^*) &amp;= \\int^\\delta_0\\left(u+U-U\\right)dy \\\\\nU(\\delta-\\delta^*) &amp;= U\\delta+\\int^\\delta_0\\left(u-U\\right)dy \\\\\n\\Rightarrow \\quad\\delta^* = \\int_0^\\delta&amp;\\left(1-\\frac uU\\right)dy\\\\\n\\Rightarrow \\quad\\color{purple}{\\frac{\\delta^*}{\\delta} = \\int_0^1}&amp;\\color{purple}{\\left(1-\\frac uU\\right)d\\eta}, \\quad\\mathrm{where~}\\eta=\\frac{y}{\\delta}\\\\\n\\end{aligned}\n\\]</span></p>\n<h3 id=\"friction-drag\">5.2 Friction drag</h3>\n<h4 id=\"drag-as-a-boundary-layer-effect\">5.2.1 Drag as a boundary layer effect</h4>\n<p>Assume a constant pressure throughout the domain, and a steady flow. The conservation of momentum in <span class=\"math inline\">\\(\\mathbf{\\hat{x}}\\)</span> writes: <span class=\"math display\">\\[\n\\begin{aligned}\n\\rho\\int_1u(0,y)(\\mathbf{u}\\cdot\\mathbf{n})ds + \n\\underbrace{\\rho\\int_2u(x,y)(\\mathbf{u}\\cdot\\mathbf{n})ds+}_{\\mathrm{streamline:~}\\mathbf{u}\\cdot\\mathbf{n}=0} ...\\\\\n\\rho\\int_3u(L,y)(\\mathbf{u}\\cdot\\mathbf{n})ds+\n\\underbrace{\\rho\\int_4u(x,0)(\\mathbf{u}\\cdot\\mathbf{n})ds}_{\\mathrm{wall:~}u=0}=\n\\Sigma F_x = -D\\mathbf{\\hat{x}}\n\\end{aligned}\n\\]</span> The equation simplifies into: <span class=\"math display\">\\[\n\\begin{aligned}\n\\rho\\int_0^hU(-U)dy + \\rho\\int_0^\\delta u^2dy=-D \\\\\n\\Rightarrow\\qquad D = \\rho hU^2 -\\rho\\int_0^\\delta u^2dy\n\\end{aligned}\n\\]</span> Combine with the <strong>mass conservation</strong> result <span class=\"math inline\">\\(Uh= \\int^\\delta_0udy\\)</span>: <span class=\"math display\">\\[\n\\begin{aligned}\nD &amp;= \\rho \\int_0^\\delta Uudy-\\rho\\int_0^\\delta u^2dy \\\\\n\\color{purple}{D }&amp;\\color{purple}{= \\rho \\int_0^\\delta \\frac{u}{U}\\left(1-\\frac{u}{U}\\right) dy}\n\\end{aligned}\n\\]</span></p>\n<h4 id=\"momentum-thickness\">5.2.2 Momentum thickness</h4>\n<p>The quantity <span class=\"math inline\">\\(\\theta\\)</span> is called <strong>momentum thickness</strong> and represents the distance by which the wall would have to be moved in the wall normal direction to <strong>obtain the same momentum</strong> in an inviscid flow. <span class=\"math display\">\\[\n\\color{purple}\\frac{\\theta}{\\delta} = \\frac{D}{\\rho U^2\\delta} = \\int_0^1 \\frac{u}{U}\\left(1-\\frac{u}{U}\\right) d\\eta, \\quad \\mathrm{where~}\\eta = \\frac{y}{\\delta}\n\\]</span> i.e. the <strong>momentum deficit</strong> can be determined by: <span class=\"math display\">\\[\n\\rho U^2\\theta = \\rho \\int_0^\\delta \\frac{u}{U}\\left(1-\\frac{u}{U}\\right)dy\n\\]</span> <div class=\"note note-info\">\n            <p>There is another <strong>Energy thickness</strong> writes: <span class=\"math display\">\\[\\color{purple}\\frac{\\theta&#39;}{\\delta} = \\int_0^1 \\frac{u}{U}\\left(1-\\frac{u^2}{U^2}\\right) d\\eta, \\quad \\mathrm{where~}\\eta = \\frac{y}{\\delta}\\]</span></p>\n          </div></p>\n<p>We can then define the <strong>shape factor</strong>: <span class=\"math display\">\\[\nH = \\frac{\\delta^*}{\\theta}\n\\]</span> <div class=\"note note-info\">\n            <p>Shape factor indicates the wall-normal distance on which the fluid is deflected from the plate compared to that on which gradients of streamwise velocities are felt.A large shape factor indicates a flow near separation.</p>\n          </div></p>\n<h4 id=\"relation-to-wall-shear-stress\">5.2.3 Relation to wall shear stress</h4>\n<p>The drag force is the integration of wall shear stress <span class=\"math inline\">\\(\\tau_w\\)</span> along the plate: <span class=\"math display\">\\[\nD = \\int_0^L\\tau_wdx\n\\]</span> Or in differential form: <span class=\"math display\">\\[\n\\tau_w = \\partial_xD\n\\]</span> Differentiate the momentum thickness representation: <span class=\"math display\">\\[\n\\partial_x\\theta = \\frac{\\partial_xD}{\\rho U^2}=\\frac{\\tau_w}{\\rho U^2}\n\\]</span> As a result, the wall shear: <span class=\"math display\">\\[\n\\color{purple}\\tau_w = \\rho U^2\\partial_x\\theta\n\\]</span></p>\n<h3 id=\"velocity-profile-approximations\">5.3 Velocity profile approximations</h3>\n<p>For <em>laminar</em> boundary layers, Von Krmn assumed that the velocity profile (<span class=\"math inline\">\\(\\frac{u}{U}\\)</span>) within the boundary layer had a parabolic shape:</p>\n<p>Given: <span class=\"math display\">\\[\n\\eta = \\frac{y}{\\delta(x)}\n\\]</span> The velocity profile (<span class=\"math inline\">\\(\\frac{u}{U}\\)</span>) writes: <span class=\"math display\">\\[\n\\frac{u}{U}\\approx 2\\eta -\\eta^2, \\qquad 0\\leq \\eta\\leq 1\n\\]</span> For <em>turbulent</em> boundary layers, Prandtl highlighted a one-seventh power velocity profile: <span class=\"math display\">\\[\n\\frac{u}{U}\\approx\\eta^\\frac{1}{7}, \\qquad 0\\leq \\eta\\leq 1\n\\]</span> These first order approximations are very close to the reality as shown below:</p>\n<p><img src=\"velocity profiles.png\" alt=\"Comparison of velocity profiles u/U in the boundary layer y/ < 1 between the Von Krmn and Prandtls approximations and the actual laminar and turbulent flows. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" /></p>\n<h3 id=\"laminar-results-von-krmn-results\">5.4 Laminar results (Von Krmn results)</h3>\n<p>Based on Von Krmn's approximation, <span class=\"math inline\">\\(\\frac{u}{U}\\approx \\frac{2y}{\\delta} -\\left(\\frac{y}{\\delta}\\right)^2\\)</span>. It is easy to get:</p>\n<ul>\n<li><p>Boundary thickness:</p>\n<p>The key point is that the wall shear stress can be expressed in two ways,</p>\n<ul>\n<li><p>by definition: <span class=\"math display\">\\[\n\\begin{aligned}\n\\tau_w &amp;= \\mu \\partial_yu|_{y=0} \\\\\n\\Rightarrow \\quad \\tau_{w} &amp;\\approx \\mu \\partial_{y}\\left.\\left(\\frac{2 y}{\\delta}-\\frac{y^{2}}{\\delta^{2}}\\right)\\right|_{y=0} \\\\\n\\Rightarrow \\quad \\tau_{w} &amp;\\approx \\mu \\frac{2 U}{\\delta}\\\\\n\\end{aligned}\n\\]</span></p></li>\n<li><p>and by the derivative of drag: <span class=\"math display\">\\[\n\\begin{aligned}\n\\tau_w &amp;= \\rho U^2\\partial_x\\theta \\\\\n\\Rightarrow \\quad \\tau_{w} &amp;\\approx \\rho U^2\\partial_x\\left[\\int_{0}^{\\delta}\\left(\\frac{2 y}{\\delta}-\\frac{y^{2}}{\\delta^{2}}\\right)\\left(1-\\frac{2 y}{\\delta}+\\frac{y^{2}}{\\delta^{2}}\\right) d y \\right] \\\\\n\\Rightarrow \\quad \\tau_{w} &amp;\\approx \\frac{2\\rho U^2}{15}\\partial_x\\delta\n\\end{aligned}\n\\]</span></p></li>\n</ul>\n<p>As a result, connect these expressions: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\mu \\frac{2 U}{\\delta} \\approx \\frac{2\\rho U^2}{15}\\partial_x\\delta \\\\\n\\Rightarrow \\quad &amp;\\int_0^x dx \\approx \\int_0^\\delta \\frac{\\rho U}{15}\\delta d\\delta \\\\\n\\Rightarrow \\quad &amp;x \\approx \\frac{\\rho U \\delta^2}{30\\mu} \\\\\n\\Rightarrow \\quad &amp; \\left(\\frac{\\delta}{x}\\right)^2 \\approx \\frac{30\\mu}{\\rho U x} \\\\\n\\Rightarrow \\quad &amp; \\color{purple}{\\frac{\\delta}{x}  \\approx 5.5 Re_x^{-1/2}} \\\\\n\\end{aligned}\n\\]</span> where <span class=\"math inline\">\\(\\color{purple}Re_x= Ux/\\nu\\)</span> as the <strong>streamwise Reynold</strong>.</p></li>\n<li><p>the displacement thickness: <span class=\"math display\">\\[\n\\begin{aligned}\n\\delta^* &amp;= \\int_0^\\delta\\left(1-\\frac{u}{U}\\right)dy \\\\\n&amp;\\approx \\int_0^\\delta\\left(1-\\frac{2y}{\\delta}+\\left(\\frac{y}{\\delta}\\right)^2\\right)dy \\\\\n\\Rightarrow \\quad \\delta^*&amp;\\approx \\frac{1}{3}\\delta\\\\\n\\end{aligned}\n\\]</span> with the boundary thickness expression: <span class=\"math display\">\\[\n\\begin{aligned}\n\\color{purple}\\frac{\\delta^*}{x}\\approx 1.83 Re_x^{-1/2}\n\\end{aligned}\n\\]</span></p></li>\n<li><p>the momentum displacement and the factor of friction: <span class=\"math display\">\\[\n\\begin{aligned}\n\\theta &amp;= \\int_{0}^{\\delta}\\left(\\frac{2 y}{\\delta}-\\frac{y^{2}}{\\delta^{2}}\\right)\\left(1-\\frac{2 y}{\\delta}+\\frac{y^{2}}{\\delta^{2}}\\right) d y \\\\\n\\Rightarrow \\quad &amp; \\theta \\approx \\frac{2}{15}\\delta \\\\\n\\Rightarrow \\quad &amp; \\color{purple}{\\frac{\\theta}{x}  \\approx 0.73 Re_x^{-1/2}} \n\\end{aligned}\n\\]</span> The factor of friction has the same order with the momentum displacement, as <span class=\"math display\">\\[\n\\color{purple}{C_f   \\approx 0.73 Re_x^{-1/2}}\n\\]</span></p></li>\n<li><p>the shape factor: <span class=\"math display\">\\[\n\\color{purple}\nH = \\frac{\\delta^*}{\\theta} \\approx 2.5\n\\]</span></p></li>\n</ul>\n<h3 id=\"laminar-results-blasius-results\">5.5 Laminar results (Blasius results)</h3>\n<p>Reference to <a href=\"https://web.mit.edu/fluids-modules/www/highspeed_flows/ver2/bl_Chap2.pdf\">MIT's note</a>, <a href=\"https://youtu.be/Lw6aQJGD3FU\">MECH 346  Heat Transfer's Youtube channel</a></p>\n<h4 id=\"governing-equations\">5.5.1 Governing equations</h4>\n<p>Conditions:</p>\n<ul>\n<li><p>2D</p></li>\n<li><p>Steady</p></li>\n<li><p>Incompressible</p></li>\n<li><p>Neglect viscous dissipation, gravity and thermal dissipation</p></li>\n<li><p>Plus the <strong>thin layer assumption (<span class=\"math inline\">\\(L\\gg\\delta\\)</span>)</strong> for boundary layer (Obtained by non-dimensional scaling analysis, Full deriving on <a href=\"#a.1-governing-equation-of-boundary-layers\">Appendix A.1</a>): <span class=\"math display\">\\[\n\\begin{aligned}\nu&amp;\\gg v \\\\\n\\frac{\\partial}{\\partial y}&amp;\\gg\\frac{\\partial}{\\partial x}\n\\end{aligned}\n\\]</span></p></li>\n</ul>\n<p>The mass and momentum conservation equations reduces to: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} &amp;= 0 \\\\\nu\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y}&amp;=-\\frac{1}{\\rho}\\frac{\\partial p}{\\partial x}+\n\\nu\\left(\\overbrace{\\frac{\\partial^2u}{\\partial x^2}}^{\\mathrm{0}}+\\frac{\\partial^2u}{\\partial y^2}\\right) \\\\\nu\\frac{\\partial v}{\\partial x}+v\\frac{\\partial v}{\\partial y}&amp;=\n\\underbrace{-\\frac{1}{\\rho}\\frac{\\partial p}{\\partial y}}_{\\text{principle order}}+\\nu\\left(\\frac{\\partial^2v}{\\partial x^2}+\\frac{\\partial^2v}{\\partial y^2}\\right)\n\\end{aligned}\n\\]</span> as a result: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} &amp;= 0 \\\\\nu\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y}&amp;=-\\frac{1}{\\rho}\\frac{\\partial p}{\\partial x}+\\nu\\frac{\\partial^2u}{\\partial y^2} \\\\\n\\frac{1}{\\rho}\\frac{\\partial p}{\\partial y}&amp;=0\n\\end{aligned}\n\\]</span></p>\n<p>For the flat plate boundary layer, it is easy to get <span class=\"math inline\">\\(\\frac{\\partial p}{\\partial x}=0\\)</span> because the free stream pressure gradient in the <span class=\"math inline\">\\(x\\)</span> direction is <span class=\"math inline\">\\(0\\)</span>, so as in the boundary layer given the <span class=\"math inline\">\\(\\frac{\\partial p}{\\partial y}=0\\)</span>. As a consequence there is no pressure gradient within the flat plate boundary layer. The final governing equation writes:</p>\n<p><span class=\"math display\">\\[\n\\color{purple}\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} &amp;= 0 \\\\\nu\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y}&amp;=\\nu\\frac{\\partial^2u}{\\partial y^2} \\\\\n\\end{aligned}\n\\]</span></p>\n<p>And the boundary conditions are:</p>\n<p><span class=\"math display\">\\[\n\\color{purple}\n\\begin{aligned}\nu=v = 0\\quad&amp;\\mathrm{at}\\quad y = 0\\\\\nu = U\\quad&amp;\\mathrm{at}\\quad x = 0 \\\\\nu \\rightarrow U\\quad&amp;\\mathrm{as}\\quad y \\rightarrow \\infty \\\\\n\\end{aligned}\n\\]</span></p>\n<div class=\"note note-info\">\n            <p>These conditions demand an <em>infinite gradient</em> in speed at the leading edge <span class=\"math inline\">\\(x = y = 0\\)</span>, which implies a singularity in the mathematical solution there. The solution given by the boundary layer approximation is not valid at the leading edge.</p>\n          </div>\n<p>Define a stream function so that the continuity equation will be automatically included: <span class=\"math display\">\\[\n\\begin{aligned}\n\\psi &amp;= \\int u dy \\\\\nu = \\frac{\\partial\\psi}{\\partial y}&amp;, \\quad v = -\\frac{\\partial \\psi}{\\partial x}\n\\end{aligned}\n\\]</span> Subscribe into the momentum equation to get an single variable equation: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial\\psi}{\\partial y} \\frac{\\partial^2\\psi}{\\partial x \\partial y}- \\frac{\\partial\\psi}{\\partial x} \\frac{\\partial^2\\psi}{\\partial y^2} = \\nu\\frac{\\partial^3\\psi}{\\partial y^3}\n\\]</span> with boundary conditions: <span class=\"math display\">\\[\n\\color{purple}\n\\begin{aligned}\n\\frac{\\partial\\psi}{\\partial y}=\\frac{\\partial\\psi}{\\partial x} = 0\\quad&amp;\\mathrm{at}\\quad y = 0\\\\\n\\frac{\\partial\\psi}{\\partial y} = U\\quad&amp;\\mathrm{at}\\quad x = 0 \\\\\n\\frac{\\partial\\psi}{\\partial y} \\rightarrow U\\quad&amp;\\mathrm{as}\\quad y \\rightarrow \\infty \\\\\n\\end{aligned}\n\\]</span> Through a coordinate transformation(<a href=\"https://en.wikipedia.org/wiki/Self-similar_solution\">similarity solution</a>), this PDE can be transferred into an ODE and thus be solved easily.</p>\n<h4 id=\"similarity-solution\">5.5.2 Similarity solution</h4>\n<blockquote>\n<p>In the study of partial differential equations, particularly in fluid dynamics, a <strong>self-similar solution</strong> is a form of solution which is similar to itself if the independent and dependent variables are appropriately scaled.</p>\n</blockquote>\n<p>In contrast to the most frequently used method of \"separation variables\", the similarity solution involves combining the variables in a special way. Another example of using similarity to solve Heat diffusion equation lies on the <a href=\"#a.2-solving-the-heat-equation-using-similarity-solution\">Appendix A.2</a>.</p>\n<p>A self-similar equation doesn't change regardless how the variables scale. So assume a transformation: <span class=\"math display\">\\[\n\\begin{aligned}\ny = \\lambda^a\\bar{y}\\\\\nx = \\lambda^b\\bar{x}\\\\\n\\psi = \\lambda^c\\bar{\\psi}\\\\\n\\end{aligned}\n\\]</span> The resulting scaled function and writes: <span class=\"math display\">\\[\n\\begin{aligned}\n\\lambda^{3c-2a-b}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{y}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{x} \\partial \\bar{y}}- \n\\lambda^{3c-2a-b}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{x}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{y}^2} =\n\\lambda^{3c-3a}\\nu\\frac{\\partial^3\\bar{\\psi}}{\\partial \\bar{y}^3} \\\\\n\\Leftrightarrow\\quad\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{y}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{x} \\partial \\bar{y}}- \n\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{x}} \\frac{\\partial^2\\bar{\\psi}}{\\partial \\bar{y}^2} =\n\\lambda^{-3c-a+b}\\nu\\frac{\\partial^3\\bar{\\psi}}{\\partial \\bar{y}^3}\n\\end{aligned}\n\\]</span> And the scaled boundary conditions gives: <span class=\"math display\">\\[\n\\begin{aligned}\n\\lambda^{c-a}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{y}}=\\lambda^{c-b}\\frac{\\partial\\bar{\\psi}}{\\partial \\bar{x}} = 0\\quad&amp;\\mathrm{at}\\quad \\lambda^{a}\\bar{y} = 0\\\\\n\\end{aligned}\n\\]</span> As a result, all the powers should be 0: <span class=\"math display\">\\[\n\\left.\\begin{array}{c}\n\\left.\\begin{array}{c}\n-c-a+b=0 \\\\\nc-a=0\n\\end{array}\\right\\} \\quad b=a / 2 \\\\\nc-b=0 \\qquad \\qquad  \\quad\n\\end{array}\\quad\\right\\} \\quad c=a / 2\n\\]</span> Here I need to put my derivation here:</p>\n<blockquote>\n<p>Similar to <a href=\"#a.2-solving-the-heat-equation-using-similarity-solution\">Appendix A.2</a>, we can construct an expression of <span class=\"math inline\">\\(\\psi\\)</span> as: <span class=\"math display\">\\[\n\\psi(x,y)= x^{1/2}f^\\dagger(\\eta^\\dagger), \\quad \\eta^\\dagger = yx^{-1/2}\n\\]</span> <div class=\"note note-danger\">\n            <blockquote><p><strong>Personal comment:</strong> I still don't know how to construct this kinda thing or why it work. The formula in Appendix gives me some idea but following it I got <span class=\"math inline\">\\(\\psi(x,y)= x^{1}f^\\dagger(\\eta^\\dagger)\\)</span>, <span class=\"math inline\">\\(\\eta^\\dagger = yx^{-1/2}\\)</span> instead...</p></blockquote>\n          </div></p>\n<p>Substitute the expression of <span class=\"math inline\">\\(\\psi\\)</span> into the equation with <span class=\"math inline\">\\(f^{\\dagger&#39;} = \\partial_{\\eta^{\\dagger}}f^{\\dagger}\\)</span>: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial\\psi}{\\partial y} &amp;= f^{\\dagger&#39;} \\\\\n\\frac{\\partial^2\\psi}{\\partial y^2} &amp;= x^{-1/2}f^{\\dagger&#39;&#39;} \\\\\n\\frac{\\partial^3\\psi}{\\partial y^3}&amp;= x^{-1}f^{\\dagger&#39;&#39;&#39;}\\\\\n\\frac{\\partial\\psi}{\\partial x} &amp;= \\frac{1}{2}x^{-1/2}f^{\\dagger}-\\frac{1}{2}x^{-1}f^{\\dagger&#39;}y \\\\\n&amp;= \\frac{1}{2}x^{-1/2}(f^{\\dagger} -\\eta^{\\dagger} f^{\\dagger&#39;}) \\\\\n\\frac{\\partial^2\\psi}{\\partial x \\partial y} &amp;= \\frac{1}{2}x^{-1/2}(x^{-1/2}f^{\\dagger&#39;} -x^{-1/2}\\eta^{\\dagger} f^{\\dagger&#39;&#39;} - x^{-1/2}f^{\\dagger&#39;}) \\\\\n&amp;=-\\frac{1}{2}x^{-1}\\eta^{\\dagger} f^{\\dagger&#39;&#39;}\\\\ \n\\frac{\\partial\\psi}{\\partial y}\\frac{\\partial^2\\psi}{\\partial x \\partial y} &amp;= f^{\\dagger&#39;}\\left[-\\frac{1}{2}x^{-1}\\eta^{\\dagger} f^{\\dagger&#39;&#39;}\\right] \\\\\n&amp;= -\\frac{1}{2}x^{-1} \\eta^{\\dagger}f^{\\dagger&#39;}f^{\\dagger&#39;&#39;} \\\\\n-\\frac{\\partial\\psi}{\\partial x}\\frac{\\partial^2\\psi}{\\partial y^2} &amp;=\\frac{1}{2}x^{-1/2}(f^{\\dagger} -\\eta^{\\dagger} f^{\\dagger&#39;})\\left[x^{-1/2}f^{\\dagger&#39;&#39;}\\right] \\\\\n&amp;= \\frac{1}{2}x^{-1}(f^{\\dagger} +\\eta^{\\dagger} f^{\\dagger&#39;})f^{\\dagger&#39;&#39;}\\\\\n\\end{aligned}\n\\]</span> As a result: <span class=\"math display\">\\[\n\\begin{aligned}\n-\\frac{1}{2}x^{-1}\\eta^{\\dagger} f^{\\dagger&#39;}f^{\\dagger&#39;&#39;}+ \\frac{1}{2}x^{-1}(f^{\\dagger} &amp;+\\eta^{\\dagger} f^{\\dagger&#39;})f^{\\dagger&#39;&#39;} = \\nu x^{-1}f^{\\dagger&#39;&#39;&#39;}\\\\\n\\Leftrightarrow \\qquad \\nu f^{\\dagger&#39;&#39;&#39;} - &amp;\\frac{1}{2} f^{\\dagger}f^{\\dagger&#39;&#39;} = 0\n\\end{aligned}\n\\]</span></p>\n</blockquote>\n<p>Ok.. above is what I derived, it's still an ODE but normally we want a cleaner result.</p>\n<p>So Blasius construct <span class=\"math inline\">\\(\\psi\\)</span> and <span class=\"math inline\">\\(\\eta\\)</span> with physical meaningful non-dimensional parameters to get (reference to <a href=\"https://youtu.be/Lw6aQJGD3FU\">MECH 346  Heat Transfer's Youtube channel</a>): <span class=\"math display\">\\[\n\\color{purple}\n\\psi(x,y)= (\\nu Ux)^{1/2}f(\\eta), \\quad \\eta = \\left(\\frac{U}{\\nu x}\\right)^{1/2}y\n\\]</span> So that: <span class=\"math display\">\\[\n\\begin{aligned}\n\\eta = \\sqrt{\\frac{U}{\\nu x}}y,&amp; \\quad\\mathrm{dimensionless~wall~normal~coordinate}\\\\\nf = \\frac{\\psi}{\\sqrt{\\nu Ux}},&amp; \\quad\\mathrm{dimensionless~stream~function}\\\\\nf&#39; = \\frac{u}{U},&amp; \\quad\\mathrm{dimensionless~velocity~profile} \\\\\nf&#39;&#39; = \\frac{\\sqrt{\\nu Ux}}{U^2}\\partial_yu, &amp;\\quad\\mathrm{related~to~shear~stress} \\\\\n\\end{aligned}\n\\]</span> And terms of the governing equation becomes: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial\\psi}{\\partial y} &amp;= Uf&#39; \\\\\n\\frac{\\partial^2\\psi}{\\partial y^2} &amp;= {(U\\nu x)}^{-1/2}f&#39;&#39; \\\\\n\\frac{\\partial^3\\psi}{\\partial y^3}&amp;= U^2x^{-1}f&#39;&#39;&#39;\\\\\n\\frac{\\partial\\psi}{\\partial x} &amp;= \\frac{1}{2}(\\nu U/x)^{1/2}(f -\\eta f&#39;)\\\\\n\\frac{\\partial^2\\psi}{\\partial x \\partial y} &amp;=-\\frac{1}{2}Ux^{-1}\\eta f&#39;&#39;\n\\\\ \n\\frac{\\partial\\psi}{\\partial y}\\frac{\\partial^2\\psi}{\\partial x \\partial y} &amp;= -\\frac{1}{2}U^2x^{-1}\\eta f&#39;f&#39;&#39;\\\\\n-\\frac{\\partial\\psi}{\\partial x}\\frac{\\partial^2\\psi}{\\partial y^2}\n&amp;= \\frac{1}{2}U^2x^{-1}(f +\\eta f&#39;)f&#39;&#39;\\\\\n\\end{aligned}\n\\]</span> And the ODE turns out to be: <span class=\"math display\">\\[\n\\color{purple}\n2f&#39;&#39;&#39; +ff&#39;&#39; = 0\n\\]</span> Resulting boundary condition is: <span class=\"math display\">\\[\n\\color{purple}\n\\begin{aligned}\nf&#39; = 0\\quad &amp;at\\quad \\eta=0     \\quad\\mathrm{(no~slip)}\\\\\nf = 0\\quad &amp;at\\quad \\eta=0      \\quad\\mathrm{(impenetrability)} \\\\\nf&#39; = 1\\quad &amp;at\\quad \\eta\\rightarrow\\infty \\quad(u = U\\mathrm{~free stream}) \\\\\nf&#39;&#39; = 0\\quad &amp;at\\quad \\eta\\rightarrow\\infty \\quad(\\partial_yu=0,\\mathrm{unnecessary}) \\\\\n\\end{aligned}\n\\]</span></p>\n<h4 id=\"solving-the-similarity-solution\">5.5.3 Solving the similarity solution</h4>\n<p>Split the 3-order ODE into a set of 3 first order ODEs: <span class=\"math display\">\\[\n\\left\\{\\begin{array}{l}\n    f_p  = f&#39; \\\\\n    f_{pp} = f_p&#39; \\\\\n    2f&#39;_{pp} +ff_{pp}  = 0\n\\end{array}\\right.\n\\]</span> with boundary conditions: <span class=\"math display\">\\[\n\\begin{aligned}\nf_p = 0\\quad &amp;at\\quad \\eta=0    \\\\\nf = 0\\quad &amp;at\\quad \\eta=0      \\\\\nf_p = 1\\quad &amp;at\\quad \\eta\\rightarrow\\infty \\\\\nf_{pp} = 0\\quad &amp;at\\quad \\eta\\rightarrow\\infty,\\mathrm{unnecessary} \\\\\n\\end{aligned}\n\\]</span> The third boundary condition has no closed form solution, so we need to solve it numerically.</p>\n<ol type=\"1\">\n<li><p>One method of doing it is guessing another initial condition <span class=\"math inline\">\\(f_{pp} = ?\\)</span> at <span class=\"math inline\">\\(\\eta=0\\)</span>, integrating the equation from <span class=\"math inline\">\\(\\eta=0\\)</span> with Runge-Kutta method to meet the 3rd boundary condition i.e. <strong>transfer the boundary condition to the initial condition</strong>.</p>\n<div class=\"note note-info\">\n            <p>RungeKutta method is an effective and widely used numerical method for solving the initial-value problems of differential equations. It integrated the function discretely from zero in small steps (<span class=\"math inline\">\\(h\\)</span>) in an order of 4 (more on <a href=\"https://youtu.be/kUcc8vAgoQ0\">LearnChemE's Youtube</a>). <span class=\"math display\">\\[\\left\\{\\begin{array}{l}y_{n+1}=y_{n}+\\frac{1}{6}\\left(K_{1}+2 K_{2}+2 K_{3}+K_{4}\\right) \\\\K_{1}=h f\\left(x_{n}, y_{n}\\right) \\\\K_{2}=h f\\left(x_{n}+\\frac{1}{2} h, y_{n}+\\frac{1}{2} K_{1}\\right) \\\\K_{3}=h f\\left(x_{n}+\\frac{1}{2} h, y_{n}+\\frac{1}{2} K_{2}\\right) \\\\K_{4}=h f\\left(x_{n}+h, y_{n}+K_{3}\\right)\\end{array}\\right.\\]</span></p>\n          </div>\n<p>It turns out it meets the 3<sup>rd</sup> boundary condition when: <span class=\"math display\">\\[\nf_{pp} = 0.332~at~ \\eta=0\n\\]</span> And the function looks like below:</p>\n<p><img src=\"Similarity solution.png\" alt=\"Numerical solution to the similarity solution, the 4 boundary conditions are fitted. After MECH 346  Heat Transfer's Youtube channel(https://youtu.be/Lw6aQJGD3FU)\" style=\"zoom:40%;\" /></p>\n<p>From the solution, we can see the stream function <span class=\"math inline\">\\(f\\)</span> first increases with a decreasing slop then approaches to a linear increase line. While the velocity profile <span class=\"math inline\">\\(f&#39;\\)</span> and shear stress <span class=\"math inline\">\\(f&#39;&#39;\\)</span> approach the 1 and 0 at the free stream respectively,</p></li>\n<li><p>Another method is solve <span class=\"math inline\">\\(f_{pp}~at~ \\eta=0\\)</span> directly numerically. And the solution is: <span class=\"math display\">\\[\nf_{pp} = 0.332096~at~ \\eta=0\n\\]</span> More on <a href=\"https://youtu.be/Lw6aQJGD3FU\">MECH 346  Heat Transfer's Youtube channel</a> and <a href=\"https://web.mit.edu/fluids-modules/www/highspeed_flows/ver2/bl_Chap2.pdf\">MIT's note</a>.</p></li>\n</ol>\n<h4 id=\"blasius-results\">5.5.4 Blasius results</h4>\n<p>As a consequence, similar to what we do based on the <a href=\"#laminar-results-von-k%C3%A1rm%C3%A1n-results\">Von Krmn results result</a>, recall the definition of the boundary layer: <span class=\"math display\">\\[\nf_p = \\frac{u|_\\delta}{U} =  0.99\n\\]</span> It is easy to get</p>\n<ul>\n<li><p>the boundary layer thickness: <span class=\"math display\">\\[\n\\begin{aligned}\n\\eta_1&amp;=\\sqrt{\\frac{U}{\\nu x}}\\delta\\approx5.0 \\\\\n\\Rightarrow \\delta &amp;\\approx 5.0 \\sqrt{\\frac{\\nu x}{U}} \\\\\n\\Rightarrow \\frac{\\delta}{x} &amp;\\approx 5.0 \\sqrt{\\frac{\\nu}{Ux}} \\\\\n\\color{purple}{\\frac{\\delta}{x} }&amp;\\color{purple}{\\approx 5 Re_x^{-1/2}}\\\\\n\\end{aligned}\n\\]</span> with <span class=\"math inline\">\\(\\color{purple}Re_x= Ux/\\nu\\)</span> as the <strong>streamwise Reynolds number</strong>.</p></li>\n<li><p>the thickness displacement: <span class=\"math display\">\\[\n\\begin{aligned}\n\\delta^* &amp;= \\int_0^\\delta\\left(1-\\frac{u}{U}\\right)dy \\\\\n&amp;= \\sqrt{\\frac{\\nu x}{U}}\\int_0^{\\eta_1\\approx5.0 }\\left(1-f&#39;\\right)d\\eta \\\\\n&amp;= \\sqrt{\\frac{\\nu x}{U}}\\left[\\eta_1 - f_1\\right]\\\\\n\\end{aligned}\n\\]</span> with <span class=\"math inline\">\\(f_1 \\approx 3.283\\)</span>: <span class=\"math display\">\\[\n\\begin{aligned}\n\\color{purple}\\frac{\\delta^*}{x}\\approx 1.721 Re_x^{-1/2}\n\\end{aligned}\n\\]</span></p></li>\n<li><p>the momentum displacement and the factor of friction: <span class=\"math display\">\\[\n\\tau_w = \\rho\\nu\\frac{\\partial u}{\\partial y}|_{y=0} = \\rho\\nu U\\sqrt{\\frac{U}{\\nu x}}f&#39;&#39;(0)\n\\]</span> with <span class=\"math inline\">\\(f&#39;&#39;(0) \\approx 0.332\\)</span>: <span class=\"math display\">\\[\nC_f = \\frac{\\tau_w}{1/2\\rho U^2} \\approx 0.664Re_x^{-1/2}\n\\]</span></p>\n<p><span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\theta}{x} \\approx 0.664Re_x^{-1/2}\n\\]</span></p></li>\n<li><p>the shape factor: <span class=\"math display\">\\[\n\\color{purple}\nH = \\frac{\\delta^*}{\\theta} \\approx 2.59\n\\]</span></p></li>\n</ul>\n<h3 id=\"validity-of-the-laminar-results\">5.6 Validity of the laminar results</h3>\n<p>The above results are based on the hypothesis that the boundary layer is thin enough so that the coupling with the outer flow is negligible. This theory breaks down as soon as <span class=\"math inline\">\\(\\frac{\\delta}{x}=\\mathcal{O}(1)\\)</span> i.e. <span class=\"math inline\">\\(\\frac{\\delta}{x}&lt;0.1\\)</span>. As a result, based on the Blasius result, the upper limit of the streamwise Reynolds number depends on transition to turbulence writes <span class=\"math display\">\\[\n5Re_x^{-1/2}&lt;0.1\\\\\n\\Rightarrow Re_{x,min} &gt; 2500\n\\]</span> For smaller <span class=\"math inline\">\\(Re_x\\)</span>, the interaction with the outer flow is important and leads to departures from these results.</p>\n<p>Besides, at a threshold Reynolds number, the boundary layer becomes <strong>turbulent</strong> and the results above do not hold. This critical value of the Reynolds number is <span class=\"math inline\">\\(Re_c\\approx 3  10^6\\)</span>. Usually, the surfaces are not smooth and transition occurs earlier, sometimes at Reynolds numbers as low as <span class=\"math inline\">\\(10^5\\)</span>.</p>\n<h3 id=\"comparison-of-the-results\">5.7 Comparison of the results</h3>\n<p>Similar to what we do based on the <a href=\"#laminar-results-von-k%C3%A1rm%C3%A1n-results\">Von Krmn results result</a>, based on the Prandtl one-seventh power law, the turbulence results can be derived easily, here is the table of all results:</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th>Results</th>\n<th><span class=\"math inline\">\\(\\delta/x\\)</span></th>\n<th><span class=\"math inline\">\\(\\delta^*/x\\)</span></th>\n<th><span class=\"math inline\">\\(H\\)</span></th>\n<th><span class=\"math inline\">\\(c_f\\)</span></th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>Blasius laminar</td>\n<td><span class=\"math inline\">\\(5.0Re_x^{-1/2}\\)</span></td>\n<td><span class=\"math inline\">\\(1.72Re_x^{-1/2}\\)</span></td>\n<td><span class=\"math inline\">\\(2.59\\)</span></td>\n<td><span class=\"math inline\">\\(0.664Re_x^{-1/2}\\)</span></td>\n</tr>\n<tr class=\"even\">\n<td>Integral laminar</td>\n<td><span class=\"math inline\">\\(5.5Re_x^{-1/2}\\)</span></td>\n<td><span class=\"math inline\">\\(1.83Re_x^{-1/2}\\)</span></td>\n<td><span class=\"math inline\">\\(2.5\\)</span></td>\n<td><span class=\"math inline\">\\(0.73Re_x^{-1/2}\\)</span></td>\n</tr>\n<tr class=\"odd\">\n<td>Error</td>\n<td><span class=\"math inline\">\\(10\\%\\)</span></td>\n<td><span class=\"math inline\">\\(6\\%\\)</span></td>\n<td><span class=\"math inline\">\\(3\\%\\)</span></td>\n<td><span class=\"math inline\">\\(10\\%\\)</span></td>\n</tr>\n<tr class=\"even\">\n<td>Integral turbulent</td>\n<td><span class=\"math inline\">\\(0.16Re_x^{-1/7}\\)</span></td>\n<td><span class=\"math inline\">\\(0.02Re_x^{-1/7}\\)</span></td>\n<td><span class=\"math inline\">\\(1.3\\)</span></td>\n<td><span class=\"math inline\">\\(0.027Re_x^{-1/7}\\)</span></td>\n</tr>\n</tbody>\n</table>\n<p>Several points:</p>\n<ul>\n<li>There is an error of less than 10% between integral and Blasius results.</li>\n<li>The boundary layer thickness <span class=\"math inline\">\\(\\delta\\)</span> grows like <span class=\"math inline\">\\(x^{6/7}\\)</span> for turbulent flows, which represents a faster growth than the <span class=\"math inline\">\\(x^{1/2}\\)</span> law for the laminar boundary layer.</li>\n<li>The viscous displacement thickness <span class=\"math inline\">\\(\\delta^*\\)</span> and the shape factor <span class=\"math inline\">\\(H=\\delta^*/\\theta\\)</span> for turbulent boundary layers is very small.</li>\n<li>The skin friction coefficient <span class=\"math inline\">\\(c_f\\)</span> is greater for turbulent boundary layers than for the laminar ones.</li>\n</ul>\n<h2 id=\"appendix\">Appendix</h2>\n<h3 id=\"a.1-governing-equation-of-boundary-layers\">A.1 Governing equation of boundary layers</h3>\n<h4 id=\"a.1.1-scalings\">A.1.1 Scalings</h4>\n<p>Started by scaling the spatial derivatives: <span class=\"math display\">\\[\n\\partial_x \\sim \\frac{1}{L} \\qquad \\partial_y \\sim \\frac{1}{\\delta}\n\\]</span> By the thin-layer condition: <span class=\"math inline\">\\(L\\gg\\delta\\)</span>, we can introduce a small parameter <span class=\"math inline\">\\(\\epsilon \\ll 1\\)</span> as: <span class=\"math display\">\\[\n\\frac{\\delta}{L} = \\epsilon\n\\]</span> As a result, introduce the stream function <span class=\"math inline\">\\(\\psi\\)</span> under the conditions of 2D and incompressibility. The proportion of the streamwise and normal streamwise velocities <span class=\"math inline\">\\(u, v\\)</span> can be expressed as: <span class=\"math display\">\\[\n\\frac{u}{v} = \\frac{\\partial_y\\psi}{-\\partial_x\\psi}\\sim\\frac{L}{\\delta}\n\\]</span> which gives: <span class=\"math display\">\\[\n\\Rightarrow \\quad v\\sim\\epsilon u\n\\]</span> implying that the <span class=\"math inline\">\\(v\\)</span> is much smaller than <span class=\"math inline\">\\(u\\)</span>.</p>\n<p>Then rescale the wall normal quantities according to the streamwise quantities: <span class=\"math display\">\\[\n\\begin{aligned}\nx^* &amp;= \\frac{x}{L} \\\\\ny^* &amp;= \\frac{y}{\\delta} = \\frac{y}{\\epsilon L}\\\\\nu^* &amp;= \\frac{u}{U} \\\\\nv^* &amp;= \\frac{v}{\\epsilon U} \\\\\np^* &amp;= \\frac{p}{\\rho U^2}\n\\end{aligned}\n\\]</span> <div class=\"note note-info\">\n            <p>In this case, <span class=\"math inline\">\\(p^*\\)</span> can be thought of as a mathematical function to ensure incompressibility of the scaled function.</p>\n          </div></p>\n<h4 id=\"a.1.2-asymptotic-derivation\">A.1.2 Asymptotic derivation</h4>\n<p>Substitute the scaled variables into the governing equations: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{U}{L} \\partial_{x^{*}} u^{*}+\\frac{\\epsilon U}{\\epsilon L} \\partial_{y^{*}} v^{*} &amp;= 0 \\\\\n\\frac{U^{2}}{L} u^{*} \\partial_{x^{*}} u^{*}+\\frac{U^{2}}{L} v^{*} \\partial_{y^{*}} u^{*}&amp;=-\\frac{ U^{2}}{L} \\partial_{x^{*}} p^{*}+\\nu\\left(\\frac{U}{L^{2}} \\partial_{x^{*}}^{2} u^{*}+\\frac{U}{\\epsilon^{2} L^{2}} \\partial_{y^{*}}^{2} u^{*}\\right) \\\\\n\\frac{\\epsilon U^{2}}{L} u^{*} \\partial_{x^{*}} v^{*}+\\frac{\\epsilon U^{2}}{L} v^{*} \\partial_{y^{*}} v^{*} &amp;=-\\frac{ U^{2}}{\\epsilon L} \\partial_{y^{*}} p^{*}+\\nu\\left(\\frac{\\epsilon U}{L^{2}} \\partial_{x^{*}}^{2} v^{*}+\\frac{U}{\\epsilon L^{2}} \\partial_{y^{*}}^{2} v^{*}\\right)\n\\end{aligned}\n\\]</span> Can be simplified into: <span class=\"math display\">\\[\n\\begin{aligned}\n\\partial_{x^{*}} u^{*}+\\partial_{y^{*}} v^{*} &amp;= 0 \\\\\nu^{*} \\partial_{x^{*}} u^{*}+v^{*} \\partial_{y^{*}} u^{*} &amp;=-\\partial_{x^{*}} p^{*}+\\frac{1}{Re_{L}} \\partial_{x^{*}}^{2} u^{*}+\\frac{1}{\\epsilon^{2} Re_{L}} \\partial_{y^{*}}^{2} u^{*} \\\\\nu^{*} \\partial_{x^{*}} v^{*}+v^{*} \\partial_{y^{*}} v^{*} &amp;=-\\frac{1}{\\epsilon^{2}} \\partial_{y^{*}} p^{*}+\\frac{1}{Re_{L}} \\partial_{x^{*}}^{2} v^{*}+\\frac{1}{\\epsilon^{2} Re_{L}} \\partial_{y^{*}}^{2} v^{*}\n\\end{aligned}\n\\]</span> where <span class=\"math inline\">\\(Re_L = UL/\\nu\\)</span></p>\n<p>To keep a balance between the advection(LHS) and diffusion (RHS), impose: <span class=\"math display\">\\[\n\\epsilon^2Re_L=1 \\\\\n\\Rightarrow \\epsilon = \\frac{\\delta}{L}=Re_L^{-1/2}\n\\]</span> As a result, the leading order of the system is: <span class=\"math display\">\\[\n\\begin{aligned}\n\\partial_{x^{*}} u^{*}+\\partial_{y^{*}} v^{*} &amp;= 0 \\\\\nu^{*} \\partial_{x^{*}} u^{*}+v^{*} \\partial_{y^{*}} u^{*} &amp;=-\\partial_{x^{*}} p^{*}+\\partial_{y^{*}}^{2} u^{*} \\\\\n0&amp;=\\partial_{y^{*}} p^{*}\n\\end{aligned}\n\\]</span></p>\n<h3 id=\"a.2-solving-the-heat-equation-using-similarity-solution\">A.2 Solving the heat equation using similarity solution</h3>\n<p>References<a href=\"https://youtu.be/dNLmvhZWEq8\">Dr Chris Tisdell's Youtube</a>, <a href=\"https://www.ucl.ac.uk/~ucahhwi/LTCC/sectionB-similarity.pdf\">UCL's class note</a>.</p>\n<p>Given PDE with boundary and initial conditions: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} =&amp; k\\frac{\\partial^2 u}{\\partial x^2}\\\\\nu(x,0)=0, &amp;\\quad x&gt;0\\\\\nu(x,t)\\rightarrow0, &amp;\\quad x\\rightarrow\\infty \\\\\n\\partial_x u(0,t)=N, &amp;\\quad t&gt;0\n\\end{aligned}\n\\]</span></p>\n<ol type=\"1\">\n<li><p>Determine a set of transformations: <span class=\"math display\">\\[\n\\begin{aligned}\nx &amp;= \\lambda^a\\bar{x}\\\\\nt &amp;= \\lambda^b\\bar{t}\\\\\nu &amp;= \\lambda^c\\bar{u}\\\\\n\\end{aligned}\n\\]</span> Substitute into the equation: <span class=\"math display\">\\[\n\\begin{aligned}\n\\lambda^{c-b}\\frac{\\partial \\bar{u}}{\\partial \\bar{t}} = \\lambda^{c-2a}k\\frac{\\partial^2 \\bar{u}}{\\partial \\bar{x}^2} \\\\\n\\frac{\\partial \\bar{u}}{\\partial \\bar{t}} = \\lambda^{-2a+b}k\\frac{\\partial^2 \\bar{u}}{\\partial \\bar{x}^2}\n\\end{aligned}\n\\]</span> Boundary condition: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial x} =N, \\quad t&gt;0 \\\\\n\\lambda^{c-a}\\frac{\\partial \\bar{u}}{\\partial \\bar{x}}=N\n\\end{aligned}\n\\]</span></p>\n<p>As a result: <span class=\"math display\">\\[\n\\begin{aligned}\n-2a+b &amp;= 0 \\\\\nc-a&amp;=0\n\\end{aligned}\n\\]</span></p></li>\n<li><p>Determin <span class=\"math inline\">\\(s\\)</span> and <span class=\"math inline\">\\(r\\)</span> such that: <span class=\"math display\">\\[\n\\bar{x\\vphantom{t}}\\bar{t}^s=xt^s\\qquad \\bar{u\\vphantom{t}}\\bar{t}^r = ut^r\n\\]</span> Substitute we have: <span class=\"math display\">\\[\n\\begin{aligned}\n\\bar{x\\vphantom{t}}\\bar{t}^s&amp;=xt^s \\\\\n\\bar{x\\vphantom{t}}\\bar{t}^s &amp;= \\lambda^{a+sb}\\bar{x\\vphantom{t}}\\bar{t}^s  \\\\\n\\Rightarrow \\quad s &amp;= -a/b =  -1/2\n\\end{aligned}\n\\]</span> and <span class=\"math display\">\\[\n\\begin{aligned}\n\\bar{u\\vphantom{t}}\\bar{t}^r&amp;=ut^r \\\\\n\\bar{u\\vphantom{t}}\\bar{t}^r &amp;= \\lambda^{c+rb}\\bar{x\\vphantom{t}}\\bar{t}^r = \\lambda^{(c+2ar)}\\bar{x\\vphantom{t}}\\bar{t}^r\\\\\n\\Rightarrow \\quad r &amp;= -c/b = -1/2\n\\end{aligned}\n\\]</span></p></li>\n<li><p>With two terms unchanged by the transformation. A solution combines these two terms can be constructed as <span class=\"math inline\">\\(u(x,t) = t^{-r}f(xt^s) = t^{-r}f(\\eta)\\)</span>: <span class=\"math display\">\\[\n\\begin{aligned}\nu(x,t) = t^{c/b}f(\\eta), \\quad\\mathrm{where~}\\eta = xt^{-a/b} \\\\\n\\Leftrightarrow\\quad u(x,t) = t^{1/2}f(\\eta),\\quad\\mathrm{where~}\\eta = \\frac{x}{t^{1/2}}\n\\end{aligned}\n\\]</span> <div class=\"note note-info\">\n            <p>Note that <span class=\"math inline\">\\(u(x,t) = t^{c/b}f(\\eta), \\quad \\eta = xt^{-a/b}\\)</span> is a general solution and it suits for every conditions.</p>\n          </div></p></li>\n<li><p>Substitute into the original function to get a ODE: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} &amp;= \\frac{1}{2}t^{-1/2}f - \\frac{1}{2}t^{-1}xf&#39; \\\\ &amp;= \\frac{1}{2}t^{-1/2}f - \\frac{1}{2}t^{-1/2}\\eta f&#39;\\\\&amp;=\\frac{1}{2}t^{-1/2}\\left(f-\\eta f&#39;\\right)\\\\\n\\frac{\\partial^2 u}{\\partial x^2} &amp;= t^{-1/2}f&#39;&#39;\\\\\n\\end{aligned}\n\\]</span> The resulting equation is therefore: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\frac{1}{2}t^{-1/2}\\left(f-\\eta f&#39;\\right)= kt^{-1/2}f&#39;&#39; \\\\\n\\Leftrightarrow\\quad&amp; \\frac{1}{2}\\left(f-\\eta f&#39;\\right)= kf&#39;&#39; \\\\\n\\Leftrightarrow\\quad&amp; 2kf&#39;&#39;+\\eta f&#39;-f = 0\n\\end{aligned}\n\\]</span></p>\n<p>The following work is solving this ODE, which is illustrated more on <a href=\"https://www.ucl.ac.uk/~ucahhwi/LTCC/sectionB-similarity.pdf\">UCL's class note</a>.</p></li>\n</ol>"},{"title":"Hello ShouRou","date":"2022-02-22T02:44:29.000Z","_content":"\n### Welcome\n\nThis is the first blog on ShouRou. The name of the website is extracted from the cute nikenames between a pair of good-looking lovers.\n\nShoushou the dumb and his girl Rourou the clever, cute and sexy will start up magnifisent careers of each own and be together as a happy couple.\n\n","source":"_posts/Hello-ShouRou.md","raw":"---\ntitle: Hello ShouRou\ndate: 2022-02-22 10:44:29\ntags: blog\n---\n\n### Welcome\n\nThis is the first blog on ShouRou. The name of the website is extracted from the cute nikenames between a pair of good-looking lovers.\n\nShoushou the dumb and his girl Rourou the clever, cute and sexy will start up magnifisent careers of each own and be together as a happy couple.\n\n","slug":"Hello-ShouRou","published":1,"updated":"2022-06-09T10:15:14.480Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz1z0006l8ybbhga7l63","content":"<h3 id=\"welcome\">Welcome</h3>\n<p>This is the first blog on ShouRou. The name of the website is extracted from the cute nikenames between a pair of good-looking lovers.</p>\n<p>Shoushou the dumb and his girl Rourou the clever, cute and sexy will start up magnifisent careers of each own and be together as a happy couple.</p>\n","site":{"data":{}},"wordcount":236,"excerpt":"","more":"<h3 id=\"welcome\">Welcome</h3>\n<p>This is the first blog on ShouRou. The name of the website is extracted from the cute nikenames between a pair of good-looking lovers.</p>\n<p>Shoushou the dumb and his girl Rourou the clever, cute and sexy will start up magnifisent careers of each own and be together as a happy couple.</p>\n"},{"title":"Derivation of Integral Fluid Equations","author":"Ryan LI","toc":true,"declare":true,"index_img":"/index/deriving_NS_intergral.png","date":"2022-05-12T09:39:18.000Z","_content":"\n{% note primary %}\n\nFeeling unsafe when deploying CFD algorithms, the best way to alleviate the anxiety is to derive the fundamentals again.\n\n{% endnote%}\n\n<!-- more -->\n\n## 1 Control Volumes\n\n### 1.1 Basic Physical laws of fluid Mechanics\n\n#### 1.1.1 Control mass & *Lagrangian* frame of reference\n\n4 terms & 3 facts:\n\n- A *<font color=#6944ba>system</font> (or <font color=#6944ba>control mass</font>)* is a collection of moving particles of interest. \n\n- The *<font color=#6944ba>boundary</font>* separates the system with its *<font color=#6944ba>surroundings</font>*.\n- The boundary may move and deform with the moving particles.\n\n#### 1.1.2 Laws of Mechanics\n\n3 laws of a control mass (suitable for bath fluid and solid systems):\n\n- Conservation of mass\n  $$\n  m=const\\text {  or equivalently } \\frac{\\mathrm{d} m}{\\mathrm{~d} t}=0\n  $$\n  \n- Linear momentum equation (Newton's second law)\n  $$\n  \\textbf{F}  = m\\textbf{a} = m\\frac{d\\textbf{V}}{dt} = \\frac{d}{dt}(m\\textbf{V})\n  $$\n\n- First law of thermodynamics\n  $$\n  dE=\\delta Q-\\delta W\n  $$\n\n{% note info %}\n\nAngular coordinate is not considered\n\n{% endnote %}\n\n#### 1.1.3 Control volume & *Eulerian* frame of reference\n\n- A *<font color=#6944ba>control volume</font>* is a region of interest in space.\n\n- A *<font color=#6944ba>control surface</font>* closures the control volume\n- Mass, heat and work can cross the control surface and mass and properties can change with time within the control volume.\n\n#### 1.1.4 Volume and mass rate of flow\n\n3 key quantities of interest: Velocity $\\textbf{V}$, Volume flow $Q$ and Mass flow $\\dot{m}$.\n\n<img src=\"Flow_pass_control_surface.png\" style=\"zoom:20%;\" />\n\nShown above, given a flow of fluid passing through an infinitesimal control surface ($S$) with an area of $dA$ at an angle $\\theta$ to the surface outward normal $\\textbf{n}$, in time $dt$, the volume of the flow can be expressed as:\n$$\nd \\mathcal{V}=V d t d A \\cos \\theta=(\\mathbf{V} \\cdot \\mathbf{n}) d A d t\n$$\nFlow rate through surface can be integrated as:\n$$\n\\color{purple}{Q=\\int_{S} \\frac{\\mathrm{d} \\mathcal{V}}{\\mathrm{d} t}=\\int_{S}(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n$$\n{% note info %}\n\nSign of $Q$ is important, inflow = negative, outflow = positive.\n\n{% endnote %}\n\nAnd the corresponding mass flow is:\n$$\n\\dot{m}=\\int_{S} \\rho(\\mathbf{x})(\\mathbf{V} \\cdot \\mathbf{n}) d A\n$$\nIn the special case that $\\rho$ and $\\mathbf{V}$ remain constant in space,  \n$$\n\\dot{m}=\\rho AV\n$$\n\n### 1.2 The Reynolds Transport Theorem\n\nThe theorem refers to the relationship between (a) time derivative of a system property and (b) the rate of change of that property within a region of interest.\n\nLet $B$ be the property (e.g. mass, energy, momentum) and $\\beta$ be the amount of $B$ per unit mass $\\mathrm{d}B/\\mathrm{d}m$, often called the *intensive value*. The Reynolds Transport Theorem stats that:\n$$\n\\color{purple}{\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(B_{s}\\right)=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\beta \\rho d \\mathcal{V}\\right)+\\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n$$\n\n#### 1.2.1 concise proof\n\nConsider a fixed control volume with fluid moving through it shown as below. The control mass (particles) of interest move from the area surrounded by the solid circle to the area surrounded by dashed line within a time interval of $dt$.\n\n<img src=\"Reynolds transport theorem proof.png\" style=\"zoom:45%;\" />\n\nThe change rate of $B$ of the control mass equals the sum of \n\n- the change rate of B in the **fixed** control volume ($CV$)\n- outflow of B from the fixed control volume ($CV$)\n- inflow of B into the fixed control volume ($CV$)\n\n{% note info %}\n\nThe condition **fixed** is critical, if the control volume is moving with a velocity $\\mathbf{V_{s}}$, a reference system conversion is needed to set control volume fix, i.e. using relative velocity $\\mathbf{V_{r}}=\\mathbf{V}-\\mathbf{V_{s}}$\n\n{% endnote %}\n\nConsider $b = \\mathrm{d}B/\\mathrm{d}m$ Total amount of $B$ in the fixed control volume ($CV$) is:\n$$\nB_{C V}=\\int_{C V} \\beta d m=\\int_{C V} \\beta \\rho d \\mathcal{V}\n$$\nCorrespondingly, the change rate of $B$ within $CV$:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\beta \\rho d \\mathcal{V}\\right)\n$$\nSum of inflow and outflow of $B$ toward $CV$:\n$$\n\\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\hat{\\mathbf{n}}) d A_{o u t} + \\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\hat{\\mathbf{n}}) d A_{in} = \\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\hat{\\mathbf{n}}) d A\n$$\n{% note info %}\n\nThough this equation seems intuitive, more steps are needed to prove this from the idea of limits.\n\n{% endnote %}\n\nAs a result, the Reynolds transport theorem is arrived.\n\n## 2 Conservation of Mass and Momentum\n\nThe Reynolds transport theorem (RTT) establishes the relation between control mass and control volume, we already have control mass laws in [1.1.2 Laws of Mechanics](#laws-of-mechanics). To have the laws of fluid mechanics, the only thing needed is bringing [RTT](#the-reynolds-transport-theorem) into laws of mechanics.\n\n```mermaid\nclassDiagram\ndirection LR\n    mechanical --> RTT\n    RTT --> fluid\n    class mechanical{\n    \t+Conservation of Mass \n    \t+Newton's 2nd law\n    \t+Theomal equation\n    }\n    class fluid{\n    \t+Continuity equation\n    \t+Momentum equation\n    \t+Energy equation\n    }\n```\n\n### 2.1 Conservation of Mass \n\nWe have RTT together with:\n$$\nB=m, \\\\\n\\Rightarrow \\beta=\\frac{\\mathrm{d}m}{\\mathrm{d}m}=1, \\\\\n\\frac{\\mathrm{d}m}{\\mathrm{d}t}=0\n$$\nAs a result,\n$$\n\\color{purple}{\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(m\\right)=0=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\rho d \\mathcal{V}\\right)+\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n$$\n\n#### 2.1.1 simplification\n\n1. In the case of a **fixed $CV$**, the equation becomes,\n   $$\n   \\int_{C V} \\frac{\\partial}{\\partial t}\\rho d \\mathcal{V}+\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A=0\n   $$\n   {% note info %}\n\n   Note that if $CV$ is deformable, ${\\color{red}\\frac{\\mathrm{d}}{\\mathrm{d} t}}\\left(\\int_{C V} \\beta d \\mathcal{V}\\right)\\neq \\left(\\int_{C V} {\\color{red}\\frac{\\partial}{\\partial t}}\\beta d \\mathcal{V}\\right)$. \n\n   {% endnote %}\n\n   {% note info %}\n\n   Note that instead of $\\frac{\\mathrm{d}}{\\mathrm{d} t}$, $\\frac{\\partial}{\\partial t}$ is used when moving into the integration sign $\\int_{CS}$, because inside the integration, $\\beta=\\beta(x,y,z,t)$.\n\n   {% endnote %}\n\n2. **Steady flow** $\\frac{\\partial}{\\partial t}\\rho=0$, then\n   $$\n   \\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A=0\n   $$\n   it also means the rate of mass entering the $CV$ equals that of leaving it i.e.\n   $$\n   \\sum_{i}\\left(\\dot{m}_{i}\\right)_{i n}=\\sum_{i}\\left(\\dot{m}_{i}\\right)_{o u t}\n   $$\n   as a result\n   $$\n   \\dot{m}_{CS} = \\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n   $$\n\n3. **Incompressible flow** $rho=Constant$, then\n\n   {% note info %}\n\n   it happens when a steady flow has a speed < 0.3 Ma\n\n   {% endnote %}\n   $$\n   \\int_{C S}(\\mathbf{V} \\cdot \\mathbf{n}) d A=0\n   $$\n   it means net volume flow entering and leaving the $CV$ is zero\n\n### 2.2 Linear Momentum Equation\n\nWe have RTT together with:\n$$\n\\mathbf{B}=m\\mathbf{V}, \\\\\n\\Rightarrow \\beta=\\frac{\\mathrm{d}m\\mathbf{V}}{\\mathrm{d}m}=\\mathbf{V}, \\\\\n\\textbf{F}  = \\frac{d}{dt}(m\\textbf{V})\n$$\ntherefore:\n$$\n\\color{purple}{\\sum\\mathbf{F} = \\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\mathbf{V} \\rho d \\mathcal{V}\\right)+\\int_{C S} \\mathbf{V} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n$$\n{% note info %}\n\nSome comments on this equation:\n\n- this is a vector equation that can be divided into 3 directions, e.g. in x direction:\n  $$\n  \\sum\\mathbf{F_{x}} = \\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\mathbf{V} \\rho d \\mathcal{V}\\right)+\\int_{C S} \\mathbf{V} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n  $$\n\n- $\\sum \\mathbf{F}$ includes forces acting on the boundary (pressure and viscous stress forces) and body force (gravity).\n- inertial (non-accelerating) frame of reference is needed\n\n{% endnote %}\n\n## 3 Energy Equation and the Bernoulli Equation\n\n### 3.1 the energy equation\n\nWe have RTT together with:\n$$\n\\mathbf{B}=E, \\\\\n\\Rightarrow \\beta=\\frac{\\mathrm{d}E}{\\mathrm{d}m}=e, \\\\\ndE=\\delta Q-\\delta W\n$$\nAs a result:\n$$\n\\frac{\\mathrm{d}Q}{\\mathrm{d} t}-\\frac{\\mathrm{d}W}{\\mathrm{d} t}=\\frac{\\mathrm{d}E}{\\mathrm{d} t}=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} e\\rho d \\mathcal{V}\\right)+\\int_{C S} e\\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n$$\nwhere $Q$ denotes heat added to the system(energy diffusion)\n\n$W$ denotes work done by the system(performed by forces)\n\n$e$, energy per unit mass is a sum of\n\n- Internal: $e_{i}=\\hat{u}$, temperature, internal pressure\n- Kinetic: $e_{k}=\\frac{u^{2}}{2}$, momentum of fluid\n- Potential: $e_{p}=gz$, gravity\n\n$$\ne=\\hat{u}+\\frac{u^{2}}{2}+gz\n$$\n\n{% note info %}\n\n$\\hat{u}$ denotes the internal energy, nothing to do with $u$ the velocity\n\n{% endnote %}\n\n{% note info %}\n\nOther forms of energy might be involved such as chemical, electromagnetic, but is neglected here.\n\n{% endnote %}\n\n#### 3.1.1 Work\n\n$$\n\\dot{W} = \\dot{W}_{s}+\\dot{W}_{p}+\\dot{W}_{v}\n$$\n\n{% note info %}\n\nNote the symbol of work in this section is actually rate of work $\\dot{W} = \\frac{dW}{dt}$\n\n{% endnote %}\n\nAs shown, work is a sum of:\n\n- Shaft work: $\\dot{W}_{s}$, done by the fluid\n\n- Pressure work: $\\dot{W}_{p}$, only applicable at surfaces, net effect is always zero\n\n  Pressure work performed on a surface element:\n  $$\n  d \\dot{W}_{p}=-p(-\\mathbf{V} \\cdot \\mathbf{n}) d A\n  $$\n  and the total pressure work on a control surface can then be integrated:\n  $$\n  \\dot{W}_{p}=\\int_{CS}p(\\mathbf{V} \\cdot \\mathbf{n}) d A\n  $$\n\n- Viscous work: $W_{v}$, only applicable at surfaces, due to the shear stresses\n\n  Viscous work performed on a surface in differential and integral formats:\n\n  $$\n  d \\dot{W}_{v}=-\\tau \\cdot \\mathbf{V} d A\n  $$\n\n  $$\n  \\dot{W}_{v}=-\\int_{C S} \\tau \\cdot \\mathbf{V} d A\n  $$\n  \n  {% note info %}\n  \n  Note the negative sign represents the work done on the fluid, instead of the other way around.\n  \n  {% endnote %}\n  \n  {% note info %}\n  \n  This term is always negligible when the control surface is at a:\n  \n  - Solid surface: $\\mathbf{V}=0$ from no-slip condition at wall, so $\\dot{W}_{v}=0$\n  - Machine surface, always absorbed in $ \\dot{W}_{s}$\n  - Inlets and outlets, flow is approximately normal to the surface, the only stresses are normal and typically extremely small, neglected.\n  \n  This term needs to be evaluated for **steamline surfaces**.\n  \n  <img src=\"region of significant viscous work.png\" alt=\"region of significant viscous work\" style=\"zoom:40%;\" />\n  \n  {% endnote %}\n\nAs a result the rate of work is:\n$$\n\\dot{W} = \\dot{W}_{s}+\\int_{CS}p(\\mathbf{V} \\cdot \\mathbf{n}) d A-\\int_{C S} (\\tau \\cdot \\mathbf{V})_{stream} d A\n$$\n\n#### 3.1.2 General Energy Equation\n\nSubstitute previous work equation into [the energy equation](#the-energy-equation), while leave the viscosity work as a whole:\n$$\n\\dot{Q}-\\dot{W}_{s}-\\int_{CS}p(\\mathbf{V} \\cdot \\mathbf{n}) d A-\\dot{W}_{v}=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} e\\rho d \\mathcal{V}\\right)+\\int_{C S} e\\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n$$\nCombine the left 3<sup>rd</sup> term, with the most right term:\n$$\n\\dot{Q}-\\dot{W}_{s}-\\dot{W}_{v}=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} e\\rho d \\mathcal{V}\\right)+\\int_{C S} \\left(e+\\frac{p}{\\rho}\\right)\\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n$$\nSubstitute into $e=\\hat{u}+\\frac{u^{2}}{2}+gz$, and $\\hat{h}=\\hat{u}+\\frac{p}{\\rho}$, here is the final form of the energy equation:\n$$\n\\color{purple}{\\begin{aligned}\n\\dot{Q}-\\dot{W}_{s}-\\dot{W}_{v} &=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left[\\int_{C V}\\left(\\hat{u}+\\frac{1}{2} V^{2}+g z\\right) \\rho d \\mathcal{V}\\right] \\\\\n&+\\int_{C S}\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right) \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\end{aligned}}\n$$\n{% note info %}\n\nEnthalpy: The amount of heat content used or released in a system of constant pressure\n$$\n\\hat{h}=\\hat{u}+\\frac{p}{\\rho}\n$$\n{% endnote %}\n\n#### 3.1.3 Simplicatation\n\n1. One-dimensional, we have the surface integration\n   $$\n   \\begin{aligned}\n   \\int_{C S}\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right) \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A=& \\sum\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right)_{out} \\dot{m}_{out} \\\\\n   &-\\sum\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right)_{in} \\dot{m}_{in}\n   \\end{aligned}\n   $$\n   \n2. Steady one dimensional flow with one inlet (point 1) and outlet (point 2)\n   $$\n   \\dot{Q}-\\dot{W}_{s}-\\dot{W}_{v}=\\dot{m}_{1}\\left(\\hat{h}_{1}+\\frac{1}{2} V_{1}^{2}+g z_{1}\\right)-\\dot{m}_{2}\\left(\\hat{h}_{2}+\\frac{1}{2} V_{2}^{2}+g z_{2}\\right)\n   $$\n   by conservation of mass i.e. $\\dot{m}_{1} = \\dot{m}_{2}$,\n   $$\n   \\hat{h}_{1}+\\frac{1}{2} V_{1}^{2}+g z_{1}=\\left(\\hat{h}_{2}+\\frac{1}{2} V_{2}^{2}+g z_{2}\\right)-q+w_{s}+w_{v}\n   $$\n   where $q$, $w_{s}$ and $w_{v}$ are energy, shaft work and viscosity work per unit mass, respectively.\n\n\n### 3.2 The Bernoulli Equation\n\n#### 3.2.1 Streamlines, streamtubes, pathlines and streaklines\n\n1. Streamline, a line tangent to the velocity field everywhere.\n\n$$\n\\frac{d x}{u}=\\frac{d y}{v}=\\frac{d z}{w}=\\frac{d r}{|\\mathbf{V}|}\n$$\n\n2. Streamtube, a closed arrangement of streamlines over which fluid cannot pass.\n3. Pathline, actual trajectory followed by a given particle over time.\n4. Streakline, history of a particles position which passed through a given point\n\nFor **steady flow**, streamlines, pathlines and streaklines coincide.\n\n#### 3.2.2 Derivation of Bernoulli's Equation\n\nControl volume: streamtube\n\n<img src=\"Bernoulli's Equation CV.png\" alt=\"Bernoulli's Equation CV\" style=\"zoom:50%;\" />\n\nConservation of mass in **steady and incompressibility**  condition:\n$$\n\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A =0\n$$\n\n$$\n\\mathrm{d}\\dot{m} = \\rho\\mathbf{V}A = \\rho\\left(\\mathbf{V}+\\mathrm{d}\\mathbf{V}\\right)\\left(A+\\mathrm{d}A\\right)\n$$\n\nThe forces along tube in the streamwise direction:\n\n- Body force due to gravity:\n  $$\n  \\begin{aligned}\n  F_{B}=-d W \\sin \\theta &=-\\rho g d \\mathcal{V} \\sin \\theta \\\\\n  &=-\\rho g\\left(A+\\frac{d A}{2}\\right) d s \\sin \\theta \\\\\n  &=-\\rho g\\left(A+\\frac{d A}{2}\\right) d z \\\\\n  &\\approx-\\rho gAd z\n  \\end{aligned}\n  $$\n\n- Surface force due to pressure, in **frictionless** condition:\n\n$$\n\\begin{aligned}\nF_{S} &=p A-(p+d p)(A+d A)+\\frac{1}{2}(p+p+d p) d A \\\\\n&\\approx-A d p\n\\end{aligned}\n$$\n\nApply linear momentum conservation in the streamwise direction, **steady** condition:\n$$\n\\begin{aligned}\nF_{B}+F_{S} &=\\int_{C S} V \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A \\\\\n&=V \\rho(-V) A+(V+d V) \\rho(V+d V)(A+d A)\n\\end{aligned}\n$$\nWith continuity equation before $\\rho VA=\\rho(V+d V)(A+d A)$:\n$$\n\\begin{aligned}\nF_{B}+F_{S} &=\\int_{C S} V \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A \\\\\n&=V \\rho(-V) A+(V+d V) \\rho VA \\\\\n&=\\rho AVd V\n\\end{aligned}\n$$\nSubstitute the forces:\n$$\n\\begin{aligned}\n-\\rho gAd z -A d p=\\rho AVd V \\\\ \n\\color{purple}{gd z +\\frac{d p}{\\rho}+Vd V =0}\n\\end{aligned}\n$$\nIntegrated **along a streamline**:\n$$\n\\begin{aligned}\n\\int_{S}gd z +\\int_{S}\\frac{d p}{\\rho}+\\int_{S}Vd V =0 \\\\\n\\color{purple}{gz+\\frac{p}{\\rho}+\\frac{1}{2}V^{2}=C}\n\\end{aligned}\n$$\n{% note info %}\n\nAssumptions below are made:\n\n- steady flow\n- incompressible, typically $Ma<0.3$\n- frictionless\n- flow along a single streamline\n\n{% endnote %}\n\n","source":"_posts/Derive-the-NS-equation-from-scratch-AGAIN.md","raw":"---\ntitle: Derivation of Integral Fluid Equations\nauthor: Ryan LI\ntoc: true\ndeclare: true\nindex_img: /index/deriving_NS_intergral.png\ntags:\n  - fluid dynamics\ndate: 2022-05-12 17:39:18\n---\n\n{% note primary %}\n\nFeeling unsafe when deploying CFD algorithms, the best way to alleviate the anxiety is to derive the fundamentals again.\n\n{% endnote%}\n\n<!-- more -->\n\n## 1 Control Volumes\n\n### 1.1 Basic Physical laws of fluid Mechanics\n\n#### 1.1.1 Control mass & *Lagrangian* frame of reference\n\n4 terms & 3 facts:\n\n- A *<font color=#6944ba>system</font> (or <font color=#6944ba>control mass</font>)* is a collection of moving particles of interest. \n\n- The *<font color=#6944ba>boundary</font>* separates the system with its *<font color=#6944ba>surroundings</font>*.\n- The boundary may move and deform with the moving particles.\n\n#### 1.1.2 Laws of Mechanics\n\n3 laws of a control mass (suitable for bath fluid and solid systems):\n\n- Conservation of mass\n  $$\n  m=const\\text {  or equivalently } \\frac{\\mathrm{d} m}{\\mathrm{~d} t}=0\n  $$\n  \n- Linear momentum equation (Newton's second law)\n  $$\n  \\textbf{F}  = m\\textbf{a} = m\\frac{d\\textbf{V}}{dt} = \\frac{d}{dt}(m\\textbf{V})\n  $$\n\n- First law of thermodynamics\n  $$\n  dE=\\delta Q-\\delta W\n  $$\n\n{% note info %}\n\nAngular coordinate is not considered\n\n{% endnote %}\n\n#### 1.1.3 Control volume & *Eulerian* frame of reference\n\n- A *<font color=#6944ba>control volume</font>* is a region of interest in space.\n\n- A *<font color=#6944ba>control surface</font>* closures the control volume\n- Mass, heat and work can cross the control surface and mass and properties can change with time within the control volume.\n\n#### 1.1.4 Volume and mass rate of flow\n\n3 key quantities of interest: Velocity $\\textbf{V}$, Volume flow $Q$ and Mass flow $\\dot{m}$.\n\n<img src=\"Flow_pass_control_surface.png\" style=\"zoom:20%;\" />\n\nShown above, given a flow of fluid passing through an infinitesimal control surface ($S$) with an area of $dA$ at an angle $\\theta$ to the surface outward normal $\\textbf{n}$, in time $dt$, the volume of the flow can be expressed as:\n$$\nd \\mathcal{V}=V d t d A \\cos \\theta=(\\mathbf{V} \\cdot \\mathbf{n}) d A d t\n$$\nFlow rate through surface can be integrated as:\n$$\n\\color{purple}{Q=\\int_{S} \\frac{\\mathrm{d} \\mathcal{V}}{\\mathrm{d} t}=\\int_{S}(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n$$\n{% note info %}\n\nSign of $Q$ is important, inflow = negative, outflow = positive.\n\n{% endnote %}\n\nAnd the corresponding mass flow is:\n$$\n\\dot{m}=\\int_{S} \\rho(\\mathbf{x})(\\mathbf{V} \\cdot \\mathbf{n}) d A\n$$\nIn the special case that $\\rho$ and $\\mathbf{V}$ remain constant in space,  \n$$\n\\dot{m}=\\rho AV\n$$\n\n### 1.2 The Reynolds Transport Theorem\n\nThe theorem refers to the relationship between (a) time derivative of a system property and (b) the rate of change of that property within a region of interest.\n\nLet $B$ be the property (e.g. mass, energy, momentum) and $\\beta$ be the amount of $B$ per unit mass $\\mathrm{d}B/\\mathrm{d}m$, often called the *intensive value*. The Reynolds Transport Theorem stats that:\n$$\n\\color{purple}{\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(B_{s}\\right)=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\beta \\rho d \\mathcal{V}\\right)+\\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n$$\n\n#### 1.2.1 concise proof\n\nConsider a fixed control volume with fluid moving through it shown as below. The control mass (particles) of interest move from the area surrounded by the solid circle to the area surrounded by dashed line within a time interval of $dt$.\n\n<img src=\"Reynolds transport theorem proof.png\" style=\"zoom:45%;\" />\n\nThe change rate of $B$ of the control mass equals the sum of \n\n- the change rate of B in the **fixed** control volume ($CV$)\n- outflow of B from the fixed control volume ($CV$)\n- inflow of B into the fixed control volume ($CV$)\n\n{% note info %}\n\nThe condition **fixed** is critical, if the control volume is moving with a velocity $\\mathbf{V_{s}}$, a reference system conversion is needed to set control volume fix, i.e. using relative velocity $\\mathbf{V_{r}}=\\mathbf{V}-\\mathbf{V_{s}}$\n\n{% endnote %}\n\nConsider $b = \\mathrm{d}B/\\mathrm{d}m$ Total amount of $B$ in the fixed control volume ($CV$) is:\n$$\nB_{C V}=\\int_{C V} \\beta d m=\\int_{C V} \\beta \\rho d \\mathcal{V}\n$$\nCorrespondingly, the change rate of $B$ within $CV$:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\beta \\rho d \\mathcal{V}\\right)\n$$\nSum of inflow and outflow of $B$ toward $CV$:\n$$\n\\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\hat{\\mathbf{n}}) d A_{o u t} + \\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\hat{\\mathbf{n}}) d A_{in} = \\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\hat{\\mathbf{n}}) d A\n$$\n{% note info %}\n\nThough this equation seems intuitive, more steps are needed to prove this from the idea of limits.\n\n{% endnote %}\n\nAs a result, the Reynolds transport theorem is arrived.\n\n## 2 Conservation of Mass and Momentum\n\nThe Reynolds transport theorem (RTT) establishes the relation between control mass and control volume, we already have control mass laws in [1.1.2 Laws of Mechanics](#laws-of-mechanics). To have the laws of fluid mechanics, the only thing needed is bringing [RTT](#the-reynolds-transport-theorem) into laws of mechanics.\n\n```mermaid\nclassDiagram\ndirection LR\n    mechanical --> RTT\n    RTT --> fluid\n    class mechanical{\n    \t+Conservation of Mass \n    \t+Newton's 2nd law\n    \t+Theomal equation\n    }\n    class fluid{\n    \t+Continuity equation\n    \t+Momentum equation\n    \t+Energy equation\n    }\n```\n\n### 2.1 Conservation of Mass \n\nWe have RTT together with:\n$$\nB=m, \\\\\n\\Rightarrow \\beta=\\frac{\\mathrm{d}m}{\\mathrm{d}m}=1, \\\\\n\\frac{\\mathrm{d}m}{\\mathrm{d}t}=0\n$$\nAs a result,\n$$\n\\color{purple}{\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(m\\right)=0=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\rho d \\mathcal{V}\\right)+\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n$$\n\n#### 2.1.1 simplification\n\n1. In the case of a **fixed $CV$**, the equation becomes,\n   $$\n   \\int_{C V} \\frac{\\partial}{\\partial t}\\rho d \\mathcal{V}+\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A=0\n   $$\n   {% note info %}\n\n   Note that if $CV$ is deformable, ${\\color{red}\\frac{\\mathrm{d}}{\\mathrm{d} t}}\\left(\\int_{C V} \\beta d \\mathcal{V}\\right)\\neq \\left(\\int_{C V} {\\color{red}\\frac{\\partial}{\\partial t}}\\beta d \\mathcal{V}\\right)$. \n\n   {% endnote %}\n\n   {% note info %}\n\n   Note that instead of $\\frac{\\mathrm{d}}{\\mathrm{d} t}$, $\\frac{\\partial}{\\partial t}$ is used when moving into the integration sign $\\int_{CS}$, because inside the integration, $\\beta=\\beta(x,y,z,t)$.\n\n   {% endnote %}\n\n2. **Steady flow** $\\frac{\\partial}{\\partial t}\\rho=0$, then\n   $$\n   \\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A=0\n   $$\n   it also means the rate of mass entering the $CV$ equals that of leaving it i.e.\n   $$\n   \\sum_{i}\\left(\\dot{m}_{i}\\right)_{i n}=\\sum_{i}\\left(\\dot{m}_{i}\\right)_{o u t}\n   $$\n   as a result\n   $$\n   \\dot{m}_{CS} = \\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n   $$\n\n3. **Incompressible flow** $rho=Constant$, then\n\n   {% note info %}\n\n   it happens when a steady flow has a speed < 0.3 Ma\n\n   {% endnote %}\n   $$\n   \\int_{C S}(\\mathbf{V} \\cdot \\mathbf{n}) d A=0\n   $$\n   it means net volume flow entering and leaving the $CV$ is zero\n\n### 2.2 Linear Momentum Equation\n\nWe have RTT together with:\n$$\n\\mathbf{B}=m\\mathbf{V}, \\\\\n\\Rightarrow \\beta=\\frac{\\mathrm{d}m\\mathbf{V}}{\\mathrm{d}m}=\\mathbf{V}, \\\\\n\\textbf{F}  = \\frac{d}{dt}(m\\textbf{V})\n$$\ntherefore:\n$$\n\\color{purple}{\\sum\\mathbf{F} = \\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\mathbf{V} \\rho d \\mathcal{V}\\right)+\\int_{C S} \\mathbf{V} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n$$\n{% note info %}\n\nSome comments on this equation:\n\n- this is a vector equation that can be divided into 3 directions, e.g. in x direction:\n  $$\n  \\sum\\mathbf{F_{x}} = \\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\mathbf{V} \\rho d \\mathcal{V}\\right)+\\int_{C S} \\mathbf{V} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n  $$\n\n- $\\sum \\mathbf{F}$ includes forces acting on the boundary (pressure and viscous stress forces) and body force (gravity).\n- inertial (non-accelerating) frame of reference is needed\n\n{% endnote %}\n\n## 3 Energy Equation and the Bernoulli Equation\n\n### 3.1 the energy equation\n\nWe have RTT together with:\n$$\n\\mathbf{B}=E, \\\\\n\\Rightarrow \\beta=\\frac{\\mathrm{d}E}{\\mathrm{d}m}=e, \\\\\ndE=\\delta Q-\\delta W\n$$\nAs a result:\n$$\n\\frac{\\mathrm{d}Q}{\\mathrm{d} t}-\\frac{\\mathrm{d}W}{\\mathrm{d} t}=\\frac{\\mathrm{d}E}{\\mathrm{d} t}=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} e\\rho d \\mathcal{V}\\right)+\\int_{C S} e\\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n$$\nwhere $Q$ denotes heat added to the system(energy diffusion)\n\n$W$ denotes work done by the system(performed by forces)\n\n$e$, energy per unit mass is a sum of\n\n- Internal: $e_{i}=\\hat{u}$, temperature, internal pressure\n- Kinetic: $e_{k}=\\frac{u^{2}}{2}$, momentum of fluid\n- Potential: $e_{p}=gz$, gravity\n\n$$\ne=\\hat{u}+\\frac{u^{2}}{2}+gz\n$$\n\n{% note info %}\n\n$\\hat{u}$ denotes the internal energy, nothing to do with $u$ the velocity\n\n{% endnote %}\n\n{% note info %}\n\nOther forms of energy might be involved such as chemical, electromagnetic, but is neglected here.\n\n{% endnote %}\n\n#### 3.1.1 Work\n\n$$\n\\dot{W} = \\dot{W}_{s}+\\dot{W}_{p}+\\dot{W}_{v}\n$$\n\n{% note info %}\n\nNote the symbol of work in this section is actually rate of work $\\dot{W} = \\frac{dW}{dt}$\n\n{% endnote %}\n\nAs shown, work is a sum of:\n\n- Shaft work: $\\dot{W}_{s}$, done by the fluid\n\n- Pressure work: $\\dot{W}_{p}$, only applicable at surfaces, net effect is always zero\n\n  Pressure work performed on a surface element:\n  $$\n  d \\dot{W}_{p}=-p(-\\mathbf{V} \\cdot \\mathbf{n}) d A\n  $$\n  and the total pressure work on a control surface can then be integrated:\n  $$\n  \\dot{W}_{p}=\\int_{CS}p(\\mathbf{V} \\cdot \\mathbf{n}) d A\n  $$\n\n- Viscous work: $W_{v}$, only applicable at surfaces, due to the shear stresses\n\n  Viscous work performed on a surface in differential and integral formats:\n\n  $$\n  d \\dot{W}_{v}=-\\tau \\cdot \\mathbf{V} d A\n  $$\n\n  $$\n  \\dot{W}_{v}=-\\int_{C S} \\tau \\cdot \\mathbf{V} d A\n  $$\n  \n  {% note info %}\n  \n  Note the negative sign represents the work done on the fluid, instead of the other way around.\n  \n  {% endnote %}\n  \n  {% note info %}\n  \n  This term is always negligible when the control surface is at a:\n  \n  - Solid surface: $\\mathbf{V}=0$ from no-slip condition at wall, so $\\dot{W}_{v}=0$\n  - Machine surface, always absorbed in $ \\dot{W}_{s}$\n  - Inlets and outlets, flow is approximately normal to the surface, the only stresses are normal and typically extremely small, neglected.\n  \n  This term needs to be evaluated for **steamline surfaces**.\n  \n  <img src=\"region of significant viscous work.png\" alt=\"region of significant viscous work\" style=\"zoom:40%;\" />\n  \n  {% endnote %}\n\nAs a result the rate of work is:\n$$\n\\dot{W} = \\dot{W}_{s}+\\int_{CS}p(\\mathbf{V} \\cdot \\mathbf{n}) d A-\\int_{C S} (\\tau \\cdot \\mathbf{V})_{stream} d A\n$$\n\n#### 3.1.2 General Energy Equation\n\nSubstitute previous work equation into [the energy equation](#the-energy-equation), while leave the viscosity work as a whole:\n$$\n\\dot{Q}-\\dot{W}_{s}-\\int_{CS}p(\\mathbf{V} \\cdot \\mathbf{n}) d A-\\dot{W}_{v}=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} e\\rho d \\mathcal{V}\\right)+\\int_{C S} e\\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n$$\nCombine the left 3<sup>rd</sup> term, with the most right term:\n$$\n\\dot{Q}-\\dot{W}_{s}-\\dot{W}_{v}=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} e\\rho d \\mathcal{V}\\right)+\\int_{C S} \\left(e+\\frac{p}{\\rho}\\right)\\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n$$\nSubstitute into $e=\\hat{u}+\\frac{u^{2}}{2}+gz$, and $\\hat{h}=\\hat{u}+\\frac{p}{\\rho}$, here is the final form of the energy equation:\n$$\n\\color{purple}{\\begin{aligned}\n\\dot{Q}-\\dot{W}_{s}-\\dot{W}_{v} &=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left[\\int_{C V}\\left(\\hat{u}+\\frac{1}{2} V^{2}+g z\\right) \\rho d \\mathcal{V}\\right] \\\\\n&+\\int_{C S}\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right) \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\end{aligned}}\n$$\n{% note info %}\n\nEnthalpy: The amount of heat content used or released in a system of constant pressure\n$$\n\\hat{h}=\\hat{u}+\\frac{p}{\\rho}\n$$\n{% endnote %}\n\n#### 3.1.3 Simplicatation\n\n1. One-dimensional, we have the surface integration\n   $$\n   \\begin{aligned}\n   \\int_{C S}\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right) \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A=& \\sum\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right)_{out} \\dot{m}_{out} \\\\\n   &-\\sum\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right)_{in} \\dot{m}_{in}\n   \\end{aligned}\n   $$\n   \n2. Steady one dimensional flow with one inlet (point 1) and outlet (point 2)\n   $$\n   \\dot{Q}-\\dot{W}_{s}-\\dot{W}_{v}=\\dot{m}_{1}\\left(\\hat{h}_{1}+\\frac{1}{2} V_{1}^{2}+g z_{1}\\right)-\\dot{m}_{2}\\left(\\hat{h}_{2}+\\frac{1}{2} V_{2}^{2}+g z_{2}\\right)\n   $$\n   by conservation of mass i.e. $\\dot{m}_{1} = \\dot{m}_{2}$,\n   $$\n   \\hat{h}_{1}+\\frac{1}{2} V_{1}^{2}+g z_{1}=\\left(\\hat{h}_{2}+\\frac{1}{2} V_{2}^{2}+g z_{2}\\right)-q+w_{s}+w_{v}\n   $$\n   where $q$, $w_{s}$ and $w_{v}$ are energy, shaft work and viscosity work per unit mass, respectively.\n\n\n### 3.2 The Bernoulli Equation\n\n#### 3.2.1 Streamlines, streamtubes, pathlines and streaklines\n\n1. Streamline, a line tangent to the velocity field everywhere.\n\n$$\n\\frac{d x}{u}=\\frac{d y}{v}=\\frac{d z}{w}=\\frac{d r}{|\\mathbf{V}|}\n$$\n\n2. Streamtube, a closed arrangement of streamlines over which fluid cannot pass.\n3. Pathline, actual trajectory followed by a given particle over time.\n4. Streakline, history of a particles position which passed through a given point\n\nFor **steady flow**, streamlines, pathlines and streaklines coincide.\n\n#### 3.2.2 Derivation of Bernoulli's Equation\n\nControl volume: streamtube\n\n<img src=\"Bernoulli's Equation CV.png\" alt=\"Bernoulli's Equation CV\" style=\"zoom:50%;\" />\n\nConservation of mass in **steady and incompressibility**  condition:\n$$\n\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A =0\n$$\n\n$$\n\\mathrm{d}\\dot{m} = \\rho\\mathbf{V}A = \\rho\\left(\\mathbf{V}+\\mathrm{d}\\mathbf{V}\\right)\\left(A+\\mathrm{d}A\\right)\n$$\n\nThe forces along tube in the streamwise direction:\n\n- Body force due to gravity:\n  $$\n  \\begin{aligned}\n  F_{B}=-d W \\sin \\theta &=-\\rho g d \\mathcal{V} \\sin \\theta \\\\\n  &=-\\rho g\\left(A+\\frac{d A}{2}\\right) d s \\sin \\theta \\\\\n  &=-\\rho g\\left(A+\\frac{d A}{2}\\right) d z \\\\\n  &\\approx-\\rho gAd z\n  \\end{aligned}\n  $$\n\n- Surface force due to pressure, in **frictionless** condition:\n\n$$\n\\begin{aligned}\nF_{S} &=p A-(p+d p)(A+d A)+\\frac{1}{2}(p+p+d p) d A \\\\\n&\\approx-A d p\n\\end{aligned}\n$$\n\nApply linear momentum conservation in the streamwise direction, **steady** condition:\n$$\n\\begin{aligned}\nF_{B}+F_{S} &=\\int_{C S} V \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A \\\\\n&=V \\rho(-V) A+(V+d V) \\rho(V+d V)(A+d A)\n\\end{aligned}\n$$\nWith continuity equation before $\\rho VA=\\rho(V+d V)(A+d A)$:\n$$\n\\begin{aligned}\nF_{B}+F_{S} &=\\int_{C S} V \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A \\\\\n&=V \\rho(-V) A+(V+d V) \\rho VA \\\\\n&=\\rho AVd V\n\\end{aligned}\n$$\nSubstitute the forces:\n$$\n\\begin{aligned}\n-\\rho gAd z -A d p=\\rho AVd V \\\\ \n\\color{purple}{gd z +\\frac{d p}{\\rho}+Vd V =0}\n\\end{aligned}\n$$\nIntegrated **along a streamline**:\n$$\n\\begin{aligned}\n\\int_{S}gd z +\\int_{S}\\frac{d p}{\\rho}+\\int_{S}Vd V =0 \\\\\n\\color{purple}{gz+\\frac{p}{\\rho}+\\frac{1}{2}V^{2}=C}\n\\end{aligned}\n$$\n{% note info %}\n\nAssumptions below are made:\n\n- steady flow\n- incompressible, typically $Ma<0.3$\n- frictionless\n- flow along a single streamline\n\n{% endnote %}\n\n","slug":"Derive-the-NS-equation-from-scratch-AGAIN","published":1,"updated":"2022-05-20T16:26:46.974Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz1z0007l8yb5og0h0ed","content":"<div class=\"note note-primary\">\n            <p>Feeling unsafe when deploying CFD algorithms, the best way to alleviate the anxiety is to derive the fundamentals again.</p>\n          </div>\n<span id=\"more\"></span>\n<h2 id=\"control-volumes\">1 Control Volumes</h2>\n<h3 id=\"basic-physical-laws-of-fluid-mechanics\">1.1 Basic Physical laws of fluid Mechanics</h3>\n<h4 id=\"control-mass-lagrangian-frame-of-reference\">1.1.1 Control mass &amp; <em>Lagrangian</em> frame of reference</h4>\n<p>4 terms &amp; 3 facts:</p>\n<ul>\n<li><p>A <em><font color=#6944ba>system</font> (or <font color=#6944ba>control mass</font>)</em> is a collection of moving particles of interest.</p></li>\n<li><p>The <em><font color=#6944ba>boundary</font></em> separates the system with its <em><font color=#6944ba>surroundings</font></em>.</p></li>\n<li><p>The boundary may move and deform with the moving particles.</p></li>\n</ul>\n<h4 id=\"laws-of-mechanics\">1.1.2 Laws of Mechanics</h4>\n<p>3 laws of a control mass (suitable for bath fluid and solid systems):</p>\n<ul>\n<li><p>Conservation of mass <span class=\"math display\">\\[\nm=const\\text {  or equivalently } \\frac{\\mathrm{d} m}{\\mathrm{~d} t}=0\n\\]</span></p></li>\n<li><p>Linear momentum equation (Newton's second law) <span class=\"math display\">\\[\n\\textbf{F}  = m\\textbf{a} = m\\frac{d\\textbf{V}}{dt} = \\frac{d}{dt}(m\\textbf{V})\n\\]</span></p></li>\n<li><p>First law of thermodynamics <span class=\"math display\">\\[\ndE=\\delta Q-\\delta W\n\\]</span></p></li>\n</ul>\n<div class=\"note note-info\">\n            <p>Angular coordinate is not considered</p>\n          </div>\n<h4 id=\"control-volume-eulerian-frame-of-reference\">1.1.3 Control volume &amp; <em>Eulerian</em> frame of reference</h4>\n<ul>\n<li><p>A <em><font color=#6944ba>control volume</font></em> is a region of interest in space.</p></li>\n<li><p>A <em><font color=#6944ba>control surface</font></em> closures the control volume</p></li>\n<li><p>Mass, heat and work can cross the control surface and mass and properties can change with time within the control volume.</p></li>\n</ul>\n<h4 id=\"volume-and-mass-rate-of-flow\">1.1.4 Volume and mass rate of flow</h4>\n<p>3 key quantities of interest: Velocity <span class=\"math inline\">\\(\\textbf{V}\\)</span>, Volume flow <span class=\"math inline\">\\(Q\\)</span> and Mass flow <span class=\"math inline\">\\(\\dot{m}\\)</span>.</p>\n<p><img src=\"Flow_pass_control_surface.png\" srcset=\"/img/loading.gif\" lazyload style=\"zoom:20%;\" /></p>\n<p>Shown above, given a flow of fluid passing through an infinitesimal control surface (<span class=\"math inline\">\\(S\\)</span>) with an area of <span class=\"math inline\">\\(dA\\)</span> at an angle <span class=\"math inline\">\\(\\theta\\)</span> to the surface outward normal <span class=\"math inline\">\\(\\textbf{n}\\)</span>, in time <span class=\"math inline\">\\(dt\\)</span>, the volume of the flow can be expressed as: <span class=\"math display\">\\[\nd \\mathcal{V}=V d t d A \\cos \\theta=(\\mathbf{V} \\cdot \\mathbf{n}) d A d t\n\\]</span> Flow rate through surface can be integrated as: <span class=\"math display\">\\[\n\\color{purple}{Q=\\int_{S} \\frac{\\mathrm{d} \\mathcal{V}}{\\mathrm{d} t}=\\int_{S}(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n\\]</span> <div class=\"note note-info\">\n            <p>Sign of <span class=\"math inline\">\\(Q\\)</span> is important, inflow = negative, outflow = positive.</p>\n          </div></p>\n<p>And the corresponding mass flow is: <span class=\"math display\">\\[\n\\dot{m}=\\int_{S} \\rho(\\mathbf{x})(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> In the special case that <span class=\"math inline\">\\(\\rho\\)</span> and <span class=\"math inline\">\\(\\mathbf{V}\\)</span> remain constant in space,<br />\n<span class=\"math display\">\\[\n\\dot{m}=\\rho AV\n\\]</span></p>\n<h3 id=\"the-reynolds-transport-theorem\">1.2 The Reynolds Transport Theorem</h3>\n<p>The theorem refers to the relationship between (a) time derivative of a system property and (b) the rate of change of that property within a region of interest.</p>\n<p>Let <span class=\"math inline\">\\(B\\)</span> be the property (e.g. mass, energy, momentum) and <span class=\"math inline\">\\(\\beta\\)</span> be the amount of <span class=\"math inline\">\\(B\\)</span> per unit mass <span class=\"math inline\">\\(\\mathrm{d}B/\\mathrm{d}m\\)</span>, often called the <em>intensive value</em>. The Reynolds Transport Theorem stats that: <span class=\"math display\">\\[\n\\color{purple}{\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(B_{s}\\right)=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\beta \\rho d \\mathcal{V}\\right)+\\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n\\]</span></p>\n<h4 id=\"concise-proof\">1.2.1 concise proof</h4>\n<p>Consider a fixed control volume with fluid moving through it shown as below. The control mass (particles) of interest move from the area surrounded by the solid circle to the area surrounded by dashed line within a time interval of <span class=\"math inline\">\\(dt\\)</span>.</p>\n<p><img src=\"Reynolds transport theorem proof.png\" srcset=\"/img/loading.gif\" lazyload style=\"zoom:45%;\" /></p>\n<p>The change rate of <span class=\"math inline\">\\(B\\)</span> of the control mass equals the sum of</p>\n<ul>\n<li>the change rate of B in the <strong>fixed</strong> control volume (<span class=\"math inline\">\\(CV\\)</span>)</li>\n<li>outflow of B from the fixed control volume (<span class=\"math inline\">\\(CV\\)</span>)</li>\n<li>inflow of B into the fixed control volume (<span class=\"math inline\">\\(CV\\)</span>)</li>\n</ul>\n<div class=\"note note-info\">\n            <p>The condition <strong>fixed</strong> is critical, if the control volume is moving with a velocity <span class=\"math inline\">\\(\\mathbf{V_{s}}\\)</span>, a reference system conversion is needed to set control volume fix, i.e. using relative velocity <span class=\"math inline\">\\(\\mathbf{V_{r}}=\\mathbf{V}-\\mathbf{V_{s}}\\)</span></p>\n          </div>\n<p>Consider <span class=\"math inline\">\\(b = \\mathrm{d}B/\\mathrm{d}m\\)</span> Total amount of <span class=\"math inline\">\\(B\\)</span> in the fixed control volume (<span class=\"math inline\">\\(CV\\)</span>) is: <span class=\"math display\">\\[\nB_{C V}=\\int_{C V} \\beta d m=\\int_{C V} \\beta \\rho d \\mathcal{V}\n\\]</span> Correspondingly, the change rate of <span class=\"math inline\">\\(B\\)</span> within <span class=\"math inline\">\\(CV\\)</span>: <span class=\"math display\">\\[\n\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\beta \\rho d \\mathcal{V}\\right)\n\\]</span> Sum of inflow and outflow of <span class=\"math inline\">\\(B\\)</span> toward <span class=\"math inline\">\\(CV\\)</span>: <span class=\"math display\">\\[\n\\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\hat{\\mathbf{n}}) d A_{o u t} + \\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\hat{\\mathbf{n}}) d A_{in} = \\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\hat{\\mathbf{n}}) d A\n\\]</span> <div class=\"note note-info\">\n            <p>Though this equation seems intuitive, more steps are needed to prove this from the idea of limits.</p>\n          </div></p>\n<p>As a result, the Reynolds transport theorem is arrived.</p>\n<h2 id=\"conservation-of-mass-and-momentum\">2 Conservation of Mass and Momentum</h2>\n<p>The Reynolds transport theorem (RTT) establishes the relation between control mass and control volume, we already have control mass laws in <a href=\"#laws-of-mechanics\">1.1.2 Laws of Mechanics</a>. To have the laws of fluid mechanics, the only thing needed is bringing <a href=\"#the-reynolds-transport-theorem\">RTT</a> into laws of mechanics.</p>\n<pre><code class=\" mermaid\">classDiagram\ndirection LR\n    mechanical --&gt; RTT\n    RTT --&gt; fluid\n    class mechanical&#123;\n    \t+Conservation of Mass \n    \t+Newton&#x27;s 2nd law\n    \t+Theomal equation\n    &#125;\n    class fluid&#123;\n    \t+Continuity equation\n    \t+Momentum equation\n    \t+Energy equation\n    &#125;</code></pre>\n<h3 id=\"conservation-of-mass\">2.1 Conservation of Mass</h3>\n<p>We have RTT together with: <span class=\"math display\">\\[\nB=m, \\\\\n\\Rightarrow \\beta=\\frac{\\mathrm{d}m}{\\mathrm{d}m}=1, \\\\\n\\frac{\\mathrm{d}m}{\\mathrm{d}t}=0\n\\]</span> As a result, <span class=\"math display\">\\[\n\\color{purple}{\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(m\\right)=0=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\rho d \\mathcal{V}\\right)+\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n\\]</span></p>\n<h4 id=\"simplification\">2.1.1 simplification</h4>\n<ol type=\"1\">\n<li><p>In the case of a <strong>fixed <span class=\"math inline\">\\(CV\\)</span></strong>, the equation becomes, <span class=\"math display\">\\[\n\\int_{C V} \\frac{\\partial}{\\partial t}\\rho d \\mathcal{V}+\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A=0\n\\]</span> <div class=\"note note-info\">\n            <p>Note that if <span class=\"math inline\">\\(CV\\)</span> is deformable, <span class=\"math inline\">\\({\\color{red}\\frac{\\mathrm{d}}{\\mathrm{d} t}}\\left(\\int_{C V} \\beta d \\mathcal{V}\\right)\\neq \\left(\\int_{C V} {\\color{red}\\frac{\\partial}{\\partial t}}\\beta d \\mathcal{V}\\right)\\)</span>.</p>\n          </div></p>\n<div class=\"note note-info\">\n            <p>Note that instead of <span class=\"math inline\">\\(\\frac{\\mathrm{d}}{\\mathrm{d} t}\\)</span>, <span class=\"math inline\">\\(\\frac{\\partial}{\\partial t}\\)</span> is used when moving into the integration sign <span class=\"math inline\">\\(\\int_{CS}\\)</span>, because inside the integration, <span class=\"math inline\">\\(\\beta=\\beta(x,y,z,t)\\)</span>.</p>\n          </div></li>\n<li><p><strong>Steady flow</strong> <span class=\"math inline\">\\(\\frac{\\partial}{\\partial t}\\rho=0\\)</span>, then <span class=\"math display\">\\[\n\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A=0\n\\]</span> it also means the rate of mass entering the <span class=\"math inline\">\\(CV\\)</span> equals that of leaving it i.e. <span class=\"math display\">\\[\n\\sum_{i}\\left(\\dot{m}_{i}\\right)_{i n}=\\sum_{i}\\left(\\dot{m}_{i}\\right)_{o u t}\n\\]</span> as a result <span class=\"math display\">\\[\n\\dot{m}_{CS} = \\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span></p></li>\n<li><p><strong>Incompressible flow</strong> <span class=\"math inline\">\\(rho=Constant\\)</span>, then</p>\n<div class=\"note note-info\">\n            <p>it happens when a steady flow has a speed &lt; 0.3 Ma</p>\n          </div>\n<p><span class=\"math display\">\\[\n\\int_{C S}(\\mathbf{V} \\cdot \\mathbf{n}) d A=0\n\\]</span> it means net volume flow entering and leaving the <span class=\"math inline\">\\(CV\\)</span> is zero</p></li>\n</ol>\n<h3 id=\"linear-momentum-equation\">2.2 Linear Momentum Equation</h3>\n<p>We have RTT together with: <span class=\"math display\">\\[\n\\mathbf{B}=m\\mathbf{V}, \\\\\n\\Rightarrow \\beta=\\frac{\\mathrm{d}m\\mathbf{V}}{\\mathrm{d}m}=\\mathbf{V}, \\\\\n\\textbf{F}  = \\frac{d}{dt}(m\\textbf{V})\n\\]</span> therefore: <span class=\"math display\">\\[\n\\color{purple}{\\sum\\mathbf{F} = \\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\mathbf{V} \\rho d \\mathcal{V}\\right)+\\int_{C S} \\mathbf{V} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n\\]</span> <div class=\"note note-info\">\n            <p>Some comments on this equation:</p><ul><li><p>this is a vector equation that can be divided into 3 directions, e.g. in x direction: <span class=\"math display\">\\[\\sum\\mathbf{F_{x}} = \\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\mathbf{V} \\rho d \\mathcal{V}\\right)+\\int_{C S} \\mathbf{V} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\\]</span></p></li><li><p><span class=\"math inline\">\\(\\sum \\mathbf{F}\\)</span> includes forces acting on the boundary (pressure and viscous stress forces) and body force (gravity).</p></li><li><p>inertial (non-accelerating) frame of reference is needed</p></li></ul>\n          </div></p>\n<h2 id=\"energy-equation-and-the-bernoulli-equation\">3 Energy Equation and the Bernoulli Equation</h2>\n<h3 id=\"the-energy-equation\">3.1 the energy equation</h3>\n<p>We have RTT together with: <span class=\"math display\">\\[\n\\mathbf{B}=E, \\\\\n\\Rightarrow \\beta=\\frac{\\mathrm{d}E}{\\mathrm{d}m}=e, \\\\\ndE=\\delta Q-\\delta W\n\\]</span> As a result: <span class=\"math display\">\\[\n\\frac{\\mathrm{d}Q}{\\mathrm{d} t}-\\frac{\\mathrm{d}W}{\\mathrm{d} t}=\\frac{\\mathrm{d}E}{\\mathrm{d} t}=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} e\\rho d \\mathcal{V}\\right)+\\int_{C S} e\\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> where <span class=\"math inline\">\\(Q\\)</span> denotes heat added to the system(energy diffusion)</p>\n<p><span class=\"math inline\">\\(W\\)</span> denotes work done by the system(performed by forces)</p>\n<p><span class=\"math inline\">\\(e\\)</span>, energy per unit mass is a sum of</p>\n<ul>\n<li>Internal: <span class=\"math inline\">\\(e_{i}=\\hat{u}\\)</span>, temperature, internal pressure</li>\n<li>Kinetic: <span class=\"math inline\">\\(e_{k}=\\frac{u^{2}}{2}\\)</span>, momentum of fluid</li>\n<li>Potential: <span class=\"math inline\">\\(e_{p}=gz\\)</span>, gravity</li>\n</ul>\n<p><span class=\"math display\">\\[\ne=\\hat{u}+\\frac{u^{2}}{2}+gz\n\\]</span></p>\n<div class=\"note note-info\">\n            <p><span class=\"math inline\">\\(\\hat{u}\\)</span> denotes the internal energy, nothing to do with <span class=\"math inline\">\\(u\\)</span> the velocity</p>\n          </div>\n<div class=\"note note-info\">\n            <p>Other forms of energy might be involved such as chemical, electromagnetic, but is neglected here.</p>\n          </div>\n<h4 id=\"work\">3.1.1 Work</h4>\n<p><span class=\"math display\">\\[\n\\dot{W} = \\dot{W}_{s}+\\dot{W}_{p}+\\dot{W}_{v}\n\\]</span></p>\n<div class=\"note note-info\">\n            <p>Note the symbol of work in this section is actually rate of work <span class=\"math inline\">\\(\\dot{W} = \\frac{dW}{dt}\\)</span></p>\n          </div>\n<p>As shown, work is a sum of:</p>\n<ul>\n<li><p>Shaft work: <span class=\"math inline\">\\(\\dot{W}_{s}\\)</span>, done by the fluid</p></li>\n<li><p>Pressure work: <span class=\"math inline\">\\(\\dot{W}_{p}\\)</span>, only applicable at surfaces, net effect is always zero</p>\n<p>Pressure work performed on a surface element: <span class=\"math display\">\\[\nd \\dot{W}_{p}=-p(-\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> and the total pressure work on a control surface can then be integrated: <span class=\"math display\">\\[\n\\dot{W}_{p}=\\int_{CS}p(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span></p></li>\n<li><p>Viscous work: <span class=\"math inline\">\\(W_{v}\\)</span>, only applicable at surfaces, due to the shear stresses</p>\n<p>Viscous work performed on a surface in differential and integral formats:</p>\n<p><span class=\"math display\">\\[\nd \\dot{W}_{v}=-\\tau \\cdot \\mathbf{V} d A\n\\]</span></p>\n<p><span class=\"math display\">\\[\n\\dot{W}_{v}=-\\int_{C S} \\tau \\cdot \\mathbf{V} d A\n\\]</span></p>\n<div class=\"note note-info\">\n            <p>Note the negative sign represents the work done on the fluid, instead of the other way around.</p>\n          </div>\n<div class=\"note note-info\">\n            <p>This term is always negligible when the control surface is at a:</p><ul><li>Solid surface: <span class=\"math inline\">\\(\\mathbf{V}=0\\)</span> from no-slip condition at wall, so <span class=\"math inline\">\\(\\dot{W}_{v}=0\\)</span></li><li>Machine surface, always absorbed in $ _{s}$</li><li>Inlets and outlets, flow is approximately normal to the surface, the only stresses are normal and typically extremely small, neglected.</li></ul><p>This term needs to be evaluated for <strong>steamline surfaces</strong>.</p><p><img src=\"region of significant viscous work.png\" srcset=\"/img/loading.gif\" lazyload alt=\"region of significant viscous work\" style=\"zoom:40%;\" /></p>\n          </div></li>\n</ul>\n<p>As a result the rate of work is: <span class=\"math display\">\\[\n\\dot{W} = \\dot{W}_{s}+\\int_{CS}p(\\mathbf{V} \\cdot \\mathbf{n}) d A-\\int_{C S} (\\tau \\cdot \\mathbf{V})_{stream} d A\n\\]</span></p>\n<h4 id=\"general-energy-equation\">3.1.2 General Energy Equation</h4>\n<p>Substitute previous work equation into <a href=\"#the-energy-equation\">the energy equation</a>, while leave the viscosity work as a whole: <span class=\"math display\">\\[\n\\dot{Q}-\\dot{W}_{s}-\\int_{CS}p(\\mathbf{V} \\cdot \\mathbf{n}) d A-\\dot{W}_{v}=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} e\\rho d \\mathcal{V}\\right)+\\int_{C S} e\\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> Combine the left 3<sup>rd</sup> term, with the most right term: <span class=\"math display\">\\[\n\\dot{Q}-\\dot{W}_{s}-\\dot{W}_{v}=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} e\\rho d \\mathcal{V}\\right)+\\int_{C S} \\left(e+\\frac{p}{\\rho}\\right)\\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> Substitute into <span class=\"math inline\">\\(e=\\hat{u}+\\frac{u^{2}}{2}+gz\\)</span>, and <span class=\"math inline\">\\(\\hat{h}=\\hat{u}+\\frac{p}{\\rho}\\)</span>, here is the final form of the energy equation: <span class=\"math display\">\\[\n\\color{purple}{\\begin{aligned}\n\\dot{Q}-\\dot{W}_{s}-\\dot{W}_{v} &amp;=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left[\\int_{C V}\\left(\\hat{u}+\\frac{1}{2} V^{2}+g z\\right) \\rho d \\mathcal{V}\\right] \\\\\n&amp;+\\int_{C S}\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right) \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\end{aligned}}\n\\]</span> <div class=\"note note-info\">\n            <p>Enthalpy: The amount of heat content used or released in a system of constant pressure <span class=\"math display\">\\[\\hat{h}=\\hat{u}+\\frac{p}{\\rho}\\]</span></p>\n          </div></p>\n<h4 id=\"simplicatation\">3.1.3 Simplicatation</h4>\n<ol type=\"1\">\n<li><p>One-dimensional, we have the surface integration <span class=\"math display\">\\[\n\\begin{aligned}\n\\int_{C S}\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right) \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A=&amp; \\sum\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right)_{out} \\dot{m}_{out} \\\\\n&amp;-\\sum\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right)_{in} \\dot{m}_{in}\n\\end{aligned}\n\\]</span></p></li>\n<li><p>Steady one dimensional flow with one inlet (point 1) and outlet (point 2) <span class=\"math display\">\\[\n\\dot{Q}-\\dot{W}_{s}-\\dot{W}_{v}=\\dot{m}_{1}\\left(\\hat{h}_{1}+\\frac{1}{2} V_{1}^{2}+g z_{1}\\right)-\\dot{m}_{2}\\left(\\hat{h}_{2}+\\frac{1}{2} V_{2}^{2}+g z_{2}\\right)\n\\]</span> by conservation of mass i.e. <span class=\"math inline\">\\(\\dot{m}_{1} = \\dot{m}_{2}\\)</span>, <span class=\"math display\">\\[\n\\hat{h}_{1}+\\frac{1}{2} V_{1}^{2}+g z_{1}=\\left(\\hat{h}_{2}+\\frac{1}{2} V_{2}^{2}+g z_{2}\\right)-q+w_{s}+w_{v}\n\\]</span> where <span class=\"math inline\">\\(q\\)</span>, <span class=\"math inline\">\\(w_{s}\\)</span> and <span class=\"math inline\">\\(w_{v}\\)</span> are energy, shaft work and viscosity work per unit mass, respectively.</p></li>\n</ol>\n<h3 id=\"the-bernoulli-equation\">3.2 The Bernoulli Equation</h3>\n<h4 id=\"streamlines-streamtubes-pathlines-and-streaklines\">3.2.1 Streamlines, streamtubes, pathlines and streaklines</h4>\n<ol type=\"1\">\n<li>Streamline, a line tangent to the velocity field everywhere.</li>\n</ol>\n<p><span class=\"math display\">\\[\n\\frac{d x}{u}=\\frac{d y}{v}=\\frac{d z}{w}=\\frac{d r}{|\\mathbf{V}|}\n\\]</span></p>\n<ol start=\"2\" type=\"1\">\n<li>Streamtube, a closed arrangement of streamlines over which fluid cannot pass.</li>\n<li>Pathline, actual trajectory followed by a given particle over time.</li>\n<li>Streakline, history of a particles position which passed through a given point</li>\n</ol>\n<p>For <strong>steady flow</strong>, streamlines, pathlines and streaklines coincide.</p>\n<h4 id=\"derivation-of-bernoullis-equation\">3.2.2 Derivation of Bernoulli's Equation</h4>\n<p>Control volume: streamtube</p>\n<p><img src=\"Bernoulli's Equation CV.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Bernoulli's Equation CV\" style=\"zoom:50%;\" /></p>\n<p>Conservation of mass in <strong>steady and incompressibility</strong> condition: <span class=\"math display\">\\[\n\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A =0\n\\]</span></p>\n<p><span class=\"math display\">\\[\n\\mathrm{d}\\dot{m} = \\rho\\mathbf{V}A = \\rho\\left(\\mathbf{V}+\\mathrm{d}\\mathbf{V}\\right)\\left(A+\\mathrm{d}A\\right)\n\\]</span></p>\n<p>The forces along tube in the streamwise direction:</p>\n<ul>\n<li><p>Body force due to gravity: <span class=\"math display\">\\[\n\\begin{aligned}\nF_{B}=-d W \\sin \\theta &amp;=-\\rho g d \\mathcal{V} \\sin \\theta \\\\\n&amp;=-\\rho g\\left(A+\\frac{d A}{2}\\right) d s \\sin \\theta \\\\\n&amp;=-\\rho g\\left(A+\\frac{d A}{2}\\right) d z \\\\\n&amp;\\approx-\\rho gAd z\n\\end{aligned}\n\\]</span></p></li>\n<li><p>Surface force due to pressure, in <strong>frictionless</strong> condition:</p></li>\n</ul>\n<p><span class=\"math display\">\\[\n\\begin{aligned}\nF_{S} &amp;=p A-(p+d p)(A+d A)+\\frac{1}{2}(p+p+d p) d A \\\\\n&amp;\\approx-A d p\n\\end{aligned}\n\\]</span></p>\n<p>Apply linear momentum conservation in the streamwise direction, <strong>steady</strong> condition: <span class=\"math display\">\\[\n\\begin{aligned}\nF_{B}+F_{S} &amp;=\\int_{C S} V \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A \\\\\n&amp;=V \\rho(-V) A+(V+d V) \\rho(V+d V)(A+d A)\n\\end{aligned}\n\\]</span> With continuity equation before <span class=\"math inline\">\\(\\rho VA=\\rho(V+d V)(A+d A)\\)</span>: <span class=\"math display\">\\[\n\\begin{aligned}\nF_{B}+F_{S} &amp;=\\int_{C S} V \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A \\\\\n&amp;=V \\rho(-V) A+(V+d V) \\rho VA \\\\\n&amp;=\\rho AVd V\n\\end{aligned}\n\\]</span> Substitute the forces: <span class=\"math display\">\\[\n\\begin{aligned}\n-\\rho gAd z -A d p=\\rho AVd V \\\\ \n\\color{purple}{gd z +\\frac{d p}{\\rho}+Vd V =0}\n\\end{aligned}\n\\]</span> Integrated <strong>along a streamline</strong>: <span class=\"math display\">\\[\n\\begin{aligned}\n\\int_{S}gd z +\\int_{S}\\frac{d p}{\\rho}+\\int_{S}Vd V =0 \\\\\n\\color{purple}{gz+\\frac{p}{\\rho}+\\frac{1}{2}V^{2}=C}\n\\end{aligned}\n\\]</span> <div class=\"note note-info\">\n            <p>Assumptions below are made:</p><ul><li>steady flow</li><li>incompressible, typically <span class=\"math inline\">\\(Ma&lt;0.3\\)</span></li><li>frictionless</li><li>flow along a single streamline</li></ul>\n          </div></p>\n","site":{"data":{}},"wordcount":11905,"excerpt":"<div class=\"note note-primary\">\n            <p>Feeling unsafe when deploying CFD algorithms, the best way to alleviate the anxiety is to derive the fundamentals again.</p>\n          </div>","more":"<h2 id=\"control-volumes\">1 Control Volumes</h2>\n<h3 id=\"basic-physical-laws-of-fluid-mechanics\">1.1 Basic Physical laws of fluid Mechanics</h3>\n<h4 id=\"control-mass-lagrangian-frame-of-reference\">1.1.1 Control mass &amp; <em>Lagrangian</em> frame of reference</h4>\n<p>4 terms &amp; 3 facts:</p>\n<ul>\n<li><p>A <em><font color=#6944ba>system</font> (or <font color=#6944ba>control mass</font>)</em> is a collection of moving particles of interest.</p></li>\n<li><p>The <em><font color=#6944ba>boundary</font></em> separates the system with its <em><font color=#6944ba>surroundings</font></em>.</p></li>\n<li><p>The boundary may move and deform with the moving particles.</p></li>\n</ul>\n<h4 id=\"laws-of-mechanics\">1.1.2 Laws of Mechanics</h4>\n<p>3 laws of a control mass (suitable for bath fluid and solid systems):</p>\n<ul>\n<li><p>Conservation of mass <span class=\"math display\">\\[\nm=const\\text {  or equivalently } \\frac{\\mathrm{d} m}{\\mathrm{~d} t}=0\n\\]</span></p></li>\n<li><p>Linear momentum equation (Newton's second law) <span class=\"math display\">\\[\n\\textbf{F}  = m\\textbf{a} = m\\frac{d\\textbf{V}}{dt} = \\frac{d}{dt}(m\\textbf{V})\n\\]</span></p></li>\n<li><p>First law of thermodynamics <span class=\"math display\">\\[\ndE=\\delta Q-\\delta W\n\\]</span></p></li>\n</ul>\n<div class=\"note note-info\">\n            <p>Angular coordinate is not considered</p>\n          </div>\n<h4 id=\"control-volume-eulerian-frame-of-reference\">1.1.3 Control volume &amp; <em>Eulerian</em> frame of reference</h4>\n<ul>\n<li><p>A <em><font color=#6944ba>control volume</font></em> is a region of interest in space.</p></li>\n<li><p>A <em><font color=#6944ba>control surface</font></em> closures the control volume</p></li>\n<li><p>Mass, heat and work can cross the control surface and mass and properties can change with time within the control volume.</p></li>\n</ul>\n<h4 id=\"volume-and-mass-rate-of-flow\">1.1.4 Volume and mass rate of flow</h4>\n<p>3 key quantities of interest: Velocity <span class=\"math inline\">\\(\\textbf{V}\\)</span>, Volume flow <span class=\"math inline\">\\(Q\\)</span> and Mass flow <span class=\"math inline\">\\(\\dot{m}\\)</span>.</p>\n<p><img src=\"Flow_pass_control_surface.png\" style=\"zoom:20%;\" /></p>\n<p>Shown above, given a flow of fluid passing through an infinitesimal control surface (<span class=\"math inline\">\\(S\\)</span>) with an area of <span class=\"math inline\">\\(dA\\)</span> at an angle <span class=\"math inline\">\\(\\theta\\)</span> to the surface outward normal <span class=\"math inline\">\\(\\textbf{n}\\)</span>, in time <span class=\"math inline\">\\(dt\\)</span>, the volume of the flow can be expressed as: <span class=\"math display\">\\[\nd \\mathcal{V}=V d t d A \\cos \\theta=(\\mathbf{V} \\cdot \\mathbf{n}) d A d t\n\\]</span> Flow rate through surface can be integrated as: <span class=\"math display\">\\[\n\\color{purple}{Q=\\int_{S} \\frac{\\mathrm{d} \\mathcal{V}}{\\mathrm{d} t}=\\int_{S}(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n\\]</span> <div class=\"note note-info\">\n            <p>Sign of <span class=\"math inline\">\\(Q\\)</span> is important, inflow = negative, outflow = positive.</p>\n          </div></p>\n<p>And the corresponding mass flow is: <span class=\"math display\">\\[\n\\dot{m}=\\int_{S} \\rho(\\mathbf{x})(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> In the special case that <span class=\"math inline\">\\(\\rho\\)</span> and <span class=\"math inline\">\\(\\mathbf{V}\\)</span> remain constant in space,<br />\n<span class=\"math display\">\\[\n\\dot{m}=\\rho AV\n\\]</span></p>\n<h3 id=\"the-reynolds-transport-theorem\">1.2 The Reynolds Transport Theorem</h3>\n<p>The theorem refers to the relationship between (a) time derivative of a system property and (b) the rate of change of that property within a region of interest.</p>\n<p>Let <span class=\"math inline\">\\(B\\)</span> be the property (e.g. mass, energy, momentum) and <span class=\"math inline\">\\(\\beta\\)</span> be the amount of <span class=\"math inline\">\\(B\\)</span> per unit mass <span class=\"math inline\">\\(\\mathrm{d}B/\\mathrm{d}m\\)</span>, often called the <em>intensive value</em>. The Reynolds Transport Theorem stats that: <span class=\"math display\">\\[\n\\color{purple}{\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(B_{s}\\right)=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\beta \\rho d \\mathcal{V}\\right)+\\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n\\]</span></p>\n<h4 id=\"concise-proof\">1.2.1 concise proof</h4>\n<p>Consider a fixed control volume with fluid moving through it shown as below. The control mass (particles) of interest move from the area surrounded by the solid circle to the area surrounded by dashed line within a time interval of <span class=\"math inline\">\\(dt\\)</span>.</p>\n<p><img src=\"Reynolds transport theorem proof.png\" style=\"zoom:45%;\" /></p>\n<p>The change rate of <span class=\"math inline\">\\(B\\)</span> of the control mass equals the sum of</p>\n<ul>\n<li>the change rate of B in the <strong>fixed</strong> control volume (<span class=\"math inline\">\\(CV\\)</span>)</li>\n<li>outflow of B from the fixed control volume (<span class=\"math inline\">\\(CV\\)</span>)</li>\n<li>inflow of B into the fixed control volume (<span class=\"math inline\">\\(CV\\)</span>)</li>\n</ul>\n<div class=\"note note-info\">\n            <p>The condition <strong>fixed</strong> is critical, if the control volume is moving with a velocity <span class=\"math inline\">\\(\\mathbf{V_{s}}\\)</span>, a reference system conversion is needed to set control volume fix, i.e. using relative velocity <span class=\"math inline\">\\(\\mathbf{V_{r}}=\\mathbf{V}-\\mathbf{V_{s}}\\)</span></p>\n          </div>\n<p>Consider <span class=\"math inline\">\\(b = \\mathrm{d}B/\\mathrm{d}m\\)</span> Total amount of <span class=\"math inline\">\\(B\\)</span> in the fixed control volume (<span class=\"math inline\">\\(CV\\)</span>) is: <span class=\"math display\">\\[\nB_{C V}=\\int_{C V} \\beta d m=\\int_{C V} \\beta \\rho d \\mathcal{V}\n\\]</span> Correspondingly, the change rate of <span class=\"math inline\">\\(B\\)</span> within <span class=\"math inline\">\\(CV\\)</span>: <span class=\"math display\">\\[\n\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\beta \\rho d \\mathcal{V}\\right)\n\\]</span> Sum of inflow and outflow of <span class=\"math inline\">\\(B\\)</span> toward <span class=\"math inline\">\\(CV\\)</span>: <span class=\"math display\">\\[\n\\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\hat{\\mathbf{n}}) d A_{o u t} + \\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\hat{\\mathbf{n}}) d A_{in} = \\int_{C S} \\beta \\rho(\\mathbf{V} \\cdot \\hat{\\mathbf{n}}) d A\n\\]</span> <div class=\"note note-info\">\n            <p>Though this equation seems intuitive, more steps are needed to prove this from the idea of limits.</p>\n          </div></p>\n<p>As a result, the Reynolds transport theorem is arrived.</p>\n<h2 id=\"conservation-of-mass-and-momentum\">2 Conservation of Mass and Momentum</h2>\n<p>The Reynolds transport theorem (RTT) establishes the relation between control mass and control volume, we already have control mass laws in <a href=\"#laws-of-mechanics\">1.1.2 Laws of Mechanics</a>. To have the laws of fluid mechanics, the only thing needed is bringing <a href=\"#the-reynolds-transport-theorem\">RTT</a> into laws of mechanics.</p>\n<pre><code class=\"hljs mermaid\">classDiagram\ndirection LR\n    mechanical --&gt; RTT\n    RTT --&gt; fluid\n    class mechanical&#123;\n    \t+Conservation of Mass \n    \t+Newton&#x27;s 2nd law\n    \t+Theomal equation\n    &#125;\n    class fluid&#123;\n    \t+Continuity equation\n    \t+Momentum equation\n    \t+Energy equation\n    &#125;</code></pre>\n<h3 id=\"conservation-of-mass\">2.1 Conservation of Mass</h3>\n<p>We have RTT together with: <span class=\"math display\">\\[\nB=m, \\\\\n\\Rightarrow \\beta=\\frac{\\mathrm{d}m}{\\mathrm{d}m}=1, \\\\\n\\frac{\\mathrm{d}m}{\\mathrm{d}t}=0\n\\]</span> As a result, <span class=\"math display\">\\[\n\\color{purple}{\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(m\\right)=0=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\rho d \\mathcal{V}\\right)+\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n\\]</span></p>\n<h4 id=\"simplification\">2.1.1 simplification</h4>\n<ol type=\"1\">\n<li><p>In the case of a <strong>fixed <span class=\"math inline\">\\(CV\\)</span></strong>, the equation becomes, <span class=\"math display\">\\[\n\\int_{C V} \\frac{\\partial}{\\partial t}\\rho d \\mathcal{V}+\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A=0\n\\]</span> <div class=\"note note-info\">\n            <p>Note that if <span class=\"math inline\">\\(CV\\)</span> is deformable, <span class=\"math inline\">\\({\\color{red}\\frac{\\mathrm{d}}{\\mathrm{d} t}}\\left(\\int_{C V} \\beta d \\mathcal{V}\\right)\\neq \\left(\\int_{C V} {\\color{red}\\frac{\\partial}{\\partial t}}\\beta d \\mathcal{V}\\right)\\)</span>.</p>\n          </div></p>\n<div class=\"note note-info\">\n            <p>Note that instead of <span class=\"math inline\">\\(\\frac{\\mathrm{d}}{\\mathrm{d} t}\\)</span>, <span class=\"math inline\">\\(\\frac{\\partial}{\\partial t}\\)</span> is used when moving into the integration sign <span class=\"math inline\">\\(\\int_{CS}\\)</span>, because inside the integration, <span class=\"math inline\">\\(\\beta=\\beta(x,y,z,t)\\)</span>.</p>\n          </div></li>\n<li><p><strong>Steady flow</strong> <span class=\"math inline\">\\(\\frac{\\partial}{\\partial t}\\rho=0\\)</span>, then <span class=\"math display\">\\[\n\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A=0\n\\]</span> it also means the rate of mass entering the <span class=\"math inline\">\\(CV\\)</span> equals that of leaving it i.e. <span class=\"math display\">\\[\n\\sum_{i}\\left(\\dot{m}_{i}\\right)_{i n}=\\sum_{i}\\left(\\dot{m}_{i}\\right)_{o u t}\n\\]</span> as a result <span class=\"math display\">\\[\n\\dot{m}_{CS} = \\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span></p></li>\n<li><p><strong>Incompressible flow</strong> <span class=\"math inline\">\\(rho=Constant\\)</span>, then</p>\n<div class=\"note note-info\">\n            <p>it happens when a steady flow has a speed &lt; 0.3 Ma</p>\n          </div>\n<p><span class=\"math display\">\\[\n\\int_{C S}(\\mathbf{V} \\cdot \\mathbf{n}) d A=0\n\\]</span> it means net volume flow entering and leaving the <span class=\"math inline\">\\(CV\\)</span> is zero</p></li>\n</ol>\n<h3 id=\"linear-momentum-equation\">2.2 Linear Momentum Equation</h3>\n<p>We have RTT together with: <span class=\"math display\">\\[\n\\mathbf{B}=m\\mathbf{V}, \\\\\n\\Rightarrow \\beta=\\frac{\\mathrm{d}m\\mathbf{V}}{\\mathrm{d}m}=\\mathbf{V}, \\\\\n\\textbf{F}  = \\frac{d}{dt}(m\\textbf{V})\n\\]</span> therefore: <span class=\"math display\">\\[\n\\color{purple}{\\sum\\mathbf{F} = \\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\mathbf{V} \\rho d \\mathcal{V}\\right)+\\int_{C S} \\mathbf{V} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A}\n\\]</span> <div class=\"note note-info\">\n            <p>Some comments on this equation:</p><ul><li><p>this is a vector equation that can be divided into 3 directions, e.g. in x direction: <span class=\"math display\">\\[\\sum\\mathbf{F_{x}} = \\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} \\mathbf{V} \\rho d \\mathcal{V}\\right)+\\int_{C S} \\mathbf{V} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\\]</span></p></li><li><p><span class=\"math inline\">\\(\\sum \\mathbf{F}\\)</span> includes forces acting on the boundary (pressure and viscous stress forces) and body force (gravity).</p></li><li><p>inertial (non-accelerating) frame of reference is needed</p></li></ul>\n          </div></p>\n<h2 id=\"energy-equation-and-the-bernoulli-equation\">3 Energy Equation and the Bernoulli Equation</h2>\n<h3 id=\"the-energy-equation\">3.1 the energy equation</h3>\n<p>We have RTT together with: <span class=\"math display\">\\[\n\\mathbf{B}=E, \\\\\n\\Rightarrow \\beta=\\frac{\\mathrm{d}E}{\\mathrm{d}m}=e, \\\\\ndE=\\delta Q-\\delta W\n\\]</span> As a result: <span class=\"math display\">\\[\n\\frac{\\mathrm{d}Q}{\\mathrm{d} t}-\\frac{\\mathrm{d}W}{\\mathrm{d} t}=\\frac{\\mathrm{d}E}{\\mathrm{d} t}=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} e\\rho d \\mathcal{V}\\right)+\\int_{C S} e\\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> where <span class=\"math inline\">\\(Q\\)</span> denotes heat added to the system(energy diffusion)</p>\n<p><span class=\"math inline\">\\(W\\)</span> denotes work done by the system(performed by forces)</p>\n<p><span class=\"math inline\">\\(e\\)</span>, energy per unit mass is a sum of</p>\n<ul>\n<li>Internal: <span class=\"math inline\">\\(e_{i}=\\hat{u}\\)</span>, temperature, internal pressure</li>\n<li>Kinetic: <span class=\"math inline\">\\(e_{k}=\\frac{u^{2}}{2}\\)</span>, momentum of fluid</li>\n<li>Potential: <span class=\"math inline\">\\(e_{p}=gz\\)</span>, gravity</li>\n</ul>\n<p><span class=\"math display\">\\[\ne=\\hat{u}+\\frac{u^{2}}{2}+gz\n\\]</span></p>\n<div class=\"note note-info\">\n            <p><span class=\"math inline\">\\(\\hat{u}\\)</span> denotes the internal energy, nothing to do with <span class=\"math inline\">\\(u\\)</span> the velocity</p>\n          </div>\n<div class=\"note note-info\">\n            <p>Other forms of energy might be involved such as chemical, electromagnetic, but is neglected here.</p>\n          </div>\n<h4 id=\"work\">3.1.1 Work</h4>\n<p><span class=\"math display\">\\[\n\\dot{W} = \\dot{W}_{s}+\\dot{W}_{p}+\\dot{W}_{v}\n\\]</span></p>\n<div class=\"note note-info\">\n            <p>Note the symbol of work in this section is actually rate of work <span class=\"math inline\">\\(\\dot{W} = \\frac{dW}{dt}\\)</span></p>\n          </div>\n<p>As shown, work is a sum of:</p>\n<ul>\n<li><p>Shaft work: <span class=\"math inline\">\\(\\dot{W}_{s}\\)</span>, done by the fluid</p></li>\n<li><p>Pressure work: <span class=\"math inline\">\\(\\dot{W}_{p}\\)</span>, only applicable at surfaces, net effect is always zero</p>\n<p>Pressure work performed on a surface element: <span class=\"math display\">\\[\nd \\dot{W}_{p}=-p(-\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> and the total pressure work on a control surface can then be integrated: <span class=\"math display\">\\[\n\\dot{W}_{p}=\\int_{CS}p(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span></p></li>\n<li><p>Viscous work: <span class=\"math inline\">\\(W_{v}\\)</span>, only applicable at surfaces, due to the shear stresses</p>\n<p>Viscous work performed on a surface in differential and integral formats:</p>\n<p><span class=\"math display\">\\[\nd \\dot{W}_{v}=-\\tau \\cdot \\mathbf{V} d A\n\\]</span></p>\n<p><span class=\"math display\">\\[\n\\dot{W}_{v}=-\\int_{C S} \\tau \\cdot \\mathbf{V} d A\n\\]</span></p>\n<div class=\"note note-info\">\n            <p>Note the negative sign represents the work done on the fluid, instead of the other way around.</p>\n          </div>\n<div class=\"note note-info\">\n            <p>This term is always negligible when the control surface is at a:</p><ul><li>Solid surface: <span class=\"math inline\">\\(\\mathbf{V}=0\\)</span> from no-slip condition at wall, so <span class=\"math inline\">\\(\\dot{W}_{v}=0\\)</span></li><li>Machine surface, always absorbed in $ _{s}$</li><li>Inlets and outlets, flow is approximately normal to the surface, the only stresses are normal and typically extremely small, neglected.</li></ul><p>This term needs to be evaluated for <strong>steamline surfaces</strong>.</p><p><img src=\"region of significant viscous work.png\" alt=\"region of significant viscous work\" style=\"zoom:40%;\" /></p>\n          </div></li>\n</ul>\n<p>As a result the rate of work is: <span class=\"math display\">\\[\n\\dot{W} = \\dot{W}_{s}+\\int_{CS}p(\\mathbf{V} \\cdot \\mathbf{n}) d A-\\int_{C S} (\\tau \\cdot \\mathbf{V})_{stream} d A\n\\]</span></p>\n<h4 id=\"general-energy-equation\">3.1.2 General Energy Equation</h4>\n<p>Substitute previous work equation into <a href=\"#the-energy-equation\">the energy equation</a>, while leave the viscosity work as a whole: <span class=\"math display\">\\[\n\\dot{Q}-\\dot{W}_{s}-\\int_{CS}p(\\mathbf{V} \\cdot \\mathbf{n}) d A-\\dot{W}_{v}=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} e\\rho d \\mathcal{V}\\right)+\\int_{C S} e\\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> Combine the left 3<sup>rd</sup> term, with the most right term: <span class=\"math display\">\\[\n\\dot{Q}-\\dot{W}_{s}-\\dot{W}_{v}=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left(\\int_{C V} e\\rho d \\mathcal{V}\\right)+\\int_{C S} \\left(e+\\frac{p}{\\rho}\\right)\\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\]</span> Substitute into <span class=\"math inline\">\\(e=\\hat{u}+\\frac{u^{2}}{2}+gz\\)</span>, and <span class=\"math inline\">\\(\\hat{h}=\\hat{u}+\\frac{p}{\\rho}\\)</span>, here is the final form of the energy equation: <span class=\"math display\">\\[\n\\color{purple}{\\begin{aligned}\n\\dot{Q}-\\dot{W}_{s}-\\dot{W}_{v} &amp;=\\frac{\\mathrm{d}}{\\mathrm{d} t}\\left[\\int_{C V}\\left(\\hat{u}+\\frac{1}{2} V^{2}+g z\\right) \\rho d \\mathcal{V}\\right] \\\\\n&amp;+\\int_{C S}\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right) \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A\n\\end{aligned}}\n\\]</span> <div class=\"note note-info\">\n            <p>Enthalpy: The amount of heat content used or released in a system of constant pressure <span class=\"math display\">\\[\\hat{h}=\\hat{u}+\\frac{p}{\\rho}\\]</span></p>\n          </div></p>\n<h4 id=\"simplicatation\">3.1.3 Simplicatation</h4>\n<ol type=\"1\">\n<li><p>One-dimensional, we have the surface integration <span class=\"math display\">\\[\n\\begin{aligned}\n\\int_{C S}\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right) \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A=&amp; \\sum\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right)_{out} \\dot{m}_{out} \\\\\n&amp;-\\sum\\left(\\hat{h}+\\frac{1}{2} V^{2}+g z\\right)_{in} \\dot{m}_{in}\n\\end{aligned}\n\\]</span></p></li>\n<li><p>Steady one dimensional flow with one inlet (point 1) and outlet (point 2) <span class=\"math display\">\\[\n\\dot{Q}-\\dot{W}_{s}-\\dot{W}_{v}=\\dot{m}_{1}\\left(\\hat{h}_{1}+\\frac{1}{2} V_{1}^{2}+g z_{1}\\right)-\\dot{m}_{2}\\left(\\hat{h}_{2}+\\frac{1}{2} V_{2}^{2}+g z_{2}\\right)\n\\]</span> by conservation of mass i.e. <span class=\"math inline\">\\(\\dot{m}_{1} = \\dot{m}_{2}\\)</span>, <span class=\"math display\">\\[\n\\hat{h}_{1}+\\frac{1}{2} V_{1}^{2}+g z_{1}=\\left(\\hat{h}_{2}+\\frac{1}{2} V_{2}^{2}+g z_{2}\\right)-q+w_{s}+w_{v}\n\\]</span> where <span class=\"math inline\">\\(q\\)</span>, <span class=\"math inline\">\\(w_{s}\\)</span> and <span class=\"math inline\">\\(w_{v}\\)</span> are energy, shaft work and viscosity work per unit mass, respectively.</p></li>\n</ol>\n<h3 id=\"the-bernoulli-equation\">3.2 The Bernoulli Equation</h3>\n<h4 id=\"streamlines-streamtubes-pathlines-and-streaklines\">3.2.1 Streamlines, streamtubes, pathlines and streaklines</h4>\n<ol type=\"1\">\n<li>Streamline, a line tangent to the velocity field everywhere.</li>\n</ol>\n<p><span class=\"math display\">\\[\n\\frac{d x}{u}=\\frac{d y}{v}=\\frac{d z}{w}=\\frac{d r}{|\\mathbf{V}|}\n\\]</span></p>\n<ol start=\"2\" type=\"1\">\n<li>Streamtube, a closed arrangement of streamlines over which fluid cannot pass.</li>\n<li>Pathline, actual trajectory followed by a given particle over time.</li>\n<li>Streakline, history of a particles position which passed through a given point</li>\n</ol>\n<p>For <strong>steady flow</strong>, streamlines, pathlines and streaklines coincide.</p>\n<h4 id=\"derivation-of-bernoullis-equation\">3.2.2 Derivation of Bernoulli's Equation</h4>\n<p>Control volume: streamtube</p>\n<p><img src=\"Bernoulli's Equation CV.png\" alt=\"Bernoulli's Equation CV\" style=\"zoom:50%;\" /></p>\n<p>Conservation of mass in <strong>steady and incompressibility</strong> condition: <span class=\"math display\">\\[\n\\int_{C S} \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A =0\n\\]</span></p>\n<p><span class=\"math display\">\\[\n\\mathrm{d}\\dot{m} = \\rho\\mathbf{V}A = \\rho\\left(\\mathbf{V}+\\mathrm{d}\\mathbf{V}\\right)\\left(A+\\mathrm{d}A\\right)\n\\]</span></p>\n<p>The forces along tube in the streamwise direction:</p>\n<ul>\n<li><p>Body force due to gravity: <span class=\"math display\">\\[\n\\begin{aligned}\nF_{B}=-d W \\sin \\theta &amp;=-\\rho g d \\mathcal{V} \\sin \\theta \\\\\n&amp;=-\\rho g\\left(A+\\frac{d A}{2}\\right) d s \\sin \\theta \\\\\n&amp;=-\\rho g\\left(A+\\frac{d A}{2}\\right) d z \\\\\n&amp;\\approx-\\rho gAd z\n\\end{aligned}\n\\]</span></p></li>\n<li><p>Surface force due to pressure, in <strong>frictionless</strong> condition:</p></li>\n</ul>\n<p><span class=\"math display\">\\[\n\\begin{aligned}\nF_{S} &amp;=p A-(p+d p)(A+d A)+\\frac{1}{2}(p+p+d p) d A \\\\\n&amp;\\approx-A d p\n\\end{aligned}\n\\]</span></p>\n<p>Apply linear momentum conservation in the streamwise direction, <strong>steady</strong> condition: <span class=\"math display\">\\[\n\\begin{aligned}\nF_{B}+F_{S} &amp;=\\int_{C S} V \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A \\\\\n&amp;=V \\rho(-V) A+(V+d V) \\rho(V+d V)(A+d A)\n\\end{aligned}\n\\]</span> With continuity equation before <span class=\"math inline\">\\(\\rho VA=\\rho(V+d V)(A+d A)\\)</span>: <span class=\"math display\">\\[\n\\begin{aligned}\nF_{B}+F_{S} &amp;=\\int_{C S} V \\rho(\\mathbf{V} \\cdot \\mathbf{n}) d A \\\\\n&amp;=V \\rho(-V) A+(V+d V) \\rho VA \\\\\n&amp;=\\rho AVd V\n\\end{aligned}\n\\]</span> Substitute the forces: <span class=\"math display\">\\[\n\\begin{aligned}\n-\\rho gAd z -A d p=\\rho AVd V \\\\ \n\\color{purple}{gd z +\\frac{d p}{\\rho}+Vd V =0}\n\\end{aligned}\n\\]</span> Integrated <strong>along a streamline</strong>: <span class=\"math display\">\\[\n\\begin{aligned}\n\\int_{S}gd z +\\int_{S}\\frac{d p}{\\rho}+\\int_{S}Vd V =0 \\\\\n\\color{purple}{gz+\\frac{p}{\\rho}+\\frac{1}{2}V^{2}=C}\n\\end{aligned}\n\\]</span> <div class=\"note note-info\">\n            <p>Assumptions below are made:</p><ul><li>steady flow</li><li>incompressible, typically <span class=\"math inline\">\\(Ma&lt;0.3\\)</span></li><li>frictionless</li><li>flow along a single streamline</li></ul>\n          </div></p>"},{"title":"Build and configure a personal blog via hexo and yilia on github","date":"2022-02-22T08:15:03.000Z","toc":true,"declare":true,"_content":"\n> Technical blog has a hundred benefits and no harm\n>\n> This blog records the process of building and customizing this personal blog from 0 to 1\n\n> Unfortunately, the yilia theme has been no longer updating and it is too buggy right now. I switch to [other theme.](/2022/04/30/Switch-blog-theme-to-FLUID/)\n\n<!-- more -->\n\n## Preliminary\n\n### Why personal blog\n\n> Keeping a technical blog can be **a great way of documenting your growth as a developer**. This documentation can be particularly useful on a professional level. All software companies want to hire smart, thoughtful, communicative developers who can easily assimilate into a team, and who are ready to both teach and learn\n\n### Static vs dynamic blog\n\nthere are 2 types of mainstream personal blog: static and dynamic.\n\nStatic is recommended considering its simplicity, 0 maintenance and 0 safety worry. \n\n|              | Static blog                                                  | Dynamic blog                                                 |\n| :----------- | :----------------------------------------------------------- | :----------------------------------------------------------- |\n| Price        | low, 0 cost when the traffic is relatively low               | High, server is needed, cloud server of  high performance is usually very expensive. |\n| Features     | Limited, only third-party services can be used to complete certain \"dynamic\" functions, such as comments | Rich, in WordPress for example, basically any kind of plugins can be found. Featuers such as auto-resizing, media players, multiple authors, scheduled posts, user analysis can be easily realize. |\n| Speed        | Fast                                                         | Slow                                                         |\n| Maintainance | 0                                                            | Need to care about the sever                                 |\n| Markdown     | Supported yet it's the only choice                           | not supported                                                |\n| Geeky        | YES                                                          | No                                                           |\n\nAnd I also chose static because I'm geeky (poor of money) and results-driven (lazy to spend time on maintaining).\n\n## Build a static blog via hexo\n\n### Set environment\n\n1.check machine information: macOS on M1 MacBook\n\n2.Install Nodejs, including node and npm\n\nopen  https://nodejs.org/en/download/ and click download\n\n<img src=\"node js install.png\" alt=\"node js install\" style=\"zoom:50%;\" />\n\n3.Install Git\n\nAready installed\n\n4.Open terminal, check node, npm and git versions\n\n```shell\n$ npm -v\n$ node -v\n$ git --version\n8.3.1\nv16.14.0\ngit version 2.32.0 (Apple Git-132)\n```\n\n### Initialize blog\n\n1.install hexo via npm\n\n```shell\n$ sudo npm install -g hexo-cli\n$ hexo -v\nINFO  Validating config\nhexo: 6.0.0\nhexo-cli: 4.3.0\nos: darwin 21.2.0 12.1\n\nnode: 16.14.0\nv8: 9.4.146.24-node.20\nuv: 1.43.0\nzlib: 1.2.11\nbrotli: 1.0.9\nares: 1.18.1\nmodules: 93\nnghttp2: 1.45.1\nnapi: 8\nllhttp: 6.0.4\nopenssl: 1.1.1m+quic\ncldr: 40.0\nicu: 70.1\ntz: 2021a3\nunicode: 14.0\nngtcp2: 0.1.0-DEV\nnghttp3: 0.1.0-DEV\n```\n\n2.create a new folder in terminal and initialize the blog\n\n```shell\n$ cd ~/Documents/\n$ makedir self_blog\n$ cd self_blog/\n$ hexo init\nINFO  Cloning hexo-starter https://github.com/hexojs/hexo-starter.gitINFO  Install dependencies#########  idealTree:hexo-front-matter: timing idealTree:node_modules/hexo-front-matter Completed in 212msINFO  Start blogging with Hexo! \n```\n\n3.view the blog on localhost, s for start\n\n```shell\n$ hexo s\nINFO  Validating config\nINFO  Start processing\nINFO  Hexo is running at http://localhost:4000/ . Press Ctrl+C to stop.\n```\n\n\n### Write first blog\n\n1.write a new blog, n for new\n\n```shell\n$ hexo n 'Hello ShouRou'\nINFO  Validating config\nINFO  Created: ~/Documents/self_blog/source/_posts/Hello-ShouRou.md\n```\n\nthe blog can be written on any editor, Typora in use.\n\n```shell\nopen ~/Documents/self_blog/source/_posts/Hello-ShouRou.md\n```\n\n2.clean cache(not necessary)\n\n```shell\n$ hexo clean\n```\n\n3.generate the blog, g for generate\n\n```shell\n$ hexo g\nINFO  Validating config\nINFO  Start processing\nINFO  Files loaded in 61 ms\n(node:10719) Warning: Accessing non-existent property 'lineno' of module exports inside circular dependency\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:10719) Warning: Accessing non-existent property 'column' of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property 'filename' of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property 'lineno' of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property 'column' of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property 'filename' of module exports inside circular dependency\nINFO  Generated: archives/2022/index.html\nINFO  Generated: archives/index.html\nINFO  Generated: js/script.js\nINFO  Generated: fancybox/jquery.fancybox.min.css\nINFO  Generated: index.html\nINFO  Generated: css/style.css\nINFO  Generated: css/fonts/fontawesome-webfont.woff2\nINFO  Generated: fancybox/jquery.fancybox.min.js\nINFO  Generated: js/jquery-3.4.1.min.js\nINFO  Generated: archives/2022/02/index.html\nINFO  Generated: css/fonts/FontAwesome.otf\nINFO  Generated: css/fonts/fontawesome-webfont.woff\nINFO  Generated: css/fonts/fontawesome-webfont.eot\nINFO  Generated: css/fonts/fontawesome-webfont.ttf\nINFO  Generated: css/images/banner.jpg\nINFO  Generated: 2022/02/22/hello-world/index.html\nINFO  Generated: css/fonts/fontawesome-webfont.svg\nINFO  Generated: 2022/02/22/Hello-ShouRou/index.html\nINFO  18 files generated in 161 ms\n```\n\n### Deploy to remote (GitHub)\n\n1.Create a new repository with the name of $username.github.io\n\n<img src=\"github page.png\" alt=\"github page\" style=\"zoom:50%;\" />\n\nuse default setting\n\n2.open terminal, install plugin of deploying to git\n\n```shell\n$ npm install --save hexo-deployer-git\n```\n\n3.Open the `_config.yml` file in the blog `root` directory, add these lines afterwards\n\n```yml\ndeploy:\n type: git\n repo: git@github.com:DaydreamAtNight/DaydreamAtNight.github.io.git\n branch: master\n```\n\n4.Go to the blog `root`, deploy the blog to remote, d for deploy\n\n```shell\n$ hexo clean\n$ hexo g\n$ hexo d\n```\n\nOpen https://daydreamatnight.github.io/ to see if it works\n\n## Change theme to yilia\n\ndefault theme of hexo is called landscape and it's not beautiful enough to most of the people. Yilia is a fast, simple, elegant and popular theme. Thought it has not been updated since Nov 2017, it still a good choice for fresh bloggers.\n\n### Download and deploy yilia\n\n1.go to the blog `root`\n\n``` shell\n$ git clone https://github.com/litten/hexo-theme-yilia theme/yilia\n```\n\n2.eidt the `_config.yml` file, add\n\n```yml\ntheme: yilia\n```\n\n3.clean and deploy hexo\n\n```shell\n$ hexo clean\n$ hexo g\n$ hexo d\n```\n\n### Basic customize yillia\n\n#### Activate `aboutme` left slider button\n\n1.go to terminal run\n\n```shell\n$ npm i hexo-generator-json-content --save\n```\n\n2.go to the blog `root` directory, add these lines to the `_config.yml` file\n\n```yml\njsonContent:\n    meta: false\n    pages: false\n    posts:\n      title: true\n      date: true\n      path: true\n      text: false\n      raw: false\n      content: false\n      slug: false\n      updated: false\n      comments: false\n      link: false\n      permalink: false\n      excerpt: false\n      categories: false\n      tags: true\n```\n\n#### Customize avatar\n\nput the avatar file in directory  `themes/yilia/source/img`\n\n> do not add to the public repository directly, or the img get cleaned every time running `hexo clean` , need to upload to the same dir again after this command.\n\n#### Set favicon (icon on the tab of website)\n\nput the favicon img in directory `themes/yilia/source/img`\n\n[Bitbug](https://www.bitbug.net/) is a way of converting image into .ico file.\n\n#### Other configuration\n\nSet file of yillia is in `themes/yilia/_config.yml` as:\n\n```yml\n# Header\nauthor: Ryan LI\nsubtitle: 'Daydreaming at night'\nmenu:\n  main: /\n  archives: /archives/index.html\n  learn: /tags/learn/\n\n# SubNav\nsubnav:\n  github: \"https://github.com/DaydreamAtNight\"\n  # weibo: \"#\"\n  # rss: \"#\"\n  # zhihu: \"#\"\n  #qq: \"#\"\n  #weixin: \"#\"\n  #jianshu: \"#\"\n  #douban: \"#\"\n  #segmentfault: \"#\"\n  #bilibili: \"#\"\n  #acfun: \"#\"\n  mail: \"mailto:lishoushou2019@gmail.com\"\n  #facebook: \"#\"\n  #google: \"#\"\n  #twitter: \"#\"\n  #linkedin: \"#\"\n\nrss: /atom.xml\n\n#  root \n#  http://yoursite.com/blog\n#  url  http://yoursite.com/blog  root  /blog/\nroot: /\n\n# Content\n\n# \n# excerpt_link: more\n# false\nshow_all_link: 'show all'\n# \nmathjax: false\n# \nopen_in_new: false\n\n# \n# type0- 1-mdreward:true 2-\nreward_type: 0\n# # wording\n# reward_wording: ''\n# # /assets/img/alipay.jpg\n# alipay: \n# # \n# weixin: \n\n# \n# 0- 1-mdtoc:true 2-\ntoc: 1\n# truehexofalse\ntoc_hide_index: true\n# \ntoc_empty_wording: 'directery none exist'\n\n# \ntop: true\n\n# Miscellaneous\nbaidu_analytics: ''\ngoogle_analytics: ''\nfavicon: /img/favicon.ico\n\n#url\navatar: /img/avatar.jpeg\n\n#\n# share_jia: true\n\n# #1234Disqus5Gitment\n# #false\n# #wikihttps://github.com/litten/hexo-theme-yilia/wiki/\n\n# #1\n# duoshuo: false\n\n# #2\n# wangyiyun: false\n\n# #3\n# changyan_appid: false\n# changyan_conf: false\n\n# #4Disqus hexoconfigdisqus_shortnameyilia\n# disqus: false\n\n# #5Gitment\n# gitment_owner: false      # GitHub ID\n# gitment_repo: ''          # repo\n# gitment_oauth:\n#   client_id: ''           #client ID\n#   client_secret: ''       #client secret\n\n#  - \nstyle:\n  # \n  header: '#ece0cf'\n  # \n  slider: 'linear-gradient(45deg,#b4a698,#ece0cf)'\n\n# slider\nslider:\n  # tags\n  showTags: false\n\n# \n# false\n# \n#smart_menu:\n#  friends: false\nsmart_menu:\n  innerArchive: 'All articles'\n  # friends: ''\n  aboutme: 'About me'\n\n# friends:\n#   1: http://localhost:4000/\n#   2: http://localhost:4000/\n#   3: http://localhost:4000/\n#   4: http://localhost:4000/\n#   5: http://localhost:4000/\n#   6: http://localhost:4000/\n\naboutme: Stay hungry, stay fullish\n```\n\n## Advance customize\n\n### Stop visit litten.me:9005\n\nSometimes the user's client information is collected, see [here](https://github.com/litten/hexo-theme-yilia/issues/528) for details. \n\nStop reporting by clear the contents in `themes/yilia/source-src/js/report.js`\n\n### Limit display numbers on the main page\n\nSimply insert `<! -- more -->` to show only what comes before it while collapse the afterwards,  click on the article title to read it in full.\n\n### Easily add pics to blogs via hexo-renderer-marked plugin\n\n1.find `post_asset_folder ` in `_config.yml` file in the blog `root` directory, set to be true\n\n```yml\npost_asset_folder:true\n```\n\n2.Install plugin\n\n```shell\nnpm install hexo-renderer-marked --save\n```\n\n3.change `_config.yml` in blog `root` directory as\n\n```yml\npost_asset_folder: true\nmarked:\n  prependRoot: true\n  postAsset: true\n```\n\nthen img can be easily add with `![img description](img.png)` after add the image to the folder with the same name as the article in `/source/_posts/`\n\n4.change Typora pereference as\n\n<img src=\"typora setting.png\" alt=\"typora setting\" style=\"zoom:50%;\" />\n\nimg can drag into typro, yet blogname need to be deleted before deploying\n\n### Show number of articles and words on the left panel\n\n1.add wordcount plugin in terminal\n\n```shell\nnpm i --save hexo-wordcount\n```\n\n2.change `themes/yilia/layout/_partial/left-col.ejs` \n\nafter\n\n```html\n<nav class=\"header-menu\">\n  <ul>\n    <% for (var i in theme.menu){ %>\n      <li><a href=\"<%- url_for(theme.menu[i]) %>\"><%= i %></a></li>\n    <%}%>\n  </ul>\n</nav>\n```\n\nadd\n\n```html\n<span class=\"post-count\"><%=site.posts.length%> articles\n\t\t\t<span><%= totalcount(site, '0,0.0a') %></span> words</span>\n```\n\nadd style sheet in `themes/yilia/source/main.0cf68a.css`\n\n```\n.post-count{\n  font-size: 12px;\n  color: #696969;\n}\n```\n\n### Show number of visits in the footer\n\n[busuanzi](https://busuanzi.ibruce.info/) is in use, which is super easy to deploy\n\nchange `themes/yilia/layout/_partial/footer.ejs` as\n\n```html\n<footer id=\"footer\">\n  <div class=\"outer\">\n    <div id=\"footer-info\">\n    \t<div class=\"footer-left\">\n    \t\t<!-- total visits number -->\n          <% if (theme.busuanzi && theme.busuanzi.enable){ %>\n            <!-- busuanzi statistics -->\n            <span id=\"busuanzi_value_site_pv\"></span>&nbsp;visits in total\n            <script async src=\"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"></script>\n          <% } %>\n        <!-- end -->\n    \t</div>\n      \t<div class=\"footer-right\">\n      \t\t&copy; <%= date(new Date(), 'YYYY') %> <%= config.author || config.title %>\n      \t</div>\n    </div>\n  </div>\n</footer>\n```\n\nand add \n\n```yml\nbusuanzi:\n  enable: true\n```\n\n### Add button of hiding the left panel\n\nRefer to  [hexo yilia](https://cqh-i.github.io/2019/08/07/hexo-yilia%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E9%9A%90%E8%97%8F%E5%B7%A6%E8%BE%B9%E6%A0%8F%E7%9B%AE%E6%8C%89%E9%92%AE/ )  \n\n1.add style list to file ` /themes/yilia/source/main.0cf68a.css `\n\n```css\n/*stylesheet for hide the left panel*/\n.mymenucontainer {\n\tdisplay:block;\n\tcursor:pointer;\n\tleft:0;\n\ttop:0;\n\twidth:35px;\n\theight:35px;\n\tz-index:9999;\n\tposition:fixed;\n}\n.bar1 {\n\twidth:35px;\n\theight:3px;\n\tborder-radius:3px;\n\tbackground-color:#8E6D51;\n\tmargin:6px 0;\n\ttransition:0.1s;\n\t-webkit-transform:rotate(-45deg) translate(-8px,8px);\n\ttransform:rotate(-45deg) translate(-8px,8px);\n}\n.bar2 {\n\twidth:35px;\n\theight:3px;\n\tborder-radius:3px;\n\tbackground-color:#8E6D51;\n\tmargin:6px 0;\n\ttransition:0.1s;\n\topacity:0;\n}\n.bar3 {\n\twidth:35px;\n\theight:3px;\n\tborder-radius:3px;\n\tbackground-color:#8E6D51;\n\tmargin:6px 0;\n\ttransition:0.1s;\n\t-webkit-transform:rotate(45deg) translate(-4px,-6px);\n\ttransform:rotate(45deg) translate(-4px,-6px);\n}\n.change .bar1 {\n\t-webkit-transform:rotate(0deg) translate(0px,0px);\n\ttransform:rotate(0deg) translate(0px,0px);\n}\n.change .bar2 {\n\topacity:1;\n}\n.change .bar3 {\n\t-webkit-transform:rotate(0deg) translate(0px,0px);\n\ttransform:rotate(0deg) translate(0px,0px);\n}\n/*stylesheet for hide the left panel end*/\n```\n\n2.go to ` /themes/yilia/layout/layout.ejs ` add before `  <div class=\"left-col\"  ` \n\n```html\n<div class=\"mymenucontainer\" onclick=\"myFunction(this)\">\n  <div class=\"bar1\"></div>\n  <div class=\"bar2\"></div>\n  <div class=\"bar3\"></div>\n</div>\n```\n\n3.add between ` </body> ` and ` </html> ` \n\n```js\n<script>\n    var hide = false;\n    function myFunction(x) {\n        x.classList.toggle(\"change\");\n        if(hide == false){\n            $(\".left-col\").css('display', 'none');\n            $(\".mid-col\").css(\"left\", 6);\n            $(\".tools-col\").css('display', 'none');\n            $(\".tools-col.hide\").css('display', 'none');\n            hide = true;\n        }else{\n            $(\".left-col\").css('display', '');\n            $(\".mid-col\").css(\"left\", 300);\n            $(\".tools-col\").css('display', '');\n            $(\".tools-col.hide\").css('display', '');\n            hide = false;\n        }\n    }\n</script>\n```\n\n\n\n\n\n### Beautiful contents navigation in articles\n\nDefault navigator is kind of ugly so found a more beautiful version, to use default version, simply change `toc: 2` in file `themes/yilia/_config.yml`\n\n1.add this block at the end of `themes/yilia/source/main.0cf68a.css`\n\n```css\n/* navigator */\n#container .show-toc-btn,#container .toc-article{display:block}\n.toc-article{z-index:100;background:#fff;border:1px solid #ccc;max-width:250px;min-width:150px;max-height:500px;overflow-y:auto;-webkit-box-shadow:5px 5px 2px #ccc;box-shadow:5px 5px 2px #ccc;font-size:12px;padding:10px;position:fixed;right:35px;top:129px}.toc-article .toc-close{font-weight:700;font-size:20px;cursor:pointer;float:right;color:#ccc}.toc-article .toc-close:hover{color:#000}.toc-article .toc{font-size:12px;padding:0;line-height:20px}.toc-article .toc .toc-number{color:#333}.toc-article .toc .toc-text:hover{text-decoration:underline;color:#2a6496}.toc-article li{list-style-type:none}.toc-article .toc-level-1{margin:4px 0}.toc-article .toc-child{}@-moz-keyframes cd-bounce-1{0%{opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}60%{opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)}100%{-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}}@-webkit-keyframes cd-bounce-1{0%{opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}60%{opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)}100%{-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}}@-o-keyframes cd-bounce-1{0%{opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}60%{opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)}100%{-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}}@keyframes cd-bounce-1{0%{opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}60%{opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)}100%{-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}}.show-toc-btn{display:none;z-index:10;width:30px;min-height:14px;overflow:hidden;padding:4px 6px 8px 5px;border:1px solid #ddd;border-right:none;position:fixed;right:40px;text-align:center;background-color:#f9f9f9}.show-toc-btn .btn-bg{margin-top:2px;display:block;width:16px;height:14px;background:url(http://7xtawy.com1.z0.glb.clouddn.com/show.png) no-repeat;-webkit-background-size:100%;-moz-background-size:100%;background-size:100%}.show-toc-btn .btn-text{color:#999;font-size:12px}.show-toc-btn:hover{cursor:pointer}.show-toc-btn:hover .btn-bg{background-position:0 -16px}.show-toc-btn:hover .btn-text{font-size:12px;color:#ea8010}\n.toc-article li ol, .toc-article li ul {\n    margin-left: 30px;\n}\n.toc-article ol, .toc-article ul {\n    margin: 10px 0;\n}\n```\n\n2.after `</header><% } %>` in file `themes/yilia/layout/_partial/article.ejs` add\n\n```html\n    <!-- navigator -->\n    <% if (!index && post.toc){ %>\n      <p class=\"show-toc-btn\" id=\"show-toc-btn\" onclick=\"showToc();\" style=\"display:none\">\n            <span class=\"btn-bg\"></span>\n            <span class=\"btn-text\">...</span>\n            </p>\n      <div id=\"toc-article\" class=\"toc-article\">\n          <span id=\"toc-close\" class=\"toc-close\" title=\"hide navigator\" onclick=\"showBtn();\"></span>\n          <strong class=\"toc-title\">navigator</strong>\n            <%- toc(post.content) %>\n          </div>\n    <script type=\"text/javascript\">\n      function showToc(){\n          var toc_article = document.getElementById(\"toc-article\");\n          var show_toc_btn = document.getElementById(\"show-toc-btn\");\n          toc_article.setAttribute(\"style\",\"display:block\");\n          show_toc_btn.setAttribute(\"style\",\"display:none\");\n          };\n      function showBtn(){\n          var toc_article = document.getElementById(\"toc-article\");\n          var show_toc_btn = document.getElementById(\"show-toc-btn\");\n          toc_article.setAttribute(\"style\",\"display:none\");\n          show_toc_btn.setAttribute(\"style\",\"display:block\");\n          };\n    </script>\n        <% } %>\n    <!-- navigator end -->\n```\n\n3.add `toc:true` to the articles that need the navigator.\n\n### Add custormize header to articles\n\nwhen run `hexo new` to initiate a new blog, a defaul head would generate, change it by\n\nchange the `scaffolds/post.md` in the `root` directory\n\n```txt\n---\ntitle: {{ title }}\ndate: {{ date }}\nauthor: daydreamatnight\ntoc: true\ndeclare: true\ntags:\n---\n```\n\n#### more headers to choose when writing a blog\n\nbefore a blog, more paras can be chosen to add\n\n```txt\n--- \ntitle: # \ntoc: ture #toc \ndate: 2020-09-07 09:25:00 # \nauthor: GavenLee # \nimg: /source/images/xxx.jpg # \ntop: true # \ncover: true # \ncoverImg: /images/1.jpg # \npassword: # \nmathjax: false #mathjax \nsummary:  \ncategories: Markdown # \ntags: # \nabbrlink: HexoLearn # \n---\n```\n\n### Disable auto wrap in code block\n\nlocate and delete `white-space:pre-wrap` in file `themes/yilia/source/main.0cf68a.css` \n\n### Add copy button to code block\n\n1.create a `clipboard_use.js` file in directory `themes/yilia/source` \n\n```js\n$(\".highlight\").wrap(\"<div class='code-wrapper' style='position:relative'></div>\");\n/*create copy button after page loaded*/\n!function (e, t, a) {\n    /* code */\n    var initCopyCode = function () {\n        var copyHtml = '';\n        copyHtml += '<button class=\"btn-copy\" data-clipboard-snippet=\"\">';\n        copyHtml += '  <i class=\"fa fa-clipboard\"></i><span>copy</span>';\n        copyHtml += '</button>';\n        $(\".highlight .code\").before(copyHtml);\n        var clipboard = new ClipboardJS('.btn-copy', {\n            target: function (trigger) {\n                return trigger.nextElementSibling;\n            }\n        });\n        clipboard.on('success', function (e) {\n            e.trigger.innerHTML = \"<i class='fa fa-check' style='color:green'></i><span style='color:green'>copy success</span>\"\n            setTimeout(function () {\n                e.trigger.innerHTML = \"<i class='fa fa-clipboard'></i><span>copy</span>\"\n            }, 1000)\n            e.clearSelection();\n        });\n        clipboard.on('error', function (e) {\n            e.trigger.innerHTML = \"<i class='fa fa-exclamation' style='color:red'></i><span style='color:red'>copy success</span>\"\n            setTimeout(function () {\n                e.trigger.innerHTML = \"<i class='fa fa-clipboard'></i><span>copy</span>\"\n            }, 1000)\n            e.clearSelection();\n        });\n    }\n    initCopyCode();\n}(window, document);\n```\n\n2.load .js file, edit `themes/yilia/layout/layout.ejs` file, add before `</body>`. \n\n```html\n<!-- copy button in code block-->\n<script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.js\"></script>\n<script type=\"text/javascript\" src=\"https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js\"></script>\n<script type=\"text/javascript\" src=\"/clipboard_use.js\"></script>\n```\n\n3.add stylesheet the end of `themes/yilia/source/main.0cf68a.css`\n\n```css\n/* code copy button */\n.btn-copy {\n  display: inline-block;\n  cursor: pointer;\n  background-color: #eee;\n  background-image: linear-gradient(#fcfcfc, #eee);\n  border: 1px solid #d5d5d5;\n  border-radius: 3px;\n  -webkit-user-select: none;\n  -moz-user-select: none;\n  -ms-user-select: none;\n  user-select: none;\n  -webkit-appearance: none;\n  font-size: 13px;\n  font-weight: 700;\n  line-height: 20px;\n  color: #333;\n  -webkit-transition: opacity .3s ease-in-out;\n  -o-transition: opacity .3s ease-in-out;\n  transition: opacity .3s ease-in-out;\n  padding: 2px 6px;\n  position: absolute;\n  right: 5px;\n  top: 5px;\n  opacity: 0;\n}\n.btn-copy span {\n  margin-left: 5px;\n}\n.highlight:hover .btn-copy {\n  opacity: 1;\n}\n/* code copy button end */\n```\n\n4.add copy button icon, edit `themes/yilia/layout/_partia/head.ejs` add before `</head>` \n\n```html\n<!-- copy button icon -->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css\">\n```\n\n### Allow search engines to index this Blog\n\n#### index Google to this Blog\n\ncheck if google can find you, enter `site:daydreamatnight.github.io` to see\n\n<img src=\"check google search.png\" alt=\"check google search\" style=\"zoom:50%;\" />\n\n##### Add url to goole search console\n\n1.open [google console](https://search.google.com/search-console/welcome) , add URL link of the blog (https://daydreamatnight.github.io), in the `URL prefix` block, click `CONTINUE`\n\n<img src=\"google search console.png\" alt=\"google console\" style=\"zoom:50%;\" />\n\n2.upload the html file to the blog `root` directory and deploy the website, then clicke verify.\n\n<img src=\"google console varification.png\" alt=\"google console varification\" style=\"zoom:50%;\" />\n\nlittle buggy here, see [**dont upload** the file **using hexo** command](https://hilyy.xyz/how-to-allow-google-to-index-your-hexo-blog-website-google-search-console-verification-methods/)\n\n##### add sitemap for google\n\nadd sitemap for google and baidu together\n\n> A *sitemap* is a file where you provide information about the pages, videos, and other files on your site, and the relationships between them. Search engines like Google read this file to more intelligently crawl your site. A sitemap tells Google which pages and files you think are important in your site, and also provides valuable information about these files: for example, for pages, when the page was last updated, how often the page is changed, and any alternate language versions of a page.\n\n1.install sitemap plugins\t\n\n```shell\n$ npm install hexo-generator-sitemap --save\n$ npm install hexo-generator-baidu-sitemap --save\n```\n\n2.add to the `_config.yml` in the blog `root` \n\n```yml\n# hexo sitemap\nsitemap:\n  path: sitemap.xml\nbaidusitemap:\n  path: baidusitemap.xml\n```\n\n3.Deploy the blog, go to  https://daydreamatnight.github.io/sitemap.xml and https://daydreamatnight.github.io/baidusitemap.xml to see if sitemaps are uploaded\n\n4.Go to Google Search Console, in the left panel, click `Sitemaps`, enter your sitemap URL `sitemap.xml` \n\n<img src=\"can't fetch sitemap.png\" alt=\"can't fetch sitemap\" style=\"zoom:50%;\" />\n\nGooglebot won't download the sitemap immediately. Give it time. \n\n##### add robots.txt\n\n> A robots.txt file tells search engine crawlers which URLs the crawler can access on your site. This is used mainly to avoid overloading your site with requests; **it is not a mechanism for keeping a web page out of Google**. To keep a web page out of Google, [block indexing with `noindex`](https://developers.google.com/search/docs/advanced/crawling/block-indexing) or password-protect the page.\n>\n> A robots.txt file is used primarily to manage crawler traffic to your site, and *usually* to keep a file off Google, depending on the file type:\n\n```txt\nUser-agent: *\nAllow: /\nAllow: /archives/\nAllow: /tags/\nAllow: /categories/\nAllow: /about/\nAllow: /guestbook/\nAllow: /others/\n\n\nDisallow: /js/\nDisallow: /css/\nDisallow: /lib/\n\nSitemap: https://daydreamatnight.github.io/sitemap.xml\nSitemap: https://daydreamatnight.github.io/baidusitemap.xml\n```\n\ndeploy the blog and wait.\n\n##### check if sitemap is available\n\nAfter uploaded several updates, my sitemap still didn't fetched by google. So I went to check, it turns out my url setting in `_config.yml` is wrong.  So I changed it to be my home url. And check it with  [URL Inspection Tool](https://www.jcchouinard.com/url-inspection-tool/). \n\n1.Open [google search console](https://search.google.com/search-console), add the url of sitemap in the upper url inspecting box.\n\n<img src=\"Google%20sitemap%20inspect.png\" alt=\"Google sitemap inspect URL is not on Google \" style=\"zoom:22%;\" />\n\n<img src=\"Google%20sitemap%20inspect%202.png\" alt=\"Google sitemap inspect 2\" style=\"zoom:22%;\" />\n\nIt's normal it shows `URL is not on Google` because it shouldn't as a sitemap.\n\n2.click `live test` to check the availability.\n\n<img src=\"Google%20sitemap%20inspect%203.png\" alt=\"Google sitemap inspect 3\" style=\"zoom:75%;\" />\n\nIt should be available, then just wait.\n\n#### index Bing to this Blog\n\n1.go to [Bing webmaster](https://www.bing.com/webmasters/) and login\n\n2.connect with google webmaster.\n\n<img src=\"bing%20sitemap.png\" alt=\"bing sitemap\" style=\"zoom:75%;\" />\n\n  \n\n<img src=\"being%20sitemap%20connect%20google.png\" alt=\"being sitemap connect google\" style=\"zoom:75%;\" />\n\n  \n\n<img src=\"bing%20search%20console%20success.png\" alt=\"bing search console success\" style=\"zoom:75%;\" />\n\n#### index baidu to this Blog(not possibly working)\n\ngo to the [baidu search console](https://ziyuan.baidu.com/site/index) , \n\n<img src=\"baidu console.png\" alt=\"baidu console\" style=\"zoom:50%;\" />\n\nClick `` and input every thing, do similar thing\n\n<img src=\"baidu console varification.png\" alt=\"baidu console varification\" style=\"zoom:50%;\" />\n\nadd sitemap\n\n<img src=\"baidu console sitemap.png\" alt=\"baidu console sitemap\" style=\"zoom:50%;\" />\n\njust wait forever, this could take 2000 years, so give up\n\n### Add copyright statement\n\n1.open file `themes/yilia/layout/_partial/article.ejs` add before `<% if ((theme.reward_type === 2 || (theme.reward_type === 1 && post.reward)) && !index){ %>`\n\n```html\n<!-- add copyright statement -->\n<% if(theme.declare){%>\n    <%- partial('post/declare') %>\n<% } %>\n<!-- end -->\n```\n\n2.create new file `declare.ejs` under `themes/yilia/layout/_partial/post/` with:\n\n```html\n<!--add copyright statement https://github.com/JoeyBling/hexo-theme-yilia-plus/commit/c1215e132f6d5621c5fea83d3c4f7ccbcca074a3-->\n<%\n  var sUrl = url.replace(/index\\.html$/, '');\n  sUrl = /^(http:|https:)\\/\\//.test(sUrl) ? sUrl : 'https:' + sUrl;\n%>\n\n<!-- #copyright setting0-close statement; 1-declare statement if declare: true in the article header; 2-always declare the copyright -->\n<% if ((theme.declare.declare_type === 2 || (theme.declare.declare_type === 1 && post.declare)) && !index){ %>\n  <div class=\"declare\">\n    <strong class=\"author\">author: </strong>\n    <% if(config.author != undefined){ %>\n      <%= config.author%>\n    <% }else{%>\n      <font color=\"red\">please add right \"author\" name in \"_config.yml\" in the blog root</font>\n    <%}%>\n    <br>\n    <strong class=\"create-time\">posting date: </strong>\n    <%- date(post.date, 'YYYY-MM-DD HH:MM:SS') %>\n    <br>\n    <strong class=\"update-time\">last update: </strong>\n    <%- date(post.updated, 'YYYY-MM-DD HH:MM:SS') %>\n    <br>\n    <strong class=\"article-titles\">article title: </strong>\n    <a href=\"<%= config.url %>/<%= post.path %>\" title=\"<%= post.title %>\" target=\"_blank\"><%= post.title %></a>\n    <br>\n    <strong class=\"article-url\">article link: </strong>\n    <a href=\"<%= config.url %>/<%= post.path %>\" title=\"<%= post.title %>\" target=\"_blank\"><%= config.url %>/<%= post.path %></a>\n    <br>\n    <strong class=\"copyright\">copyright:</strong>\n    This work is licensed under a\n    <a rel=\"license\" href=\"<%= theme.declare.licensee_url%>\" title=\"<%= theme.declare.licensee_alias %>\"><%= theme.declare.licensee_name%></a>\n    licience \n    <% if(theme.declare.licensee_img != undefined){ %>\n      <a rel=\"license\" href=\"<%= theme.declare.licensee_url%>\"><img alt=\"\" style=\"border-width:0\" src=\"<%= theme.declare.licensee_img%>\"/></a>\n    <% } %>\n  </div>\n<% } else {%>\n  <div class=\"declare\" hidden=\"hidden\"></div>\n<% } %>\n<!-- add copyright statement -->\n```\n\n3.add stylesheet the end of `themes/yilia/source/main.0cf68a.css` \n\n```css\n/*stylesheet for the delcare*/\n.declare {\n  background-color: #eaeaea;\n  margin-top: 2em;\n  border-left: 3px solid #ff1700;\n  padding: .5em 1em; \n}\n/*stylesheet for the delcare end*/\n```\n\n4.add at the end of `themes/yilia/_config.yml` file:\n\n```\ndeclare:\n  declare_type: 1\n  licensee_url: http://creativecommons.org/licenses/by-nc-sa/4.0/      \n  licensee_name: 'CC BY-NC-SA 4.0'                              \n  licensee_alias: 'CC BY-NC-SA 4.0'     \n  licensee_img: https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png\n```\n\n### Add mind-map support\n\n```shell\nnpm install hexo-markmap\n```\n\nDetailed in its [Github](https://github.com/MaxChang3/hexo-markmap)\n\nExample:\n\n```\n{% markmap 300px %}\n- Testa\n  - test1\n  - test2\n- Testb\n  - test1\n  - test2\n{%endmarkmap%}\n```\n\n### Add Latex math support\n\nChange the renderer to the more powerful pandoc:\n\n1.Install pandoc on macOS:\n\n```\ncopybrew install pandoc\n```\n\n2.in the blog root directory uninstall the default renderer then install the pandoc renderer:\n\n```\ncopynpm uninstall hexo-renderer-marked --save\nnpm install hexo-renderer-pandoc --save\n```\n\n3.install the hexo math plugin\n\n```\ncopynpm install hexo-math --save\n```\n\n4.add these lines to the hexo `_config` file\n\n```\ncopymarkdown:\n  plugins:\n    - markdown-it-footnote\n    - markdown-it-sup\n    - markdown-it-sub\n    - markdown-it-abbr\n    - markdown-it-emoji\n    - hexo-math\n```\n\n5.add these lines to the theme `_config` file\n\n```\ncopy# MathJax Support\nmathjax:\n  enable: true\n  per_page: true\n```\n\n6.rebuild the to blog see changes\n\n7.Examples: $this_{is}an\\frac{inline}{equation}$\n$$\n\\begin{equation}\n    \\mathbf{K}_\\mathbf{1}=\\frac{1}{\\Delta r}\\ \\left[\\begin{matrix}\\begin{matrix}-1&1\\\\-1&1\\\\\\end{matrix}&\\ &\\ \\\\\\begin{matrix}\\ &\\ddots\\\\\\end{matrix}&\\begin{matrix}\\ddots&\\ \\\\\\end{matrix}&\\ \\\\\\ &-1\\ &1\\\\\\end{matrix}\\right],\\ \\ {\\ \\mathbf{K}}_\\mathbf{2}=\\frac{1}{\\Delta r}\\ \\left[\\begin{matrix}\\begin{matrix}-1&1\\\\\\ &\\ddots\\\\\\end{matrix}&\\begin{matrix}\\\\\\ddots\\\\\\end{matrix}&\\ \\\\\\begin{matrix}\\ &\\ \\\\\\end{matrix}&-1&1\\ \\\\\\ &-1\\ &1\\\\\\end{matrix}\\right]\n    \\label{K2}\n\\end{equation}\n$$\n\n### The last snapshot\n\nOk, never spend time on a no-longer maintained project. Here's the last figure of it.\n\n<img src=\"Last snapshot.png\" alt=\"Last snapshot\" style=\"zoom:80%;\" />\n\n## Reference\n\nhttps://flatironschool.com/blog/the-benefits-of-blogging-how-and-why-to-keep-a-technical-blog/\n\nhttps://weblog.masukomi.org/2015/10/18/static-vs-dynamic-blogging/\n\nhttps://www.cnblogs.com/aoguai/p/11781505.html\n\nhttps://www.kblog.top/post/30452.html\n\nhttps://wkzqn.gitee.io/2020/02/16/typora%E7%BC%96%E5%86%99hexo%E5%8D%9A%E5%AE%A2%E6%97%B6%E7%9A%84%E5%9B%BE%E7%89%87%E6%98%BE%E7%A4%BA/\n\nhttps://segmentfault.com/a/1190000009478837#articleHeader5\n\nhttps://hilyy.xyz/how-to-allow-google-to-index-your-hexo-blog-website-google-search-console-verification-methods/\n\nhttps://busuanzi.ibruce.info/\n\nhttps://creativecommons.org/choose/results-one?license_code=by-nc-sa&amp;jurisdiction=&amp;version=4.0&amp;lang=en\n\nhttps://www.jcchouinard.com/sitemap-could-not-be-read-couldnt-fetch-in-google-search-console/\n\nhttps://cqh-i.github.io/2019/08/07/hexo-yilia%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E9%9A%90%E8%97%8F%E5%B7%A6%E8%BE%B9%E6%A0%8F%E7%9B%AE%E6%8C%89%E9%92%AE/","source":"_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia.md","raw":"---\ntitle: Build and configure a personal blog via hexo and yilia on github\ndate: 2022-02-22 16:15:03\ntoc: true\ndeclare: true\ntags: \n  - hexo\n  - blog\n---\n\n> Technical blog has a hundred benefits and no harm\n>\n> This blog records the process of building and customizing this personal blog from 0 to 1\n\n> Unfortunately, the yilia theme has been no longer updating and it is too buggy right now. I switch to [other theme.](/2022/04/30/Switch-blog-theme-to-FLUID/)\n\n<!-- more -->\n\n## Preliminary\n\n### Why personal blog\n\n> Keeping a technical blog can be **a great way of documenting your growth as a developer**. This documentation can be particularly useful on a professional level. All software companies want to hire smart, thoughtful, communicative developers who can easily assimilate into a team, and who are ready to both teach and learn\n\n### Static vs dynamic blog\n\nthere are 2 types of mainstream personal blog: static and dynamic.\n\nStatic is recommended considering its simplicity, 0 maintenance and 0 safety worry. \n\n|              | Static blog                                                  | Dynamic blog                                                 |\n| :----------- | :----------------------------------------------------------- | :----------------------------------------------------------- |\n| Price        | low, 0 cost when the traffic is relatively low               | High, server is needed, cloud server of  high performance is usually very expensive. |\n| Features     | Limited, only third-party services can be used to complete certain \"dynamic\" functions, such as comments | Rich, in WordPress for example, basically any kind of plugins can be found. Featuers such as auto-resizing, media players, multiple authors, scheduled posts, user analysis can be easily realize. |\n| Speed        | Fast                                                         | Slow                                                         |\n| Maintainance | 0                                                            | Need to care about the sever                                 |\n| Markdown     | Supported yet it's the only choice                           | not supported                                                |\n| Geeky        | YES                                                          | No                                                           |\n\nAnd I also chose static because I'm geeky (poor of money) and results-driven (lazy to spend time on maintaining).\n\n## Build a static blog via hexo\n\n### Set environment\n\n1.check machine information: macOS on M1 MacBook\n\n2.Install Nodejs, including node and npm\n\nopen  https://nodejs.org/en/download/ and click download\n\n<img src=\"node js install.png\" alt=\"node js install\" style=\"zoom:50%;\" />\n\n3.Install Git\n\nAready installed\n\n4.Open terminal, check node, npm and git versions\n\n```shell\n$ npm -v\n$ node -v\n$ git --version\n8.3.1\nv16.14.0\ngit version 2.32.0 (Apple Git-132)\n```\n\n### Initialize blog\n\n1.install hexo via npm\n\n```shell\n$ sudo npm install -g hexo-cli\n$ hexo -v\nINFO  Validating config\nhexo: 6.0.0\nhexo-cli: 4.3.0\nos: darwin 21.2.0 12.1\n\nnode: 16.14.0\nv8: 9.4.146.24-node.20\nuv: 1.43.0\nzlib: 1.2.11\nbrotli: 1.0.9\nares: 1.18.1\nmodules: 93\nnghttp2: 1.45.1\nnapi: 8\nllhttp: 6.0.4\nopenssl: 1.1.1m+quic\ncldr: 40.0\nicu: 70.1\ntz: 2021a3\nunicode: 14.0\nngtcp2: 0.1.0-DEV\nnghttp3: 0.1.0-DEV\n```\n\n2.create a new folder in terminal and initialize the blog\n\n```shell\n$ cd ~/Documents/\n$ makedir self_blog\n$ cd self_blog/\n$ hexo init\nINFO  Cloning hexo-starter https://github.com/hexojs/hexo-starter.gitINFO  Install dependencies#########  idealTree:hexo-front-matter: timing idealTree:node_modules/hexo-front-matter Completed in 212msINFO  Start blogging with Hexo! \n```\n\n3.view the blog on localhost, s for start\n\n```shell\n$ hexo s\nINFO  Validating config\nINFO  Start processing\nINFO  Hexo is running at http://localhost:4000/ . Press Ctrl+C to stop.\n```\n\n\n### Write first blog\n\n1.write a new blog, n for new\n\n```shell\n$ hexo n 'Hello ShouRou'\nINFO  Validating config\nINFO  Created: ~/Documents/self_blog/source/_posts/Hello-ShouRou.md\n```\n\nthe blog can be written on any editor, Typora in use.\n\n```shell\nopen ~/Documents/self_blog/source/_posts/Hello-ShouRou.md\n```\n\n2.clean cache(not necessary)\n\n```shell\n$ hexo clean\n```\n\n3.generate the blog, g for generate\n\n```shell\n$ hexo g\nINFO  Validating config\nINFO  Start processing\nINFO  Files loaded in 61 ms\n(node:10719) Warning: Accessing non-existent property 'lineno' of module exports inside circular dependency\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:10719) Warning: Accessing non-existent property 'column' of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property 'filename' of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property 'lineno' of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property 'column' of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property 'filename' of module exports inside circular dependency\nINFO  Generated: archives/2022/index.html\nINFO  Generated: archives/index.html\nINFO  Generated: js/script.js\nINFO  Generated: fancybox/jquery.fancybox.min.css\nINFO  Generated: index.html\nINFO  Generated: css/style.css\nINFO  Generated: css/fonts/fontawesome-webfont.woff2\nINFO  Generated: fancybox/jquery.fancybox.min.js\nINFO  Generated: js/jquery-3.4.1.min.js\nINFO  Generated: archives/2022/02/index.html\nINFO  Generated: css/fonts/FontAwesome.otf\nINFO  Generated: css/fonts/fontawesome-webfont.woff\nINFO  Generated: css/fonts/fontawesome-webfont.eot\nINFO  Generated: css/fonts/fontawesome-webfont.ttf\nINFO  Generated: css/images/banner.jpg\nINFO  Generated: 2022/02/22/hello-world/index.html\nINFO  Generated: css/fonts/fontawesome-webfont.svg\nINFO  Generated: 2022/02/22/Hello-ShouRou/index.html\nINFO  18 files generated in 161 ms\n```\n\n### Deploy to remote (GitHub)\n\n1.Create a new repository with the name of $username.github.io\n\n<img src=\"github page.png\" alt=\"github page\" style=\"zoom:50%;\" />\n\nuse default setting\n\n2.open terminal, install plugin of deploying to git\n\n```shell\n$ npm install --save hexo-deployer-git\n```\n\n3.Open the `_config.yml` file in the blog `root` directory, add these lines afterwards\n\n```yml\ndeploy:\n type: git\n repo: git@github.com:DaydreamAtNight/DaydreamAtNight.github.io.git\n branch: master\n```\n\n4.Go to the blog `root`, deploy the blog to remote, d for deploy\n\n```shell\n$ hexo clean\n$ hexo g\n$ hexo d\n```\n\nOpen https://daydreamatnight.github.io/ to see if it works\n\n## Change theme to yilia\n\ndefault theme of hexo is called landscape and it's not beautiful enough to most of the people. Yilia is a fast, simple, elegant and popular theme. Thought it has not been updated since Nov 2017, it still a good choice for fresh bloggers.\n\n### Download and deploy yilia\n\n1.go to the blog `root`\n\n``` shell\n$ git clone https://github.com/litten/hexo-theme-yilia theme/yilia\n```\n\n2.eidt the `_config.yml` file, add\n\n```yml\ntheme: yilia\n```\n\n3.clean and deploy hexo\n\n```shell\n$ hexo clean\n$ hexo g\n$ hexo d\n```\n\n### Basic customize yillia\n\n#### Activate `aboutme` left slider button\n\n1.go to terminal run\n\n```shell\n$ npm i hexo-generator-json-content --save\n```\n\n2.go to the blog `root` directory, add these lines to the `_config.yml` file\n\n```yml\njsonContent:\n    meta: false\n    pages: false\n    posts:\n      title: true\n      date: true\n      path: true\n      text: false\n      raw: false\n      content: false\n      slug: false\n      updated: false\n      comments: false\n      link: false\n      permalink: false\n      excerpt: false\n      categories: false\n      tags: true\n```\n\n#### Customize avatar\n\nput the avatar file in directory  `themes/yilia/source/img`\n\n> do not add to the public repository directly, or the img get cleaned every time running `hexo clean` , need to upload to the same dir again after this command.\n\n#### Set favicon (icon on the tab of website)\n\nput the favicon img in directory `themes/yilia/source/img`\n\n[Bitbug](https://www.bitbug.net/) is a way of converting image into .ico file.\n\n#### Other configuration\n\nSet file of yillia is in `themes/yilia/_config.yml` as:\n\n```yml\n# Header\nauthor: Ryan LI\nsubtitle: 'Daydreaming at night'\nmenu:\n  main: /\n  archives: /archives/index.html\n  learn: /tags/learn/\n\n# SubNav\nsubnav:\n  github: \"https://github.com/DaydreamAtNight\"\n  # weibo: \"#\"\n  # rss: \"#\"\n  # zhihu: \"#\"\n  #qq: \"#\"\n  #weixin: \"#\"\n  #jianshu: \"#\"\n  #douban: \"#\"\n  #segmentfault: \"#\"\n  #bilibili: \"#\"\n  #acfun: \"#\"\n  mail: \"mailto:lishoushou2019@gmail.com\"\n  #facebook: \"#\"\n  #google: \"#\"\n  #twitter: \"#\"\n  #linkedin: \"#\"\n\nrss: /atom.xml\n\n#  root \n#  http://yoursite.com/blog\n#  url  http://yoursite.com/blog  root  /blog/\nroot: /\n\n# Content\n\n# \n# excerpt_link: more\n# false\nshow_all_link: 'show all'\n# \nmathjax: false\n# \nopen_in_new: false\n\n# \n# type0- 1-mdreward:true 2-\nreward_type: 0\n# # wording\n# reward_wording: ''\n# # /assets/img/alipay.jpg\n# alipay: \n# # \n# weixin: \n\n# \n# 0- 1-mdtoc:true 2-\ntoc: 1\n# truehexofalse\ntoc_hide_index: true\n# \ntoc_empty_wording: 'directery none exist'\n\n# \ntop: true\n\n# Miscellaneous\nbaidu_analytics: ''\ngoogle_analytics: ''\nfavicon: /img/favicon.ico\n\n#url\navatar: /img/avatar.jpeg\n\n#\n# share_jia: true\n\n# #1234Disqus5Gitment\n# #false\n# #wikihttps://github.com/litten/hexo-theme-yilia/wiki/\n\n# #1\n# duoshuo: false\n\n# #2\n# wangyiyun: false\n\n# #3\n# changyan_appid: false\n# changyan_conf: false\n\n# #4Disqus hexoconfigdisqus_shortnameyilia\n# disqus: false\n\n# #5Gitment\n# gitment_owner: false      # GitHub ID\n# gitment_repo: ''          # repo\n# gitment_oauth:\n#   client_id: ''           #client ID\n#   client_secret: ''       #client secret\n\n#  - \nstyle:\n  # \n  header: '#ece0cf'\n  # \n  slider: 'linear-gradient(45deg,#b4a698,#ece0cf)'\n\n# slider\nslider:\n  # tags\n  showTags: false\n\n# \n# false\n# \n#smart_menu:\n#  friends: false\nsmart_menu:\n  innerArchive: 'All articles'\n  # friends: ''\n  aboutme: 'About me'\n\n# friends:\n#   1: http://localhost:4000/\n#   2: http://localhost:4000/\n#   3: http://localhost:4000/\n#   4: http://localhost:4000/\n#   5: http://localhost:4000/\n#   6: http://localhost:4000/\n\naboutme: Stay hungry, stay fullish\n```\n\n## Advance customize\n\n### Stop visit litten.me:9005\n\nSometimes the user's client information is collected, see [here](https://github.com/litten/hexo-theme-yilia/issues/528) for details. \n\nStop reporting by clear the contents in `themes/yilia/source-src/js/report.js`\n\n### Limit display numbers on the main page\n\nSimply insert `<! -- more -->` to show only what comes before it while collapse the afterwards,  click on the article title to read it in full.\n\n### Easily add pics to blogs via hexo-renderer-marked plugin\n\n1.find `post_asset_folder ` in `_config.yml` file in the blog `root` directory, set to be true\n\n```yml\npost_asset_folder:true\n```\n\n2.Install plugin\n\n```shell\nnpm install hexo-renderer-marked --save\n```\n\n3.change `_config.yml` in blog `root` directory as\n\n```yml\npost_asset_folder: true\nmarked:\n  prependRoot: true\n  postAsset: true\n```\n\nthen img can be easily add with `![img description](img.png)` after add the image to the folder with the same name as the article in `/source/_posts/`\n\n4.change Typora pereference as\n\n<img src=\"typora setting.png\" alt=\"typora setting\" style=\"zoom:50%;\" />\n\nimg can drag into typro, yet blogname need to be deleted before deploying\n\n### Show number of articles and words on the left panel\n\n1.add wordcount plugin in terminal\n\n```shell\nnpm i --save hexo-wordcount\n```\n\n2.change `themes/yilia/layout/_partial/left-col.ejs` \n\nafter\n\n```html\n<nav class=\"header-menu\">\n  <ul>\n    <% for (var i in theme.menu){ %>\n      <li><a href=\"<%- url_for(theme.menu[i]) %>\"><%= i %></a></li>\n    <%}%>\n  </ul>\n</nav>\n```\n\nadd\n\n```html\n<span class=\"post-count\"><%=site.posts.length%> articles\n\t\t\t<span><%= totalcount(site, '0,0.0a') %></span> words</span>\n```\n\nadd style sheet in `themes/yilia/source/main.0cf68a.css`\n\n```\n.post-count{\n  font-size: 12px;\n  color: #696969;\n}\n```\n\n### Show number of visits in the footer\n\n[busuanzi](https://busuanzi.ibruce.info/) is in use, which is super easy to deploy\n\nchange `themes/yilia/layout/_partial/footer.ejs` as\n\n```html\n<footer id=\"footer\">\n  <div class=\"outer\">\n    <div id=\"footer-info\">\n    \t<div class=\"footer-left\">\n    \t\t<!-- total visits number -->\n          <% if (theme.busuanzi && theme.busuanzi.enable){ %>\n            <!-- busuanzi statistics -->\n            <span id=\"busuanzi_value_site_pv\"></span>&nbsp;visits in total\n            <script async src=\"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"></script>\n          <% } %>\n        <!-- end -->\n    \t</div>\n      \t<div class=\"footer-right\">\n      \t\t&copy; <%= date(new Date(), 'YYYY') %> <%= config.author || config.title %>\n      \t</div>\n    </div>\n  </div>\n</footer>\n```\n\nand add \n\n```yml\nbusuanzi:\n  enable: true\n```\n\n### Add button of hiding the left panel\n\nRefer to  [hexo yilia](https://cqh-i.github.io/2019/08/07/hexo-yilia%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E9%9A%90%E8%97%8F%E5%B7%A6%E8%BE%B9%E6%A0%8F%E7%9B%AE%E6%8C%89%E9%92%AE/ )  \n\n1.add style list to file ` /themes/yilia/source/main.0cf68a.css `\n\n```css\n/*stylesheet for hide the left panel*/\n.mymenucontainer {\n\tdisplay:block;\n\tcursor:pointer;\n\tleft:0;\n\ttop:0;\n\twidth:35px;\n\theight:35px;\n\tz-index:9999;\n\tposition:fixed;\n}\n.bar1 {\n\twidth:35px;\n\theight:3px;\n\tborder-radius:3px;\n\tbackground-color:#8E6D51;\n\tmargin:6px 0;\n\ttransition:0.1s;\n\t-webkit-transform:rotate(-45deg) translate(-8px,8px);\n\ttransform:rotate(-45deg) translate(-8px,8px);\n}\n.bar2 {\n\twidth:35px;\n\theight:3px;\n\tborder-radius:3px;\n\tbackground-color:#8E6D51;\n\tmargin:6px 0;\n\ttransition:0.1s;\n\topacity:0;\n}\n.bar3 {\n\twidth:35px;\n\theight:3px;\n\tborder-radius:3px;\n\tbackground-color:#8E6D51;\n\tmargin:6px 0;\n\ttransition:0.1s;\n\t-webkit-transform:rotate(45deg) translate(-4px,-6px);\n\ttransform:rotate(45deg) translate(-4px,-6px);\n}\n.change .bar1 {\n\t-webkit-transform:rotate(0deg) translate(0px,0px);\n\ttransform:rotate(0deg) translate(0px,0px);\n}\n.change .bar2 {\n\topacity:1;\n}\n.change .bar3 {\n\t-webkit-transform:rotate(0deg) translate(0px,0px);\n\ttransform:rotate(0deg) translate(0px,0px);\n}\n/*stylesheet for hide the left panel end*/\n```\n\n2.go to ` /themes/yilia/layout/layout.ejs ` add before `  <div class=\"left-col\"  ` \n\n```html\n<div class=\"mymenucontainer\" onclick=\"myFunction(this)\">\n  <div class=\"bar1\"></div>\n  <div class=\"bar2\"></div>\n  <div class=\"bar3\"></div>\n</div>\n```\n\n3.add between ` </body> ` and ` </html> ` \n\n```js\n<script>\n    var hide = false;\n    function myFunction(x) {\n        x.classList.toggle(\"change\");\n        if(hide == false){\n            $(\".left-col\").css('display', 'none');\n            $(\".mid-col\").css(\"left\", 6);\n            $(\".tools-col\").css('display', 'none');\n            $(\".tools-col.hide\").css('display', 'none');\n            hide = true;\n        }else{\n            $(\".left-col\").css('display', '');\n            $(\".mid-col\").css(\"left\", 300);\n            $(\".tools-col\").css('display', '');\n            $(\".tools-col.hide\").css('display', '');\n            hide = false;\n        }\n    }\n</script>\n```\n\n\n\n\n\n### Beautiful contents navigation in articles\n\nDefault navigator is kind of ugly so found a more beautiful version, to use default version, simply change `toc: 2` in file `themes/yilia/_config.yml`\n\n1.add this block at the end of `themes/yilia/source/main.0cf68a.css`\n\n```css\n/* navigator */\n#container .show-toc-btn,#container .toc-article{display:block}\n.toc-article{z-index:100;background:#fff;border:1px solid #ccc;max-width:250px;min-width:150px;max-height:500px;overflow-y:auto;-webkit-box-shadow:5px 5px 2px #ccc;box-shadow:5px 5px 2px #ccc;font-size:12px;padding:10px;position:fixed;right:35px;top:129px}.toc-article .toc-close{font-weight:700;font-size:20px;cursor:pointer;float:right;color:#ccc}.toc-article .toc-close:hover{color:#000}.toc-article .toc{font-size:12px;padding:0;line-height:20px}.toc-article .toc .toc-number{color:#333}.toc-article .toc .toc-text:hover{text-decoration:underline;color:#2a6496}.toc-article li{list-style-type:none}.toc-article .toc-level-1{margin:4px 0}.toc-article .toc-child{}@-moz-keyframes cd-bounce-1{0%{opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}60%{opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)}100%{-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}}@-webkit-keyframes cd-bounce-1{0%{opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}60%{opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)}100%{-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}}@-o-keyframes cd-bounce-1{0%{opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}60%{opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)}100%{-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}}@keyframes cd-bounce-1{0%{opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}60%{opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)}100%{-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)}}.show-toc-btn{display:none;z-index:10;width:30px;min-height:14px;overflow:hidden;padding:4px 6px 8px 5px;border:1px solid #ddd;border-right:none;position:fixed;right:40px;text-align:center;background-color:#f9f9f9}.show-toc-btn .btn-bg{margin-top:2px;display:block;width:16px;height:14px;background:url(http://7xtawy.com1.z0.glb.clouddn.com/show.png) no-repeat;-webkit-background-size:100%;-moz-background-size:100%;background-size:100%}.show-toc-btn .btn-text{color:#999;font-size:12px}.show-toc-btn:hover{cursor:pointer}.show-toc-btn:hover .btn-bg{background-position:0 -16px}.show-toc-btn:hover .btn-text{font-size:12px;color:#ea8010}\n.toc-article li ol, .toc-article li ul {\n    margin-left: 30px;\n}\n.toc-article ol, .toc-article ul {\n    margin: 10px 0;\n}\n```\n\n2.after `</header><% } %>` in file `themes/yilia/layout/_partial/article.ejs` add\n\n```html\n    <!-- navigator -->\n    <% if (!index && post.toc){ %>\n      <p class=\"show-toc-btn\" id=\"show-toc-btn\" onclick=\"showToc();\" style=\"display:none\">\n            <span class=\"btn-bg\"></span>\n            <span class=\"btn-text\">...</span>\n            </p>\n      <div id=\"toc-article\" class=\"toc-article\">\n          <span id=\"toc-close\" class=\"toc-close\" title=\"hide navigator\" onclick=\"showBtn();\"></span>\n          <strong class=\"toc-title\">navigator</strong>\n            <%- toc(post.content) %>\n          </div>\n    <script type=\"text/javascript\">\n      function showToc(){\n          var toc_article = document.getElementById(\"toc-article\");\n          var show_toc_btn = document.getElementById(\"show-toc-btn\");\n          toc_article.setAttribute(\"style\",\"display:block\");\n          show_toc_btn.setAttribute(\"style\",\"display:none\");\n          };\n      function showBtn(){\n          var toc_article = document.getElementById(\"toc-article\");\n          var show_toc_btn = document.getElementById(\"show-toc-btn\");\n          toc_article.setAttribute(\"style\",\"display:none\");\n          show_toc_btn.setAttribute(\"style\",\"display:block\");\n          };\n    </script>\n        <% } %>\n    <!-- navigator end -->\n```\n\n3.add `toc:true` to the articles that need the navigator.\n\n### Add custormize header to articles\n\nwhen run `hexo new` to initiate a new blog, a defaul head would generate, change it by\n\nchange the `scaffolds/post.md` in the `root` directory\n\n```txt\n---\ntitle: {{ title }}\ndate: {{ date }}\nauthor: daydreamatnight\ntoc: true\ndeclare: true\ntags:\n---\n```\n\n#### more headers to choose when writing a blog\n\nbefore a blog, more paras can be chosen to add\n\n```txt\n--- \ntitle: # \ntoc: ture #toc \ndate: 2020-09-07 09:25:00 # \nauthor: GavenLee # \nimg: /source/images/xxx.jpg # \ntop: true # \ncover: true # \ncoverImg: /images/1.jpg # \npassword: # \nmathjax: false #mathjax \nsummary:  \ncategories: Markdown # \ntags: # \nabbrlink: HexoLearn # \n---\n```\n\n### Disable auto wrap in code block\n\nlocate and delete `white-space:pre-wrap` in file `themes/yilia/source/main.0cf68a.css` \n\n### Add copy button to code block\n\n1.create a `clipboard_use.js` file in directory `themes/yilia/source` \n\n```js\n$(\".highlight\").wrap(\"<div class='code-wrapper' style='position:relative'></div>\");\n/*create copy button after page loaded*/\n!function (e, t, a) {\n    /* code */\n    var initCopyCode = function () {\n        var copyHtml = '';\n        copyHtml += '<button class=\"btn-copy\" data-clipboard-snippet=\"\">';\n        copyHtml += '  <i class=\"fa fa-clipboard\"></i><span>copy</span>';\n        copyHtml += '</button>';\n        $(\".highlight .code\").before(copyHtml);\n        var clipboard = new ClipboardJS('.btn-copy', {\n            target: function (trigger) {\n                return trigger.nextElementSibling;\n            }\n        });\n        clipboard.on('success', function (e) {\n            e.trigger.innerHTML = \"<i class='fa fa-check' style='color:green'></i><span style='color:green'>copy success</span>\"\n            setTimeout(function () {\n                e.trigger.innerHTML = \"<i class='fa fa-clipboard'></i><span>copy</span>\"\n            }, 1000)\n            e.clearSelection();\n        });\n        clipboard.on('error', function (e) {\n            e.trigger.innerHTML = \"<i class='fa fa-exclamation' style='color:red'></i><span style='color:red'>copy success</span>\"\n            setTimeout(function () {\n                e.trigger.innerHTML = \"<i class='fa fa-clipboard'></i><span>copy</span>\"\n            }, 1000)\n            e.clearSelection();\n        });\n    }\n    initCopyCode();\n}(window, document);\n```\n\n2.load .js file, edit `themes/yilia/layout/layout.ejs` file, add before `</body>`. \n\n```html\n<!-- copy button in code block-->\n<script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.js\"></script>\n<script type=\"text/javascript\" src=\"https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js\"></script>\n<script type=\"text/javascript\" src=\"/clipboard_use.js\"></script>\n```\n\n3.add stylesheet the end of `themes/yilia/source/main.0cf68a.css`\n\n```css\n/* code copy button */\n.btn-copy {\n  display: inline-block;\n  cursor: pointer;\n  background-color: #eee;\n  background-image: linear-gradient(#fcfcfc, #eee);\n  border: 1px solid #d5d5d5;\n  border-radius: 3px;\n  -webkit-user-select: none;\n  -moz-user-select: none;\n  -ms-user-select: none;\n  user-select: none;\n  -webkit-appearance: none;\n  font-size: 13px;\n  font-weight: 700;\n  line-height: 20px;\n  color: #333;\n  -webkit-transition: opacity .3s ease-in-out;\n  -o-transition: opacity .3s ease-in-out;\n  transition: opacity .3s ease-in-out;\n  padding: 2px 6px;\n  position: absolute;\n  right: 5px;\n  top: 5px;\n  opacity: 0;\n}\n.btn-copy span {\n  margin-left: 5px;\n}\n.highlight:hover .btn-copy {\n  opacity: 1;\n}\n/* code copy button end */\n```\n\n4.add copy button icon, edit `themes/yilia/layout/_partia/head.ejs` add before `</head>` \n\n```html\n<!-- copy button icon -->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css\">\n```\n\n### Allow search engines to index this Blog\n\n#### index Google to this Blog\n\ncheck if google can find you, enter `site:daydreamatnight.github.io` to see\n\n<img src=\"check google search.png\" alt=\"check google search\" style=\"zoom:50%;\" />\n\n##### Add url to goole search console\n\n1.open [google console](https://search.google.com/search-console/welcome) , add URL link of the blog (https://daydreamatnight.github.io), in the `URL prefix` block, click `CONTINUE`\n\n<img src=\"google search console.png\" alt=\"google console\" style=\"zoom:50%;\" />\n\n2.upload the html file to the blog `root` directory and deploy the website, then clicke verify.\n\n<img src=\"google console varification.png\" alt=\"google console varification\" style=\"zoom:50%;\" />\n\nlittle buggy here, see [**dont upload** the file **using hexo** command](https://hilyy.xyz/how-to-allow-google-to-index-your-hexo-blog-website-google-search-console-verification-methods/)\n\n##### add sitemap for google\n\nadd sitemap for google and baidu together\n\n> A *sitemap* is a file where you provide information about the pages, videos, and other files on your site, and the relationships between them. Search engines like Google read this file to more intelligently crawl your site. A sitemap tells Google which pages and files you think are important in your site, and also provides valuable information about these files: for example, for pages, when the page was last updated, how often the page is changed, and any alternate language versions of a page.\n\n1.install sitemap plugins\t\n\n```shell\n$ npm install hexo-generator-sitemap --save\n$ npm install hexo-generator-baidu-sitemap --save\n```\n\n2.add to the `_config.yml` in the blog `root` \n\n```yml\n# hexo sitemap\nsitemap:\n  path: sitemap.xml\nbaidusitemap:\n  path: baidusitemap.xml\n```\n\n3.Deploy the blog, go to  https://daydreamatnight.github.io/sitemap.xml and https://daydreamatnight.github.io/baidusitemap.xml to see if sitemaps are uploaded\n\n4.Go to Google Search Console, in the left panel, click `Sitemaps`, enter your sitemap URL `sitemap.xml` \n\n<img src=\"can't fetch sitemap.png\" alt=\"can't fetch sitemap\" style=\"zoom:50%;\" />\n\nGooglebot won't download the sitemap immediately. Give it time. \n\n##### add robots.txt\n\n> A robots.txt file tells search engine crawlers which URLs the crawler can access on your site. This is used mainly to avoid overloading your site with requests; **it is not a mechanism for keeping a web page out of Google**. To keep a web page out of Google, [block indexing with `noindex`](https://developers.google.com/search/docs/advanced/crawling/block-indexing) or password-protect the page.\n>\n> A robots.txt file is used primarily to manage crawler traffic to your site, and *usually* to keep a file off Google, depending on the file type:\n\n```txt\nUser-agent: *\nAllow: /\nAllow: /archives/\nAllow: /tags/\nAllow: /categories/\nAllow: /about/\nAllow: /guestbook/\nAllow: /others/\n\n\nDisallow: /js/\nDisallow: /css/\nDisallow: /lib/\n\nSitemap: https://daydreamatnight.github.io/sitemap.xml\nSitemap: https://daydreamatnight.github.io/baidusitemap.xml\n```\n\ndeploy the blog and wait.\n\n##### check if sitemap is available\n\nAfter uploaded several updates, my sitemap still didn't fetched by google. So I went to check, it turns out my url setting in `_config.yml` is wrong.  So I changed it to be my home url. And check it with  [URL Inspection Tool](https://www.jcchouinard.com/url-inspection-tool/). \n\n1.Open [google search console](https://search.google.com/search-console), add the url of sitemap in the upper url inspecting box.\n\n<img src=\"Google%20sitemap%20inspect.png\" alt=\"Google sitemap inspect URL is not on Google \" style=\"zoom:22%;\" />\n\n<img src=\"Google%20sitemap%20inspect%202.png\" alt=\"Google sitemap inspect 2\" style=\"zoom:22%;\" />\n\nIt's normal it shows `URL is not on Google` because it shouldn't as a sitemap.\n\n2.click `live test` to check the availability.\n\n<img src=\"Google%20sitemap%20inspect%203.png\" alt=\"Google sitemap inspect 3\" style=\"zoom:75%;\" />\n\nIt should be available, then just wait.\n\n#### index Bing to this Blog\n\n1.go to [Bing webmaster](https://www.bing.com/webmasters/) and login\n\n2.connect with google webmaster.\n\n<img src=\"bing%20sitemap.png\" alt=\"bing sitemap\" style=\"zoom:75%;\" />\n\n  \n\n<img src=\"being%20sitemap%20connect%20google.png\" alt=\"being sitemap connect google\" style=\"zoom:75%;\" />\n\n  \n\n<img src=\"bing%20search%20console%20success.png\" alt=\"bing search console success\" style=\"zoom:75%;\" />\n\n#### index baidu to this Blog(not possibly working)\n\ngo to the [baidu search console](https://ziyuan.baidu.com/site/index) , \n\n<img src=\"baidu console.png\" alt=\"baidu console\" style=\"zoom:50%;\" />\n\nClick `` and input every thing, do similar thing\n\n<img src=\"baidu console varification.png\" alt=\"baidu console varification\" style=\"zoom:50%;\" />\n\nadd sitemap\n\n<img src=\"baidu console sitemap.png\" alt=\"baidu console sitemap\" style=\"zoom:50%;\" />\n\njust wait forever, this could take 2000 years, so give up\n\n### Add copyright statement\n\n1.open file `themes/yilia/layout/_partial/article.ejs` add before `<% if ((theme.reward_type === 2 || (theme.reward_type === 1 && post.reward)) && !index){ %>`\n\n```html\n<!-- add copyright statement -->\n<% if(theme.declare){%>\n    <%- partial('post/declare') %>\n<% } %>\n<!-- end -->\n```\n\n2.create new file `declare.ejs` under `themes/yilia/layout/_partial/post/` with:\n\n```html\n<!--add copyright statement https://github.com/JoeyBling/hexo-theme-yilia-plus/commit/c1215e132f6d5621c5fea83d3c4f7ccbcca074a3-->\n<%\n  var sUrl = url.replace(/index\\.html$/, '');\n  sUrl = /^(http:|https:)\\/\\//.test(sUrl) ? sUrl : 'https:' + sUrl;\n%>\n\n<!-- #copyright setting0-close statement; 1-declare statement if declare: true in the article header; 2-always declare the copyright -->\n<% if ((theme.declare.declare_type === 2 || (theme.declare.declare_type === 1 && post.declare)) && !index){ %>\n  <div class=\"declare\">\n    <strong class=\"author\">author: </strong>\n    <% if(config.author != undefined){ %>\n      <%= config.author%>\n    <% }else{%>\n      <font color=\"red\">please add right \"author\" name in \"_config.yml\" in the blog root</font>\n    <%}%>\n    <br>\n    <strong class=\"create-time\">posting date: </strong>\n    <%- date(post.date, 'YYYY-MM-DD HH:MM:SS') %>\n    <br>\n    <strong class=\"update-time\">last update: </strong>\n    <%- date(post.updated, 'YYYY-MM-DD HH:MM:SS') %>\n    <br>\n    <strong class=\"article-titles\">article title: </strong>\n    <a href=\"<%= config.url %>/<%= post.path %>\" title=\"<%= post.title %>\" target=\"_blank\"><%= post.title %></a>\n    <br>\n    <strong class=\"article-url\">article link: </strong>\n    <a href=\"<%= config.url %>/<%= post.path %>\" title=\"<%= post.title %>\" target=\"_blank\"><%= config.url %>/<%= post.path %></a>\n    <br>\n    <strong class=\"copyright\">copyright:</strong>\n    This work is licensed under a\n    <a rel=\"license\" href=\"<%= theme.declare.licensee_url%>\" title=\"<%= theme.declare.licensee_alias %>\"><%= theme.declare.licensee_name%></a>\n    licience \n    <% if(theme.declare.licensee_img != undefined){ %>\n      <a rel=\"license\" href=\"<%= theme.declare.licensee_url%>\"><img alt=\"\" style=\"border-width:0\" src=\"<%= theme.declare.licensee_img%>\"/></a>\n    <% } %>\n  </div>\n<% } else {%>\n  <div class=\"declare\" hidden=\"hidden\"></div>\n<% } %>\n<!-- add copyright statement -->\n```\n\n3.add stylesheet the end of `themes/yilia/source/main.0cf68a.css` \n\n```css\n/*stylesheet for the delcare*/\n.declare {\n  background-color: #eaeaea;\n  margin-top: 2em;\n  border-left: 3px solid #ff1700;\n  padding: .5em 1em; \n}\n/*stylesheet for the delcare end*/\n```\n\n4.add at the end of `themes/yilia/_config.yml` file:\n\n```\ndeclare:\n  declare_type: 1\n  licensee_url: http://creativecommons.org/licenses/by-nc-sa/4.0/      \n  licensee_name: 'CC BY-NC-SA 4.0'                              \n  licensee_alias: 'CC BY-NC-SA 4.0'     \n  licensee_img: https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png\n```\n\n### Add mind-map support\n\n```shell\nnpm install hexo-markmap\n```\n\nDetailed in its [Github](https://github.com/MaxChang3/hexo-markmap)\n\nExample:\n\n```\n{% markmap 300px %}\n- Testa\n  - test1\n  - test2\n- Testb\n  - test1\n  - test2\n{%endmarkmap%}\n```\n\n### Add Latex math support\n\nChange the renderer to the more powerful pandoc:\n\n1.Install pandoc on macOS:\n\n```\ncopybrew install pandoc\n```\n\n2.in the blog root directory uninstall the default renderer then install the pandoc renderer:\n\n```\ncopynpm uninstall hexo-renderer-marked --save\nnpm install hexo-renderer-pandoc --save\n```\n\n3.install the hexo math plugin\n\n```\ncopynpm install hexo-math --save\n```\n\n4.add these lines to the hexo `_config` file\n\n```\ncopymarkdown:\n  plugins:\n    - markdown-it-footnote\n    - markdown-it-sup\n    - markdown-it-sub\n    - markdown-it-abbr\n    - markdown-it-emoji\n    - hexo-math\n```\n\n5.add these lines to the theme `_config` file\n\n```\ncopy# MathJax Support\nmathjax:\n  enable: true\n  per_page: true\n```\n\n6.rebuild the to blog see changes\n\n7.Examples: $this_{is}an\\frac{inline}{equation}$\n$$\n\\begin{equation}\n    \\mathbf{K}_\\mathbf{1}=\\frac{1}{\\Delta r}\\ \\left[\\begin{matrix}\\begin{matrix}-1&1\\\\-1&1\\\\\\end{matrix}&\\ &\\ \\\\\\begin{matrix}\\ &\\ddots\\\\\\end{matrix}&\\begin{matrix}\\ddots&\\ \\\\\\end{matrix}&\\ \\\\\\ &-1\\ &1\\\\\\end{matrix}\\right],\\ \\ {\\ \\mathbf{K}}_\\mathbf{2}=\\frac{1}{\\Delta r}\\ \\left[\\begin{matrix}\\begin{matrix}-1&1\\\\\\ &\\ddots\\\\\\end{matrix}&\\begin{matrix}\\\\\\ddots\\\\\\end{matrix}&\\ \\\\\\begin{matrix}\\ &\\ \\\\\\end{matrix}&-1&1\\ \\\\\\ &-1\\ &1\\\\\\end{matrix}\\right]\n    \\label{K2}\n\\end{equation}\n$$\n\n### The last snapshot\n\nOk, never spend time on a no-longer maintained project. Here's the last figure of it.\n\n<img src=\"Last snapshot.png\" alt=\"Last snapshot\" style=\"zoom:80%;\" />\n\n## Reference\n\nhttps://flatironschool.com/blog/the-benefits-of-blogging-how-and-why-to-keep-a-technical-blog/\n\nhttps://weblog.masukomi.org/2015/10/18/static-vs-dynamic-blogging/\n\nhttps://www.cnblogs.com/aoguai/p/11781505.html\n\nhttps://www.kblog.top/post/30452.html\n\nhttps://wkzqn.gitee.io/2020/02/16/typora%E7%BC%96%E5%86%99hexo%E5%8D%9A%E5%AE%A2%E6%97%B6%E7%9A%84%E5%9B%BE%E7%89%87%E6%98%BE%E7%A4%BA/\n\nhttps://segmentfault.com/a/1190000009478837#articleHeader5\n\nhttps://hilyy.xyz/how-to-allow-google-to-index-your-hexo-blog-website-google-search-console-verification-methods/\n\nhttps://busuanzi.ibruce.info/\n\nhttps://creativecommons.org/choose/results-one?license_code=by-nc-sa&amp;jurisdiction=&amp;version=4.0&amp;lang=en\n\nhttps://www.jcchouinard.com/sitemap-could-not-be-read-couldnt-fetch-in-google-search-console/\n\nhttps://cqh-i.github.io/2019/08/07/hexo-yilia%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E9%9A%90%E8%97%8F%E5%B7%A6%E8%BE%B9%E6%A0%8F%E7%9B%AE%E6%8C%89%E9%92%AE/","slug":"Build-and-configure-a-personal-blog-via-hexo-and-yilia","published":1,"updated":"2022-05-28T03:51:04.561Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz1z0009l8ybdazg9109","content":"<blockquote>\n<p>Technical blog has a hundred benefits and no harm</p>\n<p>This blog records the process of building and customizing this personal blog from 0 to 1</p>\n</blockquote>\n<blockquote>\n<p>Unfortunately, the yilia theme has been no longer updating and it is too buggy right now. I switch to <a href=\"/2022/04/30/Switch-blog-theme-to-FLUID/\">other theme.</a></p>\n</blockquote>\n<span id=\"more\"></span>\n<h2 id=\"preliminary\">Preliminary</h2>\n<h3 id=\"why-personal-blog\">Why personal blog</h3>\n<blockquote>\n<p>Keeping a technical blog can be <strong>a great way of documenting your growth as a developer</strong>. This documentation can be particularly useful on a professional level. All software companies want to hire smart, thoughtful, communicative developers who can easily assimilate into a team, and who are ready to both teach and learn</p>\n</blockquote>\n<h3 id=\"static-vs-dynamic-blog\">Static vs dynamic blog</h3>\n<p>there are 2 types of mainstream personal blog: static and dynamic.</p>\n<p>Static is recommended considering its simplicity, 0 maintenance and 0 safety worry.</p>\n<table>\n<colgroup>\n<col style=\"width: 9%\" />\n<col style=\"width: 45%\" />\n<col style=\"width: 45%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\"></th>\n<th style=\"text-align: left;\">Static blog</th>\n<th style=\"text-align: left;\">Dynamic blog</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">Price</td>\n<td style=\"text-align: left;\">low, 0 cost when the traffic is relatively low</td>\n<td style=\"text-align: left;\">High, server is needed, cloud server of high performance is usually very expensive.</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">Features</td>\n<td style=\"text-align: left;\">Limited, only third-party services can be used to complete certain \"dynamic\" functions, such as comments</td>\n<td style=\"text-align: left;\">Rich, in WordPress for example, basically any kind of plugins can be found. Featuers such as auto-resizing, media players, multiple authors, scheduled posts, user analysis can be easily realize.</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">Speed</td>\n<td style=\"text-align: left;\">Fast</td>\n<td style=\"text-align: left;\">Slow</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">Maintainance</td>\n<td style=\"text-align: left;\">0</td>\n<td style=\"text-align: left;\">Need to care about the sever</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">Markdown</td>\n<td style=\"text-align: left;\">Supported yet it's the only choice</td>\n<td style=\"text-align: left;\">not supported</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">Geeky</td>\n<td style=\"text-align: left;\">YES</td>\n<td style=\"text-align: left;\">No</td>\n</tr>\n</tbody>\n</table>\n<p>And I also chose static because I'm geeky (poor of money) and results-driven (lazy to spend time on maintaining).</p>\n<h2 id=\"build-a-static-blog-via-hexo\">Build a static blog via hexo</h2>\n<h3 id=\"set-environment\">Set environment</h3>\n<p>1.check machine information: macOS on M1 MacBook</p>\n<p>2.Install Nodejs, including node and npm</p>\n<p>open https://nodejs.org/en/download/ and click download</p>\n<p><img src=\"node js install.png\" srcset=\"/img/loading.gif\" lazyload alt=\"node js install\" style=\"zoom:50%;\" /></p>\n<p>3.Install Git</p>\n<p>Aready installed</p>\n<p>4.Open terminal, check node, npm and git versions</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">npm -v</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">node -v</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">git --version</span>\n8.3.1\nv16.14.0\ngit version 2.32.0 (Apple Git-132)</code></pre></div>\n<h3 id=\"initialize-blog\">Initialize blog</h3>\n<p>1.install hexo via npm</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">sudo npm install -g hexo-cli</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo -v</span>\nINFO  Validating config\nhexo: 6.0.0\nhexo-cli: 4.3.0\nos: darwin 21.2.0 12.1\n\nnode: 16.14.0\nv8: 9.4.146.24-node.20\nuv: 1.43.0\nzlib: 1.2.11\nbrotli: 1.0.9\nares: 1.18.1\nmodules: 93\nnghttp2: 1.45.1\nnapi: 8\nllhttp: 6.0.4\nopenssl: 1.1.1m+quic\ncldr: 40.0\nicu: 70.1\ntz: 2021a3\nunicode: 14.0\nngtcp2: 0.1.0-DEV\nnghttp3: 0.1.0-DEV</code></pre></div>\n<p>2.create a new folder in terminal and initialize the blog</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\"><span class=\"hljs-built_in\">cd</span> ~/Documents/</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">makedir self_blog</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\"><span class=\"hljs-built_in\">cd</span> self_blog/</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo init</span>\nINFO  Cloning hexo-starter https://github.com/hexojs/hexo-starter.gitINFO  Install dependencies#########  idealTree:hexo-front-matter: timing idealTree:node_modules/hexo-front-matter Completed in 212msINFO  Start blogging with Hexo!</code></pre></div>\n<p>3.view the blog on localhost, s for start</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo s</span>\nINFO  Validating config\nINFO  Start processing\nINFO  Hexo is running at http://localhost:4000/ . Press Ctrl+C to stop.</code></pre></div>\n<h3 id=\"write-first-blog\">Write first blog</h3>\n<p>1.write a new blog, n for new</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo n <span class=\"hljs-string\">&#x27;Hello ShouRou&#x27;</span></span>\nINFO  Validating config\nINFO  Created: ~/Documents/self_blog/source/_posts/Hello-ShouRou.md</code></pre></div>\n<p>the blog can be written on any editor, Typora in use.</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">open ~/Documents/self_blog/source/_posts/Hello-ShouRou.md</code></pre></div>\n<p>2.clean cache(not necessary)</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo clean</span></code></pre></div>\n<p>3.generate the blog, g for generate</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo g</span>\nINFO  Validating config\nINFO  Start processing\nINFO  Files loaded in 61 ms\n(node:10719) Warning: Accessing non-existent property &#x27;lineno&#x27; of module exports inside circular dependency\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:10719) Warning: Accessing non-existent property &#x27;column&#x27; of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property &#x27;filename&#x27; of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property &#x27;lineno&#x27; of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property &#x27;column&#x27; of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property &#x27;filename&#x27; of module exports inside circular dependency\nINFO  Generated: archives/2022/index.html\nINFO  Generated: archives/index.html\nINFO  Generated: js/script.js\nINFO  Generated: fancybox/jquery.fancybox.min.css\nINFO  Generated: index.html\nINFO  Generated: css/style.css\nINFO  Generated: css/fonts/fontawesome-webfont.woff2\nINFO  Generated: fancybox/jquery.fancybox.min.js\nINFO  Generated: js/jquery-3.4.1.min.js\nINFO  Generated: archives/2022/02/index.html\nINFO  Generated: css/fonts/FontAwesome.otf\nINFO  Generated: css/fonts/fontawesome-webfont.woff\nINFO  Generated: css/fonts/fontawesome-webfont.eot\nINFO  Generated: css/fonts/fontawesome-webfont.ttf\nINFO  Generated: css/images/banner.jpg\nINFO  Generated: 2022/02/22/hello-world/index.html\nINFO  Generated: css/fonts/fontawesome-webfont.svg\nINFO  Generated: 2022/02/22/Hello-ShouRou/index.html\nINFO  18 files generated in 161 ms</code></pre></div>\n<h3 id=\"deploy-to-remote-github\">Deploy to remote (GitHub)</h3>\n<p>1.Create a new repository with the name of $username.github.io</p>\n<p><img src=\"github page.png\" srcset=\"/img/loading.gif\" lazyload alt=\"github page\" style=\"zoom:50%;\" /></p>\n<p>use default setting</p>\n<p>2.open terminal, install plugin of deploying to git</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">npm install --save hexo-deployer-git</span></code></pre></div>\n<p>3.Open the <code>_config.yml</code> file in the blog <code>root</code> directory, add these lines afterwards</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs yml\"><span class=\"hljs-attr\">deploy:</span>\n <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">git</span>\n <span class=\"hljs-attr\">repo:</span> <span class=\"hljs-string\">git@github.com:DaydreamAtNight/DaydreamAtNight.github.io.git</span>\n <span class=\"hljs-attr\">branch:</span> <span class=\"hljs-string\">master</span></code></pre></div>\n<p>4.Go to the blog <code>root</code>, deploy the blog to remote, d for deploy</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo clean</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo g</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo d</span></code></pre></div>\n<p>Open https://daydreamatnight.github.io/ to see if it works</p>\n<h2 id=\"change-theme-to-yilia\">Change theme to yilia</h2>\n<p>default theme of hexo is called landscape and it's not beautiful enough to most of the people. Yilia is a fast, simple, elegant and popular theme. Thought it has not been updated since Nov 2017, it still a good choice for fresh bloggers.</p>\n<h3 id=\"download-and-deploy-yilia\">Download and deploy yilia</h3>\n<p>1.go to the blog <code>root</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">git <span class=\"hljs-built_in\">clone</span> https://github.com/litten/hexo-theme-yilia theme/yilia</span></code></pre></div>\n<p>2.eidt the <code>_config.yml</code> file, add</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs yml\"><span class=\"hljs-attr\">theme:</span> <span class=\"hljs-string\">yilia</span></code></pre></div>\n<p>3.clean and deploy hexo</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo clean</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo g</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo d</span></code></pre></div>\n<h3 id=\"basic-customize-yillia\">Basic customize yillia</h3>\n<h4 id=\"activate-aboutme-left-slider-button\">Activate <code>aboutme</code> left slider button</h4>\n<p>1.go to terminal run</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">npm i hexo-generator-json-content --save</span></code></pre></div>\n<p>2.go to the blog <code>root</code> directory, add these lines to the <code>_config.yml</code> file</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs yml\"><span class=\"hljs-attr\">jsonContent:</span>\n    <span class=\"hljs-attr\">meta:</span> <span class=\"hljs-literal\">false</span>\n    <span class=\"hljs-attr\">pages:</span> <span class=\"hljs-literal\">false</span>\n    <span class=\"hljs-attr\">posts:</span>\n      <span class=\"hljs-attr\">title:</span> <span class=\"hljs-literal\">true</span>\n      <span class=\"hljs-attr\">date:</span> <span class=\"hljs-literal\">true</span>\n      <span class=\"hljs-attr\">path:</span> <span class=\"hljs-literal\">true</span>\n      <span class=\"hljs-attr\">text:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">raw:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">content:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">slug:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">updated:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">comments:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">link:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">permalink:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">excerpt:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">categories:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">tags:</span> <span class=\"hljs-literal\">true</span></code></pre></div>\n<h4 id=\"customize-avatar\">Customize avatar</h4>\n<p>put the avatar file in directory <code>themes/yilia/source/img</code></p>\n<blockquote>\n<p>do not add to the public repository directly, or the img get cleaned every time running <code>hexo clean</code> , need to upload to the same dir again after this command.</p>\n</blockquote>\n<h4 id=\"set-favicon-icon-on-the-tab-of-website\">Set favicon (icon on the tab of website)</h4>\n<p>put the favicon img in directory <code>themes/yilia/source/img</code></p>\n<p><a href=\"https://www.bitbug.net/\">Bitbug</a> is a way of converting image into .ico file.</p>\n<h4 id=\"other-configuration\">Other configuration</h4>\n<p>Set file of yillia is in <code>themes/yilia/_config.yml</code> as:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs yml\"><span class=\"hljs-comment\"># Header</span>\n<span class=\"hljs-attr\">author:</span> <span class=\"hljs-string\">Ryan</span> <span class=\"hljs-string\">LI</span>\n<span class=\"hljs-attr\">subtitle:</span> <span class=\"hljs-string\">&#x27;Daydreaming at night&#x27;</span>\n<span class=\"hljs-attr\">menu:</span>\n  <span class=\"hljs-attr\">main:</span> <span class=\"hljs-string\">/</span>\n  <span class=\"hljs-attr\">archives:</span> <span class=\"hljs-string\">/archives/index.html</span>\n  <span class=\"hljs-attr\">learn:</span> <span class=\"hljs-string\">/tags/learn/</span>\n\n<span class=\"hljs-comment\"># SubNav</span>\n<span class=\"hljs-attr\">subnav:</span>\n  <span class=\"hljs-attr\">github:</span> <span class=\"hljs-string\">&quot;https://github.com/DaydreamAtNight&quot;</span>\n  <span class=\"hljs-comment\"># weibo: &quot;#&quot;</span>\n  <span class=\"hljs-comment\"># rss: &quot;#&quot;</span>\n  <span class=\"hljs-comment\"># zhihu: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#qq: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#weixin: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#jianshu: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#douban: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#segmentfault: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#bilibili: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#acfun: &quot;#&quot;</span>\n  <span class=\"hljs-attr\">mail:</span> <span class=\"hljs-string\">&quot;mailto:lishoushou2019@gmail.com&quot;</span>\n  <span class=\"hljs-comment\">#facebook: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#google: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#twitter: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#linkedin: &quot;#&quot;</span>\n\n<span class=\"hljs-attr\">rss:</span> <span class=\"hljs-string\">/atom.xml</span>\n\n<span class=\"hljs-comment\">#  root </span>\n<span class=\"hljs-comment\">#  http://yoursite.com/blog</span>\n<span class=\"hljs-comment\">#  url  http://yoursite.com/blog  root  /blog/</span>\n<span class=\"hljs-attr\">root:</span> <span class=\"hljs-string\">/</span>\n\n<span class=\"hljs-comment\"># Content</span>\n\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-comment\"># excerpt_link: more</span>\n<span class=\"hljs-comment\"># false</span>\n<span class=\"hljs-attr\">show_all_link:</span> <span class=\"hljs-string\">&#x27;show all&#x27;</span>\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-attr\">mathjax:</span> <span class=\"hljs-literal\">false</span>\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-attr\">open_in_new:</span> <span class=\"hljs-literal\">false</span>\n\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-comment\"># type0- 1-mdreward:true 2-</span>\n<span class=\"hljs-attr\">reward_type:</span> <span class=\"hljs-number\">0</span>\n<span class=\"hljs-comment\"># # wording</span>\n<span class=\"hljs-comment\"># reward_wording: &#x27;&#x27;</span>\n<span class=\"hljs-comment\"># # /assets/img/alipay.jpg</span>\n<span class=\"hljs-comment\"># alipay: </span>\n<span class=\"hljs-comment\"># # </span>\n<span class=\"hljs-comment\"># weixin: </span>\n\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-comment\"># 0- 1-mdtoc:true 2-</span>\n<span class=\"hljs-attr\">toc:</span> <span class=\"hljs-number\">1</span>\n<span class=\"hljs-comment\"># truehexofalse</span>\n<span class=\"hljs-attr\">toc_hide_index:</span> <span class=\"hljs-literal\">true</span>\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-attr\">toc_empty_wording:</span> <span class=\"hljs-string\">&#x27;directery none exist&#x27;</span>\n\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-attr\">top:</span> <span class=\"hljs-literal\">true</span>\n\n<span class=\"hljs-comment\"># Miscellaneous</span>\n<span class=\"hljs-attr\">baidu_analytics:</span> <span class=\"hljs-string\">&#x27;&#x27;</span>\n<span class=\"hljs-attr\">google_analytics:</span> <span class=\"hljs-string\">&#x27;&#x27;</span>\n<span class=\"hljs-attr\">favicon:</span> <span class=\"hljs-string\">/img/favicon.ico</span>\n\n<span class=\"hljs-comment\">#url</span>\n<span class=\"hljs-attr\">avatar:</span> <span class=\"hljs-string\">/img/avatar.jpeg</span>\n\n<span class=\"hljs-comment\">#</span>\n<span class=\"hljs-comment\"># share_jia: true</span>\n\n<span class=\"hljs-comment\"># #1234Disqus5Gitment</span>\n<span class=\"hljs-comment\"># #false</span>\n<span class=\"hljs-comment\"># #wikihttps://github.com/litten/hexo-theme-yilia/wiki/</span>\n\n<span class=\"hljs-comment\"># #1</span>\n<span class=\"hljs-comment\"># duoshuo: false</span>\n\n<span class=\"hljs-comment\"># #2</span>\n<span class=\"hljs-comment\"># wangyiyun: false</span>\n\n<span class=\"hljs-comment\"># #3</span>\n<span class=\"hljs-comment\"># changyan_appid: false</span>\n<span class=\"hljs-comment\"># changyan_conf: false</span>\n\n<span class=\"hljs-comment\"># #4Disqus hexoconfigdisqus_shortnameyilia</span>\n<span class=\"hljs-comment\"># disqus: false</span>\n\n<span class=\"hljs-comment\"># #5Gitment</span>\n<span class=\"hljs-comment\"># gitment_owner: false      # GitHub ID</span>\n<span class=\"hljs-comment\"># gitment_repo: &#x27;&#x27;          # repo</span>\n<span class=\"hljs-comment\"># gitment_oauth:</span>\n<span class=\"hljs-comment\">#   client_id: &#x27;&#x27;           #client ID</span>\n<span class=\"hljs-comment\">#   client_secret: &#x27;&#x27;       #client secret</span>\n\n<span class=\"hljs-comment\">#  - </span>\n<span class=\"hljs-attr\">style:</span>\n  <span class=\"hljs-comment\"># </span>\n  <span class=\"hljs-attr\">header:</span> <span class=\"hljs-string\">&#x27;#ece0cf&#x27;</span>\n  <span class=\"hljs-comment\"># </span>\n  <span class=\"hljs-attr\">slider:</span> <span class=\"hljs-string\">&#x27;linear-gradient(45deg,#b4a698,#ece0cf)&#x27;</span>\n\n<span class=\"hljs-comment\"># slider</span>\n<span class=\"hljs-attr\">slider:</span>\n  <span class=\"hljs-comment\"># tags</span>\n  <span class=\"hljs-attr\">showTags:</span> <span class=\"hljs-literal\">false</span>\n\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-comment\"># false</span>\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-comment\">#smart_menu:</span>\n<span class=\"hljs-comment\">#  friends: false</span>\n<span class=\"hljs-attr\">smart_menu:</span>\n  <span class=\"hljs-attr\">innerArchive:</span> <span class=\"hljs-string\">&#x27;All articles&#x27;</span>\n  <span class=\"hljs-comment\"># friends: &#x27;&#x27;</span>\n  <span class=\"hljs-attr\">aboutme:</span> <span class=\"hljs-string\">&#x27;About me&#x27;</span>\n\n<span class=\"hljs-comment\"># friends:</span>\n<span class=\"hljs-comment\">#   1: http://localhost:4000/</span>\n<span class=\"hljs-comment\">#   2: http://localhost:4000/</span>\n<span class=\"hljs-comment\">#   3: http://localhost:4000/</span>\n<span class=\"hljs-comment\">#   4: http://localhost:4000/</span>\n<span class=\"hljs-comment\">#   5: http://localhost:4000/</span>\n<span class=\"hljs-comment\">#   6: http://localhost:4000/</span>\n\n<span class=\"hljs-attr\">aboutme:</span> <span class=\"hljs-string\">Stay</span> <span class=\"hljs-string\">hungry,</span> <span class=\"hljs-string\">stay</span> <span class=\"hljs-string\">fullish</span></code></pre></div>\n<h2 id=\"advance-customize\">Advance customize</h2>\n<h3 id=\"stop-visit-litten.me9005\">Stop visit litten.me:9005</h3>\n<p>Sometimes the user's client information is collected, see <a href=\"https://github.com/litten/hexo-theme-yilia/issues/528\">here</a> for details.</p>\n<p>Stop reporting by clear the contents in <code>themes/yilia/source-src/js/report.js</code></p>\n<h3 id=\"limit-display-numbers-on-the-main-page\">Limit display numbers on the main page</h3>\n<p>Simply insert <code>&lt;! -- more --&gt;</code> to show only what comes before it while collapse the afterwards, click on the article title to read it in full.</p>\n<h3 id=\"easily-add-pics-to-blogs-via-hexo-renderer-marked-plugin\">Easily add pics to blogs via hexo-renderer-marked plugin</h3>\n<p>1.find <code>post_asset_folder</code> in <code>_config.yml</code> file in the blog <code>root</code> directory, set to be true</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs yml\"><span class=\"hljs-string\">post_asset_folder:true</span></code></pre></div>\n<p>2.Install plugin</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">npm install hexo-renderer-marked --save</code></pre></div>\n<p>3.change <code>_config.yml</code> in blog <code>root</code> directory as</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs yml\"><span class=\"hljs-attr\">post_asset_folder:</span> <span class=\"hljs-literal\">true</span>\n<span class=\"hljs-attr\">marked:</span>\n  <span class=\"hljs-attr\">prependRoot:</span> <span class=\"hljs-literal\">true</span>\n  <span class=\"hljs-attr\">postAsset:</span> <span class=\"hljs-literal\">true</span></code></pre></div>\n<p>then img can be easily add with <code>![img description](img.png)</code> after add the image to the folder with the same name as the article in <code>/source/_posts/</code></p>\n<p>4.change Typora pereference as</p>\n<p><img src=\"typora setting.png\" srcset=\"/img/loading.gif\" lazyload alt=\"typora setting\" style=\"zoom:50%;\" /></p>\n<p>img can drag into typro, yet blogname need to be deleted before deploying</p>\n<h3 id=\"show-number-of-articles-and-words-on-the-left-panel\">Show number of articles and words on the left panel</h3>\n<p>1.add wordcount plugin in terminal</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">npm i --save hexo-wordcount</code></pre></div>\n<p>2.change <code>themes/yilia/layout/_partial/left-col.ejs</code></p>\n<p>after</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs html\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">nav</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;header-menu&quot;</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">ul</span>&gt;</span>\n    &lt;% for (var i in theme.menu)&#123; %&gt;\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">li</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">a</span> <span class=\"hljs-attr\">href</span>=<span class=\"hljs-string\">&quot;&lt;%- url_for(theme.menu[i]) %&gt;&quot;</span>&gt;</span>&lt;%= i %&gt;<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">a</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">li</span>&gt;</span>\n    &lt;%&#125;%&gt;\n  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">ul</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">nav</span>&gt;</span></code></pre></div>\n<p>add</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs html\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">span</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;post-count&quot;</span>&gt;</span>&lt;%=site.posts.length%&gt; articles\n\t\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">span</span>&gt;</span>&lt;%= totalcount(site, &#x27;0,0.0a&#x27;) %&gt;<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">span</span>&gt;</span> words<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">span</span>&gt;</span></code></pre></div>\n<p>add style sheet in <code>themes/yilia/source/main.0cf68a.css</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs css\"><span class=\"hljs-selector-class\">.post-count</span>&#123;\n  <span class=\"hljs-attribute\">font-size</span>: <span class=\"hljs-number\">12px</span>;\n  <span class=\"hljs-attribute\">color</span>: <span class=\"hljs-number\">#696969</span>;\n&#125;</code></pre></div>\n<h3 id=\"show-number-of-visits-in-the-footer\">Show number of visits in the footer</h3>\n<p><a href=\"https://busuanzi.ibruce.info/\">busuanzi</a> is in use, which is super easy to deploy</p>\n<p>change <code>themes/yilia/layout/_partial/footer.ejs</code> as</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs html\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">footer</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;footer&quot;</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;outer&quot;</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;footer-info&quot;</span>&gt;</span>\n    \t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;footer-left&quot;</span>&gt;</span>\n    \t\t<span class=\"hljs-comment\">&lt;!-- total visits number --&gt;</span>\n          &lt;% if (theme.busuanzi &amp;&amp; theme.busuanzi.enable)&#123; %&gt;\n            <span class=\"hljs-comment\">&lt;!-- busuanzi statistics --&gt;</span>\n            <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">span</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;busuanzi_value_site_pv&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">span</span>&gt;</span><span class=\"hljs-symbol\">&amp;nbsp;</span>visits in total\n            <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">async</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">script</span>&gt;</span>\n          &lt;% &#125; %&gt;\n        <span class=\"hljs-comment\">&lt;!-- end --&gt;</span>\n    \t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n      \t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;footer-right&quot;</span>&gt;</span>\n      \t\t<span class=\"hljs-symbol\">&amp;copy;</span> &lt;%= date(new Date(), &#x27;YYYY&#x27;) %&gt; &lt;%= config.author || config.title %&gt;\n      \t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">footer</span>&gt;</span></code></pre></div>\n<p>and add</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs yml\"><span class=\"hljs-attr\">busuanzi:</span>\n  <span class=\"hljs-attr\">enable:</span> <span class=\"hljs-literal\">true</span></code></pre></div>\n<h3 id=\"add-button-of-hiding-the-left-panel\">Add button of hiding the left panel</h3>\n<p>Refer to <a href=\"https://cqh-i.github.io/2019/08/07/hexo-yilia%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E9%9A%90%E8%97%8F%E5%B7%A6%E8%BE%B9%E6%A0%8F%E7%9B%AE%E6%8C%89%E9%92%AE/\">hexo yilia</a></p>\n<p>1.add style list to file <code>/themes/yilia/source/main.0cf68a.css</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs css\"><span class=\"hljs-comment\">/*stylesheet for hide the left panel*/</span>\n<span class=\"hljs-selector-class\">.mymenucontainer</span> &#123;\n\t<span class=\"hljs-attribute\">display</span>:block;\n\t<span class=\"hljs-attribute\">cursor</span>:pointer;\n\t<span class=\"hljs-attribute\">left</span>:<span class=\"hljs-number\">0</span>;\n\t<span class=\"hljs-attribute\">top</span>:<span class=\"hljs-number\">0</span>;\n\t<span class=\"hljs-attribute\">width</span>:<span class=\"hljs-number\">35px</span>;\n\t<span class=\"hljs-attribute\">height</span>:<span class=\"hljs-number\">35px</span>;\n\t<span class=\"hljs-attribute\">z-index</span>:<span class=\"hljs-number\">9999</span>;\n\t<span class=\"hljs-attribute\">position</span>:fixed;\n&#125;\n<span class=\"hljs-selector-class\">.bar1</span> &#123;\n\t<span class=\"hljs-attribute\">width</span>:<span class=\"hljs-number\">35px</span>;\n\t<span class=\"hljs-attribute\">height</span>:<span class=\"hljs-number\">3px</span>;\n\t<span class=\"hljs-attribute\">border-radius</span>:<span class=\"hljs-number\">3px</span>;\n\t<span class=\"hljs-attribute\">background-color</span>:<span class=\"hljs-number\">#8E6D51</span>;\n\t<span class=\"hljs-attribute\">margin</span>:<span class=\"hljs-number\">6px</span> <span class=\"hljs-number\">0</span>;\n\t<span class=\"hljs-attribute\">transition</span>:<span class=\"hljs-number\">0.1s</span>;\n\t-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(-<span class=\"hljs-number\">45deg</span>) <span class=\"hljs-built_in\">translate</span>(-<span class=\"hljs-number\">8px</span>,<span class=\"hljs-number\">8px</span>);\n\t<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(-<span class=\"hljs-number\">45deg</span>) <span class=\"hljs-built_in\">translate</span>(-<span class=\"hljs-number\">8px</span>,<span class=\"hljs-number\">8px</span>);\n&#125;\n<span class=\"hljs-selector-class\">.bar2</span> &#123;\n\t<span class=\"hljs-attribute\">width</span>:<span class=\"hljs-number\">35px</span>;\n\t<span class=\"hljs-attribute\">height</span>:<span class=\"hljs-number\">3px</span>;\n\t<span class=\"hljs-attribute\">border-radius</span>:<span class=\"hljs-number\">3px</span>;\n\t<span class=\"hljs-attribute\">background-color</span>:<span class=\"hljs-number\">#8E6D51</span>;\n\t<span class=\"hljs-attribute\">margin</span>:<span class=\"hljs-number\">6px</span> <span class=\"hljs-number\">0</span>;\n\t<span class=\"hljs-attribute\">transition</span>:<span class=\"hljs-number\">0.1s</span>;\n\t<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">0</span>;\n&#125;\n<span class=\"hljs-selector-class\">.bar3</span> &#123;\n\t<span class=\"hljs-attribute\">width</span>:<span class=\"hljs-number\">35px</span>;\n\t<span class=\"hljs-attribute\">height</span>:<span class=\"hljs-number\">3px</span>;\n\t<span class=\"hljs-attribute\">border-radius</span>:<span class=\"hljs-number\">3px</span>;\n\t<span class=\"hljs-attribute\">background-color</span>:<span class=\"hljs-number\">#8E6D51</span>;\n\t<span class=\"hljs-attribute\">margin</span>:<span class=\"hljs-number\">6px</span> <span class=\"hljs-number\">0</span>;\n\t<span class=\"hljs-attribute\">transition</span>:<span class=\"hljs-number\">0.1s</span>;\n\t-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(<span class=\"hljs-number\">45deg</span>) <span class=\"hljs-built_in\">translate</span>(-<span class=\"hljs-number\">4px</span>,-<span class=\"hljs-number\">6px</span>);\n\t<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(<span class=\"hljs-number\">45deg</span>) <span class=\"hljs-built_in\">translate</span>(-<span class=\"hljs-number\">4px</span>,-<span class=\"hljs-number\">6px</span>);\n&#125;\n<span class=\"hljs-selector-class\">.change</span> <span class=\"hljs-selector-class\">.bar1</span> &#123;\n\t-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(<span class=\"hljs-number\">0deg</span>) <span class=\"hljs-built_in\">translate</span>(<span class=\"hljs-number\">0px</span>,<span class=\"hljs-number\">0px</span>);\n\t<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(<span class=\"hljs-number\">0deg</span>) <span class=\"hljs-built_in\">translate</span>(<span class=\"hljs-number\">0px</span>,<span class=\"hljs-number\">0px</span>);\n&#125;\n<span class=\"hljs-selector-class\">.change</span> <span class=\"hljs-selector-class\">.bar2</span> &#123;\n\t<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">1</span>;\n&#125;\n<span class=\"hljs-selector-class\">.change</span> <span class=\"hljs-selector-class\">.bar3</span> &#123;\n\t-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(<span class=\"hljs-number\">0deg</span>) <span class=\"hljs-built_in\">translate</span>(<span class=\"hljs-number\">0px</span>,<span class=\"hljs-number\">0px</span>);\n\t<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(<span class=\"hljs-number\">0deg</span>) <span class=\"hljs-built_in\">translate</span>(<span class=\"hljs-number\">0px</span>,<span class=\"hljs-number\">0px</span>);\n&#125;\n<span class=\"hljs-comment\">/*stylesheet for hide the left panel end*/</span></code></pre></div>\n<p>2.go to <code>/themes/yilia/layout/layout.ejs</code> add before <code>&lt;div class=\"left-col\"</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs html\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;mymenucontainer&quot;</span> <span class=\"hljs-attr\">onclick</span>=<span class=\"hljs-string\">&quot;myFunction(this)&quot;</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;bar1&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;bar2&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;bar3&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span></code></pre></div>\n<p>3.add between <code>&lt;/body&gt;</code> and <code>&lt;/html&gt;</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs js\">&lt;script&gt;\n    <span class=\"hljs-keyword\">var</span> hide = <span class=\"hljs-literal\">false</span>;\n    <span class=\"hljs-keyword\">function</span> <span class=\"hljs-title function_\">myFunction</span>(<span class=\"hljs-params\">x</span>) &#123;\n        x.<span class=\"hljs-property\">classList</span>.<span class=\"hljs-title function_\">toggle</span>(<span class=\"hljs-string\">&quot;change&quot;</span>);\n        <span class=\"hljs-keyword\">if</span>(hide == <span class=\"hljs-literal\">false</span>)&#123;\n            $(<span class=\"hljs-string\">&quot;.left-col&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&#x27;display&#x27;</span>, <span class=\"hljs-string\">&#x27;none&#x27;</span>);\n            $(<span class=\"hljs-string\">&quot;.mid-col&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&quot;left&quot;</span>, <span class=\"hljs-number\">6</span>);\n            $(<span class=\"hljs-string\">&quot;.tools-col&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&#x27;display&#x27;</span>, <span class=\"hljs-string\">&#x27;none&#x27;</span>);\n            $(<span class=\"hljs-string\">&quot;.tools-col.hide&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&#x27;display&#x27;</span>, <span class=\"hljs-string\">&#x27;none&#x27;</span>);\n            hide = <span class=\"hljs-literal\">true</span>;\n        &#125;<span class=\"hljs-keyword\">else</span>&#123;\n            $(<span class=\"hljs-string\">&quot;.left-col&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&#x27;display&#x27;</span>, <span class=\"hljs-string\">&#x27;&#x27;</span>);\n            $(<span class=\"hljs-string\">&quot;.mid-col&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&quot;left&quot;</span>, <span class=\"hljs-number\">300</span>);\n            $(<span class=\"hljs-string\">&quot;.tools-col&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&#x27;display&#x27;</span>, <span class=\"hljs-string\">&#x27;&#x27;</span>);\n            $(<span class=\"hljs-string\">&quot;.tools-col.hide&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&#x27;display&#x27;</span>, <span class=\"hljs-string\">&#x27;&#x27;</span>);\n            hide = <span class=\"hljs-literal\">false</span>;\n        &#125;\n    &#125;\n&lt;/script&gt;</code></pre></div>\n<h3 id=\"beautiful-contents-navigation-in-articles\">Beautiful contents navigation in articles</h3>\n<p>Default navigator is kind of ugly so found a more beautiful version, to use default version, simply change <code>toc: 2</code> in file <code>themes/yilia/_config.yml</code></p>\n<p>1.add this block at the end of <code>themes/yilia/source/main.0cf68a.css</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs css\"><span class=\"hljs-comment\">/* navigator */</span>\n<span class=\"hljs-selector-id\">#container</span> <span class=\"hljs-selector-class\">.show-toc-btn</span>,<span class=\"hljs-selector-id\">#container</span> <span class=\"hljs-selector-class\">.toc-article</span>&#123;<span class=\"hljs-attribute\">display</span>:block&#125;\n<span class=\"hljs-selector-class\">.toc-article</span>&#123;<span class=\"hljs-attribute\">z-index</span>:<span class=\"hljs-number\">100</span>;<span class=\"hljs-attribute\">background</span>:<span class=\"hljs-number\">#fff</span>;<span class=\"hljs-attribute\">border</span>:<span class=\"hljs-number\">1px</span> solid <span class=\"hljs-number\">#ccc</span>;<span class=\"hljs-attribute\">max-width</span>:<span class=\"hljs-number\">250px</span>;<span class=\"hljs-attribute\">min-width</span>:<span class=\"hljs-number\">150px</span>;<span class=\"hljs-attribute\">max-height</span>:<span class=\"hljs-number\">500px</span>;<span class=\"hljs-attribute\">overflow-y</span>:auto;-webkit-<span class=\"hljs-attribute\">box-shadow</span>:<span class=\"hljs-number\">5px</span> <span class=\"hljs-number\">5px</span> <span class=\"hljs-number\">2px</span> <span class=\"hljs-number\">#ccc</span>;<span class=\"hljs-attribute\">box-shadow</span>:<span class=\"hljs-number\">5px</span> <span class=\"hljs-number\">5px</span> <span class=\"hljs-number\">2px</span> <span class=\"hljs-number\">#ccc</span>;<span class=\"hljs-attribute\">font-size</span>:<span class=\"hljs-number\">12px</span>;<span class=\"hljs-attribute\">padding</span>:<span class=\"hljs-number\">10px</span>;<span class=\"hljs-attribute\">position</span>:fixed;<span class=\"hljs-attribute\">right</span>:<span class=\"hljs-number\">35px</span>;<span class=\"hljs-attribute\">top</span>:<span class=\"hljs-number\">129px</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc-close</span>&#123;<span class=\"hljs-attribute\">font-weight</span>:<span class=\"hljs-number\">700</span>;<span class=\"hljs-attribute\">font-size</span>:<span class=\"hljs-number\">20px</span>;<span class=\"hljs-attribute\">cursor</span>:pointer;<span class=\"hljs-attribute\">float</span><span class=\"hljs-selector-pseudo\">:right</span>;<span class=\"hljs-attribute\">color</span>:<span class=\"hljs-number\">#ccc</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc-close</span><span class=\"hljs-selector-pseudo\">:hover</span>&#123;<span class=\"hljs-attribute\">color</span>:<span class=\"hljs-number\">#000</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc</span>&#123;<span class=\"hljs-attribute\">font-size</span>:<span class=\"hljs-number\">12px</span>;<span class=\"hljs-attribute\">padding</span>:<span class=\"hljs-number\">0</span>;<span class=\"hljs-attribute\">line-height</span>:<span class=\"hljs-number\">20px</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc</span> <span class=\"hljs-selector-class\">.toc-number</span>&#123;<span class=\"hljs-attribute\">color</span>:<span class=\"hljs-number\">#333</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc</span> <span class=\"hljs-selector-class\">.toc-text</span><span class=\"hljs-selector-pseudo\">:hover</span>&#123;<span class=\"hljs-attribute\">text-decoration</span>:underline;<span class=\"hljs-attribute\">color</span>:<span class=\"hljs-number\">#2a6496</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-tag\">li</span>&#123;<span class=\"hljs-attribute\">list-style-type</span>:none&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc-level-1</span>&#123;<span class=\"hljs-attribute\">margin</span>:<span class=\"hljs-number\">4px</span> <span class=\"hljs-number\">0</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc-child</span>&#123;&#125;<span class=\"hljs-keyword\">@-moz-keyframes</span> cd-bounce-<span class=\"hljs-number\">1</span>&#123;<span class=\"hljs-number\">0%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">0</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;<span class=\"hljs-number\">60%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">1</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>)&#125;<span class=\"hljs-number\">100%</span>&#123;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;&#125;<span class=\"hljs-keyword\">@-webkit-keyframes</span> cd-bounce-<span class=\"hljs-number\">1</span>&#123;<span class=\"hljs-number\">0%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">0</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;<span class=\"hljs-number\">60%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">1</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>)&#125;<span class=\"hljs-number\">100%</span>&#123;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;&#125;<span class=\"hljs-keyword\">@-o-keyframes</span> cd-bounce-<span class=\"hljs-number\">1</span>&#123;<span class=\"hljs-number\">0%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">0</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;<span class=\"hljs-number\">60%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">1</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>)&#125;<span class=\"hljs-number\">100%</span>&#123;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;&#125;<span class=\"hljs-keyword\">@keyframes</span> cd-bounce-<span class=\"hljs-number\">1</span>&#123;<span class=\"hljs-number\">0%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">0</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;<span class=\"hljs-number\">60%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">1</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>)&#125;<span class=\"hljs-number\">100%</span>&#123;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;&#125;<span class=\"hljs-selector-class\">.show-toc-btn</span>&#123;<span class=\"hljs-attribute\">display</span>:none;<span class=\"hljs-attribute\">z-index</span>:<span class=\"hljs-number\">10</span>;<span class=\"hljs-attribute\">width</span>:<span class=\"hljs-number\">30px</span>;<span class=\"hljs-attribute\">min-height</span>:<span class=\"hljs-number\">14px</span>;<span class=\"hljs-attribute\">overflow</span>:hidden;<span class=\"hljs-attribute\">padding</span>:<span class=\"hljs-number\">4px</span> <span class=\"hljs-number\">6px</span> <span class=\"hljs-number\">8px</span> <span class=\"hljs-number\">5px</span>;<span class=\"hljs-attribute\">border</span>:<span class=\"hljs-number\">1px</span> solid <span class=\"hljs-number\">#ddd</span>;<span class=\"hljs-attribute\">border-right</span>:none;<span class=\"hljs-attribute\">position</span>:fixed;<span class=\"hljs-attribute\">right</span>:<span class=\"hljs-number\">40px</span>;<span class=\"hljs-attribute\">text-align</span>:center;<span class=\"hljs-attribute\">background-color</span>:<span class=\"hljs-number\">#f9f9f9</span>&#125;<span class=\"hljs-selector-class\">.show-toc-btn</span> <span class=\"hljs-selector-class\">.btn-bg</span>&#123;<span class=\"hljs-attribute\">margin-top</span>:<span class=\"hljs-number\">2px</span>;<span class=\"hljs-attribute\">display</span>:block;<span class=\"hljs-attribute\">width</span>:<span class=\"hljs-number\">16px</span>;<span class=\"hljs-attribute\">height</span>:<span class=\"hljs-number\">14px</span>;<span class=\"hljs-attribute\">background</span>:<span class=\"hljs-built_in\">url</span>(<span class=\"hljs-string\">http://7xtawy.com1.z0.glb.clouddn.com/show.png</span>) no-repeat;-webkit-<span class=\"hljs-attribute\">background-size</span>:<span class=\"hljs-number\">100%</span>;-moz-<span class=\"hljs-attribute\">background-size</span>:<span class=\"hljs-number\">100%</span>;<span class=\"hljs-attribute\">background-size</span>:<span class=\"hljs-number\">100%</span>&#125;<span class=\"hljs-selector-class\">.show-toc-btn</span> <span class=\"hljs-selector-class\">.btn-text</span>&#123;<span class=\"hljs-attribute\">color</span>:<span class=\"hljs-number\">#999</span>;<span class=\"hljs-attribute\">font-size</span>:<span class=\"hljs-number\">12px</span>&#125;<span class=\"hljs-selector-class\">.show-toc-btn</span><span class=\"hljs-selector-pseudo\">:hover</span>&#123;<span class=\"hljs-attribute\">cursor</span>:pointer&#125;<span class=\"hljs-selector-class\">.show-toc-btn</span><span class=\"hljs-selector-pseudo\">:hover</span> <span class=\"hljs-selector-class\">.btn-bg</span>&#123;<span class=\"hljs-attribute\">background-position</span>:<span class=\"hljs-number\">0</span> -<span class=\"hljs-number\">16px</span>&#125;<span class=\"hljs-selector-class\">.show-toc-btn</span><span class=\"hljs-selector-pseudo\">:hover</span> <span class=\"hljs-selector-class\">.btn-text</span>&#123;<span class=\"hljs-attribute\">font-size</span>:<span class=\"hljs-number\">12px</span>;<span class=\"hljs-attribute\">color</span>:<span class=\"hljs-number\">#ea8010</span>&#125;\n<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-tag\">li</span> <span class=\"hljs-selector-tag\">ol</span>, <span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-tag\">li</span> <span class=\"hljs-selector-tag\">ul</span> &#123;\n    <span class=\"hljs-attribute\">margin-left</span>: <span class=\"hljs-number\">30px</span>;\n&#125;\n<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-tag\">ol</span>, <span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-tag\">ul</span> &#123;\n    <span class=\"hljs-attribute\">margin</span>: <span class=\"hljs-number\">10px</span> <span class=\"hljs-number\">0</span>;\n&#125;</code></pre></div>\n<p>2.after <code>&lt;/header&gt;&lt;% &#125; %&gt;</code> in file <code>themes/yilia/layout/_partial/article.ejs</code> add</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs html\"><span class=\"hljs-comment\">&lt;!-- navigator --&gt;</span>\n&lt;% if (!index &amp;&amp; post.toc)&#123; %&gt;\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;show-toc-btn&quot;</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;show-toc-btn&quot;</span> <span class=\"hljs-attr\">onclick</span>=<span class=\"hljs-string\">&quot;showToc();&quot;</span> <span class=\"hljs-attr\">style</span>=<span class=\"hljs-string\">&quot;display:none&quot;</span>&gt;</span>\n        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">span</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;btn-bg&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">span</span>&gt;</span>\n        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">span</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;btn-text&quot;</span>&gt;</span>...<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">span</span>&gt;</span>\n        <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;toc-article&quot;</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;toc-article&quot;</span>&gt;</span>\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">span</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;toc-close&quot;</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;toc-close&quot;</span> <span class=\"hljs-attr\">title</span>=<span class=\"hljs-string\">&quot;hide navigator&quot;</span> <span class=\"hljs-attr\">onclick</span>=<span class=\"hljs-string\">&quot;showBtn();&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">span</span>&gt;</span>\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;toc-title&quot;</span>&gt;</span>navigator<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n        &lt;%- toc(post.content) %&gt;\n      <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">type</span>=<span class=\"hljs-string\">&quot;text/javascript&quot;</span>&gt;</span><span class=\"language-javascript\"></span>\n<span class=\"language-javascript\">  <span class=\"hljs-keyword\">function</span> <span class=\"hljs-title function_\">showToc</span>(<span class=\"hljs-params\"></span>)&#123;</span>\n<span class=\"language-javascript\">      <span class=\"hljs-keyword\">var</span> toc_article = <span class=\"hljs-variable language_\">document</span>.<span class=\"hljs-title function_\">getElementById</span>(<span class=\"hljs-string\">&quot;toc-article&quot;</span>);</span>\n<span class=\"language-javascript\">      <span class=\"hljs-keyword\">var</span> show_toc_btn = <span class=\"hljs-variable language_\">document</span>.<span class=\"hljs-title function_\">getElementById</span>(<span class=\"hljs-string\">&quot;show-toc-btn&quot;</span>);</span>\n<span class=\"language-javascript\">      toc_article.<span class=\"hljs-title function_\">setAttribute</span>(<span class=\"hljs-string\">&quot;style&quot;</span>,<span class=\"hljs-string\">&quot;display:block&quot;</span>);</span>\n<span class=\"language-javascript\">      show_toc_btn.<span class=\"hljs-title function_\">setAttribute</span>(<span class=\"hljs-string\">&quot;style&quot;</span>,<span class=\"hljs-string\">&quot;display:none&quot;</span>);</span>\n<span class=\"language-javascript\">      &#125;;</span>\n<span class=\"language-javascript\">  <span class=\"hljs-keyword\">function</span> <span class=\"hljs-title function_\">showBtn</span>(<span class=\"hljs-params\"></span>)&#123;</span>\n<span class=\"language-javascript\">      <span class=\"hljs-keyword\">var</span> toc_article = <span class=\"hljs-variable language_\">document</span>.<span class=\"hljs-title function_\">getElementById</span>(<span class=\"hljs-string\">&quot;toc-article&quot;</span>);</span>\n<span class=\"language-javascript\">      <span class=\"hljs-keyword\">var</span> show_toc_btn = <span class=\"hljs-variable language_\">document</span>.<span class=\"hljs-title function_\">getElementById</span>(<span class=\"hljs-string\">&quot;show-toc-btn&quot;</span>);</span>\n<span class=\"language-javascript\">      toc_article.<span class=\"hljs-title function_\">setAttribute</span>(<span class=\"hljs-string\">&quot;style&quot;</span>,<span class=\"hljs-string\">&quot;display:none&quot;</span>);</span>\n<span class=\"language-javascript\">      show_toc_btn.<span class=\"hljs-title function_\">setAttribute</span>(<span class=\"hljs-string\">&quot;style&quot;</span>,<span class=\"hljs-string\">&quot;display:block&quot;</span>);</span>\n<span class=\"language-javascript\">      &#125;;</span>\n<span class=\"language-javascript\"></span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">script</span>&gt;</span>\n    &lt;% &#125; %&gt;\n<span class=\"hljs-comment\">&lt;!-- navigator end --&gt;</span></code></pre></div>\n<p>3.add <code>toc:true</code> to the articles that need the navigator.</p>\n<h3 id=\"add-custormize-header-to-articles\">Add custormize header to articles</h3>\n<p>when run <code>hexo new</code> to initiate a new blog, a defaul head would generate, change it by</p>\n<p>change the <code>scaffolds/post.md</code> in the <code>root</code> directory</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs txt\">---\ntitle: &#123;&#123; title &#125;&#125;\ndate: &#123;&#123; date &#125;&#125;\nauthor: daydreamatnight\ntoc: true\ndeclare: true\ntags:\n---</code></pre></div>\n<h4 id=\"more-headers-to-choose-when-writing-a-blog\">more headers to choose when writing a blog</h4>\n<p>before a blog, more paras can be chosen to add</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs txt\">--- \ntitle: # \ntoc: ture #toc \ndate: 2020-09-07 09:25:00 # \nauthor: GavenLee # \nimg: /source/images/xxx.jpg # \ntop: true # \ncover: true # \ncoverImg: /images/1.jpg # \npassword: # \nmathjax: false #mathjax \nsummary:  \ncategories: Markdown # \ntags: # \nabbrlink: HexoLearn # \n---</code></pre></div>\n<h3 id=\"disable-auto-wrap-in-code-block\">Disable auto wrap in code block</h3>\n<p>locate and delete <code>white-space:pre-wrap</code> in file <code>themes/yilia/source/main.0cf68a.css</code></p>\n<h3 id=\"add-copy-button-to-code-block\">Add copy button to code block</h3>\n<p>1.create a <code>clipboard_use.js</code> file in directory <code>themes/yilia/source</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs js\">$(<span class=\"hljs-string\">&quot;.highlight&quot;</span>).<span class=\"hljs-title function_\">wrap</span>(<span class=\"hljs-string\">&quot;&lt;div class=&#x27;code-wrapper&#x27; style=&#x27;position:relative&#x27;&gt;&lt;/div&gt;&quot;</span>);\n<span class=\"hljs-comment\">/*create copy button after page loaded*/</span>\n!<span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\">e, t, a</span>) &#123;\n    <span class=\"hljs-comment\">/* code */</span>\n    <span class=\"hljs-keyword\">var</span> initCopyCode = <span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\"></span>) &#123;\n        <span class=\"hljs-keyword\">var</span> copyHtml = <span class=\"hljs-string\">&#x27;&#x27;</span>;\n        copyHtml += <span class=\"hljs-string\">&#x27;&lt;button class=&quot;btn-copy&quot; data-clipboard-snippet=&quot;&quot;&gt;&#x27;</span>;\n        copyHtml += <span class=\"hljs-string\">&#x27;  &lt;i class=&quot;fa fa-clipboard&quot;&gt;&lt;/i&gt;&lt;span&gt;copy&lt;/span&gt;&#x27;</span>;\n        copyHtml += <span class=\"hljs-string\">&#x27;&lt;/button&gt;&#x27;</span>;\n        $(<span class=\"hljs-string\">&quot;.highlight .code&quot;</span>).<span class=\"hljs-title function_\">before</span>(copyHtml);\n        <span class=\"hljs-keyword\">var</span> clipboard = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">ClipboardJS</span>(<span class=\"hljs-string\">&#x27;.btn-copy&#x27;</span>, &#123;\n            <span class=\"hljs-attr\">target</span>: <span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\">trigger</span>) &#123;\n                <span class=\"hljs-keyword\">return</span> trigger.<span class=\"hljs-property\">nextElementSibling</span>;\n            &#125;\n        &#125;);\n        clipboard.<span class=\"hljs-title function_\">on</span>(<span class=\"hljs-string\">&#x27;success&#x27;</span>, <span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\">e</span>) &#123;\n            e.<span class=\"hljs-property\">trigger</span>.<span class=\"hljs-property\">innerHTML</span> = <span class=\"hljs-string\">&quot;&lt;i class=&#x27;fa fa-check&#x27; style=&#x27;color:green&#x27;&gt;&lt;/i&gt;&lt;span style=&#x27;color:green&#x27;&gt;copy success&lt;/span&gt;&quot;</span>\n            <span class=\"hljs-built_in\">setTimeout</span>(<span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\"></span>) &#123;\n                e.<span class=\"hljs-property\">trigger</span>.<span class=\"hljs-property\">innerHTML</span> = <span class=\"hljs-string\">&quot;&lt;i class=&#x27;fa fa-clipboard&#x27;&gt;&lt;/i&gt;&lt;span&gt;copy&lt;/span&gt;&quot;</span>\n            &#125;, <span class=\"hljs-number\">1000</span>)\n            e.<span class=\"hljs-title function_\">clearSelection</span>();\n        &#125;);\n        clipboard.<span class=\"hljs-title function_\">on</span>(<span class=\"hljs-string\">&#x27;error&#x27;</span>, <span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\">e</span>) &#123;\n            e.<span class=\"hljs-property\">trigger</span>.<span class=\"hljs-property\">innerHTML</span> = <span class=\"hljs-string\">&quot;&lt;i class=&#x27;fa fa-exclamation&#x27; style=&#x27;color:red&#x27;&gt;&lt;/i&gt;&lt;span style=&#x27;color:red&#x27;&gt;copy success&lt;/span&gt;&quot;</span>\n            <span class=\"hljs-built_in\">setTimeout</span>(<span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\"></span>) &#123;\n                e.<span class=\"hljs-property\">trigger</span>.<span class=\"hljs-property\">innerHTML</span> = <span class=\"hljs-string\">&quot;&lt;i class=&#x27;fa fa-clipboard&#x27;&gt;&lt;/i&gt;&lt;span&gt;copy&lt;/span&gt;&quot;</span>\n            &#125;, <span class=\"hljs-number\">1000</span>)\n            e.<span class=\"hljs-title function_\">clearSelection</span>();\n        &#125;);\n    &#125;\n    <span class=\"hljs-title function_\">initCopyCode</span>();\n&#125;(<span class=\"hljs-variable language_\">window</span>, <span class=\"hljs-variable language_\">document</span>);</code></pre></div>\n<p>2.load .js file, edit <code>themes/yilia/layout/layout.ejs</code> file, add before <code>&lt;/body&gt;</code>.</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs html\"><span class=\"hljs-comment\">&lt;!-- copy button in code block--&gt;</span>\n<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">type</span>=<span class=\"hljs-string\">&quot;text/javascript&quot;</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">&quot;https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.js&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">script</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">type</span>=<span class=\"hljs-string\">&quot;text/javascript&quot;</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">&quot;https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">script</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">type</span>=<span class=\"hljs-string\">&quot;text/javascript&quot;</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">&quot;/clipboard_use.js&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">script</span>&gt;</span></code></pre></div>\n<p>3.add stylesheet the end of <code>themes/yilia/source/main.0cf68a.css</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs css\"><span class=\"hljs-comment\">/* code copy button */</span>\n<span class=\"hljs-selector-class\">.btn-copy</span> &#123;\n  <span class=\"hljs-attribute\">display</span>: inline-block;\n  <span class=\"hljs-attribute\">cursor</span>: pointer;\n  <span class=\"hljs-attribute\">background-color</span>: <span class=\"hljs-number\">#eee</span>;\n  <span class=\"hljs-attribute\">background-image</span>: <span class=\"hljs-built_in\">linear-gradient</span>(<span class=\"hljs-number\">#fcfcfc</span>, <span class=\"hljs-number\">#eee</span>);\n  <span class=\"hljs-attribute\">border</span>: <span class=\"hljs-number\">1px</span> solid <span class=\"hljs-number\">#d5d5d5</span>;\n  <span class=\"hljs-attribute\">border-radius</span>: <span class=\"hljs-number\">3px</span>;\n  -webkit-user-select: none;\n  -moz-user-select: none;\n  -ms-user-select: none;\n  user-select: none;\n  -webkit-appearance: none;\n  <span class=\"hljs-attribute\">font-size</span>: <span class=\"hljs-number\">13px</span>;\n  <span class=\"hljs-attribute\">font-weight</span>: <span class=\"hljs-number\">700</span>;\n  <span class=\"hljs-attribute\">line-height</span>: <span class=\"hljs-number\">20px</span>;\n  <span class=\"hljs-attribute\">color</span>: <span class=\"hljs-number\">#333</span>;\n  -webkit-<span class=\"hljs-attribute\">transition</span>: opacity .<span class=\"hljs-number\">3s</span> ease-in-out;\n  -o-<span class=\"hljs-attribute\">transition</span>: opacity .<span class=\"hljs-number\">3s</span> ease-in-out;\n  <span class=\"hljs-attribute\">transition</span>: opacity .<span class=\"hljs-number\">3s</span> ease-in-out;\n  <span class=\"hljs-attribute\">padding</span>: <span class=\"hljs-number\">2px</span> <span class=\"hljs-number\">6px</span>;\n  <span class=\"hljs-attribute\">position</span>: absolute;\n  <span class=\"hljs-attribute\">right</span>: <span class=\"hljs-number\">5px</span>;\n  <span class=\"hljs-attribute\">top</span>: <span class=\"hljs-number\">5px</span>;\n  <span class=\"hljs-attribute\">opacity</span>: <span class=\"hljs-number\">0</span>;\n&#125;\n<span class=\"hljs-selector-class\">.btn-copy</span> <span class=\"hljs-selector-tag\">span</span> &#123;\n  <span class=\"hljs-attribute\">margin-left</span>: <span class=\"hljs-number\">5px</span>;\n&#125;\n<span class=\"hljs-selector-class\">.highlight</span><span class=\"hljs-selector-pseudo\">:hover</span> <span class=\"hljs-selector-class\">.btn-copy</span> &#123;\n  <span class=\"hljs-attribute\">opacity</span>: <span class=\"hljs-number\">1</span>;\n&#125;\n<span class=\"hljs-comment\">/* code copy button end */</span></code></pre></div>\n<p>4.add copy button icon, edit <code>themes/yilia/layout/_partia/head.ejs</code> add before <code>&lt;/head&gt;</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs html\"><span class=\"hljs-comment\">&lt;!-- copy button icon --&gt;</span>\n<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">link</span> <span class=\"hljs-attr\">rel</span>=<span class=\"hljs-string\">&quot;stylesheet&quot;</span> <span class=\"hljs-attr\">type</span>=<span class=\"hljs-string\">&quot;text/css&quot;</span> <span class=\"hljs-attr\">href</span>=<span class=\"hljs-string\">&quot;//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css&quot;</span>&gt;</span></code></pre></div>\n<h3 id=\"allow-search-engines-to-index-this-blog\">Allow search engines to index this Blog</h3>\n<h4 id=\"index-google-to-this-blog\">index Google to this Blog</h4>\n<p>check if google can find you, enter <code>site:daydreamatnight.github.io</code> to see</p>\n<p><img src=\"check google search.png\" srcset=\"/img/loading.gif\" lazyload alt=\"check google search\" style=\"zoom:50%;\" /></p>\n<h5 id=\"add-url-to-goole-search-console\">Add url to goole search console</h5>\n<p>1.open <a href=\"https://search.google.com/search-console/welcome\">google console</a> , add URL link of the blog (https://daydreamatnight.github.io), in the <code>URL prefix</code> block, click <code>CONTINUE</code></p>\n<p><img src=\"google search console.png\" srcset=\"/img/loading.gif\" lazyload alt=\"google console\" style=\"zoom:50%;\" /></p>\n<p>2.upload the html file to the blog <code>root</code> directory and deploy the website, then clicke verify.</p>\n<p><img src=\"google console varification.png\" srcset=\"/img/loading.gif\" lazyload alt=\"google console varification\" style=\"zoom:50%;\" /></p>\n<p>little buggy here, see <a href=\"https://hilyy.xyz/how-to-allow-google-to-index-your-hexo-blog-website-google-search-console-verification-methods/\"><strong>dont upload</strong> the file <strong>using hexo</strong> command</a></p>\n<h5 id=\"add-sitemap-for-google\">add sitemap for google</h5>\n<p>add sitemap for google and baidu together</p>\n<blockquote>\n<p>A <em>sitemap</em> is a file where you provide information about the pages, videos, and other files on your site, and the relationships between them. Search engines like Google read this file to more intelligently crawl your site. A sitemap tells Google which pages and files you think are important in your site, and also provides valuable information about these files: for example, for pages, when the page was last updated, how often the page is changed, and any alternate language versions of a page.</p>\n</blockquote>\n<p>1.install sitemap plugins</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">npm install hexo-generator-sitemap --save</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">npm install hexo-generator-baidu-sitemap --save</span></code></pre></div>\n<p>2.add to the <code>_config.yml</code> in the blog <code>root</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs yml\"><span class=\"hljs-comment\"># hexo sitemap</span>\n<span class=\"hljs-attr\">sitemap:</span>\n  <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">sitemap.xml</span>\n<span class=\"hljs-attr\">baidusitemap:</span>\n  <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">baidusitemap.xml</span></code></pre></div>\n<p>3.Deploy the blog, go to https://daydreamatnight.github.io/sitemap.xml and https://daydreamatnight.github.io/baidusitemap.xml to see if sitemaps are uploaded</p>\n<p>4.Go to Google Search Console, in the left panel, click <code>Sitemaps</code>, enter your sitemap URL <code>sitemap.xml</code></p>\n<p><img src=\"can't fetch sitemap.png\" srcset=\"/img/loading.gif\" lazyload alt=\"can't fetch sitemap\" style=\"zoom:50%;\" /></p>\n<p>Googlebot won't download the sitemap immediately. Give it time.</p>\n<h5 id=\"add-robots.txt\">add robots.txt</h5>\n<blockquote>\n<p>A robots.txt file tells search engine crawlers which URLs the crawler can access on your site. This is used mainly to avoid overloading your site with requests; <strong>it is not a mechanism for keeping a web page out of Google</strong>. To keep a web page out of Google, <a href=\"https://developers.google.com/search/docs/advanced/crawling/block-indexing\">block indexing with <code>noindex</code></a> or password-protect the page.</p>\n<p>A robots.txt file is used primarily to manage crawler traffic to your site, and <em>usually</em> to keep a file off Google, depending on the file type:</p>\n</blockquote>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs txt\">User-agent: *\nAllow: /\nAllow: /archives/\nAllow: /tags/\nAllow: /categories/\nAllow: /about/\nAllow: /guestbook/\nAllow: /others/\n\n\nDisallow: /js/\nDisallow: /css/\nDisallow: /lib/\n\nSitemap: https://daydreamatnight.github.io/sitemap.xml\nSitemap: https://daydreamatnight.github.io/baidusitemap.xml</code></pre></div>\n<p>deploy the blog and wait.</p>\n<h5 id=\"check-if-sitemap-is-available\">check if sitemap is available</h5>\n<p>After uploaded several updates, my sitemap still didn't fetched by google. So I went to check, it turns out my url setting in <code>_config.yml</code> is wrong. So I changed it to be my home url. And check it with <a href=\"https://www.jcchouinard.com/url-inspection-tool/\">URL Inspection Tool</a>.</p>\n<p>1.Open <a href=\"https://search.google.com/search-console\">google search console</a>, add the url of sitemap in the upper url inspecting box.</p>\n<p><img src=\"Google%20sitemap%20inspect.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Google sitemap inspect URL is not on Google \" style=\"zoom:22%;\" /></p>\n<p><img src=\"Google%20sitemap%20inspect%202.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Google sitemap inspect 2\" style=\"zoom:22%;\" /></p>\n<p>It's normal it shows <code>URL is not on Google</code> because it shouldn't as a sitemap.</p>\n<p>2.click <code>live test</code> to check the availability.</p>\n<p><img src=\"Google%20sitemap%20inspect%203.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Google sitemap inspect 3\" style=\"zoom:75%;\" /></p>\n<p>It should be available, then just wait.</p>\n<h4 id=\"index-bing-to-this-blog\">index Bing to this Blog</h4>\n<p>1.go to <a href=\"https://www.bing.com/webmasters/\">Bing webmaster</a> and login</p>\n<p>2.connect with google webmaster.</p>\n<p><img src=\"bing%20sitemap.png\" srcset=\"/img/loading.gif\" lazyload alt=\"bing sitemap\" style=\"zoom:75%;\" /></p>\n<p><img src=\"being%20sitemap%20connect%20google.png\" srcset=\"/img/loading.gif\" lazyload alt=\"being sitemap connect google\" style=\"zoom:75%;\" /></p>\n<p><img src=\"bing%20search%20console%20success.png\" srcset=\"/img/loading.gif\" lazyload alt=\"bing search console success\" style=\"zoom:75%;\" /></p>\n<h4 id=\"index-baidu-to-this-blognot-possibly-working\">index baidu to this Blog(not possibly working)</h4>\n<p>go to the <a href=\"https://ziyuan.baidu.com/site/index\">baidu search console</a> ,</p>\n<p><img src=\"baidu console.png\" srcset=\"/img/loading.gif\" lazyload alt=\"baidu console\" style=\"zoom:50%;\" /></p>\n<p>Click <code></code> and input every thing, do similar thing</p>\n<p><img src=\"baidu console varification.png\" srcset=\"/img/loading.gif\" lazyload alt=\"baidu console varification\" style=\"zoom:50%;\" /></p>\n<p>add sitemap</p>\n<p><img src=\"baidu console sitemap.png\" srcset=\"/img/loading.gif\" lazyload alt=\"baidu console sitemap\" style=\"zoom:50%;\" /></p>\n<p>just wait forever, this could take 2000 years, so give up</p>\n<h3 id=\"add-copyright-statement\">Add copyright statement</h3>\n<p>1.open file <code>themes/yilia/layout/_partial/article.ejs</code> add before <code>&lt;% if ((theme.reward_type === 2 || (theme.reward_type === 1 &amp;&amp; post.reward)) &amp;&amp; !index)&#123; %&gt;</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs html\"><span class=\"hljs-comment\">&lt;!-- add copyright statement --&gt;</span>\n&lt;% if(theme.declare)&#123;%&gt;\n    &lt;%- partial(&#x27;post/declare&#x27;) %&gt;\n&lt;% &#125; %&gt;\n<span class=\"hljs-comment\">&lt;!-- end --&gt;</span></code></pre></div>\n<p>2.create new file <code>declare.ejs</code> under <code>themes/yilia/layout/_partial/post/</code> with:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs html\"><span class=\"hljs-comment\">&lt;!--add copyright statement https://github.com/JoeyBling/hexo-theme-yilia-plus/commit/c1215e132f6d5621c5fea83d3c4f7ccbcca074a3--&gt;</span>\n&lt;%\n  var sUrl = url.replace(/index\\.html$/, &#x27;&#x27;);\n  sUrl = /^(http:|https:)\\/\\//.test(sUrl) ? sUrl : &#x27;https:&#x27; + sUrl;\n%&gt;\n\n<span class=\"hljs-comment\">&lt;!-- #copyright setting0-close statement; 1-declare statement if declare: true in the article header; 2-always declare the copyright --&gt;</span>\n&lt;% if ((theme.declare.declare_type === 2 || (theme.declare.declare_type === 1 &amp;&amp; post.declare)) &amp;&amp; !index)&#123; %&gt;\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;declare&quot;</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;author&quot;</span>&gt;</span>author: <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n    &lt;% if(config.author != undefined)&#123; %&gt;\n      &lt;%= config.author%&gt;\n    &lt;% &#125;else&#123;%&gt;\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">font</span> <span class=\"hljs-attr\">color</span>=<span class=\"hljs-string\">&quot;red&quot;</span>&gt;</span>please add right &quot;author&quot; name in &quot;_config.yml&quot; in the blog root<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">font</span>&gt;</span>\n    &lt;%&#125;%&gt;\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">br</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;create-time&quot;</span>&gt;</span>posting date: <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n    &lt;%- date(post.date, &#x27;YYYY-MM-DD HH:MM:SS&#x27;) %&gt;\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">br</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;update-time&quot;</span>&gt;</span>last update: <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n    &lt;%- date(post.updated, &#x27;YYYY-MM-DD HH:MM:SS&#x27;) %&gt;\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">br</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;article-titles&quot;</span>&gt;</span>article title: <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">a</span> <span class=\"hljs-attr\">href</span>=<span class=\"hljs-string\">&quot;&lt;%= config.url %&gt;/&lt;%= post.path %&gt;&quot;</span> <span class=\"hljs-attr\">title</span>=<span class=\"hljs-string\">&quot;&lt;%= post.title %&gt;&quot;</span> <span class=\"hljs-attr\">target</span>=<span class=\"hljs-string\">&quot;_blank&quot;</span>&gt;</span>&lt;%= post.title %&gt;<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">a</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">br</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;article-url&quot;</span>&gt;</span>article link: <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">a</span> <span class=\"hljs-attr\">href</span>=<span class=\"hljs-string\">&quot;&lt;%= config.url %&gt;/&lt;%= post.path %&gt;&quot;</span> <span class=\"hljs-attr\">title</span>=<span class=\"hljs-string\">&quot;&lt;%= post.title %&gt;&quot;</span> <span class=\"hljs-attr\">target</span>=<span class=\"hljs-string\">&quot;_blank&quot;</span>&gt;</span>&lt;%= config.url %&gt;/&lt;%= post.path %&gt;<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">a</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">br</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;copyright&quot;</span>&gt;</span>copyright:<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n    This work is licensed under a\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">a</span> <span class=\"hljs-attr\">rel</span>=<span class=\"hljs-string\">&quot;license&quot;</span> <span class=\"hljs-attr\">href</span>=<span class=\"hljs-string\">&quot;&lt;%= theme.declare.licensee_url%&gt;&quot;</span> <span class=\"hljs-attr\">title</span>=<span class=\"hljs-string\">&quot;&lt;%= theme.declare.licensee_alias %&gt;&quot;</span>&gt;</span>&lt;%= theme.declare.licensee_name%&gt;<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">a</span>&gt;</span>\n    licience \n    &lt;% if(theme.declare.licensee_img != undefined)&#123; %&gt;\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">a</span> <span class=\"hljs-attr\">rel</span>=<span class=\"hljs-string\">&quot;license&quot;</span> <span class=\"hljs-attr\">href</span>=<span class=\"hljs-string\">&quot;&lt;%= theme.declare.licensee_url%&gt;&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">img</span> <span class=\"hljs-attr\">alt</span>=<span class=\"hljs-string\">&quot;&quot;</span> <span class=\"hljs-attr\">style</span>=<span class=\"hljs-string\">&quot;border-width:0&quot;</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">&quot;&lt;%= theme.declare.licensee_img%&gt;&quot;</span>/&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">a</span>&gt;</span>\n    &lt;% &#125; %&gt;\n  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n&lt;% &#125; else &#123;%&gt;\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;declare&quot;</span> <span class=\"hljs-attr\">hidden</span>=<span class=\"hljs-string\">&quot;hidden&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n&lt;% &#125; %&gt;\n<span class=\"hljs-comment\">&lt;!-- add copyright statement --&gt;</span></code></pre></div>\n<p>3.add stylesheet the end of <code>themes/yilia/source/main.0cf68a.css</code></p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs css\"><span class=\"hljs-comment\">/*stylesheet for the delcare*/</span>\n<span class=\"hljs-selector-class\">.declare</span> &#123;\n  <span class=\"hljs-attribute\">background-color</span>: <span class=\"hljs-number\">#eaeaea</span>;\n  <span class=\"hljs-attribute\">margin-top</span>: <span class=\"hljs-number\">2em</span>;\n  <span class=\"hljs-attribute\">border-left</span>: <span class=\"hljs-number\">3px</span> solid <span class=\"hljs-number\">#ff1700</span>;\n  <span class=\"hljs-attribute\">padding</span>: .<span class=\"hljs-number\">5em</span> <span class=\"hljs-number\">1em</span>; \n&#125;\n<span class=\"hljs-comment\">/*stylesheet for the delcare end*/</span></code></pre></div>\n<p>4.add at the end of <code>themes/yilia/_config.yml</code> file:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs awk\">declare:\n  declare_type: <span class=\"hljs-number\">1</span>\n  licensee_url: http:<span class=\"hljs-regexp\">//</span>creativecommons.org<span class=\"hljs-regexp\">/licenses/</span>by-nc-sa<span class=\"hljs-regexp\">/4.0/</span>      \n  licensee_name: <span class=\"hljs-string\">&#x27;CC BY-NC-SA 4.0&#x27;</span>                              \n  licensee_alias: <span class=\"hljs-string\">&#x27;CC BY-NC-SA 4.0&#x27;</span>     \n  licensee_img: https:<span class=\"hljs-regexp\">//i</span>.creativecommons.org<span class=\"hljs-regexp\">/l/</span>by-nc-sa<span class=\"hljs-regexp\">/4.0/</span><span class=\"hljs-number\">80</span>x15.png</code></pre></div>\n<h3 id=\"add-mind-map-support\">Add mind-map support</h3>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">npm install hexo-markmap</code></pre></div>\n<p>Detailed in its <a href=\"https://github.com/MaxChang3/hexo-markmap\">Github</a></p>\n<p>Example:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs markdown\">&#123;% markmap 300px %&#125;\n<span class=\"hljs-bullet\">-</span> Testa\n<span class=\"hljs-bullet\">  -</span> test1\n<span class=\"hljs-bullet\">  -</span> test2\n<span class=\"hljs-bullet\">-</span> Testb\n<span class=\"hljs-bullet\">  -</span> test1\n<span class=\"hljs-bullet\">  -</span> test2\n&#123;%endmarkmap%&#125;</code></pre></div>\n<h3 id=\"add-latex-math-support\">Add Latex math support</h3>\n<p>Change the renderer to the more powerful pandoc:</p>\n<p>1.Install pandoc on macOS:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs cmake\">copybrew <span class=\"hljs-keyword\">install</span> pandoc</code></pre></div>\n<p>2.in the blog root directory uninstall the default renderer then install the pandoc renderer:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs ada\">copynpm uninstall hexo-renderer-marked <span class=\"hljs-comment\">--save</span>\nnpm install hexo-renderer-pandoc <span class=\"hljs-comment\">--save</span></code></pre></div>\n<p>3.install the hexo math plugin</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs cmake\">copynpm <span class=\"hljs-keyword\">install</span> hexo-<span class=\"hljs-keyword\">math</span> --save</code></pre></div>\n<p>4.add these lines to the hexo <code>_config</code> file</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs nestedtext\"><span class=\"hljs-attribute\">copymarkdown</span><span class=\"hljs-punctuation\">:</span>\n  <span class=\"hljs-attribute\">plugins</span><span class=\"hljs-punctuation\">:</span>\n    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">markdown-it-footnote</span>\n    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">markdown-it-sup</span>\n    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">markdown-it-sub</span>\n    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">markdown-it-abbr</span>\n    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">markdown-it-emoji</span>\n    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">hexo-math</span></code></pre></div>\n<p>5.add these lines to the theme <code>_config</code> file</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs yaml\"><span class=\"hljs-string\">copy#</span> <span class=\"hljs-string\">MathJax</span> <span class=\"hljs-string\">Support</span>\n<span class=\"hljs-attr\">mathjax:</span>\n  <span class=\"hljs-attr\">enable:</span> <span class=\"hljs-literal\">true</span>\n  <span class=\"hljs-attr\">per_page:</span> <span class=\"hljs-literal\">true</span></code></pre></div>\n<p>6.rebuild the to blog see changes</p>\n<p>7.Examples: <span class=\"math inline\">\\(this_{is}an\\frac{inline}{equation}\\)</span> <span class=\"math display\">\\[\n\\begin{equation}\n    \\mathbf{K}_\\mathbf{1}=\\frac{1}{\\Delta r}\\ \\left[\\begin{matrix}\\begin{matrix}-1&amp;1\\\\-1&amp;1\\\\\\end{matrix}&amp;\\ &amp;\\ \\\\\\begin{matrix}\\ &amp;\\ddots\\\\\\end{matrix}&amp;\\begin{matrix}\\ddots&amp;\\ \\\\\\end{matrix}&amp;\\ \\\\\\ &amp;-1\\ &amp;1\\\\\\end{matrix}\\right],\\ \\ {\\ \\mathbf{K}}_\\mathbf{2}=\\frac{1}{\\Delta r}\\ \\left[\\begin{matrix}\\begin{matrix}-1&amp;1\\\\\\ &amp;\\ddots\\\\\\end{matrix}&amp;\\begin{matrix}\\\\\\ddots\\\\\\end{matrix}&amp;\\ \\\\\\begin{matrix}\\ &amp;\\ \\\\\\end{matrix}&amp;-1&amp;1\\ \\\\\\ &amp;-1\\ &amp;1\\\\\\end{matrix}\\right]\n    \\label{K2}\n\\end{equation}\n\\]</span></p>\n<h3 id=\"the-last-snapshot\">The last snapshot</h3>\n<p>Ok, never spend time on a no-longer maintained project. Here's the last figure of it.</p>\n<p><img src=\"Last snapshot.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Last snapshot\" style=\"zoom:80%;\" /></p>\n<h2 id=\"reference\">Reference</h2>\n<p>https://flatironschool.com/blog/the-benefits-of-blogging-how-and-why-to-keep-a-technical-blog/</p>\n<p>https://weblog.masukomi.org/2015/10/18/static-vs-dynamic-blogging/</p>\n<p>https://www.cnblogs.com/aoguai/p/11781505.html</p>\n<p>https://www.kblog.top/post/30452.html</p>\n<p>https://wkzqn.gitee.io/2020/02/16/typora%E7%BC%96%E5%86%99hexo%E5%8D%9A%E5%AE%A2%E6%97%B6%E7%9A%84%E5%9B%BE%E7%89%87%E6%98%BE%E7%A4%BA/</p>\n<p>https://segmentfault.com/a/1190000009478837#articleHeader5</p>\n<p>https://hilyy.xyz/how-to-allow-google-to-index-your-hexo-blog-website-google-search-console-verification-methods/</p>\n<p>https://busuanzi.ibruce.info/</p>\n<p>https://creativecommons.org/choose/results-one?license_code=by-nc-sa&amp;jurisdiction=&amp;version=4.0&amp;lang=en</p>\n<p>https://www.jcchouinard.com/sitemap-could-not-be-read-couldnt-fetch-in-google-search-console/</p>\n<p>https://cqh-i.github.io/2019/08/07/hexo-yilia%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E9%9A%90%E8%97%8F%E5%B7%A6%E8%BE%B9%E6%A0%8F%E7%9B%AE%E6%8C%89%E9%92%AE/</p>\n","site":{"data":{}},"wordcount":29761,"excerpt":"<blockquote>\n<p>Technical blog has a hundred benefits and no harm</p>\n<p>This blog records the process of building and customizing this personal blog from 0 to 1</p>\n</blockquote>\n<blockquote>\n<p>Unfortunately, the yilia theme has been no longer updating and it is too buggy right now. I switch to <a href=\"/2022/04/30/Switch-blog-theme-to-FLUID/\">other theme.</a></p>\n</blockquote>","more":"<h2 id=\"preliminary\">Preliminary</h2>\n<h3 id=\"why-personal-blog\">Why personal blog</h3>\n<blockquote>\n<p>Keeping a technical blog can be <strong>a great way of documenting your growth as a developer</strong>. This documentation can be particularly useful on a professional level. All software companies want to hire smart, thoughtful, communicative developers who can easily assimilate into a team, and who are ready to both teach and learn</p>\n</blockquote>\n<h3 id=\"static-vs-dynamic-blog\">Static vs dynamic blog</h3>\n<p>there are 2 types of mainstream personal blog: static and dynamic.</p>\n<p>Static is recommended considering its simplicity, 0 maintenance and 0 safety worry.</p>\n<table>\n<colgroup>\n<col style=\"width: 9%\" />\n<col style=\"width: 45%\" />\n<col style=\"width: 45%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\"></th>\n<th style=\"text-align: left;\">Static blog</th>\n<th style=\"text-align: left;\">Dynamic blog</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">Price</td>\n<td style=\"text-align: left;\">low, 0 cost when the traffic is relatively low</td>\n<td style=\"text-align: left;\">High, server is needed, cloud server of high performance is usually very expensive.</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">Features</td>\n<td style=\"text-align: left;\">Limited, only third-party services can be used to complete certain \"dynamic\" functions, such as comments</td>\n<td style=\"text-align: left;\">Rich, in WordPress for example, basically any kind of plugins can be found. Featuers such as auto-resizing, media players, multiple authors, scheduled posts, user analysis can be easily realize.</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">Speed</td>\n<td style=\"text-align: left;\">Fast</td>\n<td style=\"text-align: left;\">Slow</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">Maintainance</td>\n<td style=\"text-align: left;\">0</td>\n<td style=\"text-align: left;\">Need to care about the sever</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">Markdown</td>\n<td style=\"text-align: left;\">Supported yet it's the only choice</td>\n<td style=\"text-align: left;\">not supported</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">Geeky</td>\n<td style=\"text-align: left;\">YES</td>\n<td style=\"text-align: left;\">No</td>\n</tr>\n</tbody>\n</table>\n<p>And I also chose static because I'm geeky (poor of money) and results-driven (lazy to spend time on maintaining).</p>\n<h2 id=\"build-a-static-blog-via-hexo\">Build a static blog via hexo</h2>\n<h3 id=\"set-environment\">Set environment</h3>\n<p>1.check machine information: macOS on M1 MacBook</p>\n<p>2.Install Nodejs, including node and npm</p>\n<p>open https://nodejs.org/en/download/ and click download</p>\n<p><img src=\"node js install.png\" alt=\"node js install\" style=\"zoom:50%;\" /></p>\n<p>3.Install Git</p>\n<p>Aready installed</p>\n<p>4.Open terminal, check node, npm and git versions</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">npm -v</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">node -v</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">git --version</span>\n8.3.1\nv16.14.0\ngit version 2.32.0 (Apple Git-132)</code></pre>\n<h3 id=\"initialize-blog\">Initialize blog</h3>\n<p>1.install hexo via npm</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">sudo npm install -g hexo-cli</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo -v</span>\nINFO  Validating config\nhexo: 6.0.0\nhexo-cli: 4.3.0\nos: darwin 21.2.0 12.1\n\nnode: 16.14.0\nv8: 9.4.146.24-node.20\nuv: 1.43.0\nzlib: 1.2.11\nbrotli: 1.0.9\nares: 1.18.1\nmodules: 93\nnghttp2: 1.45.1\nnapi: 8\nllhttp: 6.0.4\nopenssl: 1.1.1m+quic\ncldr: 40.0\nicu: 70.1\ntz: 2021a3\nunicode: 14.0\nngtcp2: 0.1.0-DEV\nnghttp3: 0.1.0-DEV</code></pre>\n<p>2.create a new folder in terminal and initialize the blog</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\"><span class=\"hljs-built_in\">cd</span> ~/Documents/</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">makedir self_blog</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\"><span class=\"hljs-built_in\">cd</span> self_blog/</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo init</span>\nINFO  Cloning hexo-starter https://github.com/hexojs/hexo-starter.gitINFO  Install dependencies#########  idealTree:hexo-front-matter: timing idealTree:node_modules/hexo-front-matter Completed in 212msINFO  Start blogging with Hexo!</code></pre>\n<p>3.view the blog on localhost, s for start</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo s</span>\nINFO  Validating config\nINFO  Start processing\nINFO  Hexo is running at http://localhost:4000/ . Press Ctrl+C to stop.</code></pre>\n<h3 id=\"write-first-blog\">Write first blog</h3>\n<p>1.write a new blog, n for new</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo n <span class=\"hljs-string\">&#x27;Hello ShouRou&#x27;</span></span>\nINFO  Validating config\nINFO  Created: ~/Documents/self_blog/source/_posts/Hello-ShouRou.md</code></pre>\n<p>the blog can be written on any editor, Typora in use.</p>\n<pre><code class=\"hljs shell\">open ~/Documents/self_blog/source/_posts/Hello-ShouRou.md</code></pre>\n<p>2.clean cache(not necessary)</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo clean</span></code></pre>\n<p>3.generate the blog, g for generate</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo g</span>\nINFO  Validating config\nINFO  Start processing\nINFO  Files loaded in 61 ms\n(node:10719) Warning: Accessing non-existent property &#x27;lineno&#x27; of module exports inside circular dependency\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:10719) Warning: Accessing non-existent property &#x27;column&#x27; of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property &#x27;filename&#x27; of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property &#x27;lineno&#x27; of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property &#x27;column&#x27; of module exports inside circular dependency\n(node:10719) Warning: Accessing non-existent property &#x27;filename&#x27; of module exports inside circular dependency\nINFO  Generated: archives/2022/index.html\nINFO  Generated: archives/index.html\nINFO  Generated: js/script.js\nINFO  Generated: fancybox/jquery.fancybox.min.css\nINFO  Generated: index.html\nINFO  Generated: css/style.css\nINFO  Generated: css/fonts/fontawesome-webfont.woff2\nINFO  Generated: fancybox/jquery.fancybox.min.js\nINFO  Generated: js/jquery-3.4.1.min.js\nINFO  Generated: archives/2022/02/index.html\nINFO  Generated: css/fonts/FontAwesome.otf\nINFO  Generated: css/fonts/fontawesome-webfont.woff\nINFO  Generated: css/fonts/fontawesome-webfont.eot\nINFO  Generated: css/fonts/fontawesome-webfont.ttf\nINFO  Generated: css/images/banner.jpg\nINFO  Generated: 2022/02/22/hello-world/index.html\nINFO  Generated: css/fonts/fontawesome-webfont.svg\nINFO  Generated: 2022/02/22/Hello-ShouRou/index.html\nINFO  18 files generated in 161 ms</code></pre>\n<h3 id=\"deploy-to-remote-github\">Deploy to remote (GitHub)</h3>\n<p>1.Create a new repository with the name of $username.github.io</p>\n<p><img src=\"github page.png\" alt=\"github page\" style=\"zoom:50%;\" /></p>\n<p>use default setting</p>\n<p>2.open terminal, install plugin of deploying to git</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">npm install --save hexo-deployer-git</span></code></pre>\n<p>3.Open the <code>_config.yml</code> file in the blog <code>root</code> directory, add these lines afterwards</p>\n<pre><code class=\"hljs yml\"><span class=\"hljs-attr\">deploy:</span>\n <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">git</span>\n <span class=\"hljs-attr\">repo:</span> <span class=\"hljs-string\">git@github.com:DaydreamAtNight/DaydreamAtNight.github.io.git</span>\n <span class=\"hljs-attr\">branch:</span> <span class=\"hljs-string\">master</span></code></pre>\n<p>4.Go to the blog <code>root</code>, deploy the blog to remote, d for deploy</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo clean</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo g</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo d</span></code></pre>\n<p>Open https://daydreamatnight.github.io/ to see if it works</p>\n<h2 id=\"change-theme-to-yilia\">Change theme to yilia</h2>\n<p>default theme of hexo is called landscape and it's not beautiful enough to most of the people. Yilia is a fast, simple, elegant and popular theme. Thought it has not been updated since Nov 2017, it still a good choice for fresh bloggers.</p>\n<h3 id=\"download-and-deploy-yilia\">Download and deploy yilia</h3>\n<p>1.go to the blog <code>root</code></p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">git <span class=\"hljs-built_in\">clone</span> https://github.com/litten/hexo-theme-yilia theme/yilia</span></code></pre>\n<p>2.eidt the <code>_config.yml</code> file, add</p>\n<pre><code class=\"hljs yml\"><span class=\"hljs-attr\">theme:</span> <span class=\"hljs-string\">yilia</span></code></pre>\n<p>3.clean and deploy hexo</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo clean</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo g</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">hexo d</span></code></pre>\n<h3 id=\"basic-customize-yillia\">Basic customize yillia</h3>\n<h4 id=\"activate-aboutme-left-slider-button\">Activate <code>aboutme</code> left slider button</h4>\n<p>1.go to terminal run</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">npm i hexo-generator-json-content --save</span></code></pre>\n<p>2.go to the blog <code>root</code> directory, add these lines to the <code>_config.yml</code> file</p>\n<pre><code class=\"hljs yml\"><span class=\"hljs-attr\">jsonContent:</span>\n    <span class=\"hljs-attr\">meta:</span> <span class=\"hljs-literal\">false</span>\n    <span class=\"hljs-attr\">pages:</span> <span class=\"hljs-literal\">false</span>\n    <span class=\"hljs-attr\">posts:</span>\n      <span class=\"hljs-attr\">title:</span> <span class=\"hljs-literal\">true</span>\n      <span class=\"hljs-attr\">date:</span> <span class=\"hljs-literal\">true</span>\n      <span class=\"hljs-attr\">path:</span> <span class=\"hljs-literal\">true</span>\n      <span class=\"hljs-attr\">text:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">raw:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">content:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">slug:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">updated:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">comments:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">link:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">permalink:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">excerpt:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">categories:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">tags:</span> <span class=\"hljs-literal\">true</span></code></pre>\n<h4 id=\"customize-avatar\">Customize avatar</h4>\n<p>put the avatar file in directory <code>themes/yilia/source/img</code></p>\n<blockquote>\n<p>do not add to the public repository directly, or the img get cleaned every time running <code>hexo clean</code> , need to upload to the same dir again after this command.</p>\n</blockquote>\n<h4 id=\"set-favicon-icon-on-the-tab-of-website\">Set favicon (icon on the tab of website)</h4>\n<p>put the favicon img in directory <code>themes/yilia/source/img</code></p>\n<p><a href=\"https://www.bitbug.net/\">Bitbug</a> is a way of converting image into .ico file.</p>\n<h4 id=\"other-configuration\">Other configuration</h4>\n<p>Set file of yillia is in <code>themes/yilia/_config.yml</code> as:</p>\n<pre><code class=\"hljs yml\"><span class=\"hljs-comment\"># Header</span>\n<span class=\"hljs-attr\">author:</span> <span class=\"hljs-string\">Ryan</span> <span class=\"hljs-string\">LI</span>\n<span class=\"hljs-attr\">subtitle:</span> <span class=\"hljs-string\">&#x27;Daydreaming at night&#x27;</span>\n<span class=\"hljs-attr\">menu:</span>\n  <span class=\"hljs-attr\">main:</span> <span class=\"hljs-string\">/</span>\n  <span class=\"hljs-attr\">archives:</span> <span class=\"hljs-string\">/archives/index.html</span>\n  <span class=\"hljs-attr\">learn:</span> <span class=\"hljs-string\">/tags/learn/</span>\n\n<span class=\"hljs-comment\"># SubNav</span>\n<span class=\"hljs-attr\">subnav:</span>\n  <span class=\"hljs-attr\">github:</span> <span class=\"hljs-string\">&quot;https://github.com/DaydreamAtNight&quot;</span>\n  <span class=\"hljs-comment\"># weibo: &quot;#&quot;</span>\n  <span class=\"hljs-comment\"># rss: &quot;#&quot;</span>\n  <span class=\"hljs-comment\"># zhihu: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#qq: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#weixin: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#jianshu: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#douban: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#segmentfault: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#bilibili: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#acfun: &quot;#&quot;</span>\n  <span class=\"hljs-attr\">mail:</span> <span class=\"hljs-string\">&quot;mailto:lishoushou2019@gmail.com&quot;</span>\n  <span class=\"hljs-comment\">#facebook: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#google: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#twitter: &quot;#&quot;</span>\n  <span class=\"hljs-comment\">#linkedin: &quot;#&quot;</span>\n\n<span class=\"hljs-attr\">rss:</span> <span class=\"hljs-string\">/atom.xml</span>\n\n<span class=\"hljs-comment\">#  root </span>\n<span class=\"hljs-comment\">#  http://yoursite.com/blog</span>\n<span class=\"hljs-comment\">#  url  http://yoursite.com/blog  root  /blog/</span>\n<span class=\"hljs-attr\">root:</span> <span class=\"hljs-string\">/</span>\n\n<span class=\"hljs-comment\"># Content</span>\n\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-comment\"># excerpt_link: more</span>\n<span class=\"hljs-comment\"># false</span>\n<span class=\"hljs-attr\">show_all_link:</span> <span class=\"hljs-string\">&#x27;show all&#x27;</span>\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-attr\">mathjax:</span> <span class=\"hljs-literal\">false</span>\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-attr\">open_in_new:</span> <span class=\"hljs-literal\">false</span>\n\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-comment\"># type0- 1-mdreward:true 2-</span>\n<span class=\"hljs-attr\">reward_type:</span> <span class=\"hljs-number\">0</span>\n<span class=\"hljs-comment\"># # wording</span>\n<span class=\"hljs-comment\"># reward_wording: &#x27;&#x27;</span>\n<span class=\"hljs-comment\"># # /assets/img/alipay.jpg</span>\n<span class=\"hljs-comment\"># alipay: </span>\n<span class=\"hljs-comment\"># # </span>\n<span class=\"hljs-comment\"># weixin: </span>\n\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-comment\"># 0- 1-mdtoc:true 2-</span>\n<span class=\"hljs-attr\">toc:</span> <span class=\"hljs-number\">1</span>\n<span class=\"hljs-comment\"># truehexofalse</span>\n<span class=\"hljs-attr\">toc_hide_index:</span> <span class=\"hljs-literal\">true</span>\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-attr\">toc_empty_wording:</span> <span class=\"hljs-string\">&#x27;directery none exist&#x27;</span>\n\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-attr\">top:</span> <span class=\"hljs-literal\">true</span>\n\n<span class=\"hljs-comment\"># Miscellaneous</span>\n<span class=\"hljs-attr\">baidu_analytics:</span> <span class=\"hljs-string\">&#x27;&#x27;</span>\n<span class=\"hljs-attr\">google_analytics:</span> <span class=\"hljs-string\">&#x27;&#x27;</span>\n<span class=\"hljs-attr\">favicon:</span> <span class=\"hljs-string\">/img/favicon.ico</span>\n\n<span class=\"hljs-comment\">#url</span>\n<span class=\"hljs-attr\">avatar:</span> <span class=\"hljs-string\">/img/avatar.jpeg</span>\n\n<span class=\"hljs-comment\">#</span>\n<span class=\"hljs-comment\"># share_jia: true</span>\n\n<span class=\"hljs-comment\"># #1234Disqus5Gitment</span>\n<span class=\"hljs-comment\"># #false</span>\n<span class=\"hljs-comment\"># #wikihttps://github.com/litten/hexo-theme-yilia/wiki/</span>\n\n<span class=\"hljs-comment\"># #1</span>\n<span class=\"hljs-comment\"># duoshuo: false</span>\n\n<span class=\"hljs-comment\"># #2</span>\n<span class=\"hljs-comment\"># wangyiyun: false</span>\n\n<span class=\"hljs-comment\"># #3</span>\n<span class=\"hljs-comment\"># changyan_appid: false</span>\n<span class=\"hljs-comment\"># changyan_conf: false</span>\n\n<span class=\"hljs-comment\"># #4Disqus hexoconfigdisqus_shortnameyilia</span>\n<span class=\"hljs-comment\"># disqus: false</span>\n\n<span class=\"hljs-comment\"># #5Gitment</span>\n<span class=\"hljs-comment\"># gitment_owner: false      # GitHub ID</span>\n<span class=\"hljs-comment\"># gitment_repo: &#x27;&#x27;          # repo</span>\n<span class=\"hljs-comment\"># gitment_oauth:</span>\n<span class=\"hljs-comment\">#   client_id: &#x27;&#x27;           #client ID</span>\n<span class=\"hljs-comment\">#   client_secret: &#x27;&#x27;       #client secret</span>\n\n<span class=\"hljs-comment\">#  - </span>\n<span class=\"hljs-attr\">style:</span>\n  <span class=\"hljs-comment\"># </span>\n  <span class=\"hljs-attr\">header:</span> <span class=\"hljs-string\">&#x27;#ece0cf&#x27;</span>\n  <span class=\"hljs-comment\"># </span>\n  <span class=\"hljs-attr\">slider:</span> <span class=\"hljs-string\">&#x27;linear-gradient(45deg,#b4a698,#ece0cf)&#x27;</span>\n\n<span class=\"hljs-comment\"># slider</span>\n<span class=\"hljs-attr\">slider:</span>\n  <span class=\"hljs-comment\"># tags</span>\n  <span class=\"hljs-attr\">showTags:</span> <span class=\"hljs-literal\">false</span>\n\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-comment\"># false</span>\n<span class=\"hljs-comment\"># </span>\n<span class=\"hljs-comment\">#smart_menu:</span>\n<span class=\"hljs-comment\">#  friends: false</span>\n<span class=\"hljs-attr\">smart_menu:</span>\n  <span class=\"hljs-attr\">innerArchive:</span> <span class=\"hljs-string\">&#x27;All articles&#x27;</span>\n  <span class=\"hljs-comment\"># friends: &#x27;&#x27;</span>\n  <span class=\"hljs-attr\">aboutme:</span> <span class=\"hljs-string\">&#x27;About me&#x27;</span>\n\n<span class=\"hljs-comment\"># friends:</span>\n<span class=\"hljs-comment\">#   1: http://localhost:4000/</span>\n<span class=\"hljs-comment\">#   2: http://localhost:4000/</span>\n<span class=\"hljs-comment\">#   3: http://localhost:4000/</span>\n<span class=\"hljs-comment\">#   4: http://localhost:4000/</span>\n<span class=\"hljs-comment\">#   5: http://localhost:4000/</span>\n<span class=\"hljs-comment\">#   6: http://localhost:4000/</span>\n\n<span class=\"hljs-attr\">aboutme:</span> <span class=\"hljs-string\">Stay</span> <span class=\"hljs-string\">hungry,</span> <span class=\"hljs-string\">stay</span> <span class=\"hljs-string\">fullish</span></code></pre>\n<h2 id=\"advance-customize\">Advance customize</h2>\n<h3 id=\"stop-visit-litten.me9005\">Stop visit litten.me:9005</h3>\n<p>Sometimes the user's client information is collected, see <a href=\"https://github.com/litten/hexo-theme-yilia/issues/528\">here</a> for details.</p>\n<p>Stop reporting by clear the contents in <code>themes/yilia/source-src/js/report.js</code></p>\n<h3 id=\"limit-display-numbers-on-the-main-page\">Limit display numbers on the main page</h3>\n<p>Simply insert <code>&lt;! -- more --&gt;</code> to show only what comes before it while collapse the afterwards, click on the article title to read it in full.</p>\n<h3 id=\"easily-add-pics-to-blogs-via-hexo-renderer-marked-plugin\">Easily add pics to blogs via hexo-renderer-marked plugin</h3>\n<p>1.find <code>post_asset_folder</code> in <code>_config.yml</code> file in the blog <code>root</code> directory, set to be true</p>\n<pre><code class=\"hljs yml\"><span class=\"hljs-string\">post_asset_folder:true</span></code></pre>\n<p>2.Install plugin</p>\n<pre><code class=\"hljs shell\">npm install hexo-renderer-marked --save</code></pre>\n<p>3.change <code>_config.yml</code> in blog <code>root</code> directory as</p>\n<pre><code class=\"hljs yml\"><span class=\"hljs-attr\">post_asset_folder:</span> <span class=\"hljs-literal\">true</span>\n<span class=\"hljs-attr\">marked:</span>\n  <span class=\"hljs-attr\">prependRoot:</span> <span class=\"hljs-literal\">true</span>\n  <span class=\"hljs-attr\">postAsset:</span> <span class=\"hljs-literal\">true</span></code></pre>\n<p>then img can be easily add with <code>![img description](img.png)</code> after add the image to the folder with the same name as the article in <code>/source/_posts/</code></p>\n<p>4.change Typora pereference as</p>\n<p><img src=\"typora setting.png\" alt=\"typora setting\" style=\"zoom:50%;\" /></p>\n<p>img can drag into typro, yet blogname need to be deleted before deploying</p>\n<h3 id=\"show-number-of-articles-and-words-on-the-left-panel\">Show number of articles and words on the left panel</h3>\n<p>1.add wordcount plugin in terminal</p>\n<pre><code class=\"hljs shell\">npm i --save hexo-wordcount</code></pre>\n<p>2.change <code>themes/yilia/layout/_partial/left-col.ejs</code></p>\n<p>after</p>\n<pre><code class=\"hljs html\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">nav</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;header-menu&quot;</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">ul</span>&gt;</span>\n    &lt;% for (var i in theme.menu)&#123; %&gt;\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">li</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">a</span> <span class=\"hljs-attr\">href</span>=<span class=\"hljs-string\">&quot;&lt;%- url_for(theme.menu[i]) %&gt;&quot;</span>&gt;</span>&lt;%= i %&gt;<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">a</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">li</span>&gt;</span>\n    &lt;%&#125;%&gt;\n  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">ul</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">nav</span>&gt;</span></code></pre>\n<p>add</p>\n<pre><code class=\"hljs html\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">span</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;post-count&quot;</span>&gt;</span>&lt;%=site.posts.length%&gt; articles\n\t\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">span</span>&gt;</span>&lt;%= totalcount(site, &#x27;0,0.0a&#x27;) %&gt;<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">span</span>&gt;</span> words<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">span</span>&gt;</span></code></pre>\n<p>add style sheet in <code>themes/yilia/source/main.0cf68a.css</code></p>\n<pre><code class=\"hljs css\"><span class=\"hljs-selector-class\">.post-count</span>&#123;\n  <span class=\"hljs-attribute\">font-size</span>: <span class=\"hljs-number\">12px</span>;\n  <span class=\"hljs-attribute\">color</span>: <span class=\"hljs-number\">#696969</span>;\n&#125;</code></pre>\n<h3 id=\"show-number-of-visits-in-the-footer\">Show number of visits in the footer</h3>\n<p><a href=\"https://busuanzi.ibruce.info/\">busuanzi</a> is in use, which is super easy to deploy</p>\n<p>change <code>themes/yilia/layout/_partial/footer.ejs</code> as</p>\n<pre><code class=\"hljs html\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">footer</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;footer&quot;</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;outer&quot;</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;footer-info&quot;</span>&gt;</span>\n    \t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;footer-left&quot;</span>&gt;</span>\n    \t\t<span class=\"hljs-comment\">&lt;!-- total visits number --&gt;</span>\n          &lt;% if (theme.busuanzi &amp;&amp; theme.busuanzi.enable)&#123; %&gt;\n            <span class=\"hljs-comment\">&lt;!-- busuanzi statistics --&gt;</span>\n            <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">span</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;busuanzi_value_site_pv&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">span</span>&gt;</span><span class=\"hljs-symbol\">&amp;nbsp;</span>visits in total\n            <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">async</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">script</span>&gt;</span>\n          &lt;% &#125; %&gt;\n        <span class=\"hljs-comment\">&lt;!-- end --&gt;</span>\n    \t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n      \t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;footer-right&quot;</span>&gt;</span>\n      \t\t<span class=\"hljs-symbol\">&amp;copy;</span> &lt;%= date(new Date(), &#x27;YYYY&#x27;) %&gt; &lt;%= config.author || config.title %&gt;\n      \t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">footer</span>&gt;</span></code></pre>\n<p>and add</p>\n<pre><code class=\"hljs yml\"><span class=\"hljs-attr\">busuanzi:</span>\n  <span class=\"hljs-attr\">enable:</span> <span class=\"hljs-literal\">true</span></code></pre>\n<h3 id=\"add-button-of-hiding-the-left-panel\">Add button of hiding the left panel</h3>\n<p>Refer to <a href=\"https://cqh-i.github.io/2019/08/07/hexo-yilia%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E9%9A%90%E8%97%8F%E5%B7%A6%E8%BE%B9%E6%A0%8F%E7%9B%AE%E6%8C%89%E9%92%AE/\">hexo yilia</a></p>\n<p>1.add style list to file <code>/themes/yilia/source/main.0cf68a.css</code></p>\n<pre><code class=\"hljs css\"><span class=\"hljs-comment\">/*stylesheet for hide the left panel*/</span>\n<span class=\"hljs-selector-class\">.mymenucontainer</span> &#123;\n\t<span class=\"hljs-attribute\">display</span>:block;\n\t<span class=\"hljs-attribute\">cursor</span>:pointer;\n\t<span class=\"hljs-attribute\">left</span>:<span class=\"hljs-number\">0</span>;\n\t<span class=\"hljs-attribute\">top</span>:<span class=\"hljs-number\">0</span>;\n\t<span class=\"hljs-attribute\">width</span>:<span class=\"hljs-number\">35px</span>;\n\t<span class=\"hljs-attribute\">height</span>:<span class=\"hljs-number\">35px</span>;\n\t<span class=\"hljs-attribute\">z-index</span>:<span class=\"hljs-number\">9999</span>;\n\t<span class=\"hljs-attribute\">position</span>:fixed;\n&#125;\n<span class=\"hljs-selector-class\">.bar1</span> &#123;\n\t<span class=\"hljs-attribute\">width</span>:<span class=\"hljs-number\">35px</span>;\n\t<span class=\"hljs-attribute\">height</span>:<span class=\"hljs-number\">3px</span>;\n\t<span class=\"hljs-attribute\">border-radius</span>:<span class=\"hljs-number\">3px</span>;\n\t<span class=\"hljs-attribute\">background-color</span>:<span class=\"hljs-number\">#8E6D51</span>;\n\t<span class=\"hljs-attribute\">margin</span>:<span class=\"hljs-number\">6px</span> <span class=\"hljs-number\">0</span>;\n\t<span class=\"hljs-attribute\">transition</span>:<span class=\"hljs-number\">0.1s</span>;\n\t-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(-<span class=\"hljs-number\">45deg</span>) <span class=\"hljs-built_in\">translate</span>(-<span class=\"hljs-number\">8px</span>,<span class=\"hljs-number\">8px</span>);\n\t<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(-<span class=\"hljs-number\">45deg</span>) <span class=\"hljs-built_in\">translate</span>(-<span class=\"hljs-number\">8px</span>,<span class=\"hljs-number\">8px</span>);\n&#125;\n<span class=\"hljs-selector-class\">.bar2</span> &#123;\n\t<span class=\"hljs-attribute\">width</span>:<span class=\"hljs-number\">35px</span>;\n\t<span class=\"hljs-attribute\">height</span>:<span class=\"hljs-number\">3px</span>;\n\t<span class=\"hljs-attribute\">border-radius</span>:<span class=\"hljs-number\">3px</span>;\n\t<span class=\"hljs-attribute\">background-color</span>:<span class=\"hljs-number\">#8E6D51</span>;\n\t<span class=\"hljs-attribute\">margin</span>:<span class=\"hljs-number\">6px</span> <span class=\"hljs-number\">0</span>;\n\t<span class=\"hljs-attribute\">transition</span>:<span class=\"hljs-number\">0.1s</span>;\n\t<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">0</span>;\n&#125;\n<span class=\"hljs-selector-class\">.bar3</span> &#123;\n\t<span class=\"hljs-attribute\">width</span>:<span class=\"hljs-number\">35px</span>;\n\t<span class=\"hljs-attribute\">height</span>:<span class=\"hljs-number\">3px</span>;\n\t<span class=\"hljs-attribute\">border-radius</span>:<span class=\"hljs-number\">3px</span>;\n\t<span class=\"hljs-attribute\">background-color</span>:<span class=\"hljs-number\">#8E6D51</span>;\n\t<span class=\"hljs-attribute\">margin</span>:<span class=\"hljs-number\">6px</span> <span class=\"hljs-number\">0</span>;\n\t<span class=\"hljs-attribute\">transition</span>:<span class=\"hljs-number\">0.1s</span>;\n\t-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(<span class=\"hljs-number\">45deg</span>) <span class=\"hljs-built_in\">translate</span>(-<span class=\"hljs-number\">4px</span>,-<span class=\"hljs-number\">6px</span>);\n\t<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(<span class=\"hljs-number\">45deg</span>) <span class=\"hljs-built_in\">translate</span>(-<span class=\"hljs-number\">4px</span>,-<span class=\"hljs-number\">6px</span>);\n&#125;\n<span class=\"hljs-selector-class\">.change</span> <span class=\"hljs-selector-class\">.bar1</span> &#123;\n\t-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(<span class=\"hljs-number\">0deg</span>) <span class=\"hljs-built_in\">translate</span>(<span class=\"hljs-number\">0px</span>,<span class=\"hljs-number\">0px</span>);\n\t<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(<span class=\"hljs-number\">0deg</span>) <span class=\"hljs-built_in\">translate</span>(<span class=\"hljs-number\">0px</span>,<span class=\"hljs-number\">0px</span>);\n&#125;\n<span class=\"hljs-selector-class\">.change</span> <span class=\"hljs-selector-class\">.bar2</span> &#123;\n\t<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">1</span>;\n&#125;\n<span class=\"hljs-selector-class\">.change</span> <span class=\"hljs-selector-class\">.bar3</span> &#123;\n\t-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(<span class=\"hljs-number\">0deg</span>) <span class=\"hljs-built_in\">translate</span>(<span class=\"hljs-number\">0px</span>,<span class=\"hljs-number\">0px</span>);\n\t<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">rotate</span>(<span class=\"hljs-number\">0deg</span>) <span class=\"hljs-built_in\">translate</span>(<span class=\"hljs-number\">0px</span>,<span class=\"hljs-number\">0px</span>);\n&#125;\n<span class=\"hljs-comment\">/*stylesheet for hide the left panel end*/</span></code></pre>\n<p>2.go to <code>/themes/yilia/layout/layout.ejs</code> add before <code>&lt;div class=\"left-col\"</code></p>\n<pre><code class=\"hljs html\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;mymenucontainer&quot;</span> <span class=\"hljs-attr\">onclick</span>=<span class=\"hljs-string\">&quot;myFunction(this)&quot;</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;bar1&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;bar2&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;bar3&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span></code></pre>\n<p>3.add between <code>&lt;/body&gt;</code> and <code>&lt;/html&gt;</code></p>\n<pre><code class=\"hljs js\">&lt;script&gt;\n    <span class=\"hljs-keyword\">var</span> hide = <span class=\"hljs-literal\">false</span>;\n    <span class=\"hljs-keyword\">function</span> <span class=\"hljs-title function_\">myFunction</span>(<span class=\"hljs-params\">x</span>) &#123;\n        x.<span class=\"hljs-property\">classList</span>.<span class=\"hljs-title function_\">toggle</span>(<span class=\"hljs-string\">&quot;change&quot;</span>);\n        <span class=\"hljs-keyword\">if</span>(hide == <span class=\"hljs-literal\">false</span>)&#123;\n            $(<span class=\"hljs-string\">&quot;.left-col&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&#x27;display&#x27;</span>, <span class=\"hljs-string\">&#x27;none&#x27;</span>);\n            $(<span class=\"hljs-string\">&quot;.mid-col&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&quot;left&quot;</span>, <span class=\"hljs-number\">6</span>);\n            $(<span class=\"hljs-string\">&quot;.tools-col&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&#x27;display&#x27;</span>, <span class=\"hljs-string\">&#x27;none&#x27;</span>);\n            $(<span class=\"hljs-string\">&quot;.tools-col.hide&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&#x27;display&#x27;</span>, <span class=\"hljs-string\">&#x27;none&#x27;</span>);\n            hide = <span class=\"hljs-literal\">true</span>;\n        &#125;<span class=\"hljs-keyword\">else</span>&#123;\n            $(<span class=\"hljs-string\">&quot;.left-col&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&#x27;display&#x27;</span>, <span class=\"hljs-string\">&#x27;&#x27;</span>);\n            $(<span class=\"hljs-string\">&quot;.mid-col&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&quot;left&quot;</span>, <span class=\"hljs-number\">300</span>);\n            $(<span class=\"hljs-string\">&quot;.tools-col&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&#x27;display&#x27;</span>, <span class=\"hljs-string\">&#x27;&#x27;</span>);\n            $(<span class=\"hljs-string\">&quot;.tools-col.hide&quot;</span>).<span class=\"hljs-title function_\">css</span>(<span class=\"hljs-string\">&#x27;display&#x27;</span>, <span class=\"hljs-string\">&#x27;&#x27;</span>);\n            hide = <span class=\"hljs-literal\">false</span>;\n        &#125;\n    &#125;\n&lt;/script&gt;</code></pre>\n<h3 id=\"beautiful-contents-navigation-in-articles\">Beautiful contents navigation in articles</h3>\n<p>Default navigator is kind of ugly so found a more beautiful version, to use default version, simply change <code>toc: 2</code> in file <code>themes/yilia/_config.yml</code></p>\n<p>1.add this block at the end of <code>themes/yilia/source/main.0cf68a.css</code></p>\n<pre><code class=\"hljs css\"><span class=\"hljs-comment\">/* navigator */</span>\n<span class=\"hljs-selector-id\">#container</span> <span class=\"hljs-selector-class\">.show-toc-btn</span>,<span class=\"hljs-selector-id\">#container</span> <span class=\"hljs-selector-class\">.toc-article</span>&#123;<span class=\"hljs-attribute\">display</span>:block&#125;\n<span class=\"hljs-selector-class\">.toc-article</span>&#123;<span class=\"hljs-attribute\">z-index</span>:<span class=\"hljs-number\">100</span>;<span class=\"hljs-attribute\">background</span>:<span class=\"hljs-number\">#fff</span>;<span class=\"hljs-attribute\">border</span>:<span class=\"hljs-number\">1px</span> solid <span class=\"hljs-number\">#ccc</span>;<span class=\"hljs-attribute\">max-width</span>:<span class=\"hljs-number\">250px</span>;<span class=\"hljs-attribute\">min-width</span>:<span class=\"hljs-number\">150px</span>;<span class=\"hljs-attribute\">max-height</span>:<span class=\"hljs-number\">500px</span>;<span class=\"hljs-attribute\">overflow-y</span>:auto;-webkit-<span class=\"hljs-attribute\">box-shadow</span>:<span class=\"hljs-number\">5px</span> <span class=\"hljs-number\">5px</span> <span class=\"hljs-number\">2px</span> <span class=\"hljs-number\">#ccc</span>;<span class=\"hljs-attribute\">box-shadow</span>:<span class=\"hljs-number\">5px</span> <span class=\"hljs-number\">5px</span> <span class=\"hljs-number\">2px</span> <span class=\"hljs-number\">#ccc</span>;<span class=\"hljs-attribute\">font-size</span>:<span class=\"hljs-number\">12px</span>;<span class=\"hljs-attribute\">padding</span>:<span class=\"hljs-number\">10px</span>;<span class=\"hljs-attribute\">position</span>:fixed;<span class=\"hljs-attribute\">right</span>:<span class=\"hljs-number\">35px</span>;<span class=\"hljs-attribute\">top</span>:<span class=\"hljs-number\">129px</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc-close</span>&#123;<span class=\"hljs-attribute\">font-weight</span>:<span class=\"hljs-number\">700</span>;<span class=\"hljs-attribute\">font-size</span>:<span class=\"hljs-number\">20px</span>;<span class=\"hljs-attribute\">cursor</span>:pointer;<span class=\"hljs-attribute\">float</span><span class=\"hljs-selector-pseudo\">:right</span>;<span class=\"hljs-attribute\">color</span>:<span class=\"hljs-number\">#ccc</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc-close</span><span class=\"hljs-selector-pseudo\">:hover</span>&#123;<span class=\"hljs-attribute\">color</span>:<span class=\"hljs-number\">#000</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc</span>&#123;<span class=\"hljs-attribute\">font-size</span>:<span class=\"hljs-number\">12px</span>;<span class=\"hljs-attribute\">padding</span>:<span class=\"hljs-number\">0</span>;<span class=\"hljs-attribute\">line-height</span>:<span class=\"hljs-number\">20px</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc</span> <span class=\"hljs-selector-class\">.toc-number</span>&#123;<span class=\"hljs-attribute\">color</span>:<span class=\"hljs-number\">#333</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc</span> <span class=\"hljs-selector-class\">.toc-text</span><span class=\"hljs-selector-pseudo\">:hover</span>&#123;<span class=\"hljs-attribute\">text-decoration</span>:underline;<span class=\"hljs-attribute\">color</span>:<span class=\"hljs-number\">#2a6496</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-tag\">li</span>&#123;<span class=\"hljs-attribute\">list-style-type</span>:none&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc-level-1</span>&#123;<span class=\"hljs-attribute\">margin</span>:<span class=\"hljs-number\">4px</span> <span class=\"hljs-number\">0</span>&#125;<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-class\">.toc-child</span>&#123;&#125;<span class=\"hljs-keyword\">@-moz-keyframes</span> cd-bounce-<span class=\"hljs-number\">1</span>&#123;<span class=\"hljs-number\">0%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">0</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;<span class=\"hljs-number\">60%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">1</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>)&#125;<span class=\"hljs-number\">100%</span>&#123;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;&#125;<span class=\"hljs-keyword\">@-webkit-keyframes</span> cd-bounce-<span class=\"hljs-number\">1</span>&#123;<span class=\"hljs-number\">0%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">0</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;<span class=\"hljs-number\">60%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">1</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>)&#125;<span class=\"hljs-number\">100%</span>&#123;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;&#125;<span class=\"hljs-keyword\">@-o-keyframes</span> cd-bounce-<span class=\"hljs-number\">1</span>&#123;<span class=\"hljs-number\">0%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">0</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;<span class=\"hljs-number\">60%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">1</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>)&#125;<span class=\"hljs-number\">100%</span>&#123;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;&#125;<span class=\"hljs-keyword\">@keyframes</span> cd-bounce-<span class=\"hljs-number\">1</span>&#123;<span class=\"hljs-number\">0%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">0</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;<span class=\"hljs-number\">60%</span>&#123;<span class=\"hljs-attribute\">opacity</span>:<span class=\"hljs-number\">1</span>;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1.01</span>)&#125;<span class=\"hljs-number\">100%</span>&#123;-o-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-webkit-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-moz-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);-ms-<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>);<span class=\"hljs-attribute\">transform</span>:<span class=\"hljs-built_in\">scale</span>(<span class=\"hljs-number\">1</span>)&#125;&#125;<span class=\"hljs-selector-class\">.show-toc-btn</span>&#123;<span class=\"hljs-attribute\">display</span>:none;<span class=\"hljs-attribute\">z-index</span>:<span class=\"hljs-number\">10</span>;<span class=\"hljs-attribute\">width</span>:<span class=\"hljs-number\">30px</span>;<span class=\"hljs-attribute\">min-height</span>:<span class=\"hljs-number\">14px</span>;<span class=\"hljs-attribute\">overflow</span>:hidden;<span class=\"hljs-attribute\">padding</span>:<span class=\"hljs-number\">4px</span> <span class=\"hljs-number\">6px</span> <span class=\"hljs-number\">8px</span> <span class=\"hljs-number\">5px</span>;<span class=\"hljs-attribute\">border</span>:<span class=\"hljs-number\">1px</span> solid <span class=\"hljs-number\">#ddd</span>;<span class=\"hljs-attribute\">border-right</span>:none;<span class=\"hljs-attribute\">position</span>:fixed;<span class=\"hljs-attribute\">right</span>:<span class=\"hljs-number\">40px</span>;<span class=\"hljs-attribute\">text-align</span>:center;<span class=\"hljs-attribute\">background-color</span>:<span class=\"hljs-number\">#f9f9f9</span>&#125;<span class=\"hljs-selector-class\">.show-toc-btn</span> <span class=\"hljs-selector-class\">.btn-bg</span>&#123;<span class=\"hljs-attribute\">margin-top</span>:<span class=\"hljs-number\">2px</span>;<span class=\"hljs-attribute\">display</span>:block;<span class=\"hljs-attribute\">width</span>:<span class=\"hljs-number\">16px</span>;<span class=\"hljs-attribute\">height</span>:<span class=\"hljs-number\">14px</span>;<span class=\"hljs-attribute\">background</span>:<span class=\"hljs-built_in\">url</span>(<span class=\"hljs-string\">http://7xtawy.com1.z0.glb.clouddn.com/show.png</span>) no-repeat;-webkit-<span class=\"hljs-attribute\">background-size</span>:<span class=\"hljs-number\">100%</span>;-moz-<span class=\"hljs-attribute\">background-size</span>:<span class=\"hljs-number\">100%</span>;<span class=\"hljs-attribute\">background-size</span>:<span class=\"hljs-number\">100%</span>&#125;<span class=\"hljs-selector-class\">.show-toc-btn</span> <span class=\"hljs-selector-class\">.btn-text</span>&#123;<span class=\"hljs-attribute\">color</span>:<span class=\"hljs-number\">#999</span>;<span class=\"hljs-attribute\">font-size</span>:<span class=\"hljs-number\">12px</span>&#125;<span class=\"hljs-selector-class\">.show-toc-btn</span><span class=\"hljs-selector-pseudo\">:hover</span>&#123;<span class=\"hljs-attribute\">cursor</span>:pointer&#125;<span class=\"hljs-selector-class\">.show-toc-btn</span><span class=\"hljs-selector-pseudo\">:hover</span> <span class=\"hljs-selector-class\">.btn-bg</span>&#123;<span class=\"hljs-attribute\">background-position</span>:<span class=\"hljs-number\">0</span> -<span class=\"hljs-number\">16px</span>&#125;<span class=\"hljs-selector-class\">.show-toc-btn</span><span class=\"hljs-selector-pseudo\">:hover</span> <span class=\"hljs-selector-class\">.btn-text</span>&#123;<span class=\"hljs-attribute\">font-size</span>:<span class=\"hljs-number\">12px</span>;<span class=\"hljs-attribute\">color</span>:<span class=\"hljs-number\">#ea8010</span>&#125;\n<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-tag\">li</span> <span class=\"hljs-selector-tag\">ol</span>, <span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-tag\">li</span> <span class=\"hljs-selector-tag\">ul</span> &#123;\n    <span class=\"hljs-attribute\">margin-left</span>: <span class=\"hljs-number\">30px</span>;\n&#125;\n<span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-tag\">ol</span>, <span class=\"hljs-selector-class\">.toc-article</span> <span class=\"hljs-selector-tag\">ul</span> &#123;\n    <span class=\"hljs-attribute\">margin</span>: <span class=\"hljs-number\">10px</span> <span class=\"hljs-number\">0</span>;\n&#125;</code></pre>\n<p>2.after <code>&lt;/header&gt;&lt;% &#125; %&gt;</code> in file <code>themes/yilia/layout/_partial/article.ejs</code> add</p>\n<pre><code class=\"hljs html\"><span class=\"hljs-comment\">&lt;!-- navigator --&gt;</span>\n&lt;% if (!index &amp;&amp; post.toc)&#123; %&gt;\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;show-toc-btn&quot;</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;show-toc-btn&quot;</span> <span class=\"hljs-attr\">onclick</span>=<span class=\"hljs-string\">&quot;showToc();&quot;</span> <span class=\"hljs-attr\">style</span>=<span class=\"hljs-string\">&quot;display:none&quot;</span>&gt;</span>\n        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">span</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;btn-bg&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">span</span>&gt;</span>\n        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">span</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;btn-text&quot;</span>&gt;</span>...<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">span</span>&gt;</span>\n        <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;toc-article&quot;</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;toc-article&quot;</span>&gt;</span>\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">span</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;toc-close&quot;</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;toc-close&quot;</span> <span class=\"hljs-attr\">title</span>=<span class=\"hljs-string\">&quot;hide navigator&quot;</span> <span class=\"hljs-attr\">onclick</span>=<span class=\"hljs-string\">&quot;showBtn();&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">span</span>&gt;</span>\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;toc-title&quot;</span>&gt;</span>navigator<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n        &lt;%- toc(post.content) %&gt;\n      <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">type</span>=<span class=\"hljs-string\">&quot;text/javascript&quot;</span>&gt;</span><span class=\"language-javascript\"></span>\n<span class=\"language-javascript\">  <span class=\"hljs-keyword\">function</span> <span class=\"hljs-title function_\">showToc</span>(<span class=\"hljs-params\"></span>)&#123;</span>\n<span class=\"language-javascript\">      <span class=\"hljs-keyword\">var</span> toc_article = <span class=\"hljs-variable language_\">document</span>.<span class=\"hljs-title function_\">getElementById</span>(<span class=\"hljs-string\">&quot;toc-article&quot;</span>);</span>\n<span class=\"language-javascript\">      <span class=\"hljs-keyword\">var</span> show_toc_btn = <span class=\"hljs-variable language_\">document</span>.<span class=\"hljs-title function_\">getElementById</span>(<span class=\"hljs-string\">&quot;show-toc-btn&quot;</span>);</span>\n<span class=\"language-javascript\">      toc_article.<span class=\"hljs-title function_\">setAttribute</span>(<span class=\"hljs-string\">&quot;style&quot;</span>,<span class=\"hljs-string\">&quot;display:block&quot;</span>);</span>\n<span class=\"language-javascript\">      show_toc_btn.<span class=\"hljs-title function_\">setAttribute</span>(<span class=\"hljs-string\">&quot;style&quot;</span>,<span class=\"hljs-string\">&quot;display:none&quot;</span>);</span>\n<span class=\"language-javascript\">      &#125;;</span>\n<span class=\"language-javascript\">  <span class=\"hljs-keyword\">function</span> <span class=\"hljs-title function_\">showBtn</span>(<span class=\"hljs-params\"></span>)&#123;</span>\n<span class=\"language-javascript\">      <span class=\"hljs-keyword\">var</span> toc_article = <span class=\"hljs-variable language_\">document</span>.<span class=\"hljs-title function_\">getElementById</span>(<span class=\"hljs-string\">&quot;toc-article&quot;</span>);</span>\n<span class=\"language-javascript\">      <span class=\"hljs-keyword\">var</span> show_toc_btn = <span class=\"hljs-variable language_\">document</span>.<span class=\"hljs-title function_\">getElementById</span>(<span class=\"hljs-string\">&quot;show-toc-btn&quot;</span>);</span>\n<span class=\"language-javascript\">      toc_article.<span class=\"hljs-title function_\">setAttribute</span>(<span class=\"hljs-string\">&quot;style&quot;</span>,<span class=\"hljs-string\">&quot;display:none&quot;</span>);</span>\n<span class=\"language-javascript\">      show_toc_btn.<span class=\"hljs-title function_\">setAttribute</span>(<span class=\"hljs-string\">&quot;style&quot;</span>,<span class=\"hljs-string\">&quot;display:block&quot;</span>);</span>\n<span class=\"language-javascript\">      &#125;;</span>\n<span class=\"language-javascript\"></span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">script</span>&gt;</span>\n    &lt;% &#125; %&gt;\n<span class=\"hljs-comment\">&lt;!-- navigator end --&gt;</span></code></pre>\n<p>3.add <code>toc:true</code> to the articles that need the navigator.</p>\n<h3 id=\"add-custormize-header-to-articles\">Add custormize header to articles</h3>\n<p>when run <code>hexo new</code> to initiate a new blog, a defaul head would generate, change it by</p>\n<p>change the <code>scaffolds/post.md</code> in the <code>root</code> directory</p>\n<pre><code class=\"hljs txt\">---\ntitle: &#123;&#123; title &#125;&#125;\ndate: &#123;&#123; date &#125;&#125;\nauthor: daydreamatnight\ntoc: true\ndeclare: true\ntags:\n---</code></pre>\n<h4 id=\"more-headers-to-choose-when-writing-a-blog\">more headers to choose when writing a blog</h4>\n<p>before a blog, more paras can be chosen to add</p>\n<pre><code class=\"hljs txt\">--- \ntitle: # \ntoc: ture #toc \ndate: 2020-09-07 09:25:00 # \nauthor: GavenLee # \nimg: /source/images/xxx.jpg # \ntop: true # \ncover: true # \ncoverImg: /images/1.jpg # \npassword: # \nmathjax: false #mathjax \nsummary:  \ncategories: Markdown # \ntags: # \nabbrlink: HexoLearn # \n---</code></pre>\n<h3 id=\"disable-auto-wrap-in-code-block\">Disable auto wrap in code block</h3>\n<p>locate and delete <code>white-space:pre-wrap</code> in file <code>themes/yilia/source/main.0cf68a.css</code></p>\n<h3 id=\"add-copy-button-to-code-block\">Add copy button to code block</h3>\n<p>1.create a <code>clipboard_use.js</code> file in directory <code>themes/yilia/source</code></p>\n<pre><code class=\"hljs js\">$(<span class=\"hljs-string\">&quot;.highlight&quot;</span>).<span class=\"hljs-title function_\">wrap</span>(<span class=\"hljs-string\">&quot;&lt;div class=&#x27;code-wrapper&#x27; style=&#x27;position:relative&#x27;&gt;&lt;/div&gt;&quot;</span>);\n<span class=\"hljs-comment\">/*create copy button after page loaded*/</span>\n!<span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\">e, t, a</span>) &#123;\n    <span class=\"hljs-comment\">/* code */</span>\n    <span class=\"hljs-keyword\">var</span> initCopyCode = <span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\"></span>) &#123;\n        <span class=\"hljs-keyword\">var</span> copyHtml = <span class=\"hljs-string\">&#x27;&#x27;</span>;\n        copyHtml += <span class=\"hljs-string\">&#x27;&lt;button class=&quot;btn-copy&quot; data-clipboard-snippet=&quot;&quot;&gt;&#x27;</span>;\n        copyHtml += <span class=\"hljs-string\">&#x27;  &lt;i class=&quot;fa fa-clipboard&quot;&gt;&lt;/i&gt;&lt;span&gt;copy&lt;/span&gt;&#x27;</span>;\n        copyHtml += <span class=\"hljs-string\">&#x27;&lt;/button&gt;&#x27;</span>;\n        $(<span class=\"hljs-string\">&quot;.highlight .code&quot;</span>).<span class=\"hljs-title function_\">before</span>(copyHtml);\n        <span class=\"hljs-keyword\">var</span> clipboard = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">ClipboardJS</span>(<span class=\"hljs-string\">&#x27;.btn-copy&#x27;</span>, &#123;\n            <span class=\"hljs-attr\">target</span>: <span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\">trigger</span>) &#123;\n                <span class=\"hljs-keyword\">return</span> trigger.<span class=\"hljs-property\">nextElementSibling</span>;\n            &#125;\n        &#125;);\n        clipboard.<span class=\"hljs-title function_\">on</span>(<span class=\"hljs-string\">&#x27;success&#x27;</span>, <span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\">e</span>) &#123;\n            e.<span class=\"hljs-property\">trigger</span>.<span class=\"hljs-property\">innerHTML</span> = <span class=\"hljs-string\">&quot;&lt;i class=&#x27;fa fa-check&#x27; style=&#x27;color:green&#x27;&gt;&lt;/i&gt;&lt;span style=&#x27;color:green&#x27;&gt;copy success&lt;/span&gt;&quot;</span>\n            <span class=\"hljs-built_in\">setTimeout</span>(<span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\"></span>) &#123;\n                e.<span class=\"hljs-property\">trigger</span>.<span class=\"hljs-property\">innerHTML</span> = <span class=\"hljs-string\">&quot;&lt;i class=&#x27;fa fa-clipboard&#x27;&gt;&lt;/i&gt;&lt;span&gt;copy&lt;/span&gt;&quot;</span>\n            &#125;, <span class=\"hljs-number\">1000</span>)\n            e.<span class=\"hljs-title function_\">clearSelection</span>();\n        &#125;);\n        clipboard.<span class=\"hljs-title function_\">on</span>(<span class=\"hljs-string\">&#x27;error&#x27;</span>, <span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\">e</span>) &#123;\n            e.<span class=\"hljs-property\">trigger</span>.<span class=\"hljs-property\">innerHTML</span> = <span class=\"hljs-string\">&quot;&lt;i class=&#x27;fa fa-exclamation&#x27; style=&#x27;color:red&#x27;&gt;&lt;/i&gt;&lt;span style=&#x27;color:red&#x27;&gt;copy success&lt;/span&gt;&quot;</span>\n            <span class=\"hljs-built_in\">setTimeout</span>(<span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\"></span>) &#123;\n                e.<span class=\"hljs-property\">trigger</span>.<span class=\"hljs-property\">innerHTML</span> = <span class=\"hljs-string\">&quot;&lt;i class=&#x27;fa fa-clipboard&#x27;&gt;&lt;/i&gt;&lt;span&gt;copy&lt;/span&gt;&quot;</span>\n            &#125;, <span class=\"hljs-number\">1000</span>)\n            e.<span class=\"hljs-title function_\">clearSelection</span>();\n        &#125;);\n    &#125;\n    <span class=\"hljs-title function_\">initCopyCode</span>();\n&#125;(<span class=\"hljs-variable language_\">window</span>, <span class=\"hljs-variable language_\">document</span>);</code></pre>\n<p>2.load .js file, edit <code>themes/yilia/layout/layout.ejs</code> file, add before <code>&lt;/body&gt;</code>.</p>\n<pre><code class=\"hljs html\"><span class=\"hljs-comment\">&lt;!-- copy button in code block--&gt;</span>\n<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">type</span>=<span class=\"hljs-string\">&quot;text/javascript&quot;</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">&quot;https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.js&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">script</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">type</span>=<span class=\"hljs-string\">&quot;text/javascript&quot;</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">&quot;https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">script</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">type</span>=<span class=\"hljs-string\">&quot;text/javascript&quot;</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">&quot;/clipboard_use.js&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">script</span>&gt;</span></code></pre>\n<p>3.add stylesheet the end of <code>themes/yilia/source/main.0cf68a.css</code></p>\n<pre><code class=\"hljs css\"><span class=\"hljs-comment\">/* code copy button */</span>\n<span class=\"hljs-selector-class\">.btn-copy</span> &#123;\n  <span class=\"hljs-attribute\">display</span>: inline-block;\n  <span class=\"hljs-attribute\">cursor</span>: pointer;\n  <span class=\"hljs-attribute\">background-color</span>: <span class=\"hljs-number\">#eee</span>;\n  <span class=\"hljs-attribute\">background-image</span>: <span class=\"hljs-built_in\">linear-gradient</span>(<span class=\"hljs-number\">#fcfcfc</span>, <span class=\"hljs-number\">#eee</span>);\n  <span class=\"hljs-attribute\">border</span>: <span class=\"hljs-number\">1px</span> solid <span class=\"hljs-number\">#d5d5d5</span>;\n  <span class=\"hljs-attribute\">border-radius</span>: <span class=\"hljs-number\">3px</span>;\n  -webkit-user-select: none;\n  -moz-user-select: none;\n  -ms-user-select: none;\n  user-select: none;\n  -webkit-appearance: none;\n  <span class=\"hljs-attribute\">font-size</span>: <span class=\"hljs-number\">13px</span>;\n  <span class=\"hljs-attribute\">font-weight</span>: <span class=\"hljs-number\">700</span>;\n  <span class=\"hljs-attribute\">line-height</span>: <span class=\"hljs-number\">20px</span>;\n  <span class=\"hljs-attribute\">color</span>: <span class=\"hljs-number\">#333</span>;\n  -webkit-<span class=\"hljs-attribute\">transition</span>: opacity .<span class=\"hljs-number\">3s</span> ease-in-out;\n  -o-<span class=\"hljs-attribute\">transition</span>: opacity .<span class=\"hljs-number\">3s</span> ease-in-out;\n  <span class=\"hljs-attribute\">transition</span>: opacity .<span class=\"hljs-number\">3s</span> ease-in-out;\n  <span class=\"hljs-attribute\">padding</span>: <span class=\"hljs-number\">2px</span> <span class=\"hljs-number\">6px</span>;\n  <span class=\"hljs-attribute\">position</span>: absolute;\n  <span class=\"hljs-attribute\">right</span>: <span class=\"hljs-number\">5px</span>;\n  <span class=\"hljs-attribute\">top</span>: <span class=\"hljs-number\">5px</span>;\n  <span class=\"hljs-attribute\">opacity</span>: <span class=\"hljs-number\">0</span>;\n&#125;\n<span class=\"hljs-selector-class\">.btn-copy</span> <span class=\"hljs-selector-tag\">span</span> &#123;\n  <span class=\"hljs-attribute\">margin-left</span>: <span class=\"hljs-number\">5px</span>;\n&#125;\n<span class=\"hljs-selector-class\">.highlight</span><span class=\"hljs-selector-pseudo\">:hover</span> <span class=\"hljs-selector-class\">.btn-copy</span> &#123;\n  <span class=\"hljs-attribute\">opacity</span>: <span class=\"hljs-number\">1</span>;\n&#125;\n<span class=\"hljs-comment\">/* code copy button end */</span></code></pre>\n<p>4.add copy button icon, edit <code>themes/yilia/layout/_partia/head.ejs</code> add before <code>&lt;/head&gt;</code></p>\n<pre><code class=\"hljs html\"><span class=\"hljs-comment\">&lt;!-- copy button icon --&gt;</span>\n<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">link</span> <span class=\"hljs-attr\">rel</span>=<span class=\"hljs-string\">&quot;stylesheet&quot;</span> <span class=\"hljs-attr\">type</span>=<span class=\"hljs-string\">&quot;text/css&quot;</span> <span class=\"hljs-attr\">href</span>=<span class=\"hljs-string\">&quot;//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css&quot;</span>&gt;</span></code></pre>\n<h3 id=\"allow-search-engines-to-index-this-blog\">Allow search engines to index this Blog</h3>\n<h4 id=\"index-google-to-this-blog\">index Google to this Blog</h4>\n<p>check if google can find you, enter <code>site:daydreamatnight.github.io</code> to see</p>\n<p><img src=\"check google search.png\" alt=\"check google search\" style=\"zoom:50%;\" /></p>\n<h5 id=\"add-url-to-goole-search-console\">Add url to goole search console</h5>\n<p>1.open <a href=\"https://search.google.com/search-console/welcome\">google console</a> , add URL link of the blog (https://daydreamatnight.github.io), in the <code>URL prefix</code> block, click <code>CONTINUE</code></p>\n<p><img src=\"google search console.png\" alt=\"google console\" style=\"zoom:50%;\" /></p>\n<p>2.upload the html file to the blog <code>root</code> directory and deploy the website, then clicke verify.</p>\n<p><img src=\"google console varification.png\" alt=\"google console varification\" style=\"zoom:50%;\" /></p>\n<p>little buggy here, see <a href=\"https://hilyy.xyz/how-to-allow-google-to-index-your-hexo-blog-website-google-search-console-verification-methods/\"><strong>dont upload</strong> the file <strong>using hexo</strong> command</a></p>\n<h5 id=\"add-sitemap-for-google\">add sitemap for google</h5>\n<p>add sitemap for google and baidu together</p>\n<blockquote>\n<p>A <em>sitemap</em> is a file where you provide information about the pages, videos, and other files on your site, and the relationships between them. Search engines like Google read this file to more intelligently crawl your site. A sitemap tells Google which pages and files you think are important in your site, and also provides valuable information about these files: for example, for pages, when the page was last updated, how often the page is changed, and any alternate language versions of a page.</p>\n</blockquote>\n<p>1.install sitemap plugins</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">npm install hexo-generator-sitemap --save</span>\n<span class=\"hljs-meta\">$ </span><span class=\"language-bash\">npm install hexo-generator-baidu-sitemap --save</span></code></pre>\n<p>2.add to the <code>_config.yml</code> in the blog <code>root</code></p>\n<pre><code class=\"hljs yml\"><span class=\"hljs-comment\"># hexo sitemap</span>\n<span class=\"hljs-attr\">sitemap:</span>\n  <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">sitemap.xml</span>\n<span class=\"hljs-attr\">baidusitemap:</span>\n  <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">baidusitemap.xml</span></code></pre>\n<p>3.Deploy the blog, go to https://daydreamatnight.github.io/sitemap.xml and https://daydreamatnight.github.io/baidusitemap.xml to see if sitemaps are uploaded</p>\n<p>4.Go to Google Search Console, in the left panel, click <code>Sitemaps</code>, enter your sitemap URL <code>sitemap.xml</code></p>\n<p><img src=\"can't fetch sitemap.png\" alt=\"can't fetch sitemap\" style=\"zoom:50%;\" /></p>\n<p>Googlebot won't download the sitemap immediately. Give it time.</p>\n<h5 id=\"add-robots.txt\">add robots.txt</h5>\n<blockquote>\n<p>A robots.txt file tells search engine crawlers which URLs the crawler can access on your site. This is used mainly to avoid overloading your site with requests; <strong>it is not a mechanism for keeping a web page out of Google</strong>. To keep a web page out of Google, <a href=\"https://developers.google.com/search/docs/advanced/crawling/block-indexing\">block indexing with <code>noindex</code></a> or password-protect the page.</p>\n<p>A robots.txt file is used primarily to manage crawler traffic to your site, and <em>usually</em> to keep a file off Google, depending on the file type:</p>\n</blockquote>\n<pre><code class=\"hljs txt\">User-agent: *\nAllow: /\nAllow: /archives/\nAllow: /tags/\nAllow: /categories/\nAllow: /about/\nAllow: /guestbook/\nAllow: /others/\n\n\nDisallow: /js/\nDisallow: /css/\nDisallow: /lib/\n\nSitemap: https://daydreamatnight.github.io/sitemap.xml\nSitemap: https://daydreamatnight.github.io/baidusitemap.xml</code></pre>\n<p>deploy the blog and wait.</p>\n<h5 id=\"check-if-sitemap-is-available\">check if sitemap is available</h5>\n<p>After uploaded several updates, my sitemap still didn't fetched by google. So I went to check, it turns out my url setting in <code>_config.yml</code> is wrong. So I changed it to be my home url. And check it with <a href=\"https://www.jcchouinard.com/url-inspection-tool/\">URL Inspection Tool</a>.</p>\n<p>1.Open <a href=\"https://search.google.com/search-console\">google search console</a>, add the url of sitemap in the upper url inspecting box.</p>\n<p><img src=\"Google%20sitemap%20inspect.png\" alt=\"Google sitemap inspect URL is not on Google \" style=\"zoom:22%;\" /></p>\n<p><img src=\"Google%20sitemap%20inspect%202.png\" alt=\"Google sitemap inspect 2\" style=\"zoom:22%;\" /></p>\n<p>It's normal it shows <code>URL is not on Google</code> because it shouldn't as a sitemap.</p>\n<p>2.click <code>live test</code> to check the availability.</p>\n<p><img src=\"Google%20sitemap%20inspect%203.png\" alt=\"Google sitemap inspect 3\" style=\"zoom:75%;\" /></p>\n<p>It should be available, then just wait.</p>\n<h4 id=\"index-bing-to-this-blog\">index Bing to this Blog</h4>\n<p>1.go to <a href=\"https://www.bing.com/webmasters/\">Bing webmaster</a> and login</p>\n<p>2.connect with google webmaster.</p>\n<p><img src=\"bing%20sitemap.png\" alt=\"bing sitemap\" style=\"zoom:75%;\" /></p>\n<p><img src=\"being%20sitemap%20connect%20google.png\" alt=\"being sitemap connect google\" style=\"zoom:75%;\" /></p>\n<p><img src=\"bing%20search%20console%20success.png\" alt=\"bing search console success\" style=\"zoom:75%;\" /></p>\n<h4 id=\"index-baidu-to-this-blognot-possibly-working\">index baidu to this Blog(not possibly working)</h4>\n<p>go to the <a href=\"https://ziyuan.baidu.com/site/index\">baidu search console</a> ,</p>\n<p><img src=\"baidu console.png\" alt=\"baidu console\" style=\"zoom:50%;\" /></p>\n<p>Click <code></code> and input every thing, do similar thing</p>\n<p><img src=\"baidu console varification.png\" alt=\"baidu console varification\" style=\"zoom:50%;\" /></p>\n<p>add sitemap</p>\n<p><img src=\"baidu console sitemap.png\" alt=\"baidu console sitemap\" style=\"zoom:50%;\" /></p>\n<p>just wait forever, this could take 2000 years, so give up</p>\n<h3 id=\"add-copyright-statement\">Add copyright statement</h3>\n<p>1.open file <code>themes/yilia/layout/_partial/article.ejs</code> add before <code>&lt;% if ((theme.reward_type === 2 || (theme.reward_type === 1 &amp;&amp; post.reward)) &amp;&amp; !index)&#123; %&gt;</code></p>\n<pre><code class=\"hljs html\"><span class=\"hljs-comment\">&lt;!-- add copyright statement --&gt;</span>\n&lt;% if(theme.declare)&#123;%&gt;\n    &lt;%- partial(&#x27;post/declare&#x27;) %&gt;\n&lt;% &#125; %&gt;\n<span class=\"hljs-comment\">&lt;!-- end --&gt;</span></code></pre>\n<p>2.create new file <code>declare.ejs</code> under <code>themes/yilia/layout/_partial/post/</code> with:</p>\n<pre><code class=\"hljs html\"><span class=\"hljs-comment\">&lt;!--add copyright statement https://github.com/JoeyBling/hexo-theme-yilia-plus/commit/c1215e132f6d5621c5fea83d3c4f7ccbcca074a3--&gt;</span>\n&lt;%\n  var sUrl = url.replace(/index\\.html$/, &#x27;&#x27;);\n  sUrl = /^(http:|https:)\\/\\//.test(sUrl) ? sUrl : &#x27;https:&#x27; + sUrl;\n%&gt;\n\n<span class=\"hljs-comment\">&lt;!-- #copyright setting0-close statement; 1-declare statement if declare: true in the article header; 2-always declare the copyright --&gt;</span>\n&lt;% if ((theme.declare.declare_type === 2 || (theme.declare.declare_type === 1 &amp;&amp; post.declare)) &amp;&amp; !index)&#123; %&gt;\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;declare&quot;</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;author&quot;</span>&gt;</span>author: <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n    &lt;% if(config.author != undefined)&#123; %&gt;\n      &lt;%= config.author%&gt;\n    &lt;% &#125;else&#123;%&gt;\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">font</span> <span class=\"hljs-attr\">color</span>=<span class=\"hljs-string\">&quot;red&quot;</span>&gt;</span>please add right &quot;author&quot; name in &quot;_config.yml&quot; in the blog root<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">font</span>&gt;</span>\n    &lt;%&#125;%&gt;\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">br</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;create-time&quot;</span>&gt;</span>posting date: <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n    &lt;%- date(post.date, &#x27;YYYY-MM-DD HH:MM:SS&#x27;) %&gt;\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">br</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;update-time&quot;</span>&gt;</span>last update: <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n    &lt;%- date(post.updated, &#x27;YYYY-MM-DD HH:MM:SS&#x27;) %&gt;\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">br</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;article-titles&quot;</span>&gt;</span>article title: <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">a</span> <span class=\"hljs-attr\">href</span>=<span class=\"hljs-string\">&quot;&lt;%= config.url %&gt;/&lt;%= post.path %&gt;&quot;</span> <span class=\"hljs-attr\">title</span>=<span class=\"hljs-string\">&quot;&lt;%= post.title %&gt;&quot;</span> <span class=\"hljs-attr\">target</span>=<span class=\"hljs-string\">&quot;_blank&quot;</span>&gt;</span>&lt;%= post.title %&gt;<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">a</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">br</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;article-url&quot;</span>&gt;</span>article link: <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">a</span> <span class=\"hljs-attr\">href</span>=<span class=\"hljs-string\">&quot;&lt;%= config.url %&gt;/&lt;%= post.path %&gt;&quot;</span> <span class=\"hljs-attr\">title</span>=<span class=\"hljs-string\">&quot;&lt;%= post.title %&gt;&quot;</span> <span class=\"hljs-attr\">target</span>=<span class=\"hljs-string\">&quot;_blank&quot;</span>&gt;</span>&lt;%= config.url %&gt;/&lt;%= post.path %&gt;<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">a</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">br</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">strong</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;copyright&quot;</span>&gt;</span>copyright:<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">strong</span>&gt;</span>\n    This work is licensed under a\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">a</span> <span class=\"hljs-attr\">rel</span>=<span class=\"hljs-string\">&quot;license&quot;</span> <span class=\"hljs-attr\">href</span>=<span class=\"hljs-string\">&quot;&lt;%= theme.declare.licensee_url%&gt;&quot;</span> <span class=\"hljs-attr\">title</span>=<span class=\"hljs-string\">&quot;&lt;%= theme.declare.licensee_alias %&gt;&quot;</span>&gt;</span>&lt;%= theme.declare.licensee_name%&gt;<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">a</span>&gt;</span>\n    licience \n    &lt;% if(theme.declare.licensee_img != undefined)&#123; %&gt;\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">a</span> <span class=\"hljs-attr\">rel</span>=<span class=\"hljs-string\">&quot;license&quot;</span> <span class=\"hljs-attr\">href</span>=<span class=\"hljs-string\">&quot;&lt;%= theme.declare.licensee_url%&gt;&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">img</span> <span class=\"hljs-attr\">alt</span>=<span class=\"hljs-string\">&quot;&quot;</span> <span class=\"hljs-attr\">style</span>=<span class=\"hljs-string\">&quot;border-width:0&quot;</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">&quot;&lt;%= theme.declare.licensee_img%&gt;&quot;</span>/&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">a</span>&gt;</span>\n    &lt;% &#125; %&gt;\n  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n&lt;% &#125; else &#123;%&gt;\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;declare&quot;</span> <span class=\"hljs-attr\">hidden</span>=<span class=\"hljs-string\">&quot;hidden&quot;</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">div</span>&gt;</span>\n&lt;% &#125; %&gt;\n<span class=\"hljs-comment\">&lt;!-- add copyright statement --&gt;</span></code></pre>\n<p>3.add stylesheet the end of <code>themes/yilia/source/main.0cf68a.css</code></p>\n<pre><code class=\"hljs css\"><span class=\"hljs-comment\">/*stylesheet for the delcare*/</span>\n<span class=\"hljs-selector-class\">.declare</span> &#123;\n  <span class=\"hljs-attribute\">background-color</span>: <span class=\"hljs-number\">#eaeaea</span>;\n  <span class=\"hljs-attribute\">margin-top</span>: <span class=\"hljs-number\">2em</span>;\n  <span class=\"hljs-attribute\">border-left</span>: <span class=\"hljs-number\">3px</span> solid <span class=\"hljs-number\">#ff1700</span>;\n  <span class=\"hljs-attribute\">padding</span>: .<span class=\"hljs-number\">5em</span> <span class=\"hljs-number\">1em</span>; \n&#125;\n<span class=\"hljs-comment\">/*stylesheet for the delcare end*/</span></code></pre>\n<p>4.add at the end of <code>themes/yilia/_config.yml</code> file:</p>\n<pre><code class=\"hljs awk\">declare:\n  declare_type: <span class=\"hljs-number\">1</span>\n  licensee_url: http:<span class=\"hljs-regexp\">//</span>creativecommons.org<span class=\"hljs-regexp\">/licenses/</span>by-nc-sa<span class=\"hljs-regexp\">/4.0/</span>      \n  licensee_name: <span class=\"hljs-string\">&#x27;CC BY-NC-SA 4.0&#x27;</span>                              \n  licensee_alias: <span class=\"hljs-string\">&#x27;CC BY-NC-SA 4.0&#x27;</span>     \n  licensee_img: https:<span class=\"hljs-regexp\">//i</span>.creativecommons.org<span class=\"hljs-regexp\">/l/</span>by-nc-sa<span class=\"hljs-regexp\">/4.0/</span><span class=\"hljs-number\">80</span>x15.png</code></pre>\n<h3 id=\"add-mind-map-support\">Add mind-map support</h3>\n<pre><code class=\"hljs shell\">npm install hexo-markmap</code></pre>\n<p>Detailed in its <a href=\"https://github.com/MaxChang3/hexo-markmap\">Github</a></p>\n<p>Example:</p>\n<pre><code class=\"hljs markdown\">&#123;% markmap 300px %&#125;\n<span class=\"hljs-bullet\">-</span> Testa\n<span class=\"hljs-bullet\">  -</span> test1\n<span class=\"hljs-bullet\">  -</span> test2\n<span class=\"hljs-bullet\">-</span> Testb\n<span class=\"hljs-bullet\">  -</span> test1\n<span class=\"hljs-bullet\">  -</span> test2\n&#123;%endmarkmap%&#125;</code></pre>\n<h3 id=\"add-latex-math-support\">Add Latex math support</h3>\n<p>Change the renderer to the more powerful pandoc:</p>\n<p>1.Install pandoc on macOS:</p>\n<pre><code class=\"hljs cmake\">copybrew <span class=\"hljs-keyword\">install</span> pandoc</code></pre>\n<p>2.in the blog root directory uninstall the default renderer then install the pandoc renderer:</p>\n<pre><code class=\"hljs ada\">copynpm uninstall hexo-renderer-marked <span class=\"hljs-comment\">--save</span>\nnpm install hexo-renderer-pandoc <span class=\"hljs-comment\">--save</span></code></pre>\n<p>3.install the hexo math plugin</p>\n<pre><code class=\"hljs cmake\">copynpm <span class=\"hljs-keyword\">install</span> hexo-<span class=\"hljs-keyword\">math</span> --save</code></pre>\n<p>4.add these lines to the hexo <code>_config</code> file</p>\n<pre><code class=\"hljs nestedtext\"><span class=\"hljs-attribute\">copymarkdown</span><span class=\"hljs-punctuation\">:</span>\n  <span class=\"hljs-attribute\">plugins</span><span class=\"hljs-punctuation\">:</span>\n    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">markdown-it-footnote</span>\n    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">markdown-it-sup</span>\n    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">markdown-it-sub</span>\n    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">markdown-it-abbr</span>\n    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">markdown-it-emoji</span>\n    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">hexo-math</span></code></pre>\n<p>5.add these lines to the theme <code>_config</code> file</p>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-string\">copy#</span> <span class=\"hljs-string\">MathJax</span> <span class=\"hljs-string\">Support</span>\n<span class=\"hljs-attr\">mathjax:</span>\n  <span class=\"hljs-attr\">enable:</span> <span class=\"hljs-literal\">true</span>\n  <span class=\"hljs-attr\">per_page:</span> <span class=\"hljs-literal\">true</span></code></pre>\n<p>6.rebuild the to blog see changes</p>\n<p>7.Examples: <span class=\"math inline\">\\(this_{is}an\\frac{inline}{equation}\\)</span> <span class=\"math display\">\\[\n\\begin{equation}\n    \\mathbf{K}_\\mathbf{1}=\\frac{1}{\\Delta r}\\ \\left[\\begin{matrix}\\begin{matrix}-1&amp;1\\\\-1&amp;1\\\\\\end{matrix}&amp;\\ &amp;\\ \\\\\\begin{matrix}\\ &amp;\\ddots\\\\\\end{matrix}&amp;\\begin{matrix}\\ddots&amp;\\ \\\\\\end{matrix}&amp;\\ \\\\\\ &amp;-1\\ &amp;1\\\\\\end{matrix}\\right],\\ \\ {\\ \\mathbf{K}}_\\mathbf{2}=\\frac{1}{\\Delta r}\\ \\left[\\begin{matrix}\\begin{matrix}-1&amp;1\\\\\\ &amp;\\ddots\\\\\\end{matrix}&amp;\\begin{matrix}\\\\\\ddots\\\\\\end{matrix}&amp;\\ \\\\\\begin{matrix}\\ &amp;\\ \\\\\\end{matrix}&amp;-1&amp;1\\ \\\\\\ &amp;-1\\ &amp;1\\\\\\end{matrix}\\right]\n    \\label{K2}\n\\end{equation}\n\\]</span></p>\n<h3 id=\"the-last-snapshot\">The last snapshot</h3>\n<p>Ok, never spend time on a no-longer maintained project. Here's the last figure of it.</p>\n<p><img src=\"Last snapshot.png\" alt=\"Last snapshot\" style=\"zoom:80%;\" /></p>\n<h2 id=\"reference\">Reference</h2>\n<p>https://flatironschool.com/blog/the-benefits-of-blogging-how-and-why-to-keep-a-technical-blog/</p>\n<p>https://weblog.masukomi.org/2015/10/18/static-vs-dynamic-blogging/</p>\n<p>https://www.cnblogs.com/aoguai/p/11781505.html</p>\n<p>https://www.kblog.top/post/30452.html</p>\n<p>https://wkzqn.gitee.io/2020/02/16/typora%E7%BC%96%E5%86%99hexo%E5%8D%9A%E5%AE%A2%E6%97%B6%E7%9A%84%E5%9B%BE%E7%89%87%E6%98%BE%E7%A4%BA/</p>\n<p>https://segmentfault.com/a/1190000009478837#articleHeader5</p>\n<p>https://hilyy.xyz/how-to-allow-google-to-index-your-hexo-blog-website-google-search-console-verification-methods/</p>\n<p>https://busuanzi.ibruce.info/</p>\n<p>https://creativecommons.org/choose/results-one?license_code=by-nc-sa&amp;jurisdiction=&amp;version=4.0&amp;lang=en</p>\n<p>https://www.jcchouinard.com/sitemap-could-not-be-read-couldnt-fetch-in-google-search-console/</p>\n<p>https://cqh-i.github.io/2019/08/07/hexo-yilia%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E9%9A%90%E8%97%8F%E5%B7%A6%E8%BE%B9%E6%A0%8F%E7%9B%AE%E6%8C%89%E9%92%AE/</p>"},{"title":"Derivation of Non-dimensional NS Equations","author":"Ryan LI","toc":true,"declare":true,"index_img":"/index/non-dimensional_NS.png","date":"2022-05-20T02:13:03.000Z","_content":"\n{% note primary %}\n\nFeeling unsafe when deploying CFD algorithms, the best way to alleviate the anxiety is to derive the fundamentals again.\n\n{% endnote%}\n\n<!-- more -->\n\nIntroduce dimensionless parameters into the incompressible Navier-Stokes equations to arrive at a non-dimensional form.\n\n### 1 Motivation\n\nTo reduce the dimensionality of the problem.\n\n### 2 Dimensional analysis\n\nGiven fundamental physical quantities such as length $[L]$, time $[T]$, mass $[M]$ and temperature $[\\Theta]$,\n\n- Aera $A$ is $[L^2]$\n- Velocity $V$ is $[LT^{-1}]$\n- Acceleration $a$ is $[LT^{-2}]$\n- Force $F$ is $[MLT^{-2}]$\n- Pressure $p$ is $[ML^{-1}T^{-2}]$\n- Energy $J$ is $[ML^2T^{-2}]$\n\nThe *principle of dimensional homogeneity* states the dimensions on both sides of an equation balance. And it applies to all equations of mechanics.\n\nIn dimensional analysis, take Bernoulli equation as an example, there are 4 factors:\n$$\n\\frac{p}{\\rho} + \\frac{1}{2}V^2 +gz = Const.\n$$\n\n- *Dimensional variables*: variables, $p$, $V$ and $z$\n- *Dimensional parameters*: fixed throughout experiment although with a dimension, $\\rho$, $g$ and $Const$\n- *Pure constants*: mathematical manipulations, $\\pi$ and $e\\approx2.718$\n\n{% note info %}\n\nSpecial care: \n\n- *Angles* are dimensionless yet the units are radians\n\n- Some physical quantities are dimensionless by their definition, such as *strain* as a change in length per unit length\n- Integration and differentiation change the dimension of the equation as well\n\n{% endnote %}\n\n### 3 Non-dimensionalisation of equations\n\nAny dimensionally homogeneous equation can be non-dimensionalised, This process roughly proceeds as follows:\n\n1. Identify which quantities are *variables* (vary or measured) and *parameters* (fixed per experiment).\n\n2. Identify the number of fundamental dimensions, $N$, involved.\n\n3. Select $N$ parameters to be scaling parameters with which to define dimensionless variables.\n\n   {% note info %}\n\n   Note: There are often multiple choices here and the choice will depend on exactly what we are aiming to show with our data.\n\n   {% endnote %}\n\n4. Scale each variable $u$ by combinations of these scaling parameters $s_i$ to arrive at a non-dimensional form $u^$. i.e. write $u^ = \\alpha(s_i)u$.\n\n5. Substitute into the equation and simplify to arrive at its non-dimensional form.\n\nSome rules for selecting scaling parameters:\n\n- They must *not* form a dimensionless group amongst themselves. For example:\n  $$\n  S_{0}^{a} V_{0}^{b}=[L]^{a}\\left[L T^{-1}\\right]^{b}=L^{0} T^{0} \\quad \\Leftrightarrow \\quad a=b=0\n  $$\n\n- Do not include the output variables you wish to analyse/plot.\n\n**Example**\n\nGive the falling-body equation, and follow the process\n$$\nS = S_0+V_0t+\\frac{1}{2}gt^2\n$$\n\n1. Divide the variables and parameters:\n   $$\n   \\mathrm{Variables:~}S,t,\\qquad\\mathrm{Parameters:~}S_0,V_0,g\n   $$\n\n2. Identify the dimensions:\n   $$\n   S = [L], \\quad t=[T],\\quad S_0=[L],\\quad V_0=[L/t],\\quad g=[L/t^2]\n   $$\n   And 2 dimensions exist: $[L]$ and $[T]$ \n\n---\n\n3. There are 3 options of parameters choosing, choose $(S_0,V_0)$ for instance,\n\n4. Non-dimensional variables can be described as:\n\n$$\nS^* = \\frac{1}{S_0}S  \\qquad t^* = \\frac{V_0}{S_0}t\n$$\n\n5. Subscribe into the function to get a non-dimensional form of it:\n   $$\n   S^* = 1+t^*+\\frac{1}{2}\\alpha t^{*2}, \\quad \\mathrm{with} \\quad \\alpha = \\frac{gS_0}{V_0^2}\n   $$\n   It is a function of a single dimensionless parameter $\\alpha$ identifying the effect of gravity.\n\n---\n\n3. Similarly, choose $(S_0,g)$, we have\n\n4. $$\n   S^{**} = \\frac{g}{V_0^2}S  \\qquad t^{**} = \\frac{g}{V_0}t\n   $$\n\n5. The non-dimensional form body-drop function is therefore:\n   $$\n   S^* =  \\alpha+ t^{**}+ \\frac{1}{2}gt^{**},\\quad \\mathrm{with} \\quad \\alpha=\\frac{gS_0}{V_0^2}\n   $$\n   Here, $\\alpha$  identifies the effect of $V_0$.\n\n----\n\nThe reduction in the number of variables/parameters (2 in this case, from 5 down to 3) equals the number of fundamental dimensions of the problem. This observation was formalised by **Buckingham**.\n\n### 4 Buckinghams Pi theorem\n\nProposed by Buckingham in 1914, it is a means of finding dimensionless groups, or $\\Pi$s\n\n>If a physical process satisfies the PDH(Principle of Dimensional Homogeneity) and involves $n$ dimensional variables, it can be reduced to a relation between only $k$ dimensionless variables or $\\Pi$s. The reduction $j = n - k$ equals the maximum number of variables that do not form a $\\Pi$ among themselves and is always less than or equal to the number of dimensions describing the variables.\n>\n>\n>\n>Find the reduction $j$, then select $j$ scaling variables that do not form a $\\Pi$ among themselves. Each desired $\\Pi$ group will be a power product of these $j$ variables plus one additional variable, which is assigned any convenient nonzero exponent. Each $\\Pi$ group thus found is independent.\n\nThe first part of this theorem describes what sort of a reduction we can achieve for a given equation. The second part describes a methodology for systematically identifying $\\Pi$s\n\n**Example 1** \n\nSuppose we have that the drag force on a body depends on length of the body, velocity of the flow, density and viscosity of the fluid:\n$$\nF = f(L,V,\\rho,\\mu)\n$$\n\n1. Dimensions of each variables are:\n   $$\n   F=\\left[M L T^{-2}\\right], \\quad L=[L], \\quad V=\\left[L T^{-1}\\right], \\quad \\rho=\\left[M L^{-3}\\right], \\quad \\mu=\\left[M L^{-1} T^{-1}\\right]\n   $$\n   3 dimensions exist, $j=3$\n\n2. And we expect to find $k = 5-3 = 2 ~\\Pi$ groups. We are intersted in how the drag force relates to the velocity, so we choose $(L,\\rho,\\mu)$, The two $\\Pi$s are:\n   $$\n   \\begin{array}{ll}\n   \\Pi_{1}=L^{a} \\rho^{b} \\mu^{c} F=L^{0} \\rho^{1} \\mu^{-2} F & {[1]\\left[M L^{-3}\\right]\\left[M L^{-1} T^{-1}\\right]^{-2}\\left[M L T^{-2}\\right]=\\left[M^{0} L^{0} T^{0}\\right]} \\\\\n   \\Pi_{2}=L^{a} \\rho^{b} \\mu^{c} V=L^{1} \\rho^{1} \\mu^{-1} V & {[L]\\left[M L^{-3}\\right]\\left[M L^{-1} T^{-1}\\right]^{-1}\\left[L T^{-1}\\right]=\\left[M^{0} L^{0} T^{0}\\right]}\n   \\end{array}\n   $$\n\n3. As a result we have the dimensionless coefficients:\n   $$\n   C_{f}=\\frac{\\rho F}{\\mu^{2}}=f(\\mathrm{Re}) \\quad \\text { with } R e=\\frac{\\rho L V}{\\mu}\n   $$\n   $C_f$ is the force coefficients and $Re$ is the famous Reynolds number.\n\n**Example 2**\n\nAt low velocities (laminar flow), the volume flow $Q$ through a small-bore tube is a function only of the tube radius $R$, the fluid viscosity $\\mu$ and the pressure drop per unit tube length $dp/dx$. Using the Pi theorem, find an appropriate dimensionless relationship.\n\nWe have:\n$$\nQ = f(R,\\mu,dp/dx)\n$$\n\n1. with dimensions:\n   $$\n   Q=\\left[L^{3} T^{-1}\\right], \\quad R=[L], \\quad \\mu=\\left[M L^{-1} T^{-1}\\right], \\quad d p / d x=\\left[M L^{-2} T^{-2}\\right]\n   $$\n\n2. 3 dimensions $\\Rightarrow$ 3 scaling variables & 1 $\\Pi$ group. Choose $(R, \\mu, dp/dx)$:\n   $$\n   \\begin{aligned}\n   \\Pi_{1} &=R^{a} \\mu^{b}(d p / d x)^{c} Q \\\\\n   &=[L]^{a}\\left[M L^{-1} T^{-1}\\right]^{b}\\left[M L^{-2} T^{-2}\\right]^{c}\\left[L^{3} T^{-1}\\right] \\\\\n   &=\\left[M^{0} L^{0} T^{0}\\right] \\quad \\Leftrightarrow \\quad a=-4, b=1, c=-1\n   \\end{aligned}\n   $$\n\n3. Therefore we have:\n   $$\n   C = \\frac{Q\\mu}{R^4(dp/dx)}\n   $$\n\n### 5 Non-dimensionalisation of the governing equations\n\nGive incompressible, no gravity governing equations. Take the case of open flow past an infinitely long circular cylinder. The continuity and momentum equations are given by:\n$$\n\\begin{aligned}\n0 &= \\boldsymbol{\\nabla}\\cdot\\mathbf{V} \\\\\n\\rho\\frac{\\mathrm{d}\\mathbf{V}}{dt} &= -\\boldsymbol{\\nabla}p + \\mu \\boldsymbol{\\nabla}^2\\mathbf{V}\n\\end{aligned}\n$$\nPlus boundary conditions:\n$$\n\\begin{aligned}\n\\mathrm{Solid~surface:~}&\\mathbf{V}=0 \\\\\n\\mathrm{Inlet~or~outlet:~}&\\mathrm{Known}~\\mathbf{V},p\n\\end{aligned}\n$$\nPlus the cylinder has diameter $D$ and the flow has free-stream velocity of $U_0$. Recall that one might suppose that our velocity field is a function of the cylinder diameter, the free-stream velocity, as well as the fluid density and viscosity. We have that:\n$$\n\\mathbf{V} = f(\\mathbf{x},t,p,D,U_0,\\rho,\\mu)\n$$\n\n1. with dimensions:\n   $$\n   \\begin{aligned}\n   \\Pi_{1} &=R^{a} \\mu^{b}(d p / d x)^{c} Q \\\\\n   &=[L]^{a}\\left[M L^{-1} T^{-1}\\right]^{b}\\left[M L^{-2} T^{-2}\\right]^{c}\\left[L^{3} T^{-1}\\right] \\\\\n   &=\\left[M^{0} L^{0} T^{0}\\right] \\quad \\Leftrightarrow \\quad a=-4, b=1, c=-1\n   \\end{aligned}\n   $$\n\n2. 3 dimensions and 8 variables $\\Rightarrow$ 3 scaling variables & 5 $\\Pi$ group. Choose $(D,U_0,\\rho)$ since they cannot form a $\\Pi$ group, we have:\n   $$\n   \\begin{aligned}\n   &\\Pi_{1}=U_{0}^{a} D^{b} \\rho^{c} V=U_{0}^{-1} V \\\\\n   &\\Pi_{2}=U_{0}^{a} D^{b} \\rho^{c} \\mathbf{x}=D^{-1} \\mathbf{x} \\\\\n   &\\Pi_{3}=U_{0}^{a} D^{b} \\rho^{c} t=U_{0} D^{-1} t \\\\\n   &\\Pi_{4}=U_{0}^{a} D^{b} \\rho^{c} p=\\left[L T^{-1}\\right]^{a}[L]^{b}\\left[M L^{-3}\\right]^{c}\\left[M L^{-1} T^{-2}\\right]=U_{0}^{-2} \\rho^{-1} p \\\\\n   &\\Pi_{5}=U_{0}^{a} D^{b} \\rho^{c} \\mu=\\left[L T^{-1}\\right]^{a}[L]^{b}\\left[M L^{-3}\\right]^{c}\\left[M L^{-1} T^{-1}\\right]=U_{0}^{-1} D^{-1} \\rho^{-1} \\mu\n   \\end{aligned}\n   $$\n\n3. Therefore:\n   $$\n   \\frac{V}{U_{0}}=f\\left(\\frac{x}{D}, \\frac{t U_{0}}{D}, \\frac{p}{U_{0}^{2} \\rho}, \\frac{\\mu}{\\rho U_{0} D}\\right)\n   $$\n\n4. Use above to write down the non-dimensional scaling of the parameters:\n   $$\n   V^{*}=\\frac{1}{U_{0}} V \\quad \\mathbf{x}^{*}=\\frac{1}{D} \\mathbf{x} \\quad t^{*}=\\frac{U_{0}}{D} t \\quad p^{*}=\\frac{1}{\\rho U_{0}^{2}} p \\quad \\nabla^{*}=D \\nabla \\quad \\mu^{*}=\\frac{1}{\\rho U_{0} D} \\mu\n   $$\n\n5. Therefore the non-dimensional form of N-S equations:\n   $$\n   \\begin{aligned}\n   0 &= \\boldsymbol{\\nabla^*}\\cdot\\mathbf{V^*} \\\\\n   \\rho\\frac{\\mathrm{d}\\mathbf{V^*}}{dt^*} &= -\\boldsymbol{\\nabla^*}p^* + \\frac{1}{Re} \\boldsymbol{\\nabla^{*2}}\\mathbf{V^*}\n   \\end{aligned}\n   $$\n   where $Re = \\frac{\\rho U_0D}{\\mu}$ and with boundary conditions:\n   $$\n   \\begin{aligned}\n   \\mathrm{Solid~surface:~}&\\mathbf{V^*}=0 \\\\\n   \\mathrm{Inlet~or~outlet:~}&\\mathrm{Known}~\\mathbf{V^*},p^*\n   \\end{aligned}\n   $$\n\nIn this case, rather than analysing our flow problem with respect to the four parameters (cylinder radius, free-stream velocity, density and viscosity), we need only analyse it with respect to the single dimensionless Reynolds number.\n\nBesides, the above can be generalised by considering $U_0$ and $D$ to be any characteristic velocity- and length-scale of the specific problem being considered.\n\n### 6 Dimensionless parameters\n\nTo conclude we highlight a couple of the dimensionless parameters which can arise in the incompressible Navier-Stokes equations.\n\nThere are no dimensionless parameters in the continuity equation. However, there is one in the momentum equation, the Reynolds number\n$$\nRe = \\frac{\\rho U_0D}{\\mu}\n$$\nIt can be considered as the ratio of *inertial* to *viscous* effects and is widely considered the **most important** parameter in fluid mechanics.\n\nIf the free-stream velocity $U_0$ were instead considered to be oscillating rather than constant, and of the form:\n$$\nU = U_0\\cos(\\omega t)\n$$\nthen the problem can be considered as:\n$$\n\\mathbf{V} = f(\\mathbf{x},t,p,D,U_0,\\rho,\\mu, \\omega)\n$$\nAnd the non-dimensionalised $U(t)$, we observe that:\n$$\n\\frac{U}{U_0}=U^*=\\cos\\left(\\frac{\\omega D}{U_0}t^*\\right)\n$$\nwhere $\\omega$ is the frequency. We now have an additional dimensionless parameter called the ***Strouhal number*:**\n$$\nSt = \\frac{\\omega D}{U_0}\n$$\nThere are many other dimensionless parameters which arise in specific types of flow problems.\n","source":"_posts/Derivation-of-Non-dimensional-NS-Equations.md","raw":"---\ntitle: Derivation of Non-dimensional NS Equations\nauthor: Ryan LI\ntoc: true\ndeclare: true\nindex_img: /index/non-dimensional_NS.png\ntags:\n  - fluid dynamics\ndate: 2022-05-20 10:13:03\n---\n\n{% note primary %}\n\nFeeling unsafe when deploying CFD algorithms, the best way to alleviate the anxiety is to derive the fundamentals again.\n\n{% endnote%}\n\n<!-- more -->\n\nIntroduce dimensionless parameters into the incompressible Navier-Stokes equations to arrive at a non-dimensional form.\n\n### 1 Motivation\n\nTo reduce the dimensionality of the problem.\n\n### 2 Dimensional analysis\n\nGiven fundamental physical quantities such as length $[L]$, time $[T]$, mass $[M]$ and temperature $[\\Theta]$,\n\n- Aera $A$ is $[L^2]$\n- Velocity $V$ is $[LT^{-1}]$\n- Acceleration $a$ is $[LT^{-2}]$\n- Force $F$ is $[MLT^{-2}]$\n- Pressure $p$ is $[ML^{-1}T^{-2}]$\n- Energy $J$ is $[ML^2T^{-2}]$\n\nThe *principle of dimensional homogeneity* states the dimensions on both sides of an equation balance. And it applies to all equations of mechanics.\n\nIn dimensional analysis, take Bernoulli equation as an example, there are 4 factors:\n$$\n\\frac{p}{\\rho} + \\frac{1}{2}V^2 +gz = Const.\n$$\n\n- *Dimensional variables*: variables, $p$, $V$ and $z$\n- *Dimensional parameters*: fixed throughout experiment although with a dimension, $\\rho$, $g$ and $Const$\n- *Pure constants*: mathematical manipulations, $\\pi$ and $e\\approx2.718$\n\n{% note info %}\n\nSpecial care: \n\n- *Angles* are dimensionless yet the units are radians\n\n- Some physical quantities are dimensionless by their definition, such as *strain* as a change in length per unit length\n- Integration and differentiation change the dimension of the equation as well\n\n{% endnote %}\n\n### 3 Non-dimensionalisation of equations\n\nAny dimensionally homogeneous equation can be non-dimensionalised, This process roughly proceeds as follows:\n\n1. Identify which quantities are *variables* (vary or measured) and *parameters* (fixed per experiment).\n\n2. Identify the number of fundamental dimensions, $N$, involved.\n\n3. Select $N$ parameters to be scaling parameters with which to define dimensionless variables.\n\n   {% note info %}\n\n   Note: There are often multiple choices here and the choice will depend on exactly what we are aiming to show with our data.\n\n   {% endnote %}\n\n4. Scale each variable $u$ by combinations of these scaling parameters $s_i$ to arrive at a non-dimensional form $u^$. i.e. write $u^ = \\alpha(s_i)u$.\n\n5. Substitute into the equation and simplify to arrive at its non-dimensional form.\n\nSome rules for selecting scaling parameters:\n\n- They must *not* form a dimensionless group amongst themselves. For example:\n  $$\n  S_{0}^{a} V_{0}^{b}=[L]^{a}\\left[L T^{-1}\\right]^{b}=L^{0} T^{0} \\quad \\Leftrightarrow \\quad a=b=0\n  $$\n\n- Do not include the output variables you wish to analyse/plot.\n\n**Example**\n\nGive the falling-body equation, and follow the process\n$$\nS = S_0+V_0t+\\frac{1}{2}gt^2\n$$\n\n1. Divide the variables and parameters:\n   $$\n   \\mathrm{Variables:~}S,t,\\qquad\\mathrm{Parameters:~}S_0,V_0,g\n   $$\n\n2. Identify the dimensions:\n   $$\n   S = [L], \\quad t=[T],\\quad S_0=[L],\\quad V_0=[L/t],\\quad g=[L/t^2]\n   $$\n   And 2 dimensions exist: $[L]$ and $[T]$ \n\n---\n\n3. There are 3 options of parameters choosing, choose $(S_0,V_0)$ for instance,\n\n4. Non-dimensional variables can be described as:\n\n$$\nS^* = \\frac{1}{S_0}S  \\qquad t^* = \\frac{V_0}{S_0}t\n$$\n\n5. Subscribe into the function to get a non-dimensional form of it:\n   $$\n   S^* = 1+t^*+\\frac{1}{2}\\alpha t^{*2}, \\quad \\mathrm{with} \\quad \\alpha = \\frac{gS_0}{V_0^2}\n   $$\n   It is a function of a single dimensionless parameter $\\alpha$ identifying the effect of gravity.\n\n---\n\n3. Similarly, choose $(S_0,g)$, we have\n\n4. $$\n   S^{**} = \\frac{g}{V_0^2}S  \\qquad t^{**} = \\frac{g}{V_0}t\n   $$\n\n5. The non-dimensional form body-drop function is therefore:\n   $$\n   S^* =  \\alpha+ t^{**}+ \\frac{1}{2}gt^{**},\\quad \\mathrm{with} \\quad \\alpha=\\frac{gS_0}{V_0^2}\n   $$\n   Here, $\\alpha$  identifies the effect of $V_0$.\n\n----\n\nThe reduction in the number of variables/parameters (2 in this case, from 5 down to 3) equals the number of fundamental dimensions of the problem. This observation was formalised by **Buckingham**.\n\n### 4 Buckinghams Pi theorem\n\nProposed by Buckingham in 1914, it is a means of finding dimensionless groups, or $\\Pi$s\n\n>If a physical process satisfies the PDH(Principle of Dimensional Homogeneity) and involves $n$ dimensional variables, it can be reduced to a relation between only $k$ dimensionless variables or $\\Pi$s. The reduction $j = n - k$ equals the maximum number of variables that do not form a $\\Pi$ among themselves and is always less than or equal to the number of dimensions describing the variables.\n>\n>\n>\n>Find the reduction $j$, then select $j$ scaling variables that do not form a $\\Pi$ among themselves. Each desired $\\Pi$ group will be a power product of these $j$ variables plus one additional variable, which is assigned any convenient nonzero exponent. Each $\\Pi$ group thus found is independent.\n\nThe first part of this theorem describes what sort of a reduction we can achieve for a given equation. The second part describes a methodology for systematically identifying $\\Pi$s\n\n**Example 1** \n\nSuppose we have that the drag force on a body depends on length of the body, velocity of the flow, density and viscosity of the fluid:\n$$\nF = f(L,V,\\rho,\\mu)\n$$\n\n1. Dimensions of each variables are:\n   $$\n   F=\\left[M L T^{-2}\\right], \\quad L=[L], \\quad V=\\left[L T^{-1}\\right], \\quad \\rho=\\left[M L^{-3}\\right], \\quad \\mu=\\left[M L^{-1} T^{-1}\\right]\n   $$\n   3 dimensions exist, $j=3$\n\n2. And we expect to find $k = 5-3 = 2 ~\\Pi$ groups. We are intersted in how the drag force relates to the velocity, so we choose $(L,\\rho,\\mu)$, The two $\\Pi$s are:\n   $$\n   \\begin{array}{ll}\n   \\Pi_{1}=L^{a} \\rho^{b} \\mu^{c} F=L^{0} \\rho^{1} \\mu^{-2} F & {[1]\\left[M L^{-3}\\right]\\left[M L^{-1} T^{-1}\\right]^{-2}\\left[M L T^{-2}\\right]=\\left[M^{0} L^{0} T^{0}\\right]} \\\\\n   \\Pi_{2}=L^{a} \\rho^{b} \\mu^{c} V=L^{1} \\rho^{1} \\mu^{-1} V & {[L]\\left[M L^{-3}\\right]\\left[M L^{-1} T^{-1}\\right]^{-1}\\left[L T^{-1}\\right]=\\left[M^{0} L^{0} T^{0}\\right]}\n   \\end{array}\n   $$\n\n3. As a result we have the dimensionless coefficients:\n   $$\n   C_{f}=\\frac{\\rho F}{\\mu^{2}}=f(\\mathrm{Re}) \\quad \\text { with } R e=\\frac{\\rho L V}{\\mu}\n   $$\n   $C_f$ is the force coefficients and $Re$ is the famous Reynolds number.\n\n**Example 2**\n\nAt low velocities (laminar flow), the volume flow $Q$ through a small-bore tube is a function only of the tube radius $R$, the fluid viscosity $\\mu$ and the pressure drop per unit tube length $dp/dx$. Using the Pi theorem, find an appropriate dimensionless relationship.\n\nWe have:\n$$\nQ = f(R,\\mu,dp/dx)\n$$\n\n1. with dimensions:\n   $$\n   Q=\\left[L^{3} T^{-1}\\right], \\quad R=[L], \\quad \\mu=\\left[M L^{-1} T^{-1}\\right], \\quad d p / d x=\\left[M L^{-2} T^{-2}\\right]\n   $$\n\n2. 3 dimensions $\\Rightarrow$ 3 scaling variables & 1 $\\Pi$ group. Choose $(R, \\mu, dp/dx)$:\n   $$\n   \\begin{aligned}\n   \\Pi_{1} &=R^{a} \\mu^{b}(d p / d x)^{c} Q \\\\\n   &=[L]^{a}\\left[M L^{-1} T^{-1}\\right]^{b}\\left[M L^{-2} T^{-2}\\right]^{c}\\left[L^{3} T^{-1}\\right] \\\\\n   &=\\left[M^{0} L^{0} T^{0}\\right] \\quad \\Leftrightarrow \\quad a=-4, b=1, c=-1\n   \\end{aligned}\n   $$\n\n3. Therefore we have:\n   $$\n   C = \\frac{Q\\mu}{R^4(dp/dx)}\n   $$\n\n### 5 Non-dimensionalisation of the governing equations\n\nGive incompressible, no gravity governing equations. Take the case of open flow past an infinitely long circular cylinder. The continuity and momentum equations are given by:\n$$\n\\begin{aligned}\n0 &= \\boldsymbol{\\nabla}\\cdot\\mathbf{V} \\\\\n\\rho\\frac{\\mathrm{d}\\mathbf{V}}{dt} &= -\\boldsymbol{\\nabla}p + \\mu \\boldsymbol{\\nabla}^2\\mathbf{V}\n\\end{aligned}\n$$\nPlus boundary conditions:\n$$\n\\begin{aligned}\n\\mathrm{Solid~surface:~}&\\mathbf{V}=0 \\\\\n\\mathrm{Inlet~or~outlet:~}&\\mathrm{Known}~\\mathbf{V},p\n\\end{aligned}\n$$\nPlus the cylinder has diameter $D$ and the flow has free-stream velocity of $U_0$. Recall that one might suppose that our velocity field is a function of the cylinder diameter, the free-stream velocity, as well as the fluid density and viscosity. We have that:\n$$\n\\mathbf{V} = f(\\mathbf{x},t,p,D,U_0,\\rho,\\mu)\n$$\n\n1. with dimensions:\n   $$\n   \\begin{aligned}\n   \\Pi_{1} &=R^{a} \\mu^{b}(d p / d x)^{c} Q \\\\\n   &=[L]^{a}\\left[M L^{-1} T^{-1}\\right]^{b}\\left[M L^{-2} T^{-2}\\right]^{c}\\left[L^{3} T^{-1}\\right] \\\\\n   &=\\left[M^{0} L^{0} T^{0}\\right] \\quad \\Leftrightarrow \\quad a=-4, b=1, c=-1\n   \\end{aligned}\n   $$\n\n2. 3 dimensions and 8 variables $\\Rightarrow$ 3 scaling variables & 5 $\\Pi$ group. Choose $(D,U_0,\\rho)$ since they cannot form a $\\Pi$ group, we have:\n   $$\n   \\begin{aligned}\n   &\\Pi_{1}=U_{0}^{a} D^{b} \\rho^{c} V=U_{0}^{-1} V \\\\\n   &\\Pi_{2}=U_{0}^{a} D^{b} \\rho^{c} \\mathbf{x}=D^{-1} \\mathbf{x} \\\\\n   &\\Pi_{3}=U_{0}^{a} D^{b} \\rho^{c} t=U_{0} D^{-1} t \\\\\n   &\\Pi_{4}=U_{0}^{a} D^{b} \\rho^{c} p=\\left[L T^{-1}\\right]^{a}[L]^{b}\\left[M L^{-3}\\right]^{c}\\left[M L^{-1} T^{-2}\\right]=U_{0}^{-2} \\rho^{-1} p \\\\\n   &\\Pi_{5}=U_{0}^{a} D^{b} \\rho^{c} \\mu=\\left[L T^{-1}\\right]^{a}[L]^{b}\\left[M L^{-3}\\right]^{c}\\left[M L^{-1} T^{-1}\\right]=U_{0}^{-1} D^{-1} \\rho^{-1} \\mu\n   \\end{aligned}\n   $$\n\n3. Therefore:\n   $$\n   \\frac{V}{U_{0}}=f\\left(\\frac{x}{D}, \\frac{t U_{0}}{D}, \\frac{p}{U_{0}^{2} \\rho}, \\frac{\\mu}{\\rho U_{0} D}\\right)\n   $$\n\n4. Use above to write down the non-dimensional scaling of the parameters:\n   $$\n   V^{*}=\\frac{1}{U_{0}} V \\quad \\mathbf{x}^{*}=\\frac{1}{D} \\mathbf{x} \\quad t^{*}=\\frac{U_{0}}{D} t \\quad p^{*}=\\frac{1}{\\rho U_{0}^{2}} p \\quad \\nabla^{*}=D \\nabla \\quad \\mu^{*}=\\frac{1}{\\rho U_{0} D} \\mu\n   $$\n\n5. Therefore the non-dimensional form of N-S equations:\n   $$\n   \\begin{aligned}\n   0 &= \\boldsymbol{\\nabla^*}\\cdot\\mathbf{V^*} \\\\\n   \\rho\\frac{\\mathrm{d}\\mathbf{V^*}}{dt^*} &= -\\boldsymbol{\\nabla^*}p^* + \\frac{1}{Re} \\boldsymbol{\\nabla^{*2}}\\mathbf{V^*}\n   \\end{aligned}\n   $$\n   where $Re = \\frac{\\rho U_0D}{\\mu}$ and with boundary conditions:\n   $$\n   \\begin{aligned}\n   \\mathrm{Solid~surface:~}&\\mathbf{V^*}=0 \\\\\n   \\mathrm{Inlet~or~outlet:~}&\\mathrm{Known}~\\mathbf{V^*},p^*\n   \\end{aligned}\n   $$\n\nIn this case, rather than analysing our flow problem with respect to the four parameters (cylinder radius, free-stream velocity, density and viscosity), we need only analyse it with respect to the single dimensionless Reynolds number.\n\nBesides, the above can be generalised by considering $U_0$ and $D$ to be any characteristic velocity- and length-scale of the specific problem being considered.\n\n### 6 Dimensionless parameters\n\nTo conclude we highlight a couple of the dimensionless parameters which can arise in the incompressible Navier-Stokes equations.\n\nThere are no dimensionless parameters in the continuity equation. However, there is one in the momentum equation, the Reynolds number\n$$\nRe = \\frac{\\rho U_0D}{\\mu}\n$$\nIt can be considered as the ratio of *inertial* to *viscous* effects and is widely considered the **most important** parameter in fluid mechanics.\n\nIf the free-stream velocity $U_0$ were instead considered to be oscillating rather than constant, and of the form:\n$$\nU = U_0\\cos(\\omega t)\n$$\nthen the problem can be considered as:\n$$\n\\mathbf{V} = f(\\mathbf{x},t,p,D,U_0,\\rho,\\mu, \\omega)\n$$\nAnd the non-dimensionalised $U(t)$, we observe that:\n$$\n\\frac{U}{U_0}=U^*=\\cos\\left(\\frac{\\omega D}{U_0}t^*\\right)\n$$\nwhere $\\omega$ is the frequency. We now have an additional dimensionless parameter called the ***Strouhal number*:**\n$$\nSt = \\frac{\\omega D}{U_0}\n$$\nThere are many other dimensionless parameters which arise in specific types of flow problems.\n","slug":"Derivation-of-Non-dimensional-NS-Equations","published":1,"updated":"2022-05-20T16:26:44.229Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz20000al8yb6xald8mr","content":"<div class=\"note note-primary\">\n            <p>Feeling unsafe when deploying CFD algorithms, the best way to alleviate the anxiety is to derive the fundamentals again.</p>\n          </div>\n<span id=\"more\"></span>\n<p>Introduce dimensionless parameters into the incompressible Navier-Stokes equations to arrive at a non-dimensional form.</p>\n<h3 id=\"motivation\">1 Motivation</h3>\n<p>To reduce the dimensionality of the problem.</p>\n<h3 id=\"dimensional-analysis\">2 Dimensional analysis</h3>\n<p>Given fundamental physical quantities such as length <span class=\"math inline\">\\([L]\\)</span>, time <span class=\"math inline\">\\([T]\\)</span>, mass <span class=\"math inline\">\\([M]\\)</span> and temperature <span class=\"math inline\">\\([\\Theta]\\)</span>,</p>\n<ul>\n<li>Aera <span class=\"math inline\">\\(A\\)</span> is <span class=\"math inline\">\\([L^2]\\)</span></li>\n<li>Velocity <span class=\"math inline\">\\(V\\)</span> is <span class=\"math inline\">\\([LT^{-1}]\\)</span></li>\n<li>Acceleration <span class=\"math inline\">\\(a\\)</span> is <span class=\"math inline\">\\([LT^{-2}]\\)</span></li>\n<li>Force <span class=\"math inline\">\\(F\\)</span> is <span class=\"math inline\">\\([MLT^{-2}]\\)</span></li>\n<li>Pressure <span class=\"math inline\">\\(p\\)</span> is <span class=\"math inline\">\\([ML^{-1}T^{-2}]\\)</span></li>\n<li>Energy <span class=\"math inline\">\\(J\\)</span> is <span class=\"math inline\">\\([ML^2T^{-2}]\\)</span></li>\n</ul>\n<p>The <em>principle of dimensional homogeneity</em> states the dimensions on both sides of an equation balance. And it applies to all equations of mechanics.</p>\n<p>In dimensional analysis, take Bernoulli equation as an example, there are 4 factors: <span class=\"math display\">\\[\n\\frac{p}{\\rho} + \\frac{1}{2}V^2 +gz = Const.\n\\]</span></p>\n<ul>\n<li><em>Dimensional variables</em>: variables, <span class=\"math inline\">\\(p\\)</span>, <span class=\"math inline\">\\(V\\)</span> and <span class=\"math inline\">\\(z\\)</span></li>\n<li><em>Dimensional parameters</em>: fixed throughout experiment although with a dimension, <span class=\"math inline\">\\(\\rho\\)</span>, <span class=\"math inline\">\\(g\\)</span> and <span class=\"math inline\">\\(Const\\)</span></li>\n<li><em>Pure constants</em>: mathematical manipulations, <span class=\"math inline\">\\(\\pi\\)</span> and <span class=\"math inline\">\\(e\\approx2.718\\)</span></li>\n</ul>\n<div class=\"note note-info\">\n            <p>Special care:</p><ul><li><p><em>Angles</em> are dimensionless yet the units are radians</p></li><li><p>Some physical quantities are dimensionless by their definition, such as <em>strain</em> as a change in length per unit length</p></li><li><p>Integration and differentiation change the dimension of the equation as well</p></li></ul>\n          </div>\n<h3 id=\"non-dimensionalisation-of-equations\">3 Non-dimensionalisation of equations</h3>\n<p>Any dimensionally homogeneous equation can be non-dimensionalised, This process roughly proceeds as follows:</p>\n<ol type=\"1\">\n<li><p>Identify which quantities are <em>variables</em> (vary or measured) and <em>parameters</em> (fixed per experiment).</p></li>\n<li><p>Identify the number of fundamental dimensions, <span class=\"math inline\">\\(N\\)</span>, involved.</p></li>\n<li><p>Select <span class=\"math inline\">\\(N\\)</span> parameters to be scaling parameters with which to define dimensionless variables.</p>\n<div class=\"note note-info\">\n            <p>Note: There are often multiple choices here and the choice will depend on exactly what we are aiming to show with our data.</p>\n          </div></li>\n<li><p>Scale each variable <span class=\"math inline\">\\(u\\)</span> by combinations of these scaling parameters <span class=\"math inline\">\\(s_i\\)</span> to arrive at a non-dimensional form <span class=\"math inline\">\\(u^\\)</span>. i.e. write <span class=\"math inline\">\\(u^ = \\alpha(s_i)u\\)</span>.</p></li>\n<li><p>Substitute into the equation and simplify to arrive at its non-dimensional form.</p></li>\n</ol>\n<p>Some rules for selecting scaling parameters:</p>\n<ul>\n<li><p>They must <em>not</em> form a dimensionless group amongst themselves. For example: <span class=\"math display\">\\[\nS_{0}^{a} V_{0}^{b}=[L]^{a}\\left[L T^{-1}\\right]^{b}=L^{0} T^{0} \\quad \\Leftrightarrow \\quad a=b=0\n\\]</span></p></li>\n<li><p>Do not include the output variables you wish to analyse/plot.</p></li>\n</ul>\n<p><strong>Example</strong></p>\n<p>Give the falling-body equation, and follow the process <span class=\"math display\">\\[\nS = S_0+V_0t+\\frac{1}{2}gt^2\n\\]</span></p>\n<ol type=\"1\">\n<li><p>Divide the variables and parameters: <span class=\"math display\">\\[\n\\mathrm{Variables:~}S,t,\\qquad\\mathrm{Parameters:~}S_0,V_0,g\n\\]</span></p></li>\n<li><p>Identify the dimensions: <span class=\"math display\">\\[\nS = [L], \\quad t=[T],\\quad S_0=[L],\\quad V_0=[L/t],\\quad g=[L/t^2]\n\\]</span> And 2 dimensions exist: <span class=\"math inline\">\\([L]\\)</span> and <span class=\"math inline\">\\([T]\\)</span></p></li>\n</ol>\n<hr />\n<ol start=\"3\" type=\"1\">\n<li><p>There are 3 options of parameters choosing, choose <span class=\"math inline\">\\((S_0,V_0)\\)</span> for instance,</p></li>\n<li><p>Non-dimensional variables can be described as:</p></li>\n</ol>\n<p><span class=\"math display\">\\[\nS^* = \\frac{1}{S_0}S  \\qquad t^* = \\frac{V_0}{S_0}t\n\\]</span></p>\n<ol start=\"5\" type=\"1\">\n<li>Subscribe into the function to get a non-dimensional form of it: <span class=\"math display\">\\[\nS^* = 1+t^*+\\frac{1}{2}\\alpha t^{*2}, \\quad \\mathrm{with} \\quad \\alpha = \\frac{gS_0}{V_0^2}\n\\]</span> It is a function of a single dimensionless parameter <span class=\"math inline\">\\(\\alpha\\)</span> identifying the effect of gravity.</li>\n</ol>\n<hr />\n<ol start=\"3\" type=\"1\">\n<li><p>Similarly, choose <span class=\"math inline\">\\((S_0,g)\\)</span>, we have</p></li>\n<li><p><span class=\"math display\">\\[\nS^{**} = \\frac{g}{V_0^2}S  \\qquad t^{**} = \\frac{g}{V_0}t\n\\]</span></p></li>\n<li><p>The non-dimensional form body-drop function is therefore: <span class=\"math display\">\\[\nS^* =  \\alpha+ t^{**}+ \\frac{1}{2}gt^{**},\\quad \\mathrm{with} \\quad \\alpha=\\frac{gS_0}{V_0^2}\n\\]</span> Here, <span class=\"math inline\">\\(\\alpha\\)</span> identifies the effect of <span class=\"math inline\">\\(V_0\\)</span>.</p></li>\n</ol>\n<hr />\n<p>The reduction in the number of variables/parameters (2 in this case, from 5 down to 3) equals the number of fundamental dimensions of the problem. This observation was formalised by <strong>Buckingham</strong>.</p>\n<h3 id=\"buckinghams-pi-theorem\">4 Buckinghams Pi theorem</h3>\n<p>Proposed by Buckingham in 1914, it is a means of finding dimensionless groups, or <span class=\"math inline\">\\(\\Pi\\)</span>s</p>\n<blockquote>\n<p>If a physical process satisfies the PDH(Principle of Dimensional Homogeneity) and involves <span class=\"math inline\">\\(n\\)</span> dimensional variables, it can be reduced to a relation between only <span class=\"math inline\">\\(k\\)</span> dimensionless variables or <span class=\"math inline\">\\(\\Pi\\)</span>s. The reduction <span class=\"math inline\">\\(j = n - k\\)</span> equals the maximum number of variables that do not form a <span class=\"math inline\">\\(\\Pi\\)</span> among themselves and is always less than or equal to the number of dimensions describing the variables.</p>\n<p>Find the reduction <span class=\"math inline\">\\(j\\)</span>, then select <span class=\"math inline\">\\(j\\)</span> scaling variables that do not form a <span class=\"math inline\">\\(\\Pi\\)</span> among themselves. Each desired <span class=\"math inline\">\\(\\Pi\\)</span> group will be a power product of these <span class=\"math inline\">\\(j\\)</span> variables plus one additional variable, which is assigned any convenient nonzero exponent. Each <span class=\"math inline\">\\(\\Pi\\)</span> group thus found is independent.</p>\n</blockquote>\n<p>The first part of this theorem describes what sort of a reduction we can achieve for a given equation. The second part describes a methodology for systematically identifying <span class=\"math inline\">\\(\\Pi\\)</span>s</p>\n<p><strong>Example 1</strong></p>\n<p>Suppose we have that the drag force on a body depends on length of the body, velocity of the flow, density and viscosity of the fluid: <span class=\"math display\">\\[\nF = f(L,V,\\rho,\\mu)\n\\]</span></p>\n<ol type=\"1\">\n<li><p>Dimensions of each variables are: <span class=\"math display\">\\[\nF=\\left[M L T^{-2}\\right], \\quad L=[L], \\quad V=\\left[L T^{-1}\\right], \\quad \\rho=\\left[M L^{-3}\\right], \\quad \\mu=\\left[M L^{-1} T^{-1}\\right]\n\\]</span> 3 dimensions exist, <span class=\"math inline\">\\(j=3\\)</span></p></li>\n<li><p>And we expect to find <span class=\"math inline\">\\(k = 5-3 = 2 ~\\Pi\\)</span> groups. We are intersted in how the drag force relates to the velocity, so we choose <span class=\"math inline\">\\((L,\\rho,\\mu)\\)</span>, The two <span class=\"math inline\">\\(\\Pi\\)</span>s are: <span class=\"math display\">\\[\n\\begin{array}{ll}\n\\Pi_{1}=L^{a} \\rho^{b} \\mu^{c} F=L^{0} \\rho^{1} \\mu^{-2} F &amp; {[1]\\left[M L^{-3}\\right]\\left[M L^{-1} T^{-1}\\right]^{-2}\\left[M L T^{-2}\\right]=\\left[M^{0} L^{0} T^{0}\\right]} \\\\\n\\Pi_{2}=L^{a} \\rho^{b} \\mu^{c} V=L^{1} \\rho^{1} \\mu^{-1} V &amp; {[L]\\left[M L^{-3}\\right]\\left[M L^{-1} T^{-1}\\right]^{-1}\\left[L T^{-1}\\right]=\\left[M^{0} L^{0} T^{0}\\right]}\n\\end{array}\n\\]</span></p></li>\n<li><p>As a result we have the dimensionless coefficients: <span class=\"math display\">\\[\nC_{f}=\\frac{\\rho F}{\\mu^{2}}=f(\\mathrm{Re}) \\quad \\text { with } R e=\\frac{\\rho L V}{\\mu}\n\\]</span> <span class=\"math inline\">\\(C_f\\)</span> is the force coefficients and <span class=\"math inline\">\\(Re\\)</span> is the famous Reynolds number.</p></li>\n</ol>\n<p><strong>Example 2</strong></p>\n<p>At low velocities (laminar flow), the volume flow <span class=\"math inline\">\\(Q\\)</span> through a small-bore tube is a function only of the tube radius <span class=\"math inline\">\\(R\\)</span>, the fluid viscosity <span class=\"math inline\">\\(\\mu\\)</span> and the pressure drop per unit tube length <span class=\"math inline\">\\(dp/dx\\)</span>. Using the Pi theorem, find an appropriate dimensionless relationship.</p>\n<p>We have: <span class=\"math display\">\\[\nQ = f(R,\\mu,dp/dx)\n\\]</span></p>\n<ol type=\"1\">\n<li><p>with dimensions: <span class=\"math display\">\\[\nQ=\\left[L^{3} T^{-1}\\right], \\quad R=[L], \\quad \\mu=\\left[M L^{-1} T^{-1}\\right], \\quad d p / d x=\\left[M L^{-2} T^{-2}\\right]\n\\]</span></p></li>\n<li><p>3 dimensions <span class=\"math inline\">\\(\\Rightarrow\\)</span> 3 scaling variables &amp; 1 <span class=\"math inline\">\\(\\Pi\\)</span> group. Choose <span class=\"math inline\">\\((R, \\mu, dp/dx)\\)</span>: <span class=\"math display\">\\[\n\\begin{aligned}\n\\Pi_{1} &amp;=R^{a} \\mu^{b}(d p / d x)^{c} Q \\\\\n&amp;=[L]^{a}\\left[M L^{-1} T^{-1}\\right]^{b}\\left[M L^{-2} T^{-2}\\right]^{c}\\left[L^{3} T^{-1}\\right] \\\\\n&amp;=\\left[M^{0} L^{0} T^{0}\\right] \\quad \\Leftrightarrow \\quad a=-4, b=1, c=-1\n\\end{aligned}\n\\]</span></p></li>\n<li><p>Therefore we have: <span class=\"math display\">\\[\nC = \\frac{Q\\mu}{R^4(dp/dx)}\n\\]</span></p></li>\n</ol>\n<h3 id=\"non-dimensionalisation-of-the-governing-equations\">5 Non-dimensionalisation of the governing equations</h3>\n<p>Give incompressible, no gravity governing equations. Take the case of open flow past an infinitely long circular cylinder. The continuity and momentum equations are given by: <span class=\"math display\">\\[\n\\begin{aligned}\n0 &amp;= \\boldsymbol{\\nabla}\\cdot\\mathbf{V} \\\\\n\\rho\\frac{\\mathrm{d}\\mathbf{V}}{dt} &amp;= -\\boldsymbol{\\nabla}p + \\mu \\boldsymbol{\\nabla}^2\\mathbf{V}\n\\end{aligned}\n\\]</span> Plus boundary conditions: <span class=\"math display\">\\[\n\\begin{aligned}\n\\mathrm{Solid~surface:~}&amp;\\mathbf{V}=0 \\\\\n\\mathrm{Inlet~or~outlet:~}&amp;\\mathrm{Known}~\\mathbf{V},p\n\\end{aligned}\n\\]</span> Plus the cylinder has diameter <span class=\"math inline\">\\(D\\)</span> and the flow has free-stream velocity of <span class=\"math inline\">\\(U_0\\)</span>. Recall that one might suppose that our velocity field is a function of the cylinder diameter, the free-stream velocity, as well as the fluid density and viscosity. We have that: <span class=\"math display\">\\[\n\\mathbf{V} = f(\\mathbf{x},t,p,D,U_0,\\rho,\\mu)\n\\]</span></p>\n<ol type=\"1\">\n<li><p>with dimensions: <span class=\"math display\">\\[\n\\begin{aligned}\n\\Pi_{1} &amp;=R^{a} \\mu^{b}(d p / d x)^{c} Q \\\\\n&amp;=[L]^{a}\\left[M L^{-1} T^{-1}\\right]^{b}\\left[M L^{-2} T^{-2}\\right]^{c}\\left[L^{3} T^{-1}\\right] \\\\\n&amp;=\\left[M^{0} L^{0} T^{0}\\right] \\quad \\Leftrightarrow \\quad a=-4, b=1, c=-1\n\\end{aligned}\n\\]</span></p></li>\n<li><p>3 dimensions and 8 variables <span class=\"math inline\">\\(\\Rightarrow\\)</span> 3 scaling variables &amp; 5 <span class=\"math inline\">\\(\\Pi\\)</span> group. Choose <span class=\"math inline\">\\((D,U_0,\\rho)\\)</span> since they cannot form a <span class=\"math inline\">\\(\\Pi\\)</span> group, we have: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\Pi_{1}=U_{0}^{a} D^{b} \\rho^{c} V=U_{0}^{-1} V \\\\\n&amp;\\Pi_{2}=U_{0}^{a} D^{b} \\rho^{c} \\mathbf{x}=D^{-1} \\mathbf{x} \\\\\n&amp;\\Pi_{3}=U_{0}^{a} D^{b} \\rho^{c} t=U_{0} D^{-1} t \\\\\n&amp;\\Pi_{4}=U_{0}^{a} D^{b} \\rho^{c} p=\\left[L T^{-1}\\right]^{a}[L]^{b}\\left[M L^{-3}\\right]^{c}\\left[M L^{-1} T^{-2}\\right]=U_{0}^{-2} \\rho^{-1} p \\\\\n&amp;\\Pi_{5}=U_{0}^{a} D^{b} \\rho^{c} \\mu=\\left[L T^{-1}\\right]^{a}[L]^{b}\\left[M L^{-3}\\right]^{c}\\left[M L^{-1} T^{-1}\\right]=U_{0}^{-1} D^{-1} \\rho^{-1} \\mu\n\\end{aligned}\n\\]</span></p></li>\n<li><p>Therefore: <span class=\"math display\">\\[\n\\frac{V}{U_{0}}=f\\left(\\frac{x}{D}, \\frac{t U_{0}}{D}, \\frac{p}{U_{0}^{2} \\rho}, \\frac{\\mu}{\\rho U_{0} D}\\right)\n\\]</span></p></li>\n<li><p>Use above to write down the non-dimensional scaling of the parameters: <span class=\"math display\">\\[\nV^{*}=\\frac{1}{U_{0}} V \\quad \\mathbf{x}^{*}=\\frac{1}{D} \\mathbf{x} \\quad t^{*}=\\frac{U_{0}}{D} t \\quad p^{*}=\\frac{1}{\\rho U_{0}^{2}} p \\quad \\nabla^{*}=D \\nabla \\quad \\mu^{*}=\\frac{1}{\\rho U_{0} D} \\mu\n\\]</span></p></li>\n<li><p>Therefore the non-dimensional form of N-S equations: <span class=\"math display\">\\[\n\\begin{aligned}\n0 &amp;= \\boldsymbol{\\nabla^*}\\cdot\\mathbf{V^*} \\\\\n\\rho\\frac{\\mathrm{d}\\mathbf{V^*}}{dt^*} &amp;= -\\boldsymbol{\\nabla^*}p^* + \\frac{1}{Re} \\boldsymbol{\\nabla^{*2}}\\mathbf{V^*}\n\\end{aligned}\n\\]</span> where <span class=\"math inline\">\\(Re = \\frac{\\rho U_0D}{\\mu}\\)</span> and with boundary conditions: <span class=\"math display\">\\[\n\\begin{aligned}\n\\mathrm{Solid~surface:~}&amp;\\mathbf{V^*}=0 \\\\\n\\mathrm{Inlet~or~outlet:~}&amp;\\mathrm{Known}~\\mathbf{V^*},p^*\n\\end{aligned}\n\\]</span></p></li>\n</ol>\n<p>In this case, rather than analysing our flow problem with respect to the four parameters (cylinder radius, free-stream velocity, density and viscosity), we need only analyse it with respect to the single dimensionless Reynolds number.</p>\n<p>Besides, the above can be generalised by considering <span class=\"math inline\">\\(U_0\\)</span> and <span class=\"math inline\">\\(D\\)</span> to be any characteristic velocity- and length-scale of the specific problem being considered.</p>\n<h3 id=\"dimensionless-parameters\">6 Dimensionless parameters</h3>\n<p>To conclude we highlight a couple of the dimensionless parameters which can arise in the incompressible Navier-Stokes equations.</p>\n<p>There are no dimensionless parameters in the continuity equation. However, there is one in the momentum equation, the Reynolds number <span class=\"math display\">\\[\nRe = \\frac{\\rho U_0D}{\\mu}\n\\]</span> It can be considered as the ratio of <em>inertial</em> to <em>viscous</em> effects and is widely considered the <strong>most important</strong> parameter in fluid mechanics.</p>\n<p>If the free-stream velocity <span class=\"math inline\">\\(U_0\\)</span> were instead considered to be oscillating rather than constant, and of the form: <span class=\"math display\">\\[\nU = U_0\\cos(\\omega t)\n\\]</span> then the problem can be considered as: <span class=\"math display\">\\[\n\\mathbf{V} = f(\\mathbf{x},t,p,D,U_0,\\rho,\\mu, \\omega)\n\\]</span> And the non-dimensionalised <span class=\"math inline\">\\(U(t)\\)</span>, we observe that: <span class=\"math display\">\\[\n\\frac{U}{U_0}=U^*=\\cos\\left(\\frac{\\omega D}{U_0}t^*\\right)\n\\]</span> where <span class=\"math inline\">\\(\\omega\\)</span> is the frequency. We now have an additional dimensionless parameter called the <strong><em>Strouhal number</em>:</strong> <span class=\"math display\">\\[\nSt = \\frac{\\omega D}{U_0}\n\\]</span> There are many other dimensionless parameters which arise in specific types of flow problems.</p>\n","site":{"data":{}},"wordcount":9617,"excerpt":"<div class=\"note note-primary\">\n            <p>Feeling unsafe when deploying CFD algorithms, the best way to alleviate the anxiety is to derive the fundamentals again.</p>\n          </div>","more":"<p>Introduce dimensionless parameters into the incompressible Navier-Stokes equations to arrive at a non-dimensional form.</p>\n<h3 id=\"motivation\">1 Motivation</h3>\n<p>To reduce the dimensionality of the problem.</p>\n<h3 id=\"dimensional-analysis\">2 Dimensional analysis</h3>\n<p>Given fundamental physical quantities such as length <span class=\"math inline\">\\([L]\\)</span>, time <span class=\"math inline\">\\([T]\\)</span>, mass <span class=\"math inline\">\\([M]\\)</span> and temperature <span class=\"math inline\">\\([\\Theta]\\)</span>,</p>\n<ul>\n<li>Aera <span class=\"math inline\">\\(A\\)</span> is <span class=\"math inline\">\\([L^2]\\)</span></li>\n<li>Velocity <span class=\"math inline\">\\(V\\)</span> is <span class=\"math inline\">\\([LT^{-1}]\\)</span></li>\n<li>Acceleration <span class=\"math inline\">\\(a\\)</span> is <span class=\"math inline\">\\([LT^{-2}]\\)</span></li>\n<li>Force <span class=\"math inline\">\\(F\\)</span> is <span class=\"math inline\">\\([MLT^{-2}]\\)</span></li>\n<li>Pressure <span class=\"math inline\">\\(p\\)</span> is <span class=\"math inline\">\\([ML^{-1}T^{-2}]\\)</span></li>\n<li>Energy <span class=\"math inline\">\\(J\\)</span> is <span class=\"math inline\">\\([ML^2T^{-2}]\\)</span></li>\n</ul>\n<p>The <em>principle of dimensional homogeneity</em> states the dimensions on both sides of an equation balance. And it applies to all equations of mechanics.</p>\n<p>In dimensional analysis, take Bernoulli equation as an example, there are 4 factors: <span class=\"math display\">\\[\n\\frac{p}{\\rho} + \\frac{1}{2}V^2 +gz = Const.\n\\]</span></p>\n<ul>\n<li><em>Dimensional variables</em>: variables, <span class=\"math inline\">\\(p\\)</span>, <span class=\"math inline\">\\(V\\)</span> and <span class=\"math inline\">\\(z\\)</span></li>\n<li><em>Dimensional parameters</em>: fixed throughout experiment although with a dimension, <span class=\"math inline\">\\(\\rho\\)</span>, <span class=\"math inline\">\\(g\\)</span> and <span class=\"math inline\">\\(Const\\)</span></li>\n<li><em>Pure constants</em>: mathematical manipulations, <span class=\"math inline\">\\(\\pi\\)</span> and <span class=\"math inline\">\\(e\\approx2.718\\)</span></li>\n</ul>\n<div class=\"note note-info\">\n            <p>Special care:</p><ul><li><p><em>Angles</em> are dimensionless yet the units are radians</p></li><li><p>Some physical quantities are dimensionless by their definition, such as <em>strain</em> as a change in length per unit length</p></li><li><p>Integration and differentiation change the dimension of the equation as well</p></li></ul>\n          </div>\n<h3 id=\"non-dimensionalisation-of-equations\">3 Non-dimensionalisation of equations</h3>\n<p>Any dimensionally homogeneous equation can be non-dimensionalised, This process roughly proceeds as follows:</p>\n<ol type=\"1\">\n<li><p>Identify which quantities are <em>variables</em> (vary or measured) and <em>parameters</em> (fixed per experiment).</p></li>\n<li><p>Identify the number of fundamental dimensions, <span class=\"math inline\">\\(N\\)</span>, involved.</p></li>\n<li><p>Select <span class=\"math inline\">\\(N\\)</span> parameters to be scaling parameters with which to define dimensionless variables.</p>\n<div class=\"note note-info\">\n            <p>Note: There are often multiple choices here and the choice will depend on exactly what we are aiming to show with our data.</p>\n          </div></li>\n<li><p>Scale each variable <span class=\"math inline\">\\(u\\)</span> by combinations of these scaling parameters <span class=\"math inline\">\\(s_i\\)</span> to arrive at a non-dimensional form <span class=\"math inline\">\\(u^\\)</span>. i.e. write <span class=\"math inline\">\\(u^ = \\alpha(s_i)u\\)</span>.</p></li>\n<li><p>Substitute into the equation and simplify to arrive at its non-dimensional form.</p></li>\n</ol>\n<p>Some rules for selecting scaling parameters:</p>\n<ul>\n<li><p>They must <em>not</em> form a dimensionless group amongst themselves. For example: <span class=\"math display\">\\[\nS_{0}^{a} V_{0}^{b}=[L]^{a}\\left[L T^{-1}\\right]^{b}=L^{0} T^{0} \\quad \\Leftrightarrow \\quad a=b=0\n\\]</span></p></li>\n<li><p>Do not include the output variables you wish to analyse/plot.</p></li>\n</ul>\n<p><strong>Example</strong></p>\n<p>Give the falling-body equation, and follow the process <span class=\"math display\">\\[\nS = S_0+V_0t+\\frac{1}{2}gt^2\n\\]</span></p>\n<ol type=\"1\">\n<li><p>Divide the variables and parameters: <span class=\"math display\">\\[\n\\mathrm{Variables:~}S,t,\\qquad\\mathrm{Parameters:~}S_0,V_0,g\n\\]</span></p></li>\n<li><p>Identify the dimensions: <span class=\"math display\">\\[\nS = [L], \\quad t=[T],\\quad S_0=[L],\\quad V_0=[L/t],\\quad g=[L/t^2]\n\\]</span> And 2 dimensions exist: <span class=\"math inline\">\\([L]\\)</span> and <span class=\"math inline\">\\([T]\\)</span></p></li>\n</ol>\n<hr />\n<ol start=\"3\" type=\"1\">\n<li><p>There are 3 options of parameters choosing, choose <span class=\"math inline\">\\((S_0,V_0)\\)</span> for instance,</p></li>\n<li><p>Non-dimensional variables can be described as:</p></li>\n</ol>\n<p><span class=\"math display\">\\[\nS^* = \\frac{1}{S_0}S  \\qquad t^* = \\frac{V_0}{S_0}t\n\\]</span></p>\n<ol start=\"5\" type=\"1\">\n<li>Subscribe into the function to get a non-dimensional form of it: <span class=\"math display\">\\[\nS^* = 1+t^*+\\frac{1}{2}\\alpha t^{*2}, \\quad \\mathrm{with} \\quad \\alpha = \\frac{gS_0}{V_0^2}\n\\]</span> It is a function of a single dimensionless parameter <span class=\"math inline\">\\(\\alpha\\)</span> identifying the effect of gravity.</li>\n</ol>\n<hr />\n<ol start=\"3\" type=\"1\">\n<li><p>Similarly, choose <span class=\"math inline\">\\((S_0,g)\\)</span>, we have</p></li>\n<li><p><span class=\"math display\">\\[\nS^{**} = \\frac{g}{V_0^2}S  \\qquad t^{**} = \\frac{g}{V_0}t\n\\]</span></p></li>\n<li><p>The non-dimensional form body-drop function is therefore: <span class=\"math display\">\\[\nS^* =  \\alpha+ t^{**}+ \\frac{1}{2}gt^{**},\\quad \\mathrm{with} \\quad \\alpha=\\frac{gS_0}{V_0^2}\n\\]</span> Here, <span class=\"math inline\">\\(\\alpha\\)</span> identifies the effect of <span class=\"math inline\">\\(V_0\\)</span>.</p></li>\n</ol>\n<hr />\n<p>The reduction in the number of variables/parameters (2 in this case, from 5 down to 3) equals the number of fundamental dimensions of the problem. This observation was formalised by <strong>Buckingham</strong>.</p>\n<h3 id=\"buckinghams-pi-theorem\">4 Buckinghams Pi theorem</h3>\n<p>Proposed by Buckingham in 1914, it is a means of finding dimensionless groups, or <span class=\"math inline\">\\(\\Pi\\)</span>s</p>\n<blockquote>\n<p>If a physical process satisfies the PDH(Principle of Dimensional Homogeneity) and involves <span class=\"math inline\">\\(n\\)</span> dimensional variables, it can be reduced to a relation between only <span class=\"math inline\">\\(k\\)</span> dimensionless variables or <span class=\"math inline\">\\(\\Pi\\)</span>s. The reduction <span class=\"math inline\">\\(j = n - k\\)</span> equals the maximum number of variables that do not form a <span class=\"math inline\">\\(\\Pi\\)</span> among themselves and is always less than or equal to the number of dimensions describing the variables.</p>\n<p>Find the reduction <span class=\"math inline\">\\(j\\)</span>, then select <span class=\"math inline\">\\(j\\)</span> scaling variables that do not form a <span class=\"math inline\">\\(\\Pi\\)</span> among themselves. Each desired <span class=\"math inline\">\\(\\Pi\\)</span> group will be a power product of these <span class=\"math inline\">\\(j\\)</span> variables plus one additional variable, which is assigned any convenient nonzero exponent. Each <span class=\"math inline\">\\(\\Pi\\)</span> group thus found is independent.</p>\n</blockquote>\n<p>The first part of this theorem describes what sort of a reduction we can achieve for a given equation. The second part describes a methodology for systematically identifying <span class=\"math inline\">\\(\\Pi\\)</span>s</p>\n<p><strong>Example 1</strong></p>\n<p>Suppose we have that the drag force on a body depends on length of the body, velocity of the flow, density and viscosity of the fluid: <span class=\"math display\">\\[\nF = f(L,V,\\rho,\\mu)\n\\]</span></p>\n<ol type=\"1\">\n<li><p>Dimensions of each variables are: <span class=\"math display\">\\[\nF=\\left[M L T^{-2}\\right], \\quad L=[L], \\quad V=\\left[L T^{-1}\\right], \\quad \\rho=\\left[M L^{-3}\\right], \\quad \\mu=\\left[M L^{-1} T^{-1}\\right]\n\\]</span> 3 dimensions exist, <span class=\"math inline\">\\(j=3\\)</span></p></li>\n<li><p>And we expect to find <span class=\"math inline\">\\(k = 5-3 = 2 ~\\Pi\\)</span> groups. We are intersted in how the drag force relates to the velocity, so we choose <span class=\"math inline\">\\((L,\\rho,\\mu)\\)</span>, The two <span class=\"math inline\">\\(\\Pi\\)</span>s are: <span class=\"math display\">\\[\n\\begin{array}{ll}\n\\Pi_{1}=L^{a} \\rho^{b} \\mu^{c} F=L^{0} \\rho^{1} \\mu^{-2} F &amp; {[1]\\left[M L^{-3}\\right]\\left[M L^{-1} T^{-1}\\right]^{-2}\\left[M L T^{-2}\\right]=\\left[M^{0} L^{0} T^{0}\\right]} \\\\\n\\Pi_{2}=L^{a} \\rho^{b} \\mu^{c} V=L^{1} \\rho^{1} \\mu^{-1} V &amp; {[L]\\left[M L^{-3}\\right]\\left[M L^{-1} T^{-1}\\right]^{-1}\\left[L T^{-1}\\right]=\\left[M^{0} L^{0} T^{0}\\right]}\n\\end{array}\n\\]</span></p></li>\n<li><p>As a result we have the dimensionless coefficients: <span class=\"math display\">\\[\nC_{f}=\\frac{\\rho F}{\\mu^{2}}=f(\\mathrm{Re}) \\quad \\text { with } R e=\\frac{\\rho L V}{\\mu}\n\\]</span> <span class=\"math inline\">\\(C_f\\)</span> is the force coefficients and <span class=\"math inline\">\\(Re\\)</span> is the famous Reynolds number.</p></li>\n</ol>\n<p><strong>Example 2</strong></p>\n<p>At low velocities (laminar flow), the volume flow <span class=\"math inline\">\\(Q\\)</span> through a small-bore tube is a function only of the tube radius <span class=\"math inline\">\\(R\\)</span>, the fluid viscosity <span class=\"math inline\">\\(\\mu\\)</span> and the pressure drop per unit tube length <span class=\"math inline\">\\(dp/dx\\)</span>. Using the Pi theorem, find an appropriate dimensionless relationship.</p>\n<p>We have: <span class=\"math display\">\\[\nQ = f(R,\\mu,dp/dx)\n\\]</span></p>\n<ol type=\"1\">\n<li><p>with dimensions: <span class=\"math display\">\\[\nQ=\\left[L^{3} T^{-1}\\right], \\quad R=[L], \\quad \\mu=\\left[M L^{-1} T^{-1}\\right], \\quad d p / d x=\\left[M L^{-2} T^{-2}\\right]\n\\]</span></p></li>\n<li><p>3 dimensions <span class=\"math inline\">\\(\\Rightarrow\\)</span> 3 scaling variables &amp; 1 <span class=\"math inline\">\\(\\Pi\\)</span> group. Choose <span class=\"math inline\">\\((R, \\mu, dp/dx)\\)</span>: <span class=\"math display\">\\[\n\\begin{aligned}\n\\Pi_{1} &amp;=R^{a} \\mu^{b}(d p / d x)^{c} Q \\\\\n&amp;=[L]^{a}\\left[M L^{-1} T^{-1}\\right]^{b}\\left[M L^{-2} T^{-2}\\right]^{c}\\left[L^{3} T^{-1}\\right] \\\\\n&amp;=\\left[M^{0} L^{0} T^{0}\\right] \\quad \\Leftrightarrow \\quad a=-4, b=1, c=-1\n\\end{aligned}\n\\]</span></p></li>\n<li><p>Therefore we have: <span class=\"math display\">\\[\nC = \\frac{Q\\mu}{R^4(dp/dx)}\n\\]</span></p></li>\n</ol>\n<h3 id=\"non-dimensionalisation-of-the-governing-equations\">5 Non-dimensionalisation of the governing equations</h3>\n<p>Give incompressible, no gravity governing equations. Take the case of open flow past an infinitely long circular cylinder. The continuity and momentum equations are given by: <span class=\"math display\">\\[\n\\begin{aligned}\n0 &amp;= \\boldsymbol{\\nabla}\\cdot\\mathbf{V} \\\\\n\\rho\\frac{\\mathrm{d}\\mathbf{V}}{dt} &amp;= -\\boldsymbol{\\nabla}p + \\mu \\boldsymbol{\\nabla}^2\\mathbf{V}\n\\end{aligned}\n\\]</span> Plus boundary conditions: <span class=\"math display\">\\[\n\\begin{aligned}\n\\mathrm{Solid~surface:~}&amp;\\mathbf{V}=0 \\\\\n\\mathrm{Inlet~or~outlet:~}&amp;\\mathrm{Known}~\\mathbf{V},p\n\\end{aligned}\n\\]</span> Plus the cylinder has diameter <span class=\"math inline\">\\(D\\)</span> and the flow has free-stream velocity of <span class=\"math inline\">\\(U_0\\)</span>. Recall that one might suppose that our velocity field is a function of the cylinder diameter, the free-stream velocity, as well as the fluid density and viscosity. We have that: <span class=\"math display\">\\[\n\\mathbf{V} = f(\\mathbf{x},t,p,D,U_0,\\rho,\\mu)\n\\]</span></p>\n<ol type=\"1\">\n<li><p>with dimensions: <span class=\"math display\">\\[\n\\begin{aligned}\n\\Pi_{1} &amp;=R^{a} \\mu^{b}(d p / d x)^{c} Q \\\\\n&amp;=[L]^{a}\\left[M L^{-1} T^{-1}\\right]^{b}\\left[M L^{-2} T^{-2}\\right]^{c}\\left[L^{3} T^{-1}\\right] \\\\\n&amp;=\\left[M^{0} L^{0} T^{0}\\right] \\quad \\Leftrightarrow \\quad a=-4, b=1, c=-1\n\\end{aligned}\n\\]</span></p></li>\n<li><p>3 dimensions and 8 variables <span class=\"math inline\">\\(\\Rightarrow\\)</span> 3 scaling variables &amp; 5 <span class=\"math inline\">\\(\\Pi\\)</span> group. Choose <span class=\"math inline\">\\((D,U_0,\\rho)\\)</span> since they cannot form a <span class=\"math inline\">\\(\\Pi\\)</span> group, we have: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\Pi_{1}=U_{0}^{a} D^{b} \\rho^{c} V=U_{0}^{-1} V \\\\\n&amp;\\Pi_{2}=U_{0}^{a} D^{b} \\rho^{c} \\mathbf{x}=D^{-1} \\mathbf{x} \\\\\n&amp;\\Pi_{3}=U_{0}^{a} D^{b} \\rho^{c} t=U_{0} D^{-1} t \\\\\n&amp;\\Pi_{4}=U_{0}^{a} D^{b} \\rho^{c} p=\\left[L T^{-1}\\right]^{a}[L]^{b}\\left[M L^{-3}\\right]^{c}\\left[M L^{-1} T^{-2}\\right]=U_{0}^{-2} \\rho^{-1} p \\\\\n&amp;\\Pi_{5}=U_{0}^{a} D^{b} \\rho^{c} \\mu=\\left[L T^{-1}\\right]^{a}[L]^{b}\\left[M L^{-3}\\right]^{c}\\left[M L^{-1} T^{-1}\\right]=U_{0}^{-1} D^{-1} \\rho^{-1} \\mu\n\\end{aligned}\n\\]</span></p></li>\n<li><p>Therefore: <span class=\"math display\">\\[\n\\frac{V}{U_{0}}=f\\left(\\frac{x}{D}, \\frac{t U_{0}}{D}, \\frac{p}{U_{0}^{2} \\rho}, \\frac{\\mu}{\\rho U_{0} D}\\right)\n\\]</span></p></li>\n<li><p>Use above to write down the non-dimensional scaling of the parameters: <span class=\"math display\">\\[\nV^{*}=\\frac{1}{U_{0}} V \\quad \\mathbf{x}^{*}=\\frac{1}{D} \\mathbf{x} \\quad t^{*}=\\frac{U_{0}}{D} t \\quad p^{*}=\\frac{1}{\\rho U_{0}^{2}} p \\quad \\nabla^{*}=D \\nabla \\quad \\mu^{*}=\\frac{1}{\\rho U_{0} D} \\mu\n\\]</span></p></li>\n<li><p>Therefore the non-dimensional form of N-S equations: <span class=\"math display\">\\[\n\\begin{aligned}\n0 &amp;= \\boldsymbol{\\nabla^*}\\cdot\\mathbf{V^*} \\\\\n\\rho\\frac{\\mathrm{d}\\mathbf{V^*}}{dt^*} &amp;= -\\boldsymbol{\\nabla^*}p^* + \\frac{1}{Re} \\boldsymbol{\\nabla^{*2}}\\mathbf{V^*}\n\\end{aligned}\n\\]</span> where <span class=\"math inline\">\\(Re = \\frac{\\rho U_0D}{\\mu}\\)</span> and with boundary conditions: <span class=\"math display\">\\[\n\\begin{aligned}\n\\mathrm{Solid~surface:~}&amp;\\mathbf{V^*}=0 \\\\\n\\mathrm{Inlet~or~outlet:~}&amp;\\mathrm{Known}~\\mathbf{V^*},p^*\n\\end{aligned}\n\\]</span></p></li>\n</ol>\n<p>In this case, rather than analysing our flow problem with respect to the four parameters (cylinder radius, free-stream velocity, density and viscosity), we need only analyse it with respect to the single dimensionless Reynolds number.</p>\n<p>Besides, the above can be generalised by considering <span class=\"math inline\">\\(U_0\\)</span> and <span class=\"math inline\">\\(D\\)</span> to be any characteristic velocity- and length-scale of the specific problem being considered.</p>\n<h3 id=\"dimensionless-parameters\">6 Dimensionless parameters</h3>\n<p>To conclude we highlight a couple of the dimensionless parameters which can arise in the incompressible Navier-Stokes equations.</p>\n<p>There are no dimensionless parameters in the continuity equation. However, there is one in the momentum equation, the Reynolds number <span class=\"math display\">\\[\nRe = \\frac{\\rho U_0D}{\\mu}\n\\]</span> It can be considered as the ratio of <em>inertial</em> to <em>viscous</em> effects and is widely considered the <strong>most important</strong> parameter in fluid mechanics.</p>\n<p>If the free-stream velocity <span class=\"math inline\">\\(U_0\\)</span> were instead considered to be oscillating rather than constant, and of the form: <span class=\"math display\">\\[\nU = U_0\\cos(\\omega t)\n\\]</span> then the problem can be considered as: <span class=\"math display\">\\[\n\\mathbf{V} = f(\\mathbf{x},t,p,D,U_0,\\rho,\\mu, \\omega)\n\\]</span> And the non-dimensionalised <span class=\"math inline\">\\(U(t)\\)</span>, we observe that: <span class=\"math display\">\\[\n\\frac{U}{U_0}=U^*=\\cos\\left(\\frac{\\omega D}{U_0}t^*\\right)\n\\]</span> where <span class=\"math inline\">\\(\\omega\\)</span> is the frequency. We now have an additional dimensionless parameter called the <strong><em>Strouhal number</em>:</strong> <span class=\"math display\">\\[\nSt = \\frac{\\omega D}{U_0}\n\\]</span> There are many other dimensionless parameters which arise in specific types of flow problems.</p>"},{"title":"Internal flow fundamentals","author":"Ryan LI","toc":true,"declare":true,"index_img":"/index/internal_flow.png","date":"2022-05-20T16:24:41.000Z","_content":"\n{% note primary %}\n\nFeeling good deriving the basics, continue to review the following content.\n\n{% endnote%}\n\n<!-- more -->\n\n## 1 Flow regimes  case study of duct flow\n\n### 1.1 Examples of duct flows\n\n#### 1.1.1 Oil extraction\n\nUpon finding a natural oil reservoir, several techniques are employed to extract the oil.\n\n1. Drilling a long hole into the Earth and placing a duct in, the oil reservoir possesses a higher pressure then the atmosphere thus the oil is pushed upwards along the duct.\n2. Steam injection, drilling a second hole to inject steam, the addition of steam increase the pressure and push the oil further upwards. The increase in temperature reduces the viscosity.\n\n#### 1.1.2 Pipeline transport\n\nTransport systems designed to bring the oil to storage or treatment sites face many challenges. Take Trans-Alaska Pipeline System (TAPS) as an example, oil extracted is substantially warmer than anything at the surface, the permafrost (frozen ground) may warm up and become unstable. To avoid this , radiators have beed placed next to the pipeline.\n\nBesides, drag-reducing agents DRA are mixed with the oil to reduce the viscous drag produced by the massive turbulent flow inside.\n\n#### 1.1.3 Biological flow\n\nThe cerebral blood flow in the cortex can be modelled through a complex assembly of ducts, mimicking the vessel network present in the brain. Experimental data coupled with numerical simulations can then provide prediction of the pressure map in the brain.Access to these results can then be used to predict the risks of blockage or damage of the vessels and thus of brain stroke.\n\n### 1.2 Reynolds number\n\nIn 1883, Osbourne Reynolds published his famous pipe flow experiment. He placed a pipe within a tank full of water. The water entered in the pipe through a converging cone to decrease the impact of entrance effects and the flow rate is controled by a valve. Aligned with the entrance of the pipe is a needle connected to a dye container. As the desired flow rate is reached, dye is injected within the pipe to trace out the fluids trajectory.\n\n<img src=\"Reynolds experiment.png\" alt=\"Photographs of pipe flow visualised using dye injection in the centerline. The Reynolds number is increased from top to bottom and the successive snapshots represent: laminar flow, transitional flow, turbulent flow, turbulent flow. After Van Dyke, An Album of Fluid Motion (1982).\" style=\"zoom:100%;\" />\n\nIn addition to making these observations, it is possible to characterise these different regimes in a simple manner, the quantities that influence the flow are:\n\n- pipe diameter $l$: $[l]=L$\n- fluid's velocity $u$: $[u]=LT^{-1}$\n- fluid's density $\\rho$: $[\\rho] = mL^{-3}$ \n- fluid's dynamic viscosity $\\mu$: $[\\mu]=mL^{-1}T^{-1}$\n\nCombine these quantities to obtain a dimensionless number called Reynolds number,\n$$\n\\color{purple}\nRe = \\frac{\\rho V L}{\\mu}\n$$\n<img src=\"3 flow regimes.png\" alt=\"Sketch of the temporal variations of the streamwise velocity at a fixed location in the pipe. From left to right: laminar, transitional and turbulent regimes. After White, Fluid Mechanics (2011).\" style=\"zoom:100%;\" />\n\nWith Reynolds number, 3 regimes of flow can be defined:\n\n- Laminar flows: $0<Re<1000$\n- Transitional flows: $1000<Re<4000$\n- Turbulent flows: $4000<Re$\n\n<img src=\"puffs.png\" alt=\"Visualisation of a puff going through a pipe and splitting. Time goes from bottom to top and the quantity represented is the streamwise vorticity, red (resp. blue) representing positive (resp. negative) values. The Reynolds number is 2300. After Avila et al., Science 333, 192 (2011).\" style=\"zoom:100%;\" />\n\nThe intermittent bursts of turbulence displayed in the transitional regime are the signature of the passage of turbulent puffs. They can be observed by direct numerical simulation, like the figure above for Re = 2300. The upstream edge of the puff is well-defined, while the downstream edge is elongated and fuzzy.\nPuffs typically evolve in two different ways: Vanishing and decaying down to the laminar state or splitting, leading to an increasingly large turbulent fraction in the flow. Puffs decay rapidly in the laminar regime and split frequently in the turbulent regime, but they remain long-lived in the transitional one.\n\nThe lifetime of a puff before decaying and splitting in pipe flow is studied as a function of Reynolds number, and the results are shown below. It is confirmed that the puffs are long-lived over a wide range of $Re$s. Importantly, there is an intersection between the decay and the splitting lifetime curves. This intersection provides a well-defined legitimate threshold between laminar and turbulent flows: $Re_c 2040$.\n\n<img src=\"puff lifetimes.png\" alt=\"Mean lifetime of a puff before decay or splitting in pipe flow as a function of the Reynolds number. After Avila et al., Science 333, 192 (2011).\" style=\"zoom:50%;\" />\n\n### 1.3 Other considerations\n\n#### 1.3.1 Newtonian/non-Newtonian fluids\n\nWater and air all follow the rule of constant viscosity, that is, the wall shear stress is $\\mu$ proportional to the normal velocity gradient (shear, strain rate):\n$$\n\\tau = \\mu\\partial_nu\n$$\nBut not all types of fluids follow this law, as seen below. \n\n- Shear thinning: ketchup, becoming less and less viscous as they are stirred. \n- Shear thickening: corn starch, getting much harder to strain as they receive more stress. \n- Mayonnaise: tooth paste, possessing a threshold stress below which they behave like solids and above which their rheological law is linear. If you hang the open container upside down, it will not flow. An additional force is needed on the container to create a flow.\n- More complicated, HerschelBulkley fluids (e.g. paint) or even time-dependent visco-elastic fluids (e.g. polymers).\n\n<img src=\"non-newtonian flow.png\" alt=\"Rheological diagram showing the shear stress  as a function of the shear rate nu for several types of fluids.\" style=\"zoom:50%;\" />\n\n#### 1.3.2 Compressibility\n\nWhen the flow speed reach the speed of sound, the fluid becomes compressible, meaning the density becomes variant in time and space. The best unidimensional quantity to describe this threshold is called Mach number:\n$$\nMa = \\frac{u}{c}\n$$\nwhere the $c$ is the speed of sound, and the flowing regimes are observed defined by $Ma$.\n\n- $0<Ma<0.3$: incompressible flows.\n- $0.3<Ma<1$: compressible subsonic flows.\n- $1<Ma$: compressible supersonic flows.\n\n## 2 Laminar flow cases\n\n### 2.1 Incompressible framework\n\n#### 2.1.1 The Navier-Stokes equation\n\nThe incompressible NavierStokes equation describes the motion of fluids under external forces. It writes:\n$$\n\\color{purple}\n\\frac{\\partial \\mathbf{V}}{\\partial t}+\\mathbf{V}\\cdot\\boldsymbol{\\nabla} \\mathbf{V} = \\mathbf{f} -\\frac{1}{\\rho}\\boldsymbol{\\nabla} p + \\nu\\boldsymbol{\\nabla}^2\\mathbf{V}\n$$\n\n> The left-hand-side of the NavierStokes equation represents inertia. It involves the rate of change of the velocity with time tu as well as advection (u  ) u. The latter term quantifies how the fluid is transported by the flow velocity. In an equation such as the heat equation, this term applies to the temperature T, reads (u  ) T and quantifies how temperature is transported by the flow velocity.\n>\n> The right-hand-side represents all the forces acting on the fluid. In addition to the external forces f that we will not take into account in this Chapter, the other terms come from the divergence of the stress tensor. They include the pressure gradient p that translates the fact that the fluid is attracted to low pressure regions and the viscous force 2u quantifying the internal friction between in the fluid.\n\n#### 2.1.2 Continuity equation\n\nRecall the mass conservation equation in the Eulerian frame of reference,\n$$\n\\frac{\\partial\\rho}{\\partial t} + \\boldsymbol{\\nabla}\\cdot(\\rho\\mathbf{V})=0\n$$\nAnd with the incompressibility consumption, \n$$\n\\color{purple}\n\\boldsymbol{\\nabla}\\cdot\\mathbf{V} = 0\n$$\n\n#### 2.1.2 Additional hypotheses\n\nIn the laminar flow regime, it is common to assume the flow as:\n\n- steady: $\\partial_t=0$\n- unidirectional: the flow is parallel the to walls\n- symmetry: the flow is further simplified using the symmetries of the geometry\n\n### 2.2 Pipe flow\n\n#### 2.2.1 Cylindrical coordinate\n\nIn cylindrical coordinate, the velocity:\n$$\n\\mathbf{V} = u_r\\mathbf{\\hat {r}}+u_\\theta\\boldsymbol{\\hat {\\theta}}+u_z\\mathbf{\\hat {z}}\n$$\nThe line element writes:\n$$\nds = dr\\mathbf{\\hat{r}} + rd\\theta\\boldsymbol{\\hat{\\theta}}+dz\\mathbf{\\hat{z}}\n$$\nThe gradient operator\n$$\n\\boldsymbol{\\nabla} = \\partial_r\\mathbf{\\hat {r}}+\\frac{1}{r}\\partial_\\theta\\boldsymbol{\\hat {\\theta}}+\\partial_z\\mathbf{\\hat {z}}\n$$\nAnd the directions change with $\\theta$, as a consequence:\n$$\n\\partial_\\theta\\mathbf{\\hat{r}} = \\boldsymbol{\\hat {\\theta}}, \\qquad \\partial_\\theta\\boldsymbol{\\hat {\\theta}} = -\\mathbf{\\hat{r}}\n$$\nSome useful equations:\n$$\n\\begin{aligned}\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} =& \\frac{1}{r}\\partial_r(ru_r)+ \\frac{1}{r}\\partial_\\theta(u_\\theta) + \\partial_z(u_z) \\\\\n(\\mathbf{V}\\cdot\\boldsymbol{\\nabla})\\mathbf{V} =&\\left(u_{r} \\partial_{r} u_{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{r}-\\frac{u_{\\theta}^{2}}{r}+u_{z} \\partial_{z} u_{r}\\right) \\hat{\\mathbf{r}} \\\\\n&+\\left(u_{r} \\partial_{r} u_{\\theta}+\\frac{u_{r} u_{\\theta}}{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{\\theta}+u_{z} \\partial_{z} u_{\\theta}\\right) \\boldsymbol{\\hat{\\theta}}\\\\\n&+\\left(u_{r} \\partial_{r} u_{z}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{z}+u_{z} \\partial_{z} u_{z}\\right) \\hat{\\mathbf{z}}\\\\\n\n\\boldsymbol{\\nabla}^2\\mathbf{V}=&\\left[\\frac{1}{r} \\partial_{r}\\right.\\left.\\left(r \\partial_{r} u_{r}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{r}-\\frac{u_{r}}{r^{2}}-\\frac{2}{r^{2}} \\partial_{\\theta} u_{\\theta}+\\partial_{z}^{2} u_{r}\\right] \\hat{\\mathbf{r}} \\\\\n&+ {\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{\\theta}\\right)+\\frac{2}{r^{2}} \\partial_{\\theta} u_{r}+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{\\theta}-\\frac{u_{\\theta}}{r^{2}}+\\partial_{z}^{2} u_{\\theta}\\right] \\boldsymbol{\\hat{\\theta} }} \\\\\n&+ {\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{z}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{z}+\\partial_{z}^{2} u_{z}\\right] \\hat{\\mathbf{z}} } \\\\\n\\end{aligned}\n$$\n\n#### 2.2.2 Governing equations\n\nContinuity equation:\n$$\n\\frac{1}{r}\\partial_r(ru_r)+ \\frac{1}{r}\\partial_\\theta(u_\\theta) + \\partial_z(u_z) = 0\n$$\nNavierStokes equation:\n$$\n\\begin{aligned}\n\\rho\\left[\\partial_{t} u_{r}\\right.&\\left.+u_{r} \\partial_{r} u_{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{r}-\\frac{u_{\\theta}^{2}}{r}+u_{z} \\partial_{z} u_{r}\\right]=-\\partial_{r} p \\ldots \\\\\n&+\\mu\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{r}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{r}-\\frac{u_{r}}{r^{2}}-\\frac{2}{r^{2}} \\partial_{\\theta} u_{\\theta}+\\partial_{z}^{2} u_{r}\\right] \\\\\n\\rho\\left[\\partial_{t} u_{\\theta}\\right.&\\left.+u_{r} \\partial_{r} u_{\\theta}+\\frac{u_{r} u_{\\theta}}{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{\\theta}+u_{z} \\partial_{z} u_{\\theta}\\right]=-\\frac{1}{r} \\partial_{\\theta} p \\ldots \\\\\n&+\\mu\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{\\theta}\\right)+\\frac{2}{r^{2}} \\partial_{\\theta} u_{r}+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{\\theta}-\\frac{u_{\\theta}}{r^{2}}+\\partial_{z}^{2} u_{\\theta}\\right] \\\\\n\\rho\\left[\\partial_{t} u_{z}\\right.&\\left.+u_{r} \\partial_{r} u_{z}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{z}+u_{z} \\partial_{z} u_{z}\\right]=-\\partial_{z} p \\ldots \\\\\n&+\\mu\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{z}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{z}+\\partial_{z}^{2} u_{z}\\right]\n\\end{aligned}\n$$\n\n#### 2.2.3 Solution\n\nBoundary conditions, no-slip walls:\n$$\n\\mathbf{V}|_{r=R} = \\mathbf{0}\n$$\nFurther assumptions:\n\n- no radial motion: $u_r = 0$\n- no spiralling motion: $u_\\theta = 0$\n- axisymmetric flow: $\\partial_\\theta\\mathbf{V}=0$\n\nAs a result, the velocity becomes unidirectional and not vary with $\\theta$:\n$$\n\\mathbf{V} = u_z(r,z)\\mathbf{\\hat{z}}\n$$\nThen the NavierStokes equations is reduced to:\n$$\n\\begin{aligned}\n\\partial_zu_z&=0 \\\\\n\\partial_rp &= \\partial_\\theta p = 0\n\\end{aligned}\n$$\nTogether with above hypotheses the governing equation become:\n$$\n\\begin{aligned}\n\\mathbf{V}=u_z{r}\\mathbf{\\hat{z}} \\\\\np = p(z)\n\\end{aligned}\n$$\nLastly, the Navier-Stokes equation in the streamwise direction reduces to:\n$$\n0 = -\\partial_zp+\\frac{\\mu}{r}\\partial_r(r\\partial_ru_z)\n$$\nNote that the derivation of the equation above w.r.t. $z$ leads to  $\\partial^2_zp=0~( \\partial_zp=Const.)$ The solution of the N-S equation above is:\n$$\n\\begin{aligned}\n&\\frac{\\partial}{\\partial r}(r\\frac{\\partial u_z}{\\partial r})=r\\frac{\\partial p}{\\mu\\partial z} \\\\\n\\Rightarrow\\quad&\n\\frac{\\partial u_z}{\\partial r}=\\frac{r}{2}\\frac{\\partial p}{\\mu\\partial z}+\\frac{k_1}{r}\\\\\n\\Rightarrow\\quad&\nu_z=\\frac{r^2}{4}\\frac{\\partial p}{\\mu\\partial z}+k_1\\ln{r} + k_2\n\\end{aligned}\n$$\nTo avoid the singularity on $r=0$, $k_1=0$, and $k_2$ is determined by the boundary condition:\n$$\n\\begin{aligned}\n&\\mathbf{V}|_{r=R} = \\mathbf{0}\\\\\n\\Rightarrow\\quad \n&u_z|_{r=R}=\\frac{R^2}{4}\\frac{\\partial p}{\\mu\\partial z} + k_2 = 0 \\\\\n\\Rightarrow\\quad \n&k_2 = -\\frac{R^2}{4}\\frac{\\partial p}{\\mu\\partial z}\n\\end{aligned}\n$$\nThe governing function of laminar pipe flow, also know as **Poiseuille flow** is therefore a quadratic law:\n$$\n\\color{purple}\nu_z=\\frac{R^2\\partial_z p}{4\\mu}\\left(\\frac{r^2}{R^2}-1\\right)\n$$\n<img src=\"Poiseuille flow.png\" alt=\"Laminar pipe flow: Poiseuille flow\" style=\"zoom:80%;\" />\n\n{% note info %}\n\nAssumptions:\n\n- Laminar flow\n- Incompressible\n- Steady\n- Homogeneous in $r$ and $\\theta$ directions\n- viscous\n\n{% endnote %}\n\n#### 2.2.4 Some characteristic quantities\n\nThe max velocity is reached at the centre of the pipe:\n$$\nu_z|_{max} = u_z(0) z=-\\frac{R^2\\partial_z p}{4\\mu}\n$$\n{% note info %}\n\nThe minus sign shows that the flow goes against the pressure gradient, from the high pressure to the low pressure regions.\n\n{% endnote %}\n\nThe average velocity can be calculated as:\n$$\n\\begin{aligned}\nu_z|_{avg} &= \\frac{1}{\\pi R^2}\\int_0^R\\left[\\frac{R^2\\partial_z p}{4\\mu}\\left(\\frac{r^2}{R^2}-1\\right)\\right]2\\pi rdr \\\\\n &= -\\frac{R^2\\partial_z p}{8\\mu} \\\\\n &=\\frac12u_z|_{max}\n\\end{aligned}\n$$\nThe flow rate:\n$$\n\\begin{aligned}\nQ &= A u_z|_{avg} \\\\\n&=-\\frac{\\pi R^4\\partial_z p}{8\\mu}\n\\end{aligned}\n$$\nIf the total pressure drop in the pipe with a length of $L$ has a value:\n$$\n\\Delta p = \\partial_zpL\n$$\nThe flow rate is therefore:\n$$\nQ = -\\frac{\\pi R^4 \\Delta p}{8\\mu L}\n$$\nAnd the wall shear stress is:\n$$\n\\begin{aligned}\n\\tau_{w} &= \\mu \\partial_r u_z|_{r = R} \\\\\n&= -\\frac{R\\Delta p}{2L}\n\\end{aligned}\n$$\nNote that $\\tau_w$ can be related with the average velocity, and therefore the flow rate:\n$$\n\\tau_w =\\frac{4\\mu u_z|_{avg}}{R}\n$$\n\n### 2.3 Other cases\n\n#### 2.3.1 Non-viscous pipe flow\n\nInviscid flows are yielded by the Euler function (ignore the body force):\n$$\n\\partial_t\\mathbf{V}+\\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V} = -\\frac{1}{\\rho}\\boldsymbol{\\nabla} p\n$$\nand the continuity function:\n$$\n\\boldsymbol{\\nabla}\\cdot\\mathbf{V} = 0\n$$\nAnd because of the inviscid condition, the boundary equation at the wall is stated as \"free-slip\", instead of the \"no-slip\" condition:\n$$\nu_r|_{r=R}=0\\qquad\\partial_ru_\\theta|_{r=R} = 0\\qquad \\partial_ru_z|_{r=R}=0\n$$\nThe incompressibility constraint simplifies into:\n$$\n\\begin{aligned}\n&\\partial_zu_z=0 \\\\\n\\Rightarrow\\quad&\\partial_z=Const.\n\\end{aligned}\n$$\n<img src=\"plug flow.png\" alt=\"Inviscid laminar pipe flow: plug flow.\" style=\"zoom:80%;\" />\n\n{% note info %}\n\nAssumptions:\n\n- Laminar flow\n- Incompressible\n- Steady\n- Homogeneous in $r$ and $\\theta$ directions\n- inviscid\n\n{% endnote %}\n\nThe maximum and average values are equal:\n$$\nu_z|_{max} = u_z|_{avg} = u_z\n$$\nand the flow rate is:\n$$\nQ = Au_z = \\pi R^2u_z\n$$\nAnd there is no friction shear stress at walls.\n\n#### 2.3.2 Channel flow\n\nChannel flow describes a three-dimensional flow confined between two parallel plates and driven similarly to pipe flow by a pressure gradient.\n\n<img src=\"Channel flow.png\" alt=\"Channel flow between two parallel plates and driven by a pressure gradient in the x direction.\" style=\"zoom:80%;\" />\n\n{% note info %}\n\nAssumptions:\n\n- Laminar flow\n- Incompressible\n- Steady\n- Homogeneous in $x$ and $z$ directions\n- viscous\n\n{% endnote %}\n\nSimilar to the Poiseuille flow, yet in the cartesian coordinate, the velocity is defined as:\n$$\n\\mathbf{V} = u_x(y)\\mathbf{\\hat{x}}\n$$\nAnd the N-S equation is reduced to:\n$$\n0 = -\\partial_xp+\\mu\\partial_y^2u_x\n$$\nwith the boundary conditions:\n$$\n\\mathbf{V}|_{y=\\pm h} = \\mathbf{0}\n$$\nThe velocity is therefore:\n$$\n\\color{purple}\nu_x = \\frac{\\partial_xph^2}{2\\mu}\\left(\\frac{y^2}{h^2}-1\\right)\n$$\nThis is also called  **plane Poiseuille flow**.\n\n#### 2.3.3 Plane Couette flow\n\nPlane Couette flow describes a three-dimensional flow confined between two parallel plates yet driven by sliding walls.\n\n<img src=\"Plane Couette flow.png\" alt=\"Plane Couette flow between two parallel plates and driven by sliding walls.\" style=\"zoom:80%;\" />\n\n{% note info %}\n\nSame assumptions are adopted as the channel flow.\n\n{% endnote %}\n\nSimilar to the channel flow, the velocity governing equation is:\n$$\n0 = \\mu\\partial_y^2u_x\n$$\nYet the boundary conditions are changed to be:\n$$\n\\begin{aligned}\n&u_x|_{y=h} = U \\\\\n&u_x|_{y=-h} = -U\n\\end{aligned}\n$$\n As the velocity function become:\n$$\n\\color{purple}\nu_x =- \\frac{ U}{h}y\n$$\n\n## 3 Viscous losses\n\n### 3.1 Pressure drop\n\n#### 3.1.1 Experimental evidence\n\nIn 1839, Hagen studied water flows in long brass pipes and hinted at the possible existence of two different regimes of viscous flows: laminar and turbulent.\nHe characterised, in particular, laminar flows through the following law:\n$$\n\\Delta p = k\\frac{LQ}{R^4}+\\mathrm{entrance~effects}\n$$\nwhere $k = Const.$, $L$ is the length of the pipe, $Q$ the flow rate and $R$ the radius of the pipe.\n\nAs he increased Q beyond a certain threshold, Hagen observed that this law broke down, and deduced the existence of a second regime. This experimental observations are easily reproduced and the results sketched in figure below.\n\n<img src=\"Pressure drop.png\" alt=\"Relationship between the pressure drop p and the average velocity V in a pipe with radius 3mm and length 3m. After White, Fluid Mechanics (2011)\" style=\"zoom:50%;\" />\n\n#### 3.1.2 Dimensional analysis\n\nWe consider a laminar flow in a horizontal pipe for which density and gravity effects are negligible. The dimensions of related quantities are:\n\n- pressure drop $\\Delta p$: $[\\Delta p] = [ML^{-1}T^{-2}]$\n- flow rate $Q$: $[Q]=[L^3T^-1]$\n- pipe length $L$: $[L]=[L]$\n- pipe radius $R$:$[R]=[L]$\n- fluid's dynamic viscosity $\\mu$: $[\\mu]=[ML^-1T^-1]$\n\nAs the pressure gradient is constant along the pipe and the flow fully characterised by the radial direction only, we can write\n$$\n\\frac{\\Delta p}{L}=\\mathcal{F}(Q, R, \\mu)\n$$\nWe note that the left-hand-side has dimension proportional to a mass M and that only the dynamic viscosity has dimension proportional to a mass. We can then divide by the dynamic viscosity to get rid of this dimension.\n$$\n\\frac{\\Delta p}{\\mu L}=\\mathcal{F}(Q, R)\n$$\nSimilarly, to get rid of the length dimension, multiply by $R$. Then divide by $R^3$.\n$$\n\\frac{\\Delta p R}{\\mu L}=\\mathcal{F}(\\frac{Q}{R^3})\n$$\nAt this stage, both the left-hand-side and the right-hand-side terms are both homogeneous to the inverse of a time. Upon dividing the one by the other, we obtain the following relationship:\n$$\n\\frac{\\Delta p R^4}{\\mu LQ}=Const.\n$$\nwhich provide the following pressure loss drop law:\n$$\n\\Delta p = C_{onst.} \\mu\\frac{ LQ}{ R^4}\n$$\nThis law is very similar to that obtained experimentally by Hagen. In particular, it shows that Hagens constant $k$ is homogeneous to a dynamic viscosity.\n\n#### 3.1.3 Theoretical answer\n\nRecall the streamwise velocity reads:\n$$\nu_z=\\frac{R^2\\partial_z p}{4\\mu}\\left(\\frac{r^2}{R^2}-1\\right)\n$$\ngiving the following flow rate:\n$$\nQ = -\\frac{\\pi R^4\\Delta p}{8\\mu L}\n$$\nAnd the $\\Delta p $ as a function of $Q,R,\\mu,L$ reads:\n$$\n\\color{purple}\n\\Delta p = \\frac{8}{\\pi}\\mu\\frac{LQ}{R^4}\n$$\n\n### 3.2 Head loss\n\n#### 3.2.1 The Bernoulli equation\n\nAs a result of the friction between the fluid and the wall, the energy and head decrease between these two sections. We take this into account by adding a term to the Bernoulli equation as:\n$$\n\\frac{p_1}{\\rho g}+\\frac{u_1^2}{2g}+z_1 = \\frac{p_2}{\\rho g}+\\frac{u_2^2}{2g}+z_2+h_f\n$$\nwhere $h_f$ is called **head loss** and accounts for the viscous dissipation. The equivalent loss of energy per unit volume is $\\rho ghf$. Relevantly, $\\frac{p}{\\rho g}$ is called **pressure head** and $\\frac{u^2}{2g}$ is called **kinetic head**.\n\n{% note info %}\n\nConditions: \n\n- Steady\n- Incompressible\n- Streamwise\n- **Viscous**.\n\n{% endnote %}\n\n#### 3.2.2 Application to pipe flow\n\n<img src=\"inclined pipe.png\" alt=\"Sketch of an inclined pipe. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" />\n\nGiven a inclined laminar pipe. The velocity of the fluid is invariant with the streamwise direction $x$, so $u_1= u_2$. We can then express the head loss:\n$$\nh_f = \\frac{\\Delta p}{\\rho g}+\\Delta z\n$$\nApply the momentum equation for the control volume shown above:\n$$\n\\Sigma F_x = \\rho\\pi R^2\\left(u_{2avg}^2-u_{1avg}^2\\right)\n$$\nThere are three forces acting on the fluid in the x direction\n\n- pressure: $\\Delta p\\pi R^2$\n- weight: $\\rho L \\pi R^2 \\sin(\\phi)g$\n- shear: $-\\tau_w2\\pi RL$\n\nAdditionally, with constant fluid velocity i.e. $u_{1avg} = u_{2avg}$, the momentum equation can be simplified as:\n$$\n\\Delta p\\pi R^2+\\rho L \\pi R^2 \\sin(\\phi)g-\\tau_w2\\pi RL=0\n$$\nas a result:\n$$\n\\frac{\\Delta p}{\\rho g}+\\Delta z = \\frac{2\\tau_wL}{\\rho gR}\n$$\nand the head loss therefore writes:\n$$\n\\color{purple}\nh_f = \\frac{2\\tau_wL}{\\rho gR} = \\frac{4\\tau_wL}{\\rho gd}\n$$\nRecall the wall shear for the Poiseuille flow, $\\tau_w =\\frac{4\\mu u_{avg}}{R}$\n$$\n\\color{purple}\nh_f =  \\frac{8\\mu  u_{avg} L}{\\rho gR^2} = \\frac{32\\mu  u_{avg} L}{\\rho gd^2}\n$$\n\n#### 3.2.3 Physical interpretation\n\nWe can experimentally observe quantities related to the Bernoulli equation. Static pressure tubes directly connected to the side of the pipe directly observe the pressure head $p/g$. When this quantity is summed with the altitude $z$ and tracked along the pipe, we obtain the **hydraulic grade line**. The use of Pitot tubes provides additional information: as they are oriented in the direction of the flow, they are sensitive to the fluids velocity and include the kinetic head $u^2/2g$. The line obtained by summing the kinetic head together with the pressure head and the altitude is called **energy grade line**.\n\nWhen viscous effects are non-negligible, the head loss can be observed as loss of pressure and therefore as a drop for both lines. This situation is depicted below:\n\n<img src=\"Physical interpretation.png\" alt=\"Physical interpretation of head loss, together with hydraulic and energy grade lines.\" style=\"zoom:48%;\" />\n\n#### 3.2.4 General formulae (Turbulent flow)\n\nThe theory above only describes the steady laminar flow, but flows are often turbelent in applications. A need for general expression of head loss arose.\n\nIn 1850, Weisbach used physical intuition to lead the way to a unifying theory. He realised that the head loss was proportional to $L/d$ and also approximately proportional to $u_{avg}^2$ experimentally for turbulent flows. He then suggested the following relationship:\n$$\n\\color{purple}\nh_f = f\\frac{L}{d}\\frac{u_{avg}^2}{2g}\n$$\nwhere f is a non-dimensional parameter called **Darcy friction factor**. Still out of physical intuition, he precised that the friction factor depend on the **Reynolds number**, the **duct shape** and the **roughness of the wall for turbulent flows**.\n\nFor **laminar flow** in a pipe:\n$$\n\\begin{aligned}\n\\frac{32 \\mu u_{a v g} L}{\\rho g d^{2}} &=f_{l a m} \\frac{L}{d} \\frac{u_{a v g}^{2}}{2 g} \\\\\n\\Rightarrow f_{l a m} &=\\frac{64 \\mu u_{a v g} L d g}{\\rho g d^{2} L u_{a v g}^{2}}, \\\\\n\\Rightarrow f_{\\text {lam }} &=\\frac{64 \\mu}{\\rho d u_{a v g}} \\\\\n\\Rightarrow \\color{purple}{f_{l a m} }& \\color{purple}{=\\frac{64}{R e_{d}}}\n\\end{aligned}\n$$\nwhere $Re_d$ denotes the Reynolds number based on the diameter of the pipe\n\nFor **turbulent flow**:\n\nNo theoretical or experimental laws, in 1939, Colebrook provided an interpolation formula of empirical data:\n$$\n\\frac{1}{f^{1 / 2}}=-2 \\log \\left(\\frac{\\epsilon / d}{3.7}+\\frac{2.51}{R e_{d} f^{1 / 2}}\\right)\n$$\nwhere $\\epsilon/d$ (**roughness height**) quantifies the relative roughness of the walls, with $\\epsilon$ being related to the size of the disturbance from a smooth wall. For a perfectly smooth pipe, $\\epsilon/d = 0$. And this value increase with the roughness of the wall.\n\nColebrooks formula is transcendental and cannot be solved by hand. Hence, in 1944, Moody plotted what is now known as the Moody chart (below) to provide directly readable data. This chart is nowadays a standard in the engineering world.\n\n<img src=\"Moody chart.png\" alt=\"The Moody chart representing the friction factor f as a function of the Reynolds number Re and the relative roughness /d of the pipe. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" />\n\n### 3.3 Entrance effects\n\n#### 3.3.1 Definition\n\nAway from the pipe, the external flow is homogeneous (therefore, not dissipative, or conservative); the flow within the pipe displays vanishing velocity at the wall due to viscosity. It is dissipative. Thus, there is a region (time if you follow the fluid) where the flow progressively accommodates to the presence of walls. This region is called entrance region and this progress is called the entrance effects, firstly observed by Hagen.\n\n<img src=\"entrance effect.png\" alt=\"Depiction of the entrance region and the accommodation of the fluid to the presence of walls. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" />\n\n#### 3.3.2 Entrance length\n\nUse dimensional analysis:\n\nThe entrance length $L_e=[L]$ is related to:\n\n- pipe diameter $d$: $[d]=[L]$\n- average fluid velocity $u_{avg}$: $u_{avg}=[LT^{-1}]$\n- fluid's density $\\rho$: $\\rho = [ML^{-3}]$\n- fluid's dynamic viscosity $\\mu$: $\\mu = [ML^{-1}T^{-1}]$\n\nAs $[L_e/d]=[1]$, combine other quantities to get a dimensionless product:\n$$\n\\begin{aligned}\nu_{avg}^a \\rho^b \\mu^c d^d &= L^{a}T^{-a}M^{b}L^{-3b}M^{c}L^{-c}T^{-c}L^d \\\\\n&= L^{a-3b-c+d}T^{-a-c}M^{b+c} = L^0T^0M^0\\\\\n\\Rightarrow \\quad \n&\\left\\{\\begin{array}{l}\na-3b-c+d=0 \\\\\n-a-c=0 \\\\\nb+c=0\n\\end{array}\\right.\\\\\n\\Rightarrow \\quad \n&a=b=d=-c\n\\end{aligned}\n$$\nAs a result, let $c=\\gamma$:\n$$\n\\left[\\frac{L_{e}}{d}\\right]=\\left[\\frac{\\rho u_{a v g} d}{\\mu}\\right]^{\\gamma}\n$$\nThe RHS is Reynolds number based on the diameter of the pipe, $Re_d$, finally:\n$$\n\\color{purple}\n\\frac{L_e}{d}= \\mathcal{F}(Re_d^\\gamma)\n$$\nthe following empirical laws shows that:\n\n- laminar flows: $\\frac{L_e}{d}\\approx0.06Re_d$\n- turbulent flows: $\\frac{L_e}{d}\\approx1.6Re_d$\n\nNote that these laws provide some interesting differences between laminar and turbulent flows: at $Re_d= 2000$, the entrance length of a laminar flow is $L_e= 120d$ while a turbulent flow at $Re_d= 10000$ will yield an entrance length of only $L_e= 16d$.\n","source":"_posts/Internal-flow-fundamentals.md","raw":"---\ntitle: Internal flow fundamentals\nauthor: Ryan LI\ntoc: true\ndeclare: true\nindex_img: /index/internal_flow.png\ntags:\n  - fluid dynamics\ndate: 2022-05-21 00:24:41\n---\n\n{% note primary %}\n\nFeeling good deriving the basics, continue to review the following content.\n\n{% endnote%}\n\n<!-- more -->\n\n## 1 Flow regimes  case study of duct flow\n\n### 1.1 Examples of duct flows\n\n#### 1.1.1 Oil extraction\n\nUpon finding a natural oil reservoir, several techniques are employed to extract the oil.\n\n1. Drilling a long hole into the Earth and placing a duct in, the oil reservoir possesses a higher pressure then the atmosphere thus the oil is pushed upwards along the duct.\n2. Steam injection, drilling a second hole to inject steam, the addition of steam increase the pressure and push the oil further upwards. The increase in temperature reduces the viscosity.\n\n#### 1.1.2 Pipeline transport\n\nTransport systems designed to bring the oil to storage or treatment sites face many challenges. Take Trans-Alaska Pipeline System (TAPS) as an example, oil extracted is substantially warmer than anything at the surface, the permafrost (frozen ground) may warm up and become unstable. To avoid this , radiators have beed placed next to the pipeline.\n\nBesides, drag-reducing agents DRA are mixed with the oil to reduce the viscous drag produced by the massive turbulent flow inside.\n\n#### 1.1.3 Biological flow\n\nThe cerebral blood flow in the cortex can be modelled through a complex assembly of ducts, mimicking the vessel network present in the brain. Experimental data coupled with numerical simulations can then provide prediction of the pressure map in the brain.Access to these results can then be used to predict the risks of blockage or damage of the vessels and thus of brain stroke.\n\n### 1.2 Reynolds number\n\nIn 1883, Osbourne Reynolds published his famous pipe flow experiment. He placed a pipe within a tank full of water. The water entered in the pipe through a converging cone to decrease the impact of entrance effects and the flow rate is controled by a valve. Aligned with the entrance of the pipe is a needle connected to a dye container. As the desired flow rate is reached, dye is injected within the pipe to trace out the fluids trajectory.\n\n<img src=\"Reynolds experiment.png\" alt=\"Photographs of pipe flow visualised using dye injection in the centerline. The Reynolds number is increased from top to bottom and the successive snapshots represent: laminar flow, transitional flow, turbulent flow, turbulent flow. After Van Dyke, An Album of Fluid Motion (1982).\" style=\"zoom:100%;\" />\n\nIn addition to making these observations, it is possible to characterise these different regimes in a simple manner, the quantities that influence the flow are:\n\n- pipe diameter $l$: $[l]=L$\n- fluid's velocity $u$: $[u]=LT^{-1}$\n- fluid's density $\\rho$: $[\\rho] = mL^{-3}$ \n- fluid's dynamic viscosity $\\mu$: $[\\mu]=mL^{-1}T^{-1}$\n\nCombine these quantities to obtain a dimensionless number called Reynolds number,\n$$\n\\color{purple}\nRe = \\frac{\\rho V L}{\\mu}\n$$\n<img src=\"3 flow regimes.png\" alt=\"Sketch of the temporal variations of the streamwise velocity at a fixed location in the pipe. From left to right: laminar, transitional and turbulent regimes. After White, Fluid Mechanics (2011).\" style=\"zoom:100%;\" />\n\nWith Reynolds number, 3 regimes of flow can be defined:\n\n- Laminar flows: $0<Re<1000$\n- Transitional flows: $1000<Re<4000$\n- Turbulent flows: $4000<Re$\n\n<img src=\"puffs.png\" alt=\"Visualisation of a puff going through a pipe and splitting. Time goes from bottom to top and the quantity represented is the streamwise vorticity, red (resp. blue) representing positive (resp. negative) values. The Reynolds number is 2300. After Avila et al., Science 333, 192 (2011).\" style=\"zoom:100%;\" />\n\nThe intermittent bursts of turbulence displayed in the transitional regime are the signature of the passage of turbulent puffs. They can be observed by direct numerical simulation, like the figure above for Re = 2300. The upstream edge of the puff is well-defined, while the downstream edge is elongated and fuzzy.\nPuffs typically evolve in two different ways: Vanishing and decaying down to the laminar state or splitting, leading to an increasingly large turbulent fraction in the flow. Puffs decay rapidly in the laminar regime and split frequently in the turbulent regime, but they remain long-lived in the transitional one.\n\nThe lifetime of a puff before decaying and splitting in pipe flow is studied as a function of Reynolds number, and the results are shown below. It is confirmed that the puffs are long-lived over a wide range of $Re$s. Importantly, there is an intersection between the decay and the splitting lifetime curves. This intersection provides a well-defined legitimate threshold between laminar and turbulent flows: $Re_c 2040$.\n\n<img src=\"puff lifetimes.png\" alt=\"Mean lifetime of a puff before decay or splitting in pipe flow as a function of the Reynolds number. After Avila et al., Science 333, 192 (2011).\" style=\"zoom:50%;\" />\n\n### 1.3 Other considerations\n\n#### 1.3.1 Newtonian/non-Newtonian fluids\n\nWater and air all follow the rule of constant viscosity, that is, the wall shear stress is $\\mu$ proportional to the normal velocity gradient (shear, strain rate):\n$$\n\\tau = \\mu\\partial_nu\n$$\nBut not all types of fluids follow this law, as seen below. \n\n- Shear thinning: ketchup, becoming less and less viscous as they are stirred. \n- Shear thickening: corn starch, getting much harder to strain as they receive more stress. \n- Mayonnaise: tooth paste, possessing a threshold stress below which they behave like solids and above which their rheological law is linear. If you hang the open container upside down, it will not flow. An additional force is needed on the container to create a flow.\n- More complicated, HerschelBulkley fluids (e.g. paint) or even time-dependent visco-elastic fluids (e.g. polymers).\n\n<img src=\"non-newtonian flow.png\" alt=\"Rheological diagram showing the shear stress  as a function of the shear rate nu for several types of fluids.\" style=\"zoom:50%;\" />\n\n#### 1.3.2 Compressibility\n\nWhen the flow speed reach the speed of sound, the fluid becomes compressible, meaning the density becomes variant in time and space. The best unidimensional quantity to describe this threshold is called Mach number:\n$$\nMa = \\frac{u}{c}\n$$\nwhere the $c$ is the speed of sound, and the flowing regimes are observed defined by $Ma$.\n\n- $0<Ma<0.3$: incompressible flows.\n- $0.3<Ma<1$: compressible subsonic flows.\n- $1<Ma$: compressible supersonic flows.\n\n## 2 Laminar flow cases\n\n### 2.1 Incompressible framework\n\n#### 2.1.1 The Navier-Stokes equation\n\nThe incompressible NavierStokes equation describes the motion of fluids under external forces. It writes:\n$$\n\\color{purple}\n\\frac{\\partial \\mathbf{V}}{\\partial t}+\\mathbf{V}\\cdot\\boldsymbol{\\nabla} \\mathbf{V} = \\mathbf{f} -\\frac{1}{\\rho}\\boldsymbol{\\nabla} p + \\nu\\boldsymbol{\\nabla}^2\\mathbf{V}\n$$\n\n> The left-hand-side of the NavierStokes equation represents inertia. It involves the rate of change of the velocity with time tu as well as advection (u  ) u. The latter term quantifies how the fluid is transported by the flow velocity. In an equation such as the heat equation, this term applies to the temperature T, reads (u  ) T and quantifies how temperature is transported by the flow velocity.\n>\n> The right-hand-side represents all the forces acting on the fluid. In addition to the external forces f that we will not take into account in this Chapter, the other terms come from the divergence of the stress tensor. They include the pressure gradient p that translates the fact that the fluid is attracted to low pressure regions and the viscous force 2u quantifying the internal friction between in the fluid.\n\n#### 2.1.2 Continuity equation\n\nRecall the mass conservation equation in the Eulerian frame of reference,\n$$\n\\frac{\\partial\\rho}{\\partial t} + \\boldsymbol{\\nabla}\\cdot(\\rho\\mathbf{V})=0\n$$\nAnd with the incompressibility consumption, \n$$\n\\color{purple}\n\\boldsymbol{\\nabla}\\cdot\\mathbf{V} = 0\n$$\n\n#### 2.1.2 Additional hypotheses\n\nIn the laminar flow regime, it is common to assume the flow as:\n\n- steady: $\\partial_t=0$\n- unidirectional: the flow is parallel the to walls\n- symmetry: the flow is further simplified using the symmetries of the geometry\n\n### 2.2 Pipe flow\n\n#### 2.2.1 Cylindrical coordinate\n\nIn cylindrical coordinate, the velocity:\n$$\n\\mathbf{V} = u_r\\mathbf{\\hat {r}}+u_\\theta\\boldsymbol{\\hat {\\theta}}+u_z\\mathbf{\\hat {z}}\n$$\nThe line element writes:\n$$\nds = dr\\mathbf{\\hat{r}} + rd\\theta\\boldsymbol{\\hat{\\theta}}+dz\\mathbf{\\hat{z}}\n$$\nThe gradient operator\n$$\n\\boldsymbol{\\nabla} = \\partial_r\\mathbf{\\hat {r}}+\\frac{1}{r}\\partial_\\theta\\boldsymbol{\\hat {\\theta}}+\\partial_z\\mathbf{\\hat {z}}\n$$\nAnd the directions change with $\\theta$, as a consequence:\n$$\n\\partial_\\theta\\mathbf{\\hat{r}} = \\boldsymbol{\\hat {\\theta}}, \\qquad \\partial_\\theta\\boldsymbol{\\hat {\\theta}} = -\\mathbf{\\hat{r}}\n$$\nSome useful equations:\n$$\n\\begin{aligned}\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} =& \\frac{1}{r}\\partial_r(ru_r)+ \\frac{1}{r}\\partial_\\theta(u_\\theta) + \\partial_z(u_z) \\\\\n(\\mathbf{V}\\cdot\\boldsymbol{\\nabla})\\mathbf{V} =&\\left(u_{r} \\partial_{r} u_{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{r}-\\frac{u_{\\theta}^{2}}{r}+u_{z} \\partial_{z} u_{r}\\right) \\hat{\\mathbf{r}} \\\\\n&+\\left(u_{r} \\partial_{r} u_{\\theta}+\\frac{u_{r} u_{\\theta}}{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{\\theta}+u_{z} \\partial_{z} u_{\\theta}\\right) \\boldsymbol{\\hat{\\theta}}\\\\\n&+\\left(u_{r} \\partial_{r} u_{z}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{z}+u_{z} \\partial_{z} u_{z}\\right) \\hat{\\mathbf{z}}\\\\\n\n\\boldsymbol{\\nabla}^2\\mathbf{V}=&\\left[\\frac{1}{r} \\partial_{r}\\right.\\left.\\left(r \\partial_{r} u_{r}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{r}-\\frac{u_{r}}{r^{2}}-\\frac{2}{r^{2}} \\partial_{\\theta} u_{\\theta}+\\partial_{z}^{2} u_{r}\\right] \\hat{\\mathbf{r}} \\\\\n&+ {\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{\\theta}\\right)+\\frac{2}{r^{2}} \\partial_{\\theta} u_{r}+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{\\theta}-\\frac{u_{\\theta}}{r^{2}}+\\partial_{z}^{2} u_{\\theta}\\right] \\boldsymbol{\\hat{\\theta} }} \\\\\n&+ {\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{z}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{z}+\\partial_{z}^{2} u_{z}\\right] \\hat{\\mathbf{z}} } \\\\\n\\end{aligned}\n$$\n\n#### 2.2.2 Governing equations\n\nContinuity equation:\n$$\n\\frac{1}{r}\\partial_r(ru_r)+ \\frac{1}{r}\\partial_\\theta(u_\\theta) + \\partial_z(u_z) = 0\n$$\nNavierStokes equation:\n$$\n\\begin{aligned}\n\\rho\\left[\\partial_{t} u_{r}\\right.&\\left.+u_{r} \\partial_{r} u_{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{r}-\\frac{u_{\\theta}^{2}}{r}+u_{z} \\partial_{z} u_{r}\\right]=-\\partial_{r} p \\ldots \\\\\n&+\\mu\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{r}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{r}-\\frac{u_{r}}{r^{2}}-\\frac{2}{r^{2}} \\partial_{\\theta} u_{\\theta}+\\partial_{z}^{2} u_{r}\\right] \\\\\n\\rho\\left[\\partial_{t} u_{\\theta}\\right.&\\left.+u_{r} \\partial_{r} u_{\\theta}+\\frac{u_{r} u_{\\theta}}{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{\\theta}+u_{z} \\partial_{z} u_{\\theta}\\right]=-\\frac{1}{r} \\partial_{\\theta} p \\ldots \\\\\n&+\\mu\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{\\theta}\\right)+\\frac{2}{r^{2}} \\partial_{\\theta} u_{r}+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{\\theta}-\\frac{u_{\\theta}}{r^{2}}+\\partial_{z}^{2} u_{\\theta}\\right] \\\\\n\\rho\\left[\\partial_{t} u_{z}\\right.&\\left.+u_{r} \\partial_{r} u_{z}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{z}+u_{z} \\partial_{z} u_{z}\\right]=-\\partial_{z} p \\ldots \\\\\n&+\\mu\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{z}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{z}+\\partial_{z}^{2} u_{z}\\right]\n\\end{aligned}\n$$\n\n#### 2.2.3 Solution\n\nBoundary conditions, no-slip walls:\n$$\n\\mathbf{V}|_{r=R} = \\mathbf{0}\n$$\nFurther assumptions:\n\n- no radial motion: $u_r = 0$\n- no spiralling motion: $u_\\theta = 0$\n- axisymmetric flow: $\\partial_\\theta\\mathbf{V}=0$\n\nAs a result, the velocity becomes unidirectional and not vary with $\\theta$:\n$$\n\\mathbf{V} = u_z(r,z)\\mathbf{\\hat{z}}\n$$\nThen the NavierStokes equations is reduced to:\n$$\n\\begin{aligned}\n\\partial_zu_z&=0 \\\\\n\\partial_rp &= \\partial_\\theta p = 0\n\\end{aligned}\n$$\nTogether with above hypotheses the governing equation become:\n$$\n\\begin{aligned}\n\\mathbf{V}=u_z{r}\\mathbf{\\hat{z}} \\\\\np = p(z)\n\\end{aligned}\n$$\nLastly, the Navier-Stokes equation in the streamwise direction reduces to:\n$$\n0 = -\\partial_zp+\\frac{\\mu}{r}\\partial_r(r\\partial_ru_z)\n$$\nNote that the derivation of the equation above w.r.t. $z$ leads to  $\\partial^2_zp=0~( \\partial_zp=Const.)$ The solution of the N-S equation above is:\n$$\n\\begin{aligned}\n&\\frac{\\partial}{\\partial r}(r\\frac{\\partial u_z}{\\partial r})=r\\frac{\\partial p}{\\mu\\partial z} \\\\\n\\Rightarrow\\quad&\n\\frac{\\partial u_z}{\\partial r}=\\frac{r}{2}\\frac{\\partial p}{\\mu\\partial z}+\\frac{k_1}{r}\\\\\n\\Rightarrow\\quad&\nu_z=\\frac{r^2}{4}\\frac{\\partial p}{\\mu\\partial z}+k_1\\ln{r} + k_2\n\\end{aligned}\n$$\nTo avoid the singularity on $r=0$, $k_1=0$, and $k_2$ is determined by the boundary condition:\n$$\n\\begin{aligned}\n&\\mathbf{V}|_{r=R} = \\mathbf{0}\\\\\n\\Rightarrow\\quad \n&u_z|_{r=R}=\\frac{R^2}{4}\\frac{\\partial p}{\\mu\\partial z} + k_2 = 0 \\\\\n\\Rightarrow\\quad \n&k_2 = -\\frac{R^2}{4}\\frac{\\partial p}{\\mu\\partial z}\n\\end{aligned}\n$$\nThe governing function of laminar pipe flow, also know as **Poiseuille flow** is therefore a quadratic law:\n$$\n\\color{purple}\nu_z=\\frac{R^2\\partial_z p}{4\\mu}\\left(\\frac{r^2}{R^2}-1\\right)\n$$\n<img src=\"Poiseuille flow.png\" alt=\"Laminar pipe flow: Poiseuille flow\" style=\"zoom:80%;\" />\n\n{% note info %}\n\nAssumptions:\n\n- Laminar flow\n- Incompressible\n- Steady\n- Homogeneous in $r$ and $\\theta$ directions\n- viscous\n\n{% endnote %}\n\n#### 2.2.4 Some characteristic quantities\n\nThe max velocity is reached at the centre of the pipe:\n$$\nu_z|_{max} = u_z(0) z=-\\frac{R^2\\partial_z p}{4\\mu}\n$$\n{% note info %}\n\nThe minus sign shows that the flow goes against the pressure gradient, from the high pressure to the low pressure regions.\n\n{% endnote %}\n\nThe average velocity can be calculated as:\n$$\n\\begin{aligned}\nu_z|_{avg} &= \\frac{1}{\\pi R^2}\\int_0^R\\left[\\frac{R^2\\partial_z p}{4\\mu}\\left(\\frac{r^2}{R^2}-1\\right)\\right]2\\pi rdr \\\\\n &= -\\frac{R^2\\partial_z p}{8\\mu} \\\\\n &=\\frac12u_z|_{max}\n\\end{aligned}\n$$\nThe flow rate:\n$$\n\\begin{aligned}\nQ &= A u_z|_{avg} \\\\\n&=-\\frac{\\pi R^4\\partial_z p}{8\\mu}\n\\end{aligned}\n$$\nIf the total pressure drop in the pipe with a length of $L$ has a value:\n$$\n\\Delta p = \\partial_zpL\n$$\nThe flow rate is therefore:\n$$\nQ = -\\frac{\\pi R^4 \\Delta p}{8\\mu L}\n$$\nAnd the wall shear stress is:\n$$\n\\begin{aligned}\n\\tau_{w} &= \\mu \\partial_r u_z|_{r = R} \\\\\n&= -\\frac{R\\Delta p}{2L}\n\\end{aligned}\n$$\nNote that $\\tau_w$ can be related with the average velocity, and therefore the flow rate:\n$$\n\\tau_w =\\frac{4\\mu u_z|_{avg}}{R}\n$$\n\n### 2.3 Other cases\n\n#### 2.3.1 Non-viscous pipe flow\n\nInviscid flows are yielded by the Euler function (ignore the body force):\n$$\n\\partial_t\\mathbf{V}+\\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V} = -\\frac{1}{\\rho}\\boldsymbol{\\nabla} p\n$$\nand the continuity function:\n$$\n\\boldsymbol{\\nabla}\\cdot\\mathbf{V} = 0\n$$\nAnd because of the inviscid condition, the boundary equation at the wall is stated as \"free-slip\", instead of the \"no-slip\" condition:\n$$\nu_r|_{r=R}=0\\qquad\\partial_ru_\\theta|_{r=R} = 0\\qquad \\partial_ru_z|_{r=R}=0\n$$\nThe incompressibility constraint simplifies into:\n$$\n\\begin{aligned}\n&\\partial_zu_z=0 \\\\\n\\Rightarrow\\quad&\\partial_z=Const.\n\\end{aligned}\n$$\n<img src=\"plug flow.png\" alt=\"Inviscid laminar pipe flow: plug flow.\" style=\"zoom:80%;\" />\n\n{% note info %}\n\nAssumptions:\n\n- Laminar flow\n- Incompressible\n- Steady\n- Homogeneous in $r$ and $\\theta$ directions\n- inviscid\n\n{% endnote %}\n\nThe maximum and average values are equal:\n$$\nu_z|_{max} = u_z|_{avg} = u_z\n$$\nand the flow rate is:\n$$\nQ = Au_z = \\pi R^2u_z\n$$\nAnd there is no friction shear stress at walls.\n\n#### 2.3.2 Channel flow\n\nChannel flow describes a three-dimensional flow confined between two parallel plates and driven similarly to pipe flow by a pressure gradient.\n\n<img src=\"Channel flow.png\" alt=\"Channel flow between two parallel plates and driven by a pressure gradient in the x direction.\" style=\"zoom:80%;\" />\n\n{% note info %}\n\nAssumptions:\n\n- Laminar flow\n- Incompressible\n- Steady\n- Homogeneous in $x$ and $z$ directions\n- viscous\n\n{% endnote %}\n\nSimilar to the Poiseuille flow, yet in the cartesian coordinate, the velocity is defined as:\n$$\n\\mathbf{V} = u_x(y)\\mathbf{\\hat{x}}\n$$\nAnd the N-S equation is reduced to:\n$$\n0 = -\\partial_xp+\\mu\\partial_y^2u_x\n$$\nwith the boundary conditions:\n$$\n\\mathbf{V}|_{y=\\pm h} = \\mathbf{0}\n$$\nThe velocity is therefore:\n$$\n\\color{purple}\nu_x = \\frac{\\partial_xph^2}{2\\mu}\\left(\\frac{y^2}{h^2}-1\\right)\n$$\nThis is also called  **plane Poiseuille flow**.\n\n#### 2.3.3 Plane Couette flow\n\nPlane Couette flow describes a three-dimensional flow confined between two parallel plates yet driven by sliding walls.\n\n<img src=\"Plane Couette flow.png\" alt=\"Plane Couette flow between two parallel plates and driven by sliding walls.\" style=\"zoom:80%;\" />\n\n{% note info %}\n\nSame assumptions are adopted as the channel flow.\n\n{% endnote %}\n\nSimilar to the channel flow, the velocity governing equation is:\n$$\n0 = \\mu\\partial_y^2u_x\n$$\nYet the boundary conditions are changed to be:\n$$\n\\begin{aligned}\n&u_x|_{y=h} = U \\\\\n&u_x|_{y=-h} = -U\n\\end{aligned}\n$$\n As the velocity function become:\n$$\n\\color{purple}\nu_x =- \\frac{ U}{h}y\n$$\n\n## 3 Viscous losses\n\n### 3.1 Pressure drop\n\n#### 3.1.1 Experimental evidence\n\nIn 1839, Hagen studied water flows in long brass pipes and hinted at the possible existence of two different regimes of viscous flows: laminar and turbulent.\nHe characterised, in particular, laminar flows through the following law:\n$$\n\\Delta p = k\\frac{LQ}{R^4}+\\mathrm{entrance~effects}\n$$\nwhere $k = Const.$, $L$ is the length of the pipe, $Q$ the flow rate and $R$ the radius of the pipe.\n\nAs he increased Q beyond a certain threshold, Hagen observed that this law broke down, and deduced the existence of a second regime. This experimental observations are easily reproduced and the results sketched in figure below.\n\n<img src=\"Pressure drop.png\" alt=\"Relationship between the pressure drop p and the average velocity V in a pipe with radius 3mm and length 3m. After White, Fluid Mechanics (2011)\" style=\"zoom:50%;\" />\n\n#### 3.1.2 Dimensional analysis\n\nWe consider a laminar flow in a horizontal pipe for which density and gravity effects are negligible. The dimensions of related quantities are:\n\n- pressure drop $\\Delta p$: $[\\Delta p] = [ML^{-1}T^{-2}]$\n- flow rate $Q$: $[Q]=[L^3T^-1]$\n- pipe length $L$: $[L]=[L]$\n- pipe radius $R$:$[R]=[L]$\n- fluid's dynamic viscosity $\\mu$: $[\\mu]=[ML^-1T^-1]$\n\nAs the pressure gradient is constant along the pipe and the flow fully characterised by the radial direction only, we can write\n$$\n\\frac{\\Delta p}{L}=\\mathcal{F}(Q, R, \\mu)\n$$\nWe note that the left-hand-side has dimension proportional to a mass M and that only the dynamic viscosity has dimension proportional to a mass. We can then divide by the dynamic viscosity to get rid of this dimension.\n$$\n\\frac{\\Delta p}{\\mu L}=\\mathcal{F}(Q, R)\n$$\nSimilarly, to get rid of the length dimension, multiply by $R$. Then divide by $R^3$.\n$$\n\\frac{\\Delta p R}{\\mu L}=\\mathcal{F}(\\frac{Q}{R^3})\n$$\nAt this stage, both the left-hand-side and the right-hand-side terms are both homogeneous to the inverse of a time. Upon dividing the one by the other, we obtain the following relationship:\n$$\n\\frac{\\Delta p R^4}{\\mu LQ}=Const.\n$$\nwhich provide the following pressure loss drop law:\n$$\n\\Delta p = C_{onst.} \\mu\\frac{ LQ}{ R^4}\n$$\nThis law is very similar to that obtained experimentally by Hagen. In particular, it shows that Hagens constant $k$ is homogeneous to a dynamic viscosity.\n\n#### 3.1.3 Theoretical answer\n\nRecall the streamwise velocity reads:\n$$\nu_z=\\frac{R^2\\partial_z p}{4\\mu}\\left(\\frac{r^2}{R^2}-1\\right)\n$$\ngiving the following flow rate:\n$$\nQ = -\\frac{\\pi R^4\\Delta p}{8\\mu L}\n$$\nAnd the $\\Delta p $ as a function of $Q,R,\\mu,L$ reads:\n$$\n\\color{purple}\n\\Delta p = \\frac{8}{\\pi}\\mu\\frac{LQ}{R^4}\n$$\n\n### 3.2 Head loss\n\n#### 3.2.1 The Bernoulli equation\n\nAs a result of the friction between the fluid and the wall, the energy and head decrease between these two sections. We take this into account by adding a term to the Bernoulli equation as:\n$$\n\\frac{p_1}{\\rho g}+\\frac{u_1^2}{2g}+z_1 = \\frac{p_2}{\\rho g}+\\frac{u_2^2}{2g}+z_2+h_f\n$$\nwhere $h_f$ is called **head loss** and accounts for the viscous dissipation. The equivalent loss of energy per unit volume is $\\rho ghf$. Relevantly, $\\frac{p}{\\rho g}$ is called **pressure head** and $\\frac{u^2}{2g}$ is called **kinetic head**.\n\n{% note info %}\n\nConditions: \n\n- Steady\n- Incompressible\n- Streamwise\n- **Viscous**.\n\n{% endnote %}\n\n#### 3.2.2 Application to pipe flow\n\n<img src=\"inclined pipe.png\" alt=\"Sketch of an inclined pipe. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" />\n\nGiven a inclined laminar pipe. The velocity of the fluid is invariant with the streamwise direction $x$, so $u_1= u_2$. We can then express the head loss:\n$$\nh_f = \\frac{\\Delta p}{\\rho g}+\\Delta z\n$$\nApply the momentum equation for the control volume shown above:\n$$\n\\Sigma F_x = \\rho\\pi R^2\\left(u_{2avg}^2-u_{1avg}^2\\right)\n$$\nThere are three forces acting on the fluid in the x direction\n\n- pressure: $\\Delta p\\pi R^2$\n- weight: $\\rho L \\pi R^2 \\sin(\\phi)g$\n- shear: $-\\tau_w2\\pi RL$\n\nAdditionally, with constant fluid velocity i.e. $u_{1avg} = u_{2avg}$, the momentum equation can be simplified as:\n$$\n\\Delta p\\pi R^2+\\rho L \\pi R^2 \\sin(\\phi)g-\\tau_w2\\pi RL=0\n$$\nas a result:\n$$\n\\frac{\\Delta p}{\\rho g}+\\Delta z = \\frac{2\\tau_wL}{\\rho gR}\n$$\nand the head loss therefore writes:\n$$\n\\color{purple}\nh_f = \\frac{2\\tau_wL}{\\rho gR} = \\frac{4\\tau_wL}{\\rho gd}\n$$\nRecall the wall shear for the Poiseuille flow, $\\tau_w =\\frac{4\\mu u_{avg}}{R}$\n$$\n\\color{purple}\nh_f =  \\frac{8\\mu  u_{avg} L}{\\rho gR^2} = \\frac{32\\mu  u_{avg} L}{\\rho gd^2}\n$$\n\n#### 3.2.3 Physical interpretation\n\nWe can experimentally observe quantities related to the Bernoulli equation. Static pressure tubes directly connected to the side of the pipe directly observe the pressure head $p/g$. When this quantity is summed with the altitude $z$ and tracked along the pipe, we obtain the **hydraulic grade line**. The use of Pitot tubes provides additional information: as they are oriented in the direction of the flow, they are sensitive to the fluids velocity and include the kinetic head $u^2/2g$. The line obtained by summing the kinetic head together with the pressure head and the altitude is called **energy grade line**.\n\nWhen viscous effects are non-negligible, the head loss can be observed as loss of pressure and therefore as a drop for both lines. This situation is depicted below:\n\n<img src=\"Physical interpretation.png\" alt=\"Physical interpretation of head loss, together with hydraulic and energy grade lines.\" style=\"zoom:48%;\" />\n\n#### 3.2.4 General formulae (Turbulent flow)\n\nThe theory above only describes the steady laminar flow, but flows are often turbelent in applications. A need for general expression of head loss arose.\n\nIn 1850, Weisbach used physical intuition to lead the way to a unifying theory. He realised that the head loss was proportional to $L/d$ and also approximately proportional to $u_{avg}^2$ experimentally for turbulent flows. He then suggested the following relationship:\n$$\n\\color{purple}\nh_f = f\\frac{L}{d}\\frac{u_{avg}^2}{2g}\n$$\nwhere f is a non-dimensional parameter called **Darcy friction factor**. Still out of physical intuition, he precised that the friction factor depend on the **Reynolds number**, the **duct shape** and the **roughness of the wall for turbulent flows**.\n\nFor **laminar flow** in a pipe:\n$$\n\\begin{aligned}\n\\frac{32 \\mu u_{a v g} L}{\\rho g d^{2}} &=f_{l a m} \\frac{L}{d} \\frac{u_{a v g}^{2}}{2 g} \\\\\n\\Rightarrow f_{l a m} &=\\frac{64 \\mu u_{a v g} L d g}{\\rho g d^{2} L u_{a v g}^{2}}, \\\\\n\\Rightarrow f_{\\text {lam }} &=\\frac{64 \\mu}{\\rho d u_{a v g}} \\\\\n\\Rightarrow \\color{purple}{f_{l a m} }& \\color{purple}{=\\frac{64}{R e_{d}}}\n\\end{aligned}\n$$\nwhere $Re_d$ denotes the Reynolds number based on the diameter of the pipe\n\nFor **turbulent flow**:\n\nNo theoretical or experimental laws, in 1939, Colebrook provided an interpolation formula of empirical data:\n$$\n\\frac{1}{f^{1 / 2}}=-2 \\log \\left(\\frac{\\epsilon / d}{3.7}+\\frac{2.51}{R e_{d} f^{1 / 2}}\\right)\n$$\nwhere $\\epsilon/d$ (**roughness height**) quantifies the relative roughness of the walls, with $\\epsilon$ being related to the size of the disturbance from a smooth wall. For a perfectly smooth pipe, $\\epsilon/d = 0$. And this value increase with the roughness of the wall.\n\nColebrooks formula is transcendental and cannot be solved by hand. Hence, in 1944, Moody plotted what is now known as the Moody chart (below) to provide directly readable data. This chart is nowadays a standard in the engineering world.\n\n<img src=\"Moody chart.png\" alt=\"The Moody chart representing the friction factor f as a function of the Reynolds number Re and the relative roughness /d of the pipe. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" />\n\n### 3.3 Entrance effects\n\n#### 3.3.1 Definition\n\nAway from the pipe, the external flow is homogeneous (therefore, not dissipative, or conservative); the flow within the pipe displays vanishing velocity at the wall due to viscosity. It is dissipative. Thus, there is a region (time if you follow the fluid) where the flow progressively accommodates to the presence of walls. This region is called entrance region and this progress is called the entrance effects, firstly observed by Hagen.\n\n<img src=\"entrance effect.png\" alt=\"Depiction of the entrance region and the accommodation of the fluid to the presence of walls. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" />\n\n#### 3.3.2 Entrance length\n\nUse dimensional analysis:\n\nThe entrance length $L_e=[L]$ is related to:\n\n- pipe diameter $d$: $[d]=[L]$\n- average fluid velocity $u_{avg}$: $u_{avg}=[LT^{-1}]$\n- fluid's density $\\rho$: $\\rho = [ML^{-3}]$\n- fluid's dynamic viscosity $\\mu$: $\\mu = [ML^{-1}T^{-1}]$\n\nAs $[L_e/d]=[1]$, combine other quantities to get a dimensionless product:\n$$\n\\begin{aligned}\nu_{avg}^a \\rho^b \\mu^c d^d &= L^{a}T^{-a}M^{b}L^{-3b}M^{c}L^{-c}T^{-c}L^d \\\\\n&= L^{a-3b-c+d}T^{-a-c}M^{b+c} = L^0T^0M^0\\\\\n\\Rightarrow \\quad \n&\\left\\{\\begin{array}{l}\na-3b-c+d=0 \\\\\n-a-c=0 \\\\\nb+c=0\n\\end{array}\\right.\\\\\n\\Rightarrow \\quad \n&a=b=d=-c\n\\end{aligned}\n$$\nAs a result, let $c=\\gamma$:\n$$\n\\left[\\frac{L_{e}}{d}\\right]=\\left[\\frac{\\rho u_{a v g} d}{\\mu}\\right]^{\\gamma}\n$$\nThe RHS is Reynolds number based on the diameter of the pipe, $Re_d$, finally:\n$$\n\\color{purple}\n\\frac{L_e}{d}= \\mathcal{F}(Re_d^\\gamma)\n$$\nthe following empirical laws shows that:\n\n- laminar flows: $\\frac{L_e}{d}\\approx0.06Re_d$\n- turbulent flows: $\\frac{L_e}{d}\\approx1.6Re_d$\n\nNote that these laws provide some interesting differences between laminar and turbulent flows: at $Re_d= 2000$, the entrance length of a laminar flow is $L_e= 120d$ while a turbulent flow at $Re_d= 10000$ will yield an entrance length of only $L_e= 16d$.\n","slug":"Internal-flow-fundamentals","published":1,"updated":"2022-05-28T02:55:29.630Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz20000cl8yb1xite856","content":"<div class=\"note note-primary\">\n            <p>Feeling good deriving the basics, continue to review the following content.</p>\n          </div>\n<span id=\"more\"></span>\n<h2 id=\"flow-regimes-case-study-of-duct-flow\">1 Flow regimes  case study of duct flow</h2>\n<h3 id=\"examples-of-duct-flows\">1.1 Examples of duct flows</h3>\n<h4 id=\"oil-extraction\">1.1.1 Oil extraction</h4>\n<p>Upon finding a natural oil reservoir, several techniques are employed to extract the oil.</p>\n<ol type=\"1\">\n<li>Drilling a long hole into the Earth and placing a duct in, the oil reservoir possesses a higher pressure then the atmosphere thus the oil is pushed upwards along the duct.</li>\n<li>Steam injection, drilling a second hole to inject steam, the addition of steam increase the pressure and push the oil further upwards. The increase in temperature reduces the viscosity.</li>\n</ol>\n<h4 id=\"pipeline-transport\">1.1.2 Pipeline transport</h4>\n<p>Transport systems designed to bring the oil to storage or treatment sites face many challenges. Take Trans-Alaska Pipeline System (TAPS) as an example, oil extracted is substantially warmer than anything at the surface, the permafrost (frozen ground) may warm up and become unstable. To avoid this , radiators have beed placed next to the pipeline.</p>\n<p>Besides, drag-reducing agents DRA are mixed with the oil to reduce the viscous drag produced by the massive turbulent flow inside.</p>\n<h4 id=\"biological-flow\">1.1.3 Biological flow</h4>\n<p>The cerebral blood flow in the cortex can be modelled through a complex assembly of ducts, mimicking the vessel network present in the brain. Experimental data coupled with numerical simulations can then provide prediction of the pressure map in the brain.Access to these results can then be used to predict the risks of blockage or damage of the vessels and thus of brain stroke.</p>\n<h3 id=\"reynolds-number\">1.2 Reynolds number</h3>\n<p>In 1883, Osbourne Reynolds published his famous pipe flow experiment. He placed a pipe within a tank full of water. The water entered in the pipe through a converging cone to decrease the impact of entrance effects and the flow rate is controled by a valve. Aligned with the entrance of the pipe is a needle connected to a dye container. As the desired flow rate is reached, dye is injected within the pipe to trace out the fluids trajectory.</p>\n<p><img src=\"Reynolds experiment.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Photographs of pipe flow visualised using dye injection in the centerline. The Reynolds number is increased from top to bottom and the successive snapshots represent: laminar flow, transitional flow, turbulent flow, turbulent flow. After Van Dyke, An Album of Fluid Motion (1982).\" style=\"zoom:100%;\" /></p>\n<p>In addition to making these observations, it is possible to characterise these different regimes in a simple manner, the quantities that influence the flow are:</p>\n<ul>\n<li>pipe diameter <span class=\"math inline\">\\(l\\)</span>: <span class=\"math inline\">\\([l]=L\\)</span></li>\n<li>fluid's velocity <span class=\"math inline\">\\(u\\)</span>: <span class=\"math inline\">\\([u]=LT^{-1}\\)</span></li>\n<li>fluid's density <span class=\"math inline\">\\(\\rho\\)</span>: <span class=\"math inline\">\\([\\rho] = mL^{-3}\\)</span></li>\n<li>fluid's dynamic viscosity <span class=\"math inline\">\\(\\mu\\)</span>: <span class=\"math inline\">\\([\\mu]=mL^{-1}T^{-1}\\)</span></li>\n</ul>\n<p>Combine these quantities to obtain a dimensionless number called Reynolds number, <span class=\"math display\">\\[\n\\color{purple}\nRe = \\frac{\\rho V L}{\\mu}\n\\]</span> <img src=\"3 flow regimes.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Sketch of the temporal variations of the streamwise velocity at a fixed location in the pipe. From left to right: laminar, transitional and turbulent regimes. After White, Fluid Mechanics (2011).\" style=\"zoom:100%;\" /></p>\n<p>With Reynolds number, 3 regimes of flow can be defined:</p>\n<ul>\n<li>Laminar flows: <span class=\"math inline\">\\(0&lt;Re&lt;1000\\)</span></li>\n<li>Transitional flows: <span class=\"math inline\">\\(1000&lt;Re&lt;4000\\)</span></li>\n<li>Turbulent flows: <span class=\"math inline\">\\(4000&lt;Re\\)</span></li>\n</ul>\n<p><img src=\"puffs.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Visualisation of a puff going through a pipe and splitting. Time goes from bottom to top and the quantity represented is the streamwise vorticity, red (resp. blue) representing positive (resp. negative) values. The Reynolds number is 2300. After Avila et al., Science 333, 192 (2011).\" style=\"zoom:100%;\" /></p>\n<p>The intermittent bursts of turbulence displayed in the transitional regime are the signature of the passage of turbulent puffs. They can be observed by direct numerical simulation, like the figure above for Re = 2300. The upstream edge of the puff is well-defined, while the downstream edge is elongated and fuzzy. Puffs typically evolve in two different ways: Vanishing and decaying down to the laminar state or splitting, leading to an increasingly large turbulent fraction in the flow. Puffs decay rapidly in the laminar regime and split frequently in the turbulent regime, but they remain long-lived in the transitional one.</p>\n<p>The lifetime of a puff before decaying and splitting in pipe flow is studied as a function of Reynolds number, and the results are shown below. It is confirmed that the puffs are long-lived over a wide range of <span class=\"math inline\">\\(Re\\)</span>s. Importantly, there is an intersection between the decay and the splitting lifetime curves. This intersection provides a well-defined legitimate threshold between laminar and turbulent flows: <span class=\"math inline\">\\(Re_c 2040\\)</span>.</p>\n<p><img src=\"puff lifetimes.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Mean lifetime of a puff before decay or splitting in pipe flow as a function of the Reynolds number. After Avila et al., Science 333, 192 (2011).\" style=\"zoom:50%;\" /></p>\n<h3 id=\"other-considerations\">1.3 Other considerations</h3>\n<h4 id=\"newtoniannon-newtonian-fluids\">1.3.1 Newtonian/non-Newtonian fluids</h4>\n<p>Water and air all follow the rule of constant viscosity, that is, the wall shear stress is <span class=\"math inline\">\\(\\mu\\)</span> proportional to the normal velocity gradient (shear, strain rate): <span class=\"math display\">\\[\n\\tau = \\mu\\partial_nu\n\\]</span> But not all types of fluids follow this law, as seen below.</p>\n<ul>\n<li>Shear thinning: ketchup, becoming less and less viscous as they are stirred.</li>\n<li>Shear thickening: corn starch, getting much harder to strain as they receive more stress.</li>\n<li>Mayonnaise: tooth paste, possessing a threshold stress below which they behave like solids and above which their rheological law is linear. If you hang the open container upside down, it will not flow. An additional force is needed on the container to create a flow.</li>\n<li>More complicated, HerschelBulkley fluids (e.g. paint) or even time-dependent visco-elastic fluids (e.g. polymers).</li>\n</ul>\n<p><img src=\"non-newtonian flow.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Rheological diagram showing the shear stress  as a function of the shear rate nu for several types of fluids.\" style=\"zoom:50%;\" /></p>\n<h4 id=\"compressibility\">1.3.2 Compressibility</h4>\n<p>When the flow speed reach the speed of sound, the fluid becomes compressible, meaning the density becomes variant in time and space. The best unidimensional quantity to describe this threshold is called Mach number: <span class=\"math display\">\\[\nMa = \\frac{u}{c}\n\\]</span> where the <span class=\"math inline\">\\(c\\)</span> is the speed of sound, and the flowing regimes are observed defined by <span class=\"math inline\">\\(Ma\\)</span>.</p>\n<ul>\n<li><span class=\"math inline\">\\(0&lt;Ma&lt;0.3\\)</span>: incompressible flows.</li>\n<li><span class=\"math inline\">\\(0.3&lt;Ma&lt;1\\)</span>: compressible subsonic flows.</li>\n<li><span class=\"math inline\">\\(1&lt;Ma\\)</span>: compressible supersonic flows.</li>\n</ul>\n<h2 id=\"laminar-flow-cases\">2 Laminar flow cases</h2>\n<h3 id=\"incompressible-framework\">2.1 Incompressible framework</h3>\n<h4 id=\"the-navier-stokes-equation\">2.1.1 The Navier-Stokes equation</h4>\n<p>The incompressible NavierStokes equation describes the motion of fluids under external forces. It writes: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial \\mathbf{V}}{\\partial t}+\\mathbf{V}\\cdot\\boldsymbol{\\nabla} \\mathbf{V} = \\mathbf{f} -\\frac{1}{\\rho}\\boldsymbol{\\nabla} p + \\nu\\boldsymbol{\\nabla}^2\\mathbf{V}\n\\]</span></p>\n<blockquote>\n<p>The left-hand-side of the NavierStokes equation represents inertia. It involves the rate of change of the velocity with time tu as well as advection (u  ) u. The latter term quantifies how the fluid is transported by the flow velocity. In an equation such as the heat equation, this term applies to the temperature T, reads (u  ) T and quantifies how temperature is transported by the flow velocity.</p>\n<p>The right-hand-side represents all the forces acting on the fluid. In addition to the external forces f that we will not take into account in this Chapter, the other terms come from the divergence of the stress tensor. They include the pressure gradient p that translates the fact that the fluid is attracted to low pressure regions and the viscous force 2u quantifying the internal friction between in the fluid.</p>\n</blockquote>\n<h4 id=\"continuity-equation\">2.1.2 Continuity equation</h4>\n<p>Recall the mass conservation equation in the Eulerian frame of reference, <span class=\"math display\">\\[\n\\frac{\\partial\\rho}{\\partial t} + \\boldsymbol{\\nabla}\\cdot(\\rho\\mathbf{V})=0\n\\]</span> And with the incompressibility consumption, <span class=\"math display\">\\[\n\\color{purple}\n\\boldsymbol{\\nabla}\\cdot\\mathbf{V} = 0\n\\]</span></p>\n<h4 id=\"additional-hypotheses\">2.1.2 Additional hypotheses</h4>\n<p>In the laminar flow regime, it is common to assume the flow as:</p>\n<ul>\n<li>steady: <span class=\"math inline\">\\(\\partial_t=0\\)</span></li>\n<li>unidirectional: the flow is parallel the to walls</li>\n<li>symmetry: the flow is further simplified using the symmetries of the geometry</li>\n</ul>\n<h3 id=\"pipe-flow\">2.2 Pipe flow</h3>\n<h4 id=\"cylindrical-coordinate\">2.2.1 Cylindrical coordinate</h4>\nIn cylindrical coordinate, the velocity: <span class=\"math display\">\\[\n\\mathbf{V} = u_r\\mathbf{\\hat {r}}+u_\\theta\\boldsymbol{\\hat {\\theta}}+u_z\\mathbf{\\hat {z}}\n\\]</span> The line element writes: <span class=\"math display\">\\[\nds = dr\\mathbf{\\hat{r}} + rd\\theta\\boldsymbol{\\hat{\\theta}}+dz\\mathbf{\\hat{z}}\n\\]</span> The gradient operator <span class=\"math display\">\\[\n\\boldsymbol{\\nabla} = \\partial_r\\mathbf{\\hat {r}}+\\frac{1}{r}\\partial_\\theta\\boldsymbol{\\hat {\\theta}}+\\partial_z\\mathbf{\\hat {z}}\n\\]</span> And the directions change with <span class=\"math inline\">\\(\\theta\\)</span>, as a consequence: <span class=\"math display\">\\[\n\\partial_\\theta\\mathbf{\\hat{r}} = \\boldsymbol{\\hat {\\theta}}, \\qquad \\partial_\\theta\\boldsymbol{\\hat {\\theta}} = -\\mathbf{\\hat{r}}\n\\]</span> Some useful equations: $$\n<span class=\"math display\">\\[\\begin{aligned}\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} =&amp; \\frac{1}{r}\\partial_r(ru_r)+ \\frac{1}{r}\\partial_\\theta(u_\\theta) + \\partial_z(u_z) \\\\\n(\\mathbf{V}\\cdot\\boldsymbol{\\nabla})\\mathbf{V} =&amp;\\left(u_{r} \\partial_{r} u_{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{r}-\\frac{u_{\\theta}^{2}}{r}+u_{z} \\partial_{z} u_{r}\\right) \\hat{\\mathbf{r}} \\\\\n&amp;+\\left(u_{r} \\partial_{r} u_{\\theta}+\\frac{u_{r} u_{\\theta}}{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{\\theta}+u_{z} \\partial_{z} u_{\\theta}\\right) \\boldsymbol{\\hat{\\theta}}\\\\\n&amp;+\\left(u_{r} \\partial_{r} u_{z}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{z}+u_{z} \\partial_{z} u_{z}\\right) \\hat{\\mathbf{z}}\\\\\n\n\\boldsymbol{\\nabla}^2\\mathbf{V}=&amp;\\left[\\frac{1}{r} \\partial_{r}\\right.\\left.\\left(r \\partial_{r} u_{r}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{r}-\\frac{u_{r}}{r^{2}}-\\frac{2}{r^{2}} \\partial_{\\theta} u_{\\theta}+\\partial_{z}^{2} u_{r}\\right] \\hat{\\mathbf{r}} \\\\\n&amp;+ {\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{\\theta}\\right)+\\frac{2}{r^{2}} \\partial_{\\theta} u_{r}+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{\\theta}-\\frac{u_{\\theta}}{r^{2}}+\\partial_{z}^{2} u_{\\theta}\\right] \\boldsymbol{\\hat{\\theta} }} \\\\\n&amp;+ {\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{z}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{z}+\\partial_{z}^{2} u_{z}\\right] \\hat{\\mathbf{z}} } \\\\\n\\end{aligned}\\]</span>\n<p>$$</p>\n<h4 id=\"governing-equations\">2.2.2 Governing equations</h4>\n<p>Continuity equation: <span class=\"math display\">\\[\n\\frac{1}{r}\\partial_r(ru_r)+ \\frac{1}{r}\\partial_\\theta(u_\\theta) + \\partial_z(u_z) = 0\n\\]</span> NavierStokes equation: <span class=\"math display\">\\[\n\\begin{aligned}\n\\rho\\left[\\partial_{t} u_{r}\\right.&amp;\\left.+u_{r} \\partial_{r} u_{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{r}-\\frac{u_{\\theta}^{2}}{r}+u_{z} \\partial_{z} u_{r}\\right]=-\\partial_{r} p \\ldots \\\\\n&amp;+\\mu\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{r}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{r}-\\frac{u_{r}}{r^{2}}-\\frac{2}{r^{2}} \\partial_{\\theta} u_{\\theta}+\\partial_{z}^{2} u_{r}\\right] \\\\\n\\rho\\left[\\partial_{t} u_{\\theta}\\right.&amp;\\left.+u_{r} \\partial_{r} u_{\\theta}+\\frac{u_{r} u_{\\theta}}{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{\\theta}+u_{z} \\partial_{z} u_{\\theta}\\right]=-\\frac{1}{r} \\partial_{\\theta} p \\ldots \\\\\n&amp;+\\mu\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{\\theta}\\right)+\\frac{2}{r^{2}} \\partial_{\\theta} u_{r}+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{\\theta}-\\frac{u_{\\theta}}{r^{2}}+\\partial_{z}^{2} u_{\\theta}\\right] \\\\\n\\rho\\left[\\partial_{t} u_{z}\\right.&amp;\\left.+u_{r} \\partial_{r} u_{z}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{z}+u_{z} \\partial_{z} u_{z}\\right]=-\\partial_{z} p \\ldots \\\\\n&amp;+\\mu\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{z}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{z}+\\partial_{z}^{2} u_{z}\\right]\n\\end{aligned}\n\\]</span></p>\n<h4 id=\"solution\">2.2.3 Solution</h4>\n<p>Boundary conditions, no-slip walls: <span class=\"math display\">\\[\n\\mathbf{V}|_{r=R} = \\mathbf{0}\n\\]</span> Further assumptions:</p>\n<ul>\n<li>no radial motion: <span class=\"math inline\">\\(u_r = 0\\)</span></li>\n<li>no spiralling motion: <span class=\"math inline\">\\(u_\\theta = 0\\)</span></li>\n<li>axisymmetric flow: <span class=\"math inline\">\\(\\partial_\\theta\\mathbf{V}=0\\)</span></li>\n</ul>\n<p>As a result, the velocity becomes unidirectional and not vary with <span class=\"math inline\">\\(\\theta\\)</span>: <span class=\"math display\">\\[\n\\mathbf{V} = u_z(r,z)\\mathbf{\\hat{z}}\n\\]</span> Then the NavierStokes equations is reduced to: <span class=\"math display\">\\[\n\\begin{aligned}\n\\partial_zu_z&amp;=0 \\\\\n\\partial_rp &amp;= \\partial_\\theta p = 0\n\\end{aligned}\n\\]</span> Together with above hypotheses the governing equation become: <span class=\"math display\">\\[\n\\begin{aligned}\n\\mathbf{V}=u_z{r}\\mathbf{\\hat{z}} \\\\\np = p(z)\n\\end{aligned}\n\\]</span> Lastly, the Navier-Stokes equation in the streamwise direction reduces to: <span class=\"math display\">\\[\n0 = -\\partial_zp+\\frac{\\mu}{r}\\partial_r(r\\partial_ru_z)\n\\]</span> Note that the derivation of the equation above w.r.t. <span class=\"math inline\">\\(z\\)</span> leads to <span class=\"math inline\">\\(\\partial^2_zp=0~( \\partial_zp=Const.)\\)</span> The solution of the N-S equation above is: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\frac{\\partial}{\\partial r}(r\\frac{\\partial u_z}{\\partial r})=r\\frac{\\partial p}{\\mu\\partial z} \\\\\n\\Rightarrow\\quad&amp;\n\\frac{\\partial u_z}{\\partial r}=\\frac{r}{2}\\frac{\\partial p}{\\mu\\partial z}+\\frac{k_1}{r}\\\\\n\\Rightarrow\\quad&amp;\nu_z=\\frac{r^2}{4}\\frac{\\partial p}{\\mu\\partial z}+k_1\\ln{r} + k_2\n\\end{aligned}\n\\]</span> To avoid the singularity on <span class=\"math inline\">\\(r=0\\)</span>, <span class=\"math inline\">\\(k_1=0\\)</span>, and <span class=\"math inline\">\\(k_2\\)</span> is determined by the boundary condition: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\mathbf{V}|_{r=R} = \\mathbf{0}\\\\\n\\Rightarrow\\quad \n&amp;u_z|_{r=R}=\\frac{R^2}{4}\\frac{\\partial p}{\\mu\\partial z} + k_2 = 0 \\\\\n\\Rightarrow\\quad \n&amp;k_2 = -\\frac{R^2}{4}\\frac{\\partial p}{\\mu\\partial z}\n\\end{aligned}\n\\]</span> The governing function of laminar pipe flow, also know as <strong>Poiseuille flow</strong> is therefore a quadratic law: <span class=\"math display\">\\[\n\\color{purple}\nu_z=\\frac{R^2\\partial_z p}{4\\mu}\\left(\\frac{r^2}{R^2}-1\\right)\n\\]</span> <img src=\"Poiseuille flow.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Laminar pipe flow: Poiseuille flow\" style=\"zoom:80%;\" /></p>\n<div class=\"note note-info\">\n            <p>Assumptions:</p><ul><li>Laminar flow</li><li>Incompressible</li><li>Steady</li><li>Homogeneous in <span class=\"math inline\">\\(r\\)</span> and <span class=\"math inline\">\\(\\theta\\)</span> directions</li><li>viscous</li></ul>\n          </div>\n<h4 id=\"some-characteristic-quantities\">2.2.4 Some characteristic quantities</h4>\n<p>The max velocity is reached at the centre of the pipe: <span class=\"math display\">\\[\nu_z|_{max} = u_z(0) z=-\\frac{R^2\\partial_z p}{4\\mu}\n\\]</span> <div class=\"note note-info\">\n            <p>The minus sign shows that the flow goes against the pressure gradient, from the high pressure to the low pressure regions.</p>\n          </div></p>\n<p>The average velocity can be calculated as: <span class=\"math display\">\\[\n\\begin{aligned}\nu_z|_{avg} &amp;= \\frac{1}{\\pi R^2}\\int_0^R\\left[\\frac{R^2\\partial_z p}{4\\mu}\\left(\\frac{r^2}{R^2}-1\\right)\\right]2\\pi rdr \\\\\n &amp;= -\\frac{R^2\\partial_z p}{8\\mu} \\\\\n &amp;=\\frac12u_z|_{max}\n\\end{aligned}\n\\]</span> The flow rate: <span class=\"math display\">\\[\n\\begin{aligned}\nQ &amp;= A u_z|_{avg} \\\\\n&amp;=-\\frac{\\pi R^4\\partial_z p}{8\\mu}\n\\end{aligned}\n\\]</span> If the total pressure drop in the pipe with a length of <span class=\"math inline\">\\(L\\)</span> has a value: <span class=\"math display\">\\[\n\\Delta p = \\partial_zpL\n\\]</span> The flow rate is therefore: <span class=\"math display\">\\[\nQ = -\\frac{\\pi R^4 \\Delta p}{8\\mu L}\n\\]</span> And the wall shear stress is: <span class=\"math display\">\\[\n\\begin{aligned}\n\\tau_{w} &amp;= \\mu \\partial_r u_z|_{r = R} \\\\\n&amp;= -\\frac{R\\Delta p}{2L}\n\\end{aligned}\n\\]</span> Note that <span class=\"math inline\">\\(\\tau_w\\)</span> can be related with the average velocity, and therefore the flow rate: <span class=\"math display\">\\[\n\\tau_w =\\frac{4\\mu u_z|_{avg}}{R}\n\\]</span></p>\n<h3 id=\"other-cases\">2.3 Other cases</h3>\n<h4 id=\"non-viscous-pipe-flow\">2.3.1 Non-viscous pipe flow</h4>\n<p>Inviscid flows are yielded by the Euler function (ignore the body force): <span class=\"math display\">\\[\n\\partial_t\\mathbf{V}+\\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V} = -\\frac{1}{\\rho}\\boldsymbol{\\nabla} p\n\\]</span> and the continuity function: <span class=\"math display\">\\[\n\\boldsymbol{\\nabla}\\cdot\\mathbf{V} = 0\n\\]</span> And because of the inviscid condition, the boundary equation at the wall is stated as \"free-slip\", instead of the \"no-slip\" condition: <span class=\"math display\">\\[\nu_r|_{r=R}=0\\qquad\\partial_ru_\\theta|_{r=R} = 0\\qquad \\partial_ru_z|_{r=R}=0\n\\]</span> The incompressibility constraint simplifies into: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\partial_zu_z=0 \\\\\n\\Rightarrow\\quad&amp;\\partial_z=Const.\n\\end{aligned}\n\\]</span> <img src=\"plug flow.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Inviscid laminar pipe flow: plug flow.\" style=\"zoom:80%;\" /></p>\n<div class=\"note note-info\">\n            <p>Assumptions:</p><ul><li>Laminar flow</li><li>Incompressible</li><li>Steady</li><li>Homogeneous in <span class=\"math inline\">\\(r\\)</span> and <span class=\"math inline\">\\(\\theta\\)</span> directions</li><li>inviscid</li></ul>\n          </div>\n<p>The maximum and average values are equal: <span class=\"math display\">\\[\nu_z|_{max} = u_z|_{avg} = u_z\n\\]</span> and the flow rate is: <span class=\"math display\">\\[\nQ = Au_z = \\pi R^2u_z\n\\]</span> And there is no friction shear stress at walls.</p>\n<h4 id=\"channel-flow\">2.3.2 Channel flow</h4>\n<p>Channel flow describes a three-dimensional flow confined between two parallel plates and driven similarly to pipe flow by a pressure gradient.</p>\n<p><img src=\"Channel flow.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Channel flow between two parallel plates and driven by a pressure gradient in the x direction.\" style=\"zoom:80%;\" /></p>\n<div class=\"note note-info\">\n            <p>Assumptions:</p><ul><li>Laminar flow</li><li>Incompressible</li><li>Steady</li><li>Homogeneous in <span class=\"math inline\">\\(x\\)</span> and <span class=\"math inline\">\\(z\\)</span> directions</li><li>viscous</li></ul>\n          </div>\n<p>Similar to the Poiseuille flow, yet in the cartesian coordinate, the velocity is defined as: <span class=\"math display\">\\[\n\\mathbf{V} = u_x(y)\\mathbf{\\hat{x}}\n\\]</span> And the N-S equation is reduced to: <span class=\"math display\">\\[\n0 = -\\partial_xp+\\mu\\partial_y^2u_x\n\\]</span> with the boundary conditions: <span class=\"math display\">\\[\n\\mathbf{V}|_{y=\\pm h} = \\mathbf{0}\n\\]</span> The velocity is therefore: <span class=\"math display\">\\[\n\\color{purple}\nu_x = \\frac{\\partial_xph^2}{2\\mu}\\left(\\frac{y^2}{h^2}-1\\right)\n\\]</span> This is also called <strong>plane Poiseuille flow</strong>.</p>\n<h4 id=\"plane-couette-flow\">2.3.3 Plane Couette flow</h4>\n<p>Plane Couette flow describes a three-dimensional flow confined between two parallel plates yet driven by sliding walls.</p>\n<p><img src=\"Plane Couette flow.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Plane Couette flow between two parallel plates and driven by sliding walls.\" style=\"zoom:80%;\" /></p>\n<div class=\"note note-info\">\n            <p>Same assumptions are adopted as the channel flow.</p>\n          </div>\n<p>Similar to the channel flow, the velocity governing equation is: <span class=\"math display\">\\[\n0 = \\mu\\partial_y^2u_x\n\\]</span> Yet the boundary conditions are changed to be: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;u_x|_{y=h} = U \\\\\n&amp;u_x|_{y=-h} = -U\n\\end{aligned}\n\\]</span> As the velocity function become: <span class=\"math display\">\\[\n\\color{purple}\nu_x =- \\frac{ U}{h}y\n\\]</span></p>\n<h2 id=\"viscous-losses\">3 Viscous losses</h2>\n<h3 id=\"pressure-drop\">3.1 Pressure drop</h3>\n<h4 id=\"experimental-evidence\">3.1.1 Experimental evidence</h4>\n<p>In 1839, Hagen studied water flows in long brass pipes and hinted at the possible existence of two different regimes of viscous flows: laminar and turbulent. He characterised, in particular, laminar flows through the following law: <span class=\"math display\">\\[\n\\Delta p = k\\frac{LQ}{R^4}+\\mathrm{entrance~effects}\n\\]</span> where <span class=\"math inline\">\\(k = Const.\\)</span>, <span class=\"math inline\">\\(L\\)</span> is the length of the pipe, <span class=\"math inline\">\\(Q\\)</span> the flow rate and <span class=\"math inline\">\\(R\\)</span> the radius of the pipe.</p>\n<p>As he increased Q beyond a certain threshold, Hagen observed that this law broke down, and deduced the existence of a second regime. This experimental observations are easily reproduced and the results sketched in figure below.</p>\n<p><img src=\"Pressure drop.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Relationship between the pressure drop p and the average velocity V in a pipe with radius 3mm and length 3m. After White, Fluid Mechanics (2011)\" style=\"zoom:50%;\" /></p>\n<h4 id=\"dimensional-analysis\">3.1.2 Dimensional analysis</h4>\n<p>We consider a laminar flow in a horizontal pipe for which density and gravity effects are negligible. The dimensions of related quantities are:</p>\n<ul>\n<li>pressure drop <span class=\"math inline\">\\(\\Delta p\\)</span>: <span class=\"math inline\">\\([\\Delta p] = [ML^{-1}T^{-2}]\\)</span></li>\n<li>flow rate <span class=\"math inline\">\\(Q\\)</span>: <span class=\"math inline\">\\([Q]=[L^3T^-1]\\)</span></li>\n<li>pipe length <span class=\"math inline\">\\(L\\)</span>: <span class=\"math inline\">\\([L]=[L]\\)</span></li>\n<li>pipe radius <span class=\"math inline\">\\(R\\)</span>:<span class=\"math inline\">\\([R]=[L]\\)</span></li>\n<li>fluid's dynamic viscosity <span class=\"math inline\">\\(\\mu\\)</span>: <span class=\"math inline\">\\([\\mu]=[ML^-1T^-1]\\)</span></li>\n</ul>\n<p>As the pressure gradient is constant along the pipe and the flow fully characterised by the radial direction only, we can write <span class=\"math display\">\\[\n\\frac{\\Delta p}{L}=\\mathcal{F}(Q, R, \\mu)\n\\]</span> We note that the left-hand-side has dimension proportional to a mass M and that only the dynamic viscosity has dimension proportional to a mass. We can then divide by the dynamic viscosity to get rid of this dimension. <span class=\"math display\">\\[\n\\frac{\\Delta p}{\\mu L}=\\mathcal{F}(Q, R)\n\\]</span> Similarly, to get rid of the length dimension, multiply by <span class=\"math inline\">\\(R\\)</span>. Then divide by <span class=\"math inline\">\\(R^3\\)</span>. <span class=\"math display\">\\[\n\\frac{\\Delta p R}{\\mu L}=\\mathcal{F}(\\frac{Q}{R^3})\n\\]</span> At this stage, both the left-hand-side and the right-hand-side terms are both homogeneous to the inverse of a time. Upon dividing the one by the other, we obtain the following relationship: <span class=\"math display\">\\[\n\\frac{\\Delta p R^4}{\\mu LQ}=Const.\n\\]</span> which provide the following pressure loss drop law: <span class=\"math display\">\\[\n\\Delta p = C_{onst.} \\mu\\frac{ LQ}{ R^4}\n\\]</span> This law is very similar to that obtained experimentally by Hagen. In particular, it shows that Hagens constant <span class=\"math inline\">\\(k\\)</span> is homogeneous to a dynamic viscosity.</p>\n<h4 id=\"theoretical-answer\">3.1.3 Theoretical answer</h4>\n<p>Recall the streamwise velocity reads: <span class=\"math display\">\\[\nu_z=\\frac{R^2\\partial_z p}{4\\mu}\\left(\\frac{r^2}{R^2}-1\\right)\n\\]</span> giving the following flow rate: <span class=\"math display\">\\[\nQ = -\\frac{\\pi R^4\\Delta p}{8\\mu L}\n\\]</span> And the $p $ as a function of <span class=\"math inline\">\\(Q,R,\\mu,L\\)</span> reads: <span class=\"math display\">\\[\n\\color{purple}\n\\Delta p = \\frac{8}{\\pi}\\mu\\frac{LQ}{R^4}\n\\]</span></p>\n<h3 id=\"head-loss\">3.2 Head loss</h3>\n<h4 id=\"the-bernoulli-equation\">3.2.1 The Bernoulli equation</h4>\n<p>As a result of the friction between the fluid and the wall, the energy and head decrease between these two sections. We take this into account by adding a term to the Bernoulli equation as: <span class=\"math display\">\\[\n\\frac{p_1}{\\rho g}+\\frac{u_1^2}{2g}+z_1 = \\frac{p_2}{\\rho g}+\\frac{u_2^2}{2g}+z_2+h_f\n\\]</span> where <span class=\"math inline\">\\(h_f\\)</span> is called <strong>head loss</strong> and accounts for the viscous dissipation. The equivalent loss of energy per unit volume is <span class=\"math inline\">\\(\\rho ghf\\)</span>. Relevantly, <span class=\"math inline\">\\(\\frac{p}{\\rho g}\\)</span> is called <strong>pressure head</strong> and <span class=\"math inline\">\\(\\frac{u^2}{2g}\\)</span> is called <strong>kinetic head</strong>.</p>\n<div class=\"note note-info\">\n            <p>Conditions:</p><ul><li>Steady</li><li>Incompressible</li><li>Streamwise</li><li><strong>Viscous</strong>.</li></ul>\n          </div>\n<h4 id=\"application-to-pipe-flow\">3.2.2 Application to pipe flow</h4>\n<p><img src=\"inclined pipe.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Sketch of an inclined pipe. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" /></p>\n<p>Given a inclined laminar pipe. The velocity of the fluid is invariant with the streamwise direction <span class=\"math inline\">\\(x\\)</span>, so <span class=\"math inline\">\\(u_1= u_2\\)</span>. We can then express the head loss: <span class=\"math display\">\\[\nh_f = \\frac{\\Delta p}{\\rho g}+\\Delta z\n\\]</span> Apply the momentum equation for the control volume shown above: <span class=\"math display\">\\[\n\\Sigma F_x = \\rho\\pi R^2\\left(u_{2avg}^2-u_{1avg}^2\\right)\n\\]</span> There are three forces acting on the fluid in the x direction</p>\n<ul>\n<li>pressure: <span class=\"math inline\">\\(\\Delta p\\pi R^2\\)</span></li>\n<li>weight: <span class=\"math inline\">\\(\\rho L \\pi R^2 \\sin(\\phi)g\\)</span></li>\n<li>shear: <span class=\"math inline\">\\(-\\tau_w2\\pi RL\\)</span></li>\n</ul>\n<p>Additionally, with constant fluid velocity i.e. <span class=\"math inline\">\\(u_{1avg} = u_{2avg}\\)</span>, the momentum equation can be simplified as: <span class=\"math display\">\\[\n\\Delta p\\pi R^2+\\rho L \\pi R^2 \\sin(\\phi)g-\\tau_w2\\pi RL=0\n\\]</span> as a result: <span class=\"math display\">\\[\n\\frac{\\Delta p}{\\rho g}+\\Delta z = \\frac{2\\tau_wL}{\\rho gR}\n\\]</span> and the head loss therefore writes: <span class=\"math display\">\\[\n\\color{purple}\nh_f = \\frac{2\\tau_wL}{\\rho gR} = \\frac{4\\tau_wL}{\\rho gd}\n\\]</span> Recall the wall shear for the Poiseuille flow, <span class=\"math inline\">\\(\\tau_w =\\frac{4\\mu u_{avg}}{R}\\)</span> <span class=\"math display\">\\[\n\\color{purple}\nh_f =  \\frac{8\\mu  u_{avg} L}{\\rho gR^2} = \\frac{32\\mu  u_{avg} L}{\\rho gd^2}\n\\]</span></p>\n<h4 id=\"physical-interpretation\">3.2.3 Physical interpretation</h4>\n<p>We can experimentally observe quantities related to the Bernoulli equation. Static pressure tubes directly connected to the side of the pipe directly observe the pressure head <span class=\"math inline\">\\(p/g\\)</span>. When this quantity is summed with the altitude <span class=\"math inline\">\\(z\\)</span> and tracked along the pipe, we obtain the <strong>hydraulic grade line</strong>. The use of Pitot tubes provides additional information: as they are oriented in the direction of the flow, they are sensitive to the fluids velocity and include the kinetic head <span class=\"math inline\">\\(u^2/2g\\)</span>. The line obtained by summing the kinetic head together with the pressure head and the altitude is called <strong>energy grade line</strong>.</p>\n<p>When viscous effects are non-negligible, the head loss can be observed as loss of pressure and therefore as a drop for both lines. This situation is depicted below:</p>\n<p><img src=\"Physical interpretation.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Physical interpretation of head loss, together with hydraulic and energy grade lines.\" style=\"zoom:48%;\" /></p>\n<h4 id=\"general-formulae-turbulent-flow\">3.2.4 General formulae (Turbulent flow)</h4>\n<p>The theory above only describes the steady laminar flow, but flows are often turbelent in applications. A need for general expression of head loss arose.</p>\n<p>In 1850, Weisbach used physical intuition to lead the way to a unifying theory. He realised that the head loss was proportional to <span class=\"math inline\">\\(L/d\\)</span> and also approximately proportional to <span class=\"math inline\">\\(u_{avg}^2\\)</span> experimentally for turbulent flows. He then suggested the following relationship: <span class=\"math display\">\\[\n\\color{purple}\nh_f = f\\frac{L}{d}\\frac{u_{avg}^2}{2g}\n\\]</span> where f is a non-dimensional parameter called <strong>Darcy friction factor</strong>. Still out of physical intuition, he precised that the friction factor depend on the <strong>Reynolds number</strong>, the <strong>duct shape</strong> and the <strong>roughness of the wall for turbulent flows</strong>.</p>\n<p>For <strong>laminar flow</strong> in a pipe: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{32 \\mu u_{a v g} L}{\\rho g d^{2}} &amp;=f_{l a m} \\frac{L}{d} \\frac{u_{a v g}^{2}}{2 g} \\\\\n\\Rightarrow f_{l a m} &amp;=\\frac{64 \\mu u_{a v g} L d g}{\\rho g d^{2} L u_{a v g}^{2}}, \\\\\n\\Rightarrow f_{\\text {lam }} &amp;=\\frac{64 \\mu}{\\rho d u_{a v g}} \\\\\n\\Rightarrow \\color{purple}{f_{l a m} }&amp; \\color{purple}{=\\frac{64}{R e_{d}}}\n\\end{aligned}\n\\]</span> where <span class=\"math inline\">\\(Re_d\\)</span> denotes the Reynolds number based on the diameter of the pipe</p>\n<p>For <strong>turbulent flow</strong>:</p>\n<p>No theoretical or experimental laws, in 1939, Colebrook provided an interpolation formula of empirical data: <span class=\"math display\">\\[\n\\frac{1}{f^{1 / 2}}=-2 \\log \\left(\\frac{\\epsilon / d}{3.7}+\\frac{2.51}{R e_{d} f^{1 / 2}}\\right)\n\\]</span> where <span class=\"math inline\">\\(\\epsilon/d\\)</span> (<strong>roughness height</strong>) quantifies the relative roughness of the walls, with <span class=\"math inline\">\\(\\epsilon\\)</span> being related to the size of the disturbance from a smooth wall. For a perfectly smooth pipe, <span class=\"math inline\">\\(\\epsilon/d = 0\\)</span>. And this value increase with the roughness of the wall.</p>\n<p>Colebrooks formula is transcendental and cannot be solved by hand. Hence, in 1944, Moody plotted what is now known as the Moody chart (below) to provide directly readable data. This chart is nowadays a standard in the engineering world.</p>\n<p><img src=\"Moody chart.png\" srcset=\"/img/loading.gif\" lazyload alt=\"The Moody chart representing the friction factor f as a function of the Reynolds number Re and the relative roughness /d of the pipe. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" /></p>\n<h3 id=\"entrance-effects\">3.3 Entrance effects</h3>\n<h4 id=\"definition\">3.3.1 Definition</h4>\n<p>Away from the pipe, the external flow is homogeneous (therefore, not dissipative, or conservative); the flow within the pipe displays vanishing velocity at the wall due to viscosity. It is dissipative. Thus, there is a region (time if you follow the fluid) where the flow progressively accommodates to the presence of walls. This region is called entrance region and this progress is called the entrance effects, firstly observed by Hagen.</p>\n<p><img src=\"entrance effect.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Depiction of the entrance region and the accommodation of the fluid to the presence of walls. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" /></p>\n<h4 id=\"entrance-length\">3.3.2 Entrance length</h4>\n<p>Use dimensional analysis:</p>\n<p>The entrance length <span class=\"math inline\">\\(L_e=[L]\\)</span> is related to:</p>\n<ul>\n<li>pipe diameter <span class=\"math inline\">\\(d\\)</span>: <span class=\"math inline\">\\([d]=[L]\\)</span></li>\n<li>average fluid velocity <span class=\"math inline\">\\(u_{avg}\\)</span>: <span class=\"math inline\">\\(u_{avg}=[LT^{-1}]\\)</span></li>\n<li>fluid's density <span class=\"math inline\">\\(\\rho\\)</span>: <span class=\"math inline\">\\(\\rho = [ML^{-3}]\\)</span></li>\n<li>fluid's dynamic viscosity <span class=\"math inline\">\\(\\mu\\)</span>: <span class=\"math inline\">\\(\\mu = [ML^{-1}T^{-1}]\\)</span></li>\n</ul>\n<p>As <span class=\"math inline\">\\([L_e/d]=[1]\\)</span>, combine other quantities to get a dimensionless product: <span class=\"math display\">\\[\n\\begin{aligned}\nu_{avg}^a \\rho^b \\mu^c d^d &amp;= L^{a}T^{-a}M^{b}L^{-3b}M^{c}L^{-c}T^{-c}L^d \\\\\n&amp;= L^{a-3b-c+d}T^{-a-c}M^{b+c} = L^0T^0M^0\\\\\n\\Rightarrow \\quad \n&amp;\\left\\{\\begin{array}{l}\na-3b-c+d=0 \\\\\n-a-c=0 \\\\\nb+c=0\n\\end{array}\\right.\\\\\n\\Rightarrow \\quad \n&amp;a=b=d=-c\n\\end{aligned}\n\\]</span> As a result, let <span class=\"math inline\">\\(c=\\gamma\\)</span>: <span class=\"math display\">\\[\n\\left[\\frac{L_{e}}{d}\\right]=\\left[\\frac{\\rho u_{a v g} d}{\\mu}\\right]^{\\gamma}\n\\]</span> The RHS is Reynolds number based on the diameter of the pipe, <span class=\"math inline\">\\(Re_d\\)</span>, finally: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{L_e}{d}= \\mathcal{F}(Re_d^\\gamma)\n\\]</span> the following empirical laws shows that:</p>\n<ul>\n<li>laminar flows: <span class=\"math inline\">\\(\\frac{L_e}{d}\\approx0.06Re_d\\)</span></li>\n<li>turbulent flows: <span class=\"math inline\">\\(\\frac{L_e}{d}\\approx1.6Re_d\\)</span></li>\n</ul>\n<p>Note that these laws provide some interesting differences between laminar and turbulent flows: at <span class=\"math inline\">\\(Re_d= 2000\\)</span>, the entrance length of a laminar flow is <span class=\"math inline\">\\(L_e= 120d\\)</span> while a turbulent flow at <span class=\"math inline\">\\(Re_d= 10000\\)</span> will yield an entrance length of only <span class=\"math inline\">\\(L_e= 16d\\)</span>.</p>\n","site":{"data":{}},"wordcount":20979,"excerpt":"<div class=\"note note-primary\">\n            <p>Feeling good deriving the basics, continue to review the following content.</p>\n          </div>","more":"<h2 id=\"flow-regimes-case-study-of-duct-flow\">1 Flow regimes  case study of duct flow</h2>\n<h3 id=\"examples-of-duct-flows\">1.1 Examples of duct flows</h3>\n<h4 id=\"oil-extraction\">1.1.1 Oil extraction</h4>\n<p>Upon finding a natural oil reservoir, several techniques are employed to extract the oil.</p>\n<ol type=\"1\">\n<li>Drilling a long hole into the Earth and placing a duct in, the oil reservoir possesses a higher pressure then the atmosphere thus the oil is pushed upwards along the duct.</li>\n<li>Steam injection, drilling a second hole to inject steam, the addition of steam increase the pressure and push the oil further upwards. The increase in temperature reduces the viscosity.</li>\n</ol>\n<h4 id=\"pipeline-transport\">1.1.2 Pipeline transport</h4>\n<p>Transport systems designed to bring the oil to storage or treatment sites face many challenges. Take Trans-Alaska Pipeline System (TAPS) as an example, oil extracted is substantially warmer than anything at the surface, the permafrost (frozen ground) may warm up and become unstable. To avoid this , radiators have beed placed next to the pipeline.</p>\n<p>Besides, drag-reducing agents DRA are mixed with the oil to reduce the viscous drag produced by the massive turbulent flow inside.</p>\n<h4 id=\"biological-flow\">1.1.3 Biological flow</h4>\n<p>The cerebral blood flow in the cortex can be modelled through a complex assembly of ducts, mimicking the vessel network present in the brain. Experimental data coupled with numerical simulations can then provide prediction of the pressure map in the brain.Access to these results can then be used to predict the risks of blockage or damage of the vessels and thus of brain stroke.</p>\n<h3 id=\"reynolds-number\">1.2 Reynolds number</h3>\n<p>In 1883, Osbourne Reynolds published his famous pipe flow experiment. He placed a pipe within a tank full of water. The water entered in the pipe through a converging cone to decrease the impact of entrance effects and the flow rate is controled by a valve. Aligned with the entrance of the pipe is a needle connected to a dye container. As the desired flow rate is reached, dye is injected within the pipe to trace out the fluids trajectory.</p>\n<p><img src=\"Reynolds experiment.png\" alt=\"Photographs of pipe flow visualised using dye injection in the centerline. The Reynolds number is increased from top to bottom and the successive snapshots represent: laminar flow, transitional flow, turbulent flow, turbulent flow. After Van Dyke, An Album of Fluid Motion (1982).\" style=\"zoom:100%;\" /></p>\n<p>In addition to making these observations, it is possible to characterise these different regimes in a simple manner, the quantities that influence the flow are:</p>\n<ul>\n<li>pipe diameter <span class=\"math inline\">\\(l\\)</span>: <span class=\"math inline\">\\([l]=L\\)</span></li>\n<li>fluid's velocity <span class=\"math inline\">\\(u\\)</span>: <span class=\"math inline\">\\([u]=LT^{-1}\\)</span></li>\n<li>fluid's density <span class=\"math inline\">\\(\\rho\\)</span>: <span class=\"math inline\">\\([\\rho] = mL^{-3}\\)</span></li>\n<li>fluid's dynamic viscosity <span class=\"math inline\">\\(\\mu\\)</span>: <span class=\"math inline\">\\([\\mu]=mL^{-1}T^{-1}\\)</span></li>\n</ul>\n<p>Combine these quantities to obtain a dimensionless number called Reynolds number, <span class=\"math display\">\\[\n\\color{purple}\nRe = \\frac{\\rho V L}{\\mu}\n\\]</span> <img src=\"3 flow regimes.png\" alt=\"Sketch of the temporal variations of the streamwise velocity at a fixed location in the pipe. From left to right: laminar, transitional and turbulent regimes. After White, Fluid Mechanics (2011).\" style=\"zoom:100%;\" /></p>\n<p>With Reynolds number, 3 regimes of flow can be defined:</p>\n<ul>\n<li>Laminar flows: <span class=\"math inline\">\\(0&lt;Re&lt;1000\\)</span></li>\n<li>Transitional flows: <span class=\"math inline\">\\(1000&lt;Re&lt;4000\\)</span></li>\n<li>Turbulent flows: <span class=\"math inline\">\\(4000&lt;Re\\)</span></li>\n</ul>\n<p><img src=\"puffs.png\" alt=\"Visualisation of a puff going through a pipe and splitting. Time goes from bottom to top and the quantity represented is the streamwise vorticity, red (resp. blue) representing positive (resp. negative) values. The Reynolds number is 2300. After Avila et al., Science 333, 192 (2011).\" style=\"zoom:100%;\" /></p>\n<p>The intermittent bursts of turbulence displayed in the transitional regime are the signature of the passage of turbulent puffs. They can be observed by direct numerical simulation, like the figure above for Re = 2300. The upstream edge of the puff is well-defined, while the downstream edge is elongated and fuzzy. Puffs typically evolve in two different ways: Vanishing and decaying down to the laminar state or splitting, leading to an increasingly large turbulent fraction in the flow. Puffs decay rapidly in the laminar regime and split frequently in the turbulent regime, but they remain long-lived in the transitional one.</p>\n<p>The lifetime of a puff before decaying and splitting in pipe flow is studied as a function of Reynolds number, and the results are shown below. It is confirmed that the puffs are long-lived over a wide range of <span class=\"math inline\">\\(Re\\)</span>s. Importantly, there is an intersection between the decay and the splitting lifetime curves. This intersection provides a well-defined legitimate threshold between laminar and turbulent flows: <span class=\"math inline\">\\(Re_c 2040\\)</span>.</p>\n<p><img src=\"puff lifetimes.png\" alt=\"Mean lifetime of a puff before decay or splitting in pipe flow as a function of the Reynolds number. After Avila et al., Science 333, 192 (2011).\" style=\"zoom:50%;\" /></p>\n<h3 id=\"other-considerations\">1.3 Other considerations</h3>\n<h4 id=\"newtoniannon-newtonian-fluids\">1.3.1 Newtonian/non-Newtonian fluids</h4>\n<p>Water and air all follow the rule of constant viscosity, that is, the wall shear stress is <span class=\"math inline\">\\(\\mu\\)</span> proportional to the normal velocity gradient (shear, strain rate): <span class=\"math display\">\\[\n\\tau = \\mu\\partial_nu\n\\]</span> But not all types of fluids follow this law, as seen below.</p>\n<ul>\n<li>Shear thinning: ketchup, becoming less and less viscous as they are stirred.</li>\n<li>Shear thickening: corn starch, getting much harder to strain as they receive more stress.</li>\n<li>Mayonnaise: tooth paste, possessing a threshold stress below which they behave like solids and above which their rheological law is linear. If you hang the open container upside down, it will not flow. An additional force is needed on the container to create a flow.</li>\n<li>More complicated, HerschelBulkley fluids (e.g. paint) or even time-dependent visco-elastic fluids (e.g. polymers).</li>\n</ul>\n<p><img src=\"non-newtonian flow.png\" alt=\"Rheological diagram showing the shear stress  as a function of the shear rate nu for several types of fluids.\" style=\"zoom:50%;\" /></p>\n<h4 id=\"compressibility\">1.3.2 Compressibility</h4>\n<p>When the flow speed reach the speed of sound, the fluid becomes compressible, meaning the density becomes variant in time and space. The best unidimensional quantity to describe this threshold is called Mach number: <span class=\"math display\">\\[\nMa = \\frac{u}{c}\n\\]</span> where the <span class=\"math inline\">\\(c\\)</span> is the speed of sound, and the flowing regimes are observed defined by <span class=\"math inline\">\\(Ma\\)</span>.</p>\n<ul>\n<li><span class=\"math inline\">\\(0&lt;Ma&lt;0.3\\)</span>: incompressible flows.</li>\n<li><span class=\"math inline\">\\(0.3&lt;Ma&lt;1\\)</span>: compressible subsonic flows.</li>\n<li><span class=\"math inline\">\\(1&lt;Ma\\)</span>: compressible supersonic flows.</li>\n</ul>\n<h2 id=\"laminar-flow-cases\">2 Laminar flow cases</h2>\n<h3 id=\"incompressible-framework\">2.1 Incompressible framework</h3>\n<h4 id=\"the-navier-stokes-equation\">2.1.1 The Navier-Stokes equation</h4>\n<p>The incompressible NavierStokes equation describes the motion of fluids under external forces. It writes: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial \\mathbf{V}}{\\partial t}+\\mathbf{V}\\cdot\\boldsymbol{\\nabla} \\mathbf{V} = \\mathbf{f} -\\frac{1}{\\rho}\\boldsymbol{\\nabla} p + \\nu\\boldsymbol{\\nabla}^2\\mathbf{V}\n\\]</span></p>\n<blockquote>\n<p>The left-hand-side of the NavierStokes equation represents inertia. It involves the rate of change of the velocity with time tu as well as advection (u  ) u. The latter term quantifies how the fluid is transported by the flow velocity. In an equation such as the heat equation, this term applies to the temperature T, reads (u  ) T and quantifies how temperature is transported by the flow velocity.</p>\n<p>The right-hand-side represents all the forces acting on the fluid. In addition to the external forces f that we will not take into account in this Chapter, the other terms come from the divergence of the stress tensor. They include the pressure gradient p that translates the fact that the fluid is attracted to low pressure regions and the viscous force 2u quantifying the internal friction between in the fluid.</p>\n</blockquote>\n<h4 id=\"continuity-equation\">2.1.2 Continuity equation</h4>\n<p>Recall the mass conservation equation in the Eulerian frame of reference, <span class=\"math display\">\\[\n\\frac{\\partial\\rho}{\\partial t} + \\boldsymbol{\\nabla}\\cdot(\\rho\\mathbf{V})=0\n\\]</span> And with the incompressibility consumption, <span class=\"math display\">\\[\n\\color{purple}\n\\boldsymbol{\\nabla}\\cdot\\mathbf{V} = 0\n\\]</span></p>\n<h4 id=\"additional-hypotheses\">2.1.2 Additional hypotheses</h4>\n<p>In the laminar flow regime, it is common to assume the flow as:</p>\n<ul>\n<li>steady: <span class=\"math inline\">\\(\\partial_t=0\\)</span></li>\n<li>unidirectional: the flow is parallel the to walls</li>\n<li>symmetry: the flow is further simplified using the symmetries of the geometry</li>\n</ul>\n<h3 id=\"pipe-flow\">2.2 Pipe flow</h3>\n<h4 id=\"cylindrical-coordinate\">2.2.1 Cylindrical coordinate</h4>\nIn cylindrical coordinate, the velocity: <span class=\"math display\">\\[\n\\mathbf{V} = u_r\\mathbf{\\hat {r}}+u_\\theta\\boldsymbol{\\hat {\\theta}}+u_z\\mathbf{\\hat {z}}\n\\]</span> The line element writes: <span class=\"math display\">\\[\nds = dr\\mathbf{\\hat{r}} + rd\\theta\\boldsymbol{\\hat{\\theta}}+dz\\mathbf{\\hat{z}}\n\\]</span> The gradient operator <span class=\"math display\">\\[\n\\boldsymbol{\\nabla} = \\partial_r\\mathbf{\\hat {r}}+\\frac{1}{r}\\partial_\\theta\\boldsymbol{\\hat {\\theta}}+\\partial_z\\mathbf{\\hat {z}}\n\\]</span> And the directions change with <span class=\"math inline\">\\(\\theta\\)</span>, as a consequence: <span class=\"math display\">\\[\n\\partial_\\theta\\mathbf{\\hat{r}} = \\boldsymbol{\\hat {\\theta}}, \\qquad \\partial_\\theta\\boldsymbol{\\hat {\\theta}} = -\\mathbf{\\hat{r}}\n\\]</span> Some useful equations: $$\n<span class=\"math display\">\\[\\begin{aligned}\n\\boldsymbol{\\nabla} \\cdot \\mathbf{V} =&amp; \\frac{1}{r}\\partial_r(ru_r)+ \\frac{1}{r}\\partial_\\theta(u_\\theta) + \\partial_z(u_z) \\\\\n(\\mathbf{V}\\cdot\\boldsymbol{\\nabla})\\mathbf{V} =&amp;\\left(u_{r} \\partial_{r} u_{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{r}-\\frac{u_{\\theta}^{2}}{r}+u_{z} \\partial_{z} u_{r}\\right) \\hat{\\mathbf{r}} \\\\\n&amp;+\\left(u_{r} \\partial_{r} u_{\\theta}+\\frac{u_{r} u_{\\theta}}{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{\\theta}+u_{z} \\partial_{z} u_{\\theta}\\right) \\boldsymbol{\\hat{\\theta}}\\\\\n&amp;+\\left(u_{r} \\partial_{r} u_{z}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{z}+u_{z} \\partial_{z} u_{z}\\right) \\hat{\\mathbf{z}}\\\\\n\n\\boldsymbol{\\nabla}^2\\mathbf{V}=&amp;\\left[\\frac{1}{r} \\partial_{r}\\right.\\left.\\left(r \\partial_{r} u_{r}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{r}-\\frac{u_{r}}{r^{2}}-\\frac{2}{r^{2}} \\partial_{\\theta} u_{\\theta}+\\partial_{z}^{2} u_{r}\\right] \\hat{\\mathbf{r}} \\\\\n&amp;+ {\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{\\theta}\\right)+\\frac{2}{r^{2}} \\partial_{\\theta} u_{r}+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{\\theta}-\\frac{u_{\\theta}}{r^{2}}+\\partial_{z}^{2} u_{\\theta}\\right] \\boldsymbol{\\hat{\\theta} }} \\\\\n&amp;+ {\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{z}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{z}+\\partial_{z}^{2} u_{z}\\right] \\hat{\\mathbf{z}} } \\\\\n\\end{aligned}\\]</span>\n<p>$$</p>\n<h4 id=\"governing-equations\">2.2.2 Governing equations</h4>\n<p>Continuity equation: <span class=\"math display\">\\[\n\\frac{1}{r}\\partial_r(ru_r)+ \\frac{1}{r}\\partial_\\theta(u_\\theta) + \\partial_z(u_z) = 0\n\\]</span> NavierStokes equation: <span class=\"math display\">\\[\n\\begin{aligned}\n\\rho\\left[\\partial_{t} u_{r}\\right.&amp;\\left.+u_{r} \\partial_{r} u_{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{r}-\\frac{u_{\\theta}^{2}}{r}+u_{z} \\partial_{z} u_{r}\\right]=-\\partial_{r} p \\ldots \\\\\n&amp;+\\mu\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{r}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{r}-\\frac{u_{r}}{r^{2}}-\\frac{2}{r^{2}} \\partial_{\\theta} u_{\\theta}+\\partial_{z}^{2} u_{r}\\right] \\\\\n\\rho\\left[\\partial_{t} u_{\\theta}\\right.&amp;\\left.+u_{r} \\partial_{r} u_{\\theta}+\\frac{u_{r} u_{\\theta}}{r}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{\\theta}+u_{z} \\partial_{z} u_{\\theta}\\right]=-\\frac{1}{r} \\partial_{\\theta} p \\ldots \\\\\n&amp;+\\mu\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{\\theta}\\right)+\\frac{2}{r^{2}} \\partial_{\\theta} u_{r}+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{\\theta}-\\frac{u_{\\theta}}{r^{2}}+\\partial_{z}^{2} u_{\\theta}\\right] \\\\\n\\rho\\left[\\partial_{t} u_{z}\\right.&amp;\\left.+u_{r} \\partial_{r} u_{z}+\\frac{u_{\\theta}}{r} \\partial_{\\theta} u_{z}+u_{z} \\partial_{z} u_{z}\\right]=-\\partial_{z} p \\ldots \\\\\n&amp;+\\mu\\left[\\frac{1}{r} \\partial_{r}\\left(r \\partial_{r} u_{z}\\right)+\\frac{1}{r^{2}} \\partial_{\\theta}^{2} u_{z}+\\partial_{z}^{2} u_{z}\\right]\n\\end{aligned}\n\\]</span></p>\n<h4 id=\"solution\">2.2.3 Solution</h4>\n<p>Boundary conditions, no-slip walls: <span class=\"math display\">\\[\n\\mathbf{V}|_{r=R} = \\mathbf{0}\n\\]</span> Further assumptions:</p>\n<ul>\n<li>no radial motion: <span class=\"math inline\">\\(u_r = 0\\)</span></li>\n<li>no spiralling motion: <span class=\"math inline\">\\(u_\\theta = 0\\)</span></li>\n<li>axisymmetric flow: <span class=\"math inline\">\\(\\partial_\\theta\\mathbf{V}=0\\)</span></li>\n</ul>\n<p>As a result, the velocity becomes unidirectional and not vary with <span class=\"math inline\">\\(\\theta\\)</span>: <span class=\"math display\">\\[\n\\mathbf{V} = u_z(r,z)\\mathbf{\\hat{z}}\n\\]</span> Then the NavierStokes equations is reduced to: <span class=\"math display\">\\[\n\\begin{aligned}\n\\partial_zu_z&amp;=0 \\\\\n\\partial_rp &amp;= \\partial_\\theta p = 0\n\\end{aligned}\n\\]</span> Together with above hypotheses the governing equation become: <span class=\"math display\">\\[\n\\begin{aligned}\n\\mathbf{V}=u_z{r}\\mathbf{\\hat{z}} \\\\\np = p(z)\n\\end{aligned}\n\\]</span> Lastly, the Navier-Stokes equation in the streamwise direction reduces to: <span class=\"math display\">\\[\n0 = -\\partial_zp+\\frac{\\mu}{r}\\partial_r(r\\partial_ru_z)\n\\]</span> Note that the derivation of the equation above w.r.t. <span class=\"math inline\">\\(z\\)</span> leads to <span class=\"math inline\">\\(\\partial^2_zp=0~( \\partial_zp=Const.)\\)</span> The solution of the N-S equation above is: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\frac{\\partial}{\\partial r}(r\\frac{\\partial u_z}{\\partial r})=r\\frac{\\partial p}{\\mu\\partial z} \\\\\n\\Rightarrow\\quad&amp;\n\\frac{\\partial u_z}{\\partial r}=\\frac{r}{2}\\frac{\\partial p}{\\mu\\partial z}+\\frac{k_1}{r}\\\\\n\\Rightarrow\\quad&amp;\nu_z=\\frac{r^2}{4}\\frac{\\partial p}{\\mu\\partial z}+k_1\\ln{r} + k_2\n\\end{aligned}\n\\]</span> To avoid the singularity on <span class=\"math inline\">\\(r=0\\)</span>, <span class=\"math inline\">\\(k_1=0\\)</span>, and <span class=\"math inline\">\\(k_2\\)</span> is determined by the boundary condition: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\mathbf{V}|_{r=R} = \\mathbf{0}\\\\\n\\Rightarrow\\quad \n&amp;u_z|_{r=R}=\\frac{R^2}{4}\\frac{\\partial p}{\\mu\\partial z} + k_2 = 0 \\\\\n\\Rightarrow\\quad \n&amp;k_2 = -\\frac{R^2}{4}\\frac{\\partial p}{\\mu\\partial z}\n\\end{aligned}\n\\]</span> The governing function of laminar pipe flow, also know as <strong>Poiseuille flow</strong> is therefore a quadratic law: <span class=\"math display\">\\[\n\\color{purple}\nu_z=\\frac{R^2\\partial_z p}{4\\mu}\\left(\\frac{r^2}{R^2}-1\\right)\n\\]</span> <img src=\"Poiseuille flow.png\" alt=\"Laminar pipe flow: Poiseuille flow\" style=\"zoom:80%;\" /></p>\n<div class=\"note note-info\">\n            <p>Assumptions:</p><ul><li>Laminar flow</li><li>Incompressible</li><li>Steady</li><li>Homogeneous in <span class=\"math inline\">\\(r\\)</span> and <span class=\"math inline\">\\(\\theta\\)</span> directions</li><li>viscous</li></ul>\n          </div>\n<h4 id=\"some-characteristic-quantities\">2.2.4 Some characteristic quantities</h4>\n<p>The max velocity is reached at the centre of the pipe: <span class=\"math display\">\\[\nu_z|_{max} = u_z(0) z=-\\frac{R^2\\partial_z p}{4\\mu}\n\\]</span> <div class=\"note note-info\">\n            <p>The minus sign shows that the flow goes against the pressure gradient, from the high pressure to the low pressure regions.</p>\n          </div></p>\n<p>The average velocity can be calculated as: <span class=\"math display\">\\[\n\\begin{aligned}\nu_z|_{avg} &amp;= \\frac{1}{\\pi R^2}\\int_0^R\\left[\\frac{R^2\\partial_z p}{4\\mu}\\left(\\frac{r^2}{R^2}-1\\right)\\right]2\\pi rdr \\\\\n &amp;= -\\frac{R^2\\partial_z p}{8\\mu} \\\\\n &amp;=\\frac12u_z|_{max}\n\\end{aligned}\n\\]</span> The flow rate: <span class=\"math display\">\\[\n\\begin{aligned}\nQ &amp;= A u_z|_{avg} \\\\\n&amp;=-\\frac{\\pi R^4\\partial_z p}{8\\mu}\n\\end{aligned}\n\\]</span> If the total pressure drop in the pipe with a length of <span class=\"math inline\">\\(L\\)</span> has a value: <span class=\"math display\">\\[\n\\Delta p = \\partial_zpL\n\\]</span> The flow rate is therefore: <span class=\"math display\">\\[\nQ = -\\frac{\\pi R^4 \\Delta p}{8\\mu L}\n\\]</span> And the wall shear stress is: <span class=\"math display\">\\[\n\\begin{aligned}\n\\tau_{w} &amp;= \\mu \\partial_r u_z|_{r = R} \\\\\n&amp;= -\\frac{R\\Delta p}{2L}\n\\end{aligned}\n\\]</span> Note that <span class=\"math inline\">\\(\\tau_w\\)</span> can be related with the average velocity, and therefore the flow rate: <span class=\"math display\">\\[\n\\tau_w =\\frac{4\\mu u_z|_{avg}}{R}\n\\]</span></p>\n<h3 id=\"other-cases\">2.3 Other cases</h3>\n<h4 id=\"non-viscous-pipe-flow\">2.3.1 Non-viscous pipe flow</h4>\n<p>Inviscid flows are yielded by the Euler function (ignore the body force): <span class=\"math display\">\\[\n\\partial_t\\mathbf{V}+\\mathbf{V}\\cdot\\boldsymbol{\\nabla}\\mathbf{V} = -\\frac{1}{\\rho}\\boldsymbol{\\nabla} p\n\\]</span> and the continuity function: <span class=\"math display\">\\[\n\\boldsymbol{\\nabla}\\cdot\\mathbf{V} = 0\n\\]</span> And because of the inviscid condition, the boundary equation at the wall is stated as \"free-slip\", instead of the \"no-slip\" condition: <span class=\"math display\">\\[\nu_r|_{r=R}=0\\qquad\\partial_ru_\\theta|_{r=R} = 0\\qquad \\partial_ru_z|_{r=R}=0\n\\]</span> The incompressibility constraint simplifies into: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;\\partial_zu_z=0 \\\\\n\\Rightarrow\\quad&amp;\\partial_z=Const.\n\\end{aligned}\n\\]</span> <img src=\"plug flow.png\" alt=\"Inviscid laminar pipe flow: plug flow.\" style=\"zoom:80%;\" /></p>\n<div class=\"note note-info\">\n            <p>Assumptions:</p><ul><li>Laminar flow</li><li>Incompressible</li><li>Steady</li><li>Homogeneous in <span class=\"math inline\">\\(r\\)</span> and <span class=\"math inline\">\\(\\theta\\)</span> directions</li><li>inviscid</li></ul>\n          </div>\n<p>The maximum and average values are equal: <span class=\"math display\">\\[\nu_z|_{max} = u_z|_{avg} = u_z\n\\]</span> and the flow rate is: <span class=\"math display\">\\[\nQ = Au_z = \\pi R^2u_z\n\\]</span> And there is no friction shear stress at walls.</p>\n<h4 id=\"channel-flow\">2.3.2 Channel flow</h4>\n<p>Channel flow describes a three-dimensional flow confined between two parallel plates and driven similarly to pipe flow by a pressure gradient.</p>\n<p><img src=\"Channel flow.png\" alt=\"Channel flow between two parallel plates and driven by a pressure gradient in the x direction.\" style=\"zoom:80%;\" /></p>\n<div class=\"note note-info\">\n            <p>Assumptions:</p><ul><li>Laminar flow</li><li>Incompressible</li><li>Steady</li><li>Homogeneous in <span class=\"math inline\">\\(x\\)</span> and <span class=\"math inline\">\\(z\\)</span> directions</li><li>viscous</li></ul>\n          </div>\n<p>Similar to the Poiseuille flow, yet in the cartesian coordinate, the velocity is defined as: <span class=\"math display\">\\[\n\\mathbf{V} = u_x(y)\\mathbf{\\hat{x}}\n\\]</span> And the N-S equation is reduced to: <span class=\"math display\">\\[\n0 = -\\partial_xp+\\mu\\partial_y^2u_x\n\\]</span> with the boundary conditions: <span class=\"math display\">\\[\n\\mathbf{V}|_{y=\\pm h} = \\mathbf{0}\n\\]</span> The velocity is therefore: <span class=\"math display\">\\[\n\\color{purple}\nu_x = \\frac{\\partial_xph^2}{2\\mu}\\left(\\frac{y^2}{h^2}-1\\right)\n\\]</span> This is also called <strong>plane Poiseuille flow</strong>.</p>\n<h4 id=\"plane-couette-flow\">2.3.3 Plane Couette flow</h4>\n<p>Plane Couette flow describes a three-dimensional flow confined between two parallel plates yet driven by sliding walls.</p>\n<p><img src=\"Plane Couette flow.png\" alt=\"Plane Couette flow between two parallel plates and driven by sliding walls.\" style=\"zoom:80%;\" /></p>\n<div class=\"note note-info\">\n            <p>Same assumptions are adopted as the channel flow.</p>\n          </div>\n<p>Similar to the channel flow, the velocity governing equation is: <span class=\"math display\">\\[\n0 = \\mu\\partial_y^2u_x\n\\]</span> Yet the boundary conditions are changed to be: <span class=\"math display\">\\[\n\\begin{aligned}\n&amp;u_x|_{y=h} = U \\\\\n&amp;u_x|_{y=-h} = -U\n\\end{aligned}\n\\]</span> As the velocity function become: <span class=\"math display\">\\[\n\\color{purple}\nu_x =- \\frac{ U}{h}y\n\\]</span></p>\n<h2 id=\"viscous-losses\">3 Viscous losses</h2>\n<h3 id=\"pressure-drop\">3.1 Pressure drop</h3>\n<h4 id=\"experimental-evidence\">3.1.1 Experimental evidence</h4>\n<p>In 1839, Hagen studied water flows in long brass pipes and hinted at the possible existence of two different regimes of viscous flows: laminar and turbulent. He characterised, in particular, laminar flows through the following law: <span class=\"math display\">\\[\n\\Delta p = k\\frac{LQ}{R^4}+\\mathrm{entrance~effects}\n\\]</span> where <span class=\"math inline\">\\(k = Const.\\)</span>, <span class=\"math inline\">\\(L\\)</span> is the length of the pipe, <span class=\"math inline\">\\(Q\\)</span> the flow rate and <span class=\"math inline\">\\(R\\)</span> the radius of the pipe.</p>\n<p>As he increased Q beyond a certain threshold, Hagen observed that this law broke down, and deduced the existence of a second regime. This experimental observations are easily reproduced and the results sketched in figure below.</p>\n<p><img src=\"Pressure drop.png\" alt=\"Relationship between the pressure drop p and the average velocity V in a pipe with radius 3mm and length 3m. After White, Fluid Mechanics (2011)\" style=\"zoom:50%;\" /></p>\n<h4 id=\"dimensional-analysis\">3.1.2 Dimensional analysis</h4>\n<p>We consider a laminar flow in a horizontal pipe for which density and gravity effects are negligible. The dimensions of related quantities are:</p>\n<ul>\n<li>pressure drop <span class=\"math inline\">\\(\\Delta p\\)</span>: <span class=\"math inline\">\\([\\Delta p] = [ML^{-1}T^{-2}]\\)</span></li>\n<li>flow rate <span class=\"math inline\">\\(Q\\)</span>: <span class=\"math inline\">\\([Q]=[L^3T^-1]\\)</span></li>\n<li>pipe length <span class=\"math inline\">\\(L\\)</span>: <span class=\"math inline\">\\([L]=[L]\\)</span></li>\n<li>pipe radius <span class=\"math inline\">\\(R\\)</span>:<span class=\"math inline\">\\([R]=[L]\\)</span></li>\n<li>fluid's dynamic viscosity <span class=\"math inline\">\\(\\mu\\)</span>: <span class=\"math inline\">\\([\\mu]=[ML^-1T^-1]\\)</span></li>\n</ul>\n<p>As the pressure gradient is constant along the pipe and the flow fully characterised by the radial direction only, we can write <span class=\"math display\">\\[\n\\frac{\\Delta p}{L}=\\mathcal{F}(Q, R, \\mu)\n\\]</span> We note that the left-hand-side has dimension proportional to a mass M and that only the dynamic viscosity has dimension proportional to a mass. We can then divide by the dynamic viscosity to get rid of this dimension. <span class=\"math display\">\\[\n\\frac{\\Delta p}{\\mu L}=\\mathcal{F}(Q, R)\n\\]</span> Similarly, to get rid of the length dimension, multiply by <span class=\"math inline\">\\(R\\)</span>. Then divide by <span class=\"math inline\">\\(R^3\\)</span>. <span class=\"math display\">\\[\n\\frac{\\Delta p R}{\\mu L}=\\mathcal{F}(\\frac{Q}{R^3})\n\\]</span> At this stage, both the left-hand-side and the right-hand-side terms are both homogeneous to the inverse of a time. Upon dividing the one by the other, we obtain the following relationship: <span class=\"math display\">\\[\n\\frac{\\Delta p R^4}{\\mu LQ}=Const.\n\\]</span> which provide the following pressure loss drop law: <span class=\"math display\">\\[\n\\Delta p = C_{onst.} \\mu\\frac{ LQ}{ R^4}\n\\]</span> This law is very similar to that obtained experimentally by Hagen. In particular, it shows that Hagens constant <span class=\"math inline\">\\(k\\)</span> is homogeneous to a dynamic viscosity.</p>\n<h4 id=\"theoretical-answer\">3.1.3 Theoretical answer</h4>\n<p>Recall the streamwise velocity reads: <span class=\"math display\">\\[\nu_z=\\frac{R^2\\partial_z p}{4\\mu}\\left(\\frac{r^2}{R^2}-1\\right)\n\\]</span> giving the following flow rate: <span class=\"math display\">\\[\nQ = -\\frac{\\pi R^4\\Delta p}{8\\mu L}\n\\]</span> And the $p $ as a function of <span class=\"math inline\">\\(Q,R,\\mu,L\\)</span> reads: <span class=\"math display\">\\[\n\\color{purple}\n\\Delta p = \\frac{8}{\\pi}\\mu\\frac{LQ}{R^4}\n\\]</span></p>\n<h3 id=\"head-loss\">3.2 Head loss</h3>\n<h4 id=\"the-bernoulli-equation\">3.2.1 The Bernoulli equation</h4>\n<p>As a result of the friction between the fluid and the wall, the energy and head decrease between these two sections. We take this into account by adding a term to the Bernoulli equation as: <span class=\"math display\">\\[\n\\frac{p_1}{\\rho g}+\\frac{u_1^2}{2g}+z_1 = \\frac{p_2}{\\rho g}+\\frac{u_2^2}{2g}+z_2+h_f\n\\]</span> where <span class=\"math inline\">\\(h_f\\)</span> is called <strong>head loss</strong> and accounts for the viscous dissipation. The equivalent loss of energy per unit volume is <span class=\"math inline\">\\(\\rho ghf\\)</span>. Relevantly, <span class=\"math inline\">\\(\\frac{p}{\\rho g}\\)</span> is called <strong>pressure head</strong> and <span class=\"math inline\">\\(\\frac{u^2}{2g}\\)</span> is called <strong>kinetic head</strong>.</p>\n<div class=\"note note-info\">\n            <p>Conditions:</p><ul><li>Steady</li><li>Incompressible</li><li>Streamwise</li><li><strong>Viscous</strong>.</li></ul>\n          </div>\n<h4 id=\"application-to-pipe-flow\">3.2.2 Application to pipe flow</h4>\n<p><img src=\"inclined pipe.png\" alt=\"Sketch of an inclined pipe. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" /></p>\n<p>Given a inclined laminar pipe. The velocity of the fluid is invariant with the streamwise direction <span class=\"math inline\">\\(x\\)</span>, so <span class=\"math inline\">\\(u_1= u_2\\)</span>. We can then express the head loss: <span class=\"math display\">\\[\nh_f = \\frac{\\Delta p}{\\rho g}+\\Delta z\n\\]</span> Apply the momentum equation for the control volume shown above: <span class=\"math display\">\\[\n\\Sigma F_x = \\rho\\pi R^2\\left(u_{2avg}^2-u_{1avg}^2\\right)\n\\]</span> There are three forces acting on the fluid in the x direction</p>\n<ul>\n<li>pressure: <span class=\"math inline\">\\(\\Delta p\\pi R^2\\)</span></li>\n<li>weight: <span class=\"math inline\">\\(\\rho L \\pi R^2 \\sin(\\phi)g\\)</span></li>\n<li>shear: <span class=\"math inline\">\\(-\\tau_w2\\pi RL\\)</span></li>\n</ul>\n<p>Additionally, with constant fluid velocity i.e. <span class=\"math inline\">\\(u_{1avg} = u_{2avg}\\)</span>, the momentum equation can be simplified as: <span class=\"math display\">\\[\n\\Delta p\\pi R^2+\\rho L \\pi R^2 \\sin(\\phi)g-\\tau_w2\\pi RL=0\n\\]</span> as a result: <span class=\"math display\">\\[\n\\frac{\\Delta p}{\\rho g}+\\Delta z = \\frac{2\\tau_wL}{\\rho gR}\n\\]</span> and the head loss therefore writes: <span class=\"math display\">\\[\n\\color{purple}\nh_f = \\frac{2\\tau_wL}{\\rho gR} = \\frac{4\\tau_wL}{\\rho gd}\n\\]</span> Recall the wall shear for the Poiseuille flow, <span class=\"math inline\">\\(\\tau_w =\\frac{4\\mu u_{avg}}{R}\\)</span> <span class=\"math display\">\\[\n\\color{purple}\nh_f =  \\frac{8\\mu  u_{avg} L}{\\rho gR^2} = \\frac{32\\mu  u_{avg} L}{\\rho gd^2}\n\\]</span></p>\n<h4 id=\"physical-interpretation\">3.2.3 Physical interpretation</h4>\n<p>We can experimentally observe quantities related to the Bernoulli equation. Static pressure tubes directly connected to the side of the pipe directly observe the pressure head <span class=\"math inline\">\\(p/g\\)</span>. When this quantity is summed with the altitude <span class=\"math inline\">\\(z\\)</span> and tracked along the pipe, we obtain the <strong>hydraulic grade line</strong>. The use of Pitot tubes provides additional information: as they are oriented in the direction of the flow, they are sensitive to the fluids velocity and include the kinetic head <span class=\"math inline\">\\(u^2/2g\\)</span>. The line obtained by summing the kinetic head together with the pressure head and the altitude is called <strong>energy grade line</strong>.</p>\n<p>When viscous effects are non-negligible, the head loss can be observed as loss of pressure and therefore as a drop for both lines. This situation is depicted below:</p>\n<p><img src=\"Physical interpretation.png\" alt=\"Physical interpretation of head loss, together with hydraulic and energy grade lines.\" style=\"zoom:48%;\" /></p>\n<h4 id=\"general-formulae-turbulent-flow\">3.2.4 General formulae (Turbulent flow)</h4>\n<p>The theory above only describes the steady laminar flow, but flows are often turbelent in applications. A need for general expression of head loss arose.</p>\n<p>In 1850, Weisbach used physical intuition to lead the way to a unifying theory. He realised that the head loss was proportional to <span class=\"math inline\">\\(L/d\\)</span> and also approximately proportional to <span class=\"math inline\">\\(u_{avg}^2\\)</span> experimentally for turbulent flows. He then suggested the following relationship: <span class=\"math display\">\\[\n\\color{purple}\nh_f = f\\frac{L}{d}\\frac{u_{avg}^2}{2g}\n\\]</span> where f is a non-dimensional parameter called <strong>Darcy friction factor</strong>. Still out of physical intuition, he precised that the friction factor depend on the <strong>Reynolds number</strong>, the <strong>duct shape</strong> and the <strong>roughness of the wall for turbulent flows</strong>.</p>\n<p>For <strong>laminar flow</strong> in a pipe: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{32 \\mu u_{a v g} L}{\\rho g d^{2}} &amp;=f_{l a m} \\frac{L}{d} \\frac{u_{a v g}^{2}}{2 g} \\\\\n\\Rightarrow f_{l a m} &amp;=\\frac{64 \\mu u_{a v g} L d g}{\\rho g d^{2} L u_{a v g}^{2}}, \\\\\n\\Rightarrow f_{\\text {lam }} &amp;=\\frac{64 \\mu}{\\rho d u_{a v g}} \\\\\n\\Rightarrow \\color{purple}{f_{l a m} }&amp; \\color{purple}{=\\frac{64}{R e_{d}}}\n\\end{aligned}\n\\]</span> where <span class=\"math inline\">\\(Re_d\\)</span> denotes the Reynolds number based on the diameter of the pipe</p>\n<p>For <strong>turbulent flow</strong>:</p>\n<p>No theoretical or experimental laws, in 1939, Colebrook provided an interpolation formula of empirical data: <span class=\"math display\">\\[\n\\frac{1}{f^{1 / 2}}=-2 \\log \\left(\\frac{\\epsilon / d}{3.7}+\\frac{2.51}{R e_{d} f^{1 / 2}}\\right)\n\\]</span> where <span class=\"math inline\">\\(\\epsilon/d\\)</span> (<strong>roughness height</strong>) quantifies the relative roughness of the walls, with <span class=\"math inline\">\\(\\epsilon\\)</span> being related to the size of the disturbance from a smooth wall. For a perfectly smooth pipe, <span class=\"math inline\">\\(\\epsilon/d = 0\\)</span>. And this value increase with the roughness of the wall.</p>\n<p>Colebrooks formula is transcendental and cannot be solved by hand. Hence, in 1944, Moody plotted what is now known as the Moody chart (below) to provide directly readable data. This chart is nowadays a standard in the engineering world.</p>\n<p><img src=\"Moody chart.png\" alt=\"The Moody chart representing the friction factor f as a function of the Reynolds number Re and the relative roughness /d of the pipe. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" /></p>\n<h3 id=\"entrance-effects\">3.3 Entrance effects</h3>\n<h4 id=\"definition\">3.3.1 Definition</h4>\n<p>Away from the pipe, the external flow is homogeneous (therefore, not dissipative, or conservative); the flow within the pipe displays vanishing velocity at the wall due to viscosity. It is dissipative. Thus, there is a region (time if you follow the fluid) where the flow progressively accommodates to the presence of walls. This region is called entrance region and this progress is called the entrance effects, firstly observed by Hagen.</p>\n<p><img src=\"entrance effect.png\" alt=\"Depiction of the entrance region and the accommodation of the fluid to the presence of walls. After White, Fluid Mechanics (2011).\" style=\"zoom:50%;\" /></p>\n<h4 id=\"entrance-length\">3.3.2 Entrance length</h4>\n<p>Use dimensional analysis:</p>\n<p>The entrance length <span class=\"math inline\">\\(L_e=[L]\\)</span> is related to:</p>\n<ul>\n<li>pipe diameter <span class=\"math inline\">\\(d\\)</span>: <span class=\"math inline\">\\([d]=[L]\\)</span></li>\n<li>average fluid velocity <span class=\"math inline\">\\(u_{avg}\\)</span>: <span class=\"math inline\">\\(u_{avg}=[LT^{-1}]\\)</span></li>\n<li>fluid's density <span class=\"math inline\">\\(\\rho\\)</span>: <span class=\"math inline\">\\(\\rho = [ML^{-3}]\\)</span></li>\n<li>fluid's dynamic viscosity <span class=\"math inline\">\\(\\mu\\)</span>: <span class=\"math inline\">\\(\\mu = [ML^{-1}T^{-1}]\\)</span></li>\n</ul>\n<p>As <span class=\"math inline\">\\([L_e/d]=[1]\\)</span>, combine other quantities to get a dimensionless product: <span class=\"math display\">\\[\n\\begin{aligned}\nu_{avg}^a \\rho^b \\mu^c d^d &amp;= L^{a}T^{-a}M^{b}L^{-3b}M^{c}L^{-c}T^{-c}L^d \\\\\n&amp;= L^{a-3b-c+d}T^{-a-c}M^{b+c} = L^0T^0M^0\\\\\n\\Rightarrow \\quad \n&amp;\\left\\{\\begin{array}{l}\na-3b-c+d=0 \\\\\n-a-c=0 \\\\\nb+c=0\n\\end{array}\\right.\\\\\n\\Rightarrow \\quad \n&amp;a=b=d=-c\n\\end{aligned}\n\\]</span> As a result, let <span class=\"math inline\">\\(c=\\gamma\\)</span>: <span class=\"math display\">\\[\n\\left[\\frac{L_{e}}{d}\\right]=\\left[\\frac{\\rho u_{a v g} d}{\\mu}\\right]^{\\gamma}\n\\]</span> The RHS is Reynolds number based on the diameter of the pipe, <span class=\"math inline\">\\(Re_d\\)</span>, finally: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{L_e}{d}= \\mathcal{F}(Re_d^\\gamma)\n\\]</span> the following empirical laws shows that:</p>\n<ul>\n<li>laminar flows: <span class=\"math inline\">\\(\\frac{L_e}{d}\\approx0.06Re_d\\)</span></li>\n<li>turbulent flows: <span class=\"math inline\">\\(\\frac{L_e}{d}\\approx1.6Re_d\\)</span></li>\n</ul>\n<p>Note that these laws provide some interesting differences between laminar and turbulent flows: at <span class=\"math inline\">\\(Re_d= 2000\\)</span>, the entrance length of a laminar flow is <span class=\"math inline\">\\(L_e= 120d\\)</span> while a turbulent flow at <span class=\"math inline\">\\(Re_d= 10000\\)</span> will yield an entrance length of only <span class=\"math inline\">\\(L_e= 16d\\)</span>.</p>"},{"title":"Introduction, Machine learning for fluids dynamics","author":"Ryan LI","toc":true,"declare":true,"index_img":"/index/Lesson_note_ML_for_fluid_dynamics.jpeg","date":"2022-06-01T09:09:11.000Z","_content":"\n> This is a series of brief notes for the popular lesson: [Machine Learning for Fluid Mechanics](https://www.youtube.com/watch?v=8e3OT2K99Kw&list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&index=1), by [Dr. Steve Brunton](https://www.eigensteve.com/). He is not only a good instructor, but an active researcher focusing combining techniques in dimensionality reduction, sparse sensing, and machine learning for the data-driven discovery and control of complex dynamical systems. \n\n<!-- more -->\n\n{% note primary %}\n\nGiven the background of the popularity of ML in the CV area, this lesson focus on how to apply it into the field of traditional physics science and engineering, especially dynamical systems and fluid mechanics. \n\n{% endnote %}\n\n## Introduction\n\nSeveral Q&As:\n\n- Explain machine learning in nutshell.\n\n  Machine learning is a growing set of techniques for high dimensional, non-convex optimisations based on a growing wealth of data.\n\n- Why machine learning suits fluid mechanics? \n\n  Almost all of the fluid dynamics tasks (including Reduction, modelling, control, sensing and closure) can be written as nonlinear, non-convex, multi-scale and very high dimensional (very hard) **optimisation problems** that can't be solved efficiently by traditional methods. Yet it is exactly the field of machine learning. \n\n- What is high dimensional?\n\n  Fluid itself has many degrees of freedom, million or billion degrees of freedom might be needed for simulate a turbulent fluid. And a growing of data leads an explosion of dimension.\n\n- What is non-linear?\n\n  Because fluids is governed by a nonlinear PDE, the NS equation.\n\n- What is non-convex?\n\n  Because there exists local minima in the optimisation problems.\n\n- What kind of ML do we need?\n\n  Interpretable, generalisable i.e. reliable\n\n  Sparse, low-dimensional, robust\n\n## History\n\nMachine learning and fluid dynamics share a long history of interfaces. \n\nPioneered by Rechenberg (1973) and Schwefel (1977), who introduced Evolution Strategies (ES) to design and optimise the profile of a multi-panel plate in order to minimise the drag. The stochastic was introduced and a optimisation similar to the SGD is applied to find the best configuration. \n\nAnother link is Sir James Lighthill's report (1974), which leads the AI winter. His report says AI fails to meet the promises in several fields, such as speech recognition, and natural language processing (NLP).\n\n{% note success %}\n\nThe first time I heard this part of history, I thought this Lighthill was some idiot who lacks insight. I never connected this man with the very person who proposed the Lighthill's Equation with the acoustic analogy method and founded the subject of aeroacoustics, during his PHD!\n\nAlso, it reminds me a talk I saw by Geoffrey Hinton, who said he came to the US because he couldn't find a job in the UK with a degree in AI. Back then (1978) UK refused to fund almost any research topics related to AI and deep learning, partly of Sir Lighthill's consequences. \n\nIt's just like someone of my field narrowly buried the AI halfway yet at the same time influenced a star in this area.\n\n{% endnote %}\n\n## Examples\n\n### POD/PCA/SVA\n\nPOD refers to the PCA done on the flow data. With a series of snapshots of a flow past a cylinder at $Re\\approx100$, subtracting the mean flow and applying a singular value decomposition (SVA), the resulting dominant eigen flows (modes, representing the flow patterns) can be used to construct a **reduced order model** to reproduce the fluid flow field efficiently.\n\n<img src=\"POD Analysis of Cylinder Flow.jpeg\" alt=\"POD Analysis of Cylinder Flow. (a) Original Flow Field (vorticity shown). (b) First 8 dominant POD modes. After https://www.researchgate.net/publication/318710028_Special_Topics_in_CFD/citations\" style=\"zoom:50%;\" />\n\nOne application of this method is shown below[^1], RPCA, a variant of PCA is applied to denoise the artificially pepper-salt corrupted DNS simulation result, and real PIV experiment result. The outliers and the true fluid field are able to separate with a change of the $\\lambda$.\n\n<img src=\"RPCA for denoising.png\" alt=\"RPCA filtering removes noise and outliers in the flow past a cylinder (black circle), from DNS (left) with 10% of velocity field measurements corrupted with salt and pepper noise, and PIV measurements (right). All frames show resultant vorticity fields. As the parameter  is decreased, RPCA filtering is more aggressive, eventually incorrectly identifying coherent flow structures as outliers. After Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., & Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. *Physical Review Fluids*, *5*(5), 054401.\" style=\"zoom:48%;\" />\n\n### Closure modelling\n\n<p align = \"center\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Wr984EOmNaY?start=15\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></p>\n\nThis is a DNS simulation on turbulent boundary layers by HTL. As we zoom in and out, massive fractal, multi-scale patterns are found in space and time. This happens everytime and everywhere when fluid flowing past a wing, car, or inside an engine. But instead of simulating the full DNS equation i.e. resolving the patterns with all the energy scales, we only want to get a reduced order model approximating the small energy scales while focusing on only the scales of energy that resulting in the macroscopic change of the fluid.\n\n{% note info %}\n\nSteve reckons this as the one of the most exciting area where ML can really make a practical impact on everyday industrials. And I heard that after a talk in China, he said a great progress on the area of turbulence might be made in the next 2 decades. (I'm not sure, just heard of it)\n\n{% endnote %}\n\n<img src=\"RANs modeling with DNN.png\" alt=\"The novel architecture used for Rans closure model. Unlike the traditional MLP, an extra Tenser Input Layer, fixed during training, is introduced before the emerging layer. After Ling, J., Kurzawski, A., & Templeton, J. (2016). Reynolds averaged turbulence modelling using deep neural networks with embedded invariance. Journal of Fluid Mechanics, 807, 155-166.\" style=\"zoom:50%;\" />\n\nOne inspiring job[^2] is mentioned which study the RANs closure models. They designed a novel customised structure that embed the physical variables one layer before the output layer of NN. And it inspires us how to \"bake in\" prior knowledge to design a model not only accurate but also physically meaningful\".\n\n### Super resolution\n\nSuper resolution is already a mature field in image sciences, and it can be directly deployed into flow fields.\n\n<img src=\"Super resolution.png\" alt=\"Super resolution reconstruction for turbulence flow, the interpolation error of the SHALLOW DECODER error is about 9.3%. From Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., & Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. *Proceedings of the Royal Society A*, *476*(2238), 20200097.\" style=\"zoom:50%;\" />\n\nAbove is the result of reconstructing the turbulence flow fields([Johns Hopkins Turbulence Database](http://turbulence.pha.jhu.edu/)) from the coarse results obtained by applying an average pooling on the original flow fields[^3]. Multiple MLPs are deployed for this task. \n\n<img src=\"super resolution interpolation and extrapolation comparison.png\" alt=\"Two different training and test set configurations, showing (a) a within sample prediction task and (b) an out of sample prediction task. Here, the gray columns indicate snapshots used for training, while the red columns indicate snapshots used for testing. From Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., & Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. *Proceedings of the Royal Society A*, *476*(2238), 20200097.\" style=\"zoom:50%;\" />\n\nYet the good results only happen at the interpolation scenario, for the extrapolation i.e. prediction task, the reconstruction failed. More physics need to add to make this work.\n\n### Deep autoencoders\n\nThe classical POD/PCA can be written in a form of one-layer linear autoencoder. And instead solving by the analytic SVD algorithm, it can be solved by SGD. So why not change the two-layer, linear autoencoder into the non-linear, multilayer deep autoencoder?\n\n<img src=\"Deep autoencoder reconstruction.png\" alt=\"Deep autoencoder reconstruction examples, (a) NN performs good, (b) NN performs bad. From Milano, M., & Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.\" style=\"zoom:48%;\" />\n\nBased on this thought, Michele Milano and Petros Koumoutsakos deployed neural network modeling for near wall turbulent flow[^4], and compared with POD results, 2 decades ahead of its time. \n\n<img src=\"parabolic reduced order model.png\" alt=\"Transient solution of the NavierStokes equation (solid circles) and Galerkin model B (solid curve). The figure shows (a1(t), a?(t)) of a transient trajectory starting close to the steady NavierStokes solution corresponding to the fixed point in the Galerkin system. From Noack, B. R., Afanasiev, K., MORZYSKI, M., Tadmor, G., & Thiele, F. (2003). A hierarchy of low-dimensional models for the transient and post-transient cylinder wake. *Journal of Fluid Mechanics*, *497*, 335-363\" style=\"zoom:50%;\" />\n\nThis concepts are also developed to build the reduced order models. The pattens extracted from POD or AE can be used to build simple representations in a low dimensional coordinate. For example Bernd R. Noack et als' work[^5] showed the dynamics of transient cylinder wakes can be concluded by a hierarchy of low-dimensional models lived on parabolic bowls.\n\n<img src=\"Schematic overview of the proposed sparse modeling procedure.png\" alt=\"Schematic overview of the proposed sparse modeling procedure. A sparse dynamical system is identified based on features obtained from sensor signals s and the full state u may also be estimated with the ability of PIV snapshots (optional). From Loiseau, J. C., Noack, B. R., & Brunton, S. L. (2018). Sparse reduced-order modelling: sensor-based dynamics to full-state estimation. *Journal of Fluid Mechanics*, *844*, 459-490\" style=\"zoom:50%;\" />\n\nAnd these learned coordinates can be used with data-diven methods like SINDy(the sparse identification of nonlinear dynamics)[^6] to build efficient models for predicting the modes purely from measurement data. Jean-Christophe Loiseau has done a lot work based on this[^7].\n\n### The ultimate goal:  Flow control\n\nIt is a very principled optimisation of the flow field and of the control law with some objectives in mind. Those objectives come from the real wold such as: increasing the lift, decreasing the drag. And these optimisation problems can be solved better with machine learning tools. \n\n<img src=\"Structure of control scheme.png\" alt=\"Structure of the control scheme, where a classical MPC controller based on a model for the full system state is shown in green and a controller using a surrogate model in orange. After. After ieker, K., Peitz, S., Brunton, S. L., Kutz, J. N., & Dellnitz, M. (2019). Deep model predictive control with online learning for complex physical systems. arXiv preprint arXiv:1905.10094.\" style=\"zoom:50%;\" />\n\nAs shown by Bieker at als' diagram[^8], instead of controlling a NS equation, an efficient alternative is controlling  a machine learning surrogate model to realise the real-time control.\n\n## Inspiration from biology\n\nAt last to give us some confidence, Steve mentioned without knowing the NS equations, eagle can somehow manoeuvre the complex turbulence flow by its own sensors on its wings. And the insects, with way small neural system,  they can handle the complex turbulence flow elegantly and seamlessly (I don't feel any self-confidence hearing this). And maybe we can learn something from them and fit into our engineering world. \n\n\n\n[^1]:[Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., & Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. *Physical Review Fluids*, *5*(5), 054401.](https://scholar.google.com/scholar_url?url=https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.5.054401&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=9368717229379747223&ei=eXCcYp2tDZb0yAT_6KLYDw&scisig=AAGBfm3dnQgKr4Ku82Fv4l8EQlBowAQZdQ)\n[^2]:[Ling, J., Kurzawski, A., & Templeton, J. (2016). Reynolds averaged turbulence modelling using deep neural networks with embedded invariance. Journal of Fluid Mechanics, 807, 155-166.](https://scholar.google.com/scholar_url?url=https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/reynolds-averaged-turbulence-modelling-using-deep-neural-networks-with-embedded-invariance/0B280EEE89C74A7BF651C422F8FBD1EB&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=17265256326087997648&ei=iXCcYrLaKuOEywThnbSYCQ&scisig=AAGBfm1mnR-uoBACuF1rcikuCwEx5HWzKw)\n[^3]: [Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., & Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. *Proceedings of the Royal Society A*, *476*(2238), 20200097.](https://scholar.google.com/scholar_url?url=https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2020.0097&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=4644643361595480852&ei=72-cYoPaH8nFywSZv6aYDQ&scisig=AAGBfm3cHzLDR-qONvANNbFZQE0NFSr01Q)\n[^4]:[Milano, M., & Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.](https://www.semanticscholar.org/paper/Neural-network-modeling-for-near-wall-turbulent-Milano-Koumoutsakos/f0e8198850dae31cc9612940581ec8c059c24475)\n[^5]:[Noack, B. R., Afanasiev, K., MORZYSKI, M., Tadmor, G., & Thiele, F. (2003). A hierarchy of low-dimensional models for the transient and post-transient cylinder wake. *Journal of Fluid Mechanics*, *497*, 335-363.](https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/hierarchy-of-lowdimensional-models-for-the-transient-and-posttransient-cylinder-wake/0F114BEB5DD20B7342E99ED8D0070C01)\n[^6]:[Brunton, S. L., Proctor, J. L., & Kutz, J. N. (2016). Discovering governing equations from data by sparse identification of nonlinear dynamical systems. *Proceedings of the national academy of sciences*, *113*(15), 3932-3937.](https://www.pnas.org/content/113/15/3932.short)\n[^7]:[Loiseau, J. C., Noack, B. R., & Brunton, S. L. (2018). Sparse reduced-order modelling: sensor-based dynamics to full-state estimation. *Journal of Fluid Mechanics*, *844*, 459-490.](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4rvzkMEAAAAJ&citation_for_view=4rvzkMEAAAAJ:qxL8FJ1GzNcC)\n[^8]:[Bieker, K., Peitz, S., Brunton, S. L., Kutz, J. N., & Dellnitz, M. (2019). Deep model predictive control with online learning for complex physical systems. *arXiv preprint arXiv:1905.10094*.](https://arxiv.org/abs/1905.10094)\n","source":"_posts/Lesson-note-Machine-learning-for-fluids-dynamics.md","raw":"---\ntitle: 'Introduction, Machine learning for fluids dynamics'\nauthor: Ryan LI\ntoc: true\ndeclare: true\nindex_img: /index/Lesson_note_ML_for_fluid_dynamics.jpeg\ntags:\n  - fluid dynamics\n  - deep learning\ndate: 2022-06-01 17:09:11\n---\n\n> This is a series of brief notes for the popular lesson: [Machine Learning for Fluid Mechanics](https://www.youtube.com/watch?v=8e3OT2K99Kw&list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&index=1), by [Dr. Steve Brunton](https://www.eigensteve.com/). He is not only a good instructor, but an active researcher focusing combining techniques in dimensionality reduction, sparse sensing, and machine learning for the data-driven discovery and control of complex dynamical systems. \n\n<!-- more -->\n\n{% note primary %}\n\nGiven the background of the popularity of ML in the CV area, this lesson focus on how to apply it into the field of traditional physics science and engineering, especially dynamical systems and fluid mechanics. \n\n{% endnote %}\n\n## Introduction\n\nSeveral Q&As:\n\n- Explain machine learning in nutshell.\n\n  Machine learning is a growing set of techniques for high dimensional, non-convex optimisations based on a growing wealth of data.\n\n- Why machine learning suits fluid mechanics? \n\n  Almost all of the fluid dynamics tasks (including Reduction, modelling, control, sensing and closure) can be written as nonlinear, non-convex, multi-scale and very high dimensional (very hard) **optimisation problems** that can't be solved efficiently by traditional methods. Yet it is exactly the field of machine learning. \n\n- What is high dimensional?\n\n  Fluid itself has many degrees of freedom, million or billion degrees of freedom might be needed for simulate a turbulent fluid. And a growing of data leads an explosion of dimension.\n\n- What is non-linear?\n\n  Because fluids is governed by a nonlinear PDE, the NS equation.\n\n- What is non-convex?\n\n  Because there exists local minima in the optimisation problems.\n\n- What kind of ML do we need?\n\n  Interpretable, generalisable i.e. reliable\n\n  Sparse, low-dimensional, robust\n\n## History\n\nMachine learning and fluid dynamics share a long history of interfaces. \n\nPioneered by Rechenberg (1973) and Schwefel (1977), who introduced Evolution Strategies (ES) to design and optimise the profile of a multi-panel plate in order to minimise the drag. The stochastic was introduced and a optimisation similar to the SGD is applied to find the best configuration. \n\nAnother link is Sir James Lighthill's report (1974), which leads the AI winter. His report says AI fails to meet the promises in several fields, such as speech recognition, and natural language processing (NLP).\n\n{% note success %}\n\nThe first time I heard this part of history, I thought this Lighthill was some idiot who lacks insight. I never connected this man with the very person who proposed the Lighthill's Equation with the acoustic analogy method and founded the subject of aeroacoustics, during his PHD!\n\nAlso, it reminds me a talk I saw by Geoffrey Hinton, who said he came to the US because he couldn't find a job in the UK with a degree in AI. Back then (1978) UK refused to fund almost any research topics related to AI and deep learning, partly of Sir Lighthill's consequences. \n\nIt's just like someone of my field narrowly buried the AI halfway yet at the same time influenced a star in this area.\n\n{% endnote %}\n\n## Examples\n\n### POD/PCA/SVA\n\nPOD refers to the PCA done on the flow data. With a series of snapshots of a flow past a cylinder at $Re\\approx100$, subtracting the mean flow and applying a singular value decomposition (SVA), the resulting dominant eigen flows (modes, representing the flow patterns) can be used to construct a **reduced order model** to reproduce the fluid flow field efficiently.\n\n<img src=\"POD Analysis of Cylinder Flow.jpeg\" alt=\"POD Analysis of Cylinder Flow. (a) Original Flow Field (vorticity shown). (b) First 8 dominant POD modes. After https://www.researchgate.net/publication/318710028_Special_Topics_in_CFD/citations\" style=\"zoom:50%;\" />\n\nOne application of this method is shown below[^1], RPCA, a variant of PCA is applied to denoise the artificially pepper-salt corrupted DNS simulation result, and real PIV experiment result. The outliers and the true fluid field are able to separate with a change of the $\\lambda$.\n\n<img src=\"RPCA for denoising.png\" alt=\"RPCA filtering removes noise and outliers in the flow past a cylinder (black circle), from DNS (left) with 10% of velocity field measurements corrupted with salt and pepper noise, and PIV measurements (right). All frames show resultant vorticity fields. As the parameter  is decreased, RPCA filtering is more aggressive, eventually incorrectly identifying coherent flow structures as outliers. After Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., & Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. *Physical Review Fluids*, *5*(5), 054401.\" style=\"zoom:48%;\" />\n\n### Closure modelling\n\n<p align = \"center\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Wr984EOmNaY?start=15\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></p>\n\nThis is a DNS simulation on turbulent boundary layers by HTL. As we zoom in and out, massive fractal, multi-scale patterns are found in space and time. This happens everytime and everywhere when fluid flowing past a wing, car, or inside an engine. But instead of simulating the full DNS equation i.e. resolving the patterns with all the energy scales, we only want to get a reduced order model approximating the small energy scales while focusing on only the scales of energy that resulting in the macroscopic change of the fluid.\n\n{% note info %}\n\nSteve reckons this as the one of the most exciting area where ML can really make a practical impact on everyday industrials. And I heard that after a talk in China, he said a great progress on the area of turbulence might be made in the next 2 decades. (I'm not sure, just heard of it)\n\n{% endnote %}\n\n<img src=\"RANs modeling with DNN.png\" alt=\"The novel architecture used for Rans closure model. Unlike the traditional MLP, an extra Tenser Input Layer, fixed during training, is introduced before the emerging layer. After Ling, J., Kurzawski, A., & Templeton, J. (2016). Reynolds averaged turbulence modelling using deep neural networks with embedded invariance. Journal of Fluid Mechanics, 807, 155-166.\" style=\"zoom:50%;\" />\n\nOne inspiring job[^2] is mentioned which study the RANs closure models. They designed a novel customised structure that embed the physical variables one layer before the output layer of NN. And it inspires us how to \"bake in\" prior knowledge to design a model not only accurate but also physically meaningful\".\n\n### Super resolution\n\nSuper resolution is already a mature field in image sciences, and it can be directly deployed into flow fields.\n\n<img src=\"Super resolution.png\" alt=\"Super resolution reconstruction for turbulence flow, the interpolation error of the SHALLOW DECODER error is about 9.3%. From Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., & Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. *Proceedings of the Royal Society A*, *476*(2238), 20200097.\" style=\"zoom:50%;\" />\n\nAbove is the result of reconstructing the turbulence flow fields([Johns Hopkins Turbulence Database](http://turbulence.pha.jhu.edu/)) from the coarse results obtained by applying an average pooling on the original flow fields[^3]. Multiple MLPs are deployed for this task. \n\n<img src=\"super resolution interpolation and extrapolation comparison.png\" alt=\"Two different training and test set configurations, showing (a) a within sample prediction task and (b) an out of sample prediction task. Here, the gray columns indicate snapshots used for training, while the red columns indicate snapshots used for testing. From Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., & Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. *Proceedings of the Royal Society A*, *476*(2238), 20200097.\" style=\"zoom:50%;\" />\n\nYet the good results only happen at the interpolation scenario, for the extrapolation i.e. prediction task, the reconstruction failed. More physics need to add to make this work.\n\n### Deep autoencoders\n\nThe classical POD/PCA can be written in a form of one-layer linear autoencoder. And instead solving by the analytic SVD algorithm, it can be solved by SGD. So why not change the two-layer, linear autoencoder into the non-linear, multilayer deep autoencoder?\n\n<img src=\"Deep autoencoder reconstruction.png\" alt=\"Deep autoencoder reconstruction examples, (a) NN performs good, (b) NN performs bad. From Milano, M., & Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.\" style=\"zoom:48%;\" />\n\nBased on this thought, Michele Milano and Petros Koumoutsakos deployed neural network modeling for near wall turbulent flow[^4], and compared with POD results, 2 decades ahead of its time. \n\n<img src=\"parabolic reduced order model.png\" alt=\"Transient solution of the NavierStokes equation (solid circles) and Galerkin model B (solid curve). The figure shows (a1(t), a?(t)) of a transient trajectory starting close to the steady NavierStokes solution corresponding to the fixed point in the Galerkin system. From Noack, B. R., Afanasiev, K., MORZYSKI, M., Tadmor, G., & Thiele, F. (2003). A hierarchy of low-dimensional models for the transient and post-transient cylinder wake. *Journal of Fluid Mechanics*, *497*, 335-363\" style=\"zoom:50%;\" />\n\nThis concepts are also developed to build the reduced order models. The pattens extracted from POD or AE can be used to build simple representations in a low dimensional coordinate. For example Bernd R. Noack et als' work[^5] showed the dynamics of transient cylinder wakes can be concluded by a hierarchy of low-dimensional models lived on parabolic bowls.\n\n<img src=\"Schematic overview of the proposed sparse modeling procedure.png\" alt=\"Schematic overview of the proposed sparse modeling procedure. A sparse dynamical system is identified based on features obtained from sensor signals s and the full state u may also be estimated with the ability of PIV snapshots (optional). From Loiseau, J. C., Noack, B. R., & Brunton, S. L. (2018). Sparse reduced-order modelling: sensor-based dynamics to full-state estimation. *Journal of Fluid Mechanics*, *844*, 459-490\" style=\"zoom:50%;\" />\n\nAnd these learned coordinates can be used with data-diven methods like SINDy(the sparse identification of nonlinear dynamics)[^6] to build efficient models for predicting the modes purely from measurement data. Jean-Christophe Loiseau has done a lot work based on this[^7].\n\n### The ultimate goal:  Flow control\n\nIt is a very principled optimisation of the flow field and of the control law with some objectives in mind. Those objectives come from the real wold such as: increasing the lift, decreasing the drag. And these optimisation problems can be solved better with machine learning tools. \n\n<img src=\"Structure of control scheme.png\" alt=\"Structure of the control scheme, where a classical MPC controller based on a model for the full system state is shown in green and a controller using a surrogate model in orange. After. After ieker, K., Peitz, S., Brunton, S. L., Kutz, J. N., & Dellnitz, M. (2019). Deep model predictive control with online learning for complex physical systems. arXiv preprint arXiv:1905.10094.\" style=\"zoom:50%;\" />\n\nAs shown by Bieker at als' diagram[^8], instead of controlling a NS equation, an efficient alternative is controlling  a machine learning surrogate model to realise the real-time control.\n\n## Inspiration from biology\n\nAt last to give us some confidence, Steve mentioned without knowing the NS equations, eagle can somehow manoeuvre the complex turbulence flow by its own sensors on its wings. And the insects, with way small neural system,  they can handle the complex turbulence flow elegantly and seamlessly (I don't feel any self-confidence hearing this). And maybe we can learn something from them and fit into our engineering world. \n\n\n\n[^1]:[Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., & Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. *Physical Review Fluids*, *5*(5), 054401.](https://scholar.google.com/scholar_url?url=https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.5.054401&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=9368717229379747223&ei=eXCcYp2tDZb0yAT_6KLYDw&scisig=AAGBfm3dnQgKr4Ku82Fv4l8EQlBowAQZdQ)\n[^2]:[Ling, J., Kurzawski, A., & Templeton, J. (2016). Reynolds averaged turbulence modelling using deep neural networks with embedded invariance. Journal of Fluid Mechanics, 807, 155-166.](https://scholar.google.com/scholar_url?url=https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/reynolds-averaged-turbulence-modelling-using-deep-neural-networks-with-embedded-invariance/0B280EEE89C74A7BF651C422F8FBD1EB&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=17265256326087997648&ei=iXCcYrLaKuOEywThnbSYCQ&scisig=AAGBfm1mnR-uoBACuF1rcikuCwEx5HWzKw)\n[^3]: [Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., & Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. *Proceedings of the Royal Society A*, *476*(2238), 20200097.](https://scholar.google.com/scholar_url?url=https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2020.0097&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=4644643361595480852&ei=72-cYoPaH8nFywSZv6aYDQ&scisig=AAGBfm3cHzLDR-qONvANNbFZQE0NFSr01Q)\n[^4]:[Milano, M., & Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.](https://www.semanticscholar.org/paper/Neural-network-modeling-for-near-wall-turbulent-Milano-Koumoutsakos/f0e8198850dae31cc9612940581ec8c059c24475)\n[^5]:[Noack, B. R., Afanasiev, K., MORZYSKI, M., Tadmor, G., & Thiele, F. (2003). A hierarchy of low-dimensional models for the transient and post-transient cylinder wake. *Journal of Fluid Mechanics*, *497*, 335-363.](https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/hierarchy-of-lowdimensional-models-for-the-transient-and-posttransient-cylinder-wake/0F114BEB5DD20B7342E99ED8D0070C01)\n[^6]:[Brunton, S. L., Proctor, J. L., & Kutz, J. N. (2016). Discovering governing equations from data by sparse identification of nonlinear dynamical systems. *Proceedings of the national academy of sciences*, *113*(15), 3932-3937.](https://www.pnas.org/content/113/15/3932.short)\n[^7]:[Loiseau, J. C., Noack, B. R., & Brunton, S. L. (2018). Sparse reduced-order modelling: sensor-based dynamics to full-state estimation. *Journal of Fluid Mechanics*, *844*, 459-490.](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4rvzkMEAAAAJ&citation_for_view=4rvzkMEAAAAJ:qxL8FJ1GzNcC)\n[^8]:[Bieker, K., Peitz, S., Brunton, S. L., Kutz, J. N., & Dellnitz, M. (2019). Deep model predictive control with online learning for complex physical systems. *arXiv preprint arXiv:1905.10094*.](https://arxiv.org/abs/1905.10094)\n","slug":"Lesson-note-Machine-learning-for-fluids-dynamics","published":1,"updated":"2022-06-08T18:16:37.950Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz20000el8yb3bsce4sy","content":"<blockquote>\n<p>This is a series of brief notes for the popular lesson: <a href=\"https://www.youtube.com/watch?v=8e3OT2K99Kw&amp;list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&amp;index=1\">Machine Learning for Fluid Mechanics</a>, by <a href=\"https://www.eigensteve.com/\">Dr. Steve Brunton</a>. He is not only a good instructor, but an active researcher focusing combining techniques in dimensionality reduction, sparse sensing, and machine learning for the data-driven discovery and control of complex dynamical systems.</p>\n</blockquote>\n<span id=\"more\"></span>\n<div class=\"note note-primary\">\n            <p>Given the background of the popularity of ML in the CV area, this lesson focus on how to apply it into the field of traditional physics science and engineering, especially dynamical systems and fluid mechanics.</p>\n          </div>\n<h2 id=\"introduction\">Introduction</h2>\n<p>Several Q&amp;As:</p>\n<ul>\n<li><p>Explain machine learning in nutshell.</p>\n<p>Machine learning is a growing set of techniques for high dimensional, non-convex optimisations based on a growing wealth of data.</p></li>\n<li><p>Why machine learning suits fluid mechanics?</p>\n<p>Almost all of the fluid dynamics tasks (including Reduction, modelling, control, sensing and closure) can be written as nonlinear, non-convex, multi-scale and very high dimensional (very hard) <strong>optimisation problems</strong> that can't be solved efficiently by traditional methods. Yet it is exactly the field of machine learning.</p></li>\n<li><p>What is high dimensional?</p>\n<p>Fluid itself has many degrees of freedom, million or billion degrees of freedom might be needed for simulate a turbulent fluid. And a growing of data leads an explosion of dimension.</p></li>\n<li><p>What is non-linear?</p>\n<p>Because fluids is governed by a nonlinear PDE, the NS equation.</p></li>\n<li><p>What is non-convex?</p>\n<p>Because there exists local minima in the optimisation problems.</p></li>\n<li><p>What kind of ML do we need?</p>\n<p>Interpretable, generalisable i.e. reliable</p>\n<p>Sparse, low-dimensional, robust</p></li>\n</ul>\n<h2 id=\"history\">History</h2>\n<p>Machine learning and fluid dynamics share a long history of interfaces.</p>\n<p>Pioneered by Rechenberg (1973) and Schwefel (1977), who introduced Evolution Strategies (ES) to design and optimise the profile of a multi-panel plate in order to minimise the drag. The stochastic was introduced and a optimisation similar to the SGD is applied to find the best configuration.</p>\n<p>Another link is Sir James Lighthill's report (1974), which leads the AI winter. His report says AI fails to meet the promises in several fields, such as speech recognition, and natural language processing (NLP).</p>\n<div class=\"note note-success\">\n            <p>The first time I heard this part of history, I thought this Lighthill was some idiot who lacks insight. I never connected this man with the very person who proposed the Lighthill's Equation with the acoustic analogy method and founded the subject of aeroacoustics, during his PHD!</p><p>Also, it reminds me a talk I saw by Geoffrey Hinton, who said he came to the US because he couldn't find a job in the UK with a degree in AI. Back then (1978) UK refused to fund almost any research topics related to AI and deep learning, partly of Sir Lighthill's consequences.</p><p>It's just like someone of my field narrowly buried the AI halfway yet at the same time influenced a star in this area.</p>\n          </div>\n<h2 id=\"examples\">Examples</h2>\n<h3 id=\"podpcasva\">POD/PCA/SVA</h3>\n<p>POD refers to the PCA done on the flow data. With a series of snapshots of a flow past a cylinder at <span class=\"math inline\">\\(Re\\approx100\\)</span>, subtracting the mean flow and applying a singular value decomposition (SVA), the resulting dominant eigen flows (modes, representing the flow patterns) can be used to construct a <strong>reduced order model</strong> to reproduce the fluid flow field efficiently.</p>\n<p><img src=\"POD Analysis of Cylinder Flow.jpeg\" srcset=\"/img/loading.gif\" lazyload alt=\"POD Analysis of Cylinder Flow. (a) Original Flow Field (vorticity shown). (b) First 8 dominant POD modes. After https://www.researchgate.net/publication/318710028_Special_Topics_in_CFD/citations\" style=\"zoom:50%;\" /></p>\n<p>One application of this method is shown below<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., &amp; Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. Physical Review Fluids, 5(5), 054401.\n\">[1]</span></a></sup>, RPCA, a variant of PCA is applied to denoise the artificially pepper-salt corrupted DNS simulation result, and real PIV experiment result. The outliers and the true fluid field are able to separate with a change of the <span class=\"math inline\">\\(\\lambda\\)</span>.</p>\n<p><img src=\"RPCA for denoising.png\" srcset=\"/img/loading.gif\" lazyload alt=\"RPCA filtering removes noise and outliers in the flow past a cylinder (black circle), from DNS (left) with 10% of velocity field measurements corrupted with salt and pepper noise, and PIV measurements (right). All frames show resultant vorticity fields. As the parameter  is decreased, RPCA filtering is more aggressive, eventually incorrectly identifying coherent flow structures as outliers. After Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., & Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. *Physical Review Fluids*, *5*(5), 054401.\" style=\"zoom:48%;\" /></p>\n<h3 id=\"closure-modelling\">Closure modelling</h3>\n<p align=\"center\">\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Wr984EOmNaY?start=15\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n</iframe>\n</p>\n<p>This is a DNS simulation on turbulent boundary layers by HTL. As we zoom in and out, massive fractal, multi-scale patterns are found in space and time. This happens everytime and everywhere when fluid flowing past a wing, car, or inside an engine. But instead of simulating the full DNS equation i.e. resolving the patterns with all the energy scales, we only want to get a reduced order model approximating the small energy scales while focusing on only the scales of energy that resulting in the macroscopic change of the fluid.</p>\n<div class=\"note note-info\">\n            <p>Steve reckons this as the one of the most exciting area where ML can really make a practical impact on everyday industrials. And I heard that after a talk in China, he said a great progress on the area of turbulence might be made in the next 2 decades. (I'm not sure, just heard of it)</p>\n          </div>\n<p><img src=\"RANs modeling with DNN.png\" srcset=\"/img/loading.gif\" lazyload alt=\"The novel architecture used for Rans closure model. Unlike the traditional MLP, an extra Tenser Input Layer, fixed during training, is introduced before the emerging layer. After Ling, J., Kurzawski, A., & Templeton, J. (2016). Reynolds averaged turbulence modelling using deep neural networks with embedded invariance. Journal of Fluid Mechanics, 807, 155-166.\" style=\"zoom:50%;\" /></p>\n<p>One inspiring job<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Ling, J., Kurzawski, A., &amp; Templeton, J. (2016). Reynolds averaged turbulence modelling using deep neural networks with embedded invariance. Journal of Fluid Mechanics, 807, 155-166.\n\">[2]</span></a></sup> is mentioned which study the RANs closure models. They designed a novel customised structure that embed the physical variables one layer before the output layer of NN. And it inspires us how to \"bake in\" prior knowledge to design a model not only accurate but also physically meaningful\".</p>\n<h3 id=\"super-resolution\">Super resolution</h3>\n<p>Super resolution is already a mature field in image sciences, and it can be directly deployed into flow fields.</p>\n<p><img src=\"Super resolution.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Super resolution reconstruction for turbulence flow, the interpolation error of the SHALLOW DECODER error is about 9.3%. From Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., & Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. *Proceedings of the Royal Society A*, *476*(2238), 20200097.\" style=\"zoom:50%;\" /></p>\n<p>Above is the result of reconstructing the turbulence flow fields(<a href=\"http://turbulence.pha.jhu.edu/\">Johns Hopkins Turbulence Database</a>) from the coarse results obtained by applying an average pooling on the original flow fields<sup id=\"fnref:3\" class=\"footnote-ref\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., &amp; Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. Proceedings of the Royal Society A, 476(2238), 20200097.\n\">[3]</span></a></sup>. Multiple MLPs are deployed for this task.</p>\n<p><img src=\"super resolution interpolation and extrapolation comparison.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Two different training and test set configurations, showing (a) a within sample prediction task and (b) an out of sample prediction task. Here, the gray columns indicate snapshots used for training, while the red columns indicate snapshots used for testing. From Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., & Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. *Proceedings of the Royal Society A*, *476*(2238), 20200097.\" style=\"zoom:50%;\" /></p>\n<p>Yet the good results only happen at the interpolation scenario, for the extrapolation i.e. prediction task, the reconstruction failed. More physics need to add to make this work.</p>\n<h3 id=\"deep-autoencoders\">Deep autoencoders</h3>\n<p>The classical POD/PCA can be written in a form of one-layer linear autoencoder. And instead solving by the analytic SVD algorithm, it can be solved by SGD. So why not change the two-layer, linear autoencoder into the non-linear, multilayer deep autoencoder?</p>\n<p><img src=\"Deep autoencoder reconstruction.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Deep autoencoder reconstruction examples, (a) NN performs good, (b) NN performs bad. From Milano, M., & Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.\" style=\"zoom:48%;\" /></p>\n<p>Based on this thought, Michele Milano and Petros Koumoutsakos deployed neural network modeling for near wall turbulent flow<sup id=\"fnref:4\" class=\"footnote-ref\"><a href=\"#fn:4\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.\n\">[4]</span></a></sup>, and compared with POD results, 2 decades ahead of its time.</p>\n<p><img src=\"parabolic reduced order model.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Transient solution of the NavierStokes equation (solid circles) and Galerkin model B (solid curve). The figure shows (a1(t), a?(t)) of a transient trajectory starting close to the steady NavierStokes solution corresponding to the fixed point in the Galerkin system. From Noack, B. R., Afanasiev, K., MORZYSKI, M., Tadmor, G., & Thiele, F. (2003). A hierarchy of low-dimensional models for the transient and post-transient cylinder wake. *Journal of Fluid Mechanics*, *497*, 335-363\" style=\"zoom:50%;\" /></p>\n<p>This concepts are also developed to build the reduced order models. The pattens extracted from POD or AE can be used to build simple representations in a low dimensional coordinate. For example Bernd R. Noack et als' work<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Noack, B. R., Afanasiev, K., MORZYSKI, M., Tadmor, G., &amp; Thiele, F. (2003). A hierarchy of low-dimensional models for the transient and post-transient cylinder wake. Journal of Fluid Mechanics, 497, 335-363.\n\">[5]</span></a></sup> showed the dynamics of transient cylinder wakes can be concluded by a hierarchy of low-dimensional models lived on parabolic bowls.</p>\n<p><img src=\"Schematic overview of the proposed sparse modeling procedure.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Schematic overview of the proposed sparse modeling procedure. A sparse dynamical system is identified based on features obtained from sensor signals s and the full state u may also be estimated with the ability of PIV snapshots (optional). From Loiseau, J. C., Noack, B. R., & Brunton, S. L. (2018). Sparse reduced-order modelling: sensor-based dynamics to full-state estimation. *Journal of Fluid Mechanics*, *844*, 459-490\" style=\"zoom:50%;\" /></p>\n<p>And these learned coordinates can be used with data-diven methods like SINDy(the sparse identification of nonlinear dynamics)<sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Brunton, S. L., Proctor, J. L., &amp; Kutz, J. N. (2016). Discovering governing equations from data by sparse identification of nonlinear dynamical systems. Proceedings of the national academy of sciences, 113(15), 3932-3937.\n\">[6]</span></a></sup> to build efficient models for predicting the modes purely from measurement data. Jean-Christophe Loiseau has done a lot work based on this<sup id=\"fnref:7\" class=\"footnote-ref\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Loiseau, J. C., Noack, B. R., &amp; Brunton, S. L. (2018). Sparse reduced-order modelling: sensor-based dynamics to full-state estimation. Journal of Fluid Mechanics, 844, 459-490.\n\">[7]</span></a></sup>.</p>\n<h3 id=\"the-ultimate-goal-flow-control\">The ultimate goal: Flow control</h3>\n<p>It is a very principled optimisation of the flow field and of the control law with some objectives in mind. Those objectives come from the real wold such as: increasing the lift, decreasing the drag. And these optimisation problems can be solved better with machine learning tools.</p>\n<p><img src=\"Structure of control scheme.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Structure of the control scheme, where a classical MPC controller based on a model for the full system state is shown in green and a controller using a surrogate model in orange. After. After ieker, K., Peitz, S., Brunton, S. L., Kutz, J. N., & Dellnitz, M. (2019). Deep model predictive control with online learning for complex physical systems. arXiv preprint arXiv:1905.10094.\" style=\"zoom:50%;\" /></p>\n<p>As shown by Bieker at als' diagram<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Bieker, K., Peitz, S., Brunton, S. L., Kutz, J. N., &amp; Dellnitz, M. (2019). Deep model predictive control with online learning for complex physical systems. arXiv preprint arXiv:1905.10094.\n\">[8]</span></a></sup>, instead of controlling a NS equation, an efficient alternative is controlling a machine learning surrogate model to realise the real-time control.</p>\n<h2 id=\"inspiration-from-biology\">Inspiration from biology</h2>\n<p>At last to give us some confidence, Steve mentioned without knowing the NS equations, eagle can somehow manoeuvre the complex turbulence flow by its own sensors on its wings. And the insects, with way small neural system, they can handle the complex turbulence flow elegantly and seamlessly (I don't feel any self-confidence hearing this). And maybe we can learn something from them and fit into our engineering world.</p>\n<section class=\"footnotes\">\n<div class=\"footnote-list\">\n<ol>\n<li>\n<span id=\"fn:1\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.5.054401&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=9368717229379747223&amp;ei=eXCcYp2tDZb0yAT_6KLYDw&amp;scisig=AAGBfm3dnQgKr4Ku82Fv4l8EQlBowAQZdQ\">Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., &amp; Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. <em>Physical Review Fluids</em>, <em>5</em>(5), 054401.</a> <a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:2\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/reynolds-averaged-turbulence-modelling-using-deep-neural-networks-with-embedded-invariance/0B280EEE89C74A7BF651C422F8FBD1EB&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=17265256326087997648&amp;ei=iXCcYrLaKuOEywThnbSYCQ&amp;scisig=AAGBfm1mnR-uoBACuF1rcikuCwEx5HWzKw\">Ling, J., Kurzawski, A., &amp; Templeton, J. (2016). Reynolds averaged turbulence modelling using deep neural networks with embedded invariance. Journal of Fluid Mechanics, 807, 155-166.</a> <a href=\"#fnref:2\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:3\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2020.0097&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=4644643361595480852&amp;ei=72-cYoPaH8nFywSZv6aYDQ&amp;scisig=AAGBfm3cHzLDR-qONvANNbFZQE0NFSr01Q\">Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., &amp; Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. <em>Proceedings of the Royal Society A</em>, <em>476</em>(2238), 20200097.</a> <a href=\"#fnref:3\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:4\" class=\"footnote-text\"><span><a href=\"https://www.semanticscholar.org/paper/Neural-network-modeling-for-near-wall-turbulent-Milano-Koumoutsakos/f0e8198850dae31cc9612940581ec8c059c24475\">Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.</a> <a href=\"#fnref:4\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:5\" class=\"footnote-text\"><span><a href=\"https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/hierarchy-of-lowdimensional-models-for-the-transient-and-posttransient-cylinder-wake/0F114BEB5DD20B7342E99ED8D0070C01\">Noack, B. R., Afanasiev, K., MORZYSKI, M., Tadmor, G., &amp; Thiele, F. (2003). A hierarchy of low-dimensional models for the transient and post-transient cylinder wake. <em>Journal of Fluid Mechanics</em>, <em>497</em>, 335-363.</a> <a href=\"#fnref:5\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:6\" class=\"footnote-text\"><span><a href=\"https://www.pnas.org/content/113/15/3932.short\">Brunton, S. L., Proctor, J. L., &amp; Kutz, J. N. (2016). Discovering governing equations from data by sparse identification of nonlinear dynamical systems. <em>Proceedings of the national academy of sciences</em>, <em>113</em>(15), 3932-3937.</a> <a href=\"#fnref:6\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:7\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=4rvzkMEAAAAJ&amp;citation_for_view=4rvzkMEAAAAJ:qxL8FJ1GzNcC\">Loiseau, J. C., Noack, B. R., &amp; Brunton, S. L. (2018). Sparse reduced-order modelling: sensor-based dynamics to full-state estimation. <em>Journal of Fluid Mechanics</em>, <em>844</em>, 459-490.</a> <a href=\"#fnref:7\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:8\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/1905.10094\">Bieker, K., Peitz, S., Brunton, S. L., Kutz, J. N., &amp; Dellnitz, M. (2019). Deep model predictive control with online learning for complex physical systems. <em>arXiv preprint arXiv:1905.10094</em>.</a> <a href=\"#fnref:8\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n</ol>\n</div>\n</section>\n","site":{"data":{}},"wordcount":7467,"excerpt":"<blockquote>\n<p>This is a series of brief notes for the popular lesson: <a href=\"https://www.youtube.com/watch?v=8e3OT2K99Kw&amp;list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&amp;index=1\">Machine Learning for Fluid Mechanics</a>, by <a href=\"https://www.eigensteve.com/\">Dr. Steve Brunton</a>. He is not only a good instructor, but an active researcher focusing combining techniques in dimensionality reduction, sparse sensing, and machine learning for the data-driven discovery and control of complex dynamical systems.</p>\n</blockquote>","more":"<div class=\"note note-primary\">\n            <p>Given the background of the popularity of ML in the CV area, this lesson focus on how to apply it into the field of traditional physics science and engineering, especially dynamical systems and fluid mechanics.</p>\n          </div>\n<h2 id=\"introduction\">Introduction</h2>\n<p>Several Q&amp;As:</p>\n<ul>\n<li><p>Explain machine learning in nutshell.</p>\n<p>Machine learning is a growing set of techniques for high dimensional, non-convex optimisations based on a growing wealth of data.</p></li>\n<li><p>Why machine learning suits fluid mechanics?</p>\n<p>Almost all of the fluid dynamics tasks (including Reduction, modelling, control, sensing and closure) can be written as nonlinear, non-convex, multi-scale and very high dimensional (very hard) <strong>optimisation problems</strong> that can't be solved efficiently by traditional methods. Yet it is exactly the field of machine learning.</p></li>\n<li><p>What is high dimensional?</p>\n<p>Fluid itself has many degrees of freedom, million or billion degrees of freedom might be needed for simulate a turbulent fluid. And a growing of data leads an explosion of dimension.</p></li>\n<li><p>What is non-linear?</p>\n<p>Because fluids is governed by a nonlinear PDE, the NS equation.</p></li>\n<li><p>What is non-convex?</p>\n<p>Because there exists local minima in the optimisation problems.</p></li>\n<li><p>What kind of ML do we need?</p>\n<p>Interpretable, generalisable i.e. reliable</p>\n<p>Sparse, low-dimensional, robust</p></li>\n</ul>\n<h2 id=\"history\">History</h2>\n<p>Machine learning and fluid dynamics share a long history of interfaces.</p>\n<p>Pioneered by Rechenberg (1973) and Schwefel (1977), who introduced Evolution Strategies (ES) to design and optimise the profile of a multi-panel plate in order to minimise the drag. The stochastic was introduced and a optimisation similar to the SGD is applied to find the best configuration.</p>\n<p>Another link is Sir James Lighthill's report (1974), which leads the AI winter. His report says AI fails to meet the promises in several fields, such as speech recognition, and natural language processing (NLP).</p>\n<div class=\"note note-success\">\n            <p>The first time I heard this part of history, I thought this Lighthill was some idiot who lacks insight. I never connected this man with the very person who proposed the Lighthill's Equation with the acoustic analogy method and founded the subject of aeroacoustics, during his PHD!</p><p>Also, it reminds me a talk I saw by Geoffrey Hinton, who said he came to the US because he couldn't find a job in the UK with a degree in AI. Back then (1978) UK refused to fund almost any research topics related to AI and deep learning, partly of Sir Lighthill's consequences.</p><p>It's just like someone of my field narrowly buried the AI halfway yet at the same time influenced a star in this area.</p>\n          </div>\n<h2 id=\"examples\">Examples</h2>\n<h3 id=\"podpcasva\">POD/PCA/SVA</h3>\n<p>POD refers to the PCA done on the flow data. With a series of snapshots of a flow past a cylinder at <span class=\"math inline\">\\(Re\\approx100\\)</span>, subtracting the mean flow and applying a singular value decomposition (SVA), the resulting dominant eigen flows (modes, representing the flow patterns) can be used to construct a <strong>reduced order model</strong> to reproduce the fluid flow field efficiently.</p>\n<p><img src=\"POD Analysis of Cylinder Flow.jpeg\" alt=\"POD Analysis of Cylinder Flow. (a) Original Flow Field (vorticity shown). (b) First 8 dominant POD modes. After https://www.researchgate.net/publication/318710028_Special_Topics_in_CFD/citations\" style=\"zoom:50%;\" /></p>\n<p>One application of this method is shown below<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., &amp; Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. Physical Review Fluids, 5(5), 054401.\n\">[1]</span></a></sup>, RPCA, a variant of PCA is applied to denoise the artificially pepper-salt corrupted DNS simulation result, and real PIV experiment result. The outliers and the true fluid field are able to separate with a change of the <span class=\"math inline\">\\(\\lambda\\)</span>.</p>\n<p><img src=\"RPCA for denoising.png\" alt=\"RPCA filtering removes noise and outliers in the flow past a cylinder (black circle), from DNS (left) with 10% of velocity field measurements corrupted with salt and pepper noise, and PIV measurements (right). All frames show resultant vorticity fields. As the parameter  is decreased, RPCA filtering is more aggressive, eventually incorrectly identifying coherent flow structures as outliers. After Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., & Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. *Physical Review Fluids*, *5*(5), 054401.\" style=\"zoom:48%;\" /></p>\n<h3 id=\"closure-modelling\">Closure modelling</h3>\n<p align=\"center\">\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Wr984EOmNaY?start=15\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n</iframe>\n</p>\n<p>This is a DNS simulation on turbulent boundary layers by HTL. As we zoom in and out, massive fractal, multi-scale patterns are found in space and time. This happens everytime and everywhere when fluid flowing past a wing, car, or inside an engine. But instead of simulating the full DNS equation i.e. resolving the patterns with all the energy scales, we only want to get a reduced order model approximating the small energy scales while focusing on only the scales of energy that resulting in the macroscopic change of the fluid.</p>\n<div class=\"note note-info\">\n            <p>Steve reckons this as the one of the most exciting area where ML can really make a practical impact on everyday industrials. And I heard that after a talk in China, he said a great progress on the area of turbulence might be made in the next 2 decades. (I'm not sure, just heard of it)</p>\n          </div>\n<p><img src=\"RANs modeling with DNN.png\" alt=\"The novel architecture used for Rans closure model. Unlike the traditional MLP, an extra Tenser Input Layer, fixed during training, is introduced before the emerging layer. After Ling, J., Kurzawski, A., & Templeton, J. (2016). Reynolds averaged turbulence modelling using deep neural networks with embedded invariance. Journal of Fluid Mechanics, 807, 155-166.\" style=\"zoom:50%;\" /></p>\n<p>One inspiring job<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Ling, J., Kurzawski, A., &amp; Templeton, J. (2016). Reynolds averaged turbulence modelling using deep neural networks with embedded invariance. Journal of Fluid Mechanics, 807, 155-166.\n\">[2]</span></a></sup> is mentioned which study the RANs closure models. They designed a novel customised structure that embed the physical variables one layer before the output layer of NN. And it inspires us how to \"bake in\" prior knowledge to design a model not only accurate but also physically meaningful\".</p>\n<h3 id=\"super-resolution\">Super resolution</h3>\n<p>Super resolution is already a mature field in image sciences, and it can be directly deployed into flow fields.</p>\n<p><img src=\"Super resolution.png\" alt=\"Super resolution reconstruction for turbulence flow, the interpolation error of the SHALLOW DECODER error is about 9.3%. From Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., & Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. *Proceedings of the Royal Society A*, *476*(2238), 20200097.\" style=\"zoom:50%;\" /></p>\n<p>Above is the result of reconstructing the turbulence flow fields(<a href=\"http://turbulence.pha.jhu.edu/\">Johns Hopkins Turbulence Database</a>) from the coarse results obtained by applying an average pooling on the original flow fields<sup id=\"fnref:3\" class=\"footnote-ref\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., &amp; Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. Proceedings of the Royal Society A, 476(2238), 20200097.\n\">[3]</span></a></sup>. Multiple MLPs are deployed for this task.</p>\n<p><img src=\"super resolution interpolation and extrapolation comparison.png\" alt=\"Two different training and test set configurations, showing (a) a within sample prediction task and (b) an out of sample prediction task. Here, the gray columns indicate snapshots used for training, while the red columns indicate snapshots used for testing. From Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., & Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. *Proceedings of the Royal Society A*, *476*(2238), 20200097.\" style=\"zoom:50%;\" /></p>\n<p>Yet the good results only happen at the interpolation scenario, for the extrapolation i.e. prediction task, the reconstruction failed. More physics need to add to make this work.</p>\n<h3 id=\"deep-autoencoders\">Deep autoencoders</h3>\n<p>The classical POD/PCA can be written in a form of one-layer linear autoencoder. And instead solving by the analytic SVD algorithm, it can be solved by SGD. So why not change the two-layer, linear autoencoder into the non-linear, multilayer deep autoencoder?</p>\n<p><img src=\"Deep autoencoder reconstruction.png\" alt=\"Deep autoencoder reconstruction examples, (a) NN performs good, (b) NN performs bad. From Milano, M., & Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.\" style=\"zoom:48%;\" /></p>\n<p>Based on this thought, Michele Milano and Petros Koumoutsakos deployed neural network modeling for near wall turbulent flow<sup id=\"fnref:4\" class=\"footnote-ref\"><a href=\"#fn:4\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.\n\">[4]</span></a></sup>, and compared with POD results, 2 decades ahead of its time.</p>\n<p><img src=\"parabolic reduced order model.png\" alt=\"Transient solution of the NavierStokes equation (solid circles) and Galerkin model B (solid curve). The figure shows (a1(t), a?(t)) of a transient trajectory starting close to the steady NavierStokes solution corresponding to the fixed point in the Galerkin system. From Noack, B. R., Afanasiev, K., MORZYSKI, M., Tadmor, G., & Thiele, F. (2003). A hierarchy of low-dimensional models for the transient and post-transient cylinder wake. *Journal of Fluid Mechanics*, *497*, 335-363\" style=\"zoom:50%;\" /></p>\n<p>This concepts are also developed to build the reduced order models. The pattens extracted from POD or AE can be used to build simple representations in a low dimensional coordinate. For example Bernd R. Noack et als' work<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Noack, B. R., Afanasiev, K., MORZYSKI, M., Tadmor, G., &amp; Thiele, F. (2003). A hierarchy of low-dimensional models for the transient and post-transient cylinder wake. Journal of Fluid Mechanics, 497, 335-363.\n\">[5]</span></a></sup> showed the dynamics of transient cylinder wakes can be concluded by a hierarchy of low-dimensional models lived on parabolic bowls.</p>\n<p><img src=\"Schematic overview of the proposed sparse modeling procedure.png\" alt=\"Schematic overview of the proposed sparse modeling procedure. A sparse dynamical system is identified based on features obtained from sensor signals s and the full state u may also be estimated with the ability of PIV snapshots (optional). From Loiseau, J. C., Noack, B. R., & Brunton, S. L. (2018). Sparse reduced-order modelling: sensor-based dynamics to full-state estimation. *Journal of Fluid Mechanics*, *844*, 459-490\" style=\"zoom:50%;\" /></p>\n<p>And these learned coordinates can be used with data-diven methods like SINDy(the sparse identification of nonlinear dynamics)<sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Brunton, S. L., Proctor, J. L., &amp; Kutz, J. N. (2016). Discovering governing equations from data by sparse identification of nonlinear dynamical systems. Proceedings of the national academy of sciences, 113(15), 3932-3937.\n\">[6]</span></a></sup> to build efficient models for predicting the modes purely from measurement data. Jean-Christophe Loiseau has done a lot work based on this<sup id=\"fnref:7\" class=\"footnote-ref\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Loiseau, J. C., Noack, B. R., &amp; Brunton, S. L. (2018). Sparse reduced-order modelling: sensor-based dynamics to full-state estimation. Journal of Fluid Mechanics, 844, 459-490.\n\">[7]</span></a></sup>.</p>\n<h3 id=\"the-ultimate-goal-flow-control\">The ultimate goal: Flow control</h3>\n<p>It is a very principled optimisation of the flow field and of the control law with some objectives in mind. Those objectives come from the real wold such as: increasing the lift, decreasing the drag. And these optimisation problems can be solved better with machine learning tools.</p>\n<p><img src=\"Structure of control scheme.png\" alt=\"Structure of the control scheme, where a classical MPC controller based on a model for the full system state is shown in green and a controller using a surrogate model in orange. After. After ieker, K., Peitz, S., Brunton, S. L., Kutz, J. N., & Dellnitz, M. (2019). Deep model predictive control with online learning for complex physical systems. arXiv preprint arXiv:1905.10094.\" style=\"zoom:50%;\" /></p>\n<p>As shown by Bieker at als' diagram<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Bieker, K., Peitz, S., Brunton, S. L., Kutz, J. N., &amp; Dellnitz, M. (2019). Deep model predictive control with online learning for complex physical systems. arXiv preprint arXiv:1905.10094.\n\">[8]</span></a></sup>, instead of controlling a NS equation, an efficient alternative is controlling a machine learning surrogate model to realise the real-time control.</p>\n<h2 id=\"inspiration-from-biology\">Inspiration from biology</h2>\n<p>At last to give us some confidence, Steve mentioned without knowing the NS equations, eagle can somehow manoeuvre the complex turbulence flow by its own sensors on its wings. And the insects, with way small neural system, they can handle the complex turbulence flow elegantly and seamlessly (I don't feel any self-confidence hearing this). And maybe we can learn something from them and fit into our engineering world.</p>\n<section class=\"footnotes\">\n<div class=\"footnote-list\">\n<ol>\n<li>\n<span id=\"fn:1\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.5.054401&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=9368717229379747223&amp;ei=eXCcYp2tDZb0yAT_6KLYDw&amp;scisig=AAGBfm3dnQgKr4Ku82Fv4l8EQlBowAQZdQ\">Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., &amp; Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. <em>Physical Review Fluids</em>, <em>5</em>(5), 054401.</a> <a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:2\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/reynolds-averaged-turbulence-modelling-using-deep-neural-networks-with-embedded-invariance/0B280EEE89C74A7BF651C422F8FBD1EB&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=17265256326087997648&amp;ei=iXCcYrLaKuOEywThnbSYCQ&amp;scisig=AAGBfm1mnR-uoBACuF1rcikuCwEx5HWzKw\">Ling, J., Kurzawski, A., &amp; Templeton, J. (2016). Reynolds averaged turbulence modelling using deep neural networks with embedded invariance. Journal of Fluid Mechanics, 807, 155-166.</a> <a href=\"#fnref:2\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:3\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2020.0097&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=4644643361595480852&amp;ei=72-cYoPaH8nFywSZv6aYDQ&amp;scisig=AAGBfm3cHzLDR-qONvANNbFZQE0NFSr01Q\">Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., &amp; Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. <em>Proceedings of the Royal Society A</em>, <em>476</em>(2238), 20200097.</a> <a href=\"#fnref:3\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:4\" class=\"footnote-text\"><span><a href=\"https://www.semanticscholar.org/paper/Neural-network-modeling-for-near-wall-turbulent-Milano-Koumoutsakos/f0e8198850dae31cc9612940581ec8c059c24475\">Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.</a> <a href=\"#fnref:4\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:5\" class=\"footnote-text\"><span><a href=\"https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/hierarchy-of-lowdimensional-models-for-the-transient-and-posttransient-cylinder-wake/0F114BEB5DD20B7342E99ED8D0070C01\">Noack, B. R., Afanasiev, K., MORZYSKI, M., Tadmor, G., &amp; Thiele, F. (2003). A hierarchy of low-dimensional models for the transient and post-transient cylinder wake. <em>Journal of Fluid Mechanics</em>, <em>497</em>, 335-363.</a> <a href=\"#fnref:5\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:6\" class=\"footnote-text\"><span><a href=\"https://www.pnas.org/content/113/15/3932.short\">Brunton, S. L., Proctor, J. L., &amp; Kutz, J. N. (2016). Discovering governing equations from data by sparse identification of nonlinear dynamical systems. <em>Proceedings of the national academy of sciences</em>, <em>113</em>(15), 3932-3937.</a> <a href=\"#fnref:6\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:7\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=4rvzkMEAAAAJ&amp;citation_for_view=4rvzkMEAAAAJ:qxL8FJ1GzNcC\">Loiseau, J. C., Noack, B. R., &amp; Brunton, S. L. (2018). Sparse reduced-order modelling: sensor-based dynamics to full-state estimation. <em>Journal of Fluid Mechanics</em>, <em>844</em>, 459-490.</a> <a href=\"#fnref:7\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:8\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/1905.10094\">Bieker, K., Peitz, S., Brunton, S. L., Kutz, J. N., &amp; Dellnitz, M. (2019). Deep model predictive control with online learning for complex physical systems. <em>arXiv preprint arXiv:1905.10094</em>.</a> <a href=\"#fnref:8\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n</ol>\n</div>\n</section>"},{"title":"Patterns, Machine learning for fluids dynamics","author":"Ryan LI","toc":true,"declare":true,"index_img":"/index/Lesson_note_MLFD_patterns.jpeg","date":"2022-06-05T09:42:04.000Z","_content":"\n> [The second course](https://www.youtube.com/watch?v=3fOXIbycAmc&list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&index=2&ab_channel=SteveBrunton) introduces the patterns and coherent structures in high-dimensional fluid dynamics and how machine learning is currently being used to extract them.\n\n<!-- more -->\n\n> This is a series of brief notes for the popular lesson: [Machine Learning for Fluid Mechanics](https://www.youtube.com/watch?v=8e3OT2K99Kw&list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&index=1), by [Dr. Steve Brunton](https://www.eigensteve.com/). He is not only a good instructor, but an active researcher focusing combining techniques in dimensionality reduction, sparse sensing, and machine learning for the data-driven discovery and control of complex dynamical systems. \n\n{% note primary %}\n\nAs we all know, computer vision is one major and advanced field of Machine learning. And the developed CV techniques can be leveraged directly to process fluid fields just by seeing them as images or movies. Some notable works as follows.\n\n{% endnote %}\n\n### Patterns exist\n\n<img src=\"The-von-Karman-vortex-street-generated-by-the-Rishiri-island.jpeg\" alt=\"The von Krmn vortex street generated by the Rishiri island of Hokkaido, Japan (top, photo from NASA, 2001; STS-100). This wake produced at high Reynolds number shares great similarity with the cylinder wake at low Reynolds number (bottom). After https://www.researchgate.net/publication/331768849_Modal_Analysis_of_Fluid_Flows_Applications_and_Outlook/figures?lo=1\" style=\"zoom:50%;\" />\n\nThis is the fundamental fact, even in the most complex systems, patterns exist. Just like there are dominant patterns (normally called latent features in the ML world) to define whether there is a human face or a dog in an image, there are dominant patterers to define a fluid field. \n\n{% note info %}\n\nInteresting facts: In 1987, Sirovich wrote two papers that pioneered in two fields. In April, he applied the PCA/SVD algorithm to human faces to generate the \"eigenfaces\" for face recognition[^1]. Later in October, he applied this same technique into fluid fields to extract the coherent structures of flow fields[^2].\n\n{% endnote %}\n\n### POD/PCA and Autoencoder\n\n#### Background\n\n<img src=\"flow past a cylinder result.gif\" alt=\"Flow past a cylinder result. After https://courses.ansys.com/index.php/courses/simple-approximations-of-fluid-flows/lessons/simulation-examples-homework-quizzes/topic/unsteady-flow-over-a-cylinder-simulation-example/\" style=\"zoom:80%;\" />\n\n**POD:** Given a complex fluid field sequence such as the von Krmn vortex street, one can tell there's a simple regular pattern emerging here even if it has lots of pixels or generated by a sophisticate simulation with large degree of freedom. The patterns can be extracted by simple tools in linear algebra. For example, subtracting off the mean flow then deploying a singular vector decomposition to get a POD expansion as:\n$$\n\\mathbf{u} \\approx \\bar{\\mathbf{u}} + \\sum^r_{k=1}\\boldsymbol{\\psi}_k(x)\\mathbf{a}_k(t)\n$$\nIt writes the spatial-temporal flow field as the mean flow plus the summation of several static eigenflow fields. And the eigen vector $\\mathbf{a}$ changes with time enabling the summation also a function of time $t$.\n\nPOD method has been developed for 50 years and it is a cornerstone on how to analysis complex flow fields. \n\n{% note info %}\n\nNote that this can be seen as a special form of the Fourier decomposition, space-time separation of variables. Fourier transform are very useful to decompose space-time variables and POD is a data-driven generalisation of the Fourier transform that satisfies the  particular fluid boundary conditions and is generated form physical data of an actual flow simulation.\n\n{% endnote %}\n\n<img src=\"PCA as auto-encoder.png\" alt=\"PCA architecture as a one hidden layer, linear auto-encoder. From https://www.jeremyjordan.me/autoencoders/\" style=\"zoom:50%;\" />\n\n**Autoencoder:** In this modern era, the POD/PCA can be rewritten in the form of the neural network as shown above. It works as a bottom neck information filter where the encoder compress the complex data into a latent space and the decoder reconstructs the full flow field image. And the objective is to minimise the distance between the reconstructed image and the original image. And by constraining the hidden layer size as much as possible, the encoder is able to distill the most important fluid coherent structure for reconstruction of the flow field image. \n\n<img src=\"deeper auto-encoder.png\" alt=\"deeper auto-encoder architecture with multiple hidden layers and non-linear activation. From https://www.jeremyjordan.me/autoencoders/\" style=\"zoom:50%;\" />\n\n**Deep Autoencoder:** Now a deep autoencoder with more hidden layers with non-linear activation functions can be deployed to enhance the performance i.e. smaller latent space in the middle, better coordinate representations of the flow field, and simpler representations to work with downstream tasks.\n\n#### Example\n\n<img src=\"Deep autoencoder reconstruction.png\" alt=\"Deep autoencoder reconstruction examples, (a) NN performs good, (b) NN performs bad. From Milano, M., & Koumoutsakos, P. [3]\" style=\"zoom:48%;\" />\n\nMichele Milano and Petros Koumoutsakos are the first to introduce AE into fluid dynamic. They applied neural network modelling for near wall turbulent flow[^3], and compared with POD results, 2 decades ahead of its time. \n\n### Robust PCA\n\nFollowing the above work,  lots of things can be done such as robustify the extraction of patterns, on noisy data, corrupted data or data with outliers. \n\n#### Background\n\n<img src=\"Removing shadows, specularities and saturations from face images.png\" alt=\"Removing shadows, specularities, and saturations from face images. (a) Cropped and aligned images of a persons face under different illuminations from the Extended Yale B database. The size of each image is 192  168 pixels, a total of 58 different illuminations were used for each person. (b) Low-rank approximationL recovered by convex programming. (c) Sparse errorS corresponding to specularities in the eyes, shadows around the nose region, or brightness saturations on the face. Notice in the bottom left that the sparse term also compensates for errors in image acquisition. After Cands et.al[6]\" style=\"zoom:50%;\" />\n\n**PIV:** Particle Image Velocimetry (PIV) is an experimental technique to measure the fluid non-invasively. And the flow field tend to become highly noisy with higher speed and larger window. \n\n**RPCA:** While in the field of the image science, Cands et.al[^6] suggests the principal components of data can be recovered even if part of the data is arbitrarily corrupted. They describes the corrupted data as a superposition of a **Low rank component $L_0$** and a **sparse component $S_0$**, and the robust PCA is presented to recover each components. They also deploy the RPCA to recover the main characters from the background in surveillance videos and remove the shadows and specialities in faces images (as shown above). Why not apply it into the fluid flow images?\n\n{% note success %} \n\n<img src=\"Cross_Correlation_Animation.gif\" alt=\"Animated illustration of Cross Correlation algorithm. After https://commons.wikimedia.org/wiki/File:Cross_Correlation_Animation.gif\" style=\"zoom:80%;\" />\n\nPIV uses the **cross-correlation algorithm**[^4] to determine the displacement of each sub-window. This is the exact same algorithm used in the CNNs. However, they call it \"**convolution**\"[^5], regardless of the fact that the actual convolution method is the transposition of the cross-correlation algorithm.\n\n{% endnote %}\n\n#### Example: \n\n<img src=\"RPCA for denoising.png\" alt=\"RPCA filtering removes noise and outliers in the flow past a cylinder (black circle), from DNS (left) with 10% of velocity field measurements corrupted with salt and pepper noise, and PIV measurements (right). All frames show resultant vorticity fields. As the parameter  is decreased, RPCA filtering is more aggressive, eventually incorrectly identifying coherent flow structures as outliers. After Scherl et.al [7]\" style=\"zoom:48%;\" />\n\nIsabel Scherl et.al[^7] apply the RPCA algorithm to recover the the salt pepper corrupted flow fields, by solving a ralated relaxed optimisation problem. The low rank and sparse component refer to the coherent structure and the noise. And the POD and DMD modes separated from the recovered data can be highly optimised as well.\n\n### Super resolution\n\n#### Background\n\nSuper resolution is already a mature field in image sciences, and it can be directly deployed into flow fields.\n\n#### Example\n\n<img src=\"Super resolution.png\" alt=\"Super resolution reconstruction for turbulence flow, the interpolation error of the SHALLOW DECODER error is about 9.3%. After Erichson, N. B. et.al [8]\" style=\"zoom:50%;\" />\n\nAbove is the result of reconstructing the turbulence flow fields([Johns Hopkins Turbulence Database](http://turbulence.pha.jhu.edu/)) from the coarse results obtained by applying an average pooling on the original flow fields[^3]. Multiple MLPs are deployed for this task. \n\n<img src=\"super resolution interpolation and extrapolation comparison.png\" alt=\"Two different training and test set configurations, showing (a) a within sample prediction task and (b) an out of sample prediction task. Here, the gray columns indicate snapshots used for training, while the red columns indicate snapshots used for testing. After Erichson, N. B. et.al [8]\" style=\"zoom:50%;\" />\n\nYet the good results only happen at the interpolation scenario, for the extrapolation i.e. prediction task, the reconstruction failed. More physics need to add to make this work.\n\n{% note info %}\n\nCompared with the flow field prediction, all the CV tasks with large pretrained models are interpolation tasks. The training data already contains all the data that needed.\n\n{% endnote %}\n\n### Statistical stationarity\n\nIn stead of a simple flow passed a cylinder, most fluid fields in the real life are more complicated. It brings more difficulties for models to reconstruct the fluid.\n\n#### Example\n\n<img src=\"statistical stationarity.png\" alt=\"Singular value spectra for the flows studied. The singular values for vortex shedding past a cylinder (blue) converge quickly, whereas the Gulf of Mexico vorticity data (purple) has a long tail. The sea surface temperature (yellow) and mixing layer vorticity (red) are of intermediate complexity. After Callaham, J. L et.al[9]\" style=\"zoom:28%;\" />\n\nCallaham, J. L et.al [^9] apply robust flow reconstruction via sparse representation on flow pass a cylinder, mixing layer, sea surface temperature and gulf of Mexico. And the modes needed to reconstruct each flow fields increase as shown above.\n\nThis article mainly shows the sparse model outperforms the general model. But in the discussion session, it brings up the key requirements of the reconstruction: **sufficient training data** and **sufficient measured information**. And they quantify the rate of sufficiency in each cases.\n\n<img src=\"sufficient training data.png\" alt=\"Comparison of the amounts of training data needed to predict the test data. After Callaham, J. L et.al[9] \" style=\"zoom:50%;\" />\n\nThe residuals of projecting test data onto the linear subspaces of POD modes of increasing training data is provided. As more data is added to the training set, test set are more likely to be generalised by the training data modes. \n\n{% note danger %}\n\nPersonally, I don't really understand the term **projection**. Whether it is same as **reconstruction** but in an opposite direction? Need more knowledge on it.\n\n{% endnote %}\n\nFor flow pass a cylinder, the model performs well even with very few training data since the flow is simple and periodic. However, the mixing layer and Gulf of Mexico vorticity data have relatively large residual, indicating that there are still new structures that havent been observed in the training data.\n\n<img src=\"sufficient measurements.png\" alt=\"Comparison of the amounts of measurements needed to reconstruct the test data. After Callaham, J. L et.al[9]\" style=\"zoom:50%;\" />\n\nAbove compares the normalised residual error of sparse representation-based reconstructions with increasing number of random point measurements. Similar to the research on amount of the training data, more information is needed from measurements to reconstruct a more complicate flow field.\n\n{% note info %}\n\nThe result might be better if a powerful reconstruction model is used such as the Deep Autoencoder. It is still an open area.\n\n{% endnote %}\n\n### Reference\n\n[^1]: [Sirovich, L., & Kirby, M. (1987). Low-dimensional procedure for the characterization of human faces. *Josa a*, *4*(3), 519-524.](https://scholar.google.com/scholar_url?url=https://www.osapublishing.org/abstract.cfm%3Furi%3Djosaa-4-3-519&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=2157283586688201779&ei=iIGcYpXMOP6J6rQPzPSs-A8&scisig=AAGBfm1UtAAHt6JMQKL_6kZNl8eYHaRD7g)\n[^2]:[Sirovich, L. (1987). Turbulence and the dynamics of coherent structures. I. Coherent structures. *Quarterly of applied mathematics*, *45*(3), 561-571.](https://scholar.google.com/scholar_url?url=https://www.ams.org/qam/1987-45-03/S0033-569X-1987-0910462-6/&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=16097515379918329562&ei=r4GcYrGXCZb0yAT_6KLYDw&scisig=AAGBfm2FAMjBm8d7M0kmOWq1CQ5iribTeg)\n[^3]:[Milano, M., & Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.](https://www.semanticscholar.org/paper/Neural-network-modeling-for-near-wall-turbulent-Milano-Koumoutsakos/f0e8198850dae31cc9612940581ec8c059c24475)\n[^4]: [Keane, R. D., & Adrian, R. J. (1992). Theory of cross-correlation analysis of PIV images. Applied scientific research, 49(3), 191-215. ](https://link.springer.com/article/10.1007/BF00384623)\n[^5]: [LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. *Proceedings of the IEEE*, *86*(11), 2278-2324.](https://ieeexplore.ieee.org/abstract/document/726791/)\n[^6]: [Cands, E. J., Li, X., Ma, Y., & Wright, J. (2011). Robust principal component analysis?. *Journal of the ACM (JACM)*, *58*(3), 1-37.](https://dl.acm.org/doi/abs/10.1145/1970392.1970395)\n[^7]: [Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., & Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. *Physical Review Fluids*, *5*(5), 054401.](https://scholar.google.com/scholar_url?url=https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.5.054401&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=9368717229379747223&ei=eXCcYp2tDZb0yAT_6KLYDw&scisig=AAGBfm3dnQgKr4Ku82Fv4l8EQlBowAQZdQ)\n[^8]:[Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., & Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. *Proceedings of the Royal Society A*, *476*(2238), 20200097.](https://scholar.google.com/scholar_url?url=https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2020.0097&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=4644643361595480852&ei=gcigYuSJPIOM6rQPoeQk&scisig=AAGBfm3cHzLDR-qONvANNbFZQE0NFSr01Q)\n[^9]: [Callaham, J. L., Maeda, K., & Brunton, S. L. (2019). Robust flow reconstruction from limited measurements via sparse representation. *Physical Review Fluids*, *4*(10), 103907.](https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.4.103907)\n","source":"_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics.md","raw":"---\ntitle: 'Patterns, Machine learning for fluids dynamics'\nauthor: Ryan LI\ntoc: true\ndeclare: true\nindex_img: /index/Lesson_note_MLFD_patterns.jpeg\ntags:\n  - fluid dynamics\n  - deep learning\ndate: 2022-06-05 17:42:04\n---\n\n> [The second course](https://www.youtube.com/watch?v=3fOXIbycAmc&list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&index=2&ab_channel=SteveBrunton) introduces the patterns and coherent structures in high-dimensional fluid dynamics and how machine learning is currently being used to extract them.\n\n<!-- more -->\n\n> This is a series of brief notes for the popular lesson: [Machine Learning for Fluid Mechanics](https://www.youtube.com/watch?v=8e3OT2K99Kw&list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&index=1), by [Dr. Steve Brunton](https://www.eigensteve.com/). He is not only a good instructor, but an active researcher focusing combining techniques in dimensionality reduction, sparse sensing, and machine learning for the data-driven discovery and control of complex dynamical systems. \n\n{% note primary %}\n\nAs we all know, computer vision is one major and advanced field of Machine learning. And the developed CV techniques can be leveraged directly to process fluid fields just by seeing them as images or movies. Some notable works as follows.\n\n{% endnote %}\n\n### Patterns exist\n\n<img src=\"The-von-Karman-vortex-street-generated-by-the-Rishiri-island.jpeg\" alt=\"The von Krmn vortex street generated by the Rishiri island of Hokkaido, Japan (top, photo from NASA, 2001; STS-100). This wake produced at high Reynolds number shares great similarity with the cylinder wake at low Reynolds number (bottom). After https://www.researchgate.net/publication/331768849_Modal_Analysis_of_Fluid_Flows_Applications_and_Outlook/figures?lo=1\" style=\"zoom:50%;\" />\n\nThis is the fundamental fact, even in the most complex systems, patterns exist. Just like there are dominant patterns (normally called latent features in the ML world) to define whether there is a human face or a dog in an image, there are dominant patterers to define a fluid field. \n\n{% note info %}\n\nInteresting facts: In 1987, Sirovich wrote two papers that pioneered in two fields. In April, he applied the PCA/SVD algorithm to human faces to generate the \"eigenfaces\" for face recognition[^1]. Later in October, he applied this same technique into fluid fields to extract the coherent structures of flow fields[^2].\n\n{% endnote %}\n\n### POD/PCA and Autoencoder\n\n#### Background\n\n<img src=\"flow past a cylinder result.gif\" alt=\"Flow past a cylinder result. After https://courses.ansys.com/index.php/courses/simple-approximations-of-fluid-flows/lessons/simulation-examples-homework-quizzes/topic/unsteady-flow-over-a-cylinder-simulation-example/\" style=\"zoom:80%;\" />\n\n**POD:** Given a complex fluid field sequence such as the von Krmn vortex street, one can tell there's a simple regular pattern emerging here even if it has lots of pixels or generated by a sophisticate simulation with large degree of freedom. The patterns can be extracted by simple tools in linear algebra. For example, subtracting off the mean flow then deploying a singular vector decomposition to get a POD expansion as:\n$$\n\\mathbf{u} \\approx \\bar{\\mathbf{u}} + \\sum^r_{k=1}\\boldsymbol{\\psi}_k(x)\\mathbf{a}_k(t)\n$$\nIt writes the spatial-temporal flow field as the mean flow plus the summation of several static eigenflow fields. And the eigen vector $\\mathbf{a}$ changes with time enabling the summation also a function of time $t$.\n\nPOD method has been developed for 50 years and it is a cornerstone on how to analysis complex flow fields. \n\n{% note info %}\n\nNote that this can be seen as a special form of the Fourier decomposition, space-time separation of variables. Fourier transform are very useful to decompose space-time variables and POD is a data-driven generalisation of the Fourier transform that satisfies the  particular fluid boundary conditions and is generated form physical data of an actual flow simulation.\n\n{% endnote %}\n\n<img src=\"PCA as auto-encoder.png\" alt=\"PCA architecture as a one hidden layer, linear auto-encoder. From https://www.jeremyjordan.me/autoencoders/\" style=\"zoom:50%;\" />\n\n**Autoencoder:** In this modern era, the POD/PCA can be rewritten in the form of the neural network as shown above. It works as a bottom neck information filter where the encoder compress the complex data into a latent space and the decoder reconstructs the full flow field image. And the objective is to minimise the distance between the reconstructed image and the original image. And by constraining the hidden layer size as much as possible, the encoder is able to distill the most important fluid coherent structure for reconstruction of the flow field image. \n\n<img src=\"deeper auto-encoder.png\" alt=\"deeper auto-encoder architecture with multiple hidden layers and non-linear activation. From https://www.jeremyjordan.me/autoencoders/\" style=\"zoom:50%;\" />\n\n**Deep Autoencoder:** Now a deep autoencoder with more hidden layers with non-linear activation functions can be deployed to enhance the performance i.e. smaller latent space in the middle, better coordinate representations of the flow field, and simpler representations to work with downstream tasks.\n\n#### Example\n\n<img src=\"Deep autoencoder reconstruction.png\" alt=\"Deep autoencoder reconstruction examples, (a) NN performs good, (b) NN performs bad. From Milano, M., & Koumoutsakos, P. [3]\" style=\"zoom:48%;\" />\n\nMichele Milano and Petros Koumoutsakos are the first to introduce AE into fluid dynamic. They applied neural network modelling for near wall turbulent flow[^3], and compared with POD results, 2 decades ahead of its time. \n\n### Robust PCA\n\nFollowing the above work,  lots of things can be done such as robustify the extraction of patterns, on noisy data, corrupted data or data with outliers. \n\n#### Background\n\n<img src=\"Removing shadows, specularities and saturations from face images.png\" alt=\"Removing shadows, specularities, and saturations from face images. (a) Cropped and aligned images of a persons face under different illuminations from the Extended Yale B database. The size of each image is 192  168 pixels, a total of 58 different illuminations were used for each person. (b) Low-rank approximationL recovered by convex programming. (c) Sparse errorS corresponding to specularities in the eyes, shadows around the nose region, or brightness saturations on the face. Notice in the bottom left that the sparse term also compensates for errors in image acquisition. After Cands et.al[6]\" style=\"zoom:50%;\" />\n\n**PIV:** Particle Image Velocimetry (PIV) is an experimental technique to measure the fluid non-invasively. And the flow field tend to become highly noisy with higher speed and larger window. \n\n**RPCA:** While in the field of the image science, Cands et.al[^6] suggests the principal components of data can be recovered even if part of the data is arbitrarily corrupted. They describes the corrupted data as a superposition of a **Low rank component $L_0$** and a **sparse component $S_0$**, and the robust PCA is presented to recover each components. They also deploy the RPCA to recover the main characters from the background in surveillance videos and remove the shadows and specialities in faces images (as shown above). Why not apply it into the fluid flow images?\n\n{% note success %} \n\n<img src=\"Cross_Correlation_Animation.gif\" alt=\"Animated illustration of Cross Correlation algorithm. After https://commons.wikimedia.org/wiki/File:Cross_Correlation_Animation.gif\" style=\"zoom:80%;\" />\n\nPIV uses the **cross-correlation algorithm**[^4] to determine the displacement of each sub-window. This is the exact same algorithm used in the CNNs. However, they call it \"**convolution**\"[^5], regardless of the fact that the actual convolution method is the transposition of the cross-correlation algorithm.\n\n{% endnote %}\n\n#### Example: \n\n<img src=\"RPCA for denoising.png\" alt=\"RPCA filtering removes noise and outliers in the flow past a cylinder (black circle), from DNS (left) with 10% of velocity field measurements corrupted with salt and pepper noise, and PIV measurements (right). All frames show resultant vorticity fields. As the parameter  is decreased, RPCA filtering is more aggressive, eventually incorrectly identifying coherent flow structures as outliers. After Scherl et.al [7]\" style=\"zoom:48%;\" />\n\nIsabel Scherl et.al[^7] apply the RPCA algorithm to recover the the salt pepper corrupted flow fields, by solving a ralated relaxed optimisation problem. The low rank and sparse component refer to the coherent structure and the noise. And the POD and DMD modes separated from the recovered data can be highly optimised as well.\n\n### Super resolution\n\n#### Background\n\nSuper resolution is already a mature field in image sciences, and it can be directly deployed into flow fields.\n\n#### Example\n\n<img src=\"Super resolution.png\" alt=\"Super resolution reconstruction for turbulence flow, the interpolation error of the SHALLOW DECODER error is about 9.3%. After Erichson, N. B. et.al [8]\" style=\"zoom:50%;\" />\n\nAbove is the result of reconstructing the turbulence flow fields([Johns Hopkins Turbulence Database](http://turbulence.pha.jhu.edu/)) from the coarse results obtained by applying an average pooling on the original flow fields[^3]. Multiple MLPs are deployed for this task. \n\n<img src=\"super resolution interpolation and extrapolation comparison.png\" alt=\"Two different training and test set configurations, showing (a) a within sample prediction task and (b) an out of sample prediction task. Here, the gray columns indicate snapshots used for training, while the red columns indicate snapshots used for testing. After Erichson, N. B. et.al [8]\" style=\"zoom:50%;\" />\n\nYet the good results only happen at the interpolation scenario, for the extrapolation i.e. prediction task, the reconstruction failed. More physics need to add to make this work.\n\n{% note info %}\n\nCompared with the flow field prediction, all the CV tasks with large pretrained models are interpolation tasks. The training data already contains all the data that needed.\n\n{% endnote %}\n\n### Statistical stationarity\n\nIn stead of a simple flow passed a cylinder, most fluid fields in the real life are more complicated. It brings more difficulties for models to reconstruct the fluid.\n\n#### Example\n\n<img src=\"statistical stationarity.png\" alt=\"Singular value spectra for the flows studied. The singular values for vortex shedding past a cylinder (blue) converge quickly, whereas the Gulf of Mexico vorticity data (purple) has a long tail. The sea surface temperature (yellow) and mixing layer vorticity (red) are of intermediate complexity. After Callaham, J. L et.al[9]\" style=\"zoom:28%;\" />\n\nCallaham, J. L et.al [^9] apply robust flow reconstruction via sparse representation on flow pass a cylinder, mixing layer, sea surface temperature and gulf of Mexico. And the modes needed to reconstruct each flow fields increase as shown above.\n\nThis article mainly shows the sparse model outperforms the general model. But in the discussion session, it brings up the key requirements of the reconstruction: **sufficient training data** and **sufficient measured information**. And they quantify the rate of sufficiency in each cases.\n\n<img src=\"sufficient training data.png\" alt=\"Comparison of the amounts of training data needed to predict the test data. After Callaham, J. L et.al[9] \" style=\"zoom:50%;\" />\n\nThe residuals of projecting test data onto the linear subspaces of POD modes of increasing training data is provided. As more data is added to the training set, test set are more likely to be generalised by the training data modes. \n\n{% note danger %}\n\nPersonally, I don't really understand the term **projection**. Whether it is same as **reconstruction** but in an opposite direction? Need more knowledge on it.\n\n{% endnote %}\n\nFor flow pass a cylinder, the model performs well even with very few training data since the flow is simple and periodic. However, the mixing layer and Gulf of Mexico vorticity data have relatively large residual, indicating that there are still new structures that havent been observed in the training data.\n\n<img src=\"sufficient measurements.png\" alt=\"Comparison of the amounts of measurements needed to reconstruct the test data. After Callaham, J. L et.al[9]\" style=\"zoom:50%;\" />\n\nAbove compares the normalised residual error of sparse representation-based reconstructions with increasing number of random point measurements. Similar to the research on amount of the training data, more information is needed from measurements to reconstruct a more complicate flow field.\n\n{% note info %}\n\nThe result might be better if a powerful reconstruction model is used such as the Deep Autoencoder. It is still an open area.\n\n{% endnote %}\n\n### Reference\n\n[^1]: [Sirovich, L., & Kirby, M. (1987). Low-dimensional procedure for the characterization of human faces. *Josa a*, *4*(3), 519-524.](https://scholar.google.com/scholar_url?url=https://www.osapublishing.org/abstract.cfm%3Furi%3Djosaa-4-3-519&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=2157283586688201779&ei=iIGcYpXMOP6J6rQPzPSs-A8&scisig=AAGBfm1UtAAHt6JMQKL_6kZNl8eYHaRD7g)\n[^2]:[Sirovich, L. (1987). Turbulence and the dynamics of coherent structures. I. Coherent structures. *Quarterly of applied mathematics*, *45*(3), 561-571.](https://scholar.google.com/scholar_url?url=https://www.ams.org/qam/1987-45-03/S0033-569X-1987-0910462-6/&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=16097515379918329562&ei=r4GcYrGXCZb0yAT_6KLYDw&scisig=AAGBfm2FAMjBm8d7M0kmOWq1CQ5iribTeg)\n[^3]:[Milano, M., & Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.](https://www.semanticscholar.org/paper/Neural-network-modeling-for-near-wall-turbulent-Milano-Koumoutsakos/f0e8198850dae31cc9612940581ec8c059c24475)\n[^4]: [Keane, R. D., & Adrian, R. J. (1992). Theory of cross-correlation analysis of PIV images. Applied scientific research, 49(3), 191-215. ](https://link.springer.com/article/10.1007/BF00384623)\n[^5]: [LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. *Proceedings of the IEEE*, *86*(11), 2278-2324.](https://ieeexplore.ieee.org/abstract/document/726791/)\n[^6]: [Cands, E. J., Li, X., Ma, Y., & Wright, J. (2011). Robust principal component analysis?. *Journal of the ACM (JACM)*, *58*(3), 1-37.](https://dl.acm.org/doi/abs/10.1145/1970392.1970395)\n[^7]: [Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., & Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. *Physical Review Fluids*, *5*(5), 054401.](https://scholar.google.com/scholar_url?url=https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.5.054401&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=9368717229379747223&ei=eXCcYp2tDZb0yAT_6KLYDw&scisig=AAGBfm3dnQgKr4Ku82Fv4l8EQlBowAQZdQ)\n[^8]:[Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., & Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. *Proceedings of the Royal Society A*, *476*(2238), 20200097.](https://scholar.google.com/scholar_url?url=https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2020.0097&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=4644643361595480852&ei=gcigYuSJPIOM6rQPoeQk&scisig=AAGBfm3cHzLDR-qONvANNbFZQE0NFSr01Q)\n[^9]: [Callaham, J. L., Maeda, K., & Brunton, S. L. (2019). Robust flow reconstruction from limited measurements via sparse representation. *Physical Review Fluids*, *4*(10), 103907.](https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.4.103907)\n","slug":"Lesson-note-Patterns-Machine-learning-for-fluids-dynamics","published":1,"updated":"2022-06-08T18:16:23.553Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz21000hl8yb5ocp49zl","content":"<blockquote>\n<p><a href=\"https://www.youtube.com/watch?v=3fOXIbycAmc&amp;list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&amp;index=2&amp;ab_channel=SteveBrunton\">The second course</a> introduces the patterns and coherent structures in high-dimensional fluid dynamics and how machine learning is currently being used to extract them.</p>\n</blockquote>\n<span id=\"more\"></span>\n<blockquote>\n<p>This is a series of brief notes for the popular lesson: <a href=\"https://www.youtube.com/watch?v=8e3OT2K99Kw&amp;list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&amp;index=1\">Machine Learning for Fluid Mechanics</a>, by <a href=\"https://www.eigensteve.com/\">Dr. Steve Brunton</a>. He is not only a good instructor, but an active researcher focusing combining techniques in dimensionality reduction, sparse sensing, and machine learning for the data-driven discovery and control of complex dynamical systems.</p>\n</blockquote>\n<div class=\"note note-primary\">\n            <p>As we all know, computer vision is one major and advanced field of Machine learning. And the developed CV techniques can be leveraged directly to process fluid fields just by seeing them as images or movies. Some notable works as follows.</p>\n          </div>\n<h3 id=\"patterns-exist\">Patterns exist</h3>\n<p><img src=\"The-von-Karman-vortex-street-generated-by-the-Rishiri-island.jpeg\" srcset=\"/img/loading.gif\" lazyload alt=\"The von Krmn vortex street generated by the Rishiri island of Hokkaido, Japan (top, photo from NASA, 2001; STS-100). This wake produced at high Reynolds number shares great similarity with the cylinder wake at low Reynolds number (bottom). After https://www.researchgate.net/publication/331768849_Modal_Analysis_of_Fluid_Flows_Applications_and_Outlook/figures?lo=1\" style=\"zoom:50%;\" /></p>\n<p>This is the fundamental fact, even in the most complex systems, patterns exist. Just like there are dominant patterns (normally called latent features in the ML world) to define whether there is a human face or a dog in an image, there are dominant patterers to define a fluid field.</p>\n<div class=\"note note-info\">\n            <p>Interesting facts: In 1987, Sirovich wrote two papers that pioneered in two fields. In April, he applied the PCA/SVD algorithm to human faces to generate the \"eigenfaces\" for face recognition<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Sirovich, L., &amp; Kirby, M. (1987). Low-dimensional procedure for the characterization of human faces. Josa a, 4(3), 519-524.\">[1]</span></a></sup>. Later in October, he applied this same technique into fluid fields to extract the coherent structures of flow fields<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Sirovich, L. (1987). Turbulence and the dynamics of coherent structures. I. Coherent structures. Quarterly of applied mathematics, 45(3), 561-571.\">[2]</span></a></sup>.</p>\n          </div>\n<h3 id=\"podpca-and-autoencoder\">POD/PCA and Autoencoder</h3>\n<h4 id=\"background\">Background</h4>\n<p><img src=\"flow past a cylinder result.gif\" srcset=\"/img/loading.gif\" lazyload alt=\"Flow past a cylinder result. After https://courses.ansys.com/index.php/courses/simple-approximations-of-fluid-flows/lessons/simulation-examples-homework-quizzes/topic/unsteady-flow-over-a-cylinder-simulation-example/\" style=\"zoom:80%;\" /></p>\n<p><strong>POD:</strong> Given a complex fluid field sequence such as the von Krmn vortex street, one can tell there's a simple regular pattern emerging here even if it has lots of pixels or generated by a sophisticate simulation with large degree of freedom. The patterns can be extracted by simple tools in linear algebra. For example, subtracting off the mean flow then deploying a singular vector decomposition to get a POD expansion as: <span class=\"math display\">\\[\n\\mathbf{u} \\approx \\bar{\\mathbf{u}} + \\sum^r_{k=1}\\boldsymbol{\\psi}_k(x)\\mathbf{a}_k(t)\n\\]</span> It writes the spatial-temporal flow field as the mean flow plus the summation of several static eigenflow fields. And the eigen vector <span class=\"math inline\">\\(\\mathbf{a}\\)</span> changes with time enabling the summation also a function of time <span class=\"math inline\">\\(t\\)</span>.</p>\n<p>POD method has been developed for 50 years and it is a cornerstone on how to analysis complex flow fields.</p>\n<div class=\"note note-info\">\n            <p>Note that this can be seen as a special form of the Fourier decomposition, space-time separation of variables. Fourier transform are very useful to decompose space-time variables and POD is a data-driven generalisation of the Fourier transform that satisfies the particular fluid boundary conditions and is generated form physical data of an actual flow simulation.</p>\n          </div>\n<p><img src=\"PCA as auto-encoder.png\" srcset=\"/img/loading.gif\" lazyload alt=\"PCA architecture as a one hidden layer, linear auto-encoder. From https://www.jeremyjordan.me/autoencoders/\" style=\"zoom:50%;\" /></p>\n<p><strong>Autoencoder:</strong> In this modern era, the POD/PCA can be rewritten in the form of the neural network as shown above. It works as a bottom neck information filter where the encoder compress the complex data into a latent space and the decoder reconstructs the full flow field image. And the objective is to minimise the distance between the reconstructed image and the original image. And by constraining the hidden layer size as much as possible, the encoder is able to distill the most important fluid coherent structure for reconstruction of the flow field image.</p>\n<p><img src=\"deeper auto-encoder.png\" srcset=\"/img/loading.gif\" lazyload alt=\"deeper auto-encoder architecture with multiple hidden layers and non-linear activation. From https://www.jeremyjordan.me/autoencoders/\" style=\"zoom:50%;\" /></p>\n<p><strong>Deep Autoencoder:</strong> Now a deep autoencoder with more hidden layers with non-linear activation functions can be deployed to enhance the performance i.e. smaller latent space in the middle, better coordinate representations of the flow field, and simpler representations to work with downstream tasks.</p>\n<h4 id=\"example\">Example</h4>\n<p><img src=\"Deep autoencoder reconstruction.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Deep autoencoder reconstruction examples, (a) NN performs good, (b) NN performs bad. From Milano, M., & Koumoutsakos, P. [3]\" style=\"zoom:48%;\" /></p>\n<p>Michele Milano and Petros Koumoutsakos are the first to introduce AE into fluid dynamic. They applied neural network modelling for near wall turbulent flow<sup id=\"fnref:3\" class=\"footnote-ref\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.\n\">[3]</span></a></sup>, and compared with POD results, 2 decades ahead of its time.</p>\n<h3 id=\"robust-pca\">Robust PCA</h3>\n<p>Following the above work, lots of things can be done such as robustify the extraction of patterns, on noisy data, corrupted data or data with outliers.</p>\n<h4 id=\"background-1\">Background</h4>\n<p><img src=\"Removing shadows, specularities and saturations from face images.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Removing shadows, specularities, and saturations from face images. (a) Cropped and aligned images of a persons face under different illuminations from the Extended Yale B database. The size of each image is 192  168 pixels, a total of 58 different illuminations were used for each person. (b) Low-rank approximationL recovered by convex programming. (c) Sparse errorS corresponding to specularities in the eyes, shadows around the nose region, or brightness saturations on the face. Notice in the bottom left that the sparse term also compensates for errors in image acquisition. After Cands et.al[6]\" style=\"zoom:50%;\" /></p>\n<p><strong>PIV:</strong> Particle Image Velocimetry (PIV) is an experimental technique to measure the fluid non-invasively. And the flow field tend to become highly noisy with higher speed and larger window.</p>\n<p><strong>RPCA:</strong> While in the field of the image science, Cands et.al<sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Cands, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?. Journal of the ACM (JACM), 58(3), 1-37.\n\">[6]</span></a></sup> suggests the principal components of data can be recovered even if part of the data is arbitrarily corrupted. They describes the corrupted data as a superposition of a <strong>Low rank component <span class=\"math inline\">\\(L_0\\)</span></strong> and a <strong>sparse component <span class=\"math inline\">\\(S_0\\)</span></strong>, and the robust PCA is presented to recover each components. They also deploy the RPCA to recover the main characters from the background in surveillance videos and remove the shadows and specialities in faces images (as shown above). Why not apply it into the fluid flow images?</p>\n<div class=\"note note-success\">\n            <p><img src=\"Cross_Correlation_Animation.gif\" srcset=\"/img/loading.gif\" lazyload alt=\"Animated illustration of Cross Correlation algorithm. After https://commons.wikimedia.org/wiki/File:Cross_Correlation_Animation.gif\" style=\"zoom:80%;\" /></p><p>PIV uses the <strong>cross-correlation algorithm</strong><sup id=\"fnref:4\" class=\"footnote-ref\"><a href=\"#fn:4\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Keane, R. D., &amp; Adrian, R. J. (1992). Theory of cross-correlation analysis of PIV images. Applied scientific research, 49(3), 191-215.\">[4]</span></a></sup> to determine the displacement of each sub-window. This is the exact same algorithm used in the CNNs. However, they call it \"<strong>convolution</strong>\"<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.\">[5]</span></a></sup>, regardless of the fact that the actual convolution method is the transposition of the cross-correlation algorithm.</p>\n          </div>\n<h4 id=\"example-1\">Example:</h4>\n<p><img src=\"RPCA for denoising.png\" srcset=\"/img/loading.gif\" lazyload alt=\"RPCA filtering removes noise and outliers in the flow past a cylinder (black circle), from DNS (left) with 10% of velocity field measurements corrupted with salt and pepper noise, and PIV measurements (right). All frames show resultant vorticity fields. As the parameter  is decreased, RPCA filtering is more aggressive, eventually incorrectly identifying coherent flow structures as outliers. After Scherl et.al [7]\" style=\"zoom:48%;\" /></p>\n<p>Isabel Scherl et.al<sup id=\"fnref:7\" class=\"footnote-ref\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., &amp; Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. Physical Review Fluids, 5(5), 054401.\n\">[7]</span></a></sup> apply the RPCA algorithm to recover the the salt pepper corrupted flow fields, by solving a ralated relaxed optimisation problem. The low rank and sparse component refer to the coherent structure and the noise. And the POD and DMD modes separated from the recovered data can be highly optimised as well.</p>\n<h3 id=\"super-resolution\">Super resolution</h3>\n<h4 id=\"background-2\">Background</h4>\n<p>Super resolution is already a mature field in image sciences, and it can be directly deployed into flow fields.</p>\n<h4 id=\"example-2\">Example</h4>\n<p><img src=\"Super resolution.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Super resolution reconstruction for turbulence flow, the interpolation error of the SHALLOW DECODER error is about 9.3%. After Erichson, N. B. et.al [8]\" style=\"zoom:50%;\" /></p>\n<p>Above is the result of reconstructing the turbulence flow fields(<a href=\"http://turbulence.pha.jhu.edu/\">Johns Hopkins Turbulence Database</a>) from the coarse results obtained by applying an average pooling on the original flow fields<sup id=\"fnref:3\" class=\"footnote-ref\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.\n\">[3]</span></a></sup>. Multiple MLPs are deployed for this task.</p>\n<p><img src=\"super resolution interpolation and extrapolation comparison.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Two different training and test set configurations, showing (a) a within sample prediction task and (b) an out of sample prediction task. Here, the gray columns indicate snapshots used for training, while the red columns indicate snapshots used for testing. After Erichson, N. B. et.al [8]\" style=\"zoom:50%;\" /></p>\n<p>Yet the good results only happen at the interpolation scenario, for the extrapolation i.e. prediction task, the reconstruction failed. More physics need to add to make this work.</p>\n<div class=\"note note-info\">\n            <p>Compared with the flow field prediction, all the CV tasks with large pretrained models are interpolation tasks. The training data already contains all the data that needed.</p>\n          </div>\n<h3 id=\"statistical-stationarity\">Statistical stationarity</h3>\n<p>In stead of a simple flow passed a cylinder, most fluid fields in the real life are more complicated. It brings more difficulties for models to reconstruct the fluid.</p>\n<h4 id=\"example-3\">Example</h4>\n<p><img src=\"statistical stationarity.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Singular value spectra for the flows studied. The singular values for vortex shedding past a cylinder (blue) converge quickly, whereas the Gulf of Mexico vorticity data (purple) has a long tail. The sea surface temperature (yellow) and mixing layer vorticity (red) are of intermediate complexity. After Callaham, J. L et.al[9]\" style=\"zoom:28%;\" /></p>\n<p>Callaham, J. L et.al <sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Callaham, J. L., Maeda, K., &amp; Brunton, S. L. (2019). Robust flow reconstruction from limited measurements via sparse representation. Physical Review Fluids, 4(10), 103907.\n\">[9]</span></a></sup> apply robust flow reconstruction via sparse representation on flow pass a cylinder, mixing layer, sea surface temperature and gulf of Mexico. And the modes needed to reconstruct each flow fields increase as shown above.</p>\n<p>This article mainly shows the sparse model outperforms the general model. But in the discussion session, it brings up the key requirements of the reconstruction: <strong>sufficient training data</strong> and <strong>sufficient measured information</strong>. And they quantify the rate of sufficiency in each cases.</p>\n<p><img src=\"sufficient training data.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Comparison of the amounts of training data needed to predict the test data. After Callaham, J. L et.al[9] \" style=\"zoom:50%;\" /></p>\n<p>The residuals of projecting test data onto the linear subspaces of POD modes of increasing training data is provided. As more data is added to the training set, test set are more likely to be generalised by the training data modes.</p>\n<div class=\"note note-danger\">\n            <p>Personally, I don't really understand the term <strong>projection</strong>. Whether it is same as <strong>reconstruction</strong> but in an opposite direction? Need more knowledge on it.</p>\n          </div>\n<p>For flow pass a cylinder, the model performs well even with very few training data since the flow is simple and periodic. However, the mixing layer and Gulf of Mexico vorticity data have relatively large residual, indicating that there are still new structures that havent been observed in the training data.</p>\n<p><img src=\"sufficient measurements.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Comparison of the amounts of measurements needed to reconstruct the test data. After Callaham, J. L et.al[9]\" style=\"zoom:50%;\" /></p>\n<p>Above compares the normalised residual error of sparse representation-based reconstructions with increasing number of random point measurements. Similar to the research on amount of the training data, more information is needed from measurements to reconstruct a more complicate flow field.</p>\n<div class=\"note note-info\">\n            <p>The result might be better if a powerful reconstruction model is used such as the Deep Autoencoder. It is still an open area.</p>\n          </div>\n<h3 id=\"reference\">Reference</h3>\n<section class=\"footnotes\">\n<div class=\"footnote-list\">\n<ol>\n<li>\n<span id=\"fn:1\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://www.osapublishing.org/abstract.cfm%3Furi%3Djosaa-4-3-519&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=2157283586688201779&amp;ei=iIGcYpXMOP6J6rQPzPSs-A8&amp;scisig=AAGBfm1UtAAHt6JMQKL_6kZNl8eYHaRD7g\">Sirovich, L., &amp; Kirby, M. (1987). Low-dimensional procedure for the characterization of human faces. <em>Josa a</em>, <em>4</em>(3), 519-524.</a> <a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:2\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://www.ams.org/qam/1987-45-03/S0033-569X-1987-0910462-6/&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=16097515379918329562&amp;ei=r4GcYrGXCZb0yAT_6KLYDw&amp;scisig=AAGBfm2FAMjBm8d7M0kmOWq1CQ5iribTeg\">Sirovich, L. (1987). Turbulence and the dynamics of coherent structures. I. Coherent structures. <em>Quarterly of applied mathematics</em>, <em>45</em>(3), 561-571.</a> <a href=\"#fnref:2\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:3\" class=\"footnote-text\"><span><a href=\"https://www.semanticscholar.org/paper/Neural-network-modeling-for-near-wall-turbulent-Milano-Koumoutsakos/f0e8198850dae31cc9612940581ec8c059c24475\">Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.</a> <a href=\"#fnref:3\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:4\" class=\"footnote-text\"><span><a href=\"https://link.springer.com/article/10.1007/BF00384623\">Keane, R. D., &amp; Adrian, R. J. (1992). Theory of cross-correlation analysis of PIV images. Applied scientific research, 49(3), 191-215.</a> <a href=\"#fnref:4\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:5\" class=\"footnote-text\"><span><a href=\"https://ieeexplore.ieee.org/abstract/document/726791/\">LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). Gradient-based learning applied to document recognition. <em>Proceedings of the IEEE</em>, <em>86</em>(11), 2278-2324.</a> <a href=\"#fnref:5\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:6\" class=\"footnote-text\"><span><a href=\"https://dl.acm.org/doi/abs/10.1145/1970392.1970395\">Cands, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?. <em>Journal of the ACM (JACM)</em>, <em>58</em>(3), 1-37.</a> <a href=\"#fnref:6\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:7\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.5.054401&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=9368717229379747223&amp;ei=eXCcYp2tDZb0yAT_6KLYDw&amp;scisig=AAGBfm3dnQgKr4Ku82Fv4l8EQlBowAQZdQ\">Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., &amp; Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. <em>Physical Review Fluids</em>, <em>5</em>(5), 054401.</a> <a href=\"#fnref:7\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:8\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2020.0097&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=4644643361595480852&amp;ei=gcigYuSJPIOM6rQPoeQk&amp;scisig=AAGBfm3cHzLDR-qONvANNbFZQE0NFSr01Q\">Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., &amp; Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. <em>Proceedings of the Royal Society A</em>, <em>476</em>(2238), 20200097.</a> <a href=\"#fnref:8\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:9\" class=\"footnote-text\"><span><a href=\"https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.4.103907\">Callaham, J. L., Maeda, K., &amp; Brunton, S. L. (2019). Robust flow reconstruction from limited measurements via sparse representation. <em>Physical Review Fluids</em>, <em>4</em>(10), 103907.</a> <a href=\"#fnref:9\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n</ol>\n</div>\n</section>\n","site":{"data":{}},"wordcount":7896,"excerpt":"<blockquote>\n<p><a href=\"https://www.youtube.com/watch?v=3fOXIbycAmc&amp;list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&amp;index=2&amp;ab_channel=SteveBrunton\">The second course</a> introduces the patterns and coherent structures in high-dimensional fluid dynamics and how machine learning is currently being used to extract them.</p>\n</blockquote>","more":"<blockquote>\n<p>This is a series of brief notes for the popular lesson: <a href=\"https://www.youtube.com/watch?v=8e3OT2K99Kw&amp;list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&amp;index=1\">Machine Learning for Fluid Mechanics</a>, by <a href=\"https://www.eigensteve.com/\">Dr. Steve Brunton</a>. He is not only a good instructor, but an active researcher focusing combining techniques in dimensionality reduction, sparse sensing, and machine learning for the data-driven discovery and control of complex dynamical systems.</p>\n</blockquote>\n<div class=\"note note-primary\">\n            <p>As we all know, computer vision is one major and advanced field of Machine learning. And the developed CV techniques can be leveraged directly to process fluid fields just by seeing them as images or movies. Some notable works as follows.</p>\n          </div>\n<h3 id=\"patterns-exist\">Patterns exist</h3>\n<p><img src=\"The-von-Karman-vortex-street-generated-by-the-Rishiri-island.jpeg\" alt=\"The von Krmn vortex street generated by the Rishiri island of Hokkaido, Japan (top, photo from NASA, 2001; STS-100). This wake produced at high Reynolds number shares great similarity with the cylinder wake at low Reynolds number (bottom). After https://www.researchgate.net/publication/331768849_Modal_Analysis_of_Fluid_Flows_Applications_and_Outlook/figures?lo=1\" style=\"zoom:50%;\" /></p>\n<p>This is the fundamental fact, even in the most complex systems, patterns exist. Just like there are dominant patterns (normally called latent features in the ML world) to define whether there is a human face or a dog in an image, there are dominant patterers to define a fluid field.</p>\n<div class=\"note note-info\">\n            <p>Interesting facts: In 1987, Sirovich wrote two papers that pioneered in two fields. In April, he applied the PCA/SVD algorithm to human faces to generate the \"eigenfaces\" for face recognition<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Sirovich, L., &amp; Kirby, M. (1987). Low-dimensional procedure for the characterization of human faces. Josa a, 4(3), 519-524.\">[1]</span></a></sup>. Later in October, he applied this same technique into fluid fields to extract the coherent structures of flow fields<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Sirovich, L. (1987). Turbulence and the dynamics of coherent structures. I. Coherent structures. Quarterly of applied mathematics, 45(3), 561-571.\">[2]</span></a></sup>.</p>\n          </div>\n<h3 id=\"podpca-and-autoencoder\">POD/PCA and Autoencoder</h3>\n<h4 id=\"background\">Background</h4>\n<p><img src=\"flow past a cylinder result.gif\" alt=\"Flow past a cylinder result. After https://courses.ansys.com/index.php/courses/simple-approximations-of-fluid-flows/lessons/simulation-examples-homework-quizzes/topic/unsteady-flow-over-a-cylinder-simulation-example/\" style=\"zoom:80%;\" /></p>\n<p><strong>POD:</strong> Given a complex fluid field sequence such as the von Krmn vortex street, one can tell there's a simple regular pattern emerging here even if it has lots of pixels or generated by a sophisticate simulation with large degree of freedom. The patterns can be extracted by simple tools in linear algebra. For example, subtracting off the mean flow then deploying a singular vector decomposition to get a POD expansion as: <span class=\"math display\">\\[\n\\mathbf{u} \\approx \\bar{\\mathbf{u}} + \\sum^r_{k=1}\\boldsymbol{\\psi}_k(x)\\mathbf{a}_k(t)\n\\]</span> It writes the spatial-temporal flow field as the mean flow plus the summation of several static eigenflow fields. And the eigen vector <span class=\"math inline\">\\(\\mathbf{a}\\)</span> changes with time enabling the summation also a function of time <span class=\"math inline\">\\(t\\)</span>.</p>\n<p>POD method has been developed for 50 years and it is a cornerstone on how to analysis complex flow fields.</p>\n<div class=\"note note-info\">\n            <p>Note that this can be seen as a special form of the Fourier decomposition, space-time separation of variables. Fourier transform are very useful to decompose space-time variables and POD is a data-driven generalisation of the Fourier transform that satisfies the particular fluid boundary conditions and is generated form physical data of an actual flow simulation.</p>\n          </div>\n<p><img src=\"PCA as auto-encoder.png\" alt=\"PCA architecture as a one hidden layer, linear auto-encoder. From https://www.jeremyjordan.me/autoencoders/\" style=\"zoom:50%;\" /></p>\n<p><strong>Autoencoder:</strong> In this modern era, the POD/PCA can be rewritten in the form of the neural network as shown above. It works as a bottom neck information filter where the encoder compress the complex data into a latent space and the decoder reconstructs the full flow field image. And the objective is to minimise the distance between the reconstructed image and the original image. And by constraining the hidden layer size as much as possible, the encoder is able to distill the most important fluid coherent structure for reconstruction of the flow field image.</p>\n<p><img src=\"deeper auto-encoder.png\" alt=\"deeper auto-encoder architecture with multiple hidden layers and non-linear activation. From https://www.jeremyjordan.me/autoencoders/\" style=\"zoom:50%;\" /></p>\n<p><strong>Deep Autoencoder:</strong> Now a deep autoencoder with more hidden layers with non-linear activation functions can be deployed to enhance the performance i.e. smaller latent space in the middle, better coordinate representations of the flow field, and simpler representations to work with downstream tasks.</p>\n<h4 id=\"example\">Example</h4>\n<p><img src=\"Deep autoencoder reconstruction.png\" alt=\"Deep autoencoder reconstruction examples, (a) NN performs good, (b) NN performs bad. From Milano, M., & Koumoutsakos, P. [3]\" style=\"zoom:48%;\" /></p>\n<p>Michele Milano and Petros Koumoutsakos are the first to introduce AE into fluid dynamic. They applied neural network modelling for near wall turbulent flow<sup id=\"fnref:3\" class=\"footnote-ref\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.\n\">[3]</span></a></sup>, and compared with POD results, 2 decades ahead of its time.</p>\n<h3 id=\"robust-pca\">Robust PCA</h3>\n<p>Following the above work, lots of things can be done such as robustify the extraction of patterns, on noisy data, corrupted data or data with outliers.</p>\n<h4 id=\"background-1\">Background</h4>\n<p><img src=\"Removing shadows, specularities and saturations from face images.png\" alt=\"Removing shadows, specularities, and saturations from face images. (a) Cropped and aligned images of a persons face under different illuminations from the Extended Yale B database. The size of each image is 192  168 pixels, a total of 58 different illuminations were used for each person. (b) Low-rank approximationL recovered by convex programming. (c) Sparse errorS corresponding to specularities in the eyes, shadows around the nose region, or brightness saturations on the face. Notice in the bottom left that the sparse term also compensates for errors in image acquisition. After Cands et.al[6]\" style=\"zoom:50%;\" /></p>\n<p><strong>PIV:</strong> Particle Image Velocimetry (PIV) is an experimental technique to measure the fluid non-invasively. And the flow field tend to become highly noisy with higher speed and larger window.</p>\n<p><strong>RPCA:</strong> While in the field of the image science, Cands et.al<sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Cands, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?. Journal of the ACM (JACM), 58(3), 1-37.\n\">[6]</span></a></sup> suggests the principal components of data can be recovered even if part of the data is arbitrarily corrupted. They describes the corrupted data as a superposition of a <strong>Low rank component <span class=\"math inline\">\\(L_0\\)</span></strong> and a <strong>sparse component <span class=\"math inline\">\\(S_0\\)</span></strong>, and the robust PCA is presented to recover each components. They also deploy the RPCA to recover the main characters from the background in surveillance videos and remove the shadows and specialities in faces images (as shown above). Why not apply it into the fluid flow images?</p>\n<div class=\"note note-success\">\n            <p><img src=\"Cross_Correlation_Animation.gif\" alt=\"Animated illustration of Cross Correlation algorithm. After https://commons.wikimedia.org/wiki/File:Cross_Correlation_Animation.gif\" style=\"zoom:80%;\" /></p><p>PIV uses the <strong>cross-correlation algorithm</strong><sup id=\"fnref:4\" class=\"footnote-ref\"><a href=\"#fn:4\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Keane, R. D., &amp; Adrian, R. J. (1992). Theory of cross-correlation analysis of PIV images. Applied scientific research, 49(3), 191-215.\">[4]</span></a></sup> to determine the displacement of each sub-window. This is the exact same algorithm used in the CNNs. However, they call it \"<strong>convolution</strong>\"<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.\">[5]</span></a></sup>, regardless of the fact that the actual convolution method is the transposition of the cross-correlation algorithm.</p>\n          </div>\n<h4 id=\"example-1\">Example:</h4>\n<p><img src=\"RPCA for denoising.png\" alt=\"RPCA filtering removes noise and outliers in the flow past a cylinder (black circle), from DNS (left) with 10% of velocity field measurements corrupted with salt and pepper noise, and PIV measurements (right). All frames show resultant vorticity fields. As the parameter  is decreased, RPCA filtering is more aggressive, eventually incorrectly identifying coherent flow structures as outliers. After Scherl et.al [7]\" style=\"zoom:48%;\" /></p>\n<p>Isabel Scherl et.al<sup id=\"fnref:7\" class=\"footnote-ref\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., &amp; Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. Physical Review Fluids, 5(5), 054401.\n\">[7]</span></a></sup> apply the RPCA algorithm to recover the the salt pepper corrupted flow fields, by solving a ralated relaxed optimisation problem. The low rank and sparse component refer to the coherent structure and the noise. And the POD and DMD modes separated from the recovered data can be highly optimised as well.</p>\n<h3 id=\"super-resolution\">Super resolution</h3>\n<h4 id=\"background-2\">Background</h4>\n<p>Super resolution is already a mature field in image sciences, and it can be directly deployed into flow fields.</p>\n<h4 id=\"example-2\">Example</h4>\n<p><img src=\"Super resolution.png\" alt=\"Super resolution reconstruction for turbulence flow, the interpolation error of the SHALLOW DECODER error is about 9.3%. After Erichson, N. B. et.al [8]\" style=\"zoom:50%;\" /></p>\n<p>Above is the result of reconstructing the turbulence flow fields(<a href=\"http://turbulence.pha.jhu.edu/\">Johns Hopkins Turbulence Database</a>) from the coarse results obtained by applying an average pooling on the original flow fields<sup id=\"fnref:3\" class=\"footnote-ref\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.\n\">[3]</span></a></sup>. Multiple MLPs are deployed for this task.</p>\n<p><img src=\"super resolution interpolation and extrapolation comparison.png\" alt=\"Two different training and test set configurations, showing (a) a within sample prediction task and (b) an out of sample prediction task. Here, the gray columns indicate snapshots used for training, while the red columns indicate snapshots used for testing. After Erichson, N. B. et.al [8]\" style=\"zoom:50%;\" /></p>\n<p>Yet the good results only happen at the interpolation scenario, for the extrapolation i.e. prediction task, the reconstruction failed. More physics need to add to make this work.</p>\n<div class=\"note note-info\">\n            <p>Compared with the flow field prediction, all the CV tasks with large pretrained models are interpolation tasks. The training data already contains all the data that needed.</p>\n          </div>\n<h3 id=\"statistical-stationarity\">Statistical stationarity</h3>\n<p>In stead of a simple flow passed a cylinder, most fluid fields in the real life are more complicated. It brings more difficulties for models to reconstruct the fluid.</p>\n<h4 id=\"example-3\">Example</h4>\n<p><img src=\"statistical stationarity.png\" alt=\"Singular value spectra for the flows studied. The singular values for vortex shedding past a cylinder (blue) converge quickly, whereas the Gulf of Mexico vorticity data (purple) has a long tail. The sea surface temperature (yellow) and mixing layer vorticity (red) are of intermediate complexity. After Callaham, J. L et.al[9]\" style=\"zoom:28%;\" /></p>\n<p>Callaham, J. L et.al <sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Callaham, J. L., Maeda, K., &amp; Brunton, S. L. (2019). Robust flow reconstruction from limited measurements via sparse representation. Physical Review Fluids, 4(10), 103907.\n\">[9]</span></a></sup> apply robust flow reconstruction via sparse representation on flow pass a cylinder, mixing layer, sea surface temperature and gulf of Mexico. And the modes needed to reconstruct each flow fields increase as shown above.</p>\n<p>This article mainly shows the sparse model outperforms the general model. But in the discussion session, it brings up the key requirements of the reconstruction: <strong>sufficient training data</strong> and <strong>sufficient measured information</strong>. And they quantify the rate of sufficiency in each cases.</p>\n<p><img src=\"sufficient training data.png\" alt=\"Comparison of the amounts of training data needed to predict the test data. After Callaham, J. L et.al[9] \" style=\"zoom:50%;\" /></p>\n<p>The residuals of projecting test data onto the linear subspaces of POD modes of increasing training data is provided. As more data is added to the training set, test set are more likely to be generalised by the training data modes.</p>\n<div class=\"note note-danger\">\n            <p>Personally, I don't really understand the term <strong>projection</strong>. Whether it is same as <strong>reconstruction</strong> but in an opposite direction? Need more knowledge on it.</p>\n          </div>\n<p>For flow pass a cylinder, the model performs well even with very few training data since the flow is simple and periodic. However, the mixing layer and Gulf of Mexico vorticity data have relatively large residual, indicating that there are still new structures that havent been observed in the training data.</p>\n<p><img src=\"sufficient measurements.png\" alt=\"Comparison of the amounts of measurements needed to reconstruct the test data. After Callaham, J. L et.al[9]\" style=\"zoom:50%;\" /></p>\n<p>Above compares the normalised residual error of sparse representation-based reconstructions with increasing number of random point measurements. Similar to the research on amount of the training data, more information is needed from measurements to reconstruct a more complicate flow field.</p>\n<div class=\"note note-info\">\n            <p>The result might be better if a powerful reconstruction model is used such as the Deep Autoencoder. It is still an open area.</p>\n          </div>\n<h3 id=\"reference\">Reference</h3>\n<section class=\"footnotes\">\n<div class=\"footnote-list\">\n<ol>\n<li>\n<span id=\"fn:1\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://www.osapublishing.org/abstract.cfm%3Furi%3Djosaa-4-3-519&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=2157283586688201779&amp;ei=iIGcYpXMOP6J6rQPzPSs-A8&amp;scisig=AAGBfm1UtAAHt6JMQKL_6kZNl8eYHaRD7g\">Sirovich, L., &amp; Kirby, M. (1987). Low-dimensional procedure for the characterization of human faces. <em>Josa a</em>, <em>4</em>(3), 519-524.</a> <a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:2\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://www.ams.org/qam/1987-45-03/S0033-569X-1987-0910462-6/&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=16097515379918329562&amp;ei=r4GcYrGXCZb0yAT_6KLYDw&amp;scisig=AAGBfm2FAMjBm8d7M0kmOWq1CQ5iribTeg\">Sirovich, L. (1987). Turbulence and the dynamics of coherent structures. I. Coherent structures. <em>Quarterly of applied mathematics</em>, <em>45</em>(3), 561-571.</a> <a href=\"#fnref:2\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:3\" class=\"footnote-text\"><span><a href=\"https://www.semanticscholar.org/paper/Neural-network-modeling-for-near-wall-turbulent-Milano-Koumoutsakos/f0e8198850dae31cc9612940581ec8c059c24475\">Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.</a> <a href=\"#fnref:3\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:4\" class=\"footnote-text\"><span><a href=\"https://link.springer.com/article/10.1007/BF00384623\">Keane, R. D., &amp; Adrian, R. J. (1992). Theory of cross-correlation analysis of PIV images. Applied scientific research, 49(3), 191-215.</a> <a href=\"#fnref:4\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:5\" class=\"footnote-text\"><span><a href=\"https://ieeexplore.ieee.org/abstract/document/726791/\">LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). Gradient-based learning applied to document recognition. <em>Proceedings of the IEEE</em>, <em>86</em>(11), 2278-2324.</a> <a href=\"#fnref:5\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:6\" class=\"footnote-text\"><span><a href=\"https://dl.acm.org/doi/abs/10.1145/1970392.1970395\">Cands, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?. <em>Journal of the ACM (JACM)</em>, <em>58</em>(3), 1-37.</a> <a href=\"#fnref:6\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:7\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.5.054401&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=9368717229379747223&amp;ei=eXCcYp2tDZb0yAT_6KLYDw&amp;scisig=AAGBfm3dnQgKr4Ku82Fv4l8EQlBowAQZdQ\">Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., &amp; Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. <em>Physical Review Fluids</em>, <em>5</em>(5), 054401.</a> <a href=\"#fnref:7\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:8\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2020.0097&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=4644643361595480852&amp;ei=gcigYuSJPIOM6rQPoeQk&amp;scisig=AAGBfm3cHzLDR-qONvANNbFZQE0NFSr01Q\">Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., &amp; Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. <em>Proceedings of the Royal Society A</em>, <em>476</em>(2238), 20200097.</a> <a href=\"#fnref:8\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:9\" class=\"footnote-text\"><span><a href=\"https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.4.103907\">Callaham, J. L., Maeda, K., &amp; Brunton, S. L. (2019). Robust flow reconstruction from limited measurements via sparse representation. <em>Physical Review Fluids</em>, <em>4</em>(10), 103907.</a> <a href=\"#fnref:9\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n</ol>\n</div>\n</section>"},{"title":"Intro and Pytorch Implementation of Label Smoothing Regularization (LSR)","author":"Ryan LI","toc":true,"declare":true,"date":"2022-03-04T05:59:58.000Z","_content":"\n> Soft label is a commonly used trick to prevent overfitting. It can always gain some extra points on the image classification tasks. In this article, I have put together useful information from theory to implementation of it.\n\n> Recently, I joined a [Kaggle image classification competition](https://www.kaggle.com/c/classify-leaves/), I used the pretrained ResNet50 plus other tricks and here is to record some of them I've learned for now. \n\n\n<!-- more -->\n\n### Introduction: from hard label to soft label\n\nIn deep learning, the neural network is basically a super powerful non-linear regression machine aimed to fit a function between the input and the label. And the result is always called label.\n\nHard label, in another word:  the one-hot vector, is the most commonly type of label that is used. For example, in this [Kaggle image classification competition](https://www.kaggle.com/c/classify-leaves/), to digitalize the different name of the leaves, it is intuitive to encode the leaves categories as: 0, 1, 2, 3. And the factorized target labels would be somehow like [1,3,0...] where each element stands for the categories of the data. With the resulting category dictionary, it can be easily decoded after the training.\n\n<img src=\"leave%20class%20code.png\" alt=\"leave class code\" style=\"zoom:22%;\" />\n\nActually, there is a slightly difference in the binary world. What usually do is, the previously factorized label will be extended to be a 2-dimensional \"on-hot\" matrix where the elements stands for the probability of each class. And the network is aimed to train itself to make inference label nearest to the target label.\n\n<img src=\"hard%20label.png\" alt=\"hard label\" style=\"zoom:22%;\" />\n\nSoft label is just slightly deteriorate the strong one-hot label into a weaker one.\n\n<img src=\"soft%20label.png\" alt=\"soft label\" style=\"zoom:22%;\" />\n\n### Simple explanation: How loss function lost information?\n\nIn the cross entropy loss function, where `y_inference` and `y_grountruth` stands for inference and target label, n stands for the number of class.\n\n<img src=\"Cross%20entropy%20loss%20function.png\" alt=\"Cross entropy loss function\" style=\"zoom:22%;\" />\n\nWith the one-hot label, the components are 0 except for the true category. In a other word, the `y_inference` of the wrong category is not considered at all i.e. the information of the wrong category is lost. Which is against the real word classification. \n\n### Effectiveness: Visualization\n\nIn [When does label smoothing help?](https://arxiv.org/pdf/1906.02629.pdf)  Hinton shows the feature map difference between without and with LSR:\n\n<img src=\"Label%20smoothing%20feature%20norm.png\" alt=\"Label smoothing feature norm\" style=\"zoom:80%;\" />\n\n>- When label smoothing is applied, the clusters are much tighter because label smoothing encourages that each example in the training set is to be equidistant from all other classs templates.\n>- With hard targets, the clusters for semantically similar classes (for example different breed of dogs in ImageNet), are isotropic whereas, with label smoothing, clusters lie in an arc as shown in the third row. If you mix two semantically similar classes with a third semantically different class, the clusters are still much better than the ones obtained with hard targets as shown in the fourth row.\n\n### Experiment: apply in competition\n\nLabel smoothing can be easily applied in [Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy), but there is no such thing in PyTorch.  So overwrite the Cross-entropy loss function with LSR (implemented in 2 ways): \n\n```python\nclass LSR(nn.Module):\n    \"\"\"NLL loss with label smoothing.\n    \"\"\"\n    def __init__(self, smoothing=0.0):\n        \"\"\"Constructor for the LSR module.\n        :param smoothing: label smoothing factor\n        \"\"\"\n        super(LSR, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n\n    def forward(self, x, target):\n        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n        nll_loss = nll_loss.squeeze(1)\n        smooth_loss = -logprobs.mean(dim=-1)\n        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n        return loss.mean()\n    \nloss = LSR(0.1)\n```\n\n```python\nclass LSR2(nn.Module):\n\n    def __init__(self, e=0.01,reduction='mean'):\n        super().__init__()\n\n        self.log_softmax = nn.LogSoftmax(dim=1)\n        self.e = e\n        self.reduction = reduction\n\n    def _one_hot(self, labels, classes, value=1):\n        \"\"\"\n            Convert labels to one hot vectors\n\n        Args:\n            labels: torch tensor in format [label1, label2, label3, ...]\n            classes: int, number of classes\n            value: label value in one hot vector, default to 1\n\n        Returns:\n            return one hot format labels in shape [batchsize, classes]\n        \"\"\"\n        #print(\"classes\", classes)\n        one_hot = torch.zeros(labels.size(0), classes)\n\n        # labels and value_added  size must match\n        labels = labels.view(labels.size(0), -1)\n        value_added = torch.Tensor(labels.size(0), 1).fill_(value)\n\n        value_added = value_added.to(labels.device)\n        one_hot = one_hot.to(labels.device)\n\n        one_hot.scatter_add_(1, labels, value_added)\n\n        return one_hot\n\n    def _smooth_label(self, target, length, smooth_factor):\n        \"\"\"convert targets to one-hot format, and smooth\n        them.\n\n        Args:\n            target: target in form with [label1, label2, label_batchsize]\n            length: length of one-hot format(number of classes)\n            smooth_factor: smooth factor for label smooth\n\n        Returns:\n            smoothed labels in one hot format\n        \"\"\"\n        #print(\"length\", length)\n        #print(\"smooth_fact\", smooth_factor)\n        one_hot = self._one_hot(target, length, value=1 - smooth_factor)\n        one_hot += smooth_factor / length\n\n        return one_hot.to(target.device)\n\n    def forward(self, x, target):\n\n        if x.size(0) != target.size(0):\n            raise ValueError('Expected input batchsize ({}) to match target batch_size({})'\n                             .format(x.size(0), target.size(0)))\n\n        if x.dim() < 2:\n            raise ValueError('Expected input tensor to have least 2 dimensions(got {})'\n                             .format(x.size(0)))\n\n        if x.dim() != 2:\n            raise ValueError('Only 2 dimension tensor are implemented, (got {})'\n                             .format(x.size()))\n        #print(\"x: \", x)\n        #print(\"target\", target)\n\n        smoothed_target = self._smooth_label(target, x.size(1), self.e)\n        x = self.log_softmax(x)\n        loss = torch.sum(- x * smoothed_target, dim=1)\n        if self.reduction == 'none':\n            return loss\n\n        elif self.reduction == 'sum':\n            return torch.sum(loss)\n\n        elif self.reduction == 'mean':\n            return torch.mean(loss)\n\n        else:\n            raise ValueError('unrecognized option, expect reduction to be one of none, mean, sum')\n            \nloss = LSR2(0.1)\n```\n\nPretrained ResNet50 is in use\n\n```shell\nlr, num_epochs, batch_size = 0.01, 10, 256\n```\n\n<img src=\"accuracy%20curve%20compare%20label%20smoothing%20with%20hard%20label.png\" alt=\"accuracy curve compare label smoothing with hard label\" style=\"zoom:67%;\" />\n\nIt can bee seen that the under same `random seed`, `batch_size`, `lr`, and `num_epochs`, the overall accuracy has a fascinating rise of 0.5. \n\nThen apply the LSR and run 50 epochs, with learning rate 0.005 and batch size 256, the result turns to be:\n\n<img src=\"accuracy%20curve%20applying%20label%20smoothing.png\" alt=\"accuracy curve applying label smoothing\" style=\"zoom:67%;\" />\n\nIt is a exciting improvement, but more tricks still in need.\n\n### Conclusion\n\n3 disadvantaged of the hard label:\n\n- the relationship between the true label and the others is neglected, tend to be overfitting\n- the model is tend to be over confident i.e. less generalizable\n- more sensitive to label with noise, wrong labeled for example.\n\nSeveral good things about label smoothing:\n\n- data augmentation by add more information, compensates for the lack of supervisory signals \n- Improves generalizability\n- Improves noise robust\n- lower the feature norm\n- Improves model calibration \n\nBad things about label smoothing:\n\n-  label smoothing can't give real relationship between labels. It simply adds random noise, under fitting might happen under certain scenarios.\n- If distill in use, the teach network preforms worse when apply label smoothing, more explanation in  [When does label smoothing help?](https://arxiv.org/pdf/1906.02629.pdf) \n\n### Reference\n\n [ - Label Smoothing - + -  (tencent.com)](https://cloud.tencent.com/developer/article/1815786) \n\n [Trick (qq.com)](https://mp.weixin.qq.com/s?__biz=Mzg4MzU1NjQ2Mw==&mid=2247495228&idx=1&sn=ec685adcf8a274e8235c177718868a34&scene=21#wechat_redirect) \n\n[trick--labelsmooth](https://cloud.tencent.com/developer/article/1684298?from=article.detail.1815786)\n\n [Label Smoothing  (Label smooth regularization, LSR)_hxxjxw-CSDN](https://blog.csdn.net/hxxjxw/article/details/115298103) \n\n [When Does Label Smoothing Help?](https://medium.com/@nainaakash012/when-does-label-smoothing-help-89654ec75326)\n\n[ suvojit-0x55aa](https://gist.github.com/suvojit-0x55aa)/[label_smoothing.py](https://gist.github.com/suvojit-0x55aa/0afb3eefbb26d33f54e1fb9f94d6b609)\n\n","source":"_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR.md","raw":"---\ntitle: Intro and Pytorch Implementation of Label Smoothing Regularization (LSR)\nauthor: Ryan LI\ntoc: true\ndeclare: true\ndate: 2022-03-04 13:59:58\ntags:\n\t- deep learning\n\t- deep learning tricks\n---\n\n> Soft label is a commonly used trick to prevent overfitting. It can always gain some extra points on the image classification tasks. In this article, I have put together useful information from theory to implementation of it.\n\n> Recently, I joined a [Kaggle image classification competition](https://www.kaggle.com/c/classify-leaves/), I used the pretrained ResNet50 plus other tricks and here is to record some of them I've learned for now. \n\n\n<!-- more -->\n\n### Introduction: from hard label to soft label\n\nIn deep learning, the neural network is basically a super powerful non-linear regression machine aimed to fit a function between the input and the label. And the result is always called label.\n\nHard label, in another word:  the one-hot vector, is the most commonly type of label that is used. For example, in this [Kaggle image classification competition](https://www.kaggle.com/c/classify-leaves/), to digitalize the different name of the leaves, it is intuitive to encode the leaves categories as: 0, 1, 2, 3. And the factorized target labels would be somehow like [1,3,0...] where each element stands for the categories of the data. With the resulting category dictionary, it can be easily decoded after the training.\n\n<img src=\"leave%20class%20code.png\" alt=\"leave class code\" style=\"zoom:22%;\" />\n\nActually, there is a slightly difference in the binary world. What usually do is, the previously factorized label will be extended to be a 2-dimensional \"on-hot\" matrix where the elements stands for the probability of each class. And the network is aimed to train itself to make inference label nearest to the target label.\n\n<img src=\"hard%20label.png\" alt=\"hard label\" style=\"zoom:22%;\" />\n\nSoft label is just slightly deteriorate the strong one-hot label into a weaker one.\n\n<img src=\"soft%20label.png\" alt=\"soft label\" style=\"zoom:22%;\" />\n\n### Simple explanation: How loss function lost information?\n\nIn the cross entropy loss function, where `y_inference` and `y_grountruth` stands for inference and target label, n stands for the number of class.\n\n<img src=\"Cross%20entropy%20loss%20function.png\" alt=\"Cross entropy loss function\" style=\"zoom:22%;\" />\n\nWith the one-hot label, the components are 0 except for the true category. In a other word, the `y_inference` of the wrong category is not considered at all i.e. the information of the wrong category is lost. Which is against the real word classification. \n\n### Effectiveness: Visualization\n\nIn [When does label smoothing help?](https://arxiv.org/pdf/1906.02629.pdf)  Hinton shows the feature map difference between without and with LSR:\n\n<img src=\"Label%20smoothing%20feature%20norm.png\" alt=\"Label smoothing feature norm\" style=\"zoom:80%;\" />\n\n>- When label smoothing is applied, the clusters are much tighter because label smoothing encourages that each example in the training set is to be equidistant from all other classs templates.\n>- With hard targets, the clusters for semantically similar classes (for example different breed of dogs in ImageNet), are isotropic whereas, with label smoothing, clusters lie in an arc as shown in the third row. If you mix two semantically similar classes with a third semantically different class, the clusters are still much better than the ones obtained with hard targets as shown in the fourth row.\n\n### Experiment: apply in competition\n\nLabel smoothing can be easily applied in [Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy), but there is no such thing in PyTorch.  So overwrite the Cross-entropy loss function with LSR (implemented in 2 ways): \n\n```python\nclass LSR(nn.Module):\n    \"\"\"NLL loss with label smoothing.\n    \"\"\"\n    def __init__(self, smoothing=0.0):\n        \"\"\"Constructor for the LSR module.\n        :param smoothing: label smoothing factor\n        \"\"\"\n        super(LSR, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n\n    def forward(self, x, target):\n        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n        nll_loss = nll_loss.squeeze(1)\n        smooth_loss = -logprobs.mean(dim=-1)\n        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n        return loss.mean()\n    \nloss = LSR(0.1)\n```\n\n```python\nclass LSR2(nn.Module):\n\n    def __init__(self, e=0.01,reduction='mean'):\n        super().__init__()\n\n        self.log_softmax = nn.LogSoftmax(dim=1)\n        self.e = e\n        self.reduction = reduction\n\n    def _one_hot(self, labels, classes, value=1):\n        \"\"\"\n            Convert labels to one hot vectors\n\n        Args:\n            labels: torch tensor in format [label1, label2, label3, ...]\n            classes: int, number of classes\n            value: label value in one hot vector, default to 1\n\n        Returns:\n            return one hot format labels in shape [batchsize, classes]\n        \"\"\"\n        #print(\"classes\", classes)\n        one_hot = torch.zeros(labels.size(0), classes)\n\n        # labels and value_added  size must match\n        labels = labels.view(labels.size(0), -1)\n        value_added = torch.Tensor(labels.size(0), 1).fill_(value)\n\n        value_added = value_added.to(labels.device)\n        one_hot = one_hot.to(labels.device)\n\n        one_hot.scatter_add_(1, labels, value_added)\n\n        return one_hot\n\n    def _smooth_label(self, target, length, smooth_factor):\n        \"\"\"convert targets to one-hot format, and smooth\n        them.\n\n        Args:\n            target: target in form with [label1, label2, label_batchsize]\n            length: length of one-hot format(number of classes)\n            smooth_factor: smooth factor for label smooth\n\n        Returns:\n            smoothed labels in one hot format\n        \"\"\"\n        #print(\"length\", length)\n        #print(\"smooth_fact\", smooth_factor)\n        one_hot = self._one_hot(target, length, value=1 - smooth_factor)\n        one_hot += smooth_factor / length\n\n        return one_hot.to(target.device)\n\n    def forward(self, x, target):\n\n        if x.size(0) != target.size(0):\n            raise ValueError('Expected input batchsize ({}) to match target batch_size({})'\n                             .format(x.size(0), target.size(0)))\n\n        if x.dim() < 2:\n            raise ValueError('Expected input tensor to have least 2 dimensions(got {})'\n                             .format(x.size(0)))\n\n        if x.dim() != 2:\n            raise ValueError('Only 2 dimension tensor are implemented, (got {})'\n                             .format(x.size()))\n        #print(\"x: \", x)\n        #print(\"target\", target)\n\n        smoothed_target = self._smooth_label(target, x.size(1), self.e)\n        x = self.log_softmax(x)\n        loss = torch.sum(- x * smoothed_target, dim=1)\n        if self.reduction == 'none':\n            return loss\n\n        elif self.reduction == 'sum':\n            return torch.sum(loss)\n\n        elif self.reduction == 'mean':\n            return torch.mean(loss)\n\n        else:\n            raise ValueError('unrecognized option, expect reduction to be one of none, mean, sum')\n            \nloss = LSR2(0.1)\n```\n\nPretrained ResNet50 is in use\n\n```shell\nlr, num_epochs, batch_size = 0.01, 10, 256\n```\n\n<img src=\"accuracy%20curve%20compare%20label%20smoothing%20with%20hard%20label.png\" alt=\"accuracy curve compare label smoothing with hard label\" style=\"zoom:67%;\" />\n\nIt can bee seen that the under same `random seed`, `batch_size`, `lr`, and `num_epochs`, the overall accuracy has a fascinating rise of 0.5. \n\nThen apply the LSR and run 50 epochs, with learning rate 0.005 and batch size 256, the result turns to be:\n\n<img src=\"accuracy%20curve%20applying%20label%20smoothing.png\" alt=\"accuracy curve applying label smoothing\" style=\"zoom:67%;\" />\n\nIt is a exciting improvement, but more tricks still in need.\n\n### Conclusion\n\n3 disadvantaged of the hard label:\n\n- the relationship between the true label and the others is neglected, tend to be overfitting\n- the model is tend to be over confident i.e. less generalizable\n- more sensitive to label with noise, wrong labeled for example.\n\nSeveral good things about label smoothing:\n\n- data augmentation by add more information, compensates for the lack of supervisory signals \n- Improves generalizability\n- Improves noise robust\n- lower the feature norm\n- Improves model calibration \n\nBad things about label smoothing:\n\n-  label smoothing can't give real relationship between labels. It simply adds random noise, under fitting might happen under certain scenarios.\n- If distill in use, the teach network preforms worse when apply label smoothing, more explanation in  [When does label smoothing help?](https://arxiv.org/pdf/1906.02629.pdf) \n\n### Reference\n\n [ - Label Smoothing - + -  (tencent.com)](https://cloud.tencent.com/developer/article/1815786) \n\n [Trick (qq.com)](https://mp.weixin.qq.com/s?__biz=Mzg4MzU1NjQ2Mw==&mid=2247495228&idx=1&sn=ec685adcf8a274e8235c177718868a34&scene=21#wechat_redirect) \n\n[trick--labelsmooth](https://cloud.tencent.com/developer/article/1684298?from=article.detail.1815786)\n\n [Label Smoothing  (Label smooth regularization, LSR)_hxxjxw-CSDN](https://blog.csdn.net/hxxjxw/article/details/115298103) \n\n [When Does Label Smoothing Help?](https://medium.com/@nainaakash012/when-does-label-smoothing-help-89654ec75326)\n\n[ suvojit-0x55aa](https://gist.github.com/suvojit-0x55aa)/[label_smoothing.py](https://gist.github.com/suvojit-0x55aa/0afb3eefbb26d33f54e1fb9f94d6b609)\n\n","slug":"Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR","published":1,"updated":"2022-05-02T09:41:10.804Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz21000jl8yba4p9fgly","content":"<blockquote>\n<p>Soft label is a commonly used trick to prevent overfitting. It can always gain some extra points on the image classification tasks. In this article, I have put together useful information from theory to implementation of it.</p>\n</blockquote>\n<blockquote>\n<p>Recently, I joined a <a href=\"https://www.kaggle.com/c/classify-leaves/\">Kaggle image classification competition</a>, I used the pretrained ResNet50 plus other tricks and here is to record some of them I've learned for now.</p>\n</blockquote>\n<span id=\"more\"></span>\n<h3 id=\"introduction-from-hard-label-to-soft-label\">Introduction: from hard label to soft label</h3>\n<p>In deep learning, the neural network is basically a super powerful non-linear regression machine aimed to fit a function between the input and the label. And the result is always called label.</p>\n<p>Hard label, in another word: the one-hot vector, is the most commonly type of label that is used. For example, in this <a href=\"https://www.kaggle.com/c/classify-leaves/\">Kaggle image classification competition</a>, to digitalize the different name of the leaves, it is intuitive to encode the leaves categories as: 0, 1, 2, 3. And the factorized target labels would be somehow like [1,3,0...] where each element stands for the categories of the data. With the resulting category dictionary, it can be easily decoded after the training.</p>\n<p><img src=\"leave%20class%20code.png\" srcset=\"/img/loading.gif\" lazyload alt=\"leave class code\" style=\"zoom:22%;\" /></p>\n<p>Actually, there is a slightly difference in the binary world. What usually do is, the previously factorized label will be extended to be a 2-dimensional \"on-hot\" matrix where the elements stands for the probability of each class. And the network is aimed to train itself to make inference label nearest to the target label.</p>\n<p><img src=\"hard%20label.png\" srcset=\"/img/loading.gif\" lazyload alt=\"hard label\" style=\"zoom:22%;\" /></p>\n<p>Soft label is just slightly deteriorate the strong one-hot label into a weaker one.</p>\n<p><img src=\"soft%20label.png\" srcset=\"/img/loading.gif\" lazyload alt=\"soft label\" style=\"zoom:22%;\" /></p>\n<h3 id=\"simple-explanation-how-loss-function-lost-information\">Simple explanation: How loss function lost information?</h3>\n<p>In the cross entropy loss function, where <code>y_inference</code> and <code>y_grountruth</code> stands for inference and target label, n stands for the number of class.</p>\n<p><img src=\"Cross%20entropy%20loss%20function.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Cross entropy loss function\" style=\"zoom:22%;\" /></p>\n<p>With the one-hot label, the components are 0 except for the true category. In a other word, the <code>y_inference</code> of the wrong category is not considered at all i.e. the information of the wrong category is lost. Which is against the real word classification.</p>\n<h3 id=\"effectiveness-visualization\">Effectiveness: Visualization</h3>\n<p>In <a href=\"https://arxiv.org/pdf/1906.02629.pdf\">When does label smoothing help?</a> Hinton shows the feature map difference between without and with LSR:</p>\n<p><img src=\"Label%20smoothing%20feature%20norm.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Label smoothing feature norm\" style=\"zoom:80%;\" /></p>\n<blockquote>\n<ul>\n<li>When label smoothing is applied, the clusters are much tighter because label smoothing encourages that each example in the training set is to be equidistant from all other classs templates.</li>\n<li>With hard targets, the clusters for semantically similar classes (for example different breed of dogs in ImageNet), are isotropic whereas, with label smoothing, clusters lie in an arc as shown in the third row. If you mix two semantically similar classes with a third semantically different class, the clusters are still much better than the ones obtained with hard targets as shown in the fourth row.</li>\n</ul>\n</blockquote>\n<h3 id=\"experiment-apply-in-competition\">Experiment: apply in competition</h3>\n<p>Label smoothing can be easily applied in <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy\">Tensorflow</a>, but there is no such thing in PyTorch. So overwrite the Cross-entropy loss function with LSR (implemented in 2 ways):</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">LSR</span>(nn.Module):\n    <span class=\"hljs-string\">&quot;&quot;&quot;NLL loss with label smoothing.</span>\n<span class=\"hljs-string\">    &quot;&quot;&quot;</span>\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, smoothing=<span class=\"hljs-number\">0.0</span></span>):\n        <span class=\"hljs-string\">&quot;&quot;&quot;Constructor for the LSR module.</span>\n<span class=\"hljs-string\">        :param smoothing: label smoothing factor</span>\n<span class=\"hljs-string\">        &quot;&quot;&quot;</span>\n        <span class=\"hljs-built_in\">super</span>(LSR, self).__init__()\n        self.confidence = <span class=\"hljs-number\">1.0</span> - smoothing\n        self.smoothing = smoothing\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, target</span>):\n        logprobs = torch.nn.functional.log_softmax(x, dim=-<span class=\"hljs-number\">1</span>)\n        nll_loss = -logprobs.gather(dim=-<span class=\"hljs-number\">1</span>, index=target.unsqueeze(<span class=\"hljs-number\">1</span>))\n        nll_loss = nll_loss.squeeze(<span class=\"hljs-number\">1</span>)\n        smooth_loss = -logprobs.mean(dim=-<span class=\"hljs-number\">1</span>)\n        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n        <span class=\"hljs-keyword\">return</span> loss.mean()\n    \nloss = LSR(<span class=\"hljs-number\">0.1</span>)</code></pre></div>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">LSR2</span>(nn.Module):\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, e=<span class=\"hljs-number\">0.01</span>,reduction=<span class=\"hljs-string\">&#x27;mean&#x27;</span></span>):\n        <span class=\"hljs-built_in\">super</span>().__init__()\n\n        self.log_softmax = nn.LogSoftmax(dim=<span class=\"hljs-number\">1</span>)\n        self.e = e\n        self.reduction = reduction\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_one_hot</span>(<span class=\"hljs-params\">self, labels, classes, value=<span class=\"hljs-number\">1</span></span>):\n        <span class=\"hljs-string\">&quot;&quot;&quot;</span>\n<span class=\"hljs-string\">            Convert labels to one hot vectors</span>\n<span class=\"hljs-string\"></span>\n<span class=\"hljs-string\">        Args:</span>\n<span class=\"hljs-string\">            labels: torch tensor in format [label1, label2, label3, ...]</span>\n<span class=\"hljs-string\">            classes: int, number of classes</span>\n<span class=\"hljs-string\">            value: label value in one hot vector, default to 1</span>\n<span class=\"hljs-string\"></span>\n<span class=\"hljs-string\">        Returns:</span>\n<span class=\"hljs-string\">            return one hot format labels in shape [batchsize, classes]</span>\n<span class=\"hljs-string\">        &quot;&quot;&quot;</span>\n        <span class=\"hljs-comment\">#print(&quot;classes&quot;, classes)</span>\n        one_hot = torch.zeros(labels.size(<span class=\"hljs-number\">0</span>), classes)\n\n        <span class=\"hljs-comment\"># labels and value_added  size must match</span>\n        labels = labels.view(labels.size(<span class=\"hljs-number\">0</span>), -<span class=\"hljs-number\">1</span>)\n        value_added = torch.Tensor(labels.size(<span class=\"hljs-number\">0</span>), <span class=\"hljs-number\">1</span>).fill_(value)\n\n        value_added = value_added.to(labels.device)\n        one_hot = one_hot.to(labels.device)\n\n        one_hot.scatter_add_(<span class=\"hljs-number\">1</span>, labels, value_added)\n\n        <span class=\"hljs-keyword\">return</span> one_hot\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_smooth_label</span>(<span class=\"hljs-params\">self, target, length, smooth_factor</span>):\n        <span class=\"hljs-string\">&quot;&quot;&quot;convert targets to one-hot format, and smooth</span>\n<span class=\"hljs-string\">        them.</span>\n<span class=\"hljs-string\"></span>\n<span class=\"hljs-string\">        Args:</span>\n<span class=\"hljs-string\">            target: target in form with [label1, label2, label_batchsize]</span>\n<span class=\"hljs-string\">            length: length of one-hot format(number of classes)</span>\n<span class=\"hljs-string\">            smooth_factor: smooth factor for label smooth</span>\n<span class=\"hljs-string\"></span>\n<span class=\"hljs-string\">        Returns:</span>\n<span class=\"hljs-string\">            smoothed labels in one hot format</span>\n<span class=\"hljs-string\">        &quot;&quot;&quot;</span>\n        <span class=\"hljs-comment\">#print(&quot;length&quot;, length)</span>\n        <span class=\"hljs-comment\">#print(&quot;smooth_fact&quot;, smooth_factor)</span>\n        one_hot = self._one_hot(target, length, value=<span class=\"hljs-number\">1</span> - smooth_factor)\n        one_hot += smooth_factor / length\n\n        <span class=\"hljs-keyword\">return</span> one_hot.to(target.device)\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, target</span>):\n\n        <span class=\"hljs-keyword\">if</span> x.size(<span class=\"hljs-number\">0</span>) != target.size(<span class=\"hljs-number\">0</span>):\n            <span class=\"hljs-keyword\">raise</span> ValueError(<span class=\"hljs-string\">&#x27;Expected input batchsize (&#123;&#125;) to match target batch_size(&#123;&#125;)&#x27;</span>\n                             .<span class=\"hljs-built_in\">format</span>(x.size(<span class=\"hljs-number\">0</span>), target.size(<span class=\"hljs-number\">0</span>)))\n\n        <span class=\"hljs-keyword\">if</span> x.dim() &lt; <span class=\"hljs-number\">2</span>:\n            <span class=\"hljs-keyword\">raise</span> ValueError(<span class=\"hljs-string\">&#x27;Expected input tensor to have least 2 dimensions(got &#123;&#125;)&#x27;</span>\n                             .<span class=\"hljs-built_in\">format</span>(x.size(<span class=\"hljs-number\">0</span>)))\n\n        <span class=\"hljs-keyword\">if</span> x.dim() != <span class=\"hljs-number\">2</span>:\n            <span class=\"hljs-keyword\">raise</span> ValueError(<span class=\"hljs-string\">&#x27;Only 2 dimension tensor are implemented, (got &#123;&#125;)&#x27;</span>\n                             .<span class=\"hljs-built_in\">format</span>(x.size()))\n        <span class=\"hljs-comment\">#print(&quot;x: &quot;, x)</span>\n        <span class=\"hljs-comment\">#print(&quot;target&quot;, target)</span>\n\n        smoothed_target = self._smooth_label(target, x.size(<span class=\"hljs-number\">1</span>), self.e)\n        x = self.log_softmax(x)\n        loss = torch.<span class=\"hljs-built_in\">sum</span>(- x * smoothed_target, dim=<span class=\"hljs-number\">1</span>)\n        <span class=\"hljs-keyword\">if</span> self.reduction == <span class=\"hljs-string\">&#x27;none&#x27;</span>:\n            <span class=\"hljs-keyword\">return</span> loss\n\n        <span class=\"hljs-keyword\">elif</span> self.reduction == <span class=\"hljs-string\">&#x27;sum&#x27;</span>:\n            <span class=\"hljs-keyword\">return</span> torch.<span class=\"hljs-built_in\">sum</span>(loss)\n\n        <span class=\"hljs-keyword\">elif</span> self.reduction == <span class=\"hljs-string\">&#x27;mean&#x27;</span>:\n            <span class=\"hljs-keyword\">return</span> torch.mean(loss)\n\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-keyword\">raise</span> ValueError(<span class=\"hljs-string\">&#x27;unrecognized option, expect reduction to be one of none, mean, sum&#x27;</span>)\n            \nloss = LSR2(<span class=\"hljs-number\">0.1</span>)</code></pre></div>\n<p>Pretrained ResNet50 is in use</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">lr, num_epochs, batch_size = 0.01, 10, 256</code></pre></div>\n<p><img src=\"accuracy%20curve%20compare%20label%20smoothing%20with%20hard%20label.png\" srcset=\"/img/loading.gif\" lazyload alt=\"accuracy curve compare label smoothing with hard label\" style=\"zoom:67%;\" /></p>\n<p>It can bee seen that the under same <code>random seed</code>, <code>batch_size</code>, <code>lr</code>, and <code>num_epochs</code>, the overall accuracy has a fascinating rise of 0.5.</p>\n<p>Then apply the LSR and run 50 epochs, with learning rate 0.005 and batch size 256, the result turns to be:</p>\n<p><img src=\"accuracy%20curve%20applying%20label%20smoothing.png\" srcset=\"/img/loading.gif\" lazyload alt=\"accuracy curve applying label smoothing\" style=\"zoom:67%;\" /></p>\n<p>It is a exciting improvement, but more tricks still in need.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>3 disadvantaged of the hard label:</p>\n<ul>\n<li>the relationship between the true label and the others is neglected, tend to be overfitting</li>\n<li>the model is tend to be over confident i.e. less generalizable</li>\n<li>more sensitive to label with noise, wrong labeled for example.</li>\n</ul>\n<p>Several good things about label smoothing:</p>\n<ul>\n<li>data augmentation by add more information, compensates for the lack of supervisory signals</li>\n<li>Improves generalizability</li>\n<li>Improves noise robust</li>\n<li>lower the feature norm</li>\n<li>Improves model calibration</li>\n</ul>\n<p>Bad things about label smoothing:</p>\n<ul>\n<li>label smoothing can't give real relationship between labels. It simply adds random noise, under fitting might happen under certain scenarios.</li>\n<li>If distill in use, the teach network preforms worse when apply label smoothing, more explanation in <a href=\"https://arxiv.org/pdf/1906.02629.pdf\">When does label smoothing help?</a></li>\n</ul>\n<h3 id=\"reference\">Reference</h3>\n<p><a href=\"https://cloud.tencent.com/developer/article/1815786\"> - Label Smoothing - + -  (tencent.com)</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg4MzU1NjQ2Mw==&amp;mid=2247495228&amp;idx=1&amp;sn=ec685adcf8a274e8235c177718868a34&amp;scene=21#wechat_redirect\">Trick (qq.com)</a></p>\n<p><a href=\"https://cloud.tencent.com/developer/article/1684298?from=article.detail.1815786\">trick--labelsmooth</a></p>\n<p><a href=\"https://blog.csdn.net/hxxjxw/article/details/115298103\">Label Smoothing  (Label smooth regularization, LSR)_hxxjxw-CSDN</a></p>\n<p><a href=\"https://medium.com/@nainaakash012/when-does-label-smoothing-help-89654ec75326\">When Does Label Smoothing Help?</a></p>\n<p><a href=\"https://gist.github.com/suvojit-0x55aa\">suvojit-0x55aa</a>/<a href=\"https://gist.github.com/suvojit-0x55aa/0afb3eefbb26d33f54e1fb9f94d6b609\">label_smoothing.py</a></p>\n","site":{"data":{}},"wordcount":6374,"excerpt":"<blockquote>\n<p>Soft label is a commonly used trick to prevent overfitting. It can always gain some extra points on the image classification tasks. In this article, I have put together useful information from theory to implementation of it.</p>\n</blockquote>\n<blockquote>\n<p>Recently, I joined a <a href=\"https://www.kaggle.com/c/classify-leaves/\">Kaggle image classification competition</a>, I used the pretrained ResNet50 plus other tricks and here is to record some of them I've learned for now.</p>\n</blockquote>","more":"<h3 id=\"introduction-from-hard-label-to-soft-label\">Introduction: from hard label to soft label</h3>\n<p>In deep learning, the neural network is basically a super powerful non-linear regression machine aimed to fit a function between the input and the label. And the result is always called label.</p>\n<p>Hard label, in another word: the one-hot vector, is the most commonly type of label that is used. For example, in this <a href=\"https://www.kaggle.com/c/classify-leaves/\">Kaggle image classification competition</a>, to digitalize the different name of the leaves, it is intuitive to encode the leaves categories as: 0, 1, 2, 3. And the factorized target labels would be somehow like [1,3,0...] where each element stands for the categories of the data. With the resulting category dictionary, it can be easily decoded after the training.</p>\n<p><img src=\"leave%20class%20code.png\" alt=\"leave class code\" style=\"zoom:22%;\" /></p>\n<p>Actually, there is a slightly difference in the binary world. What usually do is, the previously factorized label will be extended to be a 2-dimensional \"on-hot\" matrix where the elements stands for the probability of each class. And the network is aimed to train itself to make inference label nearest to the target label.</p>\n<p><img src=\"hard%20label.png\" alt=\"hard label\" style=\"zoom:22%;\" /></p>\n<p>Soft label is just slightly deteriorate the strong one-hot label into a weaker one.</p>\n<p><img src=\"soft%20label.png\" alt=\"soft label\" style=\"zoom:22%;\" /></p>\n<h3 id=\"simple-explanation-how-loss-function-lost-information\">Simple explanation: How loss function lost information?</h3>\n<p>In the cross entropy loss function, where <code>y_inference</code> and <code>y_grountruth</code> stands for inference and target label, n stands for the number of class.</p>\n<p><img src=\"Cross%20entropy%20loss%20function.png\" alt=\"Cross entropy loss function\" style=\"zoom:22%;\" /></p>\n<p>With the one-hot label, the components are 0 except for the true category. In a other word, the <code>y_inference</code> of the wrong category is not considered at all i.e. the information of the wrong category is lost. Which is against the real word classification.</p>\n<h3 id=\"effectiveness-visualization\">Effectiveness: Visualization</h3>\n<p>In <a href=\"https://arxiv.org/pdf/1906.02629.pdf\">When does label smoothing help?</a> Hinton shows the feature map difference between without and with LSR:</p>\n<p><img src=\"Label%20smoothing%20feature%20norm.png\" alt=\"Label smoothing feature norm\" style=\"zoom:80%;\" /></p>\n<blockquote>\n<ul>\n<li>When label smoothing is applied, the clusters are much tighter because label smoothing encourages that each example in the training set is to be equidistant from all other classs templates.</li>\n<li>With hard targets, the clusters for semantically similar classes (for example different breed of dogs in ImageNet), are isotropic whereas, with label smoothing, clusters lie in an arc as shown in the third row. If you mix two semantically similar classes with a third semantically different class, the clusters are still much better than the ones obtained with hard targets as shown in the fourth row.</li>\n</ul>\n</blockquote>\n<h3 id=\"experiment-apply-in-competition\">Experiment: apply in competition</h3>\n<p>Label smoothing can be easily applied in <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy\">Tensorflow</a>, but there is no such thing in PyTorch. So overwrite the Cross-entropy loss function with LSR (implemented in 2 ways):</p>\n<pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">LSR</span>(nn.Module):\n    <span class=\"hljs-string\">&quot;&quot;&quot;NLL loss with label smoothing.</span>\n<span class=\"hljs-string\">    &quot;&quot;&quot;</span>\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, smoothing=<span class=\"hljs-number\">0.0</span></span>):\n        <span class=\"hljs-string\">&quot;&quot;&quot;Constructor for the LSR module.</span>\n<span class=\"hljs-string\">        :param smoothing: label smoothing factor</span>\n<span class=\"hljs-string\">        &quot;&quot;&quot;</span>\n        <span class=\"hljs-built_in\">super</span>(LSR, self).__init__()\n        self.confidence = <span class=\"hljs-number\">1.0</span> - smoothing\n        self.smoothing = smoothing\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, target</span>):\n        logprobs = torch.nn.functional.log_softmax(x, dim=-<span class=\"hljs-number\">1</span>)\n        nll_loss = -logprobs.gather(dim=-<span class=\"hljs-number\">1</span>, index=target.unsqueeze(<span class=\"hljs-number\">1</span>))\n        nll_loss = nll_loss.squeeze(<span class=\"hljs-number\">1</span>)\n        smooth_loss = -logprobs.mean(dim=-<span class=\"hljs-number\">1</span>)\n        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n        <span class=\"hljs-keyword\">return</span> loss.mean()\n    \nloss = LSR(<span class=\"hljs-number\">0.1</span>)</code></pre>\n<pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">LSR2</span>(nn.Module):\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, e=<span class=\"hljs-number\">0.01</span>,reduction=<span class=\"hljs-string\">&#x27;mean&#x27;</span></span>):\n        <span class=\"hljs-built_in\">super</span>().__init__()\n\n        self.log_softmax = nn.LogSoftmax(dim=<span class=\"hljs-number\">1</span>)\n        self.e = e\n        self.reduction = reduction\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_one_hot</span>(<span class=\"hljs-params\">self, labels, classes, value=<span class=\"hljs-number\">1</span></span>):\n        <span class=\"hljs-string\">&quot;&quot;&quot;</span>\n<span class=\"hljs-string\">            Convert labels to one hot vectors</span>\n<span class=\"hljs-string\"></span>\n<span class=\"hljs-string\">        Args:</span>\n<span class=\"hljs-string\">            labels: torch tensor in format [label1, label2, label3, ...]</span>\n<span class=\"hljs-string\">            classes: int, number of classes</span>\n<span class=\"hljs-string\">            value: label value in one hot vector, default to 1</span>\n<span class=\"hljs-string\"></span>\n<span class=\"hljs-string\">        Returns:</span>\n<span class=\"hljs-string\">            return one hot format labels in shape [batchsize, classes]</span>\n<span class=\"hljs-string\">        &quot;&quot;&quot;</span>\n        <span class=\"hljs-comment\">#print(&quot;classes&quot;, classes)</span>\n        one_hot = torch.zeros(labels.size(<span class=\"hljs-number\">0</span>), classes)\n\n        <span class=\"hljs-comment\"># labels and value_added  size must match</span>\n        labels = labels.view(labels.size(<span class=\"hljs-number\">0</span>), -<span class=\"hljs-number\">1</span>)\n        value_added = torch.Tensor(labels.size(<span class=\"hljs-number\">0</span>), <span class=\"hljs-number\">1</span>).fill_(value)\n\n        value_added = value_added.to(labels.device)\n        one_hot = one_hot.to(labels.device)\n\n        one_hot.scatter_add_(<span class=\"hljs-number\">1</span>, labels, value_added)\n\n        <span class=\"hljs-keyword\">return</span> one_hot\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_smooth_label</span>(<span class=\"hljs-params\">self, target, length, smooth_factor</span>):\n        <span class=\"hljs-string\">&quot;&quot;&quot;convert targets to one-hot format, and smooth</span>\n<span class=\"hljs-string\">        them.</span>\n<span class=\"hljs-string\"></span>\n<span class=\"hljs-string\">        Args:</span>\n<span class=\"hljs-string\">            target: target in form with [label1, label2, label_batchsize]</span>\n<span class=\"hljs-string\">            length: length of one-hot format(number of classes)</span>\n<span class=\"hljs-string\">            smooth_factor: smooth factor for label smooth</span>\n<span class=\"hljs-string\"></span>\n<span class=\"hljs-string\">        Returns:</span>\n<span class=\"hljs-string\">            smoothed labels in one hot format</span>\n<span class=\"hljs-string\">        &quot;&quot;&quot;</span>\n        <span class=\"hljs-comment\">#print(&quot;length&quot;, length)</span>\n        <span class=\"hljs-comment\">#print(&quot;smooth_fact&quot;, smooth_factor)</span>\n        one_hot = self._one_hot(target, length, value=<span class=\"hljs-number\">1</span> - smooth_factor)\n        one_hot += smooth_factor / length\n\n        <span class=\"hljs-keyword\">return</span> one_hot.to(target.device)\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, target</span>):\n\n        <span class=\"hljs-keyword\">if</span> x.size(<span class=\"hljs-number\">0</span>) != target.size(<span class=\"hljs-number\">0</span>):\n            <span class=\"hljs-keyword\">raise</span> ValueError(<span class=\"hljs-string\">&#x27;Expected input batchsize (&#123;&#125;) to match target batch_size(&#123;&#125;)&#x27;</span>\n                             .<span class=\"hljs-built_in\">format</span>(x.size(<span class=\"hljs-number\">0</span>), target.size(<span class=\"hljs-number\">0</span>)))\n\n        <span class=\"hljs-keyword\">if</span> x.dim() &lt; <span class=\"hljs-number\">2</span>:\n            <span class=\"hljs-keyword\">raise</span> ValueError(<span class=\"hljs-string\">&#x27;Expected input tensor to have least 2 dimensions(got &#123;&#125;)&#x27;</span>\n                             .<span class=\"hljs-built_in\">format</span>(x.size(<span class=\"hljs-number\">0</span>)))\n\n        <span class=\"hljs-keyword\">if</span> x.dim() != <span class=\"hljs-number\">2</span>:\n            <span class=\"hljs-keyword\">raise</span> ValueError(<span class=\"hljs-string\">&#x27;Only 2 dimension tensor are implemented, (got &#123;&#125;)&#x27;</span>\n                             .<span class=\"hljs-built_in\">format</span>(x.size()))\n        <span class=\"hljs-comment\">#print(&quot;x: &quot;, x)</span>\n        <span class=\"hljs-comment\">#print(&quot;target&quot;, target)</span>\n\n        smoothed_target = self._smooth_label(target, x.size(<span class=\"hljs-number\">1</span>), self.e)\n        x = self.log_softmax(x)\n        loss = torch.<span class=\"hljs-built_in\">sum</span>(- x * smoothed_target, dim=<span class=\"hljs-number\">1</span>)\n        <span class=\"hljs-keyword\">if</span> self.reduction == <span class=\"hljs-string\">&#x27;none&#x27;</span>:\n            <span class=\"hljs-keyword\">return</span> loss\n\n        <span class=\"hljs-keyword\">elif</span> self.reduction == <span class=\"hljs-string\">&#x27;sum&#x27;</span>:\n            <span class=\"hljs-keyword\">return</span> torch.<span class=\"hljs-built_in\">sum</span>(loss)\n\n        <span class=\"hljs-keyword\">elif</span> self.reduction == <span class=\"hljs-string\">&#x27;mean&#x27;</span>:\n            <span class=\"hljs-keyword\">return</span> torch.mean(loss)\n\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-keyword\">raise</span> ValueError(<span class=\"hljs-string\">&#x27;unrecognized option, expect reduction to be one of none, mean, sum&#x27;</span>)\n            \nloss = LSR2(<span class=\"hljs-number\">0.1</span>)</code></pre>\n<p>Pretrained ResNet50 is in use</p>\n<pre><code class=\"hljs shell\">lr, num_epochs, batch_size = 0.01, 10, 256</code></pre>\n<p><img src=\"accuracy%20curve%20compare%20label%20smoothing%20with%20hard%20label.png\" alt=\"accuracy curve compare label smoothing with hard label\" style=\"zoom:67%;\" /></p>\n<p>It can bee seen that the under same <code>random seed</code>, <code>batch_size</code>, <code>lr</code>, and <code>num_epochs</code>, the overall accuracy has a fascinating rise of 0.5.</p>\n<p>Then apply the LSR and run 50 epochs, with learning rate 0.005 and batch size 256, the result turns to be:</p>\n<p><img src=\"accuracy%20curve%20applying%20label%20smoothing.png\" alt=\"accuracy curve applying label smoothing\" style=\"zoom:67%;\" /></p>\n<p>It is a exciting improvement, but more tricks still in need.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>3 disadvantaged of the hard label:</p>\n<ul>\n<li>the relationship between the true label and the others is neglected, tend to be overfitting</li>\n<li>the model is tend to be over confident i.e. less generalizable</li>\n<li>more sensitive to label with noise, wrong labeled for example.</li>\n</ul>\n<p>Several good things about label smoothing:</p>\n<ul>\n<li>data augmentation by add more information, compensates for the lack of supervisory signals</li>\n<li>Improves generalizability</li>\n<li>Improves noise robust</li>\n<li>lower the feature norm</li>\n<li>Improves model calibration</li>\n</ul>\n<p>Bad things about label smoothing:</p>\n<ul>\n<li>label smoothing can't give real relationship between labels. It simply adds random noise, under fitting might happen under certain scenarios.</li>\n<li>If distill in use, the teach network preforms worse when apply label smoothing, more explanation in <a href=\"https://arxiv.org/pdf/1906.02629.pdf\">When does label smoothing help?</a></li>\n</ul>\n<h3 id=\"reference\">Reference</h3>\n<p><a href=\"https://cloud.tencent.com/developer/article/1815786\"> - Label Smoothing - + -  (tencent.com)</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg4MzU1NjQ2Mw==&amp;mid=2247495228&amp;idx=1&amp;sn=ec685adcf8a274e8235c177718868a34&amp;scene=21#wechat_redirect\">Trick (qq.com)</a></p>\n<p><a href=\"https://cloud.tencent.com/developer/article/1684298?from=article.detail.1815786\">trick--labelsmooth</a></p>\n<p><a href=\"https://blog.csdn.net/hxxjxw/article/details/115298103\">Label Smoothing  (Label smooth regularization, LSR)_hxxjxw-CSDN</a></p>\n<p><a href=\"https://medium.com/@nainaakash012/when-does-label-smoothing-help-89654ec75326\">When Does Label Smoothing Help?</a></p>\n<p><a href=\"https://gist.github.com/suvojit-0x55aa\">suvojit-0x55aa</a>/<a href=\"https://gist.github.com/suvojit-0x55aa/0afb3eefbb26d33f54e1fb9f94d6b609\">label_smoothing.py</a></p>"},{"title":"Review of Physical Informed Neural Network","author":"Ryan LI","toc":true,"declare":true,"index_img":"/index/PINN.png","date":"2022-06-08T18:20:20.000Z","_content":"\n> It's a brief note of the talk: [Physics-Informed Deep learning](https://www.bilibili.com/video/BV19a41167RU?share_source=copy_web), by [Dr. Lu Lu](https://lu.seas.upenn.edu/people/), based on the review paper: Physics-informed machine learning[^1]. During PHD, Lu Lu worked with [Prof. George Em Karniadakis](https://www.brown.edu/research/projects/crunch/george-karniadakis) in the same group proposing the PINN[^2] and now he is an assistant professor of the Pennsylvania University. \n\n<!-- more -->\n\n{% note primary %}\n\nHere, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems.\n\n{% endnote %}\n\n{% note secondary %}\n\nAdditional resouces:\n\nPapers:\n\n- [Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations, M.Raissi, P.Perdikaris, G.E.Karniadakis](https://arxiv.org/abs/1711.10561) \n\n- [Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations, M.Raissi, P.Perdikaris, G.E.Karniadakis](https://arxiv.org/abs/1711.10566)\n\nCourse and slides:\n\n- [CS 598: Deep Generative and Dynamical Models](https://arindam.cs.illinois.edu/courses/f21cs598/)\n\n- [CS598: Physics-Informed Neural Networks: A deep learning framework for solving forward and inverse problems involving nonlinear PDEs](https://arindam.cs.illinois.edu/courses/f21cs598/slides/pml11_598f21.pdf)\n- [Physics-Informed Neural Networks (PINNs)](https://mltp2020.com/Presentations/Karniadakis_NSF_MLTP2020.pdf)\n\nBlog:\n\n- [DS1 Physics Informed Neural Networks](https://cs598ban.github.io/Fall2021/ds/physics+ml/2021/11/18/DS1_blog2.html)\n\n{% endnote %}\n\n\n\n\n\n[^1]: [Karniadakis, G. E., Kevrekidis, I. G., Lu, L., Perdikaris, P., Wang, S., & Yang, L. (2021). Physics-informed machine learning. *Nature Reviews Physics*, *3*(6), 422-440.](https://scholar.google.com/scholar_url?url=https://www.nature.com/articles/s42254-021-00314-5&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=12413463696550326945&ei=ku-gYuLyIuOEywThnbSYCQ&scisig=AAGBfm2hbAYVf-NUg8tveih4kCyCAE_8rA)\n[^2]: [Raissi, M., Perdikaris, P., & Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. *Journal of Computational physics*, *378*, 686-707.](https://www.sciencedirect.com/science/article/pii/S0021999118307125)\n","source":"_posts/Review-of-Physical-Informed-Neural-Network.md","raw":"---\ntitle: Review of Physical Informed Neural Network\nauthor: Ryan LI\ntoc: true\ndeclare: true\nindex_img: /index/PINN.png\ntags:\n  - fluid dynamics\n  - deep learning\n  - paper reading\ndate: 2022-06-09 02:20:20\n---\n\n> It's a brief note of the talk: [Physics-Informed Deep learning](https://www.bilibili.com/video/BV19a41167RU?share_source=copy_web), by [Dr. Lu Lu](https://lu.seas.upenn.edu/people/), based on the review paper: Physics-informed machine learning[^1]. During PHD, Lu Lu worked with [Prof. George Em Karniadakis](https://www.brown.edu/research/projects/crunch/george-karniadakis) in the same group proposing the PINN[^2] and now he is an assistant professor of the Pennsylvania University. \n\n<!-- more -->\n\n{% note primary %}\n\nHere, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems.\n\n{% endnote %}\n\n{% note secondary %}\n\nAdditional resouces:\n\nPapers:\n\n- [Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations, M.Raissi, P.Perdikaris, G.E.Karniadakis](https://arxiv.org/abs/1711.10561) \n\n- [Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations, M.Raissi, P.Perdikaris, G.E.Karniadakis](https://arxiv.org/abs/1711.10566)\n\nCourse and slides:\n\n- [CS 598: Deep Generative and Dynamical Models](https://arindam.cs.illinois.edu/courses/f21cs598/)\n\n- [CS598: Physics-Informed Neural Networks: A deep learning framework for solving forward and inverse problems involving nonlinear PDEs](https://arindam.cs.illinois.edu/courses/f21cs598/slides/pml11_598f21.pdf)\n- [Physics-Informed Neural Networks (PINNs)](https://mltp2020.com/Presentations/Karniadakis_NSF_MLTP2020.pdf)\n\nBlog:\n\n- [DS1 Physics Informed Neural Networks](https://cs598ban.github.io/Fall2021/ds/physics+ml/2021/11/18/DS1_blog2.html)\n\n{% endnote %}\n\n\n\n\n\n[^1]: [Karniadakis, G. E., Kevrekidis, I. G., Lu, L., Perdikaris, P., Wang, S., & Yang, L. (2021). Physics-informed machine learning. *Nature Reviews Physics*, *3*(6), 422-440.](https://scholar.google.com/scholar_url?url=https://www.nature.com/articles/s42254-021-00314-5&hl=en&sa=T&oi=gsb&ct=res&cd=0&d=12413463696550326945&ei=ku-gYuLyIuOEywThnbSYCQ&scisig=AAGBfm2hbAYVf-NUg8tveih4kCyCAE_8rA)\n[^2]: [Raissi, M., Perdikaris, P., & Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. *Journal of Computational physics*, *378*, 686-707.](https://www.sciencedirect.com/science/article/pii/S0021999118307125)\n","slug":"Review-of-Physical-Informed-Neural-Network","published":1,"updated":"2022-06-23T14:53:36.396Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz22000ml8ybglkh00h0","content":"<blockquote>\n<p>It's a brief note of the talk: <a href=\"https://www.bilibili.com/video/BV19a41167RU?share_source=copy_web\">Physics-Informed Deep learning</a>, by <a href=\"https://lu.seas.upenn.edu/people/\">Dr. Lu Lu</a>, based on the review paper: Physics-informed machine learning<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Karniadakis, G. E., Kevrekidis, I. G., Lu, L., Perdikaris, P., Wang, S., &amp; Yang, L. (2021). Physics-informed machine learning. Nature Reviews Physics, 3(6), 422-440.\n\">[1]</span></a></sup>. During PHD, Lu Lu worked with <a href=\"https://www.brown.edu/research/projects/crunch/george-karniadakis\">Prof. George Em Karniadakis</a> in the same group proposing the PINN<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Raissi, M., Perdikaris, P., &amp; Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational physics, 378, 686-707.\n\">[2]</span></a></sup> and now he is an assistant professor of the Pennsylvania University.</p>\n</blockquote>\n<span id=\"more\"></span>\n<div class=\"note note-primary\">\n            <p>Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems.</p>\n          </div>\n<div class=\"note note-secondary\">\n            <p>Additional resouces:</p><p>Papers:</p><ul><li><p><a href=\"https://arxiv.org/abs/1711.10561\">Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations, M.Raissi, P.Perdikaris, G.E.Karniadakis</a></p></li><li><p><a href=\"https://arxiv.org/abs/1711.10566\">Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations, M.Raissi, P.Perdikaris, G.E.Karniadakis</a></p></li></ul><p>Course and slides:</p><ul><li><p><a href=\"https://arindam.cs.illinois.edu/courses/f21cs598/\">CS 598: Deep Generative and Dynamical Models</a></p></li><li><p><a href=\"https://arindam.cs.illinois.edu/courses/f21cs598/slides/pml11_598f21.pdf\">CS598: Physics-Informed Neural Networks: A deep learning framework for solving forward and inverse problems involving nonlinear PDEs</a></p></li><li><p><a href=\"https://mltp2020.com/Presentations/Karniadakis_NSF_MLTP2020.pdf\">Physics-Informed Neural Networks (PINNs)</a></p></li></ul><p>Blog:</p><ul><li><a href=\"https://cs598ban.github.io/Fall2021/ds/physics+ml/2021/11/18/DS1_blog2.html\">DS1 Physics Informed Neural Networks</a></li></ul>\n          </div>\n<section class=\"footnotes\">\n<div class=\"footnote-list\">\n<ol>\n<li>\n<span id=\"fn:1\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://www.nature.com/articles/s42254-021-00314-5&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=12413463696550326945&amp;ei=ku-gYuLyIuOEywThnbSYCQ&amp;scisig=AAGBfm2hbAYVf-NUg8tveih4kCyCAE_8rA\">Karniadakis, G. E., Kevrekidis, I. G., Lu, L., Perdikaris, P., Wang, S., &amp; Yang, L. (2021). Physics-informed machine learning. <em>Nature Reviews Physics</em>, <em>3</em>(6), 422-440.</a> <a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:2\" class=\"footnote-text\"><span><a href=\"https://www.sciencedirect.com/science/article/pii/S0021999118307125\">Raissi, M., Perdikaris, P., &amp; Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. <em>Journal of Computational physics</em>, <em>378</em>, 686-707.</a> <a href=\"#fnref:2\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n</ol>\n</div>\n</section>\n","site":{"data":{}},"wordcount":1455,"excerpt":"<blockquote>\n<p>It's a brief note of the talk: <a href=\"https://www.bilibili.com/video/BV19a41167RU?share_source=copy_web\">Physics-Informed Deep learning</a>, by <a href=\"https://lu.seas.upenn.edu/people/\">Dr. Lu Lu</a>, based on the review paper: Physics-informed machine learning<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Karniadakis, G. E., Kevrekidis, I. G., Lu, L., Perdikaris, P., Wang, S., &amp; Yang, L. (2021). Physics-informed machine learning. Nature Reviews Physics, 3(6), 422-440.\n\">[1]</span></a></sup>. During PHD, Lu Lu worked with <a href=\"https://www.brown.edu/research/projects/crunch/george-karniadakis\">Prof. George Em Karniadakis</a> in the same group proposing the PINN<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Raissi, M., Perdikaris, P., &amp; Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational physics, 378, 686-707.\n\">[2]</span></a></sup> and now he is an assistant professor of the Pennsylvania University.</p>\n</blockquote>","more":"<div class=\"note note-primary\">\n            <p>Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems.</p>\n          </div>\n<div class=\"note note-secondary\">\n            <p>Additional resouces:</p><p>Papers:</p><ul><li><p><a href=\"https://arxiv.org/abs/1711.10561\">Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations, M.Raissi, P.Perdikaris, G.E.Karniadakis</a></p></li><li><p><a href=\"https://arxiv.org/abs/1711.10566\">Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations, M.Raissi, P.Perdikaris, G.E.Karniadakis</a></p></li></ul><p>Course and slides:</p><ul><li><p><a href=\"https://arindam.cs.illinois.edu/courses/f21cs598/\">CS 598: Deep Generative and Dynamical Models</a></p></li><li><p><a href=\"https://arindam.cs.illinois.edu/courses/f21cs598/slides/pml11_598f21.pdf\">CS598: Physics-Informed Neural Networks: A deep learning framework for solving forward and inverse problems involving nonlinear PDEs</a></p></li><li><p><a href=\"https://mltp2020.com/Presentations/Karniadakis_NSF_MLTP2020.pdf\">Physics-Informed Neural Networks (PINNs)</a></p></li></ul><p>Blog:</p><ul><li><a href=\"https://cs598ban.github.io/Fall2021/ds/physics+ml/2021/11/18/DS1_blog2.html\">DS1 Physics Informed Neural Networks</a></li></ul>\n          </div>\n<section class=\"footnotes\">\n<div class=\"footnote-list\">\n<ol>\n<li>\n<span id=\"fn:1\" class=\"footnote-text\"><span><a href=\"https://scholar.google.com/scholar_url?url=https://www.nature.com/articles/s42254-021-00314-5&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=12413463696550326945&amp;ei=ku-gYuLyIuOEywThnbSYCQ&amp;scisig=AAGBfm2hbAYVf-NUg8tveih4kCyCAE_8rA\">Karniadakis, G. E., Kevrekidis, I. G., Lu, L., Perdikaris, P., Wang, S., &amp; Yang, L. (2021). Physics-informed machine learning. <em>Nature Reviews Physics</em>, <em>3</em>(6), 422-440.</a> <a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:2\" class=\"footnote-text\"><span><a href=\"https://www.sciencedirect.com/science/article/pii/S0021999118307125\">Raissi, M., Perdikaris, P., &amp; Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. <em>Journal of Computational physics</em>, <em>378</em>, 686-707.</a> <a href=\"#fnref:2\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n</ol>\n</div>\n</section>"},{"title":"install d2l module on apple m1 chip for deep learning","author":"Ryan LI","toc":true,"declare":true,"date":"2022-02-28T14:30:11.000Z","_content":"\n> [d2l](https://pypi.org/project/d2l/) is a small python module wheel that needed when read the useful deep learning book \"[dive into deeplearning](https://d2l.ai/)\", which provide interactive code examples implemented with [MXNet](https://mxnet.apache.org/versions/1.9.0/), PyTorch, and Tensorflow. \n>\n> But it took me ton's of time installing this module on the new M1 MacBook Air. Actually its easy, just to record this.\n\n<!-- more -->\n\n### How to install\n\n1.install miniforge\n\nalready did, easy.\n\n2.create a new environment with python=3.8\n\nm1 Mac officially support python>=3.9, but 3.8 can be installed.\n\n```shell\nconda create -n d2l python=3.8\nconda info --env\nconda activate d2l\n```\n\n3.install torch\n\ntorch==1.8.1 and torchvision==0.9.1 is recommended and tested in the book, but [# macOS is not currently supported for lts](https://pytorch.org/). \n\nSo the most convenient choice for mac is pytorch==1.10.2, torchvision==0.2.2\n\n```python\nconda install pytorch torchvision -c pytorch\n```\n\n#4.try install d2l directly\n\n```shell\nclear\npip install d2l==0.17.3\n```\n\nthousands lines of terrifying error will come out:\n\n```shell\n$ pip install d2l==0.17.3\nCollecting d2l==0.17.3\n  Using cached d2l-0.17.3-py3-none-any.whl (82 kB)\nCollecting jupyter==1.0.0\n  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\nCollecting numpy==1.18.5\n  Using cached numpy-1.18.5.zip (5.4 MB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... done\nCollecting pandas==1.2.2\n  Using cached pandas-1.2.2.tar.gz (5.5 MB)\n  Installing build dependencies ... error\n  error: subprocess-exited-with-error\n  \n   pip subprocess to install build dependencies did not run successfully.\n   exit code: 1\n  > [3659 lines of output]\n      Ignoring numpy: markers 'python_version == \"3.7\" and platform_system != \"AIX\"' don't match your environment\n      Ignoring numpy: markers 'python_version == \"3.7\" and platform_system == \"AIX\"' don't match your environment\n      Ignoring numpy: markers 'python_version == \"3.8\" and platform_system == \"AIX\"' don't match your environment\n      Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\n      Collecting setuptools\n        Using cached setuptools-60.9.3-py3-none-any.whl (1.1 MB)\n      Collecting wheel\n        Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n      Collecting Cython<3,>=0.29.21\n        Using cached Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n      Collecting numpy==1.17.3\n        Using cached numpy-1.17.3.zip (6.4 MB)\n        Preparing metadata (setup.py): started\n        Preparing metadata (setup.py): finished with status 'done'\n      Building wheels for collected packages: numpy\n        Building wheel for numpy (setup.py): started\n        Building wheel for numpy (setup.py): finished with status 'error'\n        error: subprocess-exited-with-error\n      \n         python setup.py bdist_wheel did not run successfully.\n         exit code: 1\n        > [3286 lines of output]\n            Running from numpy source directory.\n            blas_opt_info:\n            blas_mkl_info:\n            customize UnixCCompiler\n              libraries mkl_rt not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            blis_info:\n            customize UnixCCompiler\n              libraries blis not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            openblas_info:\n            customize UnixCCompiler\n            customize UnixCCompiler\n              libraries openblas not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            atlas_3_10_blas_threads_info:\n            Setting PTATLAS=ATLAS\n            customize UnixCCompiler\n              libraries tatlas not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            atlas_3_10_blas_info:\n            customize UnixCCompiler\n              libraries satlas not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            atlas_blas_threads_info:\n            Setting PTATLAS=ATLAS\n            customize UnixCCompiler\n              libraries ptf77blas,ptcblas,atlas not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            atlas_blas_info:\n            customize UnixCCompiler\n              libraries f77blas,cblas,atlas not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            accelerate_info:\n            customize UnixCCompiler\n              libraries accelerate not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n            Library accelerate was not found. Ignoring\n            customize UnixCCompiler\n              libraries veclib not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n            Library veclib was not found. Ignoring\n              FOUND:\n                extra_compile_args = ['-faltivec', '-I/System/Library/Frameworks/vecLib.framework/Headers']\n                extra_link_args = ['-Wl,-framework', '-Wl,Accelerate']\n                define_macros = [('NO_ATLAS_INFO', 3), ('HAVE_CBLAS', None)]\n      \n              FOUND:\n                extra_compile_args = ['-faltivec', '-I/System/Library/Frameworks/vecLib.framework/Headers']\n                extra_link_args = ['-Wl,-framework', '-Wl,Accelerate']\n                define_macros = [('NO_ATLAS_INFO', 3), ('HAVE_CBLAS', None)]\n      \n            /bin/sh: svnversion: command not found\n            non-existing path in 'numpy/distutils': 'site.cfg'\n            lapack_opt_info:\n            lapack_mkl_info:\n            customize UnixCCompiler\n              libraries mkl_rt not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            openblas_lapack_info:\n            customize UnixCCompiler\n            customize UnixCCompiler\n              libraries openblas not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            openblas_clapack_info:\n            customize UnixCCompiler\n            customize UnixCCompiler\n              libraries openblas,lapack not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            flame_info:\n            customize UnixCCompiler\n              libraries flame not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            atlas_3_10_threads_info:\n            Setting PTATLAS=ATLAS\n            customize UnixCCompiler\n              libraries lapack_atlas not found in /opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib\n...\n...\n...\n\t\n\t\t\t\t\t\tNone - nothing done with h_files = ['build/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath/npy_math_internal.h']\n            building library \"npysort\" sources\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/common' to include_dirs.\n            None - nothing done with h_files = ['build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/npy_sort.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/npy_partition.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/npy_binsearch.h']\n            building extension \"numpy.core._dummy\" sources\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h' to sources.\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h' to sources.\n            executing numpy/core/code_generators/generate_numpy_api.py\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h' to sources.\n            numpy.core - nothing done with h_files = ['build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h']\n            building extension \"numpy.core._multiarray_tests\" sources\n            building extension \"numpy.core._multiarray_umath\" sources\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h' to sources.\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h' to sources.\n            executing numpy/core/code_generators/generate_numpy_api.py\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h' to sources.\n            executing numpy/core/code_generators/generate_ufunc_api.py\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__ufunc_api.h' to sources.\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath' to include_dirs.\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath' to include_dirs.\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/common' to include_dirs.\n            numpy.core - nothing done with h_files = ['build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/funcs.inc', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/simd.inc', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/loops.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/matmul.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/clip.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath/npy_math_internal.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/templ_common.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__ufunc_api.h']\n            building extension \"numpy.core._umath_tests\" sources\n            building extension \"numpy.core._rational_tests\" sources\n            building extension \"numpy.core._struct_ufunc_tests\" sources\n            building extension \"numpy.core._operand_flag_tests\" sources\n            building extension \"numpy.fft._pocketfft_internal\" sources\n            building extension \"numpy.linalg.lapack_lite\" sources\n              adding 'numpy/linalg/lapack_lite/python_xerbla.c' to sources.\n            building extension \"numpy.linalg._umath_linalg\" sources\n              adding 'numpy/linalg/lapack_lite/python_xerbla.c' to sources.\n            building extension \"numpy.random.mt19937\" sources\n            building extension \"numpy.random.philox\" sources\n            building extension \"numpy.random.pcg64\" sources\n            building extension \"numpy.random.sfc64\" sources\n            building extension \"numpy.random.common\" sources\n            building extension \"numpy.random.bit_generator\" sources\n            building extension \"numpy.random.generator\" sources\n            building extension \"numpy.random.bounded_integers\" sources\n            building extension \"numpy.random.mtrand\" sources\n            building data_files sources\n            build_src: building npy-pkg config files\n            running build_py\n            copying numpy/version.py -> build/lib.macosx-11.0-arm64-3.8/numpy\n            copying build/src.macosx-11.0-arm64-3.8/numpy/__config__.py -> build/lib.macosx-11.0-arm64-3.8/numpy\n            copying build/src.macosx-11.0-arm64-3.8/numpy/distutils/__config__.py -> build/lib.macosx-11.0-arm64-3.8/numpy/distutils\n            running build_clib\n            customize UnixCCompiler\n            customize UnixCCompiler using build_clib\n            running build_ext\n            customize UnixCCompiler\n            customize UnixCCompiler using build_ext\n            building 'numpy.core._multiarray_umath' extension\n            compiling C sources\n            C compiler: gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64\n      \n            compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/umath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include/python3.8 -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -c'\n            extra options: '-faltivec -I/System/Library/Frameworks/vecLib.framework/Headers'\n            gcc: numpy/core/src/multiarray/alloc.c\n            gcc: numpy/core/src/multiarray/array_assign_scalar.c\n            gcc: numpy/core/src/multiarray/buffer.c\n            gcc: numpy/core/src/multiarray/common.c\n            gcc: numpy/core/src/multiarray/conversion_utils.c\n            gcc: numpy/core/src/multiarray/datetime_strings.c\n            gcc: numpy/core/src/multiarray/descriptor.c\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/einsum.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/hashdescr.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/lowlevel_strided_loops.c\n            gcc: numpy/core/src/multiarray/multiarraymodule.c\n            gcc: numpy/core/src/multiarray/nditer_constr.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/refcount.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/scalarapi.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/temp_elide.c\n            gcc: numpy/core/src/multiarray/vdot.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/loops.c\n            gcc: numpy/core/src/umath/ufunc_object.c\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/scalarmath.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/npymath/npy_math.c\n            gcc: numpy/core/src/common/npy_longdouble.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/npymath/halffloat.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/common/numpyos.c\n            gcc: /private/var/folders/5y/pqfqz2md0njg2slq29yxp12w0000gn/T/pip-install-mxyh83f9/numpy_51614e6143884c3bbd246341eeb3b857/numpy/_build_utils/src/apple_sgemv_fix.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitlyclang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n      \n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            error: Command \"gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64 -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/umath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include/python3.8 -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -c numpy/core/src/multiarray/array_assign_scalar.c -o build/temp.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/array_assign_scalar.o -MMD -MF build/temp.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/array_assign_scalar.o.d -faltivec -I/System/Library/Frameworks/vecLib.framework/Headers\" failed with exit status 1\n            [end of output]\n      \n        note: This error originates from a subprocess, and is likely not a problem with pip.\n      error: legacy-install-failure\n      \n       Encountered error while trying to install package.\n      > numpy\n      \n      note: This is an issue with the package mentioned above, not pip.\n      hint: See above for output from the failure.\n      [end of output]\n  \n  note: This error originates from a subprocess, and is likely not a problem with pip.\nerror: subprocess-exited-with-error\n\n pip subprocess to install build dependencies did not run successfully.\n exit code: 1\n> See above for output.\n\nnote: This error originates from a subprocess, and is likely not a problem with pip.\n```\n\nScroll to the top, it looks like `jupyter==1.0.0`, `pandas==1.2.2`, `numpy==1.18.5` are required, and numpy==1.18.5 is where the error comes from.\n\n4.As a result, install `jupyter==1.0.0` and `pandas==1.2.2` first\n\n```shell\npip install jupyter==1.0.0\n```\n\nconda can't be installed by pip, but can by conda\n\n```shell\nconda install pandas=1.2.2\n```\n\n5.numpy==1.18.5 can not be installed by pip or conda\n\nthanks to [tensorflow's wheel](https://github.com/apple/tensorflow_macos/releases/tag/v0.1alpha0), numpy==1.18.5's wheel for mac is included in the addons\n\ndownload and unzip [tensorflow_macos-0.1alpha0.tar.gz](https://github.com/apple/tensorflow_macos/releases/download/v0.1alpha0/tensorflow_macos-0.1alpha0.tar.gz)\n\ngo to the unzipped folder in terminal, and run\n\n```shell\npip install arm64/numpy-1.18.5-cp38-cp38-macosx_11_0_arm64.whl\n```\n\ncheck\n\n```shell\npip list |grep pandas\npip list |grep jupyter\npip list |grep numpy\n```\n\n```shell\npandas               1.2.2\njupyter              1.0.0\njupyter-client       7.1.2\njupyter-console      6.4.0\njupyter-core         4.9.2\njupyterlab-pygments  0.1.2\njupyterlab-widgets   1.0.2\nnumpy                1.18.5\n```\n\n5.install d2l\n\n```shell\npip install d2l\n```\n\nSucess!\n\n### Reference  \n\nhttps://zh-v2.d2l.ai/chapter_installation/index.html\n\nhttps://parthiban-kannan.medium.com/install-tensorflow-on-apple-macbook-m1-release-c1ce7e65cd0\n\nhttps://github.com/apple/tensorflow_macos/issues/48\n\n\n\n\n\n","source":"_posts/install-d2l-moudule-on-apple-m1-chip-for-deep-learning.md","raw":"---\ntitle: install d2l module on apple m1 chip for deep learning\nauthor: Ryan LI\ntoc: true\ndeclare: true\ndate: 2022-02-28 22:30:11\ntags:\n  - mac\n  - deep learning\n---\n\n> [d2l](https://pypi.org/project/d2l/) is a small python module wheel that needed when read the useful deep learning book \"[dive into deeplearning](https://d2l.ai/)\", which provide interactive code examples implemented with [MXNet](https://mxnet.apache.org/versions/1.9.0/), PyTorch, and Tensorflow. \n>\n> But it took me ton's of time installing this module on the new M1 MacBook Air. Actually its easy, just to record this.\n\n<!-- more -->\n\n### How to install\n\n1.install miniforge\n\nalready did, easy.\n\n2.create a new environment with python=3.8\n\nm1 Mac officially support python>=3.9, but 3.8 can be installed.\n\n```shell\nconda create -n d2l python=3.8\nconda info --env\nconda activate d2l\n```\n\n3.install torch\n\ntorch==1.8.1 and torchvision==0.9.1 is recommended and tested in the book, but [# macOS is not currently supported for lts](https://pytorch.org/). \n\nSo the most convenient choice for mac is pytorch==1.10.2, torchvision==0.2.2\n\n```python\nconda install pytorch torchvision -c pytorch\n```\n\n#4.try install d2l directly\n\n```shell\nclear\npip install d2l==0.17.3\n```\n\nthousands lines of terrifying error will come out:\n\n```shell\n$ pip install d2l==0.17.3\nCollecting d2l==0.17.3\n  Using cached d2l-0.17.3-py3-none-any.whl (82 kB)\nCollecting jupyter==1.0.0\n  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\nCollecting numpy==1.18.5\n  Using cached numpy-1.18.5.zip (5.4 MB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... done\nCollecting pandas==1.2.2\n  Using cached pandas-1.2.2.tar.gz (5.5 MB)\n  Installing build dependencies ... error\n  error: subprocess-exited-with-error\n  \n   pip subprocess to install build dependencies did not run successfully.\n   exit code: 1\n  > [3659 lines of output]\n      Ignoring numpy: markers 'python_version == \"3.7\" and platform_system != \"AIX\"' don't match your environment\n      Ignoring numpy: markers 'python_version == \"3.7\" and platform_system == \"AIX\"' don't match your environment\n      Ignoring numpy: markers 'python_version == \"3.8\" and platform_system == \"AIX\"' don't match your environment\n      Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\n      Collecting setuptools\n        Using cached setuptools-60.9.3-py3-none-any.whl (1.1 MB)\n      Collecting wheel\n        Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n      Collecting Cython<3,>=0.29.21\n        Using cached Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n      Collecting numpy==1.17.3\n        Using cached numpy-1.17.3.zip (6.4 MB)\n        Preparing metadata (setup.py): started\n        Preparing metadata (setup.py): finished with status 'done'\n      Building wheels for collected packages: numpy\n        Building wheel for numpy (setup.py): started\n        Building wheel for numpy (setup.py): finished with status 'error'\n        error: subprocess-exited-with-error\n      \n         python setup.py bdist_wheel did not run successfully.\n         exit code: 1\n        > [3286 lines of output]\n            Running from numpy source directory.\n            blas_opt_info:\n            blas_mkl_info:\n            customize UnixCCompiler\n              libraries mkl_rt not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            blis_info:\n            customize UnixCCompiler\n              libraries blis not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            openblas_info:\n            customize UnixCCompiler\n            customize UnixCCompiler\n              libraries openblas not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            atlas_3_10_blas_threads_info:\n            Setting PTATLAS=ATLAS\n            customize UnixCCompiler\n              libraries tatlas not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            atlas_3_10_blas_info:\n            customize UnixCCompiler\n              libraries satlas not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            atlas_blas_threads_info:\n            Setting PTATLAS=ATLAS\n            customize UnixCCompiler\n              libraries ptf77blas,ptcblas,atlas not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            atlas_blas_info:\n            customize UnixCCompiler\n              libraries f77blas,cblas,atlas not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            accelerate_info:\n            customize UnixCCompiler\n              libraries accelerate not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n            Library accelerate was not found. Ignoring\n            customize UnixCCompiler\n              libraries veclib not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n            Library veclib was not found. Ignoring\n              FOUND:\n                extra_compile_args = ['-faltivec', '-I/System/Library/Frameworks/vecLib.framework/Headers']\n                extra_link_args = ['-Wl,-framework', '-Wl,Accelerate']\n                define_macros = [('NO_ATLAS_INFO', 3), ('HAVE_CBLAS', None)]\n      \n              FOUND:\n                extra_compile_args = ['-faltivec', '-I/System/Library/Frameworks/vecLib.framework/Headers']\n                extra_link_args = ['-Wl,-framework', '-Wl,Accelerate']\n                define_macros = [('NO_ATLAS_INFO', 3), ('HAVE_CBLAS', None)]\n      \n            /bin/sh: svnversion: command not found\n            non-existing path in 'numpy/distutils': 'site.cfg'\n            lapack_opt_info:\n            lapack_mkl_info:\n            customize UnixCCompiler\n              libraries mkl_rt not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            openblas_lapack_info:\n            customize UnixCCompiler\n            customize UnixCCompiler\n              libraries openblas not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            openblas_clapack_info:\n            customize UnixCCompiler\n            customize UnixCCompiler\n              libraries openblas,lapack not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            flame_info:\n            customize UnixCCompiler\n              libraries flame not found in ['/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib', '/usr/local/lib', '/usr/lib']\n              NOT AVAILABLE\n      \n            atlas_3_10_threads_info:\n            Setting PTATLAS=ATLAS\n            customize UnixCCompiler\n              libraries lapack_atlas not found in /opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib\n...\n...\n...\n\t\n\t\t\t\t\t\tNone - nothing done with h_files = ['build/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath/npy_math_internal.h']\n            building library \"npysort\" sources\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/common' to include_dirs.\n            None - nothing done with h_files = ['build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/npy_sort.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/npy_partition.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/npy_binsearch.h']\n            building extension \"numpy.core._dummy\" sources\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h' to sources.\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h' to sources.\n            executing numpy/core/code_generators/generate_numpy_api.py\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h' to sources.\n            numpy.core - nothing done with h_files = ['build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h']\n            building extension \"numpy.core._multiarray_tests\" sources\n            building extension \"numpy.core._multiarray_umath\" sources\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h' to sources.\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h' to sources.\n            executing numpy/core/code_generators/generate_numpy_api.py\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h' to sources.\n            executing numpy/core/code_generators/generate_ufunc_api.py\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__ufunc_api.h' to sources.\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath' to include_dirs.\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath' to include_dirs.\n              adding 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/common' to include_dirs.\n            numpy.core - nothing done with h_files = ['build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/funcs.inc', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/simd.inc', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/loops.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/matmul.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/clip.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath/npy_math_internal.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/templ_common.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h', 'build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__ufunc_api.h']\n            building extension \"numpy.core._umath_tests\" sources\n            building extension \"numpy.core._rational_tests\" sources\n            building extension \"numpy.core._struct_ufunc_tests\" sources\n            building extension \"numpy.core._operand_flag_tests\" sources\n            building extension \"numpy.fft._pocketfft_internal\" sources\n            building extension \"numpy.linalg.lapack_lite\" sources\n              adding 'numpy/linalg/lapack_lite/python_xerbla.c' to sources.\n            building extension \"numpy.linalg._umath_linalg\" sources\n              adding 'numpy/linalg/lapack_lite/python_xerbla.c' to sources.\n            building extension \"numpy.random.mt19937\" sources\n            building extension \"numpy.random.philox\" sources\n            building extension \"numpy.random.pcg64\" sources\n            building extension \"numpy.random.sfc64\" sources\n            building extension \"numpy.random.common\" sources\n            building extension \"numpy.random.bit_generator\" sources\n            building extension \"numpy.random.generator\" sources\n            building extension \"numpy.random.bounded_integers\" sources\n            building extension \"numpy.random.mtrand\" sources\n            building data_files sources\n            build_src: building npy-pkg config files\n            running build_py\n            copying numpy/version.py -> build/lib.macosx-11.0-arm64-3.8/numpy\n            copying build/src.macosx-11.0-arm64-3.8/numpy/__config__.py -> build/lib.macosx-11.0-arm64-3.8/numpy\n            copying build/src.macosx-11.0-arm64-3.8/numpy/distutils/__config__.py -> build/lib.macosx-11.0-arm64-3.8/numpy/distutils\n            running build_clib\n            customize UnixCCompiler\n            customize UnixCCompiler using build_clib\n            running build_ext\n            customize UnixCCompiler\n            customize UnixCCompiler using build_ext\n            building 'numpy.core._multiarray_umath' extension\n            compiling C sources\n            C compiler: gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64\n      \n            compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/umath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include/python3.8 -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -c'\n            extra options: '-faltivec -I/System/Library/Frameworks/vecLib.framework/Headers'\n            gcc: numpy/core/src/multiarray/alloc.c\n            gcc: numpy/core/src/multiarray/array_assign_scalar.c\n            gcc: numpy/core/src/multiarray/buffer.c\n            gcc: numpy/core/src/multiarray/common.c\n            gcc: numpy/core/src/multiarray/conversion_utils.c\n            gcc: numpy/core/src/multiarray/datetime_strings.c\n            gcc: numpy/core/src/multiarray/descriptor.c\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/einsum.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/hashdescr.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/lowlevel_strided_loops.c\n            gcc: numpy/core/src/multiarray/multiarraymodule.c\n            gcc: numpy/core/src/multiarray/nditer_constr.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/refcount.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/scalarapi.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/temp_elide.c\n            gcc: numpy/core/src/multiarray/vdot.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/loops.c\n            gcc: numpy/core/src/umath/ufunc_object.c\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/scalarmath.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/npymath/npy_math.c\n            gcc: numpy/core/src/common/npy_longdouble.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/npymath/halffloat.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/common/numpyos.c\n            gcc: /private/var/folders/5y/pqfqz2md0njg2slq29yxp12w0000gn/T/pip-install-mxyh83f9/numpy_51614e6143884c3bbd246341eeb3b857/numpy/_build_utils/src/apple_sgemv_fix.c\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitlyclang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n      \n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly\n            error: Command \"gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64 -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/umath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include/python3.8 -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -c numpy/core/src/multiarray/array_assign_scalar.c -o build/temp.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/array_assign_scalar.o -MMD -MF build/temp.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/array_assign_scalar.o.d -faltivec -I/System/Library/Frameworks/vecLib.framework/Headers\" failed with exit status 1\n            [end of output]\n      \n        note: This error originates from a subprocess, and is likely not a problem with pip.\n      error: legacy-install-failure\n      \n       Encountered error while trying to install package.\n      > numpy\n      \n      note: This is an issue with the package mentioned above, not pip.\n      hint: See above for output from the failure.\n      [end of output]\n  \n  note: This error originates from a subprocess, and is likely not a problem with pip.\nerror: subprocess-exited-with-error\n\n pip subprocess to install build dependencies did not run successfully.\n exit code: 1\n> See above for output.\n\nnote: This error originates from a subprocess, and is likely not a problem with pip.\n```\n\nScroll to the top, it looks like `jupyter==1.0.0`, `pandas==1.2.2`, `numpy==1.18.5` are required, and numpy==1.18.5 is where the error comes from.\n\n4.As a result, install `jupyter==1.0.0` and `pandas==1.2.2` first\n\n```shell\npip install jupyter==1.0.0\n```\n\nconda can't be installed by pip, but can by conda\n\n```shell\nconda install pandas=1.2.2\n```\n\n5.numpy==1.18.5 can not be installed by pip or conda\n\nthanks to [tensorflow's wheel](https://github.com/apple/tensorflow_macos/releases/tag/v0.1alpha0), numpy==1.18.5's wheel for mac is included in the addons\n\ndownload and unzip [tensorflow_macos-0.1alpha0.tar.gz](https://github.com/apple/tensorflow_macos/releases/download/v0.1alpha0/tensorflow_macos-0.1alpha0.tar.gz)\n\ngo to the unzipped folder in terminal, and run\n\n```shell\npip install arm64/numpy-1.18.5-cp38-cp38-macosx_11_0_arm64.whl\n```\n\ncheck\n\n```shell\npip list |grep pandas\npip list |grep jupyter\npip list |grep numpy\n```\n\n```shell\npandas               1.2.2\njupyter              1.0.0\njupyter-client       7.1.2\njupyter-console      6.4.0\njupyter-core         4.9.2\njupyterlab-pygments  0.1.2\njupyterlab-widgets   1.0.2\nnumpy                1.18.5\n```\n\n5.install d2l\n\n```shell\npip install d2l\n```\n\nSucess!\n\n### Reference  \n\nhttps://zh-v2.d2l.ai/chapter_installation/index.html\n\nhttps://parthiban-kannan.medium.com/install-tensorflow-on-apple-macbook-m1-release-c1ce7e65cd0\n\nhttps://github.com/apple/tensorflow_macos/issues/48\n\n\n\n\n\n","slug":"install-d2l-moudule-on-apple-m1-chip-for-deep-learning","published":1,"updated":"2022-06-09T10:14:46.816Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz22000ol8ybekxjgi6w","content":"<blockquote>\n<p><a href=\"https://pypi.org/project/d2l/\">d2l</a> is a small python module wheel that needed when read the useful deep learning book \"<a href=\"https://d2l.ai/\">dive into deeplearning</a>\", which provide interactive code examples implemented with <a href=\"https://mxnet.apache.org/versions/1.9.0/\">MXNet</a>, PyTorch, and Tensorflow.</p>\n<p>But it took me ton's of time installing this module on the new M1 MacBook Air. Actually its easy, just to record this.</p>\n</blockquote>\n<span id=\"more\"></span>\n<h3 id=\"how-to-install\">How to install</h3>\n<p>1.install miniforge</p>\n<p>already did, easy.</p>\n<p>2.create a new environment with python=3.8</p>\n<p>m1 Mac officially support python&gt;=3.9, but 3.8 can be installed.</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">conda create -n d2l python=3.8\nconda info --env\nconda activate d2l</code></pre></div>\n<p>3.install torch</p>\n<p>torch==1.8.1 and torchvision==0.9.1 is recommended and tested in the book, but <a href=\"https://pytorch.org/\"># macOS is not currently supported for lts</a>.</p>\n<p>So the most convenient choice for mac is pytorch==1.10.2, torchvision==0.2.2</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">conda install pytorch torchvision -c pytorch</code></pre></div>\n<p>#4.try install d2l directly</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">clear\npip install d2l==0.17.3</code></pre></div>\n<p>thousands lines of terrifying error will come out:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">pip install d2l==0.17.3</span>\nCollecting d2l==0.17.3\n  Using cached d2l-0.17.3-py3-none-any.whl (82 kB)\nCollecting jupyter==1.0.0\n  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\nCollecting numpy==1.18.5\n  Using cached numpy-1.18.5.zip (5.4 MB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... done\nCollecting pandas==1.2.2\n  Using cached pandas-1.2.2.tar.gz (5.5 MB)\n  Installing build dependencies ... error\n  error: subprocess-exited-with-error\n  \n   pip subprocess to install build dependencies did not run successfully.\n   exit code: 1\n  &gt; [3659 lines of output]\n      Ignoring numpy: markers &#x27;python_version == &quot;3.7&quot; and platform_system != &quot;AIX&quot;&#x27; don&#x27;t match your environment\n      Ignoring numpy: markers &#x27;python_version == &quot;3.7&quot; and platform_system == &quot;AIX&quot;&#x27; don&#x27;t match your environment\n      Ignoring numpy: markers &#x27;python_version == &quot;3.8&quot; and platform_system == &quot;AIX&quot;&#x27; don&#x27;t match your environment\n      Ignoring numpy: markers &#x27;python_version &gt;= &quot;3.9&quot;&#x27; don&#x27;t match your environment\n      Collecting setuptools\n        Using cached setuptools-60.9.3-py3-none-any.whl (1.1 MB)\n      Collecting wheel\n        Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n      Collecting Cython&lt;3,&gt;=0.29.21\n        Using cached Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n      Collecting numpy==1.17.3\n        Using cached numpy-1.17.3.zip (6.4 MB)\n        Preparing metadata (setup.py): started\n        Preparing metadata (setup.py): finished with status &#x27;done&#x27;\n      Building wheels for collected packages: numpy\n        Building wheel for numpy (setup.py): started\n        Building wheel for numpy (setup.py): finished with status &#x27;error&#x27;\n        error: subprocess-exited-with-error\n      \n         python setup.py bdist_wheel did not run successfully.\n         exit code: 1\n        &gt; [3286 lines of output]\n            Running from numpy source directory.\n            blas_opt_info:\n            blas_mkl_info:\n            customize UnixCCompiler\n              libraries mkl_rt not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            blis_info:\n            customize UnixCCompiler\n              libraries blis not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            openblas_info:\n            customize UnixCCompiler\n            customize UnixCCompiler\n              libraries openblas not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            atlas_3_10_blas_threads_info:\n            Setting PTATLAS=ATLAS\n            customize UnixCCompiler\n              libraries tatlas not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            atlas_3_10_blas_info:\n            customize UnixCCompiler\n              libraries satlas not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            atlas_blas_threads_info:\n            Setting PTATLAS=ATLAS\n            customize UnixCCompiler\n              libraries ptf77blas,ptcblas,atlas not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            atlas_blas_info:\n            customize UnixCCompiler\n              libraries f77blas,cblas,atlas not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            accelerate_info:\n            customize UnixCCompiler\n              libraries accelerate not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n            Library accelerate was not found. Ignoring\n            customize UnixCCompiler\n              libraries veclib not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n            Library veclib was not found. Ignoring\n              FOUND:\n                extra_compile_args = [&#x27;-faltivec&#x27;, &#x27;-I/System/Library/Frameworks/vecLib.framework/Headers&#x27;]\n                extra_link_args = [&#x27;-Wl,-framework&#x27;, &#x27;-Wl,Accelerate&#x27;]\n                define_macros = [(&#x27;NO_ATLAS_INFO&#x27;, 3), (&#x27;HAVE_CBLAS&#x27;, None)]\n      \n              FOUND:\n                extra_compile_args = [&#x27;-faltivec&#x27;, &#x27;-I/System/Library/Frameworks/vecLib.framework/Headers&#x27;]\n                extra_link_args = [&#x27;-Wl,-framework&#x27;, &#x27;-Wl,Accelerate&#x27;]\n                define_macros = [(&#x27;NO_ATLAS_INFO&#x27;, 3), (&#x27;HAVE_CBLAS&#x27;, None)]\n      \n            /bin/sh: svnversion: command not found\n            non-existing path in &#x27;numpy/distutils&#x27;: &#x27;site.cfg&#x27;\n            lapack_opt_info:\n            lapack_mkl_info:\n            customize UnixCCompiler\n              libraries mkl_rt not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            openblas_lapack_info:\n            customize UnixCCompiler\n            customize UnixCCompiler\n              libraries openblas not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            openblas_clapack_info:\n            customize UnixCCompiler\n            customize UnixCCompiler\n              libraries openblas,lapack not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            flame_info:\n            customize UnixCCompiler\n              libraries flame not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            atlas_3_10_threads_info:\n            Setting PTATLAS=ATLAS\n            customize UnixCCompiler\n              libraries lapack_atlas not found in /opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib\n...\n...\n...\n\t\n\t\t\t\t\t\tNone - nothing done with h_files = [&#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath/npy_math_internal.h&#x27;]\n            building library &quot;npysort&quot; sources\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/common&#x27; to include_dirs.\n            None - nothing done with h_files = [&#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/npy_sort.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/npy_partition.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/npy_binsearch.h&#x27;]\n            building extension &quot;numpy.core._dummy&quot; sources\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h&#x27; to sources.\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h&#x27; to sources.\n            executing numpy/core/code_generators/generate_numpy_api.py\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h&#x27; to sources.\n            numpy.core - nothing done with h_files = [&#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h&#x27;]\n            building extension &quot;numpy.core._multiarray_tests&quot; sources\n            building extension &quot;numpy.core._multiarray_umath&quot; sources\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h&#x27; to sources.\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h&#x27; to sources.\n            executing numpy/core/code_generators/generate_numpy_api.py\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h&#x27; to sources.\n            executing numpy/core/code_generators/generate_ufunc_api.py\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__ufunc_api.h&#x27; to sources.\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath&#x27; to include_dirs.\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath&#x27; to include_dirs.\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/common&#x27; to include_dirs.\n            numpy.core - nothing done with h_files = [&#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/funcs.inc&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/simd.inc&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/loops.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/matmul.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/clip.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath/npy_math_internal.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/templ_common.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__ufunc_api.h&#x27;]\n            building extension &quot;numpy.core._umath_tests&quot; sources\n            building extension &quot;numpy.core._rational_tests&quot; sources\n            building extension &quot;numpy.core._struct_ufunc_tests&quot; sources\n            building extension &quot;numpy.core._operand_flag_tests&quot; sources\n            building extension &quot;numpy.fft._pocketfft_internal&quot; sources\n            building extension &quot;numpy.linalg.lapack_lite&quot; sources\n              adding &#x27;numpy/linalg/lapack_lite/python_xerbla.c&#x27; to sources.\n            building extension &quot;numpy.linalg._umath_linalg&quot; sources\n              adding &#x27;numpy/linalg/lapack_lite/python_xerbla.c&#x27; to sources.\n            building extension &quot;numpy.random.mt19937&quot; sources\n            building extension &quot;numpy.random.philox&quot; sources\n            building extension &quot;numpy.random.pcg64&quot; sources\n            building extension &quot;numpy.random.sfc64&quot; sources\n            building extension &quot;numpy.random.common&quot; sources\n            building extension &quot;numpy.random.bit_generator&quot; sources\n            building extension &quot;numpy.random.generator&quot; sources\n            building extension &quot;numpy.random.bounded_integers&quot; sources\n            building extension &quot;numpy.random.mtrand&quot; sources\n            building data_files sources\n            build_src: building npy-pkg config files\n            running build_py\n            copying numpy/version.py -&gt; build/lib.macosx-11.0-arm64-3.8/numpy\n            copying build/src.macosx-11.0-arm64-3.8/numpy/__config__.py -&gt; build/lib.macosx-11.0-arm64-3.8/numpy\n            copying build/src.macosx-11.0-arm64-3.8/numpy/distutils/__config__.py -&gt; build/lib.macosx-11.0-arm64-3.8/numpy/distutils\n            running build_clib\n            customize UnixCCompiler\n            customize UnixCCompiler using build_clib\n            running build_ext\n            customize UnixCCompiler\n            customize UnixCCompiler using build_ext\n            building &#x27;numpy.core._multiarray_umath&#x27; extension\n            compiling C sources\n            C compiler: gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64\n      \n            compile options: &#x27;-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/umath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include/python3.8 -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -c&#x27;\n            extra options: &#x27;-faltivec -I/System/Library/Frameworks/vecLib.framework/Headers&#x27;\n            gcc: numpy/core/src/multiarray/alloc.c\n            gcc: numpy/core/src/multiarray/array_assign_scalar.c\n            gcc: numpy/core/src/multiarray/buffer.c\n            gcc: numpy/core/src/multiarray/common.c\n            gcc: numpy/core/src/multiarray/conversion_utils.c\n            gcc: numpy/core/src/multiarray/datetime_strings.c\n            gcc: numpy/core/src/multiarray/descriptor.c\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/einsum.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/hashdescr.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/lowlevel_strided_loops.c\n            gcc: numpy/core/src/multiarray/multiarraymodule.c\n            gcc: numpy/core/src/multiarray/nditer_constr.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/refcount.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/scalarapi.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/temp_elide.c\n            gcc: numpy/core/src/multiarray/vdot.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/loops.c\n            gcc: numpy/core/src/umath/ufunc_object.c\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/scalarmath.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/npymath/npy_math.c\n            gcc: numpy/core/src/common/npy_longdouble.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/npymath/halffloat.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/common/numpyos.c\n            gcc: /private/var/folders/5y/pqfqz2md0njg2slq29yxp12w0000gn/T/pip-install-mxyh83f9/numpy_51614e6143884c3bbd246341eeb3b857/numpy/_build_utils/src/apple_sgemv_fix.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitlyclang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n      \n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            error: Command &quot;gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64 -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/umath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include/python3.8 -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -c numpy/core/src/multiarray/array_assign_scalar.c -o build/temp.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/array_assign_scalar.o -MMD -MF build/temp.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/array_assign_scalar.o.d -faltivec -I/System/Library/Frameworks/vecLib.framework/Headers&quot; failed with exit status 1\n            [end of output]\n      \n        note: This error originates from a subprocess, and is likely not a problem with pip.\n      error: legacy-install-failure\n      \n       Encountered error while trying to install package.\n      &gt; numpy\n      \n      note: This is an issue with the package mentioned above, not pip.\n      hint: See above for output from the failure.\n      [end of output]\n  \n  note: This error originates from a subprocess, and is likely not a problem with pip.\nerror: subprocess-exited-with-error\n\n pip subprocess to install build dependencies did not run successfully.\n exit code: 1\n&gt; See above for output.\n\nnote: This error originates from a subprocess, and is likely not a problem with pip.</code></pre></div>\n<p>Scroll to the top, it looks like <code>jupyter==1.0.0</code>, <code>pandas==1.2.2</code>, <code>numpy==1.18.5</code> are required, and numpy==1.18.5 is where the error comes from.</p>\n<p>4.As a result, install <code>jupyter==1.0.0</code> and <code>pandas==1.2.2</code> first</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">pip install jupyter==1.0.0</code></pre></div>\n<p>conda can't be installed by pip, but can by conda</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">conda install pandas=1.2.2</code></pre></div>\n<p>5.numpy==1.18.5 can not be installed by pip or conda</p>\n<p>thanks to <a href=\"https://github.com/apple/tensorflow_macos/releases/tag/v0.1alpha0\">tensorflow's wheel</a>, numpy==1.18.5's wheel for mac is included in the addons</p>\n<p>download and unzip <a href=\"https://github.com/apple/tensorflow_macos/releases/download/v0.1alpha0/tensorflow_macos-0.1alpha0.tar.gz\">tensorflow_macos-0.1alpha0.tar.gz</a></p>\n<p>go to the unzipped folder in terminal, and run</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">pip install arm64/numpy-1.18.5-cp38-cp38-macosx_11_0_arm64.whl</code></pre></div>\n<p>check</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">pip list |grep pandas\npip list |grep jupyter\npip list |grep numpy</code></pre></div>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">pandas               1.2.2\njupyter              1.0.0\njupyter-client       7.1.2\njupyter-console      6.4.0\njupyter-core         4.9.2\njupyterlab-pygments  0.1.2\njupyterlab-widgets   1.0.2\nnumpy                1.18.5</code></pre></div>\n<p>5.install d2l</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">pip install d2l</code></pre></div>\n<p>Sucess!</p>\n<h3 id=\"reference\">Reference</h3>\n<p>https://zh-v2.d2l.ai/chapter_installation/index.html</p>\n<p>https://parthiban-kannan.medium.com/install-tensorflow-on-apple-macbook-m1-release-c1ce7e65cd0</p>\n<p>https://github.com/apple/tensorflow_macos/issues/48</p>\n","site":{"data":{}},"wordcount":18538,"excerpt":"<blockquote>\n<p><a href=\"https://pypi.org/project/d2l/\">d2l</a> is a small python module wheel that needed when read the useful deep learning book \"<a href=\"https://d2l.ai/\">dive into deeplearning</a>\", which provide interactive code examples implemented with <a href=\"https://mxnet.apache.org/versions/1.9.0/\">MXNet</a>, PyTorch, and Tensorflow.</p>\n<p>But it took me ton's of time installing this module on the new M1 MacBook Air. Actually its easy, just to record this.</p>\n</blockquote>","more":"<h3 id=\"how-to-install\">How to install</h3>\n<p>1.install miniforge</p>\n<p>already did, easy.</p>\n<p>2.create a new environment with python=3.8</p>\n<p>m1 Mac officially support python&gt;=3.9, but 3.8 can be installed.</p>\n<pre><code class=\"hljs shell\">conda create -n d2l python=3.8\nconda info --env\nconda activate d2l</code></pre>\n<p>3.install torch</p>\n<p>torch==1.8.1 and torchvision==0.9.1 is recommended and tested in the book, but <a href=\"https://pytorch.org/\"># macOS is not currently supported for lts</a>.</p>\n<p>So the most convenient choice for mac is pytorch==1.10.2, torchvision==0.2.2</p>\n<pre><code class=\"hljs python\">conda install pytorch torchvision -c pytorch</code></pre>\n<p>#4.try install d2l directly</p>\n<pre><code class=\"hljs shell\">clear\npip install d2l==0.17.3</code></pre>\n<p>thousands lines of terrifying error will come out:</p>\n<pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$ </span><span class=\"language-bash\">pip install d2l==0.17.3</span>\nCollecting d2l==0.17.3\n  Using cached d2l-0.17.3-py3-none-any.whl (82 kB)\nCollecting jupyter==1.0.0\n  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\nCollecting numpy==1.18.5\n  Using cached numpy-1.18.5.zip (5.4 MB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... done\nCollecting pandas==1.2.2\n  Using cached pandas-1.2.2.tar.gz (5.5 MB)\n  Installing build dependencies ... error\n  error: subprocess-exited-with-error\n  \n   pip subprocess to install build dependencies did not run successfully.\n   exit code: 1\n  &gt; [3659 lines of output]\n      Ignoring numpy: markers &#x27;python_version == &quot;3.7&quot; and platform_system != &quot;AIX&quot;&#x27; don&#x27;t match your environment\n      Ignoring numpy: markers &#x27;python_version == &quot;3.7&quot; and platform_system == &quot;AIX&quot;&#x27; don&#x27;t match your environment\n      Ignoring numpy: markers &#x27;python_version == &quot;3.8&quot; and platform_system == &quot;AIX&quot;&#x27; don&#x27;t match your environment\n      Ignoring numpy: markers &#x27;python_version &gt;= &quot;3.9&quot;&#x27; don&#x27;t match your environment\n      Collecting setuptools\n        Using cached setuptools-60.9.3-py3-none-any.whl (1.1 MB)\n      Collecting wheel\n        Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n      Collecting Cython&lt;3,&gt;=0.29.21\n        Using cached Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n      Collecting numpy==1.17.3\n        Using cached numpy-1.17.3.zip (6.4 MB)\n        Preparing metadata (setup.py): started\n        Preparing metadata (setup.py): finished with status &#x27;done&#x27;\n      Building wheels for collected packages: numpy\n        Building wheel for numpy (setup.py): started\n        Building wheel for numpy (setup.py): finished with status &#x27;error&#x27;\n        error: subprocess-exited-with-error\n      \n         python setup.py bdist_wheel did not run successfully.\n         exit code: 1\n        &gt; [3286 lines of output]\n            Running from numpy source directory.\n            blas_opt_info:\n            blas_mkl_info:\n            customize UnixCCompiler\n              libraries mkl_rt not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            blis_info:\n            customize UnixCCompiler\n              libraries blis not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            openblas_info:\n            customize UnixCCompiler\n            customize UnixCCompiler\n              libraries openblas not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            atlas_3_10_blas_threads_info:\n            Setting PTATLAS=ATLAS\n            customize UnixCCompiler\n              libraries tatlas not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            atlas_3_10_blas_info:\n            customize UnixCCompiler\n              libraries satlas not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            atlas_blas_threads_info:\n            Setting PTATLAS=ATLAS\n            customize UnixCCompiler\n              libraries ptf77blas,ptcblas,atlas not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            atlas_blas_info:\n            customize UnixCCompiler\n              libraries f77blas,cblas,atlas not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            accelerate_info:\n            customize UnixCCompiler\n              libraries accelerate not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n            Library accelerate was not found. Ignoring\n            customize UnixCCompiler\n              libraries veclib not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n            Library veclib was not found. Ignoring\n              FOUND:\n                extra_compile_args = [&#x27;-faltivec&#x27;, &#x27;-I/System/Library/Frameworks/vecLib.framework/Headers&#x27;]\n                extra_link_args = [&#x27;-Wl,-framework&#x27;, &#x27;-Wl,Accelerate&#x27;]\n                define_macros = [(&#x27;NO_ATLAS_INFO&#x27;, 3), (&#x27;HAVE_CBLAS&#x27;, None)]\n      \n              FOUND:\n                extra_compile_args = [&#x27;-faltivec&#x27;, &#x27;-I/System/Library/Frameworks/vecLib.framework/Headers&#x27;]\n                extra_link_args = [&#x27;-Wl,-framework&#x27;, &#x27;-Wl,Accelerate&#x27;]\n                define_macros = [(&#x27;NO_ATLAS_INFO&#x27;, 3), (&#x27;HAVE_CBLAS&#x27;, None)]\n      \n            /bin/sh: svnversion: command not found\n            non-existing path in &#x27;numpy/distutils&#x27;: &#x27;site.cfg&#x27;\n            lapack_opt_info:\n            lapack_mkl_info:\n            customize UnixCCompiler\n              libraries mkl_rt not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            openblas_lapack_info:\n            customize UnixCCompiler\n            customize UnixCCompiler\n              libraries openblas not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            openblas_clapack_info:\n            customize UnixCCompiler\n            customize UnixCCompiler\n              libraries openblas,lapack not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            flame_info:\n            customize UnixCCompiler\n              libraries flame not found in [&#x27;/opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib&#x27;, &#x27;/usr/local/lib&#x27;, &#x27;/usr/lib&#x27;]\n              NOT AVAILABLE\n      \n            atlas_3_10_threads_info:\n            Setting PTATLAS=ATLAS\n            customize UnixCCompiler\n              libraries lapack_atlas not found in /opt/homebrew/Caskroom/miniforge/base/envs/d2d/lib\n...\n...\n...\n\t\n\t\t\t\t\t\tNone - nothing done with h_files = [&#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath/npy_math_internal.h&#x27;]\n            building library &quot;npysort&quot; sources\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/common&#x27; to include_dirs.\n            None - nothing done with h_files = [&#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/npy_sort.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/npy_partition.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/npy_binsearch.h&#x27;]\n            building extension &quot;numpy.core._dummy&quot; sources\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h&#x27; to sources.\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h&#x27; to sources.\n            executing numpy/core/code_generators/generate_numpy_api.py\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h&#x27; to sources.\n            numpy.core - nothing done with h_files = [&#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h&#x27;]\n            building extension &quot;numpy.core._multiarray_tests&quot; sources\n            building extension &quot;numpy.core._multiarray_umath&quot; sources\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h&#x27; to sources.\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h&#x27; to sources.\n            executing numpy/core/code_generators/generate_numpy_api.py\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h&#x27; to sources.\n            executing numpy/core/code_generators/generate_ufunc_api.py\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__ufunc_api.h&#x27; to sources.\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath&#x27; to include_dirs.\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath&#x27; to include_dirs.\n              adding &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/common&#x27; to include_dirs.\n            numpy.core - nothing done with h_files = [&#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/funcs.inc&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/simd.inc&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/loops.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/matmul.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/clip.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath/npy_math_internal.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/src/common/templ_common.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/config.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/_numpyconfig.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__multiarray_api.h&#x27;, &#x27;build/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy/__ufunc_api.h&#x27;]\n            building extension &quot;numpy.core._umath_tests&quot; sources\n            building extension &quot;numpy.core._rational_tests&quot; sources\n            building extension &quot;numpy.core._struct_ufunc_tests&quot; sources\n            building extension &quot;numpy.core._operand_flag_tests&quot; sources\n            building extension &quot;numpy.fft._pocketfft_internal&quot; sources\n            building extension &quot;numpy.linalg.lapack_lite&quot; sources\n              adding &#x27;numpy/linalg/lapack_lite/python_xerbla.c&#x27; to sources.\n            building extension &quot;numpy.linalg._umath_linalg&quot; sources\n              adding &#x27;numpy/linalg/lapack_lite/python_xerbla.c&#x27; to sources.\n            building extension &quot;numpy.random.mt19937&quot; sources\n            building extension &quot;numpy.random.philox&quot; sources\n            building extension &quot;numpy.random.pcg64&quot; sources\n            building extension &quot;numpy.random.sfc64&quot; sources\n            building extension &quot;numpy.random.common&quot; sources\n            building extension &quot;numpy.random.bit_generator&quot; sources\n            building extension &quot;numpy.random.generator&quot; sources\n            building extension &quot;numpy.random.bounded_integers&quot; sources\n            building extension &quot;numpy.random.mtrand&quot; sources\n            building data_files sources\n            build_src: building npy-pkg config files\n            running build_py\n            copying numpy/version.py -&gt; build/lib.macosx-11.0-arm64-3.8/numpy\n            copying build/src.macosx-11.0-arm64-3.8/numpy/__config__.py -&gt; build/lib.macosx-11.0-arm64-3.8/numpy\n            copying build/src.macosx-11.0-arm64-3.8/numpy/distutils/__config__.py -&gt; build/lib.macosx-11.0-arm64-3.8/numpy/distutils\n            running build_clib\n            customize UnixCCompiler\n            customize UnixCCompiler using build_clib\n            running build_ext\n            customize UnixCCompiler\n            customize UnixCCompiler using build_ext\n            building &#x27;numpy.core._multiarray_umath&#x27; extension\n            compiling C sources\n            C compiler: gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64\n      \n            compile options: &#x27;-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/umath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include/python3.8 -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -c&#x27;\n            extra options: &#x27;-faltivec -I/System/Library/Frameworks/vecLib.framework/Headers&#x27;\n            gcc: numpy/core/src/multiarray/alloc.c\n            gcc: numpy/core/src/multiarray/array_assign_scalar.c\n            gcc: numpy/core/src/multiarray/buffer.c\n            gcc: numpy/core/src/multiarray/common.c\n            gcc: numpy/core/src/multiarray/conversion_utils.c\n            gcc: numpy/core/src/multiarray/datetime_strings.c\n            gcc: numpy/core/src/multiarray/descriptor.c\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/einsum.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/hashdescr.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/lowlevel_strided_loops.c\n            gcc: numpy/core/src/multiarray/multiarraymodule.c\n            gcc: numpy/core/src/multiarray/nditer_constr.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/refcount.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/scalarapi.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/multiarray/temp_elide.c\n            gcc: numpy/core/src/multiarray/vdot.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/loops.c\n            gcc: numpy/core/src/umath/ufunc_object.c\n            gcc: build/src.macosx-11.0-arm64-3.8/numpy/core/src/umath/scalarmath.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/npymath/npy_math.c\n            gcc: numpy/core/src/common/npy_longdouble.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/npymath/halffloat.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            gcc: numpy/core/src/common/numpyos.c\n            gcc: /private/var/folders/5y/pqfqz2md0njg2slq29yxp12w0000gn/T/pip-install-mxyh83f9/numpy_51614e6143884c3bbd246341eeb3b857/numpy/_build_utils/src/apple_sgemv_fix.c\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitlyclang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n      \n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            clang: error: the clang compiler does not support &#x27;faltivec&#x27;, please use -maltivec and include altivec.h explicitly\n            error: Command &quot;gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include -arch arm64 -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/umath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/homebrew/Caskroom/miniforge/base/envs/d2d/include/python3.8 -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/common -Ibuild/src.macosx-11.0-arm64-3.8/numpy/core/src/npymath -c numpy/core/src/multiarray/array_assign_scalar.c -o build/temp.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/array_assign_scalar.o -MMD -MF build/temp.macosx-11.0-arm64-3.8/numpy/core/src/multiarray/array_assign_scalar.o.d -faltivec -I/System/Library/Frameworks/vecLib.framework/Headers&quot; failed with exit status 1\n            [end of output]\n      \n        note: This error originates from a subprocess, and is likely not a problem with pip.\n      error: legacy-install-failure\n      \n       Encountered error while trying to install package.\n      &gt; numpy\n      \n      note: This is an issue with the package mentioned above, not pip.\n      hint: See above for output from the failure.\n      [end of output]\n  \n  note: This error originates from a subprocess, and is likely not a problem with pip.\nerror: subprocess-exited-with-error\n\n pip subprocess to install build dependencies did not run successfully.\n exit code: 1\n&gt; See above for output.\n\nnote: This error originates from a subprocess, and is likely not a problem with pip.</code></pre>\n<p>Scroll to the top, it looks like <code>jupyter==1.0.0</code>, <code>pandas==1.2.2</code>, <code>numpy==1.18.5</code> are required, and numpy==1.18.5 is where the error comes from.</p>\n<p>4.As a result, install <code>jupyter==1.0.0</code> and <code>pandas==1.2.2</code> first</p>\n<pre><code class=\"hljs shell\">pip install jupyter==1.0.0</code></pre>\n<p>conda can't be installed by pip, but can by conda</p>\n<pre><code class=\"hljs shell\">conda install pandas=1.2.2</code></pre>\n<p>5.numpy==1.18.5 can not be installed by pip or conda</p>\n<p>thanks to <a href=\"https://github.com/apple/tensorflow_macos/releases/tag/v0.1alpha0\">tensorflow's wheel</a>, numpy==1.18.5's wheel for mac is included in the addons</p>\n<p>download and unzip <a href=\"https://github.com/apple/tensorflow_macos/releases/download/v0.1alpha0/tensorflow_macos-0.1alpha0.tar.gz\">tensorflow_macos-0.1alpha0.tar.gz</a></p>\n<p>go to the unzipped folder in terminal, and run</p>\n<pre><code class=\"hljs shell\">pip install arm64/numpy-1.18.5-cp38-cp38-macosx_11_0_arm64.whl</code></pre>\n<p>check</p>\n<pre><code class=\"hljs shell\">pip list |grep pandas\npip list |grep jupyter\npip list |grep numpy</code></pre>\n<pre><code class=\"hljs shell\">pandas               1.2.2\njupyter              1.0.0\njupyter-client       7.1.2\njupyter-console      6.4.0\njupyter-core         4.9.2\njupyterlab-pygments  0.1.2\njupyterlab-widgets   1.0.2\nnumpy                1.18.5</code></pre>\n<p>5.install d2l</p>\n<pre><code class=\"hljs shell\">pip install d2l</code></pre>\n<p>Sucess!</p>\n<h3 id=\"reference\">Reference</h3>\n<p>https://zh-v2.d2l.ai/chapter_installation/index.html</p>\n<p>https://parthiban-kannan.medium.com/install-tensorflow-on-apple-macbook-m1-release-c1ce7e65cd0</p>\n<p>https://github.com/apple/tensorflow_macos/issues/48</p>"},{"title":"Switch blog theme to FLUID","author":"Ryan LI","toc":true,"declare":true,"date":"2022-04-30T08:05:02.000Z","index_img":"/index/Switch-blog-theme-to-FLUID.png","_content":"\n> The former \"yilia\" theme starts to be buggy since it was no longer maintained. I switch to this \"FUILD\" theme, for now, hopefully it will stand longer.\n\n<!-- more -->\n\n### Reference docs\n\n[Docs](https://hexo.fluid-dev.com/docs/en/), [Preview](https://hexo.fluid-dev.com/posts/fluid-hitokoto/), [Github repo](https://github.com/fluid-dev/hexo-theme-fluid)\n\n### Switch theme to Fluid\n\n```shell\nnpm install --save hexo-theme-fluid\n```\n\nEdit `_config.yml` in the blog root directory as follows:\n\n```yaml\ntheme: fluid\n```\n\nCreate the about page manually:\n\n```bash\nhexo new page about\n```\n\nThen edit `/source/about/index.md` and add `layout` attribute.\n\nExecute the command in your blog directory\n\n```bash\nnpm update --save hexo-theme-fluid\n```\n\n### Customise\n\ncreate `_config.fluid.yml` in the blog directory and copy the content of [_config.yml](https://github.com/fluid-dev/hexo-theme-fluid/blob/master/_config.yml)\n\nAnd the config file so far is [_config.fluid.yml](https://github.com/DaydreamAtNight/self_blog_hexo_backup/blob/main/_config.fluid.yml)\n\ndone\n\n... way easier than the theme before\n\n### Additional settings\n\n#### Compress files add-on\n\n [hexo-all-minifier](https://github.com/chenzhutian/hexo-all-minifier) is an easy and effective add-on to compress the images and bigger css/js files. \n\n```\nnpm install hexo-all-minifier --save\n```\n\nConfig it in `config.yml`.\n\n```\nall_minifier: true\n```\n","source":"_posts/Switch-blog-theme-to-FLUID.md","raw":"---\ntitle: Switch blog theme to FLUID\nauthor: Ryan LI\ntoc: true\ndeclare: true\ndate: 2022-04-30 16:05:02\nindex_img: /index/Switch-blog-theme-to-FLUID.png\ntags:\n  - hexo\n  - blog\n---\n\n> The former \"yilia\" theme starts to be buggy since it was no longer maintained. I switch to this \"FUILD\" theme, for now, hopefully it will stand longer.\n\n<!-- more -->\n\n### Reference docs\n\n[Docs](https://hexo.fluid-dev.com/docs/en/), [Preview](https://hexo.fluid-dev.com/posts/fluid-hitokoto/), [Github repo](https://github.com/fluid-dev/hexo-theme-fluid)\n\n### Switch theme to Fluid\n\n```shell\nnpm install --save hexo-theme-fluid\n```\n\nEdit `_config.yml` in the blog root directory as follows:\n\n```yaml\ntheme: fluid\n```\n\nCreate the about page manually:\n\n```bash\nhexo new page about\n```\n\nThen edit `/source/about/index.md` and add `layout` attribute.\n\nExecute the command in your blog directory\n\n```bash\nnpm update --save hexo-theme-fluid\n```\n\n### Customise\n\ncreate `_config.fluid.yml` in the blog directory and copy the content of [_config.yml](https://github.com/fluid-dev/hexo-theme-fluid/blob/master/_config.yml)\n\nAnd the config file so far is [_config.fluid.yml](https://github.com/DaydreamAtNight/self_blog_hexo_backup/blob/main/_config.fluid.yml)\n\ndone\n\n... way easier than the theme before\n\n### Additional settings\n\n#### Compress files add-on\n\n [hexo-all-minifier](https://github.com/chenzhutian/hexo-all-minifier) is an easy and effective add-on to compress the images and bigger css/js files. \n\n```\nnpm install hexo-all-minifier --save\n```\n\nConfig it in `config.yml`.\n\n```\nall_minifier: true\n```\n","slug":"Switch-blog-theme-to-FLUID","published":1,"updated":"2022-05-28T03:47:03.981Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz23000ql8ybbofvh476","content":"<blockquote>\n<p>The former \"yilia\" theme starts to be buggy since it was no longer maintained. I switch to this \"FUILD\" theme, for now, hopefully it will stand longer.</p>\n</blockquote>\n<span id=\"more\"></span>\n<h3 id=\"reference-docs\">Reference docs</h3>\n<p><a href=\"https://hexo.fluid-dev.com/docs/en/\">Docs</a>, <a href=\"https://hexo.fluid-dev.com/posts/fluid-hitokoto/\">Preview</a>, <a href=\"https://github.com/fluid-dev/hexo-theme-fluid\">Github repo</a></p>\n<h3 id=\"switch-theme-to-fluid\">Switch theme to Fluid</h3>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">npm install --save hexo-theme-fluid</code></pre></div>\n<p>Edit <code>_config.yml</code> in the blog root directory as follows:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">theme:</span> <span class=\"hljs-string\">fluid</span></code></pre></div>\n<p>Create the about page manually:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs bash\">hexo new page about</code></pre></div>\n<p>Then edit <code>/source/about/index.md</code> and add <code>layout</code> attribute.</p>\n<p>Execute the command in your blog directory</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs bash\">npm update --save hexo-theme-fluid</code></pre></div>\n<h3 id=\"customise\">Customise</h3>\n<p>create <code>_config.fluid.yml</code> in the blog directory and copy the content of <a href=\"https://github.com/fluid-dev/hexo-theme-fluid/blob/master/_config.yml\">_config.yml</a></p>\n<p>And the config file so far is <a href=\"https://github.com/DaydreamAtNight/self_blog_hexo_backup/blob/main/_config.fluid.yml\">_config.fluid.yml</a></p>\n<p>done</p>\n<p>... way easier than the theme before</p>\n<h3 id=\"additional-settings\">Additional settings</h3>\n<h4 id=\"compress-files-add-on\">Compress files add-on</h4>\n<p><a href=\"https://github.com/chenzhutian/hexo-all-minifier\">hexo-all-minifier</a> is an easy and effective add-on to compress the images and bigger css/js files.</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs ada\">npm install hexo-<span class=\"hljs-keyword\">all</span>-minifier <span class=\"hljs-comment\">--save</span></code></pre></div>\n<p>Config it in <code>config.yml</code>.</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">all_minifier:</span> <span class=\"hljs-literal\">true</span></code></pre></div>\n","site":{"data":{}},"wordcount":777,"excerpt":"<blockquote>\n<p>The former \"yilia\" theme starts to be buggy since it was no longer maintained. I switch to this \"FUILD\" theme, for now, hopefully it will stand longer.</p>\n</blockquote>","more":"<h3 id=\"reference-docs\">Reference docs</h3>\n<p><a href=\"https://hexo.fluid-dev.com/docs/en/\">Docs</a>, <a href=\"https://hexo.fluid-dev.com/posts/fluid-hitokoto/\">Preview</a>, <a href=\"https://github.com/fluid-dev/hexo-theme-fluid\">Github repo</a></p>\n<h3 id=\"switch-theme-to-fluid\">Switch theme to Fluid</h3>\n<pre><code class=\"hljs shell\">npm install --save hexo-theme-fluid</code></pre>\n<p>Edit <code>_config.yml</code> in the blog root directory as follows:</p>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">theme:</span> <span class=\"hljs-string\">fluid</span></code></pre>\n<p>Create the about page manually:</p>\n<pre><code class=\"hljs bash\">hexo new page about</code></pre>\n<p>Then edit <code>/source/about/index.md</code> and add <code>layout</code> attribute.</p>\n<p>Execute the command in your blog directory</p>\n<pre><code class=\"hljs bash\">npm update --save hexo-theme-fluid</code></pre>\n<h3 id=\"customise\">Customise</h3>\n<p>create <code>_config.fluid.yml</code> in the blog directory and copy the content of <a href=\"https://github.com/fluid-dev/hexo-theme-fluid/blob/master/_config.yml\">_config.yml</a></p>\n<p>And the config file so far is <a href=\"https://github.com/DaydreamAtNight/self_blog_hexo_backup/blob/main/_config.fluid.yml\">_config.fluid.yml</a></p>\n<p>done</p>\n<p>... way easier than the theme before</p>\n<h3 id=\"additional-settings\">Additional settings</h3>\n<h4 id=\"compress-files-add-on\">Compress files add-on</h4>\n<p><a href=\"https://github.com/chenzhutian/hexo-all-minifier\">hexo-all-minifier</a> is an easy and effective add-on to compress the images and bigger css/js files.</p>\n<pre><code class=\"hljs ada\">npm install hexo-<span class=\"hljs-keyword\">all</span>-minifier <span class=\"hljs-comment\">--save</span></code></pre>\n<p>Config it in <code>config.yml</code>.</p>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">all_minifier:</span> <span class=\"hljs-literal\">true</span></code></pre>"},{"title":"learning rate schedule","author":"Ryan LI","toc":true,"declare":true,"date":"2022-03-08T01:32:32.000Z","_content":"\n> Learning rate schedule is one commonly used trick to control the process of training. Different kinds of learning tricks are presented every day. In this article, I have put together classical methods theories and apply them in this little competition.\n\n> Recently, I joined a [Kaggle image classification competition](https://www.kaggle.com/c/classify-leaves/), I used the pretrained ResNet50 plus other tricks and here is to record some of them I've learned for now. \n\n<!-- more -->\n\n### Introduction\n\nLearning rate is one critical parameter in alliterative algorithms, including PDE and ODE solving, optimization, and eigenvalue calculation. In the deep learning area, the learning rate is more than critical because of the notorious difficulty on [Stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent).\n\nStrictly, there are two ways of adjusting the learning rate: \n\n- learning rate scheduling: \n\n  adjust the global learning rate during iteration\n\n- adaptive learning rate: \n\n  adjust the learning rate for each parameter based on their gradients updates(moments), also called adaptive gradient or gradient descent optimization.\n\nIn this article, **learning rate schedule is mainly discussed**. Afterward, \"learning rate\" refers to the \"global learning rate\".\n\n### Methods of learning rate scheduling\n\nApart from the constant learning rate, there are several ways to schedule the learning rate:\n\n  - change with epoch numbers\n    -   learning rate decay: linear, step...\n    \n    -   learning rate down then up: stochastic gradient descent with warm restarts(SGDR) and Cyclical Learning rates(CLR) \n    \n    -  warmup\n  \n  - change on some validation measurements: plateau \n\n#### learning rate decay\n\nUnder the upper concepts of decaying the learning rate while training, how to choose a specific decay policy is personal. It can be continuous or step, linear or polynomial, exponential or trigonometric. \n\nIn articles, stepped learning rate decay is more often used as the default choice. For example, [Zagoruyko, S., & Komodakis, N ](https://arxiv.org/abs/1605.07146) set the initial learning rate as 0.1 and drop it by 0.2 every 60 epochs on their modified version of ResNet. And this version of learning rate decay is set as the control group to compare with the SGDR strategy later in [Ilya Loshchilov & Frank Hutter's work](https://arxiv.org/abs/1608.03983).  And in practice, the cosine annealing policy is a common choice today and can be used either alone or in combination with warmup and SGDR.\n\n##### Explanation\n\nBecause of the presence of stochastic noise, the entire gradient descent process is not straightforward. With a constant learning rate, as shown in the gradient contour map below, the minima can not be reached with a constant step (blue) due to the relatively small steps at the bottom. And a lower minimum can be reached if the learning rate descends with the gradient i.e. epoch(green).\n\n  <img src=\"SGD%20with%20learning%20rate%20decay.png\" alt=\"SGD with learning rate decay\" style=\"zoom:80%;\" />\n\n  #### SGDR and CLR\n\n  ##### SGDR\n\nStochastic gradient descent with warm restarts(SGDR) is firstly proposed to Deep learning in [Ilya Loshchilov & Frank Hutter's work](https://arxiv.org/abs/1608.03983). They introduced a policy of reinitializing the learning rate every certain number of epochs. Applying cosine annealing learning rate decay during each resulting \"mini-run\", the results perform fascinating.\n\n  <img src=\"SGDR.png\" alt=\"SGDR\" style=\"zoom:75%;\" />\n\n  <img src=\"SGDR_REsult.png\" alt=\"SGDR_REsult\" style=\"zoom:100%;\" />\n\nAs shown in the charts, compared to 2 default step learnin rate decay policies, they enacted several SGDR policies with different T_0 and T_mul. T_0 refers to the epoch interval of the first \"mini-run\" and the epoch interval is multiplied by T_mul after each restart. As a result, at the ith \"mini-run\", T_i = T_0*T_mul^(i) \n\nAnd they suggests a SGDR policy with a small T0 = 1 or 10 at start, and set Tmult = 2 to double the epoch interval after every restart. And they claim by this policy, at least 2 to 4 fewer epochs are required to achieve a comparable result than before.\n\n  ##### CLR\n\nA similar method called cyclical Learning rates(CLR) is proposed later by [Leslie N. Smith](https://ieeexplore.ieee.org/abstract/document/7926641/), where 2 kinds of triangular and exponential CLR policies are demonstrated on CIFAR-10 and CIFAR-100 with most kinds of mainstream CNN modules.\n\n  <img src=\"CLR.png\" alt=\"CLR\" style=\"zoom:75%;\" />\n\nSimilarly, compared with a default fixed learnin rate, the demonstrats that their policies outperforms in accuracy and efficiency on several datasetes.\n\n  > one obtains the same test classification accuracy of 81.4% after only 25, 000 iterations with the triangular2 policy as obtained by running the standard hyper-parameter settings for 70, 000 iterations.  \n\n  ##### explanation\n\nBecause of the nonconvexity, it is common sense that reaching a global minima is impossible. With a standard learning rate decay, a saddle point, or unstable local minima is more likely to trap the descending process as shown below. But cyclical Learning rates(CLR) and stochastic gradient descent with warm restarts(SGDR) would allow the process to  jump from one local minimum to another regularly until a stable one.\n\n  <img src=\"2d%20cyclic%20learning%20rate%20schedule.png\" alt=\"2d cyclic learning rate schedule\" style=\"zoom:80%;\" />\n\n  <img src=\"cyclic%20learning%20rate%20schedule.png\" alt=\"cyclic learning rate schedule\" style=\"zoom:80%;\" />\n\nStill there are several choices, but Cosine Cyclical and Cosine Annealing with Warm Restarts are more common.\n\n  #### learning rate warmup\n\nLearning rate warmup is first applied in the famous [Resnet](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) paper in one of its experiments.\n\n  > In this case, we find that the initial learning rate of 0.1 is slightly too large to start converging5 . So we use 0.01 to warm up the training until the training error is below 80% (about 400 iterations), and then go back to 0.1 and continue training.  \n\nAnd later [Goyal and He's work](https://arxiv.org/pdf/1706.02677.pdf) makes a major influence, where constant and gradual methods of warmup are discussed. And gradual warmup is proved to be effective on large minibatch size.\n\n  > As we discussed, for large minibatches (e.g., 8k) the linear scaling rule breaks down when the network is changing rapidly, which commonly occurs in early stages of training. We find that this issue can be alleviated by a properly designed warmup [16], namely, a strategy of using less aggressive learning rates at the start of training. \n\n  <img src=\"warmup%20on%20large%20batches.png\" alt=\"warmup on large batches\" style=\"zoom:100%;\" />\n\nIn practice, warmup are always combined with other learning rate methods afterwards. And linear warmup is a default method.\n\n  #### Reducing the learning rate on plateau\n\nApart from methods scheduling the learning rate with epoch, a dynamic learning rate decay method is also an option. It denotes the process of decaying the learning rate only when the optimizer fails to improve the accuracy or decrease the loss in serval epochs. \n\nFor example, in [AlexNet](https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html), \n\n> The heuristic which we followed was to divide the learning rate by 10 when the validation error rate stopped improving with the current learning rate. The learning rate was initialized at 0.01 and reduced three times prior to termination.\n\nIn  [Resnet](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) after the warm-up,\n\n> The learning rate starts from 0.1 and is divided by 10 when the error plateaus\n\n\n\n### Apply learning rate scheduling in PyTorch\n\n> `torch.optim.lr_scheduler` provides several methods to adjust the learning rate based on the number of epochs. \n\nFor example, \n\n```python\ndef train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n    print('training on', device)\n    net.to(device)\n    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs*len(train_iter)/10, eta_min=1e-9)\n    loss = LSR(0.1) \n    for epoch in range(num_epochs):\n        net.train()\n        for i, (X, y) in enumerate(train_iter):\n            X, y = X.to(device), y.to(device)\n            optimizer.zero_grad()\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            optimizer.step()\n            scheduler.step()\n```\n\nApart from well defined `lr_scheduler` ,  `torch.optim.lr_scheduler.LambdaLR` allow us to apply self define scheduler such as:\n\n```python\nprint('training on', device)\nnet.to(device)\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\n\nt=10*len(train_iter)#warmup\nT=num_epochs*len(train_iter)\nlambda1 = lambda epoch: (0.9*epoch / t+0.1) if epoch < t else  0.1  if 0.5 * (1+math.cos(math.pi*(epoch - t)/(T-t)))<0.1 else 0.5 * (1+math.cos(math.pi*(epoch - t)/(T-t)))\n\nscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n\n# plot learningrate_decay\nlr_plot = []\nfor _i in range(num_epochs):\n    for _j in range(len(train_iter)):\n        optimizer.step()\n        lr_plot.append(optimizer.param_groups[0][\"lr\"])\n        scheduler.step()\nplt.plot(lr_plot)\n```\n### Should we do scheduling with adaptive learning rate method?\n\nFrom [Should we do learning rate decay for adam optimizer](https://stackoverflow.com/questions/39517431/should-we-do-learning-rate-decay-for-adam-optimizer)?, I found it as a arguable question.\n\n>It depends. ADAM updates any parameter with an individual learning rate. This means that every parameter in the network has a specific learning rate associated. \n>\n>But* the single learning rate for each parameter is computed using lambda (the initial learning rate) as an upper limit. This means that every single learning rate can vary from 0 (no update) to lambda (maximum update).\n>\n>It's true, that the learning rates adapt themselves during training steps, but if you want to be sure that every update step doesn't exceed lambda you can than lower lambda using exponential decay or whatever. It can help to reduce loss during the latest step of training, when the computed loss with the previously associated lambda parameter has stopped to decrease.\n\n>  In my experience it usually not necessary to do learning rate decay with Adam optimizer. \n>\n> The theory is that Adam already handles learning rate optimization ([check reference](http://arxiv.org/pdf/1412.6980v8.pdf)) :\n>\n> > \"We propose Adam, a method for efficient stochastic optimization that only requires first-order gradients with little memory requirement. The method **computes individual adaptive learning rates** for different parameters from estimates of first and second moments of the gradients; the name Adam is derived from adaptive moment estimation.\"\n>\n> As with any deep learning problem YMMV, one size does not fit all, you should try different approaches and see what works for you, etc. etc.\n\n>\n>  Yes, absolutely. From my own experience, it's very useful to Adam with learning rate decay. Without decay, you have to set a very small learning rate so the loss won't begin to diverge after decrease to a point.\n\nBut in the article [Decoupled weight decay regularization](https://arxiv.org/abs/1711.05101)(AdamW), it is encouraged.\n\n> Adam can substantially benefit from a scheduled learning rate multiplier. The fact that Adam is an adaptive gradient algorithm and as such adapts the learning rate for each parameter does not rule out the possibility to substantially improve its performance by using a global learning rate multiplier, scheduled, e.g., by cosine annealing.  \n\nIn the CLR article, the authors encourage the combination of CLR methods with Adam as well.\n\n> Adaptive learning rates are fundamentally different from CLR policies, and CLR can be combined with adaptive learning rates, as shown in Section 4.1. I \n\nAll in all, theoretically, the adaptive learning rate methods such as Adam adjust the learning rate for each parameters under a upper limit as the global learning rate, which can be adjusted by scheduling. \n\nIn practice, at least SGDR and CLR have been proved to be useful combining with optimizers.\n\n### Experiment: Adam vs Adam + SGDR \n\nIn this little experiment, the best setting in the last article is set as baseline, with Adam with constant learning rate. Leave other settings, Adam with cosine annealing learning rate, and AdamW with cosine annealing learning rate are compared.\n\n`global learning rate = 0.005` \n\n`scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = **int**(num_epochs***len**(train_iter)/10), T_mult=1, eta_min=1e-9)`\n\n<img src=\"experiment.png\" alt=\"experiment\" style=\"zoom:80%;\" />\n\nAs shown in the line charts, SGDR lift both the training and test accuracies. And the overfitting of the baseline method is alleviated as well. \n\nIn the second and  sub-figure, the fluctuation in the process of gradient descend caused by the cosine learning rate is obvious. And after each learning rate restart, the rate of the descend also gets a restart.  And it takes fewer epochs than to get the same accuracy than the baseline.\n\n### Reference\n\n[Kingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. *arXiv preprint arXiv:1412.6980*.](https://arxiv.org/pdf/1412.6980.pdf)\n\n[Adaptive Learning Rate Method](https://wiki.tum.de/display/lfdv/Adaptive+Learning+Rate+Method) \n\n[Learning Rate Schedules and Adaptive Learning Rate Methods](https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1) \n\n[Learning Rate Decay and methods in Deep Learning](https://medium.com/analytics-vidhya/learning-rate-decay-and-methods-in-deep-learning-2cee564f910b#:~:text=Learning%20rate%20decay%20is%20a,help%20both%20optimization%20and%20generalization.) \n\n[A Newbies Guide to Stochastic Gradient Descent With Restarts](https://towardsdatascience.com/https-medium-com-reina-wang-tw-stochastic-gradient-descent-with-restarts-5f511975163)\n\n[Zagoruyko, S., & Komodakis, N. (2016). Wide residual networks. *arXiv preprint arXiv:1605.07146*.](https://arxiv.org/abs/1605.07146)\n\n[Loshchilov, I., & Hutter, F. (2016). Sgdr: Stochastic gradient descent with warm restarts. *arXiv preprint arXiv:1608.03983*.](https://arxiv.org/abs/1608.03983) \n\n[Smith, L. N. (2017, March). Cyclical learning rates for training neural networks. In *2017 IEEE winter conference on applications of computer vision (WACV)* (pp. 464-472). IEEE.](https://ieeexplore.ieee.org/abstract/document/7926641/) \n\n[He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 770-778).](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) \n\n[Goyal, P., Dollr, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., ... & He, K. (2017). Accurate, large minibatch sgd: Training imagenet in 1 hour. *arXiv preprint arXiv:1706.02677*.](https://arxiv.org/abs/1706.0267)\n\n[Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. *Advances in neural information processing systems*, *25*.](https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)\n\n[torch.optim  PyTorch 1.10 documentation](https://pytorch.org/docs/stable/optim.html) \n\n[Should we do learning rate decay for adam optimizer](https://stackoverflow.com/questions/39517431/should-we-do-learning-rate-decay-for-adam-optimizer)\n\n[Loshchilov, I., & Hutter, F. (2017). Decoupled weight decay regularization. *arXiv preprint arXiv:1711.05101*.](https://arxiv.org/abs/1711.05101)\n\n[Guide to Pytorch Learning Rate Scheduling](https://www.kaggle.com/isbhargav/guide-to-pytorch-learning-rate-scheduling)","source":"_posts/learning-rate-schedule.md","raw":"---\ntitle: learning rate schedule\nauthor: Ryan LI\ntoc: true\ndeclare: true\ndate: 2022-03-08 09:32:32\ntags:\n\t- deep learning\n\t- deep learning tricks\n---\n\n> Learning rate schedule is one commonly used trick to control the process of training. Different kinds of learning tricks are presented every day. In this article, I have put together classical methods theories and apply them in this little competition.\n\n> Recently, I joined a [Kaggle image classification competition](https://www.kaggle.com/c/classify-leaves/), I used the pretrained ResNet50 plus other tricks and here is to record some of them I've learned for now. \n\n<!-- more -->\n\n### Introduction\n\nLearning rate is one critical parameter in alliterative algorithms, including PDE and ODE solving, optimization, and eigenvalue calculation. In the deep learning area, the learning rate is more than critical because of the notorious difficulty on [Stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent).\n\nStrictly, there are two ways of adjusting the learning rate: \n\n- learning rate scheduling: \n\n  adjust the global learning rate during iteration\n\n- adaptive learning rate: \n\n  adjust the learning rate for each parameter based on their gradients updates(moments), also called adaptive gradient or gradient descent optimization.\n\nIn this article, **learning rate schedule is mainly discussed**. Afterward, \"learning rate\" refers to the \"global learning rate\".\n\n### Methods of learning rate scheduling\n\nApart from the constant learning rate, there are several ways to schedule the learning rate:\n\n  - change with epoch numbers\n    -   learning rate decay: linear, step...\n    \n    -   learning rate down then up: stochastic gradient descent with warm restarts(SGDR) and Cyclical Learning rates(CLR) \n    \n    -  warmup\n  \n  - change on some validation measurements: plateau \n\n#### learning rate decay\n\nUnder the upper concepts of decaying the learning rate while training, how to choose a specific decay policy is personal. It can be continuous or step, linear or polynomial, exponential or trigonometric. \n\nIn articles, stepped learning rate decay is more often used as the default choice. For example, [Zagoruyko, S., & Komodakis, N ](https://arxiv.org/abs/1605.07146) set the initial learning rate as 0.1 and drop it by 0.2 every 60 epochs on their modified version of ResNet. And this version of learning rate decay is set as the control group to compare with the SGDR strategy later in [Ilya Loshchilov & Frank Hutter's work](https://arxiv.org/abs/1608.03983).  And in practice, the cosine annealing policy is a common choice today and can be used either alone or in combination with warmup and SGDR.\n\n##### Explanation\n\nBecause of the presence of stochastic noise, the entire gradient descent process is not straightforward. With a constant learning rate, as shown in the gradient contour map below, the minima can not be reached with a constant step (blue) due to the relatively small steps at the bottom. And a lower minimum can be reached if the learning rate descends with the gradient i.e. epoch(green).\n\n  <img src=\"SGD%20with%20learning%20rate%20decay.png\" alt=\"SGD with learning rate decay\" style=\"zoom:80%;\" />\n\n  #### SGDR and CLR\n\n  ##### SGDR\n\nStochastic gradient descent with warm restarts(SGDR) is firstly proposed to Deep learning in [Ilya Loshchilov & Frank Hutter's work](https://arxiv.org/abs/1608.03983). They introduced a policy of reinitializing the learning rate every certain number of epochs. Applying cosine annealing learning rate decay during each resulting \"mini-run\", the results perform fascinating.\n\n  <img src=\"SGDR.png\" alt=\"SGDR\" style=\"zoom:75%;\" />\n\n  <img src=\"SGDR_REsult.png\" alt=\"SGDR_REsult\" style=\"zoom:100%;\" />\n\nAs shown in the charts, compared to 2 default step learnin rate decay policies, they enacted several SGDR policies with different T_0 and T_mul. T_0 refers to the epoch interval of the first \"mini-run\" and the epoch interval is multiplied by T_mul after each restart. As a result, at the ith \"mini-run\", T_i = T_0*T_mul^(i) \n\nAnd they suggests a SGDR policy with a small T0 = 1 or 10 at start, and set Tmult = 2 to double the epoch interval after every restart. And they claim by this policy, at least 2 to 4 fewer epochs are required to achieve a comparable result than before.\n\n  ##### CLR\n\nA similar method called cyclical Learning rates(CLR) is proposed later by [Leslie N. Smith](https://ieeexplore.ieee.org/abstract/document/7926641/), where 2 kinds of triangular and exponential CLR policies are demonstrated on CIFAR-10 and CIFAR-100 with most kinds of mainstream CNN modules.\n\n  <img src=\"CLR.png\" alt=\"CLR\" style=\"zoom:75%;\" />\n\nSimilarly, compared with a default fixed learnin rate, the demonstrats that their policies outperforms in accuracy and efficiency on several datasetes.\n\n  > one obtains the same test classification accuracy of 81.4% after only 25, 000 iterations with the triangular2 policy as obtained by running the standard hyper-parameter settings for 70, 000 iterations.  \n\n  ##### explanation\n\nBecause of the nonconvexity, it is common sense that reaching a global minima is impossible. With a standard learning rate decay, a saddle point, or unstable local minima is more likely to trap the descending process as shown below. But cyclical Learning rates(CLR) and stochastic gradient descent with warm restarts(SGDR) would allow the process to  jump from one local minimum to another regularly until a stable one.\n\n  <img src=\"2d%20cyclic%20learning%20rate%20schedule.png\" alt=\"2d cyclic learning rate schedule\" style=\"zoom:80%;\" />\n\n  <img src=\"cyclic%20learning%20rate%20schedule.png\" alt=\"cyclic learning rate schedule\" style=\"zoom:80%;\" />\n\nStill there are several choices, but Cosine Cyclical and Cosine Annealing with Warm Restarts are more common.\n\n  #### learning rate warmup\n\nLearning rate warmup is first applied in the famous [Resnet](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) paper in one of its experiments.\n\n  > In this case, we find that the initial learning rate of 0.1 is slightly too large to start converging5 . So we use 0.01 to warm up the training until the training error is below 80% (about 400 iterations), and then go back to 0.1 and continue training.  \n\nAnd later [Goyal and He's work](https://arxiv.org/pdf/1706.02677.pdf) makes a major influence, where constant and gradual methods of warmup are discussed. And gradual warmup is proved to be effective on large minibatch size.\n\n  > As we discussed, for large minibatches (e.g., 8k) the linear scaling rule breaks down when the network is changing rapidly, which commonly occurs in early stages of training. We find that this issue can be alleviated by a properly designed warmup [16], namely, a strategy of using less aggressive learning rates at the start of training. \n\n  <img src=\"warmup%20on%20large%20batches.png\" alt=\"warmup on large batches\" style=\"zoom:100%;\" />\n\nIn practice, warmup are always combined with other learning rate methods afterwards. And linear warmup is a default method.\n\n  #### Reducing the learning rate on plateau\n\nApart from methods scheduling the learning rate with epoch, a dynamic learning rate decay method is also an option. It denotes the process of decaying the learning rate only when the optimizer fails to improve the accuracy or decrease the loss in serval epochs. \n\nFor example, in [AlexNet](https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html), \n\n> The heuristic which we followed was to divide the learning rate by 10 when the validation error rate stopped improving with the current learning rate. The learning rate was initialized at 0.01 and reduced three times prior to termination.\n\nIn  [Resnet](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) after the warm-up,\n\n> The learning rate starts from 0.1 and is divided by 10 when the error plateaus\n\n\n\n### Apply learning rate scheduling in PyTorch\n\n> `torch.optim.lr_scheduler` provides several methods to adjust the learning rate based on the number of epochs. \n\nFor example, \n\n```python\ndef train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n    print('training on', device)\n    net.to(device)\n    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs*len(train_iter)/10, eta_min=1e-9)\n    loss = LSR(0.1) \n    for epoch in range(num_epochs):\n        net.train()\n        for i, (X, y) in enumerate(train_iter):\n            X, y = X.to(device), y.to(device)\n            optimizer.zero_grad()\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            optimizer.step()\n            scheduler.step()\n```\n\nApart from well defined `lr_scheduler` ,  `torch.optim.lr_scheduler.LambdaLR` allow us to apply self define scheduler such as:\n\n```python\nprint('training on', device)\nnet.to(device)\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\n\nt=10*len(train_iter)#warmup\nT=num_epochs*len(train_iter)\nlambda1 = lambda epoch: (0.9*epoch / t+0.1) if epoch < t else  0.1  if 0.5 * (1+math.cos(math.pi*(epoch - t)/(T-t)))<0.1 else 0.5 * (1+math.cos(math.pi*(epoch - t)/(T-t)))\n\nscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n\n# plot learningrate_decay\nlr_plot = []\nfor _i in range(num_epochs):\n    for _j in range(len(train_iter)):\n        optimizer.step()\n        lr_plot.append(optimizer.param_groups[0][\"lr\"])\n        scheduler.step()\nplt.plot(lr_plot)\n```\n### Should we do scheduling with adaptive learning rate method?\n\nFrom [Should we do learning rate decay for adam optimizer](https://stackoverflow.com/questions/39517431/should-we-do-learning-rate-decay-for-adam-optimizer)?, I found it as a arguable question.\n\n>It depends. ADAM updates any parameter with an individual learning rate. This means that every parameter in the network has a specific learning rate associated. \n>\n>But* the single learning rate for each parameter is computed using lambda (the initial learning rate) as an upper limit. This means that every single learning rate can vary from 0 (no update) to lambda (maximum update).\n>\n>It's true, that the learning rates adapt themselves during training steps, but if you want to be sure that every update step doesn't exceed lambda you can than lower lambda using exponential decay or whatever. It can help to reduce loss during the latest step of training, when the computed loss with the previously associated lambda parameter has stopped to decrease.\n\n>  In my experience it usually not necessary to do learning rate decay with Adam optimizer. \n>\n> The theory is that Adam already handles learning rate optimization ([check reference](http://arxiv.org/pdf/1412.6980v8.pdf)) :\n>\n> > \"We propose Adam, a method for efficient stochastic optimization that only requires first-order gradients with little memory requirement. The method **computes individual adaptive learning rates** for different parameters from estimates of first and second moments of the gradients; the name Adam is derived from adaptive moment estimation.\"\n>\n> As with any deep learning problem YMMV, one size does not fit all, you should try different approaches and see what works for you, etc. etc.\n\n>\n>  Yes, absolutely. From my own experience, it's very useful to Adam with learning rate decay. Without decay, you have to set a very small learning rate so the loss won't begin to diverge after decrease to a point.\n\nBut in the article [Decoupled weight decay regularization](https://arxiv.org/abs/1711.05101)(AdamW), it is encouraged.\n\n> Adam can substantially benefit from a scheduled learning rate multiplier. The fact that Adam is an adaptive gradient algorithm and as such adapts the learning rate for each parameter does not rule out the possibility to substantially improve its performance by using a global learning rate multiplier, scheduled, e.g., by cosine annealing.  \n\nIn the CLR article, the authors encourage the combination of CLR methods with Adam as well.\n\n> Adaptive learning rates are fundamentally different from CLR policies, and CLR can be combined with adaptive learning rates, as shown in Section 4.1. I \n\nAll in all, theoretically, the adaptive learning rate methods such as Adam adjust the learning rate for each parameters under a upper limit as the global learning rate, which can be adjusted by scheduling. \n\nIn practice, at least SGDR and CLR have been proved to be useful combining with optimizers.\n\n### Experiment: Adam vs Adam + SGDR \n\nIn this little experiment, the best setting in the last article is set as baseline, with Adam with constant learning rate. Leave other settings, Adam with cosine annealing learning rate, and AdamW with cosine annealing learning rate are compared.\n\n`global learning rate = 0.005` \n\n`scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = **int**(num_epochs***len**(train_iter)/10), T_mult=1, eta_min=1e-9)`\n\n<img src=\"experiment.png\" alt=\"experiment\" style=\"zoom:80%;\" />\n\nAs shown in the line charts, SGDR lift both the training and test accuracies. And the overfitting of the baseline method is alleviated as well. \n\nIn the second and  sub-figure, the fluctuation in the process of gradient descend caused by the cosine learning rate is obvious. And after each learning rate restart, the rate of the descend also gets a restart.  And it takes fewer epochs than to get the same accuracy than the baseline.\n\n### Reference\n\n[Kingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. *arXiv preprint arXiv:1412.6980*.](https://arxiv.org/pdf/1412.6980.pdf)\n\n[Adaptive Learning Rate Method](https://wiki.tum.de/display/lfdv/Adaptive+Learning+Rate+Method) \n\n[Learning Rate Schedules and Adaptive Learning Rate Methods](https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1) \n\n[Learning Rate Decay and methods in Deep Learning](https://medium.com/analytics-vidhya/learning-rate-decay-and-methods-in-deep-learning-2cee564f910b#:~:text=Learning%20rate%20decay%20is%20a,help%20both%20optimization%20and%20generalization.) \n\n[A Newbies Guide to Stochastic Gradient Descent With Restarts](https://towardsdatascience.com/https-medium-com-reina-wang-tw-stochastic-gradient-descent-with-restarts-5f511975163)\n\n[Zagoruyko, S., & Komodakis, N. (2016). Wide residual networks. *arXiv preprint arXiv:1605.07146*.](https://arxiv.org/abs/1605.07146)\n\n[Loshchilov, I., & Hutter, F. (2016). Sgdr: Stochastic gradient descent with warm restarts. *arXiv preprint arXiv:1608.03983*.](https://arxiv.org/abs/1608.03983) \n\n[Smith, L. N. (2017, March). Cyclical learning rates for training neural networks. In *2017 IEEE winter conference on applications of computer vision (WACV)* (pp. 464-472). IEEE.](https://ieeexplore.ieee.org/abstract/document/7926641/) \n\n[He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 770-778).](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) \n\n[Goyal, P., Dollr, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., ... & He, K. (2017). Accurate, large minibatch sgd: Training imagenet in 1 hour. *arXiv preprint arXiv:1706.02677*.](https://arxiv.org/abs/1706.0267)\n\n[Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. *Advances in neural information processing systems*, *25*.](https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)\n\n[torch.optim  PyTorch 1.10 documentation](https://pytorch.org/docs/stable/optim.html) \n\n[Should we do learning rate decay for adam optimizer](https://stackoverflow.com/questions/39517431/should-we-do-learning-rate-decay-for-adam-optimizer)\n\n[Loshchilov, I., & Hutter, F. (2017). Decoupled weight decay regularization. *arXiv preprint arXiv:1711.05101*.](https://arxiv.org/abs/1711.05101)\n\n[Guide to Pytorch Learning Rate Scheduling](https://www.kaggle.com/isbhargav/guide-to-pytorch-learning-rate-scheduling)","slug":"learning-rate-schedule","published":1,"updated":"2022-05-02T09:41:35.127Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz23000sl8yb7tap1lm8","content":"<blockquote>\n<p>Learning rate schedule is one commonly used trick to control the process of training. Different kinds of learning tricks are presented every day. In this article, I have put together classical methods theories and apply them in this little competition.</p>\n</blockquote>\n<blockquote>\n<p>Recently, I joined a <a href=\"https://www.kaggle.com/c/classify-leaves/\">Kaggle image classification competition</a>, I used the pretrained ResNet50 plus other tricks and here is to record some of them I've learned for now.</p>\n</blockquote>\n<span id=\"more\"></span>\n<h3 id=\"introduction\">Introduction</h3>\n<p>Learning rate is one critical parameter in alliterative algorithms, including PDE and ODE solving, optimization, and eigenvalue calculation. In the deep learning area, the learning rate is more than critical because of the notorious difficulty on <a href=\"https://en.wikipedia.org/wiki/Stochastic_gradient_descent\">Stochastic gradient descent</a>.</p>\n<p>Strictly, there are two ways of adjusting the learning rate:</p>\n<ul>\n<li><p>learning rate scheduling:</p>\n<p>adjust the global learning rate during iteration</p></li>\n<li><p>adaptive learning rate:</p>\n<p>adjust the learning rate for each parameter based on their gradients updates(moments), also called adaptive gradient or gradient descent optimization.</p></li>\n</ul>\n<p>In this article, <strong>learning rate schedule is mainly discussed</strong>. Afterward, \"learning rate\" refers to the \"global learning rate\".</p>\n<h3 id=\"methods-of-learning-rate-scheduling\">Methods of learning rate scheduling</h3>\n<p>Apart from the constant learning rate, there are several ways to schedule the learning rate:</p>\n<ul>\n<li>change with epoch numbers\n<ul>\n<li><p>learning rate decay: linear, step...</p></li>\n<li><p>learning rate down then up: stochastic gradient descent with warm restarts(SGDR) and Cyclical Learning rates(CLR)</p></li>\n<li><p>warmup</p></li>\n</ul></li>\n<li>change on some validation measurements: plateau</li>\n</ul>\n<h4 id=\"learning-rate-decay\">learning rate decay</h4>\n<p>Under the upper concepts of decaying the learning rate while training, how to choose a specific decay policy is personal. It can be continuous or step, linear or polynomial, exponential or trigonometric.</p>\n<p>In articles, stepped learning rate decay is more often used as the default choice. For example, <a href=\"https://arxiv.org/abs/1605.07146\">Zagoruyko, S., &amp; Komodakis, N</a> set the initial learning rate as 0.1 and drop it by 0.2 every 60 epochs on their modified version of ResNet. And this version of learning rate decay is set as the control group to compare with the SGDR strategy later in <a href=\"https://arxiv.org/abs/1608.03983\">Ilya Loshchilov &amp; Frank Hutter's work</a>. And in practice, the cosine annealing policy is a common choice today and can be used either alone or in combination with warmup and SGDR.</p>\n<h5 id=\"explanation\">Explanation</h5>\n<p>Because of the presence of stochastic noise, the entire gradient descent process is not straightforward. With a constant learning rate, as shown in the gradient contour map below, the minima can not be reached with a constant step (blue) due to the relatively small steps at the bottom. And a lower minimum can be reached if the learning rate descends with the gradient i.e. epoch(green).</p>\n<p><img src=\"SGD%20with%20learning%20rate%20decay.png\" srcset=\"/img/loading.gif\" lazyload alt=\"SGD with learning rate decay\" style=\"zoom:80%;\" /></p>\n<p>#### SGDR and CLR</p>\n<p>##### SGDR</p>\n<p>Stochastic gradient descent with warm restarts(SGDR) is firstly proposed to Deep learning in <a href=\"https://arxiv.org/abs/1608.03983\">Ilya Loshchilov &amp; Frank Hutter's work</a>. They introduced a policy of reinitializing the learning rate every certain number of epochs. Applying cosine annealing learning rate decay during each resulting \"mini-run\", the results perform fascinating.</p>\n<p><img src=\"SGDR.png\" srcset=\"/img/loading.gif\" lazyload alt=\"SGDR\" style=\"zoom:75%;\" /></p>\n<p><img src=\"SGDR_REsult.png\" srcset=\"/img/loading.gif\" lazyload alt=\"SGDR_REsult\" style=\"zoom:100%;\" /></p>\n<p>As shown in the charts, compared to 2 default step learnin rate decay policies, they enacted several SGDR policies with different T_0 and T_mul. T_0 refers to the epoch interval of the first \"mini-run\" and the epoch interval is multiplied by T_mul after each restart. As a result, at the ith \"mini-run\", T_i = T_0*T_mul^(i)</p>\n<p>And they suggests a SGDR policy with a small T0 = 1 or 10 at start, and set Tmult = 2 to double the epoch interval after every restart. And they claim by this policy, at least 2 to 4 fewer epochs are required to achieve a comparable result than before.</p>\n<p>##### CLR</p>\n<p>A similar method called cyclical Learning rates(CLR) is proposed later by <a href=\"https://ieeexplore.ieee.org/abstract/document/7926641/\">Leslie N. Smith</a>, where 2 kinds of triangular and exponential CLR policies are demonstrated on CIFAR-10 and CIFAR-100 with most kinds of mainstream CNN modules.</p>\n<p><img src=\"CLR.png\" srcset=\"/img/loading.gif\" lazyload alt=\"CLR\" style=\"zoom:75%;\" /></p>\n<p>Similarly, compared with a default fixed learnin rate, the demonstrats that their policies outperforms in accuracy and efficiency on several datasetes.</p>\n<blockquote>\n<p>one obtains the same test classification accuracy of 81.4% after only 25, 000 iterations with the triangular2 policy as obtained by running the standard hyper-parameter settings for 70, 000 iterations.</p>\n</blockquote>\n<p>##### explanation</p>\n<p>Because of the nonconvexity, it is common sense that reaching a global minima is impossible. With a standard learning rate decay, a saddle point, or unstable local minima is more likely to trap the descending process as shown below. But cyclical Learning rates(CLR) and stochastic gradient descent with warm restarts(SGDR) would allow the process to jump from one local minimum to another regularly until a stable one.</p>\n<p><img src=\"2d%20cyclic%20learning%20rate%20schedule.png\" srcset=\"/img/loading.gif\" lazyload alt=\"2d cyclic learning rate schedule\" style=\"zoom:80%;\" /></p>\n<p><img src=\"cyclic%20learning%20rate%20schedule.png\" srcset=\"/img/loading.gif\" lazyload alt=\"cyclic learning rate schedule\" style=\"zoom:80%;\" /></p>\n<p>Still there are several choices, but Cosine Cyclical and Cosine Annealing with Warm Restarts are more common.</p>\n<p>#### learning rate warmup</p>\n<p>Learning rate warmup is first applied in the famous <a href=\"https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\">Resnet</a> paper in one of its experiments.</p>\n<blockquote>\n<p>In this case, we find that the initial learning rate of 0.1 is slightly too large to start converging5 . So we use 0.01 to warm up the training until the training error is below 80% (about 400 iterations), and then go back to 0.1 and continue training.</p>\n</blockquote>\n<p>And later <a href=\"https://arxiv.org/pdf/1706.02677.pdf\">Goyal and He's work</a> makes a major influence, where constant and gradual methods of warmup are discussed. And gradual warmup is proved to be effective on large minibatch size.</p>\n<blockquote>\n<p>As we discussed, for large minibatches (e.g., 8k) the linear scaling rule breaks down when the network is changing rapidly, which commonly occurs in early stages of training. We find that this issue can be alleviated by a properly designed warmup [16], namely, a strategy of using less aggressive learning rates at the start of training.</p>\n</blockquote>\n<p><img src=\"warmup%20on%20large%20batches.png\" srcset=\"/img/loading.gif\" lazyload alt=\"warmup on large batches\" style=\"zoom:100%;\" /></p>\n<p>In practice, warmup are always combined with other learning rate methods afterwards. And linear warmup is a default method.</p>\n<p>#### Reducing the learning rate on plateau</p>\n<p>Apart from methods scheduling the learning rate with epoch, a dynamic learning rate decay method is also an option. It denotes the process of decaying the learning rate only when the optimizer fails to improve the accuracy or decrease the loss in serval epochs.</p>\n<p>For example, in <a href=\"https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\">AlexNet</a>,</p>\n<blockquote>\n<p>The heuristic which we followed was to divide the learning rate by 10 when the validation error rate stopped improving with the current learning rate. The learning rate was initialized at 0.01 and reduced three times prior to termination.</p>\n</blockquote>\n<p>In <a href=\"https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\">Resnet</a> after the warm-up,</p>\n<blockquote>\n<p>The learning rate starts from 0.1 and is divided by 10 when the error plateaus</p>\n</blockquote>\n<h3 id=\"apply-learning-rate-scheduling-in-pytorch\">Apply learning rate scheduling in PyTorch</h3>\n<blockquote>\n<p><code>torch.optim.lr_scheduler</code> provides several methods to adjust the learning rate based on the number of epochs.</p>\n</blockquote>\n<p>For example,</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">train_ch6</span>(<span class=\"hljs-params\">net, train_iter, test_iter, num_epochs, lr, device</span>):\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;training on&#x27;</span>, device)\n    net.to(device)\n    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs*<span class=\"hljs-built_in\">len</span>(train_iter)/<span class=\"hljs-number\">10</span>, eta_min=<span class=\"hljs-number\">1e-9</span>)\n    loss = LSR(<span class=\"hljs-number\">0.1</span>) \n    <span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(num_epochs):\n        net.train()\n        <span class=\"hljs-keyword\">for</span> i, (X, y) <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_iter):\n            X, y = X.to(device), y.to(device)\n            optimizer.zero_grad()\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            optimizer.step()\n            scheduler.step()</code></pre></div>\n<p>Apart from well defined <code>lr_scheduler</code> , <code>torch.optim.lr_scheduler.LambdaLR</code> allow us to apply self define scheduler such as:</p>\n<div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;training on&#x27;</span>, device)\nnet.to(device)\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\n\nt=<span class=\"hljs-number\">10</span>*<span class=\"hljs-built_in\">len</span>(train_iter)<span class=\"hljs-comment\">#warmup</span>\nT=num_epochs*<span class=\"hljs-built_in\">len</span>(train_iter)\nlambda1 = <span class=\"hljs-keyword\">lambda</span> epoch: (<span class=\"hljs-number\">0.9</span>*epoch / t+<span class=\"hljs-number\">0.1</span>) <span class=\"hljs-keyword\">if</span> epoch &lt; t <span class=\"hljs-keyword\">else</span>  <span class=\"hljs-number\">0.1</span>  <span class=\"hljs-keyword\">if</span> <span class=\"hljs-number\">0.5</span> * (<span class=\"hljs-number\">1</span>+math.cos(math.pi*(epoch - t)/(T-t)))&lt;<span class=\"hljs-number\">0.1</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-number\">0.5</span> * (<span class=\"hljs-number\">1</span>+math.cos(math.pi*(epoch - t)/(T-t)))\n\nscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n\n<span class=\"hljs-comment\"># plot learningrate_decay</span>\nlr_plot = []\n<span class=\"hljs-keyword\">for</span> _i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(num_epochs):\n    <span class=\"hljs-keyword\">for</span> _j <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(train_iter)):\n        optimizer.step()\n        lr_plot.append(optimizer.param_groups[<span class=\"hljs-number\">0</span>][<span class=\"hljs-string\">&quot;lr&quot;</span>])\n        scheduler.step()\nplt.plot(lr_plot)</code></pre></div>\n<h3 id=\"should-we-do-scheduling-with-adaptive-learning-rate-method\">Should we do scheduling with adaptive learning rate method?</h3>\n<p>From <a href=\"https://stackoverflow.com/questions/39517431/should-we-do-learning-rate-decay-for-adam-optimizer\">Should we do learning rate decay for adam optimizer</a>?, I found it as a arguable question.</p>\n<blockquote>\n<p>It depends. ADAM updates any parameter with an individual learning rate. This means that every parameter in the network has a specific learning rate associated.</p>\n<p>But* the single learning rate for each parameter is computed using lambda (the initial learning rate) as an upper limit. This means that every single learning rate can vary from 0 (no update) to lambda (maximum update).</p>\n<p>It's true, that the learning rates adapt themselves during training steps, but if you want to be sure that every update step doesn't exceed lambda you can than lower lambda using exponential decay or whatever. It can help to reduce loss during the latest step of training, when the computed loss with the previously associated lambda parameter has stopped to decrease.</p>\n</blockquote>\n<blockquote>\n<p>In my experience it usually not necessary to do learning rate decay with Adam optimizer.</p>\n<p>The theory is that Adam already handles learning rate optimization (<a href=\"http://arxiv.org/pdf/1412.6980v8.pdf\">check reference</a>) :</p>\n<blockquote>\n<p>\"We propose Adam, a method for efficient stochastic optimization that only requires first-order gradients with little memory requirement. The method <strong>computes individual adaptive learning rates</strong> for different parameters from estimates of first and second moments of the gradients; the name Adam is derived from adaptive moment estimation.\"</p>\n</blockquote>\n<p>As with any deep learning problem YMMV, one size does not fit all, you should try different approaches and see what works for you, etc. etc.</p>\n</blockquote>\n<blockquote>\n<p>Yes, absolutely. From my own experience, it's very useful to Adam with learning rate decay. Without decay, you have to set a very small learning rate so the loss won't begin to diverge after decrease to a point.</p>\n</blockquote>\n<p>But in the article <a href=\"https://arxiv.org/abs/1711.05101\">Decoupled weight decay regularization</a>(AdamW), it is encouraged.</p>\n<blockquote>\n<p>Adam can substantially benefit from a scheduled learning rate multiplier. The fact that Adam is an adaptive gradient algorithm and as such adapts the learning rate for each parameter does not rule out the possibility to substantially improve its performance by using a global learning rate multiplier, scheduled, e.g., by cosine annealing.</p>\n</blockquote>\n<p>In the CLR article, the authors encourage the combination of CLR methods with Adam as well.</p>\n<blockquote>\n<p>Adaptive learning rates are fundamentally different from CLR policies, and CLR can be combined with adaptive learning rates, as shown in Section 4.1. I</p>\n</blockquote>\n<p>All in all, theoretically, the adaptive learning rate methods such as Adam adjust the learning rate for each parameters under a upper limit as the global learning rate, which can be adjusted by scheduling.</p>\n<p>In practice, at least SGDR and CLR have been proved to be useful combining with optimizers.</p>\n<h3 id=\"experiment-adam-vs-adam-sgdr\">Experiment: Adam vs Adam + SGDR</h3>\n<p>In this little experiment, the best setting in the last article is set as baseline, with Adam with constant learning rate. Leave other settings, Adam with cosine annealing learning rate, and AdamW with cosine annealing learning rate are compared.</p>\n<p><code>global learning rate = 0.005</code></p>\n<p><code>scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = **int**(num_epochs***len**(train_iter)/10), T_mult=1, eta_min=1e-9)</code></p>\n<p><img src=\"experiment.png\" srcset=\"/img/loading.gif\" lazyload alt=\"experiment\" style=\"zoom:80%;\" /></p>\n<p>As shown in the line charts, SGDR lift both the training and test accuracies. And the overfitting of the baseline method is alleviated as well.</p>\n<p>In the second and sub-figure, the fluctuation in the process of gradient descend caused by the cosine learning rate is obvious. And after each learning rate restart, the rate of the descend also gets a restart. And it takes fewer epochs than to get the same accuracy than the baseline.</p>\n<h3 id=\"reference\">Reference</h3>\n<p><a href=\"https://arxiv.org/pdf/1412.6980.pdf\">Kingma, D. P., &amp; Ba, J. (2014). Adam: A method for stochastic optimization. <em>arXiv preprint arXiv:1412.6980</em>.</a></p>\n<p><a href=\"https://wiki.tum.de/display/lfdv/Adaptive+Learning+Rate+Method\">Adaptive Learning Rate Method</a></p>\n<p><a href=\"https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\">Learning Rate Schedules and Adaptive Learning Rate Methods</a></p>\n<p><a href=\"https://medium.com/analytics-vidhya/learning-rate-decay-and-methods-in-deep-learning-2cee564f910b#:~:text=Learning%20rate%20decay%20is%20a,help%20both%20optimization%20and%20generalization.\">Learning Rate Decay and methods in Deep Learning</a></p>\n<p><a href=\"https://towardsdatascience.com/https-medium-com-reina-wang-tw-stochastic-gradient-descent-with-restarts-5f511975163\">A Newbies Guide to Stochastic Gradient Descent With Restarts</a></p>\n<p><a href=\"https://arxiv.org/abs/1605.07146\">Zagoruyko, S., &amp; Komodakis, N. (2016). Wide residual networks. <em>arXiv preprint arXiv:1605.07146</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/1608.03983\">Loshchilov, I., &amp; Hutter, F. (2016). Sgdr: Stochastic gradient descent with warm restarts. <em>arXiv preprint arXiv:1608.03983</em>.</a></p>\n<p><a href=\"https://ieeexplore.ieee.org/abstract/document/7926641/\">Smith, L. N. (2017, March). Cyclical learning rates for training neural networks. In <em>2017 IEEE winter conference on applications of computer vision (WACV)</em> (pp. 464-472). IEEE.</a></p>\n<p><a href=\"https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\">He, K., Zhang, X., Ren, S., &amp; Sun, J. (2016). Deep residual learning for image recognition. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp. 770-778).</a></p>\n<p><a href=\"https://arxiv.org/abs/1706.0267\">Goyal, P., Dollr, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., ... &amp; He, K. (2017). Accurate, large minibatch sgd: Training imagenet in 1 hour. <em>arXiv preprint arXiv:1706.02677</em>.</a></p>\n<p><a href=\"https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\">Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. <em>Advances in neural information processing systems</em>, <em>25</em>.</a></p>\n<p><a href=\"https://pytorch.org/docs/stable/optim.html\">torch.optim  PyTorch 1.10 documentation</a></p>\n<p><a href=\"https://stackoverflow.com/questions/39517431/should-we-do-learning-rate-decay-for-adam-optimizer\">Should we do learning rate decay for adam optimizer</a></p>\n<p><a href=\"https://arxiv.org/abs/1711.05101\">Loshchilov, I., &amp; Hutter, F. (2017). Decoupled weight decay regularization. <em>arXiv preprint arXiv:1711.05101</em>.</a></p>\n<p><a href=\"https://www.kaggle.com/isbhargav/guide-to-pytorch-learning-rate-scheduling\">Guide to Pytorch Learning Rate Scheduling</a></p>\n","site":{"data":{}},"wordcount":11090,"excerpt":"<blockquote>\n<p>Learning rate schedule is one commonly used trick to control the process of training. Different kinds of learning tricks are presented every day. In this article, I have put together classical methods theories and apply them in this little competition.</p>\n</blockquote>\n<blockquote>\n<p>Recently, I joined a <a href=\"https://www.kaggle.com/c/classify-leaves/\">Kaggle image classification competition</a>, I used the pretrained ResNet50 plus other tricks and here is to record some of them I've learned for now.</p>\n</blockquote>","more":"<h3 id=\"introduction\">Introduction</h3>\n<p>Learning rate is one critical parameter in alliterative algorithms, including PDE and ODE solving, optimization, and eigenvalue calculation. In the deep learning area, the learning rate is more than critical because of the notorious difficulty on <a href=\"https://en.wikipedia.org/wiki/Stochastic_gradient_descent\">Stochastic gradient descent</a>.</p>\n<p>Strictly, there are two ways of adjusting the learning rate:</p>\n<ul>\n<li><p>learning rate scheduling:</p>\n<p>adjust the global learning rate during iteration</p></li>\n<li><p>adaptive learning rate:</p>\n<p>adjust the learning rate for each parameter based on their gradients updates(moments), also called adaptive gradient or gradient descent optimization.</p></li>\n</ul>\n<p>In this article, <strong>learning rate schedule is mainly discussed</strong>. Afterward, \"learning rate\" refers to the \"global learning rate\".</p>\n<h3 id=\"methods-of-learning-rate-scheduling\">Methods of learning rate scheduling</h3>\n<p>Apart from the constant learning rate, there are several ways to schedule the learning rate:</p>\n<ul>\n<li>change with epoch numbers\n<ul>\n<li><p>learning rate decay: linear, step...</p></li>\n<li><p>learning rate down then up: stochastic gradient descent with warm restarts(SGDR) and Cyclical Learning rates(CLR)</p></li>\n<li><p>warmup</p></li>\n</ul></li>\n<li>change on some validation measurements: plateau</li>\n</ul>\n<h4 id=\"learning-rate-decay\">learning rate decay</h4>\n<p>Under the upper concepts of decaying the learning rate while training, how to choose a specific decay policy is personal. It can be continuous or step, linear or polynomial, exponential or trigonometric.</p>\n<p>In articles, stepped learning rate decay is more often used as the default choice. For example, <a href=\"https://arxiv.org/abs/1605.07146\">Zagoruyko, S., &amp; Komodakis, N</a> set the initial learning rate as 0.1 and drop it by 0.2 every 60 epochs on their modified version of ResNet. And this version of learning rate decay is set as the control group to compare with the SGDR strategy later in <a href=\"https://arxiv.org/abs/1608.03983\">Ilya Loshchilov &amp; Frank Hutter's work</a>. And in practice, the cosine annealing policy is a common choice today and can be used either alone or in combination with warmup and SGDR.</p>\n<h5 id=\"explanation\">Explanation</h5>\n<p>Because of the presence of stochastic noise, the entire gradient descent process is not straightforward. With a constant learning rate, as shown in the gradient contour map below, the minima can not be reached with a constant step (blue) due to the relatively small steps at the bottom. And a lower minimum can be reached if the learning rate descends with the gradient i.e. epoch(green).</p>\n<p><img src=\"SGD%20with%20learning%20rate%20decay.png\" alt=\"SGD with learning rate decay\" style=\"zoom:80%;\" /></p>\n<p>#### SGDR and CLR</p>\n<p>##### SGDR</p>\n<p>Stochastic gradient descent with warm restarts(SGDR) is firstly proposed to Deep learning in <a href=\"https://arxiv.org/abs/1608.03983\">Ilya Loshchilov &amp; Frank Hutter's work</a>. They introduced a policy of reinitializing the learning rate every certain number of epochs. Applying cosine annealing learning rate decay during each resulting \"mini-run\", the results perform fascinating.</p>\n<p><img src=\"SGDR.png\" alt=\"SGDR\" style=\"zoom:75%;\" /></p>\n<p><img src=\"SGDR_REsult.png\" alt=\"SGDR_REsult\" style=\"zoom:100%;\" /></p>\n<p>As shown in the charts, compared to 2 default step learnin rate decay policies, they enacted several SGDR policies with different T_0 and T_mul. T_0 refers to the epoch interval of the first \"mini-run\" and the epoch interval is multiplied by T_mul after each restart. As a result, at the ith \"mini-run\", T_i = T_0*T_mul^(i)</p>\n<p>And they suggests a SGDR policy with a small T0 = 1 or 10 at start, and set Tmult = 2 to double the epoch interval after every restart. And they claim by this policy, at least 2 to 4 fewer epochs are required to achieve a comparable result than before.</p>\n<p>##### CLR</p>\n<p>A similar method called cyclical Learning rates(CLR) is proposed later by <a href=\"https://ieeexplore.ieee.org/abstract/document/7926641/\">Leslie N. Smith</a>, where 2 kinds of triangular and exponential CLR policies are demonstrated on CIFAR-10 and CIFAR-100 with most kinds of mainstream CNN modules.</p>\n<p><img src=\"CLR.png\" alt=\"CLR\" style=\"zoom:75%;\" /></p>\n<p>Similarly, compared with a default fixed learnin rate, the demonstrats that their policies outperforms in accuracy and efficiency on several datasetes.</p>\n<blockquote>\n<p>one obtains the same test classification accuracy of 81.4% after only 25, 000 iterations with the triangular2 policy as obtained by running the standard hyper-parameter settings for 70, 000 iterations.</p>\n</blockquote>\n<p>##### explanation</p>\n<p>Because of the nonconvexity, it is common sense that reaching a global minima is impossible. With a standard learning rate decay, a saddle point, or unstable local minima is more likely to trap the descending process as shown below. But cyclical Learning rates(CLR) and stochastic gradient descent with warm restarts(SGDR) would allow the process to jump from one local minimum to another regularly until a stable one.</p>\n<p><img src=\"2d%20cyclic%20learning%20rate%20schedule.png\" alt=\"2d cyclic learning rate schedule\" style=\"zoom:80%;\" /></p>\n<p><img src=\"cyclic%20learning%20rate%20schedule.png\" alt=\"cyclic learning rate schedule\" style=\"zoom:80%;\" /></p>\n<p>Still there are several choices, but Cosine Cyclical and Cosine Annealing with Warm Restarts are more common.</p>\n<p>#### learning rate warmup</p>\n<p>Learning rate warmup is first applied in the famous <a href=\"https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\">Resnet</a> paper in one of its experiments.</p>\n<blockquote>\n<p>In this case, we find that the initial learning rate of 0.1 is slightly too large to start converging5 . So we use 0.01 to warm up the training until the training error is below 80% (about 400 iterations), and then go back to 0.1 and continue training.</p>\n</blockquote>\n<p>And later <a href=\"https://arxiv.org/pdf/1706.02677.pdf\">Goyal and He's work</a> makes a major influence, where constant and gradual methods of warmup are discussed. And gradual warmup is proved to be effective on large minibatch size.</p>\n<blockquote>\n<p>As we discussed, for large minibatches (e.g., 8k) the linear scaling rule breaks down when the network is changing rapidly, which commonly occurs in early stages of training. We find that this issue can be alleviated by a properly designed warmup [16], namely, a strategy of using less aggressive learning rates at the start of training.</p>\n</blockquote>\n<p><img src=\"warmup%20on%20large%20batches.png\" alt=\"warmup on large batches\" style=\"zoom:100%;\" /></p>\n<p>In practice, warmup are always combined with other learning rate methods afterwards. And linear warmup is a default method.</p>\n<p>#### Reducing the learning rate on plateau</p>\n<p>Apart from methods scheduling the learning rate with epoch, a dynamic learning rate decay method is also an option. It denotes the process of decaying the learning rate only when the optimizer fails to improve the accuracy or decrease the loss in serval epochs.</p>\n<p>For example, in <a href=\"https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\">AlexNet</a>,</p>\n<blockquote>\n<p>The heuristic which we followed was to divide the learning rate by 10 when the validation error rate stopped improving with the current learning rate. The learning rate was initialized at 0.01 and reduced three times prior to termination.</p>\n</blockquote>\n<p>In <a href=\"https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\">Resnet</a> after the warm-up,</p>\n<blockquote>\n<p>The learning rate starts from 0.1 and is divided by 10 when the error plateaus</p>\n</blockquote>\n<h3 id=\"apply-learning-rate-scheduling-in-pytorch\">Apply learning rate scheduling in PyTorch</h3>\n<blockquote>\n<p><code>torch.optim.lr_scheduler</code> provides several methods to adjust the learning rate based on the number of epochs.</p>\n</blockquote>\n<p>For example,</p>\n<pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">train_ch6</span>(<span class=\"hljs-params\">net, train_iter, test_iter, num_epochs, lr, device</span>):\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;training on&#x27;</span>, device)\n    net.to(device)\n    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs*<span class=\"hljs-built_in\">len</span>(train_iter)/<span class=\"hljs-number\">10</span>, eta_min=<span class=\"hljs-number\">1e-9</span>)\n    loss = LSR(<span class=\"hljs-number\">0.1</span>) \n    <span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(num_epochs):\n        net.train()\n        <span class=\"hljs-keyword\">for</span> i, (X, y) <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_iter):\n            X, y = X.to(device), y.to(device)\n            optimizer.zero_grad()\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            optimizer.step()\n            scheduler.step()</code></pre>\n<p>Apart from well defined <code>lr_scheduler</code> , <code>torch.optim.lr_scheduler.LambdaLR</code> allow us to apply self define scheduler such as:</p>\n<pre><code class=\"hljs python\"><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;training on&#x27;</span>, device)\nnet.to(device)\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\n\nt=<span class=\"hljs-number\">10</span>*<span class=\"hljs-built_in\">len</span>(train_iter)<span class=\"hljs-comment\">#warmup</span>\nT=num_epochs*<span class=\"hljs-built_in\">len</span>(train_iter)\nlambda1 = <span class=\"hljs-keyword\">lambda</span> epoch: (<span class=\"hljs-number\">0.9</span>*epoch / t+<span class=\"hljs-number\">0.1</span>) <span class=\"hljs-keyword\">if</span> epoch &lt; t <span class=\"hljs-keyword\">else</span>  <span class=\"hljs-number\">0.1</span>  <span class=\"hljs-keyword\">if</span> <span class=\"hljs-number\">0.5</span> * (<span class=\"hljs-number\">1</span>+math.cos(math.pi*(epoch - t)/(T-t)))&lt;<span class=\"hljs-number\">0.1</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-number\">0.5</span> * (<span class=\"hljs-number\">1</span>+math.cos(math.pi*(epoch - t)/(T-t)))\n\nscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n\n<span class=\"hljs-comment\"># plot learningrate_decay</span>\nlr_plot = []\n<span class=\"hljs-keyword\">for</span> _i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(num_epochs):\n    <span class=\"hljs-keyword\">for</span> _j <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(train_iter)):\n        optimizer.step()\n        lr_plot.append(optimizer.param_groups[<span class=\"hljs-number\">0</span>][<span class=\"hljs-string\">&quot;lr&quot;</span>])\n        scheduler.step()\nplt.plot(lr_plot)</code></pre>\n<h3 id=\"should-we-do-scheduling-with-adaptive-learning-rate-method\">Should we do scheduling with adaptive learning rate method?</h3>\n<p>From <a href=\"https://stackoverflow.com/questions/39517431/should-we-do-learning-rate-decay-for-adam-optimizer\">Should we do learning rate decay for adam optimizer</a>?, I found it as a arguable question.</p>\n<blockquote>\n<p>It depends. ADAM updates any parameter with an individual learning rate. This means that every parameter in the network has a specific learning rate associated.</p>\n<p>But* the single learning rate for each parameter is computed using lambda (the initial learning rate) as an upper limit. This means that every single learning rate can vary from 0 (no update) to lambda (maximum update).</p>\n<p>It's true, that the learning rates adapt themselves during training steps, but if you want to be sure that every update step doesn't exceed lambda you can than lower lambda using exponential decay or whatever. It can help to reduce loss during the latest step of training, when the computed loss with the previously associated lambda parameter has stopped to decrease.</p>\n</blockquote>\n<blockquote>\n<p>In my experience it usually not necessary to do learning rate decay with Adam optimizer.</p>\n<p>The theory is that Adam already handles learning rate optimization (<a href=\"http://arxiv.org/pdf/1412.6980v8.pdf\">check reference</a>) :</p>\n<blockquote>\n<p>\"We propose Adam, a method for efficient stochastic optimization that only requires first-order gradients with little memory requirement. The method <strong>computes individual adaptive learning rates</strong> for different parameters from estimates of first and second moments of the gradients; the name Adam is derived from adaptive moment estimation.\"</p>\n</blockquote>\n<p>As with any deep learning problem YMMV, one size does not fit all, you should try different approaches and see what works for you, etc. etc.</p>\n</blockquote>\n<blockquote>\n<p>Yes, absolutely. From my own experience, it's very useful to Adam with learning rate decay. Without decay, you have to set a very small learning rate so the loss won't begin to diverge after decrease to a point.</p>\n</blockquote>\n<p>But in the article <a href=\"https://arxiv.org/abs/1711.05101\">Decoupled weight decay regularization</a>(AdamW), it is encouraged.</p>\n<blockquote>\n<p>Adam can substantially benefit from a scheduled learning rate multiplier. The fact that Adam is an adaptive gradient algorithm and as such adapts the learning rate for each parameter does not rule out the possibility to substantially improve its performance by using a global learning rate multiplier, scheduled, e.g., by cosine annealing.</p>\n</blockquote>\n<p>In the CLR article, the authors encourage the combination of CLR methods with Adam as well.</p>\n<blockquote>\n<p>Adaptive learning rates are fundamentally different from CLR policies, and CLR can be combined with adaptive learning rates, as shown in Section 4.1. I</p>\n</blockquote>\n<p>All in all, theoretically, the adaptive learning rate methods such as Adam adjust the learning rate for each parameters under a upper limit as the global learning rate, which can be adjusted by scheduling.</p>\n<p>In practice, at least SGDR and CLR have been proved to be useful combining with optimizers.</p>\n<h3 id=\"experiment-adam-vs-adam-sgdr\">Experiment: Adam vs Adam + SGDR</h3>\n<p>In this little experiment, the best setting in the last article is set as baseline, with Adam with constant learning rate. Leave other settings, Adam with cosine annealing learning rate, and AdamW with cosine annealing learning rate are compared.</p>\n<p><code>global learning rate = 0.005</code></p>\n<p><code>scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = **int**(num_epochs***len**(train_iter)/10), T_mult=1, eta_min=1e-9)</code></p>\n<p><img src=\"experiment.png\" alt=\"experiment\" style=\"zoom:80%;\" /></p>\n<p>As shown in the line charts, SGDR lift both the training and test accuracies. And the overfitting of the baseline method is alleviated as well.</p>\n<p>In the second and sub-figure, the fluctuation in the process of gradient descend caused by the cosine learning rate is obvious. And after each learning rate restart, the rate of the descend also gets a restart. And it takes fewer epochs than to get the same accuracy than the baseline.</p>\n<h3 id=\"reference\">Reference</h3>\n<p><a href=\"https://arxiv.org/pdf/1412.6980.pdf\">Kingma, D. P., &amp; Ba, J. (2014). Adam: A method for stochastic optimization. <em>arXiv preprint arXiv:1412.6980</em>.</a></p>\n<p><a href=\"https://wiki.tum.de/display/lfdv/Adaptive+Learning+Rate+Method\">Adaptive Learning Rate Method</a></p>\n<p><a href=\"https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\">Learning Rate Schedules and Adaptive Learning Rate Methods</a></p>\n<p><a href=\"https://medium.com/analytics-vidhya/learning-rate-decay-and-methods-in-deep-learning-2cee564f910b#:~:text=Learning%20rate%20decay%20is%20a,help%20both%20optimization%20and%20generalization.\">Learning Rate Decay and methods in Deep Learning</a></p>\n<p><a href=\"https://towardsdatascience.com/https-medium-com-reina-wang-tw-stochastic-gradient-descent-with-restarts-5f511975163\">A Newbies Guide to Stochastic Gradient Descent With Restarts</a></p>\n<p><a href=\"https://arxiv.org/abs/1605.07146\">Zagoruyko, S., &amp; Komodakis, N. (2016). Wide residual networks. <em>arXiv preprint arXiv:1605.07146</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/1608.03983\">Loshchilov, I., &amp; Hutter, F. (2016). Sgdr: Stochastic gradient descent with warm restarts. <em>arXiv preprint arXiv:1608.03983</em>.</a></p>\n<p><a href=\"https://ieeexplore.ieee.org/abstract/document/7926641/\">Smith, L. N. (2017, March). Cyclical learning rates for training neural networks. In <em>2017 IEEE winter conference on applications of computer vision (WACV)</em> (pp. 464-472). IEEE.</a></p>\n<p><a href=\"https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\">He, K., Zhang, X., Ren, S., &amp; Sun, J. (2016). Deep residual learning for image recognition. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp. 770-778).</a></p>\n<p><a href=\"https://arxiv.org/abs/1706.0267\">Goyal, P., Dollr, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., ... &amp; He, K. (2017). Accurate, large minibatch sgd: Training imagenet in 1 hour. <em>arXiv preprint arXiv:1706.02677</em>.</a></p>\n<p><a href=\"https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\">Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. <em>Advances in neural information processing systems</em>, <em>25</em>.</a></p>\n<p><a href=\"https://pytorch.org/docs/stable/optim.html\">torch.optim  PyTorch 1.10 documentation</a></p>\n<p><a href=\"https://stackoverflow.com/questions/39517431/should-we-do-learning-rate-decay-for-adam-optimizer\">Should we do learning rate decay for adam optimizer</a></p>\n<p><a href=\"https://arxiv.org/abs/1711.05101\">Loshchilov, I., &amp; Hutter, F. (2017). Decoupled weight decay regularization. <em>arXiv preprint arXiv:1711.05101</em>.</a></p>\n<p><a href=\"https://www.kaggle.com/isbhargav/guide-to-pytorch-learning-rate-scheduling\">Guide to Pytorch Learning Rate Scheduling</a></p>"},{"title":"Introduction to GNN","author":"Ryan LI","declare":true,"date":"2022-04-14T05:58:38.000Z","index_img":"/index/paper-reading-GNN.png","_content":"> This is a tech blog written by google research team in 2021 that introducing the graph neural network. GNN has gradually become popular in the last 4 years. Personally, I think the graph structure looks similar to the CFD mesh, and there are works  focusing on simulating physics via GNN.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\nPaper link: [A gentle introduction to graph neural networks](https://staging.distill.pub/2021/gnn-intro/?ref=https://githubhelp.com)\n\nUseful link: https://www.bilibili.com/video/BV1iT4y1d7zP\n\n## Notes\n\n*Because this blog has introduced GNN in detail and explained well with the interactive diagrams, it almost leaves me no need for extra notes. As a result, a throughout reading of the [original blog](https://staging.distill.pub/2021/gnn-intro/?ref=https://githubhelp.com) is recommended. And as a result this notes are only in pieces.*\n\n<img src=\" GNN interative archtecture.png\" alt=\"GNN interative archtecture\" style=\"zoom:50%;\" />\n\n>### Graph-level task\n>\n>In a graph-level task, our goal is to predict the property of an entire graph. For example, for a molecule represented as a graph, we might want to predict what the molecule smells like, or whether it will bind to a receptor implicated in a disease.\n>\n><img src=\" GNN graph level task.png\" alt=\"GNN graph level task\" style=\"zoom:50%;\" />\n\nThe example is actually a simple task example, and the loops can be detected with ordinary algorithm such as: [Fast and Slow Pointer: Floyd's Cycle Detection Algorithm](https://codeburst.io/fast-and-slow-pointer-floyds-cycle-detection-algorithm-9c7a8693f491). But with more complicated task, GNN can be useful. And here is the related Leetcode question: [No.141: Linked List Cycle](https://leetcode.com/problems/linked-list-cycle/description/).\n\n\n\n> <img src=\" GNN graph message passing.png\" alt=\"GNN graph message passing\" style=\"zoom:50%;\" />\n>\n> This is **reminiscent of standard convolution**: in essence, message passing and convolution are operations to aggregate and process the information of an elements neighbors in order to update the elements value. In graphs, the element is a node, and in images, the element is a pixel. **However**, the number of neighboring nodes in a graph can be variable, unlike in an image where each pixel has a set number of neighboring elements.\n\nWhen introducing the message passing method, this blog makes an analogy with the convolution. And in addition to the however part mentioned in this blog, another difference is that in convolution, each element's value is weighted differently while in the aggregation method they are all the same. \n\nInterestingly, similar weights can be achieved with Graph Attention Networks, which is introduced in later section.\n\n> Another way of communicating information between graph attributes is via attention. For example, when we consider the sum-aggregation of a node and its 1-degree neighboring nodes we could also consider using a weighted sum.\n>\n> A common scoring function is the inner product and nodes are often transformed before scoring into query and key vectors via a linear map to increase the expressivity of the scoring mechanism.\n\n## Reviews\n\nWriting: the whole article is well coherent and fluent, building the knowledge of GNN step by step, from a highly simplified model to the real GNN. The beautiful interactive figures make the article easy to read and digestible. Yet lacking mathematics and codes is both pros and cons. Unfortunately, *tarting today Distill will be taking a one year hiatus, which may be extended indefinitely.* \n\nGraph neural network: a graph is a powerful tool so that all kinds of data can be described as a graph. But this power leads to a huge difficulty in optimisation. One reason is the sparsity, the dynamic structure makes it difficult the train on CPU or GPU. Another is that GNN is very sensitive to hyper-parameters, just like the experiment section of this blog shows. As such, it is an active research area yet rarely deployed in industry.\n","source":"_posts/paper-reading-A-gentle-introduction-to-graph-neural-networks.md","raw":"---\ntitle: 'Introduction to GNN'\nauthor: Ryan LI\ndeclare: true\ndate: 2022-04-14 13:58:38\nindex_img: /index/paper-reading-GNN.png\ntags:\n  - paper reading\n  - deep learning\n---\n> This is a tech blog written by google research team in 2021 that introducing the graph neural network. GNN has gradually become popular in the last 4 years. Personally, I think the graph structure looks similar to the CFD mesh, and there are works  focusing on simulating physics via GNN.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\nPaper link: [A gentle introduction to graph neural networks](https://staging.distill.pub/2021/gnn-intro/?ref=https://githubhelp.com)\n\nUseful link: https://www.bilibili.com/video/BV1iT4y1d7zP\n\n## Notes\n\n*Because this blog has introduced GNN in detail and explained well with the interactive diagrams, it almost leaves me no need for extra notes. As a result, a throughout reading of the [original blog](https://staging.distill.pub/2021/gnn-intro/?ref=https://githubhelp.com) is recommended. And as a result this notes are only in pieces.*\n\n<img src=\" GNN interative archtecture.png\" alt=\"GNN interative archtecture\" style=\"zoom:50%;\" />\n\n>### Graph-level task\n>\n>In a graph-level task, our goal is to predict the property of an entire graph. For example, for a molecule represented as a graph, we might want to predict what the molecule smells like, or whether it will bind to a receptor implicated in a disease.\n>\n><img src=\" GNN graph level task.png\" alt=\"GNN graph level task\" style=\"zoom:50%;\" />\n\nThe example is actually a simple task example, and the loops can be detected with ordinary algorithm such as: [Fast and Slow Pointer: Floyd's Cycle Detection Algorithm](https://codeburst.io/fast-and-slow-pointer-floyds-cycle-detection-algorithm-9c7a8693f491). But with more complicated task, GNN can be useful. And here is the related Leetcode question: [No.141: Linked List Cycle](https://leetcode.com/problems/linked-list-cycle/description/).\n\n\n\n> <img src=\" GNN graph message passing.png\" alt=\"GNN graph message passing\" style=\"zoom:50%;\" />\n>\n> This is **reminiscent of standard convolution**: in essence, message passing and convolution are operations to aggregate and process the information of an elements neighbors in order to update the elements value. In graphs, the element is a node, and in images, the element is a pixel. **However**, the number of neighboring nodes in a graph can be variable, unlike in an image where each pixel has a set number of neighboring elements.\n\nWhen introducing the message passing method, this blog makes an analogy with the convolution. And in addition to the however part mentioned in this blog, another difference is that in convolution, each element's value is weighted differently while in the aggregation method they are all the same. \n\nInterestingly, similar weights can be achieved with Graph Attention Networks, which is introduced in later section.\n\n> Another way of communicating information between graph attributes is via attention. For example, when we consider the sum-aggregation of a node and its 1-degree neighboring nodes we could also consider using a weighted sum.\n>\n> A common scoring function is the inner product and nodes are often transformed before scoring into query and key vectors via a linear map to increase the expressivity of the scoring mechanism.\n\n## Reviews\n\nWriting: the whole article is well coherent and fluent, building the knowledge of GNN step by step, from a highly simplified model to the real GNN. The beautiful interactive figures make the article easy to read and digestible. Yet lacking mathematics and codes is both pros and cons. Unfortunately, *tarting today Distill will be taking a one year hiatus, which may be extended indefinitely.* \n\nGraph neural network: a graph is a powerful tool so that all kinds of data can be described as a graph. But this power leads to a huge difficulty in optimisation. One reason is the sparsity, the dynamic structure makes it difficult the train on CPU or GPU. Another is that GNN is very sensitive to hyper-parameters, just like the experiment section of this blog shows. As such, it is an active research area yet rarely deployed in industry.\n","slug":"paper-reading-A-gentle-introduction-to-graph-neural-networks","published":1,"updated":"2022-06-09T10:24:16.117Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz23000ul8yb3g59fc9r","content":"<blockquote>\n<p>This is a tech blog written by google research team in 2021 that introducing the graph neural network. GNN has gradually become popular in the last 4 years. Personally, I think the graph structure looks similar to the CFD mesh, and there are works focusing on simulating physics via GNN.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>\n<span id=\"more\"></span>\n<p>Paper link: <a href=\"https://staging.distill.pub/2021/gnn-intro/?ref=https://githubhelp.com\">A gentle introduction to graph neural networks</a></p>\n<p>Useful link: https://www.bilibili.com/video/BV1iT4y1d7zP</p>\n<h2 id=\"notes\">Notes</h2>\n<p><em>Because this blog has introduced GNN in detail and explained well with the interactive diagrams, it almost leaves me no need for extra notes. As a result, a throughout reading of the <a href=\"https://staging.distill.pub/2021/gnn-intro/?ref=https://githubhelp.com\">original blog</a> is recommended. And as a result this notes are only in pieces.</em></p>\n<p><img src=\" GNN interative archtecture.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GNN interative archtecture\" style=\"zoom:50%;\" /></p>\n<blockquote>\n<h3 id=\"graph-level-task\">Graph-level task</h3>\n<p>In a graph-level task, our goal is to predict the property of an entire graph. For example, for a molecule represented as a graph, we might want to predict what the molecule smells like, or whether it will bind to a receptor implicated in a disease.</p>\n<p><img src=\" GNN graph level task.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GNN graph level task\" style=\"zoom:50%;\" /></p>\n</blockquote>\n<p>The example is actually a simple task example, and the loops can be detected with ordinary algorithm such as: <a href=\"https://codeburst.io/fast-and-slow-pointer-floyds-cycle-detection-algorithm-9c7a8693f491\">Fast and Slow Pointer: Floyd's Cycle Detection Algorithm</a>. But with more complicated task, GNN can be useful. And here is the related Leetcode question: <a href=\"https://leetcode.com/problems/linked-list-cycle/description/\">No.141: Linked List Cycle</a>.</p>\n<blockquote>\n<p><img src=\" GNN graph message passing.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GNN graph message passing\" style=\"zoom:50%;\" /></p>\n<p>This is <strong>reminiscent of standard convolution</strong>: in essence, message passing and convolution are operations to aggregate and process the information of an elements neighbors in order to update the elements value. In graphs, the element is a node, and in images, the element is a pixel. <strong>However</strong>, the number of neighboring nodes in a graph can be variable, unlike in an image where each pixel has a set number of neighboring elements.</p>\n</blockquote>\n<p>When introducing the message passing method, this blog makes an analogy with the convolution. And in addition to the however part mentioned in this blog, another difference is that in convolution, each element's value is weighted differently while in the aggregation method they are all the same.</p>\n<p>Interestingly, similar weights can be achieved with Graph Attention Networks, which is introduced in later section.</p>\n<blockquote>\n<p>Another way of communicating information between graph attributes is via attention. For example, when we consider the sum-aggregation of a node and its 1-degree neighboring nodes we could also consider using a weighted sum.</p>\n<p>A common scoring function is the inner product and nodes are often transformed before scoring into query and key vectors via a linear map to increase the expressivity of the scoring mechanism.</p>\n</blockquote>\n<h2 id=\"reviews\">Reviews</h2>\n<p>Writing: the whole article is well coherent and fluent, building the knowledge of GNN step by step, from a highly simplified model to the real GNN. The beautiful interactive figures make the article easy to read and digestible. Yet lacking mathematics and codes is both pros and cons. Unfortunately, <em>tarting today Distill will be taking a one year hiatus, which may be extended indefinitely.</em></p>\n<p>Graph neural network: a graph is a powerful tool so that all kinds of data can be described as a graph. But this power leads to a huge difficulty in optimisation. One reason is the sparsity, the dynamic structure makes it difficult the train on CPU or GPU. Another is that GNN is very sensitive to hyper-parameters, just like the experiment section of this blog shows. As such, it is an active research area yet rarely deployed in industry.</p>\n","site":{"data":{}},"wordcount":2887,"excerpt":"<blockquote>\n<p>This is a tech blog written by google research team in 2021 that introducing the graph neural network. GNN has gradually become popular in the last 4 years. Personally, I think the graph structure looks similar to the CFD mesh, and there are works focusing on simulating physics via GNN.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>","more":"<p>Paper link: <a href=\"https://staging.distill.pub/2021/gnn-intro/?ref=https://githubhelp.com\">A gentle introduction to graph neural networks</a></p>\n<p>Useful link: https://www.bilibili.com/video/BV1iT4y1d7zP</p>\n<h2 id=\"notes\">Notes</h2>\n<p><em>Because this blog has introduced GNN in detail and explained well with the interactive diagrams, it almost leaves me no need for extra notes. As a result, a throughout reading of the <a href=\"https://staging.distill.pub/2021/gnn-intro/?ref=https://githubhelp.com\">original blog</a> is recommended. And as a result this notes are only in pieces.</em></p>\n<p><img src=\" GNN interative archtecture.png\" alt=\"GNN interative archtecture\" style=\"zoom:50%;\" /></p>\n<blockquote>\n<h3 id=\"graph-level-task\">Graph-level task</h3>\n<p>In a graph-level task, our goal is to predict the property of an entire graph. For example, for a molecule represented as a graph, we might want to predict what the molecule smells like, or whether it will bind to a receptor implicated in a disease.</p>\n<p><img src=\" GNN graph level task.png\" alt=\"GNN graph level task\" style=\"zoom:50%;\" /></p>\n</blockquote>\n<p>The example is actually a simple task example, and the loops can be detected with ordinary algorithm such as: <a href=\"https://codeburst.io/fast-and-slow-pointer-floyds-cycle-detection-algorithm-9c7a8693f491\">Fast and Slow Pointer: Floyd's Cycle Detection Algorithm</a>. But with more complicated task, GNN can be useful. And here is the related Leetcode question: <a href=\"https://leetcode.com/problems/linked-list-cycle/description/\">No.141: Linked List Cycle</a>.</p>\n<blockquote>\n<p><img src=\" GNN graph message passing.png\" alt=\"GNN graph message passing\" style=\"zoom:50%;\" /></p>\n<p>This is <strong>reminiscent of standard convolution</strong>: in essence, message passing and convolution are operations to aggregate and process the information of an elements neighbors in order to update the elements value. In graphs, the element is a node, and in images, the element is a pixel. <strong>However</strong>, the number of neighboring nodes in a graph can be variable, unlike in an image where each pixel has a set number of neighboring elements.</p>\n</blockquote>\n<p>When introducing the message passing method, this blog makes an analogy with the convolution. And in addition to the however part mentioned in this blog, another difference is that in convolution, each element's value is weighted differently while in the aggregation method they are all the same.</p>\n<p>Interestingly, similar weights can be achieved with Graph Attention Networks, which is introduced in later section.</p>\n<blockquote>\n<p>Another way of communicating information between graph attributes is via attention. For example, when we consider the sum-aggregation of a node and its 1-degree neighboring nodes we could also consider using a weighted sum.</p>\n<p>A common scoring function is the inner product and nodes are often transformed before scoring into query and key vectors via a linear map to increase the expressivity of the scoring mechanism.</p>\n</blockquote>\n<h2 id=\"reviews\">Reviews</h2>\n<p>Writing: the whole article is well coherent and fluent, building the knowledge of GNN step by step, from a highly simplified model to the real GNN. The beautiful interactive figures make the article easy to read and digestible. Yet lacking mathematics and codes is both pros and cons. Unfortunately, <em>tarting today Distill will be taking a one year hiatus, which may be extended indefinitely.</em></p>\n<p>Graph neural network: a graph is a powerful tool so that all kinds of data can be described as a graph. But this power leads to a huge difficulty in optimisation. One reason is the sparsity, the dynamic structure makes it difficult the train on CPU or GPU. Another is that GNN is very sensitive to hyper-parameters, just like the experiment section of this blog shows. As such, it is an active research area yet rarely deployed in industry.</p>"},{"title":"GPT1-3","author":"Ryan LI","toc":true,"declare":true,"date":"2022-04-18T00:58:59.000Z","index_img":"/index/paper-reading-GPT1-3.png","_content":"> GPT-3 is the most popular generative language model now. With more than 100 billion parameters, the performance is proved to be great and by now there are more than hundreds of works (commercial or academic) built on it, including the famous [GitHub Copilot](https://copilot.github.com/).\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/) hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\nPaper links:\n\nGPT-1: [Improving language understanding by generative pre-training](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf)\n\nGPT-2: [Language models are unsupervised multitask learners](http://www.persagen.com/files/misc/radford2019language.pdf)\n\nGPT-3: [Language models are few-shot learners](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html)\n\nUseful links: \n\nhttps://www.bilibili.com/video/BV1AF411b7xQ/\n\n[GPT-3 Demo: 300+ GPT-3 Examples, Demos, Apps](https://gpt3demo.com/)\n\n[GPT-3: Demos, Use-cases, Implications](https://towardsdatascience.com/gpt-3-demos-use-cases-implications-77f86e540dc1)\n\n*Since my own interest is not NLP, I haven't read these paper by myself. Instead, I follow a reference video above directly and make notes together with it.*\n\n## History and Timeline\n\n<img src=\"GPT timeline.png\" alt=\"GPT timeline\" style=\"zoom:50%;\" />\n\nGiven that the GPT series are all developed by the [OpenAI](https://openai.com/) and the Transformer & Bert are developed by Google, it seems there are two companies combating. And it is inevitable to compare these two series. \n\nFrom the perspective of number of cites, it is obviously that OpenAI have catch less attention from the academic world despite the huge cost. But it's not because GPT series are less novel, but because the goal of GPT series is bigger than that of Transformer & Bert. Transformer is originally developed for Machine Translation task only. And Bert simply aims to push the pre-training technic forward. That's the reason why Bert performs better than GPT if the number of parameters are the same. As a result, GPT is harder and more expensive to train a decent model. And the size of model make others hardly to reconstruct it. From the companies' perspective, OpenAI does this because they want to build the strong AI, but Transformer & Bert are developed only by the teams of Google.\n\n## GPT-1\n\n### Abstract\n\nThe whole idea is similar to what CV did in the last several decades, that is pre-training of a model on a massive dataset followed by fine-tuning on a small specialist dataset. Lacking of large labelled data such as ImageNet of 10 million, however, NLP can't do what CV does exactly. The scale of machine translation database might reach 10 million but one piece of image possesses almost 10 times of information than a sentence. So the database is still not big enough.\n\nGPT makes a big step by using unlabelled data for pre-training. And then aero shot on GPT-2 makes another big step. It is fair to say CV led the trend of deep learning in the first 5 years, but recent years, more new thoughts are coming from the NLP field. And these new thoughts have inspired the CV field as well such as [ViT](https://arxiv.org/abs/2010.11929), [CLIP](http://proceedings.mlr.press/v139/radford21a) and [MAE](https://arxiv.org/abs/2111.06377).\n\nBesides, actually it had been a long time since NLP started to use unsupervised pre-training back then. For example, the word embedding model had been used for decades. But, the word embedding can only be seen as a layer, extra layers of model need to be designed to suit for various tasks. With GPT, however, the architecture doesn't need much change, only adjusting the input to suit the tasks is ok.\n\nThe result is good but not as good as BERT, but the novelty of this paper is much better than BERT.\n\n### Introduction\n\nAfter briefly introducing the word embedding, problems of pre-training more than word-level data are presented. For example the type of optimisation objectives and how to transfer the extracted information to the tasks. The main reason of this problem is the variety of NLP tasks. There is no way to suit all the needs together.\n\nThen this paper introduces a semi-supervised method which has been explained many times. But actually GPT and BERT are normally called self-supervised model. Though they are the same to me. Semi-supervised learning is a common concept in the Machine Learning. It refers learning from a mix of massive unlabelled data and a few labelled data. \n\nThen the architecture is described. Interestingly, in order to list the reason of choosing transformer over RNN as backbone. The authors say \n\n> This model choice provides us with a more structured memory for handling long-term dependencies in text, compared to alternatives like recurrent networks, resulting in robust transfer performance across diverse tasks.\n\nBesides, the paper accents the task-specific input adaptions, which is the key of this paper.\n\n### Framework\n\n#### Unsupervised learning\n\nGPT uses a task that giving the data of u<sub>n-k</sub> to u<sub>n-1</sub> to predict the u<sub>n</sub>. So the likelihood function to be maximised is:\n\n$$\nL_{1}(\\mathcal{U})=\\sum_{i} \\log P\\left(u_{i} \\mid u_{i-k}, \\ldots, u_{i-1} ; \\Theta\\right)\n$$\nBecause the predicting task, the mechanism of the mask multi-head attention of transformer decoder matches the likelihood function perfectly. Because in the first layer of the transformer decoder, the data after u{i} are simply masked to be 0. \n\nAnd the whole pre-training process is like this:\n\n$$\n\\begin{aligned}\nh_{0} &=U W_{e}+W_{p} \\\\\nh_{l} &=\\operatorname{transformer}\\_\\operatorname{block}\\left(h_{l-1}\\right) \\forall i \\in[1, n] \\\\\nP(u) &=\\operatorname{softmax}\\left(h_{n} W_{e}^{T}\\right)\n\\end{aligned}\n$$\nCompared with BERT, the biggest difference is never encoder or decoder, bidirectional or one-way along. The key is the pre-training task they choose, the completion task that Bert use is much easier than GPT's prediction task. Because this is the **difference between interpolation and extrapolation**. Therefore, BERT outperforms GPT on the same number of parameters. But the potential of the GPT series goes far beyond BERT. As a result, it took OpenAI years to develop such an impressive GPT-3 model. On another side, however, GPT's prediction task leads to a different architecture with BERT. And the decoder architecture makes the GPT model hard to be bidirectional from the start. We'll see how it conquer this.\n\n#### Supervised fine-tuning\n\nThe fine-tuning task follows the standard supervise learning process as follows:\n\n$$\nL_{2}(\\mathcal{C})=\\sum_{(x, y)} \\log P\\left(y \\mid x^{1}, \\ldots, x^{m}\\right)\n$$\nwith\n$$\nP\\left(y \\mid x^{1}, \\ldots, x^{m}\\right)=\\operatorname{softmax}\\left(h_{l}^{m} W_{y}\\right)\n$$\nAnd the authors find it helpful to optimise the L1 and L2 together as:\n\n$$\nL_{3}(\\mathcal{C})=L_{2}(\\mathcal{C})+\\lambda * L_{1}(\\mathcal{C})\n$$\n\n#### Task-specific input transformations\n\nThe last thing to do is how to apply this framework to different tasks. Similar to with BERT, the pre-trained transformer block doesn't have to be changed.\n\n<img src=\"GPT objectives.png\" alt=\"GPT objectives\" style=\"zoom:40%;\" />\n\n### Experiments\n\nThe dataset GPT trained on is [BooksCorpus dataset](https://paperswithcode.com/dataset/bookcorpus), and the model has 12 layers with H<sub>model</sub> = 768, same as BERT<sub>base</sub>. Although the transformer encoder has one layer less than the decoder, GPT and BERT's numbers of parameters are still at the same level. Yet BERT has a 3 times larger BERT<sub>large</sub> model than the base. Because in addition to the BookCorpus dataset, BERT uses one more dataset for pre-training, in total the dataset is 4 times larger than GPT's.\n\n> For the pre-training corpus we use the [BooksCorpus](https://paperswithcode.com/dataset/bookcorpus) (800M words) (Zhu et al., 2015) and [English Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Database_download) (2,500M words).\n\nAnd unfortunately, the average accuracy of BERT<sub>base</sub> is higher than GPT at this time. Besides with the BERT<sub>large</sub> model , the accuracy can go higher, as shown below in BERT's paper.\n\n<img src=\"BERT result with GPT.png\" alt=\"BERT result with GPT\" style=\"zoom:50%;\" />\n\n## GPT-2\n\nAfter GPT-1 got defeated by BERT in 4 months, of course, GPT-2 aims to fight back and beat BERT to the ground. Considering the decoder path can't shift to the encoder with dignity, the simplest way then is to enlarge the model and the dataset. But what if it's still not working?\n\n### Abstract\n\nAfter developing a new dataset of millions of webpages called WebText, and training on a new1.5B parameter model. The result turns out to be no significant difference with BERT. So they bring out another sell point, zero shot.\n\nActually, the zero-shot behaviour is mentioned in the last section of GPT-1's paper in order to understand more of the unsupervised pre-training mechanism. And in GPT-2, this behaviour is brought front to increase the novelty.\n\n### Introduction\n\n> **Zero-shot learning** (ZSL) is a problem setup in [machine learning](https://en.wikipedia.org/wiki/Machine_learning), where at test time, a learner observes samples from classes, which were not observed during [training](https://en.wikipedia.org/wiki/Machine_learning#Training_models), and needs to predict the class that they belong to. Zero-shot methods generally work by associating observed and non-observed classes through some form of auxiliary information, which encodes observable distinguishing properties of objects.[[1\\]](https://en.wikipedia.org/wiki/Zero-shot_learning#cite_note-1) \n\nThe main-steam approach is one dataset - one task instead of one dataset - multiple tasks because of the generalisation that state of art models lack. Yet multitask learning (trending 2000-2010) represents the idea of training one model with a combination of multiple datasets and different loss functions. So GPT-2 takes the idea of multitask learning and trains the model with the zero-shot setting, under which the downstream tasks can be handled with no collecting of supervised data or fine-tuning. The result is competitive  and promising according to the authors.\n\n### Approach\n\nThe model architectures of GPT1 and GPT2 are pretty much the same. But the input methods are different.\n\nIn detail, recalling that during fine tuning process, the GPT1 introduces extra tokens such as [start], [Delim] and [Extract] to modify the input. But in GPT2 without the supervised fine-tuning process, these extra tokens would cause confusion. As a result, the downstream task input need to be more likely to the natural language when constructing.\n\nAs a result, the authors introduce what we are used to calling it \"prompt\", here are the examples:\n\n> For example, a translation training example can be written as the sequence (**translate to french**, english text, french text). Likewise, a reading comprehension training example can be written as (**answer the question**, document, question, answer).\n\nAnd afterward, 2 ideas for why this would work are discussed. First, if the model is powerful enough, it might be capable of understanding the prompts. Second, in such a big dataset, this kind of data structure exists. Take machine translation as an example, there should be many sentences containing \"translate to French\", English text, and French text. The authors point out some of them below.\n\n| Examples of machine translation                              |\n| :----------------------------------------------------------- |\n| Im not the cleverest man in the world, but like they say in French: Je ne suis pas un imbecile [Im not a fool]. <br /><br />In a now-deleted post from Aug. 16, Soheil Eid, Tory candidate in the riding of Joliette, wrote in French: Mentez mentez, il en restera toujours quelque chose, which translates as, Lie lie and something will always remain.<br /><br />I hate the word perfume, Burr says. Its somewhat better in French: parfum.<br /><br />If listened carefully at 29:55, a conversation can be heard between two guys in French: -Comment on fait pour aller de lautre cot? -Quel autre cot?, which means - How do you get to the other side? - What side?. <br /><br />If this sounds like a bit of a stretch, consider this question in French: As-tu aller au cinma?, or Did you go to the movies?, which literally translates as Have-you to go to movies/theater? <br /><br />Brevet Sans Garantie Du Gouvernement, translated to English: Patented without government warranty. |\n\n####  **Training data**\n\nAfter considering the need for larger data and the disadvantage(noise) of the existing dataset, they developed a new dataset. The data is collected by first crawling 45 million links discussed on Reddit, and then extracting all the contents of these pages. The dataset contains 8 million documents, 40 GB of text.\n\n### Experiment\n\nWith 4 level of model, the one-short performances on 4 downstream tasks are shown blow:\n\n<img src=\"GPT2 performance.png\" alt=\"GPT2 performance\" style=\"zoom:50%;\" />\n\nIt can be seen that first 3 tasks, the results are not the best yet not the worst, however, the performance on Question Answering is bad, and other works perform way better than GPT-2. \n\nBut this is not over, because in the figure, there is still room for performance improvement on all 4 tasks as the size of the larger model increases. So here comes GPT-3.\n\n## GPT-3\n\nThe value of an article depends on the topic, effectiveness and novelty. GPT-2 has rather low effectiveness but strong novelty. As a result, GPT-3 aims to promote the effectiveness of its predecessor, while loosing the zero-shot condition to few-shot condition.\n\n### Abstract\n\nThe parameters of GPT-3 are enlarged 10 times to 175 billion.  When applying GPT-3 to downstream tasks, strong performance is achieved without gradient update or fine-tuning. Besides, GPT-3 is capable of generating articles that are indistinguishable from humans' work.\n\nBesides, unlikely to former papers, this is a 63-page technic report. Without limitation of words or page number, it is very detailed, especially for the experiment and discussion sections.\n\n### Introduction\n\nThere are 3 problems of current pre-training + fine-tuning language model: \n\n- A large labeled dataset is still needed for a good result\n- The pre-training model is not really generalisable because of the need for fine-tuning\n- Human doesn't need large fine tuning dataset\n\nWhen introducing their work, the authors try to re-define the concept of \"meta-learning\" and \"in-context learning\". What they really mean are training a huge generalisable model and train without updating the gradient, respectively.\n\nThen 3 evaluation methods are presented:\n\n- Few-shot learning: 10-100 task-related data\n\n- One-shot learning\n- Zero-short learning\n\nAnd the performance with model size is plotted below (1.3B matches the GPT-2 model). Can be seen the final accuracy (few shot - 175B) almost doubled the former GPT-2 accuracy (1.3B zero-short)\n\n<img src=\"GPT3 performance.png\" alt=\"GPT3 performance\" style=\"zoom:50%;\" />\n\n### Approach\n\nIn this section, fine-tuning, few-shot, one-shot, zero-shot learning are explained first in this figure below:\n\n<img src=\"GPT-3 approach.png\" alt=\"GPT-3 approach\" style=\"zoom:50%;\" />\n\nThe right column denotes the traditional fine-tuning process that requires extra few gradient update steps. The left side shows how GPT-3 applies \"in-context learning\" during inference. Basically, the input is divided by 3 parts, task description, example, and prompt. The task description and prompt are ended by \":\", and \"=>\" respectively. The Transformer Decoder extracts the features of the \"context\" and then predicts the next several words starting from the prompt. As a result, the model is able to infer without gradient updates. Yet it comes 2 problems with few-shot:\n\n- Unable to process really long examples. For example, thousands of English-French translation dataset is easy to get access but they can rarely be leveraged to promote the model performance.\n- The inference is one-time thing, meaning the model can't actually learn from previous task description or example. Same samples have to be inputed again an again.\n\nAs a result, the few-shot learning is not commonly used.\n\n#### Model and Architectures\n\nGPT-3 uses the same architecture as GPT-2 yet uses the methods form \"[Sparse Transformer](https://arxiv.org/abs/1904.10509)\" to modify the layers. And 8 different size of models are developed.\n\n<img src=\"GPT3 models.png\" alt=\"GPT3 models\" style=\"zoom:60%;\" /> \n\nYet compared with previous models, GPT-3 is \"fatter\" ,meaning with same *d<sub>model</sub>* (192x of GPT3<sub>small</sub>), *n<sub>layers</sub>* is smaller (only 8x of GPT3<sub>small</sub>). \n\nThe mini-batch size goes up to 3.2M, definitely not mini. Large batch size improves the computational performance and parallelism while reducing the noise in each batch and making the model easier to overfitting. However, this defect is not evident in GPT-3. It is still an open question, now people consider it from two aspects: (1) the internal structure prevents the model from overfitting. (2) Such a large model is able to search for large space and it is more prone to converge to a simpler architecture.\n\nThe learning rate decreases with batch size increasing according to [research1](https://arxiv.org/abs/2001.08361) and [research2](https://arxiv.org/abs/1812.06162), also counter-intuitive. [Former work](https://arxiv.org/abs/1706.02677) shows that batch size should increase linear with the learning rate.\n\n#### Training Dataset\n\nWith a huge model, [Common Craw dataset](https://commoncrawl.org/) has come back as an option. The authors clean this dataset in 3 steps:\n\n- A logistic classification model is built, taking samples of Common Craw dataset as negative and WebText as positive. Such model is used on the whole dataset of Common Craw to predict positive (high quality) or negative. The positive stay and the negative are filtered.\n- [LSH algorithm](https://www.pinecone.io/learn/locality-sensitive-hashing/) is applied on the remaining dataset to filter the similar content.\n- More \"clean\" datasets are mixed in with weight.\n\n<img src=\"GPT3 training data.png\" alt=\"GPT3 training data\" style=\"zoom:50%;\" />\n\n#### Training Process\n\nSpecific training details are not presented. Information so far is [DGX-1 cluster](https://www.nvidia.com/en-us/data-center/dgx-1/) is used.\n\n### Results\n\nThe results are too many so only interesting figures are covered.\n\n<img src=\"GPT3 performance with compute.png\" alt=\"GPT3 performance with compute\" style=\"zoom:50%;\" />\n\nFrom the figure, the power law distribution of performance with compute are found, i.e. in order to decrease the validation loss linearly, the FLOPS need to increase exponentially. This still is a major problem in Machine Learning.\n\n<img src=\"GPT3 result.png\" alt=\"GPT3 result\" style=\"zoom:50%;\" />\n\nThis figure shows the compression of results with Zero-shot SOTO and human. Nothing to comment. Just ... good.\n\n<img src=\"GPT-3 result 2.png\" alt=\"GPT-3 result 2\" style=\"zoom:50%;\" />And on the Open-Domain QA tasks, GPT-3 outperform other models such as google T5. Google T5 can be considered as a model with both encoder and decoder.\n\n<img src=\"GPT3 result 3.png\" alt=\"GPT3 result 3\" style=\"zoom:50%;\" />\n\nAnd few shot learning outperform SOTO fine tuning models.\n\n<img src=\"GPT3 result4.png\" alt=\"GPT3 result4\" style=\"zoom:50%;\" />\n\nIn the machine translation task, it is interesting to see that other language to English is better than English to others.\n\n<img src=\"GPT 3 result 5.png\" alt=\"GPT 3 result 5\" style=\"zoom:50%;\" />\n\nThen a news article is generated with GPT-3 with numbers, years and time that makes the article look legit.\n\n### Limitations\n\n- Text synthesis, the predicted texts are always looping.\n- The bidirectional limit still exist because of the decoder structure.\n- The tokens that learned by GPT3 are equally weighted, yet wasting the model on the meaningless but high frequent function words.\n- No experience in Videos or real-world physical interaction.\n- The interpretation is still low. It's nearly impossible to know how does such a big model works.\n\n### Broader Impact\n\n- Can be used for fraud and crimes\n- Gender difference and race\n- Energy consuming \n\n<img src=\"GPT3 gender.png\" alt=\"GPT3 gender\" style=\"zoom:50%;\" />\n\n<img src=\"GPT3 race.png\" alt=\"GPT3 race\" style=\"zoom:50%;\" />\n\n\n\n## Reference\n\n[Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. *arXiv preprint arXiv:2010.11929*.]()\n\n[Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... & Sutskever, I. (2021, July). Learning transferable visual models from natural language supervision. In *International Conference on Machine Learning* (pp. 8748-8763). PMLR.](http://proceedings.mlr.press/v139/radford21a)\n\n[He, K., Chen, X., Xie, S., Li, Y., Dollr, P., & Girshick, R. (2021). Masked autoencoders are scalable vision learners. *arXiv preprint arXiv:2111.06377*.](https://arxiv.org/abs/2111.06377)\n\n[Child, R., Gray, S., Radford, A., & Sutskever, I. (2019). Generating long sequences with sparse transformers. *arXiv preprint arXiv:1904.10509*.](https://arxiv.org/abs/1904.10509)\n\n[Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., ... & Amodei, D. (2020). Scaling laws for neural language models. *arXiv preprint arXiv:2001.08361*.](https://arxiv.org/abs/2001.08361)\n\n[McCandlish, S., Kaplan, J., Amodei, D., & Team, O. D. (2018). An empirical model of large-batch training. *arXiv preprint arXiv:1812.06162*.](https://arxiv.org/abs/1812.06162)\n\n[Goyal, P., Dollr, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., ... & He, K. (2017). Accurate, large minibatch sgd: Training imagenet in 1 hour. *arXiv preprint arXiv:1706.02677*.](https://arxiv.org/abs/1706.02677)\n","source":"_posts/paper-reading-GPT1-3.md","raw":"---\ntitle: 'GPT1-3'\nauthor: Ryan LI\ntoc: true\ndeclare: true\ndate: 2022-04-18 08:58:59\nindex_img: /index/paper-reading-GPT1-3.png\ntags:\n  - paper reading\n  - deep learning\n---\n> GPT-3 is the most popular generative language model now. With more than 100 billion parameters, the performance is proved to be great and by now there are more than hundreds of works (commercial or academic) built on it, including the famous [GitHub Copilot](https://copilot.github.com/).\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/) hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\nPaper links:\n\nGPT-1: [Improving language understanding by generative pre-training](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf)\n\nGPT-2: [Language models are unsupervised multitask learners](http://www.persagen.com/files/misc/radford2019language.pdf)\n\nGPT-3: [Language models are few-shot learners](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html)\n\nUseful links: \n\nhttps://www.bilibili.com/video/BV1AF411b7xQ/\n\n[GPT-3 Demo: 300+ GPT-3 Examples, Demos, Apps](https://gpt3demo.com/)\n\n[GPT-3: Demos, Use-cases, Implications](https://towardsdatascience.com/gpt-3-demos-use-cases-implications-77f86e540dc1)\n\n*Since my own interest is not NLP, I haven't read these paper by myself. Instead, I follow a reference video above directly and make notes together with it.*\n\n## History and Timeline\n\n<img src=\"GPT timeline.png\" alt=\"GPT timeline\" style=\"zoom:50%;\" />\n\nGiven that the GPT series are all developed by the [OpenAI](https://openai.com/) and the Transformer & Bert are developed by Google, it seems there are two companies combating. And it is inevitable to compare these two series. \n\nFrom the perspective of number of cites, it is obviously that OpenAI have catch less attention from the academic world despite the huge cost. But it's not because GPT series are less novel, but because the goal of GPT series is bigger than that of Transformer & Bert. Transformer is originally developed for Machine Translation task only. And Bert simply aims to push the pre-training technic forward. That's the reason why Bert performs better than GPT if the number of parameters are the same. As a result, GPT is harder and more expensive to train a decent model. And the size of model make others hardly to reconstruct it. From the companies' perspective, OpenAI does this because they want to build the strong AI, but Transformer & Bert are developed only by the teams of Google.\n\n## GPT-1\n\n### Abstract\n\nThe whole idea is similar to what CV did in the last several decades, that is pre-training of a model on a massive dataset followed by fine-tuning on a small specialist dataset. Lacking of large labelled data such as ImageNet of 10 million, however, NLP can't do what CV does exactly. The scale of machine translation database might reach 10 million but one piece of image possesses almost 10 times of information than a sentence. So the database is still not big enough.\n\nGPT makes a big step by using unlabelled data for pre-training. And then aero shot on GPT-2 makes another big step. It is fair to say CV led the trend of deep learning in the first 5 years, but recent years, more new thoughts are coming from the NLP field. And these new thoughts have inspired the CV field as well such as [ViT](https://arxiv.org/abs/2010.11929), [CLIP](http://proceedings.mlr.press/v139/radford21a) and [MAE](https://arxiv.org/abs/2111.06377).\n\nBesides, actually it had been a long time since NLP started to use unsupervised pre-training back then. For example, the word embedding model had been used for decades. But, the word embedding can only be seen as a layer, extra layers of model need to be designed to suit for various tasks. With GPT, however, the architecture doesn't need much change, only adjusting the input to suit the tasks is ok.\n\nThe result is good but not as good as BERT, but the novelty of this paper is much better than BERT.\n\n### Introduction\n\nAfter briefly introducing the word embedding, problems of pre-training more than word-level data are presented. For example the type of optimisation objectives and how to transfer the extracted information to the tasks. The main reason of this problem is the variety of NLP tasks. There is no way to suit all the needs together.\n\nThen this paper introduces a semi-supervised method which has been explained many times. But actually GPT and BERT are normally called self-supervised model. Though they are the same to me. Semi-supervised learning is a common concept in the Machine Learning. It refers learning from a mix of massive unlabelled data and a few labelled data. \n\nThen the architecture is described. Interestingly, in order to list the reason of choosing transformer over RNN as backbone. The authors say \n\n> This model choice provides us with a more structured memory for handling long-term dependencies in text, compared to alternatives like recurrent networks, resulting in robust transfer performance across diverse tasks.\n\nBesides, the paper accents the task-specific input adaptions, which is the key of this paper.\n\n### Framework\n\n#### Unsupervised learning\n\nGPT uses a task that giving the data of u<sub>n-k</sub> to u<sub>n-1</sub> to predict the u<sub>n</sub>. So the likelihood function to be maximised is:\n\n$$\nL_{1}(\\mathcal{U})=\\sum_{i} \\log P\\left(u_{i} \\mid u_{i-k}, \\ldots, u_{i-1} ; \\Theta\\right)\n$$\nBecause the predicting task, the mechanism of the mask multi-head attention of transformer decoder matches the likelihood function perfectly. Because in the first layer of the transformer decoder, the data after u{i} are simply masked to be 0. \n\nAnd the whole pre-training process is like this:\n\n$$\n\\begin{aligned}\nh_{0} &=U W_{e}+W_{p} \\\\\nh_{l} &=\\operatorname{transformer}\\_\\operatorname{block}\\left(h_{l-1}\\right) \\forall i \\in[1, n] \\\\\nP(u) &=\\operatorname{softmax}\\left(h_{n} W_{e}^{T}\\right)\n\\end{aligned}\n$$\nCompared with BERT, the biggest difference is never encoder or decoder, bidirectional or one-way along. The key is the pre-training task they choose, the completion task that Bert use is much easier than GPT's prediction task. Because this is the **difference between interpolation and extrapolation**. Therefore, BERT outperforms GPT on the same number of parameters. But the potential of the GPT series goes far beyond BERT. As a result, it took OpenAI years to develop such an impressive GPT-3 model. On another side, however, GPT's prediction task leads to a different architecture with BERT. And the decoder architecture makes the GPT model hard to be bidirectional from the start. We'll see how it conquer this.\n\n#### Supervised fine-tuning\n\nThe fine-tuning task follows the standard supervise learning process as follows:\n\n$$\nL_{2}(\\mathcal{C})=\\sum_{(x, y)} \\log P\\left(y \\mid x^{1}, \\ldots, x^{m}\\right)\n$$\nwith\n$$\nP\\left(y \\mid x^{1}, \\ldots, x^{m}\\right)=\\operatorname{softmax}\\left(h_{l}^{m} W_{y}\\right)\n$$\nAnd the authors find it helpful to optimise the L1 and L2 together as:\n\n$$\nL_{3}(\\mathcal{C})=L_{2}(\\mathcal{C})+\\lambda * L_{1}(\\mathcal{C})\n$$\n\n#### Task-specific input transformations\n\nThe last thing to do is how to apply this framework to different tasks. Similar to with BERT, the pre-trained transformer block doesn't have to be changed.\n\n<img src=\"GPT objectives.png\" alt=\"GPT objectives\" style=\"zoom:40%;\" />\n\n### Experiments\n\nThe dataset GPT trained on is [BooksCorpus dataset](https://paperswithcode.com/dataset/bookcorpus), and the model has 12 layers with H<sub>model</sub> = 768, same as BERT<sub>base</sub>. Although the transformer encoder has one layer less than the decoder, GPT and BERT's numbers of parameters are still at the same level. Yet BERT has a 3 times larger BERT<sub>large</sub> model than the base. Because in addition to the BookCorpus dataset, BERT uses one more dataset for pre-training, in total the dataset is 4 times larger than GPT's.\n\n> For the pre-training corpus we use the [BooksCorpus](https://paperswithcode.com/dataset/bookcorpus) (800M words) (Zhu et al., 2015) and [English Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Database_download) (2,500M words).\n\nAnd unfortunately, the average accuracy of BERT<sub>base</sub> is higher than GPT at this time. Besides with the BERT<sub>large</sub> model , the accuracy can go higher, as shown below in BERT's paper.\n\n<img src=\"BERT result with GPT.png\" alt=\"BERT result with GPT\" style=\"zoom:50%;\" />\n\n## GPT-2\n\nAfter GPT-1 got defeated by BERT in 4 months, of course, GPT-2 aims to fight back and beat BERT to the ground. Considering the decoder path can't shift to the encoder with dignity, the simplest way then is to enlarge the model and the dataset. But what if it's still not working?\n\n### Abstract\n\nAfter developing a new dataset of millions of webpages called WebText, and training on a new1.5B parameter model. The result turns out to be no significant difference with BERT. So they bring out another sell point, zero shot.\n\nActually, the zero-shot behaviour is mentioned in the last section of GPT-1's paper in order to understand more of the unsupervised pre-training mechanism. And in GPT-2, this behaviour is brought front to increase the novelty.\n\n### Introduction\n\n> **Zero-shot learning** (ZSL) is a problem setup in [machine learning](https://en.wikipedia.org/wiki/Machine_learning), where at test time, a learner observes samples from classes, which were not observed during [training](https://en.wikipedia.org/wiki/Machine_learning#Training_models), and needs to predict the class that they belong to. Zero-shot methods generally work by associating observed and non-observed classes through some form of auxiliary information, which encodes observable distinguishing properties of objects.[[1\\]](https://en.wikipedia.org/wiki/Zero-shot_learning#cite_note-1) \n\nThe main-steam approach is one dataset - one task instead of one dataset - multiple tasks because of the generalisation that state of art models lack. Yet multitask learning (trending 2000-2010) represents the idea of training one model with a combination of multiple datasets and different loss functions. So GPT-2 takes the idea of multitask learning and trains the model with the zero-shot setting, under which the downstream tasks can be handled with no collecting of supervised data or fine-tuning. The result is competitive  and promising according to the authors.\n\n### Approach\n\nThe model architectures of GPT1 and GPT2 are pretty much the same. But the input methods are different.\n\nIn detail, recalling that during fine tuning process, the GPT1 introduces extra tokens such as [start], [Delim] and [Extract] to modify the input. But in GPT2 without the supervised fine-tuning process, these extra tokens would cause confusion. As a result, the downstream task input need to be more likely to the natural language when constructing.\n\nAs a result, the authors introduce what we are used to calling it \"prompt\", here are the examples:\n\n> For example, a translation training example can be written as the sequence (**translate to french**, english text, french text). Likewise, a reading comprehension training example can be written as (**answer the question**, document, question, answer).\n\nAnd afterward, 2 ideas for why this would work are discussed. First, if the model is powerful enough, it might be capable of understanding the prompts. Second, in such a big dataset, this kind of data structure exists. Take machine translation as an example, there should be many sentences containing \"translate to French\", English text, and French text. The authors point out some of them below.\n\n| Examples of machine translation                              |\n| :----------------------------------------------------------- |\n| Im not the cleverest man in the world, but like they say in French: Je ne suis pas un imbecile [Im not a fool]. <br /><br />In a now-deleted post from Aug. 16, Soheil Eid, Tory candidate in the riding of Joliette, wrote in French: Mentez mentez, il en restera toujours quelque chose, which translates as, Lie lie and something will always remain.<br /><br />I hate the word perfume, Burr says. Its somewhat better in French: parfum.<br /><br />If listened carefully at 29:55, a conversation can be heard between two guys in French: -Comment on fait pour aller de lautre cot? -Quel autre cot?, which means - How do you get to the other side? - What side?. <br /><br />If this sounds like a bit of a stretch, consider this question in French: As-tu aller au cinma?, or Did you go to the movies?, which literally translates as Have-you to go to movies/theater? <br /><br />Brevet Sans Garantie Du Gouvernement, translated to English: Patented without government warranty. |\n\n####  **Training data**\n\nAfter considering the need for larger data and the disadvantage(noise) of the existing dataset, they developed a new dataset. The data is collected by first crawling 45 million links discussed on Reddit, and then extracting all the contents of these pages. The dataset contains 8 million documents, 40 GB of text.\n\n### Experiment\n\nWith 4 level of model, the one-short performances on 4 downstream tasks are shown blow:\n\n<img src=\"GPT2 performance.png\" alt=\"GPT2 performance\" style=\"zoom:50%;\" />\n\nIt can be seen that first 3 tasks, the results are not the best yet not the worst, however, the performance on Question Answering is bad, and other works perform way better than GPT-2. \n\nBut this is not over, because in the figure, there is still room for performance improvement on all 4 tasks as the size of the larger model increases. So here comes GPT-3.\n\n## GPT-3\n\nThe value of an article depends on the topic, effectiveness and novelty. GPT-2 has rather low effectiveness but strong novelty. As a result, GPT-3 aims to promote the effectiveness of its predecessor, while loosing the zero-shot condition to few-shot condition.\n\n### Abstract\n\nThe parameters of GPT-3 are enlarged 10 times to 175 billion.  When applying GPT-3 to downstream tasks, strong performance is achieved without gradient update or fine-tuning. Besides, GPT-3 is capable of generating articles that are indistinguishable from humans' work.\n\nBesides, unlikely to former papers, this is a 63-page technic report. Without limitation of words or page number, it is very detailed, especially for the experiment and discussion sections.\n\n### Introduction\n\nThere are 3 problems of current pre-training + fine-tuning language model: \n\n- A large labeled dataset is still needed for a good result\n- The pre-training model is not really generalisable because of the need for fine-tuning\n- Human doesn't need large fine tuning dataset\n\nWhen introducing their work, the authors try to re-define the concept of \"meta-learning\" and \"in-context learning\". What they really mean are training a huge generalisable model and train without updating the gradient, respectively.\n\nThen 3 evaluation methods are presented:\n\n- Few-shot learning: 10-100 task-related data\n\n- One-shot learning\n- Zero-short learning\n\nAnd the performance with model size is plotted below (1.3B matches the GPT-2 model). Can be seen the final accuracy (few shot - 175B) almost doubled the former GPT-2 accuracy (1.3B zero-short)\n\n<img src=\"GPT3 performance.png\" alt=\"GPT3 performance\" style=\"zoom:50%;\" />\n\n### Approach\n\nIn this section, fine-tuning, few-shot, one-shot, zero-shot learning are explained first in this figure below:\n\n<img src=\"GPT-3 approach.png\" alt=\"GPT-3 approach\" style=\"zoom:50%;\" />\n\nThe right column denotes the traditional fine-tuning process that requires extra few gradient update steps. The left side shows how GPT-3 applies \"in-context learning\" during inference. Basically, the input is divided by 3 parts, task description, example, and prompt. The task description and prompt are ended by \":\", and \"=>\" respectively. The Transformer Decoder extracts the features of the \"context\" and then predicts the next several words starting from the prompt. As a result, the model is able to infer without gradient updates. Yet it comes 2 problems with few-shot:\n\n- Unable to process really long examples. For example, thousands of English-French translation dataset is easy to get access but they can rarely be leveraged to promote the model performance.\n- The inference is one-time thing, meaning the model can't actually learn from previous task description or example. Same samples have to be inputed again an again.\n\nAs a result, the few-shot learning is not commonly used.\n\n#### Model and Architectures\n\nGPT-3 uses the same architecture as GPT-2 yet uses the methods form \"[Sparse Transformer](https://arxiv.org/abs/1904.10509)\" to modify the layers. And 8 different size of models are developed.\n\n<img src=\"GPT3 models.png\" alt=\"GPT3 models\" style=\"zoom:60%;\" /> \n\nYet compared with previous models, GPT-3 is \"fatter\" ,meaning with same *d<sub>model</sub>* (192x of GPT3<sub>small</sub>), *n<sub>layers</sub>* is smaller (only 8x of GPT3<sub>small</sub>). \n\nThe mini-batch size goes up to 3.2M, definitely not mini. Large batch size improves the computational performance and parallelism while reducing the noise in each batch and making the model easier to overfitting. However, this defect is not evident in GPT-3. It is still an open question, now people consider it from two aspects: (1) the internal structure prevents the model from overfitting. (2) Such a large model is able to search for large space and it is more prone to converge to a simpler architecture.\n\nThe learning rate decreases with batch size increasing according to [research1](https://arxiv.org/abs/2001.08361) and [research2](https://arxiv.org/abs/1812.06162), also counter-intuitive. [Former work](https://arxiv.org/abs/1706.02677) shows that batch size should increase linear with the learning rate.\n\n#### Training Dataset\n\nWith a huge model, [Common Craw dataset](https://commoncrawl.org/) has come back as an option. The authors clean this dataset in 3 steps:\n\n- A logistic classification model is built, taking samples of Common Craw dataset as negative and WebText as positive. Such model is used on the whole dataset of Common Craw to predict positive (high quality) or negative. The positive stay and the negative are filtered.\n- [LSH algorithm](https://www.pinecone.io/learn/locality-sensitive-hashing/) is applied on the remaining dataset to filter the similar content.\n- More \"clean\" datasets are mixed in with weight.\n\n<img src=\"GPT3 training data.png\" alt=\"GPT3 training data\" style=\"zoom:50%;\" />\n\n#### Training Process\n\nSpecific training details are not presented. Information so far is [DGX-1 cluster](https://www.nvidia.com/en-us/data-center/dgx-1/) is used.\n\n### Results\n\nThe results are too many so only interesting figures are covered.\n\n<img src=\"GPT3 performance with compute.png\" alt=\"GPT3 performance with compute\" style=\"zoom:50%;\" />\n\nFrom the figure, the power law distribution of performance with compute are found, i.e. in order to decrease the validation loss linearly, the FLOPS need to increase exponentially. This still is a major problem in Machine Learning.\n\n<img src=\"GPT3 result.png\" alt=\"GPT3 result\" style=\"zoom:50%;\" />\n\nThis figure shows the compression of results with Zero-shot SOTO and human. Nothing to comment. Just ... good.\n\n<img src=\"GPT-3 result 2.png\" alt=\"GPT-3 result 2\" style=\"zoom:50%;\" />And on the Open-Domain QA tasks, GPT-3 outperform other models such as google T5. Google T5 can be considered as a model with both encoder and decoder.\n\n<img src=\"GPT3 result 3.png\" alt=\"GPT3 result 3\" style=\"zoom:50%;\" />\n\nAnd few shot learning outperform SOTO fine tuning models.\n\n<img src=\"GPT3 result4.png\" alt=\"GPT3 result4\" style=\"zoom:50%;\" />\n\nIn the machine translation task, it is interesting to see that other language to English is better than English to others.\n\n<img src=\"GPT 3 result 5.png\" alt=\"GPT 3 result 5\" style=\"zoom:50%;\" />\n\nThen a news article is generated with GPT-3 with numbers, years and time that makes the article look legit.\n\n### Limitations\n\n- Text synthesis, the predicted texts are always looping.\n- The bidirectional limit still exist because of the decoder structure.\n- The tokens that learned by GPT3 are equally weighted, yet wasting the model on the meaningless but high frequent function words.\n- No experience in Videos or real-world physical interaction.\n- The interpretation is still low. It's nearly impossible to know how does such a big model works.\n\n### Broader Impact\n\n- Can be used for fraud and crimes\n- Gender difference and race\n- Energy consuming \n\n<img src=\"GPT3 gender.png\" alt=\"GPT3 gender\" style=\"zoom:50%;\" />\n\n<img src=\"GPT3 race.png\" alt=\"GPT3 race\" style=\"zoom:50%;\" />\n\n\n\n## Reference\n\n[Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. *arXiv preprint arXiv:2010.11929*.]()\n\n[Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... & Sutskever, I. (2021, July). Learning transferable visual models from natural language supervision. In *International Conference on Machine Learning* (pp. 8748-8763). PMLR.](http://proceedings.mlr.press/v139/radford21a)\n\n[He, K., Chen, X., Xie, S., Li, Y., Dollr, P., & Girshick, R. (2021). Masked autoencoders are scalable vision learners. *arXiv preprint arXiv:2111.06377*.](https://arxiv.org/abs/2111.06377)\n\n[Child, R., Gray, S., Radford, A., & Sutskever, I. (2019). Generating long sequences with sparse transformers. *arXiv preprint arXiv:1904.10509*.](https://arxiv.org/abs/1904.10509)\n\n[Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., ... & Amodei, D. (2020). Scaling laws for neural language models. *arXiv preprint arXiv:2001.08361*.](https://arxiv.org/abs/2001.08361)\n\n[McCandlish, S., Kaplan, J., Amodei, D., & Team, O. D. (2018). An empirical model of large-batch training. *arXiv preprint arXiv:1812.06162*.](https://arxiv.org/abs/1812.06162)\n\n[Goyal, P., Dollr, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., ... & He, K. (2017). Accurate, large minibatch sgd: Training imagenet in 1 hour. *arXiv preprint arXiv:1706.02677*.](https://arxiv.org/abs/1706.02677)\n","slug":"paper-reading-GPT1-3","published":1,"updated":"2022-06-09T10:25:32.570Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz29001ul8ybdqrygfk6","content":"<blockquote>\n<p>GPT-3 is the most popular generative language model now. With more than 100 billion parameters, the performance is proved to be great and by now there are more than hundreds of works (commercial or academic) built on it, including the famous <a href=\"https://copilot.github.com/\">GitHub Copilot</a>.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a> hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>\n<span id=\"more\"></span>\n<p>Paper links:</p>\n<p>GPT-1: <a href=\"https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf\">Improving language understanding by generative pre-training</a></p>\n<p>GPT-2: <a href=\"http://www.persagen.com/files/misc/radford2019language.pdf\">Language models are unsupervised multitask learners</a></p>\n<p>GPT-3: <a href=\"https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html\">Language models are few-shot learners</a></p>\n<p>Useful links:</p>\n<p>https://www.bilibili.com/video/BV1AF411b7xQ/</p>\n<p><a href=\"https://gpt3demo.com/\">GPT-3 Demo: 300+ GPT-3 Examples, Demos, Apps</a></p>\n<p><a href=\"https://towardsdatascience.com/gpt-3-demos-use-cases-implications-77f86e540dc1\">GPT-3: Demos, Use-cases, Implications</a></p>\n<p><em>Since my own interest is not NLP, I haven't read these paper by myself. Instead, I follow a reference video above directly and make notes together with it.</em></p>\n<h2 id=\"history-and-timeline\">History and Timeline</h2>\n<p><img src=\"GPT timeline.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT timeline\" style=\"zoom:50%;\" /></p>\n<p>Given that the GPT series are all developed by the <a href=\"https://openai.com/\">OpenAI</a> and the Transformer &amp; Bert are developed by Google, it seems there are two companies combating. And it is inevitable to compare these two series.</p>\n<p>From the perspective of number of cites, it is obviously that OpenAI have catch less attention from the academic world despite the huge cost. But it's not because GPT series are less novel, but because the goal of GPT series is bigger than that of Transformer &amp; Bert. Transformer is originally developed for Machine Translation task only. And Bert simply aims to push the pre-training technic forward. That's the reason why Bert performs better than GPT if the number of parameters are the same. As a result, GPT is harder and more expensive to train a decent model. And the size of model make others hardly to reconstruct it. From the companies' perspective, OpenAI does this because they want to build the strong AI, but Transformer &amp; Bert are developed only by the teams of Google.</p>\n<h2 id=\"gpt-1\">GPT-1</h2>\n<h3 id=\"abstract\">Abstract</h3>\n<p>The whole idea is similar to what CV did in the last several decades, that is pre-training of a model on a massive dataset followed by fine-tuning on a small specialist dataset. Lacking of large labelled data such as ImageNet of 10 million, however, NLP can't do what CV does exactly. The scale of machine translation database might reach 10 million but one piece of image possesses almost 10 times of information than a sentence. So the database is still not big enough.</p>\n<p>GPT makes a big step by using unlabelled data for pre-training. And then aero shot on GPT-2 makes another big step. It is fair to say CV led the trend of deep learning in the first 5 years, but recent years, more new thoughts are coming from the NLP field. And these new thoughts have inspired the CV field as well such as <a href=\"https://arxiv.org/abs/2010.11929\">ViT</a>, <a href=\"http://proceedings.mlr.press/v139/radford21a\">CLIP</a> and <a href=\"https://arxiv.org/abs/2111.06377\">MAE</a>.</p>\n<p>Besides, actually it had been a long time since NLP started to use unsupervised pre-training back then. For example, the word embedding model had been used for decades. But, the word embedding can only be seen as a layer, extra layers of model need to be designed to suit for various tasks. With GPT, however, the architecture doesn't need much change, only adjusting the input to suit the tasks is ok.</p>\n<p>The result is good but not as good as BERT, but the novelty of this paper is much better than BERT.</p>\n<h3 id=\"introduction\">Introduction</h3>\n<p>After briefly introducing the word embedding, problems of pre-training more than word-level data are presented. For example the type of optimisation objectives and how to transfer the extracted information to the tasks. The main reason of this problem is the variety of NLP tasks. There is no way to suit all the needs together.</p>\n<p>Then this paper introduces a semi-supervised method which has been explained many times. But actually GPT and BERT are normally called self-supervised model. Though they are the same to me. Semi-supervised learning is a common concept in the Machine Learning. It refers learning from a mix of massive unlabelled data and a few labelled data.</p>\n<p>Then the architecture is described. Interestingly, in order to list the reason of choosing transformer over RNN as backbone. The authors say</p>\n<blockquote>\n<p>This model choice provides us with a more structured memory for handling long-term dependencies in text, compared to alternatives like recurrent networks, resulting in robust transfer performance across diverse tasks.</p>\n</blockquote>\n<p>Besides, the paper accents the task-specific input adaptions, which is the key of this paper.</p>\n<h3 id=\"framework\">Framework</h3>\n<h4 id=\"unsupervised-learning\">Unsupervised learning</h4>\n<p>GPT uses a task that giving the data of u<sub>n-k</sub> to u<sub>n-1</sub> to predict the u<sub>n</sub>. So the likelihood function to be maximised is:</p>\n<p><span class=\"math display\">\\[\nL_{1}(\\mathcal{U})=\\sum_{i} \\log P\\left(u_{i} \\mid u_{i-k}, \\ldots, u_{i-1} ; \\Theta\\right)\n\\]</span> Because the predicting task, the mechanism of the mask multi-head attention of transformer decoder matches the likelihood function perfectly. Because in the first layer of the transformer decoder, the data after u{i} are simply masked to be 0.</p>\n<p>And the whole pre-training process is like this:</p>\n<p><span class=\"math display\">\\[\n\\begin{aligned}\nh_{0} &amp;=U W_{e}+W_{p} \\\\\nh_{l} &amp;=\\operatorname{transformer}\\_\\operatorname{block}\\left(h_{l-1}\\right) \\forall i \\in[1, n] \\\\\nP(u) &amp;=\\operatorname{softmax}\\left(h_{n} W_{e}^{T}\\right)\n\\end{aligned}\n\\]</span> Compared with BERT, the biggest difference is never encoder or decoder, bidirectional or one-way along. The key is the pre-training task they choose, the completion task that Bert use is much easier than GPT's prediction task. Because this is the <strong>difference between interpolation and extrapolation</strong>. Therefore, BERT outperforms GPT on the same number of parameters. But the potential of the GPT series goes far beyond BERT. As a result, it took OpenAI years to develop such an impressive GPT-3 model. On another side, however, GPT's prediction task leads to a different architecture with BERT. And the decoder architecture makes the GPT model hard to be bidirectional from the start. We'll see how it conquer this.</p>\n<h4 id=\"supervised-fine-tuning\">Supervised fine-tuning</h4>\n<p>The fine-tuning task follows the standard supervise learning process as follows:</p>\n<p><span class=\"math display\">\\[\nL_{2}(\\mathcal{C})=\\sum_{(x, y)} \\log P\\left(y \\mid x^{1}, \\ldots, x^{m}\\right)\n\\]</span> with <span class=\"math display\">\\[\nP\\left(y \\mid x^{1}, \\ldots, x^{m}\\right)=\\operatorname{softmax}\\left(h_{l}^{m} W_{y}\\right)\n\\]</span> And the authors find it helpful to optimise the L1 and L2 together as:</p>\n<p><span class=\"math display\">\\[\nL_{3}(\\mathcal{C})=L_{2}(\\mathcal{C})+\\lambda * L_{1}(\\mathcal{C})\n\\]</span></p>\n<h4 id=\"task-specific-input-transformations\">Task-specific input transformations</h4>\n<p>The last thing to do is how to apply this framework to different tasks. Similar to with BERT, the pre-trained transformer block doesn't have to be changed.</p>\n<p><img src=\"GPT objectives.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT objectives\" style=\"zoom:40%;\" /></p>\n<h3 id=\"experiments\">Experiments</h3>\n<p>The dataset GPT trained on is <a href=\"https://paperswithcode.com/dataset/bookcorpus\">BooksCorpus dataset</a>, and the model has 12 layers with H<sub>model</sub> = 768, same as BERT<sub>base</sub>. Although the transformer encoder has one layer less than the decoder, GPT and BERT's numbers of parameters are still at the same level. Yet BERT has a 3 times larger BERT<sub>large</sub> model than the base. Because in addition to the BookCorpus dataset, BERT uses one more dataset for pre-training, in total the dataset is 4 times larger than GPT's.</p>\n<blockquote>\n<p>For the pre-training corpus we use the <a href=\"https://paperswithcode.com/dataset/bookcorpus\">BooksCorpus</a> (800M words) (Zhu et al., 2015) and <a href=\"https://en.wikipedia.org/wiki/Wikipedia:Database_download\">English Wikipedia</a> (2,500M words).</p>\n</blockquote>\n<p>And unfortunately, the average accuracy of BERT<sub>base</sub> is higher than GPT at this time. Besides with the BERT<sub>large</sub> model , the accuracy can go higher, as shown below in BERT's paper.</p>\n<p><img src=\"BERT result with GPT.png\" srcset=\"/img/loading.gif\" lazyload alt=\"BERT result with GPT\" style=\"zoom:50%;\" /></p>\n<h2 id=\"gpt-2\">GPT-2</h2>\n<p>After GPT-1 got defeated by BERT in 4 months, of course, GPT-2 aims to fight back and beat BERT to the ground. Considering the decoder path can't shift to the encoder with dignity, the simplest way then is to enlarge the model and the dataset. But what if it's still not working?</p>\n<h3 id=\"abstract-1\">Abstract</h3>\n<p>After developing a new dataset of millions of webpages called WebText, and training on a new1.5B parameter model. The result turns out to be no significant difference with BERT. So they bring out another sell point, zero shot.</p>\n<p>Actually, the zero-shot behaviour is mentioned in the last section of GPT-1's paper in order to understand more of the unsupervised pre-training mechanism. And in GPT-2, this behaviour is brought front to increase the novelty.</p>\n<h3 id=\"introduction-1\">Introduction</h3>\n<blockquote>\n<p><strong>Zero-shot learning</strong> (ZSL) is a problem setup in <a href=\"https://en.wikipedia.org/wiki/Machine_learning\">machine learning</a>, where at test time, a learner observes samples from classes, which were not observed during <a href=\"https://en.wikipedia.org/wiki/Machine_learning#Training_models\">training</a>, and needs to predict the class that they belong to. Zero-shot methods generally work by associating observed and non-observed classes through some form of auxiliary information, which encodes observable distinguishing properties of objects.[<a href=\"https://en.wikipedia.org/wiki/Zero-shot_learning#cite_note-1\">1]</a></p>\n</blockquote>\n<p>The main-steam approach is one dataset - one task instead of one dataset - multiple tasks because of the generalisation that state of art models lack. Yet multitask learning (trending 2000-2010) represents the idea of training one model with a combination of multiple datasets and different loss functions. So GPT-2 takes the idea of multitask learning and trains the model with the zero-shot setting, under which the downstream tasks can be handled with no collecting of supervised data or fine-tuning. The result is competitive and promising according to the authors.</p>\n<h3 id=\"approach\">Approach</h3>\n<p>The model architectures of GPT1 and GPT2 are pretty much the same. But the input methods are different.</p>\n<p>In detail, recalling that during fine tuning process, the GPT1 introduces extra tokens such as [start], [Delim] and [Extract] to modify the input. But in GPT2 without the supervised fine-tuning process, these extra tokens would cause confusion. As a result, the downstream task input need to be more likely to the natural language when constructing.</p>\n<p>As a result, the authors introduce what we are used to calling it \"prompt\", here are the examples:</p>\n<blockquote>\n<p>For example, a translation training example can be written as the sequence (<strong>translate to french</strong>, english text, french text). Likewise, a reading comprehension training example can be written as (<strong>answer the question</strong>, document, question, answer).</p>\n</blockquote>\n<p>And afterward, 2 ideas for why this would work are discussed. First, if the model is powerful enough, it might be capable of understanding the prompts. Second, in such a big dataset, this kind of data structure exists. Take machine translation as an example, there should be many sentences containing \"translate to French\", English text, and French text. The authors point out some of them below.</p>\n<table>\n<colgroup>\n<col style=\"width: 100%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Examples of machine translation</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">Im not the cleverest man in the world, but like they say in French: Je ne suis pas un imbecile [Im not a fool]. <br /><br />In a now-deleted post from Aug. 16, Soheil Eid, Tory candidate in the riding of Joliette, wrote in French: Mentez mentez, il en restera toujours quelque chose, which translates as, Lie lie and something will always remain.<br /><br />I hate the word perfume, Burr says. Its somewhat better in French: parfum.<br /><br />If listened carefully at 29:55, a conversation can be heard between two guys in French: -Comment on fait pour aller de lautre cot? -Quel autre cot?, which means - How do you get to the other side? - What side?. <br /><br />If this sounds like a bit of a stretch, consider this question in French: As-tu aller au cinma?, or Did you go to the movies?, which literally translates as Have-you to go to movies/theater? <br /><br />Brevet Sans Garantie Du Gouvernement, translated to English: Patented without government warranty.</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"training-data\"><strong>Training data</strong></h4>\n<p>After considering the need for larger data and the disadvantage(noise) of the existing dataset, they developed a new dataset. The data is collected by first crawling 45 million links discussed on Reddit, and then extracting all the contents of these pages. The dataset contains 8 million documents, 40 GB of text.</p>\n<h3 id=\"experiment\">Experiment</h3>\n<p>With 4 level of model, the one-short performances on 4 downstream tasks are shown blow:</p>\n<p><img src=\"GPT2 performance.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT2 performance\" style=\"zoom:50%;\" /></p>\n<p>It can be seen that first 3 tasks, the results are not the best yet not the worst, however, the performance on Question Answering is bad, and other works perform way better than GPT-2.</p>\n<p>But this is not over, because in the figure, there is still room for performance improvement on all 4 tasks as the size of the larger model increases. So here comes GPT-3.</p>\n<h2 id=\"gpt-3\">GPT-3</h2>\n<p>The value of an article depends on the topic, effectiveness and novelty. GPT-2 has rather low effectiveness but strong novelty. As a result, GPT-3 aims to promote the effectiveness of its predecessor, while loosing the zero-shot condition to few-shot condition.</p>\n<h3 id=\"abstract-2\">Abstract</h3>\n<p>The parameters of GPT-3 are enlarged 10 times to 175 billion. When applying GPT-3 to downstream tasks, strong performance is achieved without gradient update or fine-tuning. Besides, GPT-3 is capable of generating articles that are indistinguishable from humans' work.</p>\n<p>Besides, unlikely to former papers, this is a 63-page technic report. Without limitation of words or page number, it is very detailed, especially for the experiment and discussion sections.</p>\n<h3 id=\"introduction-2\">Introduction</h3>\n<p>There are 3 problems of current pre-training + fine-tuning language model:</p>\n<ul>\n<li>A large labeled dataset is still needed for a good result</li>\n<li>The pre-training model is not really generalisable because of the need for fine-tuning</li>\n<li>Human doesn't need large fine tuning dataset</li>\n</ul>\n<p>When introducing their work, the authors try to re-define the concept of \"meta-learning\" and \"in-context learning\". What they really mean are training a huge generalisable model and train without updating the gradient, respectively.</p>\n<p>Then 3 evaluation methods are presented:</p>\n<ul>\n<li><p>Few-shot learning: 10-100 task-related data</p></li>\n<li><p>One-shot learning</p></li>\n<li><p>Zero-short learning</p></li>\n</ul>\n<p>And the performance with model size is plotted below (1.3B matches the GPT-2 model). Can be seen the final accuracy (few shot - 175B) almost doubled the former GPT-2 accuracy (1.3B zero-short)</p>\n<p><img src=\"GPT3 performance.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT3 performance\" style=\"zoom:50%;\" /></p>\n<h3 id=\"approach-1\">Approach</h3>\n<p>In this section, fine-tuning, few-shot, one-shot, zero-shot learning are explained first in this figure below:</p>\n<p><img src=\"GPT-3 approach.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT-3 approach\" style=\"zoom:50%;\" /></p>\n<p>The right column denotes the traditional fine-tuning process that requires extra few gradient update steps. The left side shows how GPT-3 applies \"in-context learning\" during inference. Basically, the input is divided by 3 parts, task description, example, and prompt. The task description and prompt are ended by \":\", and \"=&gt;\" respectively. The Transformer Decoder extracts the features of the \"context\" and then predicts the next several words starting from the prompt. As a result, the model is able to infer without gradient updates. Yet it comes 2 problems with few-shot:</p>\n<ul>\n<li>Unable to process really long examples. For example, thousands of English-French translation dataset is easy to get access but they can rarely be leveraged to promote the model performance.</li>\n<li>The inference is one-time thing, meaning the model can't actually learn from previous task description or example. Same samples have to be inputed again an again.</li>\n</ul>\n<p>As a result, the few-shot learning is not commonly used.</p>\n<h4 id=\"model-and-architectures\">Model and Architectures</h4>\n<p>GPT-3 uses the same architecture as GPT-2 yet uses the methods form \"<a href=\"https://arxiv.org/abs/1904.10509\">Sparse Transformer</a>\" to modify the layers. And 8 different size of models are developed.</p>\n<p><img src=\"GPT3 models.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT3 models\" style=\"zoom:60%;\" /></p>\n<p>Yet compared with previous models, GPT-3 is \"fatter\" ,meaning with same <em>d<sub>model</sub></em> (192x of GPT3<sub>small</sub>), <em>n<sub>layers</sub></em> is smaller (only 8x of GPT3<sub>small</sub>).</p>\n<p>The mini-batch size goes up to 3.2M, definitely not mini. Large batch size improves the computational performance and parallelism while reducing the noise in each batch and making the model easier to overfitting. However, this defect is not evident in GPT-3. It is still an open question, now people consider it from two aspects: (1) the internal structure prevents the model from overfitting. (2) Such a large model is able to search for large space and it is more prone to converge to a simpler architecture.</p>\n<p>The learning rate decreases with batch size increasing according to <a href=\"https://arxiv.org/abs/2001.08361\">research1</a> and <a href=\"https://arxiv.org/abs/1812.06162\">research2</a>, also counter-intuitive. <a href=\"https://arxiv.org/abs/1706.02677\">Former work</a> shows that batch size should increase linear with the learning rate.</p>\n<h4 id=\"training-dataset\">Training Dataset</h4>\n<p>With a huge model, <a href=\"https://commoncrawl.org/\">Common Craw dataset</a> has come back as an option. The authors clean this dataset in 3 steps:</p>\n<ul>\n<li>A logistic classification model is built, taking samples of Common Craw dataset as negative and WebText as positive. Such model is used on the whole dataset of Common Craw to predict positive (high quality) or negative. The positive stay and the negative are filtered.</li>\n<li><a href=\"https://www.pinecone.io/learn/locality-sensitive-hashing/\">LSH algorithm</a> is applied on the remaining dataset to filter the similar content.</li>\n<li>More \"clean\" datasets are mixed in with weight.</li>\n</ul>\n<p><img src=\"GPT3 training data.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT3 training data\" style=\"zoom:50%;\" /></p>\n<h4 id=\"training-process\">Training Process</h4>\n<p>Specific training details are not presented. Information so far is <a href=\"https://www.nvidia.com/en-us/data-center/dgx-1/\">DGX-1 cluster</a> is used.</p>\n<h3 id=\"results\">Results</h3>\n<p>The results are too many so only interesting figures are covered.</p>\n<p><img src=\"GPT3 performance with compute.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT3 performance with compute\" style=\"zoom:50%;\" /></p>\n<p>From the figure, the power law distribution of performance with compute are found, i.e. in order to decrease the validation loss linearly, the FLOPS need to increase exponentially. This still is a major problem in Machine Learning.</p>\n<p><img src=\"GPT3 result.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT3 result\" style=\"zoom:50%;\" /></p>\n<p>This figure shows the compression of results with Zero-shot SOTO and human. Nothing to comment. Just ... good.</p>\n<p><img src=\"GPT-3 result 2.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT-3 result 2\" style=\"zoom:50%;\" />And on the Open-Domain QA tasks, GPT-3 outperform other models such as google T5. Google T5 can be considered as a model with both encoder and decoder.</p>\n<p><img src=\"GPT3 result 3.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT3 result 3\" style=\"zoom:50%;\" /></p>\n<p>And few shot learning outperform SOTO fine tuning models.</p>\n<p><img src=\"GPT3 result4.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT3 result4\" style=\"zoom:50%;\" /></p>\n<p>In the machine translation task, it is interesting to see that other language to English is better than English to others.</p>\n<p><img src=\"GPT 3 result 5.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT 3 result 5\" style=\"zoom:50%;\" /></p>\n<p>Then a news article is generated with GPT-3 with numbers, years and time that makes the article look legit.</p>\n<h3 id=\"limitations\">Limitations</h3>\n<ul>\n<li>Text synthesis, the predicted texts are always looping.</li>\n<li>The bidirectional limit still exist because of the decoder structure.</li>\n<li>The tokens that learned by GPT3 are equally weighted, yet wasting the model on the meaningless but high frequent function words.</li>\n<li>No experience in Videos or real-world physical interaction.</li>\n<li>The interpretation is still low. It's nearly impossible to know how does such a big model works.</li>\n</ul>\n<h3 id=\"broader-impact\">Broader Impact</h3>\n<ul>\n<li>Can be used for fraud and crimes</li>\n<li>Gender difference and race</li>\n<li>Energy consuming</li>\n</ul>\n<p><img src=\"GPT3 gender.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT3 gender\" style=\"zoom:50%;\" /></p>\n<p><img src=\"GPT3 race.png\" srcset=\"/img/loading.gif\" lazyload alt=\"GPT3 race\" style=\"zoom:50%;\" /></p>\n<h2 id=\"reference\">Reference</h2>\n<p><a href=\"\">Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. <em>arXiv preprint arXiv:2010.11929</em>.</a></p>\n<p><a href=\"http://proceedings.mlr.press/v139/radford21a\">Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... &amp; Sutskever, I. (2021, July). Learning transferable visual models from natural language supervision. In <em>International Conference on Machine Learning</em> (pp. 8748-8763). PMLR.</a></p>\n<p><a href=\"https://arxiv.org/abs/2111.06377\">He, K., Chen, X., Xie, S., Li, Y., Dollr, P., &amp; Girshick, R. (2021). Masked autoencoders are scalable vision learners. <em>arXiv preprint arXiv:2111.06377</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/1904.10509\">Child, R., Gray, S., Radford, A., &amp; Sutskever, I. (2019). Generating long sequences with sparse transformers. <em>arXiv preprint arXiv:1904.10509</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/2001.08361\">Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., ... &amp; Amodei, D. (2020). Scaling laws for neural language models. <em>arXiv preprint arXiv:2001.08361</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/1812.06162\">McCandlish, S., Kaplan, J., Amodei, D., &amp; Team, O. D. (2018). An empirical model of large-batch training. <em>arXiv preprint arXiv:1812.06162</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/1706.02677\">Goyal, P., Dollr, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., ... &amp; He, K. (2017). Accurate, large minibatch sgd: Training imagenet in 1 hour. <em>arXiv preprint arXiv:1706.02677</em>.</a></p>\n","site":{"data":{}},"wordcount":15968,"excerpt":"<blockquote>\n<p>GPT-3 is the most popular generative language model now. With more than 100 billion parameters, the performance is proved to be great and by now there are more than hundreds of works (commercial or academic) built on it, including the famous <a href=\"https://copilot.github.com/\">GitHub Copilot</a>.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a> hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>","more":"<p>Paper links:</p>\n<p>GPT-1: <a href=\"https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf\">Improving language understanding by generative pre-training</a></p>\n<p>GPT-2: <a href=\"http://www.persagen.com/files/misc/radford2019language.pdf\">Language models are unsupervised multitask learners</a></p>\n<p>GPT-3: <a href=\"https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html\">Language models are few-shot learners</a></p>\n<p>Useful links:</p>\n<p>https://www.bilibili.com/video/BV1AF411b7xQ/</p>\n<p><a href=\"https://gpt3demo.com/\">GPT-3 Demo: 300+ GPT-3 Examples, Demos, Apps</a></p>\n<p><a href=\"https://towardsdatascience.com/gpt-3-demos-use-cases-implications-77f86e540dc1\">GPT-3: Demos, Use-cases, Implications</a></p>\n<p><em>Since my own interest is not NLP, I haven't read these paper by myself. Instead, I follow a reference video above directly and make notes together with it.</em></p>\n<h2 id=\"history-and-timeline\">History and Timeline</h2>\n<p><img src=\"GPT timeline.png\" alt=\"GPT timeline\" style=\"zoom:50%;\" /></p>\n<p>Given that the GPT series are all developed by the <a href=\"https://openai.com/\">OpenAI</a> and the Transformer &amp; Bert are developed by Google, it seems there are two companies combating. And it is inevitable to compare these two series.</p>\n<p>From the perspective of number of cites, it is obviously that OpenAI have catch less attention from the academic world despite the huge cost. But it's not because GPT series are less novel, but because the goal of GPT series is bigger than that of Transformer &amp; Bert. Transformer is originally developed for Machine Translation task only. And Bert simply aims to push the pre-training technic forward. That's the reason why Bert performs better than GPT if the number of parameters are the same. As a result, GPT is harder and more expensive to train a decent model. And the size of model make others hardly to reconstruct it. From the companies' perspective, OpenAI does this because they want to build the strong AI, but Transformer &amp; Bert are developed only by the teams of Google.</p>\n<h2 id=\"gpt-1\">GPT-1</h2>\n<h3 id=\"abstract\">Abstract</h3>\n<p>The whole idea is similar to what CV did in the last several decades, that is pre-training of a model on a massive dataset followed by fine-tuning on a small specialist dataset. Lacking of large labelled data such as ImageNet of 10 million, however, NLP can't do what CV does exactly. The scale of machine translation database might reach 10 million but one piece of image possesses almost 10 times of information than a sentence. So the database is still not big enough.</p>\n<p>GPT makes a big step by using unlabelled data for pre-training. And then aero shot on GPT-2 makes another big step. It is fair to say CV led the trend of deep learning in the first 5 years, but recent years, more new thoughts are coming from the NLP field. And these new thoughts have inspired the CV field as well such as <a href=\"https://arxiv.org/abs/2010.11929\">ViT</a>, <a href=\"http://proceedings.mlr.press/v139/radford21a\">CLIP</a> and <a href=\"https://arxiv.org/abs/2111.06377\">MAE</a>.</p>\n<p>Besides, actually it had been a long time since NLP started to use unsupervised pre-training back then. For example, the word embedding model had been used for decades. But, the word embedding can only be seen as a layer, extra layers of model need to be designed to suit for various tasks. With GPT, however, the architecture doesn't need much change, only adjusting the input to suit the tasks is ok.</p>\n<p>The result is good but not as good as BERT, but the novelty of this paper is much better than BERT.</p>\n<h3 id=\"introduction\">Introduction</h3>\n<p>After briefly introducing the word embedding, problems of pre-training more than word-level data are presented. For example the type of optimisation objectives and how to transfer the extracted information to the tasks. The main reason of this problem is the variety of NLP tasks. There is no way to suit all the needs together.</p>\n<p>Then this paper introduces a semi-supervised method which has been explained many times. But actually GPT and BERT are normally called self-supervised model. Though they are the same to me. Semi-supervised learning is a common concept in the Machine Learning. It refers learning from a mix of massive unlabelled data and a few labelled data.</p>\n<p>Then the architecture is described. Interestingly, in order to list the reason of choosing transformer over RNN as backbone. The authors say</p>\n<blockquote>\n<p>This model choice provides us with a more structured memory for handling long-term dependencies in text, compared to alternatives like recurrent networks, resulting in robust transfer performance across diverse tasks.</p>\n</blockquote>\n<p>Besides, the paper accents the task-specific input adaptions, which is the key of this paper.</p>\n<h3 id=\"framework\">Framework</h3>\n<h4 id=\"unsupervised-learning\">Unsupervised learning</h4>\n<p>GPT uses a task that giving the data of u<sub>n-k</sub> to u<sub>n-1</sub> to predict the u<sub>n</sub>. So the likelihood function to be maximised is:</p>\n<p><span class=\"math display\">\\[\nL_{1}(\\mathcal{U})=\\sum_{i} \\log P\\left(u_{i} \\mid u_{i-k}, \\ldots, u_{i-1} ; \\Theta\\right)\n\\]</span> Because the predicting task, the mechanism of the mask multi-head attention of transformer decoder matches the likelihood function perfectly. Because in the first layer of the transformer decoder, the data after u{i} are simply masked to be 0.</p>\n<p>And the whole pre-training process is like this:</p>\n<p><span class=\"math display\">\\[\n\\begin{aligned}\nh_{0} &amp;=U W_{e}+W_{p} \\\\\nh_{l} &amp;=\\operatorname{transformer}\\_\\operatorname{block}\\left(h_{l-1}\\right) \\forall i \\in[1, n] \\\\\nP(u) &amp;=\\operatorname{softmax}\\left(h_{n} W_{e}^{T}\\right)\n\\end{aligned}\n\\]</span> Compared with BERT, the biggest difference is never encoder or decoder, bidirectional or one-way along. The key is the pre-training task they choose, the completion task that Bert use is much easier than GPT's prediction task. Because this is the <strong>difference between interpolation and extrapolation</strong>. Therefore, BERT outperforms GPT on the same number of parameters. But the potential of the GPT series goes far beyond BERT. As a result, it took OpenAI years to develop such an impressive GPT-3 model. On another side, however, GPT's prediction task leads to a different architecture with BERT. And the decoder architecture makes the GPT model hard to be bidirectional from the start. We'll see how it conquer this.</p>\n<h4 id=\"supervised-fine-tuning\">Supervised fine-tuning</h4>\n<p>The fine-tuning task follows the standard supervise learning process as follows:</p>\n<p><span class=\"math display\">\\[\nL_{2}(\\mathcal{C})=\\sum_{(x, y)} \\log P\\left(y \\mid x^{1}, \\ldots, x^{m}\\right)\n\\]</span> with <span class=\"math display\">\\[\nP\\left(y \\mid x^{1}, \\ldots, x^{m}\\right)=\\operatorname{softmax}\\left(h_{l}^{m} W_{y}\\right)\n\\]</span> And the authors find it helpful to optimise the L1 and L2 together as:</p>\n<p><span class=\"math display\">\\[\nL_{3}(\\mathcal{C})=L_{2}(\\mathcal{C})+\\lambda * L_{1}(\\mathcal{C})\n\\]</span></p>\n<h4 id=\"task-specific-input-transformations\">Task-specific input transformations</h4>\n<p>The last thing to do is how to apply this framework to different tasks. Similar to with BERT, the pre-trained transformer block doesn't have to be changed.</p>\n<p><img src=\"GPT objectives.png\" alt=\"GPT objectives\" style=\"zoom:40%;\" /></p>\n<h3 id=\"experiments\">Experiments</h3>\n<p>The dataset GPT trained on is <a href=\"https://paperswithcode.com/dataset/bookcorpus\">BooksCorpus dataset</a>, and the model has 12 layers with H<sub>model</sub> = 768, same as BERT<sub>base</sub>. Although the transformer encoder has one layer less than the decoder, GPT and BERT's numbers of parameters are still at the same level. Yet BERT has a 3 times larger BERT<sub>large</sub> model than the base. Because in addition to the BookCorpus dataset, BERT uses one more dataset for pre-training, in total the dataset is 4 times larger than GPT's.</p>\n<blockquote>\n<p>For the pre-training corpus we use the <a href=\"https://paperswithcode.com/dataset/bookcorpus\">BooksCorpus</a> (800M words) (Zhu et al., 2015) and <a href=\"https://en.wikipedia.org/wiki/Wikipedia:Database_download\">English Wikipedia</a> (2,500M words).</p>\n</blockquote>\n<p>And unfortunately, the average accuracy of BERT<sub>base</sub> is higher than GPT at this time. Besides with the BERT<sub>large</sub> model , the accuracy can go higher, as shown below in BERT's paper.</p>\n<p><img src=\"BERT result with GPT.png\" alt=\"BERT result with GPT\" style=\"zoom:50%;\" /></p>\n<h2 id=\"gpt-2\">GPT-2</h2>\n<p>After GPT-1 got defeated by BERT in 4 months, of course, GPT-2 aims to fight back and beat BERT to the ground. Considering the decoder path can't shift to the encoder with dignity, the simplest way then is to enlarge the model and the dataset. But what if it's still not working?</p>\n<h3 id=\"abstract-1\">Abstract</h3>\n<p>After developing a new dataset of millions of webpages called WebText, and training on a new1.5B parameter model. The result turns out to be no significant difference with BERT. So they bring out another sell point, zero shot.</p>\n<p>Actually, the zero-shot behaviour is mentioned in the last section of GPT-1's paper in order to understand more of the unsupervised pre-training mechanism. And in GPT-2, this behaviour is brought front to increase the novelty.</p>\n<h3 id=\"introduction-1\">Introduction</h3>\n<blockquote>\n<p><strong>Zero-shot learning</strong> (ZSL) is a problem setup in <a href=\"https://en.wikipedia.org/wiki/Machine_learning\">machine learning</a>, where at test time, a learner observes samples from classes, which were not observed during <a href=\"https://en.wikipedia.org/wiki/Machine_learning#Training_models\">training</a>, and needs to predict the class that they belong to. Zero-shot methods generally work by associating observed and non-observed classes through some form of auxiliary information, which encodes observable distinguishing properties of objects.[<a href=\"https://en.wikipedia.org/wiki/Zero-shot_learning#cite_note-1\">1]</a></p>\n</blockquote>\n<p>The main-steam approach is one dataset - one task instead of one dataset - multiple tasks because of the generalisation that state of art models lack. Yet multitask learning (trending 2000-2010) represents the idea of training one model with a combination of multiple datasets and different loss functions. So GPT-2 takes the idea of multitask learning and trains the model with the zero-shot setting, under which the downstream tasks can be handled with no collecting of supervised data or fine-tuning. The result is competitive and promising according to the authors.</p>\n<h3 id=\"approach\">Approach</h3>\n<p>The model architectures of GPT1 and GPT2 are pretty much the same. But the input methods are different.</p>\n<p>In detail, recalling that during fine tuning process, the GPT1 introduces extra tokens such as [start], [Delim] and [Extract] to modify the input. But in GPT2 without the supervised fine-tuning process, these extra tokens would cause confusion. As a result, the downstream task input need to be more likely to the natural language when constructing.</p>\n<p>As a result, the authors introduce what we are used to calling it \"prompt\", here are the examples:</p>\n<blockquote>\n<p>For example, a translation training example can be written as the sequence (<strong>translate to french</strong>, english text, french text). Likewise, a reading comprehension training example can be written as (<strong>answer the question</strong>, document, question, answer).</p>\n</blockquote>\n<p>And afterward, 2 ideas for why this would work are discussed. First, if the model is powerful enough, it might be capable of understanding the prompts. Second, in such a big dataset, this kind of data structure exists. Take machine translation as an example, there should be many sentences containing \"translate to French\", English text, and French text. The authors point out some of them below.</p>\n<table>\n<colgroup>\n<col style=\"width: 100%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">Examples of machine translation</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">Im not the cleverest man in the world, but like they say in French: Je ne suis pas un imbecile [Im not a fool]. <br /><br />In a now-deleted post from Aug. 16, Soheil Eid, Tory candidate in the riding of Joliette, wrote in French: Mentez mentez, il en restera toujours quelque chose, which translates as, Lie lie and something will always remain.<br /><br />I hate the word perfume, Burr says. Its somewhat better in French: parfum.<br /><br />If listened carefully at 29:55, a conversation can be heard between two guys in French: -Comment on fait pour aller de lautre cot? -Quel autre cot?, which means - How do you get to the other side? - What side?. <br /><br />If this sounds like a bit of a stretch, consider this question in French: As-tu aller au cinma?, or Did you go to the movies?, which literally translates as Have-you to go to movies/theater? <br /><br />Brevet Sans Garantie Du Gouvernement, translated to English: Patented without government warranty.</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"training-data\"><strong>Training data</strong></h4>\n<p>After considering the need for larger data and the disadvantage(noise) of the existing dataset, they developed a new dataset. The data is collected by first crawling 45 million links discussed on Reddit, and then extracting all the contents of these pages. The dataset contains 8 million documents, 40 GB of text.</p>\n<h3 id=\"experiment\">Experiment</h3>\n<p>With 4 level of model, the one-short performances on 4 downstream tasks are shown blow:</p>\n<p><img src=\"GPT2 performance.png\" alt=\"GPT2 performance\" style=\"zoom:50%;\" /></p>\n<p>It can be seen that first 3 tasks, the results are not the best yet not the worst, however, the performance on Question Answering is bad, and other works perform way better than GPT-2.</p>\n<p>But this is not over, because in the figure, there is still room for performance improvement on all 4 tasks as the size of the larger model increases. So here comes GPT-3.</p>\n<h2 id=\"gpt-3\">GPT-3</h2>\n<p>The value of an article depends on the topic, effectiveness and novelty. GPT-2 has rather low effectiveness but strong novelty. As a result, GPT-3 aims to promote the effectiveness of its predecessor, while loosing the zero-shot condition to few-shot condition.</p>\n<h3 id=\"abstract-2\">Abstract</h3>\n<p>The parameters of GPT-3 are enlarged 10 times to 175 billion. When applying GPT-3 to downstream tasks, strong performance is achieved without gradient update or fine-tuning. Besides, GPT-3 is capable of generating articles that are indistinguishable from humans' work.</p>\n<p>Besides, unlikely to former papers, this is a 63-page technic report. Without limitation of words or page number, it is very detailed, especially for the experiment and discussion sections.</p>\n<h3 id=\"introduction-2\">Introduction</h3>\n<p>There are 3 problems of current pre-training + fine-tuning language model:</p>\n<ul>\n<li>A large labeled dataset is still needed for a good result</li>\n<li>The pre-training model is not really generalisable because of the need for fine-tuning</li>\n<li>Human doesn't need large fine tuning dataset</li>\n</ul>\n<p>When introducing their work, the authors try to re-define the concept of \"meta-learning\" and \"in-context learning\". What they really mean are training a huge generalisable model and train without updating the gradient, respectively.</p>\n<p>Then 3 evaluation methods are presented:</p>\n<ul>\n<li><p>Few-shot learning: 10-100 task-related data</p></li>\n<li><p>One-shot learning</p></li>\n<li><p>Zero-short learning</p></li>\n</ul>\n<p>And the performance with model size is plotted below (1.3B matches the GPT-2 model). Can be seen the final accuracy (few shot - 175B) almost doubled the former GPT-2 accuracy (1.3B zero-short)</p>\n<p><img src=\"GPT3 performance.png\" alt=\"GPT3 performance\" style=\"zoom:50%;\" /></p>\n<h3 id=\"approach-1\">Approach</h3>\n<p>In this section, fine-tuning, few-shot, one-shot, zero-shot learning are explained first in this figure below:</p>\n<p><img src=\"GPT-3 approach.png\" alt=\"GPT-3 approach\" style=\"zoom:50%;\" /></p>\n<p>The right column denotes the traditional fine-tuning process that requires extra few gradient update steps. The left side shows how GPT-3 applies \"in-context learning\" during inference. Basically, the input is divided by 3 parts, task description, example, and prompt. The task description and prompt are ended by \":\", and \"=&gt;\" respectively. The Transformer Decoder extracts the features of the \"context\" and then predicts the next several words starting from the prompt. As a result, the model is able to infer without gradient updates. Yet it comes 2 problems with few-shot:</p>\n<ul>\n<li>Unable to process really long examples. For example, thousands of English-French translation dataset is easy to get access but they can rarely be leveraged to promote the model performance.</li>\n<li>The inference is one-time thing, meaning the model can't actually learn from previous task description or example. Same samples have to be inputed again an again.</li>\n</ul>\n<p>As a result, the few-shot learning is not commonly used.</p>\n<h4 id=\"model-and-architectures\">Model and Architectures</h4>\n<p>GPT-3 uses the same architecture as GPT-2 yet uses the methods form \"<a href=\"https://arxiv.org/abs/1904.10509\">Sparse Transformer</a>\" to modify the layers. And 8 different size of models are developed.</p>\n<p><img src=\"GPT3 models.png\" alt=\"GPT3 models\" style=\"zoom:60%;\" /></p>\n<p>Yet compared with previous models, GPT-3 is \"fatter\" ,meaning with same <em>d<sub>model</sub></em> (192x of GPT3<sub>small</sub>), <em>n<sub>layers</sub></em> is smaller (only 8x of GPT3<sub>small</sub>).</p>\n<p>The mini-batch size goes up to 3.2M, definitely not mini. Large batch size improves the computational performance and parallelism while reducing the noise in each batch and making the model easier to overfitting. However, this defect is not evident in GPT-3. It is still an open question, now people consider it from two aspects: (1) the internal structure prevents the model from overfitting. (2) Such a large model is able to search for large space and it is more prone to converge to a simpler architecture.</p>\n<p>The learning rate decreases with batch size increasing according to <a href=\"https://arxiv.org/abs/2001.08361\">research1</a> and <a href=\"https://arxiv.org/abs/1812.06162\">research2</a>, also counter-intuitive. <a href=\"https://arxiv.org/abs/1706.02677\">Former work</a> shows that batch size should increase linear with the learning rate.</p>\n<h4 id=\"training-dataset\">Training Dataset</h4>\n<p>With a huge model, <a href=\"https://commoncrawl.org/\">Common Craw dataset</a> has come back as an option. The authors clean this dataset in 3 steps:</p>\n<ul>\n<li>A logistic classification model is built, taking samples of Common Craw dataset as negative and WebText as positive. Such model is used on the whole dataset of Common Craw to predict positive (high quality) or negative. The positive stay and the negative are filtered.</li>\n<li><a href=\"https://www.pinecone.io/learn/locality-sensitive-hashing/\">LSH algorithm</a> is applied on the remaining dataset to filter the similar content.</li>\n<li>More \"clean\" datasets are mixed in with weight.</li>\n</ul>\n<p><img src=\"GPT3 training data.png\" alt=\"GPT3 training data\" style=\"zoom:50%;\" /></p>\n<h4 id=\"training-process\">Training Process</h4>\n<p>Specific training details are not presented. Information so far is <a href=\"https://www.nvidia.com/en-us/data-center/dgx-1/\">DGX-1 cluster</a> is used.</p>\n<h3 id=\"results\">Results</h3>\n<p>The results are too many so only interesting figures are covered.</p>\n<p><img src=\"GPT3 performance with compute.png\" alt=\"GPT3 performance with compute\" style=\"zoom:50%;\" /></p>\n<p>From the figure, the power law distribution of performance with compute are found, i.e. in order to decrease the validation loss linearly, the FLOPS need to increase exponentially. This still is a major problem in Machine Learning.</p>\n<p><img src=\"GPT3 result.png\" alt=\"GPT3 result\" style=\"zoom:50%;\" /></p>\n<p>This figure shows the compression of results with Zero-shot SOTO and human. Nothing to comment. Just ... good.</p>\n<p><img src=\"GPT-3 result 2.png\" alt=\"GPT-3 result 2\" style=\"zoom:50%;\" />And on the Open-Domain QA tasks, GPT-3 outperform other models such as google T5. Google T5 can be considered as a model with both encoder and decoder.</p>\n<p><img src=\"GPT3 result 3.png\" alt=\"GPT3 result 3\" style=\"zoom:50%;\" /></p>\n<p>And few shot learning outperform SOTO fine tuning models.</p>\n<p><img src=\"GPT3 result4.png\" alt=\"GPT3 result4\" style=\"zoom:50%;\" /></p>\n<p>In the machine translation task, it is interesting to see that other language to English is better than English to others.</p>\n<p><img src=\"GPT 3 result 5.png\" alt=\"GPT 3 result 5\" style=\"zoom:50%;\" /></p>\n<p>Then a news article is generated with GPT-3 with numbers, years and time that makes the article look legit.</p>\n<h3 id=\"limitations\">Limitations</h3>\n<ul>\n<li>Text synthesis, the predicted texts are always looping.</li>\n<li>The bidirectional limit still exist because of the decoder structure.</li>\n<li>The tokens that learned by GPT3 are equally weighted, yet wasting the model on the meaningless but high frequent function words.</li>\n<li>No experience in Videos or real-world physical interaction.</li>\n<li>The interpretation is still low. It's nearly impossible to know how does such a big model works.</li>\n</ul>\n<h3 id=\"broader-impact\">Broader Impact</h3>\n<ul>\n<li>Can be used for fraud and crimes</li>\n<li>Gender difference and race</li>\n<li>Energy consuming</li>\n</ul>\n<p><img src=\"GPT3 gender.png\" alt=\"GPT3 gender\" style=\"zoom:50%;\" /></p>\n<p><img src=\"GPT3 race.png\" alt=\"GPT3 race\" style=\"zoom:50%;\" /></p>\n<h2 id=\"reference\">Reference</h2>\n<p><a href=\"\">Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. <em>arXiv preprint arXiv:2010.11929</em>.</a></p>\n<p><a href=\"http://proceedings.mlr.press/v139/radford21a\">Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... &amp; Sutskever, I. (2021, July). Learning transferable visual models from natural language supervision. In <em>International Conference on Machine Learning</em> (pp. 8748-8763). PMLR.</a></p>\n<p><a href=\"https://arxiv.org/abs/2111.06377\">He, K., Chen, X., Xie, S., Li, Y., Dollr, P., &amp; Girshick, R. (2021). Masked autoencoders are scalable vision learners. <em>arXiv preprint arXiv:2111.06377</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/1904.10509\">Child, R., Gray, S., Radford, A., &amp; Sutskever, I. (2019). Generating long sequences with sparse transformers. <em>arXiv preprint arXiv:1904.10509</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/2001.08361\">Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., ... &amp; Amodei, D. (2020). Scaling laws for neural language models. <em>arXiv preprint arXiv:2001.08361</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/1812.06162\">McCandlish, S., Kaplan, J., Amodei, D., &amp; Team, O. D. (2018). An empirical model of large-batch training. <em>arXiv preprint arXiv:1812.06162</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/1706.02677\">Goyal, P., Dollr, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., ... &amp; He, K. (2017). Accurate, large minibatch sgd: Training imagenet in 1 hour. <em>arXiv preprint arXiv:1706.02677</em>.</a></p>"},{"title":"Masked Autoencoder(MAE)","author":"Ryan LI","toc":true,"declare":true,"date":"2022-04-26T18:00:38.000Z","index_img":"/index/paper-reading-MAE.png","_content":"> Published in Dec 2021, this new work by Kaiming He draws a lot of attention from the community. The astounding result of unsupervised transfer learning and the capability of reconstructing highly masked (up to 90%) images might herald a new era in CV. \n\n<!-- more -->\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\nPaper: [Masked autoencoders are scalable vision learners](https://arxiv.org/abs/2111.06377)\n\nUseful link: https://www.bilibili.com/video/BV1sq4y1q77t/\n\n|                     | NLP              | CV         |\n| ------------------- | ---------------- | ---------- |\n| **Supervised**      | Transformer[^17] | ViT[^8]    |\n| **Self-supervised** | Bert[^1]         | <u>MAE</u> |\n\nInspired by Bert[^1] and ViT[^8], MAE shows the capability of unsupervised learning on CV. It's not the first work to expand Bert [^1] to CV, but it might be the most influential one. It might accelerate the application of transformer in CV, as Bert[^1] has done with NLP.\n\n## Notes\n\n### Title\n\nNote the title format, \"Something is a good fellow\", is same as the GPT[^2] series. It is a powerful format to include the distilled conclusion in the title.\n\n### Abstract\n\nThis paper proposes an asymmetric, transformer-based, denoising auto-encoder architecture. The unsupervised pre-training task is to reconstruct highly masked input images. The high masking ratio is the key. It reduces the pre-training time by 3 times and is able to train larger model efficiently, resulting in competitive reconstructing accuracy. The transfer performance is even better than the supervised pre-training models.\n\n### Key figures\n\nFirst, the reconstruction results are shown below. \n\n<img src=\"MAE result.png\" alt=\"MAE result 1\" style=\"zoom:90%;\" />\n\n<img src=\"MAE result2.png\" alt=\"MAE result2\" style=\"zoom:30%;\" />\n\nAlthough the details are vague, the reconstruction of the main content is astonishing. Note that maybe not all of the validation images turned out as good as this, but this result is still really surprising.\n\n### Conclusion\n\nThe model is said to be simple(false) and scaled well(as long as you are rich). The results show that MAE makes scaleable unsupervised pre-training in CV applicable, a similar route to that of NLP[^1][^2]. \n\nBesides, they claim the semantic difference between text and image leads to different masking operations. Furthermore, they mention that the patch masking operation does not separate semantic entities, meaning one masked patch may include more than one piece of semantic information, unlike language. As a result the reconstruction results show that the model manages to learn from complex semantics.\n\n### Introduction\n\nAlthough yielding excellent success in NLP, applying scalable unsupervised models in CV is still a challenging problem. But why? i.e. **what makes masked autoencoding different between vision and language? **3 reasons are discussed:\n\n- The architecture difference between convolution and transformer: it's hard to integrate masked embedding or positional embedding to the convolution layer (Actually positional embedding is not needed for convolutional layer) -- addressed by ViT[^8].\n\n- The information density difference between text and image: Unlike high-semantic text, natural signals in images possess heavy spatial redundancy -- addressed by masking a very high portion of random patches.\n- Decoder difference: in NLP, take BERT as an example, a simple linear projection is used as a decoder, while in vision, a simple decoder is not powerful enough to reconstruct the semantic level information -- addressed by substituting linear projection with transformer layers.\n\nThen, the idea of MAE is on the front door. The encoder processes only the unmasked patches, while the lightweight decoder reconstructs the whole image from the encoded latent representation and the [mask] tokens. With a very high masking ratio(e.g. 75%), the pre-training time can be reduced by 3 times.\n\nBesides, the data capacity and generalisation performance are great. SOTA accuracy is achieved with fine tuning on a medium-sized dataset (ViT-Huge model on ImageNet 1K).\n\nIn this section, the reason why designing such an architecture is well presented through Q&A, highly recommended. Sometimes, motive is an important factor in distinguishing a paper from a technical report.\n\n### Relate work\n\nWorks in 4 areas are briefly reviewed. \n\n{% markmap 300px %}\n\n- **Masked language modelling:**\n\n  - BERT[^1]\n\n  - GPT[^2]\n- **Auto-encoding:** \n\n  - classic autoencoders[^3] : PCA, k-means \n\n  - denoising autoencoders(DAE)[^4]\n- **Masked image encoding:** \n\n\t- classic\n\t\t- pioneer work SDAE[^5]\n\t\t-  context encoder[^6]\n\n\t- transformer based: \n\t\t- iGPT[^7]\n\t\t- ViT[^8]\n\t\t- BEiT[^9]\n- **Self-supervised learning:** \n  - CNN based: \n    - Unsupervised learning of visual representations using videos[^10]\n    - CFN[^11]\n    - Colorful Image Colorization[^12]\n    - Unsupervised representation learning by predicting image rotations[^13]\n  - Transformer based: \n    - ViT[^8]\n  - Contrastive learning based: \n    - Unsupervised feature learning via non-parametric instance discrimination[^14]\n    - Representation learning with contrastive predictive coding[^15]\n    - MOCO[^16]\n\n{%endmarkmap%}\n\nNote that BEiT[^9] is very similar to MAE, while BEiT[^9] projects each patch to a label and predict as Bert[^1], unlike projecting to pixels in MAE. Besides, the recently popular constructive methods [^14][^15][^16] relay on data augmentation heavily, while MAE does not.\n\n### Approach\n\nThe architecture and the training approach is briefly covered in the sketch below:\n\n<img src=\"MAE architecture.png\" alt=\"MAE architecture\" style=\"zoom:40%;\" />\n\nAdditional details about the architecture: For per-processing, non-overlapped patching and random uniform masking are adopted. The [mask] token is shared, and another position embedding is introduced to the decoder input so that the inputs are different on different masked area. But it is unclear whether the positional embedding is performed only on the [mask] token or on the whole input, i.e. encoded patches + [mask] token. Furthermore, the lightweight decoder has <10% computation per token compared with the encoder.\n\nReconstruction target: The decoder aims to recreate the pixels of masked patches. The loss function is the mean squared error (MSE) between the output and the original image, only on the masked region of course. Besides, a variation reconstructing the normalised pixels shows an improvement in representation quality.\n\nImplementation: The random masking step is applied by shuffling and dropping the last part. And un-shuffling is used before the decoder to reconstruct the position. In this way, no sparse operation is needed and the cost becomes really low.\n\n### ImageNet experiments\n\n#### Setup\n\nThe model is self-supervised pre-trained on the ImageNet-1K, then evaluated by 2 kinds of supervised training: (i) end-to-end fine-tuning and (ii) linear probing(only the last linear projection layer is allowed to update). ViT-Large (ViT-L/16)[^8] is used as baseline backbone.\n\nNote that they reproduce the full supervised experiments by ViT[^8] and get 8% higher accuracy. The trick is a strong regularisation(75%). May be it meets the previous theory of the semantic difference between picture and text.\n\n| Supervised, original[^8] | Supervised, their impl. | Self-supervised, Baseline |\n| :----------------------: | :---------------------: | :-----------------------: |\n|           76.5           |          82.5           |           84.9            |\n\n#### Ablation\n\nMost of the result are recoded clearly on the figures and tables below,\n\n<img src=\"MAE mask ratio.png\" alt=\"MAE mask ratio\" style=\"zoom:90%;\" />\n\n<img src=\"MAE ablation.png\" alt=\"MAE ablation\" style=\"zoom:90%;\" />\n\n Just add some details:\n\n- Best mask ratio is higher than BERT[^1] (15%) and iGPT[^7], ViT[^8]and BEiT[^9] (25%-50%)\n- The encoder manages to learn the semantic representations given that the semantic pieces are mixed in each input patches, different from  NLP\n- No saturation of linear probing accuracy is observed, indicating the overfitting is not severer even at epoch 1600\n- One explanation for (a): a reasonably deep decoder can account for the reconstruction specialisation, leaving the encoder to extract a more abstract latent representation.\n- One explanation for (c): current architecture only process known patches, the introducing of unknown [mask] token would result in a gap between the pre-train task and inference task.\n- Result of (d) indicates that high-frequency components are useful in MAE. And the dVAE token case is actually what BEiT[^9] does, projecting each patch to a single token.\n- Result of (e) distinguishes MAE from contrastive learning and related methods. In MAE, the random masking plays the main role of data augmentation.\n\n#### Comparison\n\n<img src=\"MAE comparison.png\" alt=\"MAE comparison\" style=\"zoom:100%;\" />\n\n- with unsupervised models: not only the accuracy is better, the pre-training time is shorter than the competitors as well\n- with supervised models: it indicates that MAE can help scale up model sizes. And the MAE performance on ImageNet1K is similar to the model trained on the 300 times bigger dataset JFT300M. But, considering the number of class of JFT300M is much more than ImageNet1K as well, the result is slightly unfair. \n\n#### Partial Fine-tuning\n\nIn addition to the full fine-tuning and 0 fine-tuning (linear probing), partial ones are applied by fine tuning fixing several layers. The result indicating at least the last 6 layers are task-related.\n\n<img src=\"MAE fine tune.png\" alt=\"Partial fine-tuning\" style=\"zoom:30%;\" />\n\n### Transfer learning experiments\n\nAt last, down steam tasks are evaluated compared with other frameworks.\n\n<img src=\"MAE segmentation.png\" alt=\"MAE segmentation\" style=\"zoom:60%;\" />\n\n<img src=\"MAE classification.png\" alt=\"MAE classification\" style=\"zoom:61%;\" />\n\n<img src=\"MAE pixels vs tokens.png\" alt=\"MAE pixels vs tokens\" style=\"zoom:62%;\" />\n\n## Review\n\nWriting, simple but has a very good storyline. From the full introduction of the motivation, to the detailed clear figures explaining each part of the design.\n\nThe algorithm is simple, just applying self-supervised learning to CV based on ViT[^8]. 2 key points are introduced:\n\n- More patches need to be masked\n- Transformer decoder to reproduce the pixels instead of a simple linear layer projecting patches into tokens.\n\nIn conclusion, a simple idea, a great result and detailed experiments make this paper a great work. \n\n## Reference\n\n[^1]:[Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. *arXiv preprint arXiv:1810.04805*.](https://arxiv.org/abs/1810.04805)\n[^2]: [Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language understanding by generative pre-training.](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf)\n[^3]: [Hinton, G. E., & Zemel, R. (1993). Autoencoders, minimum description length and Helmholtz free energy. *Advances in neural information processing systems*, *6*.](https://proceedings.neurips.cc/paper/1993/hash/9e3cfc48eccf81a0d57663e129aef3cb-Abstract.html)\n[^4]: [Vincent, P., Larochelle, H., Bengio, Y., & Manzagol, P. A. (2008, July). Extracting and composing robust features with denoising autoencoders. In *Proceedings of the 25th international conference on Machine learning* (pp. 1096-1103).](https://dl.acm.org/doi/abs/10.1145/1390156.1390294)\n[^5]: [Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P. A., & Bottou, L. (2010). Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. *Journal of machine learning research*, *11*(12).](https://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf?ref=https://githubhelp.com)\n[^6]:[Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., & Efros, A. A. (2016). Context encoders: Feature learning by inpainting. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 2536-2544).](http://openaccess.thecvf.com/content_cvpr_2016/html/Pathak_Context_Encoders_Feature_CVPR_2016_paper.html)\n[^7]:[Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., & Sutskever, I. (2020, November). Generative pretraining from pixels. In *International Conference on Machine Learning* (pp. 1691-1703). PMLR.](http://proceedings.mlr.press/v119/chen20s.html)\n[^8]:[Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. *arXiv preprint arXiv:2010.11929*.](https://arxiv.org/abs/2010.11929)\n[^9]: [Bao, H., Dong, L., & Wei, F. (2021). Beit: Bert pre-training of image transformers. *arXiv preprint arXiv:2106.08254*.](https://arxiv.org/abs/2106.08254)\n[^10]: [Wang, X., & Gupta, A. (2015). Unsupervised learning of visual representations using videos. In *Proceedings of the IEEE international conference on computer vision* (pp. 2794-2802).](http://openaccess.thecvf.com/content_iccv_2015/html/Wang_Unsupervised_Learning_of_ICCV_2015_paper.html)\n[^11]: [Noroozi, M., & Favaro, P. (2016, October). Unsupervised learning of visual representations by solving jigsaw puzzles. In *European conference on computer vision* (pp. 69-84). Springer, Cham.](https://link.springer.com/chapter/10.1007/978-3-319-46466-4_5)\n[^12]: [Zhang, R., Isola, P., & Efros, A. A. (2016, October). Colorful image colorization. In *European conference on computer vision* (pp. 649-666). Springer, Cham.](https://link.springer.com/chapter/10.1007/978-3-319-46487-9_40)\n[^13]: [Gidaris, S., Singh, P., & Komodakis, N. (2018). Unsupervised representation learning by predicting image rotations. *arXiv preprint arXiv:1803.07728*.](https://arxiv.org/abs/1803.07728)\n[^14]: [Wu, Z., Xiong, Y., Yu, S. X., & Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 3733-3742).](http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html)\n[^15]: [Oord, A. V. D., Li, Y., & Vinyals, O. (2018). Representation learning with contrastive predictive coding. *arXiv preprint arXiv:1807.03748*.](https://arxiv.org/abs/1807.03748)\n[^16]: [He, K., Fan, H., Wu, Y., Xie, S., & Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition* (pp. 9729-9738).](http://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html)\n[^17]: [Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. *Advances in neural information processing systems*, *30*.](https://arxiv.org/abs/1706.03762)\n\n","source":"_posts/paper-reading-MAE.md","raw":"---\ntitle: 'Masked Autoencoder(MAE)'\nauthor: Ryan LI\ntoc: true\ndeclare: true\ndate: 2022-04-27 02:00:38\nindex_img: /index/paper-reading-MAE.png\ntags:\n  - paper reading\n  - deep learning\n---\n> Published in Dec 2021, this new work by Kaiming He draws a lot of attention from the community. The astounding result of unsupervised transfer learning and the capability of reconstructing highly masked (up to 90%) images might herald a new era in CV. \n\n<!-- more -->\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\nPaper: [Masked autoencoders are scalable vision learners](https://arxiv.org/abs/2111.06377)\n\nUseful link: https://www.bilibili.com/video/BV1sq4y1q77t/\n\n|                     | NLP              | CV         |\n| ------------------- | ---------------- | ---------- |\n| **Supervised**      | Transformer[^17] | ViT[^8]    |\n| **Self-supervised** | Bert[^1]         | <u>MAE</u> |\n\nInspired by Bert[^1] and ViT[^8], MAE shows the capability of unsupervised learning on CV. It's not the first work to expand Bert [^1] to CV, but it might be the most influential one. It might accelerate the application of transformer in CV, as Bert[^1] has done with NLP.\n\n## Notes\n\n### Title\n\nNote the title format, \"Something is a good fellow\", is same as the GPT[^2] series. It is a powerful format to include the distilled conclusion in the title.\n\n### Abstract\n\nThis paper proposes an asymmetric, transformer-based, denoising auto-encoder architecture. The unsupervised pre-training task is to reconstruct highly masked input images. The high masking ratio is the key. It reduces the pre-training time by 3 times and is able to train larger model efficiently, resulting in competitive reconstructing accuracy. The transfer performance is even better than the supervised pre-training models.\n\n### Key figures\n\nFirst, the reconstruction results are shown below. \n\n<img src=\"MAE result.png\" alt=\"MAE result 1\" style=\"zoom:90%;\" />\n\n<img src=\"MAE result2.png\" alt=\"MAE result2\" style=\"zoom:30%;\" />\n\nAlthough the details are vague, the reconstruction of the main content is astonishing. Note that maybe not all of the validation images turned out as good as this, but this result is still really surprising.\n\n### Conclusion\n\nThe model is said to be simple(false) and scaled well(as long as you are rich). The results show that MAE makes scaleable unsupervised pre-training in CV applicable, a similar route to that of NLP[^1][^2]. \n\nBesides, they claim the semantic difference between text and image leads to different masking operations. Furthermore, they mention that the patch masking operation does not separate semantic entities, meaning one masked patch may include more than one piece of semantic information, unlike language. As a result the reconstruction results show that the model manages to learn from complex semantics.\n\n### Introduction\n\nAlthough yielding excellent success in NLP, applying scalable unsupervised models in CV is still a challenging problem. But why? i.e. **what makes masked autoencoding different between vision and language? **3 reasons are discussed:\n\n- The architecture difference between convolution and transformer: it's hard to integrate masked embedding or positional embedding to the convolution layer (Actually positional embedding is not needed for convolutional layer) -- addressed by ViT[^8].\n\n- The information density difference between text and image: Unlike high-semantic text, natural signals in images possess heavy spatial redundancy -- addressed by masking a very high portion of random patches.\n- Decoder difference: in NLP, take BERT as an example, a simple linear projection is used as a decoder, while in vision, a simple decoder is not powerful enough to reconstruct the semantic level information -- addressed by substituting linear projection with transformer layers.\n\nThen, the idea of MAE is on the front door. The encoder processes only the unmasked patches, while the lightweight decoder reconstructs the whole image from the encoded latent representation and the [mask] tokens. With a very high masking ratio(e.g. 75%), the pre-training time can be reduced by 3 times.\n\nBesides, the data capacity and generalisation performance are great. SOTA accuracy is achieved with fine tuning on a medium-sized dataset (ViT-Huge model on ImageNet 1K).\n\nIn this section, the reason why designing such an architecture is well presented through Q&A, highly recommended. Sometimes, motive is an important factor in distinguishing a paper from a technical report.\n\n### Relate work\n\nWorks in 4 areas are briefly reviewed. \n\n{% markmap 300px %}\n\n- **Masked language modelling:**\n\n  - BERT[^1]\n\n  - GPT[^2]\n- **Auto-encoding:** \n\n  - classic autoencoders[^3] : PCA, k-means \n\n  - denoising autoencoders(DAE)[^4]\n- **Masked image encoding:** \n\n\t- classic\n\t\t- pioneer work SDAE[^5]\n\t\t-  context encoder[^6]\n\n\t- transformer based: \n\t\t- iGPT[^7]\n\t\t- ViT[^8]\n\t\t- BEiT[^9]\n- **Self-supervised learning:** \n  - CNN based: \n    - Unsupervised learning of visual representations using videos[^10]\n    - CFN[^11]\n    - Colorful Image Colorization[^12]\n    - Unsupervised representation learning by predicting image rotations[^13]\n  - Transformer based: \n    - ViT[^8]\n  - Contrastive learning based: \n    - Unsupervised feature learning via non-parametric instance discrimination[^14]\n    - Representation learning with contrastive predictive coding[^15]\n    - MOCO[^16]\n\n{%endmarkmap%}\n\nNote that BEiT[^9] is very similar to MAE, while BEiT[^9] projects each patch to a label and predict as Bert[^1], unlike projecting to pixels in MAE. Besides, the recently popular constructive methods [^14][^15][^16] relay on data augmentation heavily, while MAE does not.\n\n### Approach\n\nThe architecture and the training approach is briefly covered in the sketch below:\n\n<img src=\"MAE architecture.png\" alt=\"MAE architecture\" style=\"zoom:40%;\" />\n\nAdditional details about the architecture: For per-processing, non-overlapped patching and random uniform masking are adopted. The [mask] token is shared, and another position embedding is introduced to the decoder input so that the inputs are different on different masked area. But it is unclear whether the positional embedding is performed only on the [mask] token or on the whole input, i.e. encoded patches + [mask] token. Furthermore, the lightweight decoder has <10% computation per token compared with the encoder.\n\nReconstruction target: The decoder aims to recreate the pixels of masked patches. The loss function is the mean squared error (MSE) between the output and the original image, only on the masked region of course. Besides, a variation reconstructing the normalised pixels shows an improvement in representation quality.\n\nImplementation: The random masking step is applied by shuffling and dropping the last part. And un-shuffling is used before the decoder to reconstruct the position. In this way, no sparse operation is needed and the cost becomes really low.\n\n### ImageNet experiments\n\n#### Setup\n\nThe model is self-supervised pre-trained on the ImageNet-1K, then evaluated by 2 kinds of supervised training: (i) end-to-end fine-tuning and (ii) linear probing(only the last linear projection layer is allowed to update). ViT-Large (ViT-L/16)[^8] is used as baseline backbone.\n\nNote that they reproduce the full supervised experiments by ViT[^8] and get 8% higher accuracy. The trick is a strong regularisation(75%). May be it meets the previous theory of the semantic difference between picture and text.\n\n| Supervised, original[^8] | Supervised, their impl. | Self-supervised, Baseline |\n| :----------------------: | :---------------------: | :-----------------------: |\n|           76.5           |          82.5           |           84.9            |\n\n#### Ablation\n\nMost of the result are recoded clearly on the figures and tables below,\n\n<img src=\"MAE mask ratio.png\" alt=\"MAE mask ratio\" style=\"zoom:90%;\" />\n\n<img src=\"MAE ablation.png\" alt=\"MAE ablation\" style=\"zoom:90%;\" />\n\n Just add some details:\n\n- Best mask ratio is higher than BERT[^1] (15%) and iGPT[^7], ViT[^8]and BEiT[^9] (25%-50%)\n- The encoder manages to learn the semantic representations given that the semantic pieces are mixed in each input patches, different from  NLP\n- No saturation of linear probing accuracy is observed, indicating the overfitting is not severer even at epoch 1600\n- One explanation for (a): a reasonably deep decoder can account for the reconstruction specialisation, leaving the encoder to extract a more abstract latent representation.\n- One explanation for (c): current architecture only process known patches, the introducing of unknown [mask] token would result in a gap between the pre-train task and inference task.\n- Result of (d) indicates that high-frequency components are useful in MAE. And the dVAE token case is actually what BEiT[^9] does, projecting each patch to a single token.\n- Result of (e) distinguishes MAE from contrastive learning and related methods. In MAE, the random masking plays the main role of data augmentation.\n\n#### Comparison\n\n<img src=\"MAE comparison.png\" alt=\"MAE comparison\" style=\"zoom:100%;\" />\n\n- with unsupervised models: not only the accuracy is better, the pre-training time is shorter than the competitors as well\n- with supervised models: it indicates that MAE can help scale up model sizes. And the MAE performance on ImageNet1K is similar to the model trained on the 300 times bigger dataset JFT300M. But, considering the number of class of JFT300M is much more than ImageNet1K as well, the result is slightly unfair. \n\n#### Partial Fine-tuning\n\nIn addition to the full fine-tuning and 0 fine-tuning (linear probing), partial ones are applied by fine tuning fixing several layers. The result indicating at least the last 6 layers are task-related.\n\n<img src=\"MAE fine tune.png\" alt=\"Partial fine-tuning\" style=\"zoom:30%;\" />\n\n### Transfer learning experiments\n\nAt last, down steam tasks are evaluated compared with other frameworks.\n\n<img src=\"MAE segmentation.png\" alt=\"MAE segmentation\" style=\"zoom:60%;\" />\n\n<img src=\"MAE classification.png\" alt=\"MAE classification\" style=\"zoom:61%;\" />\n\n<img src=\"MAE pixels vs tokens.png\" alt=\"MAE pixels vs tokens\" style=\"zoom:62%;\" />\n\n## Review\n\nWriting, simple but has a very good storyline. From the full introduction of the motivation, to the detailed clear figures explaining each part of the design.\n\nThe algorithm is simple, just applying self-supervised learning to CV based on ViT[^8]. 2 key points are introduced:\n\n- More patches need to be masked\n- Transformer decoder to reproduce the pixels instead of a simple linear layer projecting patches into tokens.\n\nIn conclusion, a simple idea, a great result and detailed experiments make this paper a great work. \n\n## Reference\n\n[^1]:[Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. *arXiv preprint arXiv:1810.04805*.](https://arxiv.org/abs/1810.04805)\n[^2]: [Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language understanding by generative pre-training.](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf)\n[^3]: [Hinton, G. E., & Zemel, R. (1993). Autoencoders, minimum description length and Helmholtz free energy. *Advances in neural information processing systems*, *6*.](https://proceedings.neurips.cc/paper/1993/hash/9e3cfc48eccf81a0d57663e129aef3cb-Abstract.html)\n[^4]: [Vincent, P., Larochelle, H., Bengio, Y., & Manzagol, P. A. (2008, July). Extracting and composing robust features with denoising autoencoders. In *Proceedings of the 25th international conference on Machine learning* (pp. 1096-1103).](https://dl.acm.org/doi/abs/10.1145/1390156.1390294)\n[^5]: [Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P. A., & Bottou, L. (2010). Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. *Journal of machine learning research*, *11*(12).](https://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf?ref=https://githubhelp.com)\n[^6]:[Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., & Efros, A. A. (2016). Context encoders: Feature learning by inpainting. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 2536-2544).](http://openaccess.thecvf.com/content_cvpr_2016/html/Pathak_Context_Encoders_Feature_CVPR_2016_paper.html)\n[^7]:[Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., & Sutskever, I. (2020, November). Generative pretraining from pixels. In *International Conference on Machine Learning* (pp. 1691-1703). PMLR.](http://proceedings.mlr.press/v119/chen20s.html)\n[^8]:[Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. *arXiv preprint arXiv:2010.11929*.](https://arxiv.org/abs/2010.11929)\n[^9]: [Bao, H., Dong, L., & Wei, F. (2021). Beit: Bert pre-training of image transformers. *arXiv preprint arXiv:2106.08254*.](https://arxiv.org/abs/2106.08254)\n[^10]: [Wang, X., & Gupta, A. (2015). Unsupervised learning of visual representations using videos. In *Proceedings of the IEEE international conference on computer vision* (pp. 2794-2802).](http://openaccess.thecvf.com/content_iccv_2015/html/Wang_Unsupervised_Learning_of_ICCV_2015_paper.html)\n[^11]: [Noroozi, M., & Favaro, P. (2016, October). Unsupervised learning of visual representations by solving jigsaw puzzles. In *European conference on computer vision* (pp. 69-84). Springer, Cham.](https://link.springer.com/chapter/10.1007/978-3-319-46466-4_5)\n[^12]: [Zhang, R., Isola, P., & Efros, A. A. (2016, October). Colorful image colorization. In *European conference on computer vision* (pp. 649-666). Springer, Cham.](https://link.springer.com/chapter/10.1007/978-3-319-46487-9_40)\n[^13]: [Gidaris, S., Singh, P., & Komodakis, N. (2018). Unsupervised representation learning by predicting image rotations. *arXiv preprint arXiv:1803.07728*.](https://arxiv.org/abs/1803.07728)\n[^14]: [Wu, Z., Xiong, Y., Yu, S. X., & Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 3733-3742).](http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html)\n[^15]: [Oord, A. V. D., Li, Y., & Vinyals, O. (2018). Representation learning with contrastive predictive coding. *arXiv preprint arXiv:1807.03748*.](https://arxiv.org/abs/1807.03748)\n[^16]: [He, K., Fan, H., Wu, Y., Xie, S., & Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition* (pp. 9729-9738).](http://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html)\n[^17]: [Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. *Advances in neural information processing systems*, *30*.](https://arxiv.org/abs/1706.03762)\n\n","slug":"paper-reading-MAE","published":1,"updated":"2022-06-09T10:25:03.081Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz29001vl8yb3cqd7w4u","content":"<blockquote>\n<p>Published in Dec 2021, this new work by Kaiming He draws a lot of attention from the community. The astounding result of unsupervised transfer learning and the capability of reconstructing highly masked (up to 90%) images might herald a new era in CV.</p>\n</blockquote>\n<span id=\"more\"></span>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>\n<p>Paper: <a href=\"https://arxiv.org/abs/2111.06377\">Masked autoencoders are scalable vision learners</a></p>\n<p>Useful link: https://www.bilibili.com/video/BV1sq4y1q77t/</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th></th>\n<th>NLP</th>\n<th>CV</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td><strong>Supervised</strong></td>\n<td>Transformer<sup id=\"fnref:17\" class=\"footnote-ref\"><a href=\"#fn:17\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... &amp; Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.\n\">[17]</span></a></sup></td>\n<td>ViT<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup></td>\n</tr>\n<tr class=\"even\">\n<td><strong>Self-supervised</strong></td>\n<td>Bert<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup></td>\n<td><u>MAE</u></td>\n</tr>\n</tbody>\n</table>\n<p>Inspired by Bert<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup> and ViT<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup>, MAE shows the capability of unsupervised learning on CV. It's not the first work to expand Bert <sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup> to CV, but it might be the most influential one. It might accelerate the application of transformer in CV, as Bert<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup> has done with NLP.</p>\n<h2 id=\"notes\">Notes</h2>\n<h3 id=\"title\">Title</h3>\n<p>Note the title format, \"Something is a good fellow\", is same as the GPT<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Radford, A., Narasimhan, K., Salimans, T., &amp; Sutskever, I. (2018). Improving language understanding by generative pre-training.\n\">[2]</span></a></sup> series. It is a powerful format to include the distilled conclusion in the title.</p>\n<h3 id=\"abstract\">Abstract</h3>\n<p>This paper proposes an asymmetric, transformer-based, denoising auto-encoder architecture. The unsupervised pre-training task is to reconstruct highly masked input images. The high masking ratio is the key. It reduces the pre-training time by 3 times and is able to train larger model efficiently, resulting in competitive reconstructing accuracy. The transfer performance is even better than the supervised pre-training models.</p>\n<h3 id=\"key-figures\">Key figures</h3>\n<p>First, the reconstruction results are shown below.</p>\n<p><img src=\"MAE result.png\" srcset=\"/img/loading.gif\" lazyload alt=\"MAE result 1\" style=\"zoom:90%;\" /></p>\n<p><img src=\"MAE result2.png\" srcset=\"/img/loading.gif\" lazyload alt=\"MAE result2\" style=\"zoom:30%;\" /></p>\n<p>Although the details are vague, the reconstruction of the main content is astonishing. Note that maybe not all of the validation images turned out as good as this, but this result is still really surprising.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>The model is said to be simple(false) and scaled well(as long as you are rich). The results show that MAE makes scaleable unsupervised pre-training in CV applicable, a similar route to that of NLP<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup><sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Radford, A., Narasimhan, K., Salimans, T., &amp; Sutskever, I. (2018). Improving language understanding by generative pre-training.\n\">[2]</span></a></sup>.</p>\n<p>Besides, they claim the semantic difference between text and image leads to different masking operations. Furthermore, they mention that the patch masking operation does not separate semantic entities, meaning one masked patch may include more than one piece of semantic information, unlike language. As a result the reconstruction results show that the model manages to learn from complex semantics.</p>\n<h3 id=\"introduction\">Introduction</h3>\n<p>Although yielding excellent success in NLP, applying scalable unsupervised models in CV is still a challenging problem. But why? i.e. <strong>what makes masked autoencoding different between vision and language? </strong>3 reasons are discussed:</p>\n<ul>\n<li><p>The architecture difference between convolution and transformer: it's hard to integrate masked embedding or positional embedding to the convolution layer (Actually positional embedding is not needed for convolutional layer) -- addressed by ViT<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup>.</p></li>\n<li><p>The information density difference between text and image: Unlike high-semantic text, natural signals in images possess heavy spatial redundancy -- addressed by masking a very high portion of random patches.</p></li>\n<li><p>Decoder difference: in NLP, take BERT as an example, a simple linear projection is used as a decoder, while in vision, a simple decoder is not powerful enough to reconstruct the semantic level information -- addressed by substituting linear projection with transformer layers.</p></li>\n</ul>\n<p>Then, the idea of MAE is on the front door. The encoder processes only the unmasked patches, while the lightweight decoder reconstructs the whole image from the encoded latent representation and the [mask] tokens. With a very high masking ratio(e.g. 75%), the pre-training time can be reduced by 3 times.</p>\n<p>Besides, the data capacity and generalisation performance are great. SOTA accuracy is achieved with fine tuning on a medium-sized dataset (ViT-Huge model on ImageNet 1K).</p>\n<p>In this section, the reason why designing such an architecture is well presented through Q&amp;A, highly recommended. Sometimes, motive is an important factor in distinguishing a paper from a technical report.</p>\n<h3 id=\"relate-work\">Relate work</h3>\n<p>Works in 4 areas are briefly reviewed.</p>\n\n<div class=\"markmap-container\" style=\"height:300px\">\n  <svg data=\"{&quot;t&quot;:&quot;root&quot;,&quot;d&quot;:0,&quot;v&quot;:&quot;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[1,2]},&quot;v&quot;:&quot;&lt;strong&gt;Masked language modelling:&lt;/strong&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[3,5]},&quot;v&quot;:&quot;BERT&lt;sup id=\\&quot;fnref:1\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:1\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Devlin, J., Chang, M. W., Lee, K., &amp;amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\\n\\&quot;&gt;[1]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[6,8]},&quot;v&quot;:&quot;GPT&lt;sup id=\\&quot;fnref:2\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:2\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Radford, A., Narasimhan, K., Salimans, T., &amp;amp; Sutskever, I. (2018). Improving language understanding by generative pre-training.\\n\\&quot;&gt;[2]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[8,9]},&quot;v&quot;:&quot;&lt;strong&gt;Auto-encoding:&lt;/strong&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[10,12]},&quot;v&quot;:&quot;classic autoencoders&lt;sup id=\\&quot;fnref:3\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:3\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Hinton, G. E., &amp;amp; Zemel, R. (1993). Autoencoders, minimum description length and Helmholtz free energy. Advances in neural information processing systems, 6.\\n\\&quot;&gt;[3]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt; : PCA, k-means&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[13,15]},&quot;v&quot;:&quot;denoising autoencoders(DAE)&lt;sup id=\\&quot;fnref:4\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:4\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Vincent, P., Larochelle, H., Bengio, Y., &amp;amp; Manzagol, P. A. (2008, July). Extracting and composing robust features with denoising autoencoders. In Proceedings of the 25th international conference on Machine learning (pp. 1096-1103).\\n\\&quot;&gt;[4]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[15,16]},&quot;v&quot;:&quot;&lt;strong&gt;Masked image encoding:&lt;/strong&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[17,18]},&quot;v&quot;:&quot;classic&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[18,20]},&quot;v&quot;:&quot;pioneer work SDAE&lt;sup id=\\&quot;fnref:5\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:5\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P. A., &amp;amp; Bottou, L. (2010). Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. Journal of machine learning research, 11(12).\\n\\&quot;&gt;[5]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[20,22]},&quot;v&quot;:&quot;context encoder&lt;sup id=\\&quot;fnref:6\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:6\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., &amp;amp; Efros, A. A. (2016). Context encoders: Feature learning by inpainting. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2536-2544).\\n\\&quot;&gt;[6]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[23,24]},&quot;v&quot;:&quot;transformer based:&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[24,26]},&quot;v&quot;:&quot;iGPT&lt;sup id=\\&quot;fnref:7\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:7\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., &amp;amp; Sutskever, I. (2020, November). Generative pretraining from pixels. In International Conference on Machine Learning (pp. 1691-1703). PMLR.\\n\\&quot;&gt;[7]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[26,28]},&quot;v&quot;:&quot;ViT&lt;sup id=\\&quot;fnref:8\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:8\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp;amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\\n\\&quot;&gt;[8]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[28,30]},&quot;v&quot;:&quot;BEiT&lt;sup id=\\&quot;fnref:9\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:9\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Bao, H., Dong, L., &amp;amp; Wei, F. (2021). Beit: Bert pre-training of image transformers. arXiv preprint arXiv:2106.08254.\\n\\&quot;&gt;[9]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[30,31]},&quot;v&quot;:&quot;&lt;strong&gt;Self-supervised learning:&lt;/strong&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[31,32]},&quot;v&quot;:&quot;CNN based:&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[32,34]},&quot;v&quot;:&quot;Unsupervised learning of visual representations using videos&lt;sup id=\\&quot;fnref:10\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:10\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Wang, X., &amp;amp; Gupta, A. (2015). Unsupervised learning of visual representations using videos. In Proceedings of the IEEE international conference on computer vision (pp. 2794-2802).\\n\\&quot;&gt;[10]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[34,36]},&quot;v&quot;:&quot;CFN&lt;sup id=\\&quot;fnref:11\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:11\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Noroozi, M., &amp;amp; Favaro, P. (2016, October). Unsupervised learning of visual representations by solving jigsaw puzzles. In European conference on computer vision (pp. 69-84). Springer, Cham.\\n\\&quot;&gt;[11]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[36,38]},&quot;v&quot;:&quot;Colorful Image Colorization&lt;sup id=\\&quot;fnref:12\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:12\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Zhang, R., Isola, P., &amp;amp; Efros, A. A. (2016, October). Colorful image colorization. In European conference on computer vision (pp. 649-666). Springer, Cham.\\n\\&quot;&gt;[12]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[38,40]},&quot;v&quot;:&quot;Unsupervised representation learning by predicting image rotations&lt;sup id=\\&quot;fnref:13\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:13\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Gidaris, S., Singh, P., &amp;amp; Komodakis, N. (2018). Unsupervised representation learning by predicting image rotations. arXiv preprint arXiv:1803.07728.\\n\\&quot;&gt;[13]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[40,41]},&quot;v&quot;:&quot;Transformer based:&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[41,43]},&quot;v&quot;:&quot;ViT&lt;sup id=\\&quot;fnref:8\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:8\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp;amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\\n\\&quot;&gt;[8]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[43,44]},&quot;v&quot;:&quot;Contrastive learning based:&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[44,46]},&quot;v&quot;:&quot;Unsupervised feature learning via non-parametric instance discrimination&lt;sup id=\\&quot;fnref:14\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:14\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Wu, Z., Xiong, Y., Yu, S. X., &amp;amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\\n\\&quot;&gt;[14]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[46,48]},&quot;v&quot;:&quot;Representation learning with contrastive predictive coding&lt;sup id=\\&quot;fnref:15\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:15\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Oord, A. V. D., Li, Y., &amp;amp; Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748.\\n\\&quot;&gt;[15]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[48,50]},&quot;v&quot;:&quot;MOCO&lt;sup id=\\&quot;fnref:16\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:16\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;He, K., Fan, H., Wu, Y., Xie, S., &amp;amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\\n\\&quot;&gt;[16]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]}]}],&quot;p&quot;:{}}\"></svg>\n</div>\n\n<p>Note that BEiT<sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Bao, H., Dong, L., &amp; Wei, F. (2021). Beit: Bert pre-training of image transformers. arXiv preprint arXiv:2106.08254.\n\">[9]</span></a></sup> is very similar to MAE, while BEiT<sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Bao, H., Dong, L., &amp; Wei, F. (2021). Beit: Bert pre-training of image transformers. arXiv preprint arXiv:2106.08254.\n\">[9]</span></a></sup> projects each patch to a label and predict as Bert<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup>, unlike projecting to pixels in MAE. Besides, the recently popular constructive methods <sup id=\"fnref:14\" class=\"footnote-ref\"><a href=\"#fn:14\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[14]</span></a></sup><sup id=\"fnref:15\" class=\"footnote-ref\"><a href=\"#fn:15\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Oord, A. V. D., Li, Y., &amp; Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748.\n\">[15]</span></a></sup><sup id=\"fnref:16\" class=\"footnote-ref\"><a href=\"#fn:16\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[16]</span></a></sup> relay on data augmentation heavily, while MAE does not.</p>\n<h3 id=\"approach\">Approach</h3>\n<p>The architecture and the training approach is briefly covered in the sketch below:</p>\n<p><img src=\"MAE architecture.png\" srcset=\"/img/loading.gif\" lazyload alt=\"MAE architecture\" style=\"zoom:40%;\" /></p>\n<p>Additional details about the architecture: For per-processing, non-overlapped patching and random uniform masking are adopted. The [mask] token is shared, and another position embedding is introduced to the decoder input so that the inputs are different on different masked area. But it is unclear whether the positional embedding is performed only on the [mask] token or on the whole input, i.e. encoded patches + [mask] token. Furthermore, the lightweight decoder has &lt;10% computation per token compared with the encoder.</p>\n<p>Reconstruction target: The decoder aims to recreate the pixels of masked patches. The loss function is the mean squared error (MSE) between the output and the original image, only on the masked region of course. Besides, a variation reconstructing the normalised pixels shows an improvement in representation quality.</p>\n<p>Implementation: The random masking step is applied by shuffling and dropping the last part. And un-shuffling is used before the decoder to reconstruct the position. In this way, no sparse operation is needed and the cost becomes really low.</p>\n<h3 id=\"imagenet-experiments\">ImageNet experiments</h3>\n<h4 id=\"setup\">Setup</h4>\n<p>The model is self-supervised pre-trained on the ImageNet-1K, then evaluated by 2 kinds of supervised training: (i) end-to-end fine-tuning and (ii) linear probing(only the last linear projection layer is allowed to update). ViT-Large (ViT-L/16)<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup> is used as baseline backbone.</p>\n<p>Note that they reproduce the full supervised experiments by ViT<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup> and get 8% higher accuracy. The trick is a strong regularisation(75%). May be it meets the previous theory of the semantic difference between picture and text.</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: center;\">Supervised, original<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup></th>\n<th style=\"text-align: center;\">Supervised, their impl.</th>\n<th style=\"text-align: center;\">Self-supervised, Baseline</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: center;\">76.5</td>\n<td style=\"text-align: center;\">82.5</td>\n<td style=\"text-align: center;\">84.9</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"ablation\">Ablation</h4>\n<p>Most of the result are recoded clearly on the figures and tables below,</p>\n<p><img src=\"MAE mask ratio.png\" srcset=\"/img/loading.gif\" lazyload alt=\"MAE mask ratio\" style=\"zoom:90%;\" /></p>\n<p><img src=\"MAE ablation.png\" srcset=\"/img/loading.gif\" lazyload alt=\"MAE ablation\" style=\"zoom:90%;\" /></p>\n<p>Just add some details:</p>\n<ul>\n<li>Best mask ratio is higher than BERT<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup> (15%) and iGPT<sup id=\"fnref:7\" class=\"footnote-ref\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., &amp; Sutskever, I. (2020, November). Generative pretraining from pixels. In International Conference on Machine Learning (pp. 1691-1703). PMLR.\n\">[7]</span></a></sup>, ViT<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup>and BEiT<sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Bao, H., Dong, L., &amp; Wei, F. (2021). Beit: Bert pre-training of image transformers. arXiv preprint arXiv:2106.08254.\n\">[9]</span></a></sup> (25%-50%)</li>\n<li>The encoder manages to learn the semantic representations given that the semantic pieces are mixed in each input patches, different from NLP</li>\n<li>No saturation of linear probing accuracy is observed, indicating the overfitting is not severer even at epoch 1600</li>\n<li>One explanation for (a): a reasonably deep decoder can account for the reconstruction specialisation, leaving the encoder to extract a more abstract latent representation.</li>\n<li>One explanation for (c): current architecture only process known patches, the introducing of unknown [mask] token would result in a gap between the pre-train task and inference task.</li>\n<li>Result of (d) indicates that high-frequency components are useful in MAE. And the dVAE token case is actually what BEiT<sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Bao, H., Dong, L., &amp; Wei, F. (2021). Beit: Bert pre-training of image transformers. arXiv preprint arXiv:2106.08254.\n\">[9]</span></a></sup> does, projecting each patch to a single token.</li>\n<li>Result of (e) distinguishes MAE from contrastive learning and related methods. In MAE, the random masking plays the main role of data augmentation.</li>\n</ul>\n<h4 id=\"comparison\">Comparison</h4>\n<p><img src=\"MAE comparison.png\" srcset=\"/img/loading.gif\" lazyload alt=\"MAE comparison\" style=\"zoom:100%;\" /></p>\n<ul>\n<li>with unsupervised models: not only the accuracy is better, the pre-training time is shorter than the competitors as well</li>\n<li>with supervised models: it indicates that MAE can help scale up model sizes. And the MAE performance on ImageNet1K is similar to the model trained on the 300 times bigger dataset JFT300M. But, considering the number of class of JFT300M is much more than ImageNet1K as well, the result is slightly unfair.</li>\n</ul>\n<h4 id=\"partial-fine-tuning\">Partial Fine-tuning</h4>\n<p>In addition to the full fine-tuning and 0 fine-tuning (linear probing), partial ones are applied by fine tuning fixing several layers. The result indicating at least the last 6 layers are task-related.</p>\n<p><img src=\"MAE fine tune.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Partial fine-tuning\" style=\"zoom:30%;\" /></p>\n<h3 id=\"transfer-learning-experiments\">Transfer learning experiments</h3>\n<p>At last, down steam tasks are evaluated compared with other frameworks.</p>\n<p><img src=\"MAE segmentation.png\" srcset=\"/img/loading.gif\" lazyload alt=\"MAE segmentation\" style=\"zoom:60%;\" /></p>\n<p><img src=\"MAE classification.png\" srcset=\"/img/loading.gif\" lazyload alt=\"MAE classification\" style=\"zoom:61%;\" /></p>\n<p><img src=\"MAE pixels vs tokens.png\" srcset=\"/img/loading.gif\" lazyload alt=\"MAE pixels vs tokens\" style=\"zoom:62%;\" /></p>\n<h2 id=\"review\">Review</h2>\n<p>Writing, simple but has a very good storyline. From the full introduction of the motivation, to the detailed clear figures explaining each part of the design.</p>\n<p>The algorithm is simple, just applying self-supervised learning to CV based on ViT<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup>. 2 key points are introduced:</p>\n<ul>\n<li>More patches need to be masked</li>\n<li>Transformer decoder to reproduce the pixels instead of a simple linear layer projecting patches into tokens.</li>\n</ul>\n<p>In conclusion, a simple idea, a great result and detailed experiments make this paper a great work.</p>\n<h2 id=\"reference\">Reference</h2>\n<section class=\"footnotes\">\n<div class=\"footnote-list\">\n<ol>\n<li>\n<span id=\"fn:1\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/1810.04805\">Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. <em>arXiv preprint arXiv:1810.04805</em>.</a> <a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:2\" class=\"footnote-text\"><span><a href=\"https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf\">Radford, A., Narasimhan, K., Salimans, T., &amp; Sutskever, I. (2018). Improving language understanding by generative pre-training.</a> <a href=\"#fnref:2\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:3\" class=\"footnote-text\"><span><a href=\"https://proceedings.neurips.cc/paper/1993/hash/9e3cfc48eccf81a0d57663e129aef3cb-Abstract.html\">Hinton, G. E., &amp; Zemel, R. (1993). Autoencoders, minimum description length and Helmholtz free energy. <em>Advances in neural information processing systems</em>, <em>6</em>.</a> <a href=\"#fnref:3\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:4\" class=\"footnote-text\"><span><a href=\"https://dl.acm.org/doi/abs/10.1145/1390156.1390294\">Vincent, P., Larochelle, H., Bengio, Y., &amp; Manzagol, P. A. (2008, July). Extracting and composing robust features with denoising autoencoders. In <em>Proceedings of the 25th international conference on Machine learning</em> (pp. 1096-1103).</a> <a href=\"#fnref:4\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:5\" class=\"footnote-text\"><span><a href=\"https://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf?ref=https://githubhelp.com\">Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P. A., &amp; Bottou, L. (2010). Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. <em>Journal of machine learning research</em>, <em>11</em>(12).</a> <a href=\"#fnref:5\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:6\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_cvpr_2016/html/Pathak_Context_Encoders_Feature_CVPR_2016_paper.html\">Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., &amp; Efros, A. A. (2016). Context encoders: Feature learning by inpainting. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp. 2536-2544).</a> <a href=\"#fnref:6\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:7\" class=\"footnote-text\"><span><a href=\"http://proceedings.mlr.press/v119/chen20s.html\">Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., &amp; Sutskever, I. (2020, November). Generative pretraining from pixels. In <em>International Conference on Machine Learning</em> (pp. 1691-1703). PMLR.</a> <a href=\"#fnref:7\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:8\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/2010.11929\">Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. <em>arXiv preprint arXiv:2010.11929</em>.</a> <a href=\"#fnref:8\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:9\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/2106.08254\">Bao, H., Dong, L., &amp; Wei, F. (2021). Beit: Bert pre-training of image transformers. <em>arXiv preprint arXiv:2106.08254</em>.</a> <a href=\"#fnref:9\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:10\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_iccv_2015/html/Wang_Unsupervised_Learning_of_ICCV_2015_paper.html\">Wang, X., &amp; Gupta, A. (2015). Unsupervised learning of visual representations using videos. In <em>Proceedings of the IEEE international conference on computer vision</em> (pp. 2794-2802).</a> <a href=\"#fnref:10\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:11\" class=\"footnote-text\"><span><a href=\"https://link.springer.com/chapter/10.1007/978-3-319-46466-4_5\">Noroozi, M., &amp; Favaro, P. (2016, October). Unsupervised learning of visual representations by solving jigsaw puzzles. In <em>European conference on computer vision</em> (pp. 69-84). Springer, Cham.</a> <a href=\"#fnref:11\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:12\" class=\"footnote-text\"><span><a href=\"https://link.springer.com/chapter/10.1007/978-3-319-46487-9_40\">Zhang, R., Isola, P., &amp; Efros, A. A. (2016, October). Colorful image colorization. In <em>European conference on computer vision</em> (pp. 649-666). Springer, Cham.</a> <a href=\"#fnref:12\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:13\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/1803.07728\">Gidaris, S., Singh, P., &amp; Komodakis, N. (2018). Unsupervised representation learning by predicting image rotations. <em>arXiv preprint arXiv:1803.07728</em>.</a> <a href=\"#fnref:13\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:14\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html\">Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp. 3733-3742).</a> <a href=\"#fnref:14\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:15\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/1807.03748\">Oord, A. V. D., Li, Y., &amp; Vinyals, O. (2018). Representation learning with contrastive predictive coding. <em>arXiv preprint arXiv:1807.03748</em>.</a> <a href=\"#fnref:15\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:16\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html\">He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em> (pp. 9729-9738).</a> <a href=\"#fnref:16\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:17\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/1706.03762\">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... &amp; Polosukhin, I. (2017). Attention is all you need. <em>Advances in neural information processing systems</em>, <em>30</em>.</a> <a href=\"#fnref:17\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n</ol>\n</div>\n</section>\n","site":{"data":{}},"wordcount":10028,"excerpt":"<blockquote>\n<p>Published in Dec 2021, this new work by Kaiming He draws a lot of attention from the community. The astounding result of unsupervised transfer learning and the capability of reconstructing highly masked (up to 90%) images might herald a new era in CV.</p>\n</blockquote>","more":"<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>\n<p>Paper: <a href=\"https://arxiv.org/abs/2111.06377\">Masked autoencoders are scalable vision learners</a></p>\n<p>Useful link: https://www.bilibili.com/video/BV1sq4y1q77t/</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th></th>\n<th>NLP</th>\n<th>CV</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td><strong>Supervised</strong></td>\n<td>Transformer<sup id=\"fnref:17\" class=\"footnote-ref\"><a href=\"#fn:17\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... &amp; Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.\n\">[17]</span></a></sup></td>\n<td>ViT<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup></td>\n</tr>\n<tr class=\"even\">\n<td><strong>Self-supervised</strong></td>\n<td>Bert<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup></td>\n<td><u>MAE</u></td>\n</tr>\n</tbody>\n</table>\n<p>Inspired by Bert<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup> and ViT<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup>, MAE shows the capability of unsupervised learning on CV. It's not the first work to expand Bert <sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup> to CV, but it might be the most influential one. It might accelerate the application of transformer in CV, as Bert<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup> has done with NLP.</p>\n<h2 id=\"notes\">Notes</h2>\n<h3 id=\"title\">Title</h3>\n<p>Note the title format, \"Something is a good fellow\", is same as the GPT<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Radford, A., Narasimhan, K., Salimans, T., &amp; Sutskever, I. (2018). Improving language understanding by generative pre-training.\n\">[2]</span></a></sup> series. It is a powerful format to include the distilled conclusion in the title.</p>\n<h3 id=\"abstract\">Abstract</h3>\n<p>This paper proposes an asymmetric, transformer-based, denoising auto-encoder architecture. The unsupervised pre-training task is to reconstruct highly masked input images. The high masking ratio is the key. It reduces the pre-training time by 3 times and is able to train larger model efficiently, resulting in competitive reconstructing accuracy. The transfer performance is even better than the supervised pre-training models.</p>\n<h3 id=\"key-figures\">Key figures</h3>\n<p>First, the reconstruction results are shown below.</p>\n<p><img src=\"MAE result.png\" alt=\"MAE result 1\" style=\"zoom:90%;\" /></p>\n<p><img src=\"MAE result2.png\" alt=\"MAE result2\" style=\"zoom:30%;\" /></p>\n<p>Although the details are vague, the reconstruction of the main content is astonishing. Note that maybe not all of the validation images turned out as good as this, but this result is still really surprising.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>The model is said to be simple(false) and scaled well(as long as you are rich). The results show that MAE makes scaleable unsupervised pre-training in CV applicable, a similar route to that of NLP<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup><sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Radford, A., Narasimhan, K., Salimans, T., &amp; Sutskever, I. (2018). Improving language understanding by generative pre-training.\n\">[2]</span></a></sup>.</p>\n<p>Besides, they claim the semantic difference between text and image leads to different masking operations. Furthermore, they mention that the patch masking operation does not separate semantic entities, meaning one masked patch may include more than one piece of semantic information, unlike language. As a result the reconstruction results show that the model manages to learn from complex semantics.</p>\n<h3 id=\"introduction\">Introduction</h3>\n<p>Although yielding excellent success in NLP, applying scalable unsupervised models in CV is still a challenging problem. But why? i.e. <strong>what makes masked autoencoding different between vision and language? </strong>3 reasons are discussed:</p>\n<ul>\n<li><p>The architecture difference between convolution and transformer: it's hard to integrate masked embedding or positional embedding to the convolution layer (Actually positional embedding is not needed for convolutional layer) -- addressed by ViT<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup>.</p></li>\n<li><p>The information density difference between text and image: Unlike high-semantic text, natural signals in images possess heavy spatial redundancy -- addressed by masking a very high portion of random patches.</p></li>\n<li><p>Decoder difference: in NLP, take BERT as an example, a simple linear projection is used as a decoder, while in vision, a simple decoder is not powerful enough to reconstruct the semantic level information -- addressed by substituting linear projection with transformer layers.</p></li>\n</ul>\n<p>Then, the idea of MAE is on the front door. The encoder processes only the unmasked patches, while the lightweight decoder reconstructs the whole image from the encoded latent representation and the [mask] tokens. With a very high masking ratio(e.g. 75%), the pre-training time can be reduced by 3 times.</p>\n<p>Besides, the data capacity and generalisation performance are great. SOTA accuracy is achieved with fine tuning on a medium-sized dataset (ViT-Huge model on ImageNet 1K).</p>\n<p>In this section, the reason why designing such an architecture is well presented through Q&amp;A, highly recommended. Sometimes, motive is an important factor in distinguishing a paper from a technical report.</p>\n<h3 id=\"relate-work\">Relate work</h3>\n<p>Works in 4 areas are briefly reviewed.</p>\n\n<div class=\"markmap-container\" style=\"height:300px\">\n  <svg data=\"{&quot;t&quot;:&quot;root&quot;,&quot;d&quot;:0,&quot;v&quot;:&quot;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[1,2]},&quot;v&quot;:&quot;&lt;strong&gt;Masked language modelling:&lt;/strong&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[3,5]},&quot;v&quot;:&quot;BERT&lt;sup id=\\&quot;fnref:1\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:1\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Devlin, J., Chang, M. W., Lee, K., &amp;amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\\n\\&quot;&gt;[1]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[6,8]},&quot;v&quot;:&quot;GPT&lt;sup id=\\&quot;fnref:2\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:2\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Radford, A., Narasimhan, K., Salimans, T., &amp;amp; Sutskever, I. (2018). Improving language understanding by generative pre-training.\\n\\&quot;&gt;[2]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[8,9]},&quot;v&quot;:&quot;&lt;strong&gt;Auto-encoding:&lt;/strong&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[10,12]},&quot;v&quot;:&quot;classic autoencoders&lt;sup id=\\&quot;fnref:3\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:3\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Hinton, G. E., &amp;amp; Zemel, R. (1993). Autoencoders, minimum description length and Helmholtz free energy. Advances in neural information processing systems, 6.\\n\\&quot;&gt;[3]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt; : PCA, k-means&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[13,15]},&quot;v&quot;:&quot;denoising autoencoders(DAE)&lt;sup id=\\&quot;fnref:4\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:4\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Vincent, P., Larochelle, H., Bengio, Y., &amp;amp; Manzagol, P. A. (2008, July). Extracting and composing robust features with denoising autoencoders. In Proceedings of the 25th international conference on Machine learning (pp. 1096-1103).\\n\\&quot;&gt;[4]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[15,16]},&quot;v&quot;:&quot;&lt;strong&gt;Masked image encoding:&lt;/strong&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[17,18]},&quot;v&quot;:&quot;classic&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[18,20]},&quot;v&quot;:&quot;pioneer work SDAE&lt;sup id=\\&quot;fnref:5\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:5\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P. A., &amp;amp; Bottou, L. (2010). Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. Journal of machine learning research, 11(12).\\n\\&quot;&gt;[5]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[20,22]},&quot;v&quot;:&quot;context encoder&lt;sup id=\\&quot;fnref:6\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:6\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., &amp;amp; Efros, A. A. (2016). Context encoders: Feature learning by inpainting. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2536-2544).\\n\\&quot;&gt;[6]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[23,24]},&quot;v&quot;:&quot;transformer based:&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[24,26]},&quot;v&quot;:&quot;iGPT&lt;sup id=\\&quot;fnref:7\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:7\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., &amp;amp; Sutskever, I. (2020, November). Generative pretraining from pixels. In International Conference on Machine Learning (pp. 1691-1703). PMLR.\\n\\&quot;&gt;[7]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[26,28]},&quot;v&quot;:&quot;ViT&lt;sup id=\\&quot;fnref:8\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:8\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp;amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\\n\\&quot;&gt;[8]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[28,30]},&quot;v&quot;:&quot;BEiT&lt;sup id=\\&quot;fnref:9\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:9\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Bao, H., Dong, L., &amp;amp; Wei, F. (2021). Beit: Bert pre-training of image transformers. arXiv preprint arXiv:2106.08254.\\n\\&quot;&gt;[9]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[30,31]},&quot;v&quot;:&quot;&lt;strong&gt;Self-supervised learning:&lt;/strong&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[31,32]},&quot;v&quot;:&quot;CNN based:&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[32,34]},&quot;v&quot;:&quot;Unsupervised learning of visual representations using videos&lt;sup id=\\&quot;fnref:10\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:10\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Wang, X., &amp;amp; Gupta, A. (2015). Unsupervised learning of visual representations using videos. In Proceedings of the IEEE international conference on computer vision (pp. 2794-2802).\\n\\&quot;&gt;[10]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[34,36]},&quot;v&quot;:&quot;CFN&lt;sup id=\\&quot;fnref:11\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:11\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Noroozi, M., &amp;amp; Favaro, P. (2016, October). Unsupervised learning of visual representations by solving jigsaw puzzles. In European conference on computer vision (pp. 69-84). Springer, Cham.\\n\\&quot;&gt;[11]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[36,38]},&quot;v&quot;:&quot;Colorful Image Colorization&lt;sup id=\\&quot;fnref:12\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:12\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Zhang, R., Isola, P., &amp;amp; Efros, A. A. (2016, October). Colorful image colorization. In European conference on computer vision (pp. 649-666). Springer, Cham.\\n\\&quot;&gt;[12]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[38,40]},&quot;v&quot;:&quot;Unsupervised representation learning by predicting image rotations&lt;sup id=\\&quot;fnref:13\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:13\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Gidaris, S., Singh, P., &amp;amp; Komodakis, N. (2018). Unsupervised representation learning by predicting image rotations. arXiv preprint arXiv:1803.07728.\\n\\&quot;&gt;[13]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[40,41]},&quot;v&quot;:&quot;Transformer based:&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[41,43]},&quot;v&quot;:&quot;ViT&lt;sup id=\\&quot;fnref:8\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:8\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp;amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\\n\\&quot;&gt;[8]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[43,44]},&quot;v&quot;:&quot;Contrastive learning based:&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[44,46]},&quot;v&quot;:&quot;Unsupervised feature learning via non-parametric instance discrimination&lt;sup id=\\&quot;fnref:14\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:14\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Wu, Z., Xiong, Y., Yu, S. X., &amp;amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\\n\\&quot;&gt;[14]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[46,48]},&quot;v&quot;:&quot;Representation learning with contrastive predictive coding&lt;sup id=\\&quot;fnref:15\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:15\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Oord, A. V. D., Li, Y., &amp;amp; Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748.\\n\\&quot;&gt;[15]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[48,50]},&quot;v&quot;:&quot;MOCO&lt;sup id=\\&quot;fnref:16\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:16\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;He, K., Fan, H., Wu, Y., Xie, S., &amp;amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\\n\\&quot;&gt;[16]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]}]}],&quot;p&quot;:{}}\"></svg>\n</div>\n\n<p>Note that BEiT<sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Bao, H., Dong, L., &amp; Wei, F. (2021). Beit: Bert pre-training of image transformers. arXiv preprint arXiv:2106.08254.\n\">[9]</span></a></sup> is very similar to MAE, while BEiT<sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Bao, H., Dong, L., &amp; Wei, F. (2021). Beit: Bert pre-training of image transformers. arXiv preprint arXiv:2106.08254.\n\">[9]</span></a></sup> projects each patch to a label and predict as Bert<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup>, unlike projecting to pixels in MAE. Besides, the recently popular constructive methods <sup id=\"fnref:14\" class=\"footnote-ref\"><a href=\"#fn:14\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[14]</span></a></sup><sup id=\"fnref:15\" class=\"footnote-ref\"><a href=\"#fn:15\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Oord, A. V. D., Li, Y., &amp; Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748.\n\">[15]</span></a></sup><sup id=\"fnref:16\" class=\"footnote-ref\"><a href=\"#fn:16\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[16]</span></a></sup> relay on data augmentation heavily, while MAE does not.</p>\n<h3 id=\"approach\">Approach</h3>\n<p>The architecture and the training approach is briefly covered in the sketch below:</p>\n<p><img src=\"MAE architecture.png\" alt=\"MAE architecture\" style=\"zoom:40%;\" /></p>\n<p>Additional details about the architecture: For per-processing, non-overlapped patching and random uniform masking are adopted. The [mask] token is shared, and another position embedding is introduced to the decoder input so that the inputs are different on different masked area. But it is unclear whether the positional embedding is performed only on the [mask] token or on the whole input, i.e. encoded patches + [mask] token. Furthermore, the lightweight decoder has &lt;10% computation per token compared with the encoder.</p>\n<p>Reconstruction target: The decoder aims to recreate the pixels of masked patches. The loss function is the mean squared error (MSE) between the output and the original image, only on the masked region of course. Besides, a variation reconstructing the normalised pixels shows an improvement in representation quality.</p>\n<p>Implementation: The random masking step is applied by shuffling and dropping the last part. And un-shuffling is used before the decoder to reconstruct the position. In this way, no sparse operation is needed and the cost becomes really low.</p>\n<h3 id=\"imagenet-experiments\">ImageNet experiments</h3>\n<h4 id=\"setup\">Setup</h4>\n<p>The model is self-supervised pre-trained on the ImageNet-1K, then evaluated by 2 kinds of supervised training: (i) end-to-end fine-tuning and (ii) linear probing(only the last linear projection layer is allowed to update). ViT-Large (ViT-L/16)<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup> is used as baseline backbone.</p>\n<p>Note that they reproduce the full supervised experiments by ViT<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup> and get 8% higher accuracy. The trick is a strong regularisation(75%). May be it meets the previous theory of the semantic difference between picture and text.</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: center;\">Supervised, original<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup></th>\n<th style=\"text-align: center;\">Supervised, their impl.</th>\n<th style=\"text-align: center;\">Self-supervised, Baseline</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: center;\">76.5</td>\n<td style=\"text-align: center;\">82.5</td>\n<td style=\"text-align: center;\">84.9</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"ablation\">Ablation</h4>\n<p>Most of the result are recoded clearly on the figures and tables below,</p>\n<p><img src=\"MAE mask ratio.png\" alt=\"MAE mask ratio\" style=\"zoom:90%;\" /></p>\n<p><img src=\"MAE ablation.png\" alt=\"MAE ablation\" style=\"zoom:90%;\" /></p>\n<p>Just add some details:</p>\n<ul>\n<li>Best mask ratio is higher than BERT<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\">[1]</span></a></sup> (15%) and iGPT<sup id=\"fnref:7\" class=\"footnote-ref\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., &amp; Sutskever, I. (2020, November). Generative pretraining from pixels. In International Conference on Machine Learning (pp. 1691-1703). PMLR.\n\">[7]</span></a></sup>, ViT<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup>and BEiT<sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Bao, H., Dong, L., &amp; Wei, F. (2021). Beit: Bert pre-training of image transformers. arXiv preprint arXiv:2106.08254.\n\">[9]</span></a></sup> (25%-50%)</li>\n<li>The encoder manages to learn the semantic representations given that the semantic pieces are mixed in each input patches, different from NLP</li>\n<li>No saturation of linear probing accuracy is observed, indicating the overfitting is not severer even at epoch 1600</li>\n<li>One explanation for (a): a reasonably deep decoder can account for the reconstruction specialisation, leaving the encoder to extract a more abstract latent representation.</li>\n<li>One explanation for (c): current architecture only process known patches, the introducing of unknown [mask] token would result in a gap between the pre-train task and inference task.</li>\n<li>Result of (d) indicates that high-frequency components are useful in MAE. And the dVAE token case is actually what BEiT<sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Bao, H., Dong, L., &amp; Wei, F. (2021). Beit: Bert pre-training of image transformers. arXiv preprint arXiv:2106.08254.\n\">[9]</span></a></sup> does, projecting each patch to a single token.</li>\n<li>Result of (e) distinguishes MAE from contrastive learning and related methods. In MAE, the random masking plays the main role of data augmentation.</li>\n</ul>\n<h4 id=\"comparison\">Comparison</h4>\n<p><img src=\"MAE comparison.png\" alt=\"MAE comparison\" style=\"zoom:100%;\" /></p>\n<ul>\n<li>with unsupervised models: not only the accuracy is better, the pre-training time is shorter than the competitors as well</li>\n<li>with supervised models: it indicates that MAE can help scale up model sizes. And the MAE performance on ImageNet1K is similar to the model trained on the 300 times bigger dataset JFT300M. But, considering the number of class of JFT300M is much more than ImageNet1K as well, the result is slightly unfair.</li>\n</ul>\n<h4 id=\"partial-fine-tuning\">Partial Fine-tuning</h4>\n<p>In addition to the full fine-tuning and 0 fine-tuning (linear probing), partial ones are applied by fine tuning fixing several layers. The result indicating at least the last 6 layers are task-related.</p>\n<p><img src=\"MAE fine tune.png\" alt=\"Partial fine-tuning\" style=\"zoom:30%;\" /></p>\n<h3 id=\"transfer-learning-experiments\">Transfer learning experiments</h3>\n<p>At last, down steam tasks are evaluated compared with other frameworks.</p>\n<p><img src=\"MAE segmentation.png\" alt=\"MAE segmentation\" style=\"zoom:60%;\" /></p>\n<p><img src=\"MAE classification.png\" alt=\"MAE classification\" style=\"zoom:61%;\" /></p>\n<p><img src=\"MAE pixels vs tokens.png\" alt=\"MAE pixels vs tokens\" style=\"zoom:62%;\" /></p>\n<h2 id=\"review\">Review</h2>\n<p>Writing, simple but has a very good storyline. From the full introduction of the motivation, to the detailed clear figures explaining each part of the design.</p>\n<p>The algorithm is simple, just applying self-supervised learning to CV based on ViT<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[8]</span></a></sup>. 2 key points are introduced:</p>\n<ul>\n<li>More patches need to be masked</li>\n<li>Transformer decoder to reproduce the pixels instead of a simple linear layer projecting patches into tokens.</li>\n</ul>\n<p>In conclusion, a simple idea, a great result and detailed experiments make this paper a great work.</p>\n<h2 id=\"reference\">Reference</h2>\n<section class=\"footnotes\">\n<div class=\"footnote-list\">\n<ol>\n<li>\n<span id=\"fn:1\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/1810.04805\">Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. <em>arXiv preprint arXiv:1810.04805</em>.</a> <a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:2\" class=\"footnote-text\"><span><a href=\"https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf\">Radford, A., Narasimhan, K., Salimans, T., &amp; Sutskever, I. (2018). Improving language understanding by generative pre-training.</a> <a href=\"#fnref:2\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:3\" class=\"footnote-text\"><span><a href=\"https://proceedings.neurips.cc/paper/1993/hash/9e3cfc48eccf81a0d57663e129aef3cb-Abstract.html\">Hinton, G. E., &amp; Zemel, R. (1993). Autoencoders, minimum description length and Helmholtz free energy. <em>Advances in neural information processing systems</em>, <em>6</em>.</a> <a href=\"#fnref:3\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:4\" class=\"footnote-text\"><span><a href=\"https://dl.acm.org/doi/abs/10.1145/1390156.1390294\">Vincent, P., Larochelle, H., Bengio, Y., &amp; Manzagol, P. A. (2008, July). Extracting and composing robust features with denoising autoencoders. In <em>Proceedings of the 25th international conference on Machine learning</em> (pp. 1096-1103).</a> <a href=\"#fnref:4\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:5\" class=\"footnote-text\"><span><a href=\"https://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf?ref=https://githubhelp.com\">Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P. A., &amp; Bottou, L. (2010). Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. <em>Journal of machine learning research</em>, <em>11</em>(12).</a> <a href=\"#fnref:5\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:6\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_cvpr_2016/html/Pathak_Context_Encoders_Feature_CVPR_2016_paper.html\">Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., &amp; Efros, A. A. (2016). Context encoders: Feature learning by inpainting. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp. 2536-2544).</a> <a href=\"#fnref:6\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:7\" class=\"footnote-text\"><span><a href=\"http://proceedings.mlr.press/v119/chen20s.html\">Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., &amp; Sutskever, I. (2020, November). Generative pretraining from pixels. In <em>International Conference on Machine Learning</em> (pp. 1691-1703). PMLR.</a> <a href=\"#fnref:7\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:8\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/2010.11929\">Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. <em>arXiv preprint arXiv:2010.11929</em>.</a> <a href=\"#fnref:8\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:9\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/2106.08254\">Bao, H., Dong, L., &amp; Wei, F. (2021). Beit: Bert pre-training of image transformers. <em>arXiv preprint arXiv:2106.08254</em>.</a> <a href=\"#fnref:9\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:10\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_iccv_2015/html/Wang_Unsupervised_Learning_of_ICCV_2015_paper.html\">Wang, X., &amp; Gupta, A. (2015). Unsupervised learning of visual representations using videos. In <em>Proceedings of the IEEE international conference on computer vision</em> (pp. 2794-2802).</a> <a href=\"#fnref:10\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:11\" class=\"footnote-text\"><span><a href=\"https://link.springer.com/chapter/10.1007/978-3-319-46466-4_5\">Noroozi, M., &amp; Favaro, P. (2016, October). Unsupervised learning of visual representations by solving jigsaw puzzles. In <em>European conference on computer vision</em> (pp. 69-84). Springer, Cham.</a> <a href=\"#fnref:11\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:12\" class=\"footnote-text\"><span><a href=\"https://link.springer.com/chapter/10.1007/978-3-319-46487-9_40\">Zhang, R., Isola, P., &amp; Efros, A. A. (2016, October). Colorful image colorization. In <em>European conference on computer vision</em> (pp. 649-666). Springer, Cham.</a> <a href=\"#fnref:12\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:13\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/1803.07728\">Gidaris, S., Singh, P., &amp; Komodakis, N. (2018). Unsupervised representation learning by predicting image rotations. <em>arXiv preprint arXiv:1803.07728</em>.</a> <a href=\"#fnref:13\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:14\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html\">Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp. 3733-3742).</a> <a href=\"#fnref:14\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:15\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/1807.03748\">Oord, A. V. D., Li, Y., &amp; Vinyals, O. (2018). Representation learning with contrastive predictive coding. <em>arXiv preprint arXiv:1807.03748</em>.</a> <a href=\"#fnref:15\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:16\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html\">He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em> (pp. 9729-9738).</a> <a href=\"#fnref:16\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:17\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/1706.03762\">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... &amp; Polosukhin, I. (2017). Attention is all you need. <em>Advances in neural information processing systems</em>, <em>30</em>.</a> <a href=\"#fnref:17\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n</ol>\n</div>\n</section>"},{"title":"ResNet","author":"Ryan LI","toc":true,"declare":true,"date":"2022-04-09T12:42:00.000Z","index_img":"/index/paper-reading-ResNet.png","_content":"\n> Since its introduction in 2015, ResNet and its variants have accounted for 50% of deep neural networks in use. The idea of \"Residual\" has been proved to be efficient and important to deep NN.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\npaper link: [Deep residual learning for image recognition](http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)\n\nuseful link: https://www.bilibili.com/video/BV1Fb4y1h73E\n\n## Notes by sections\n\n### 0. Abstract \n\n> An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.\n>\n> Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset\n\nNot only the 1st place results on several tasks but the potential to train a 1000-layer network made this Residual framework a huge attention. \n\nUnfortunately, due to the 8-page limitation of CDPR, and the massive number of results to be presented, there is no room for the conclusion section in this paper. \n\n### Key figure\n\n<img src=\"ResNet figure 4.png\" alt=\"ResNet figure 1\" style=\"zoom:80%;\" />\n\nThis is the key figure showing that the degradation in accuracy caused by the depth in plain networks has been well addressed in ResNet.\n\n### 1. Introduction \n\nThis section first presents the need of training deeper neural network. And the first obstacle that encountered during this process is non-convergence cause by gradient vanishing / explosion, and it has been well addressed by normalised initialisation and intermediate normalisation layers.\n\nAnd the main focus of this paper is the second obstacle i.e. deeper networks have difficulty converging to lower losses and may perform worse than networks with fewer layers. And they addressed this obstacle by introducing the Residual learning framework as shown in the pic below. And this framework is easy to implement  in [caffe](https://caffe.berkeleyvision.org/), the most popular DL framework back to 2015.\n\n<img src=\"ResNet figure 2.png\" alt=\"ResNet figure 2\" style=\"zoom:30%;\" />\n\nAfterwards experiments results are briefly mentioned. \nThe introduction section played as an expanded version of the abstract and the residual method is mainly focused, which is helpful for readers to catch the essence of the whole paper.\n\n### 2. Related work\n\n#### Residual representation\n\nActually the concept of residual is more common in the fields of statistics and machine learning. For example in linear regression, the residual denotes the distance between the estimated and the actual results (residual=y- y  in 2D). And the iterative process of calculating the regression line aims to minimise the mean square of the residual loss. In addition, the well-known GB gradient boosting algorithm for machine learning is also based on the residual loss.\n\nBecause this paper mainly focus on computer vision, so these early work isn't included.\n\n#### Shortcut connections\n\nIt looks like this paper combines these two well-studied approaches with amazing results. First ideas are not necessary to make a paper a classic. Just like the quote on the Google Scholar homepage: *stand on the shoulders of giants.*\n\n### 3. Deep Residual Learning\n\n> Let us consider H(x) as an **underlying mapping** to be fit by a few stacked layers (not necessarily the entire net), with x denoting the inputs to the first of these layers.\n\nFirst is the meaning of H(x), underlying mapping is actually intuitive but it confused me for a while, so here's the answer below:\n\n[What does the phrase 'underlying mapping' mean? - Data Science Stack](https://datascience.stackexchange.com/questions/92617/what-does-the-phrase-underlying-mapping-mean)\n\n> > Functions map domains to ranges. Neural networks learn such functions, so you can think of a neural network as a mapping of input spaces to output spaces. Deep neural networks are stacked with many layers of course, and each of those can be viewed as sub-functions of the network with their own underlying mappings. For example, each layer in a convolution network consists of some convolution layers + some other helper layers such as normalisation and pooling.\n\nNext the paper brings up 2 methods to address the shape difference between X the input and H(x) the output for one particular layer that may occur. Option (A): 0 padding and Option (B): 1*1 convolution to project the channel and pooling with stride to adjust the height and width.\n\n### 4. Experiments\n\n#### Identity vs. Projection Shortcuts\n\n<img src=\"  ResNet table 3.png\" alt=\"ResNet table 3\" style=\"zoom:30%;\" />\n\nAfter introducing the well known architectures, the 2 methods to address the shape difference are also studied. 3 groups are studies,  Option (A): 0 padding,  Option (B): projection when necessary, Option (C): projection to all layers. And because of the increasing of parameters caused by the projection, it is not surprise to discover C is better than B than A. And Option (B) is the winner considering both the performance and the efficiency. \n\n#### Deeper Bottleneck Architectures\n\n<img src=\"  ResNet figure 5.png\" alt=\"ResNet figure 5\" style=\"zoom:30%;\" />\n\nIn ResNet18 and ResNet 34, the standard architecture is fine. But for deeper network, in order to decrease the flops, the bottleneck architectures is deployed. Basically in each residual block, decreasing the number of channel by 1\\*1 convolution first then expend the channel back to the number of input channel. As can be seen in Table 1, the flops of ResNet34 is similar to that in ResNet50. But this is only theory, in practice ResNet50 is obviously more expensive because of the inefficiency of computing 1\\*1 conv.\n\n<img src=\"  ResNet table 1.png\" alt=\"ResNet table 1\" style=\"zoom:80%;\" />\n\n#### Exploring Over 1000 layers\n\n<img src=\"ResNet table 6.png\" alt=\"ResNet table 6\" style=\"zoom:30%;\" />\n\nNetworks with layer numbers from 20 to 1202 are applied on dataset CIFAR-10 (With only output size 32\\*32 compared with >300\\*300 on ImageNet, the networks are slightly modified). And the results shows that even with an aggressive depth on a tiny dataset, no difficulty of optimisation occurs. Yet shown on Table6, the test set classification error goes up compared with the shallower models because of the overfitting.\n\n## Some Reviews\n\nThis is a model with relatively simple idea and the authors have a great writing skill to make this paper neat and clear.\n\nThe main contribution of this paper is introducing the residual block and skipping connection in deep learning.\n\nAlthough the authors intuitively explain and provide some experiments, the explanation is not currently accepted by the mainstream. Today, the reason why ResNet can achieve better results than ordinary networks is mainly because of its property of preventing vanishing gradients. The ordinary network without the residual framework cannot be trained in the later stage of training.\n\nIt's still an open question why the 1000-layer network has low level of overfitting on a simple dataset. The same question is good performance on large networks such as the transformer series. One explanation is that despite the large network size, the intrinsic model complexity is low.\n\n","source":"_posts/paper-reading-ResNet.md","raw":"---\ntitle: 'ResNet'\nauthor: Ryan LI\ntoc: true\ndeclare: true\ndate: 2022-04-09 20:42:00\nindex_img: /index/paper-reading-ResNet.png\ntags:\n  - paper reading\n  - deep learning\n---\n\n> Since its introduction in 2015, ResNet and its variants have accounted for 50% of deep neural networks in use. The idea of \"Residual\" has been proved to be efficient and important to deep NN.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\npaper link: [Deep residual learning for image recognition](http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)\n\nuseful link: https://www.bilibili.com/video/BV1Fb4y1h73E\n\n## Notes by sections\n\n### 0. Abstract \n\n> An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.\n>\n> Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset\n\nNot only the 1st place results on several tasks but the potential to train a 1000-layer network made this Residual framework a huge attention. \n\nUnfortunately, due to the 8-page limitation of CDPR, and the massive number of results to be presented, there is no room for the conclusion section in this paper. \n\n### Key figure\n\n<img src=\"ResNet figure 4.png\" alt=\"ResNet figure 1\" style=\"zoom:80%;\" />\n\nThis is the key figure showing that the degradation in accuracy caused by the depth in plain networks has been well addressed in ResNet.\n\n### 1. Introduction \n\nThis section first presents the need of training deeper neural network. And the first obstacle that encountered during this process is non-convergence cause by gradient vanishing / explosion, and it has been well addressed by normalised initialisation and intermediate normalisation layers.\n\nAnd the main focus of this paper is the second obstacle i.e. deeper networks have difficulty converging to lower losses and may perform worse than networks with fewer layers. And they addressed this obstacle by introducing the Residual learning framework as shown in the pic below. And this framework is easy to implement  in [caffe](https://caffe.berkeleyvision.org/), the most popular DL framework back to 2015.\n\n<img src=\"ResNet figure 2.png\" alt=\"ResNet figure 2\" style=\"zoom:30%;\" />\n\nAfterwards experiments results are briefly mentioned. \nThe introduction section played as an expanded version of the abstract and the residual method is mainly focused, which is helpful for readers to catch the essence of the whole paper.\n\n### 2. Related work\n\n#### Residual representation\n\nActually the concept of residual is more common in the fields of statistics and machine learning. For example in linear regression, the residual denotes the distance between the estimated and the actual results (residual=y- y  in 2D). And the iterative process of calculating the regression line aims to minimise the mean square of the residual loss. In addition, the well-known GB gradient boosting algorithm for machine learning is also based on the residual loss.\n\nBecause this paper mainly focus on computer vision, so these early work isn't included.\n\n#### Shortcut connections\n\nIt looks like this paper combines these two well-studied approaches with amazing results. First ideas are not necessary to make a paper a classic. Just like the quote on the Google Scholar homepage: *stand on the shoulders of giants.*\n\n### 3. Deep Residual Learning\n\n> Let us consider H(x) as an **underlying mapping** to be fit by a few stacked layers (not necessarily the entire net), with x denoting the inputs to the first of these layers.\n\nFirst is the meaning of H(x), underlying mapping is actually intuitive but it confused me for a while, so here's the answer below:\n\n[What does the phrase 'underlying mapping' mean? - Data Science Stack](https://datascience.stackexchange.com/questions/92617/what-does-the-phrase-underlying-mapping-mean)\n\n> > Functions map domains to ranges. Neural networks learn such functions, so you can think of a neural network as a mapping of input spaces to output spaces. Deep neural networks are stacked with many layers of course, and each of those can be viewed as sub-functions of the network with their own underlying mappings. For example, each layer in a convolution network consists of some convolution layers + some other helper layers such as normalisation and pooling.\n\nNext the paper brings up 2 methods to address the shape difference between X the input and H(x) the output for one particular layer that may occur. Option (A): 0 padding and Option (B): 1*1 convolution to project the channel and pooling with stride to adjust the height and width.\n\n### 4. Experiments\n\n#### Identity vs. Projection Shortcuts\n\n<img src=\"  ResNet table 3.png\" alt=\"ResNet table 3\" style=\"zoom:30%;\" />\n\nAfter introducing the well known architectures, the 2 methods to address the shape difference are also studied. 3 groups are studies,  Option (A): 0 padding,  Option (B): projection when necessary, Option (C): projection to all layers. And because of the increasing of parameters caused by the projection, it is not surprise to discover C is better than B than A. And Option (B) is the winner considering both the performance and the efficiency. \n\n#### Deeper Bottleneck Architectures\n\n<img src=\"  ResNet figure 5.png\" alt=\"ResNet figure 5\" style=\"zoom:30%;\" />\n\nIn ResNet18 and ResNet 34, the standard architecture is fine. But for deeper network, in order to decrease the flops, the bottleneck architectures is deployed. Basically in each residual block, decreasing the number of channel by 1\\*1 convolution first then expend the channel back to the number of input channel. As can be seen in Table 1, the flops of ResNet34 is similar to that in ResNet50. But this is only theory, in practice ResNet50 is obviously more expensive because of the inefficiency of computing 1\\*1 conv.\n\n<img src=\"  ResNet table 1.png\" alt=\"ResNet table 1\" style=\"zoom:80%;\" />\n\n#### Exploring Over 1000 layers\n\n<img src=\"ResNet table 6.png\" alt=\"ResNet table 6\" style=\"zoom:30%;\" />\n\nNetworks with layer numbers from 20 to 1202 are applied on dataset CIFAR-10 (With only output size 32\\*32 compared with >300\\*300 on ImageNet, the networks are slightly modified). And the results shows that even with an aggressive depth on a tiny dataset, no difficulty of optimisation occurs. Yet shown on Table6, the test set classification error goes up compared with the shallower models because of the overfitting.\n\n## Some Reviews\n\nThis is a model with relatively simple idea and the authors have a great writing skill to make this paper neat and clear.\n\nThe main contribution of this paper is introducing the residual block and skipping connection in deep learning.\n\nAlthough the authors intuitively explain and provide some experiments, the explanation is not currently accepted by the mainstream. Today, the reason why ResNet can achieve better results than ordinary networks is mainly because of its property of preventing vanishing gradients. The ordinary network without the residual framework cannot be trained in the later stage of training.\n\nIt's still an open question why the 1000-layer network has low level of overfitting on a simple dataset. The same question is good performance on large networks such as the transformer series. One explanation is that despite the large network size, the intrinsic model complexity is low.\n\n","slug":"paper-reading-ResNet","published":1,"updated":"2022-06-09T10:25:07.255Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz2a001xl8yb63ef2cd0","content":"<blockquote>\n<p>Since its introduction in 2015, ResNet and its variants have accounted for 50% of deep neural networks in use. The idea of \"Residual\" has been proved to be efficient and important to deep NN.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>\n<span id=\"more\"></span>\n<p>paper link: <a href=\"http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html\">Deep residual learning for image recognition</a></p>\n<p>useful link: https://www.bilibili.com/video/BV1Fb4y1h73E</p>\n<h2 id=\"notes-by-sections\">Notes by sections</h2>\n<h3 id=\"abstract\">0. Abstract</h3>\n<blockquote>\n<p>An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.</p>\n<p>Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset</p>\n</blockquote>\n<p>Not only the 1st place results on several tasks but the potential to train a 1000-layer network made this Residual framework a huge attention.</p>\n<p>Unfortunately, due to the 8-page limitation of CDPR, and the massive number of results to be presented, there is no room for the conclusion section in this paper.</p>\n<h3 id=\"key-figure\">Key figure</h3>\n<p><img src=\"ResNet figure 4.png\" srcset=\"/img/loading.gif\" lazyload alt=\"ResNet figure 1\" style=\"zoom:80%;\" /></p>\n<p>This is the key figure showing that the degradation in accuracy caused by the depth in plain networks has been well addressed in ResNet.</p>\n<h3 id=\"introduction\">1. Introduction</h3>\n<p>This section first presents the need of training deeper neural network. And the first obstacle that encountered during this process is non-convergence cause by gradient vanishing / explosion, and it has been well addressed by normalised initialisation and intermediate normalisation layers.</p>\n<p>And the main focus of this paper is the second obstacle i.e. deeper networks have difficulty converging to lower losses and may perform worse than networks with fewer layers. And they addressed this obstacle by introducing the Residual learning framework as shown in the pic below. And this framework is easy to implement in <a href=\"https://caffe.berkeleyvision.org/\">caffe</a>, the most popular DL framework back to 2015.</p>\n<p><img src=\"ResNet figure 2.png\" srcset=\"/img/loading.gif\" lazyload alt=\"ResNet figure 2\" style=\"zoom:30%;\" /></p>\n<p>Afterwards experiments results are briefly mentioned. The introduction section played as an expanded version of the abstract and the residual method is mainly focused, which is helpful for readers to catch the essence of the whole paper.</p>\n<h3 id=\"related-work\">2. Related work</h3>\n<h4 id=\"residual-representation\">Residual representation</h4>\n<p>Actually the concept of residual is more common in the fields of statistics and machine learning. For example in linear regression, the residual denotes the distance between the estimated and the actual results (residual=y- y  in 2D). And the iterative process of calculating the regression line aims to minimise the mean square of the residual loss. In addition, the well-known GB gradient boosting algorithm for machine learning is also based on the residual loss.</p>\n<p>Because this paper mainly focus on computer vision, so these early work isn't included.</p>\n<h4 id=\"shortcut-connections\">Shortcut connections</h4>\n<p>It looks like this paper combines these two well-studied approaches with amazing results. First ideas are not necessary to make a paper a classic. Just like the quote on the Google Scholar homepage: <em>stand on the shoulders of giants.</em></p>\n<h3 id=\"deep-residual-learning\">3. Deep Residual Learning</h3>\n<blockquote>\n<p>Let us consider H(x) as an <strong>underlying mapping</strong> to be fit by a few stacked layers (not necessarily the entire net), with x denoting the inputs to the first of these layers.</p>\n</blockquote>\n<p>First is the meaning of H(x), underlying mapping is actually intuitive but it confused me for a while, so here's the answer below:</p>\n<p><a href=\"https://datascience.stackexchange.com/questions/92617/what-does-the-phrase-underlying-mapping-mean\">What does the phrase 'underlying mapping' mean? - Data Science Stack</a></p>\n<blockquote>\n<blockquote>\n<p>Functions map domains to ranges. Neural networks learn such functions, so you can think of a neural network as a mapping of input spaces to output spaces. Deep neural networks are stacked with many layers of course, and each of those can be viewed as sub-functions of the network with their own underlying mappings. For example, each layer in a convolution network consists of some convolution layers + some other helper layers such as normalisation and pooling.</p>\n</blockquote>\n</blockquote>\n<p>Next the paper brings up 2 methods to address the shape difference between X the input and H(x) the output for one particular layer that may occur. Option (A): 0 padding and Option (B): 1*1 convolution to project the channel and pooling with stride to adjust the height and width.</p>\n<h3 id=\"experiments\">4. Experiments</h3>\n<h4 id=\"identity-vs.-projection-shortcuts\">Identity vs. Projection Shortcuts</h4>\n<p><img src=\"  ResNet table 3.png\" srcset=\"/img/loading.gif\" lazyload alt=\"ResNet table 3\" style=\"zoom:30%;\" /></p>\n<p>After introducing the well known architectures, the 2 methods to address the shape difference are also studied. 3 groups are studies, Option (A): 0 padding, Option (B): projection when necessary, Option (C): projection to all layers. And because of the increasing of parameters caused by the projection, it is not surprise to discover C is better than B than A. And Option (B) is the winner considering both the performance and the efficiency.</p>\n<h4 id=\"deeper-bottleneck-architectures\">Deeper Bottleneck Architectures</h4>\n<p><img src=\"  ResNet figure 5.png\" srcset=\"/img/loading.gif\" lazyload alt=\"ResNet figure 5\" style=\"zoom:30%;\" /></p>\n<p>In ResNet18 and ResNet 34, the standard architecture is fine. But for deeper network, in order to decrease the flops, the bottleneck architectures is deployed. Basically in each residual block, decreasing the number of channel by 1*1 convolution first then expend the channel back to the number of input channel. As can be seen in Table 1, the flops of ResNet34 is similar to that in ResNet50. But this is only theory, in practice ResNet50 is obviously more expensive because of the inefficiency of computing 1*1 conv.</p>\n<p><img src=\"  ResNet table 1.png\" srcset=\"/img/loading.gif\" lazyload alt=\"ResNet table 1\" style=\"zoom:80%;\" /></p>\n<h4 id=\"exploring-over-1000-layers\">Exploring Over 1000 layers</h4>\n<p><img src=\"ResNet table 6.png\" srcset=\"/img/loading.gif\" lazyload alt=\"ResNet table 6\" style=\"zoom:30%;\" /></p>\n<p>Networks with layer numbers from 20 to 1202 are applied on dataset CIFAR-10 (With only output size 32*32 compared with &gt;300*300 on ImageNet, the networks are slightly modified). And the results shows that even with an aggressive depth on a tiny dataset, no difficulty of optimisation occurs. Yet shown on Table6, the test set classification error goes up compared with the shallower models because of the overfitting.</p>\n<h2 id=\"some-reviews\">Some Reviews</h2>\n<p>This is a model with relatively simple idea and the authors have a great writing skill to make this paper neat and clear.</p>\n<p>The main contribution of this paper is introducing the residual block and skipping connection in deep learning.</p>\n<p>Although the authors intuitively explain and provide some experiments, the explanation is not currently accepted by the mainstream. Today, the reason why ResNet can achieve better results than ordinary networks is mainly because of its property of preventing vanishing gradients. The ordinary network without the residual framework cannot be trained in the later stage of training.</p>\n<p>It's still an open question why the 1000-layer network has low level of overfitting on a simple dataset. The same question is good performance on large networks such as the transformer series. One explanation is that despite the large network size, the intrinsic model complexity is low.</p>\n","site":{"data":{}},"wordcount":5514,"excerpt":"<blockquote>\n<p>Since its introduction in 2015, ResNet and its variants have accounted for 50% of deep neural networks in use. The idea of \"Residual\" has been proved to be efficient and important to deep NN.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>","more":"<p>paper link: <a href=\"http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html\">Deep residual learning for image recognition</a></p>\n<p>useful link: https://www.bilibili.com/video/BV1Fb4y1h73E</p>\n<h2 id=\"notes-by-sections\">Notes by sections</h2>\n<h3 id=\"abstract\">0. Abstract</h3>\n<blockquote>\n<p>An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.</p>\n<p>Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset</p>\n</blockquote>\n<p>Not only the 1st place results on several tasks but the potential to train a 1000-layer network made this Residual framework a huge attention.</p>\n<p>Unfortunately, due to the 8-page limitation of CDPR, and the massive number of results to be presented, there is no room for the conclusion section in this paper.</p>\n<h3 id=\"key-figure\">Key figure</h3>\n<p><img src=\"ResNet figure 4.png\" alt=\"ResNet figure 1\" style=\"zoom:80%;\" /></p>\n<p>This is the key figure showing that the degradation in accuracy caused by the depth in plain networks has been well addressed in ResNet.</p>\n<h3 id=\"introduction\">1. Introduction</h3>\n<p>This section first presents the need of training deeper neural network. And the first obstacle that encountered during this process is non-convergence cause by gradient vanishing / explosion, and it has been well addressed by normalised initialisation and intermediate normalisation layers.</p>\n<p>And the main focus of this paper is the second obstacle i.e. deeper networks have difficulty converging to lower losses and may perform worse than networks with fewer layers. And they addressed this obstacle by introducing the Residual learning framework as shown in the pic below. And this framework is easy to implement in <a href=\"https://caffe.berkeleyvision.org/\">caffe</a>, the most popular DL framework back to 2015.</p>\n<p><img src=\"ResNet figure 2.png\" alt=\"ResNet figure 2\" style=\"zoom:30%;\" /></p>\n<p>Afterwards experiments results are briefly mentioned. The introduction section played as an expanded version of the abstract and the residual method is mainly focused, which is helpful for readers to catch the essence of the whole paper.</p>\n<h3 id=\"related-work\">2. Related work</h3>\n<h4 id=\"residual-representation\">Residual representation</h4>\n<p>Actually the concept of residual is more common in the fields of statistics and machine learning. For example in linear regression, the residual denotes the distance between the estimated and the actual results (residual=y- y  in 2D). And the iterative process of calculating the regression line aims to minimise the mean square of the residual loss. In addition, the well-known GB gradient boosting algorithm for machine learning is also based on the residual loss.</p>\n<p>Because this paper mainly focus on computer vision, so these early work isn't included.</p>\n<h4 id=\"shortcut-connections\">Shortcut connections</h4>\n<p>It looks like this paper combines these two well-studied approaches with amazing results. First ideas are not necessary to make a paper a classic. Just like the quote on the Google Scholar homepage: <em>stand on the shoulders of giants.</em></p>\n<h3 id=\"deep-residual-learning\">3. Deep Residual Learning</h3>\n<blockquote>\n<p>Let us consider H(x) as an <strong>underlying mapping</strong> to be fit by a few stacked layers (not necessarily the entire net), with x denoting the inputs to the first of these layers.</p>\n</blockquote>\n<p>First is the meaning of H(x), underlying mapping is actually intuitive but it confused me for a while, so here's the answer below:</p>\n<p><a href=\"https://datascience.stackexchange.com/questions/92617/what-does-the-phrase-underlying-mapping-mean\">What does the phrase 'underlying mapping' mean? - Data Science Stack</a></p>\n<blockquote>\n<blockquote>\n<p>Functions map domains to ranges. Neural networks learn such functions, so you can think of a neural network as a mapping of input spaces to output spaces. Deep neural networks are stacked with many layers of course, and each of those can be viewed as sub-functions of the network with their own underlying mappings. For example, each layer in a convolution network consists of some convolution layers + some other helper layers such as normalisation and pooling.</p>\n</blockquote>\n</blockquote>\n<p>Next the paper brings up 2 methods to address the shape difference between X the input and H(x) the output for one particular layer that may occur. Option (A): 0 padding and Option (B): 1*1 convolution to project the channel and pooling with stride to adjust the height and width.</p>\n<h3 id=\"experiments\">4. Experiments</h3>\n<h4 id=\"identity-vs.-projection-shortcuts\">Identity vs. Projection Shortcuts</h4>\n<p><img src=\"  ResNet table 3.png\" alt=\"ResNet table 3\" style=\"zoom:30%;\" /></p>\n<p>After introducing the well known architectures, the 2 methods to address the shape difference are also studied. 3 groups are studies, Option (A): 0 padding, Option (B): projection when necessary, Option (C): projection to all layers. And because of the increasing of parameters caused by the projection, it is not surprise to discover C is better than B than A. And Option (B) is the winner considering both the performance and the efficiency.</p>\n<h4 id=\"deeper-bottleneck-architectures\">Deeper Bottleneck Architectures</h4>\n<p><img src=\"  ResNet figure 5.png\" alt=\"ResNet figure 5\" style=\"zoom:30%;\" /></p>\n<p>In ResNet18 and ResNet 34, the standard architecture is fine. But for deeper network, in order to decrease the flops, the bottleneck architectures is deployed. Basically in each residual block, decreasing the number of channel by 1*1 convolution first then expend the channel back to the number of input channel. As can be seen in Table 1, the flops of ResNet34 is similar to that in ResNet50. But this is only theory, in practice ResNet50 is obviously more expensive because of the inefficiency of computing 1*1 conv.</p>\n<p><img src=\"  ResNet table 1.png\" alt=\"ResNet table 1\" style=\"zoom:80%;\" /></p>\n<h4 id=\"exploring-over-1000-layers\">Exploring Over 1000 layers</h4>\n<p><img src=\"ResNet table 6.png\" alt=\"ResNet table 6\" style=\"zoom:30%;\" /></p>\n<p>Networks with layer numbers from 20 to 1202 are applied on dataset CIFAR-10 (With only output size 32*32 compared with &gt;300*300 on ImageNet, the networks are slightly modified). And the results shows that even with an aggressive depth on a tiny dataset, no difficulty of optimisation occurs. Yet shown on Table6, the test set classification error goes up compared with the shallower models because of the overfitting.</p>\n<h2 id=\"some-reviews\">Some Reviews</h2>\n<p>This is a model with relatively simple idea and the authors have a great writing skill to make this paper neat and clear.</p>\n<p>The main contribution of this paper is introducing the residual block and skipping connection in deep learning.</p>\n<p>Although the authors intuitively explain and provide some experiments, the explanation is not currently accepted by the mainstream. Today, the reason why ResNet can achieve better results than ordinary networks is mainly because of its property of preventing vanishing gradients. The ordinary network without the residual framework cannot be trained in the later stage of training.</p>\n<p>It's still an open question why the 1000-layer network has low level of overfitting on a simple dataset. The same question is good performance on large networks such as the transformer series. One explanation is that despite the large network size, the intrinsic model complexity is low.</p>"},{"title":"AlexNet","author":"Ryan LI","toc":true,"declare":true,"date":"2022-04-07T14:25:50.000Z","index_img":"/index/paper-reading-AlexNet.png","_content":"\n> It has been 10 years since AlexNet has been brought out. It is one of the cornerstones of this surge of deep learning.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\npaper link: [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)\n\nuseful link: https://www.bilibili.com/video/BV1ih411J7Kz\n\n## Little history\n\nIt hasn't gotten much attention by the area of machine learning for the first 2-3 years since it got published, because this paper is written rather as a technical report than an academic paper. A good paper needs new thoughts for the model, or at least some explanations, while this paper only presented how they applied 3 tricks and how good their results are. However, there was no doubt an influential hit in the area of computer vision, which has a passion for refreshing the top list. And this influence spread to other areas gradually with deeper studies on it.\n\n## Notes by sections\n\n### 0. Absturct \n\n> To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation.\n\nIn addition to a brief introduction to the model, the use of GPU is also mentioned in the abstract. And works around GPU are mentioned all the time. It was really a tough engineering job from the perspective of the first writer.  But it is not important for an acdemic paper. Besides, since the emergence of CUDA in 2007, the application of GPU in the ML field in 2012 is not uncommon, and MATLAB is mainly used as a ML tool with a large number of GPU acceleration libraries.\n\n> We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry\n\nAt last, the result in the ILSVRC-2012 competition is as good as knocking the second to the ground and then showing off with a set of backflips. So personally it might look like a technical report, but it's still an outstanding paper and absolutly worth reading.\n\n### 7. Discussion\n\nIn stead of conclusion, this paper leaves a discussion as the last section, which is unsual.\n\n> For example, removing any of the middle layers results in a loss of about 2% for the top-1 performance of the network. So the depth really is important for achieving our results\n\nThe depth is important, but it is insufficient to be simply concluded from the degradation caused by removing one middle layer, ignoring other effects such as superparameter settings. And, considering only the conculsion, a more complete one might be, depth and width are both very important. The ratio of height and width matters.\n\n> To simplify our experiments, we did not use any unsupervised pre-training even though we expect that it will help\n\nBefore AlexNet, it was common to warm up the NN with massive unlabelled images before the actual training i.e. use an unsupervised model as an initial. And the goal of the field of machine learning was to extract the features of data through large-scale unsupervised models. However, this sentence steered the entire field from unsupervised to supervised learning, which, according to the machine learning pioneers such as Hinton and LeCun, was a \"wrong route\". But with the rise of the pre-trained language models such as Bert, and the contrative learning model in CV field such as MoCo, the unsupervised route is gradually comming back to the foreground. \n\n<img src=\"unsupervise learning cake.png\" alt=\"unsupervise learning cake\" style=\"zoom:80%;\" />\n\n> Ultimately we would like to use very large and deep convolutional nets on video sequences where the temporal structure provides very helpful information that is missing or far less obvious in static images.\n\nActually video sequences are still a tough area beacause of the high computational comsumpution and the copyright issues.\n\n### Key figure\n\n<img src=\"alexnet results.png\" alt=\"alexnet results\" style=\"zoom:67%;\" />\n\nThe right part is the most important result in this paper, though it isn't been discussed much in this paper. Actually it shows the last layer feature vectors perform really well in the semantic space i.e. deep neural network is very suitable to extract features from data.\n\n### 1. Introduction\n\n> To improve their performance, we can collect larger datasets, learn more powerful models, and use better techniques for preventing overfitting.\n\nThe paper leads one route of deep learning, which is, with large dataset and model, developing powerful regularization methods to prevent overfitting. However there is a new route, which is focusing on designing good architecture s.t. the overfitting won't happen with large model.\n\n> Our network contains a number of new and unusual features which improve its performance and reduce its training time, which are detailed in Section 3.\n\n> we used several effective techniques for preventing overfitting, which are described in Section 4.\n\nThese two are the innovative points. People can then follow their work later, which makes this paper a cornerstone.\n\n### 2. Dataset\n\n> We did not pre-process the images in any other way, except for subtracting the mean activity over the training set from each pixel. So we trained our network on the (centered) raw RGB values of the pixels.\n\nThere is one more point that is not emphasized. Previously, features of an image (such as SIFT) were always used as input instead of raw RGB values. Datasets such as ImageNet provided SIFT of their image set as well. The end-to-end nature is the selling point of a series of deep learning papers that follow.\n\n### 3. Architecture\n\n#### 3.1. ReLU\n\nFrom a present point of view, ReLU is not that important for speeding up the training process. Other  activation functions still work. It's the simplicity of ReLU that makes it stick.\n\n### 4. Reducing Overfitting\n\nA metaphore of overfitting: In order to get a high score on an exam, you memorize all the answers to the exercises instead of understanding the question.\n\n#### 4.1 Data Augmentation\n\n> The second form of data augmentation consists of altering the intensities of the RGB channels in training images. Specifically, we perform PCA on the set of RGB pixel values throughout the ImageNet training set.\n\nPCA is here use as a augmentation method which follow-up work don't follow. For example, in ResNet a standard color augmentation is used with no fancy methods. And nowadays, standard color augmentation wins.\n\n#### 4.2 dropout\n\n> There is, however, a very efficient version of model combination that only costs about a factor of two during training. The recently-introduced technique, called dropout\n\nHere dropout is considered a light version of model ensembling, but later [study below](https://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf) has shown that the effect of dropout is actually equivalent to weight decay/regularization, yet there is no specific weight decay method equivalent to it algorithmically.\n\n>> one way to obtain some of the benefits of dropout without stochasticity is to marginalize the noise to obtain a regularizer that does the same thing as the dropout procedure, in expectation. We showed that for linear regression this regularizer is a modified form of L2 regularization. For more complicated models, it is not obvious how to obtain an equivalent regularizer. \n\n### 5. Details of learning\n\n> we trained our models using stochastic gradient descent with a batch size of 128 examples, momentum of 0.9, and weight decay of 0.0005\n\nmomentum, weight decay with SGD has become a standard method afterwards.\n\n> We initialized the weights in each layer from a zero-mean Gaussian distribution with standard deviation 0.01\n\n(0, 0.01) is usually chosen as the initialization parameter pair in most standard-sized models. (0, 0.02) is in use even for large models like Bert.\n\n> We trained the network for roughly 90 cycles through the training set of 1.2 million images, which took five to six days on two NVIDIA GTX 580 3GB GPUs.\n\nSimilar to what is happening now with training NLP, maybe it will drive the next evolution in hardware. And probably hardware similar to TPU would be popular.\n\n### 6. Results\n\n#### 6.1 Qualitative Evaluations\n\n> The kernels on GPU 1 are largely color-agnostic, while the kernels on on GPU 2 are largely color-specific. The kernels on GPU 1 are largely color-agnostic, while the kernels on on GPU 2 are largely color-specific\n\nInteresting problem but less focused by follow up work.\n\n> consider the feature activations induced by an image at the last, 4096-dimensional hidden layer. If two images produce feature activation vectors with a small Euclidean separation, we can say that the higher levels of the neural network consider them to be similar.\n\nThis is an intuitive work as talked before, and follow up work such as [Visualizing and understanding convolutional networks ](https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53) dig deeper trying to interperate the NN. And interpretion is very important for works related to physics or [fairness](https://ieeexplore.ieee.org/abstract/document/9113719/).\n\n## Reference\n\n[Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. *The journal of machine learning research*, *15*(1), 1929-1958.](https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer,)\n\n[Zeiler, M. D., & Fergus, R. (2014, September). Visualizing and understanding convolutional networks. In *European conference on computer vision* (pp. 818-833). Springer, Cham.](https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53)\n\n[Du, M., Yang, F., Zou, N., & Hu, X. (2020). Fairness in deep learning: A computational perspective. *IEEE Intelligent Systems*, *36*(4), 25-34.](https://ieeexplore.ieee.org/abstract/document/9113719/)\n","source":"_posts/paper-reading-AlexNet.md","raw":"---\ntitle: 'AlexNet'\nauthor: Ryan LI\ntoc: true\ndeclare: true\ndate: 2022-04-07 22:25:50\nindex_img: /index/paper-reading-AlexNet.png\ntags:\n  - paper reading\n  - deep learning\n---\n\n> It has been 10 years since AlexNet has been brought out. It is one of the cornerstones of this surge of deep learning.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\npaper link: [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)\n\nuseful link: https://www.bilibili.com/video/BV1ih411J7Kz\n\n## Little history\n\nIt hasn't gotten much attention by the area of machine learning for the first 2-3 years since it got published, because this paper is written rather as a technical report than an academic paper. A good paper needs new thoughts for the model, or at least some explanations, while this paper only presented how they applied 3 tricks and how good their results are. However, there was no doubt an influential hit in the area of computer vision, which has a passion for refreshing the top list. And this influence spread to other areas gradually with deeper studies on it.\n\n## Notes by sections\n\n### 0. Absturct \n\n> To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation.\n\nIn addition to a brief introduction to the model, the use of GPU is also mentioned in the abstract. And works around GPU are mentioned all the time. It was really a tough engineering job from the perspective of the first writer.  But it is not important for an acdemic paper. Besides, since the emergence of CUDA in 2007, the application of GPU in the ML field in 2012 is not uncommon, and MATLAB is mainly used as a ML tool with a large number of GPU acceleration libraries.\n\n> We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry\n\nAt last, the result in the ILSVRC-2012 competition is as good as knocking the second to the ground and then showing off with a set of backflips. So personally it might look like a technical report, but it's still an outstanding paper and absolutly worth reading.\n\n### 7. Discussion\n\nIn stead of conclusion, this paper leaves a discussion as the last section, which is unsual.\n\n> For example, removing any of the middle layers results in a loss of about 2% for the top-1 performance of the network. So the depth really is important for achieving our results\n\nThe depth is important, but it is insufficient to be simply concluded from the degradation caused by removing one middle layer, ignoring other effects such as superparameter settings. And, considering only the conculsion, a more complete one might be, depth and width are both very important. The ratio of height and width matters.\n\n> To simplify our experiments, we did not use any unsupervised pre-training even though we expect that it will help\n\nBefore AlexNet, it was common to warm up the NN with massive unlabelled images before the actual training i.e. use an unsupervised model as an initial. And the goal of the field of machine learning was to extract the features of data through large-scale unsupervised models. However, this sentence steered the entire field from unsupervised to supervised learning, which, according to the machine learning pioneers such as Hinton and LeCun, was a \"wrong route\". But with the rise of the pre-trained language models such as Bert, and the contrative learning model in CV field such as MoCo, the unsupervised route is gradually comming back to the foreground. \n\n<img src=\"unsupervise learning cake.png\" alt=\"unsupervise learning cake\" style=\"zoom:80%;\" />\n\n> Ultimately we would like to use very large and deep convolutional nets on video sequences where the temporal structure provides very helpful information that is missing or far less obvious in static images.\n\nActually video sequences are still a tough area beacause of the high computational comsumpution and the copyright issues.\n\n### Key figure\n\n<img src=\"alexnet results.png\" alt=\"alexnet results\" style=\"zoom:67%;\" />\n\nThe right part is the most important result in this paper, though it isn't been discussed much in this paper. Actually it shows the last layer feature vectors perform really well in the semantic space i.e. deep neural network is very suitable to extract features from data.\n\n### 1. Introduction\n\n> To improve their performance, we can collect larger datasets, learn more powerful models, and use better techniques for preventing overfitting.\n\nThe paper leads one route of deep learning, which is, with large dataset and model, developing powerful regularization methods to prevent overfitting. However there is a new route, which is focusing on designing good architecture s.t. the overfitting won't happen with large model.\n\n> Our network contains a number of new and unusual features which improve its performance and reduce its training time, which are detailed in Section 3.\n\n> we used several effective techniques for preventing overfitting, which are described in Section 4.\n\nThese two are the innovative points. People can then follow their work later, which makes this paper a cornerstone.\n\n### 2. Dataset\n\n> We did not pre-process the images in any other way, except for subtracting the mean activity over the training set from each pixel. So we trained our network on the (centered) raw RGB values of the pixels.\n\nThere is one more point that is not emphasized. Previously, features of an image (such as SIFT) were always used as input instead of raw RGB values. Datasets such as ImageNet provided SIFT of their image set as well. The end-to-end nature is the selling point of a series of deep learning papers that follow.\n\n### 3. Architecture\n\n#### 3.1. ReLU\n\nFrom a present point of view, ReLU is not that important for speeding up the training process. Other  activation functions still work. It's the simplicity of ReLU that makes it stick.\n\n### 4. Reducing Overfitting\n\nA metaphore of overfitting: In order to get a high score on an exam, you memorize all the answers to the exercises instead of understanding the question.\n\n#### 4.1 Data Augmentation\n\n> The second form of data augmentation consists of altering the intensities of the RGB channels in training images. Specifically, we perform PCA on the set of RGB pixel values throughout the ImageNet training set.\n\nPCA is here use as a augmentation method which follow-up work don't follow. For example, in ResNet a standard color augmentation is used with no fancy methods. And nowadays, standard color augmentation wins.\n\n#### 4.2 dropout\n\n> There is, however, a very efficient version of model combination that only costs about a factor of two during training. The recently-introduced technique, called dropout\n\nHere dropout is considered a light version of model ensembling, but later [study below](https://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf) has shown that the effect of dropout is actually equivalent to weight decay/regularization, yet there is no specific weight decay method equivalent to it algorithmically.\n\n>> one way to obtain some of the benefits of dropout without stochasticity is to marginalize the noise to obtain a regularizer that does the same thing as the dropout procedure, in expectation. We showed that for linear regression this regularizer is a modified form of L2 regularization. For more complicated models, it is not obvious how to obtain an equivalent regularizer. \n\n### 5. Details of learning\n\n> we trained our models using stochastic gradient descent with a batch size of 128 examples, momentum of 0.9, and weight decay of 0.0005\n\nmomentum, weight decay with SGD has become a standard method afterwards.\n\n> We initialized the weights in each layer from a zero-mean Gaussian distribution with standard deviation 0.01\n\n(0, 0.01) is usually chosen as the initialization parameter pair in most standard-sized models. (0, 0.02) is in use even for large models like Bert.\n\n> We trained the network for roughly 90 cycles through the training set of 1.2 million images, which took five to six days on two NVIDIA GTX 580 3GB GPUs.\n\nSimilar to what is happening now with training NLP, maybe it will drive the next evolution in hardware. And probably hardware similar to TPU would be popular.\n\n### 6. Results\n\n#### 6.1 Qualitative Evaluations\n\n> The kernels on GPU 1 are largely color-agnostic, while the kernels on on GPU 2 are largely color-specific. The kernels on GPU 1 are largely color-agnostic, while the kernels on on GPU 2 are largely color-specific\n\nInteresting problem but less focused by follow up work.\n\n> consider the feature activations induced by an image at the last, 4096-dimensional hidden layer. If two images produce feature activation vectors with a small Euclidean separation, we can say that the higher levels of the neural network consider them to be similar.\n\nThis is an intuitive work as talked before, and follow up work such as [Visualizing and understanding convolutional networks ](https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53) dig deeper trying to interperate the NN. And interpretion is very important for works related to physics or [fairness](https://ieeexplore.ieee.org/abstract/document/9113719/).\n\n## Reference\n\n[Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. *The journal of machine learning research*, *15*(1), 1929-1958.](https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer,)\n\n[Zeiler, M. D., & Fergus, R. (2014, September). Visualizing and understanding convolutional networks. In *European conference on computer vision* (pp. 818-833). Springer, Cham.](https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53)\n\n[Du, M., Yang, F., Zou, N., & Hu, X. (2020). Fairness in deep learning: A computational perspective. *IEEE Intelligent Systems*, *36*(4), 25-34.](https://ieeexplore.ieee.org/abstract/document/9113719/)\n","slug":"paper-reading-AlexNet","published":1,"updated":"2022-06-09T10:24:20.197Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz2a001zl8yb8l11c5ef","content":"<blockquote>\n<p>It has been 10 years since AlexNet has been brought out. It is one of the cornerstones of this surge of deep learning.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>\n<span id=\"more\"></span>\n<p>paper link: <a href=\"https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\">ImageNet Classification with Deep Convolutional Neural Networks</a></p>\n<p>useful link: https://www.bilibili.com/video/BV1ih411J7Kz</p>\n<h2 id=\"little-history\">Little history</h2>\n<p>It hasn't gotten much attention by the area of machine learning for the first 2-3 years since it got published, because this paper is written rather as a technical report than an academic paper. A good paper needs new thoughts for the model, or at least some explanations, while this paper only presented how they applied 3 tricks and how good their results are. However, there was no doubt an influential hit in the area of computer vision, which has a passion for refreshing the top list. And this influence spread to other areas gradually with deeper studies on it.</p>\n<h2 id=\"notes-by-sections\">Notes by sections</h2>\n<h3 id=\"absturct\">0. Absturct</h3>\n<blockquote>\n<p>To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation.</p>\n</blockquote>\n<p>In addition to a brief introduction to the model, the use of GPU is also mentioned in the abstract. And works around GPU are mentioned all the time. It was really a tough engineering job from the perspective of the first writer. But it is not important for an acdemic paper. Besides, since the emergence of CUDA in 2007, the application of GPU in the ML field in 2012 is not uncommon, and MATLAB is mainly used as a ML tool with a large number of GPU acceleration libraries.</p>\n<blockquote>\n<p>We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry</p>\n</blockquote>\n<p>At last, the result in the ILSVRC-2012 competition is as good as knocking the second to the ground and then showing off with a set of backflips. So personally it might look like a technical report, but it's still an outstanding paper and absolutly worth reading.</p>\n<h3 id=\"discussion\">7. Discussion</h3>\n<p>In stead of conclusion, this paper leaves a discussion as the last section, which is unsual.</p>\n<blockquote>\n<p>For example, removing any of the middle layers results in a loss of about 2% for the top-1 performance of the network. So the depth really is important for achieving our results</p>\n</blockquote>\n<p>The depth is important, but it is insufficient to be simply concluded from the degradation caused by removing one middle layer, ignoring other effects such as superparameter settings. And, considering only the conculsion, a more complete one might be, depth and width are both very important. The ratio of height and width matters.</p>\n<blockquote>\n<p>To simplify our experiments, we did not use any unsupervised pre-training even though we expect that it will help</p>\n</blockquote>\n<p>Before AlexNet, it was common to warm up the NN with massive unlabelled images before the actual training i.e. use an unsupervised model as an initial. And the goal of the field of machine learning was to extract the features of data through large-scale unsupervised models. However, this sentence steered the entire field from unsupervised to supervised learning, which, according to the machine learning pioneers such as Hinton and LeCun, was a \"wrong route\". But with the rise of the pre-trained language models such as Bert, and the contrative learning model in CV field such as MoCo, the unsupervised route is gradually comming back to the foreground.</p>\n<p><img src=\"unsupervise learning cake.png\" srcset=\"/img/loading.gif\" lazyload alt=\"unsupervise learning cake\" style=\"zoom:80%;\" /></p>\n<blockquote>\n<p>Ultimately we would like to use very large and deep convolutional nets on video sequences where the temporal structure provides very helpful information that is missing or far less obvious in static images.</p>\n</blockquote>\n<p>Actually video sequences are still a tough area beacause of the high computational comsumpution and the copyright issues.</p>\n<h3 id=\"key-figure\">Key figure</h3>\n<p><img src=\"alexnet results.png\" srcset=\"/img/loading.gif\" lazyload alt=\"alexnet results\" style=\"zoom:67%;\" /></p>\n<p>The right part is the most important result in this paper, though it isn't been discussed much in this paper. Actually it shows the last layer feature vectors perform really well in the semantic space i.e. deep neural network is very suitable to extract features from data.</p>\n<h3 id=\"introduction\">1. Introduction</h3>\n<blockquote>\n<p>To improve their performance, we can collect larger datasets, learn more powerful models, and use better techniques for preventing overfitting.</p>\n</blockquote>\n<p>The paper leads one route of deep learning, which is, with large dataset and model, developing powerful regularization methods to prevent overfitting. However there is a new route, which is focusing on designing good architecture s.t. the overfitting won't happen with large model.</p>\n<blockquote>\n<p>Our network contains a number of new and unusual features which improve its performance and reduce its training time, which are detailed in Section 3.</p>\n</blockquote>\n<blockquote>\n<p>we used several effective techniques for preventing overfitting, which are described in Section 4.</p>\n</blockquote>\n<p>These two are the innovative points. People can then follow their work later, which makes this paper a cornerstone.</p>\n<h3 id=\"dataset\">2. Dataset</h3>\n<blockquote>\n<p>We did not pre-process the images in any other way, except for subtracting the mean activity over the training set from each pixel. So we trained our network on the (centered) raw RGB values of the pixels.</p>\n</blockquote>\n<p>There is one more point that is not emphasized. Previously, features of an image (such as SIFT) were always used as input instead of raw RGB values. Datasets such as ImageNet provided SIFT of their image set as well. The end-to-end nature is the selling point of a series of deep learning papers that follow.</p>\n<h3 id=\"architecture\">3. Architecture</h3>\n<h4 id=\"relu\">3.1. ReLU</h4>\n<p>From a present point of view, ReLU is not that important for speeding up the training process. Other activation functions still work. It's the simplicity of ReLU that makes it stick.</p>\n<h3 id=\"reducing-overfitting\">4. Reducing Overfitting</h3>\n<p>A metaphore of overfitting: In order to get a high score on an exam, you memorize all the answers to the exercises instead of understanding the question.</p>\n<h4 id=\"data-augmentation\">4.1 Data Augmentation</h4>\n<blockquote>\n<p>The second form of data augmentation consists of altering the intensities of the RGB channels in training images. Specifically, we perform PCA on the set of RGB pixel values throughout the ImageNet training set.</p>\n</blockquote>\n<p>PCA is here use as a augmentation method which follow-up work don't follow. For example, in ResNet a standard color augmentation is used with no fancy methods. And nowadays, standard color augmentation wins.</p>\n<h4 id=\"dropout\">4.2 dropout</h4>\n<blockquote>\n<p>There is, however, a very efficient version of model combination that only costs about a factor of two during training. The recently-introduced technique, called dropout</p>\n</blockquote>\n<p>Here dropout is considered a light version of model ensembling, but later <a href=\"https://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf\">study below</a> has shown that the effect of dropout is actually equivalent to weight decay/regularization, yet there is no specific weight decay method equivalent to it algorithmically.</p>\n<blockquote>\n<blockquote>\n<p>one way to obtain some of the benefits of dropout without stochasticity is to marginalize the noise to obtain a regularizer that does the same thing as the dropout procedure, in expectation. We showed that for linear regression this regularizer is a modified form of L2 regularization. For more complicated models, it is not obvious how to obtain an equivalent regularizer.</p>\n</blockquote>\n</blockquote>\n<h3 id=\"details-of-learning\">5. Details of learning</h3>\n<blockquote>\n<p>we trained our models using stochastic gradient descent with a batch size of 128 examples, momentum of 0.9, and weight decay of 0.0005</p>\n</blockquote>\n<p>momentum, weight decay with SGD has become a standard method afterwards.</p>\n<blockquote>\n<p>We initialized the weights in each layer from a zero-mean Gaussian distribution with standard deviation 0.01</p>\n</blockquote>\n<p>(0, 0.01) is usually chosen as the initialization parameter pair in most standard-sized models. (0, 0.02) is in use even for large models like Bert.</p>\n<blockquote>\n<p>We trained the network for roughly 90 cycles through the training set of 1.2 million images, which took five to six days on two NVIDIA GTX 580 3GB GPUs.</p>\n</blockquote>\n<p>Similar to what is happening now with training NLP, maybe it will drive the next evolution in hardware. And probably hardware similar to TPU would be popular.</p>\n<h3 id=\"results\">6. Results</h3>\n<h4 id=\"qualitative-evaluations\">6.1 Qualitative Evaluations</h4>\n<blockquote>\n<p>The kernels on GPU 1 are largely color-agnostic, while the kernels on on GPU 2 are largely color-specific. The kernels on GPU 1 are largely color-agnostic, while the kernels on on GPU 2 are largely color-specific</p>\n</blockquote>\n<p>Interesting problem but less focused by follow up work.</p>\n<blockquote>\n<p>consider the feature activations induced by an image at the last, 4096-dimensional hidden layer. If two images produce feature activation vectors with a small Euclidean separation, we can say that the higher levels of the neural network consider them to be similar.</p>\n</blockquote>\n<p>This is an intuitive work as talked before, and follow up work such as <a href=\"https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53\">Visualizing and understanding convolutional networks</a> dig deeper trying to interperate the NN. And interpretion is very important for works related to physics or <a href=\"https://ieeexplore.ieee.org/abstract/document/9113719/\">fairness</a>.</p>\n<h2 id=\"reference\">Reference</h2>\n<p><a href=\"https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer,\">Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. <em>The journal of machine learning research</em>, <em>15</em>(1), 1929-1958.</a></p>\n<p><a href=\"https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53\">Zeiler, M. D., &amp; Fergus, R. (2014, September). Visualizing and understanding convolutional networks. In <em>European conference on computer vision</em> (pp. 818-833). Springer, Cham.</a></p>\n<p><a href=\"https://ieeexplore.ieee.org/abstract/document/9113719/\">Du, M., Yang, F., Zou, N., &amp; Hu, X. (2020). Fairness in deep learning: A computational perspective. <em>IEEE Intelligent Systems</em>, <em>36</em>(4), 25-34.</a></p>\n","site":{"data":{}},"wordcount":7689,"excerpt":"<blockquote>\n<p>It has been 10 years since AlexNet has been brought out. It is one of the cornerstones of this surge of deep learning.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>","more":"<p>paper link: <a href=\"https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\">ImageNet Classification with Deep Convolutional Neural Networks</a></p>\n<p>useful link: https://www.bilibili.com/video/BV1ih411J7Kz</p>\n<h2 id=\"little-history\">Little history</h2>\n<p>It hasn't gotten much attention by the area of machine learning for the first 2-3 years since it got published, because this paper is written rather as a technical report than an academic paper. A good paper needs new thoughts for the model, or at least some explanations, while this paper only presented how they applied 3 tricks and how good their results are. However, there was no doubt an influential hit in the area of computer vision, which has a passion for refreshing the top list. And this influence spread to other areas gradually with deeper studies on it.</p>\n<h2 id=\"notes-by-sections\">Notes by sections</h2>\n<h3 id=\"absturct\">0. Absturct</h3>\n<blockquote>\n<p>To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation.</p>\n</blockquote>\n<p>In addition to a brief introduction to the model, the use of GPU is also mentioned in the abstract. And works around GPU are mentioned all the time. It was really a tough engineering job from the perspective of the first writer. But it is not important for an acdemic paper. Besides, since the emergence of CUDA in 2007, the application of GPU in the ML field in 2012 is not uncommon, and MATLAB is mainly used as a ML tool with a large number of GPU acceleration libraries.</p>\n<blockquote>\n<p>We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry</p>\n</blockquote>\n<p>At last, the result in the ILSVRC-2012 competition is as good as knocking the second to the ground and then showing off with a set of backflips. So personally it might look like a technical report, but it's still an outstanding paper and absolutly worth reading.</p>\n<h3 id=\"discussion\">7. Discussion</h3>\n<p>In stead of conclusion, this paper leaves a discussion as the last section, which is unsual.</p>\n<blockquote>\n<p>For example, removing any of the middle layers results in a loss of about 2% for the top-1 performance of the network. So the depth really is important for achieving our results</p>\n</blockquote>\n<p>The depth is important, but it is insufficient to be simply concluded from the degradation caused by removing one middle layer, ignoring other effects such as superparameter settings. And, considering only the conculsion, a more complete one might be, depth and width are both very important. The ratio of height and width matters.</p>\n<blockquote>\n<p>To simplify our experiments, we did not use any unsupervised pre-training even though we expect that it will help</p>\n</blockquote>\n<p>Before AlexNet, it was common to warm up the NN with massive unlabelled images before the actual training i.e. use an unsupervised model as an initial. And the goal of the field of machine learning was to extract the features of data through large-scale unsupervised models. However, this sentence steered the entire field from unsupervised to supervised learning, which, according to the machine learning pioneers such as Hinton and LeCun, was a \"wrong route\". But with the rise of the pre-trained language models such as Bert, and the contrative learning model in CV field such as MoCo, the unsupervised route is gradually comming back to the foreground.</p>\n<p><img src=\"unsupervise learning cake.png\" alt=\"unsupervise learning cake\" style=\"zoom:80%;\" /></p>\n<blockquote>\n<p>Ultimately we would like to use very large and deep convolutional nets on video sequences where the temporal structure provides very helpful information that is missing or far less obvious in static images.</p>\n</blockquote>\n<p>Actually video sequences are still a tough area beacause of the high computational comsumpution and the copyright issues.</p>\n<h3 id=\"key-figure\">Key figure</h3>\n<p><img src=\"alexnet results.png\" alt=\"alexnet results\" style=\"zoom:67%;\" /></p>\n<p>The right part is the most important result in this paper, though it isn't been discussed much in this paper. Actually it shows the last layer feature vectors perform really well in the semantic space i.e. deep neural network is very suitable to extract features from data.</p>\n<h3 id=\"introduction\">1. Introduction</h3>\n<blockquote>\n<p>To improve their performance, we can collect larger datasets, learn more powerful models, and use better techniques for preventing overfitting.</p>\n</blockquote>\n<p>The paper leads one route of deep learning, which is, with large dataset and model, developing powerful regularization methods to prevent overfitting. However there is a new route, which is focusing on designing good architecture s.t. the overfitting won't happen with large model.</p>\n<blockquote>\n<p>Our network contains a number of new and unusual features which improve its performance and reduce its training time, which are detailed in Section 3.</p>\n</blockquote>\n<blockquote>\n<p>we used several effective techniques for preventing overfitting, which are described in Section 4.</p>\n</blockquote>\n<p>These two are the innovative points. People can then follow their work later, which makes this paper a cornerstone.</p>\n<h3 id=\"dataset\">2. Dataset</h3>\n<blockquote>\n<p>We did not pre-process the images in any other way, except for subtracting the mean activity over the training set from each pixel. So we trained our network on the (centered) raw RGB values of the pixels.</p>\n</blockquote>\n<p>There is one more point that is not emphasized. Previously, features of an image (such as SIFT) were always used as input instead of raw RGB values. Datasets such as ImageNet provided SIFT of their image set as well. The end-to-end nature is the selling point of a series of deep learning papers that follow.</p>\n<h3 id=\"architecture\">3. Architecture</h3>\n<h4 id=\"relu\">3.1. ReLU</h4>\n<p>From a present point of view, ReLU is not that important for speeding up the training process. Other activation functions still work. It's the simplicity of ReLU that makes it stick.</p>\n<h3 id=\"reducing-overfitting\">4. Reducing Overfitting</h3>\n<p>A metaphore of overfitting: In order to get a high score on an exam, you memorize all the answers to the exercises instead of understanding the question.</p>\n<h4 id=\"data-augmentation\">4.1 Data Augmentation</h4>\n<blockquote>\n<p>The second form of data augmentation consists of altering the intensities of the RGB channels in training images. Specifically, we perform PCA on the set of RGB pixel values throughout the ImageNet training set.</p>\n</blockquote>\n<p>PCA is here use as a augmentation method which follow-up work don't follow. For example, in ResNet a standard color augmentation is used with no fancy methods. And nowadays, standard color augmentation wins.</p>\n<h4 id=\"dropout\">4.2 dropout</h4>\n<blockquote>\n<p>There is, however, a very efficient version of model combination that only costs about a factor of two during training. The recently-introduced technique, called dropout</p>\n</blockquote>\n<p>Here dropout is considered a light version of model ensembling, but later <a href=\"https://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf\">study below</a> has shown that the effect of dropout is actually equivalent to weight decay/regularization, yet there is no specific weight decay method equivalent to it algorithmically.</p>\n<blockquote>\n<blockquote>\n<p>one way to obtain some of the benefits of dropout without stochasticity is to marginalize the noise to obtain a regularizer that does the same thing as the dropout procedure, in expectation. We showed that for linear regression this regularizer is a modified form of L2 regularization. For more complicated models, it is not obvious how to obtain an equivalent regularizer.</p>\n</blockquote>\n</blockquote>\n<h3 id=\"details-of-learning\">5. Details of learning</h3>\n<blockquote>\n<p>we trained our models using stochastic gradient descent with a batch size of 128 examples, momentum of 0.9, and weight decay of 0.0005</p>\n</blockquote>\n<p>momentum, weight decay with SGD has become a standard method afterwards.</p>\n<blockquote>\n<p>We initialized the weights in each layer from a zero-mean Gaussian distribution with standard deviation 0.01</p>\n</blockquote>\n<p>(0, 0.01) is usually chosen as the initialization parameter pair in most standard-sized models. (0, 0.02) is in use even for large models like Bert.</p>\n<blockquote>\n<p>We trained the network for roughly 90 cycles through the training set of 1.2 million images, which took five to six days on two NVIDIA GTX 580 3GB GPUs.</p>\n</blockquote>\n<p>Similar to what is happening now with training NLP, maybe it will drive the next evolution in hardware. And probably hardware similar to TPU would be popular.</p>\n<h3 id=\"results\">6. Results</h3>\n<h4 id=\"qualitative-evaluations\">6.1 Qualitative Evaluations</h4>\n<blockquote>\n<p>The kernels on GPU 1 are largely color-agnostic, while the kernels on on GPU 2 are largely color-specific. The kernels on GPU 1 are largely color-agnostic, while the kernels on on GPU 2 are largely color-specific</p>\n</blockquote>\n<p>Interesting problem but less focused by follow up work.</p>\n<blockquote>\n<p>consider the feature activations induced by an image at the last, 4096-dimensional hidden layer. If two images produce feature activation vectors with a small Euclidean separation, we can say that the higher levels of the neural network consider them to be similar.</p>\n</blockquote>\n<p>This is an intuitive work as talked before, and follow up work such as <a href=\"https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53\">Visualizing and understanding convolutional networks</a> dig deeper trying to interperate the NN. And interpretion is very important for works related to physics or <a href=\"https://ieeexplore.ieee.org/abstract/document/9113719/\">fairness</a>.</p>\n<h2 id=\"reference\">Reference</h2>\n<p><a href=\"https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer,\">Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. <em>The journal of machine learning research</em>, <em>15</em>(1), 1929-1958.</a></p>\n<p><a href=\"https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53\">Zeiler, M. D., &amp; Fergus, R. (2014, September). Visualizing and understanding convolutional networks. In <em>European conference on computer vision</em> (pp. 818-833). Springer, Cham.</a></p>\n<p><a href=\"https://ieeexplore.ieee.org/abstract/document/9113719/\">Du, M., Yang, F., Zou, N., &amp; Hu, X. (2020). Fairness in deep learning: A computational perspective. <em>IEEE Intelligent Systems</em>, <em>36</em>(4), 25-34.</a></p>"},{"title":"Vision Transformer","author":"Ryan LI","toc":true,"declare":true,"date":"2022-04-21T12:42:10.000Z","index_img":"/index/paper-reading-ViT.png","_content":"\n> Presented in 2021, the vision transformer model (ViT) is the most influential work in the CV field recent years. Its variants outperform the dominant convolutional networks in almost all CV tasks such as [classification](https://paperswithcode.com/sota/image-classification-on-imagenet) and [object detection](https://paperswithcode.com/sota/object-detection-on-coco). And it breaks the border of CV and NLP, providing new thoughts to CV and multi-model areas.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/),  hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\nPaper:\n\n[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929v2)\n\nUseful links:\n\nhttps://www.bilibili.com/video/BV15P4y137jb\n\nhttps://theaisummer.com/vision-transformer/\n\n<img src=\"VIT properties.png\" alt=\"VIT properties\" style=\"zoom:50%;\" />\n\nNot only Vision Transformer (ViT) performs better on traditional CV tasks, it has more impressive properties. As shown above, [Naseer et al.](https://proceedings.neurips.cc/paper/2021/hash/c404a5adbf90e09631678b13b05d9d7a-Abstract.html) demonstrate the tasks where ViT shows extra performance over CNN models, even over humans. \n\n## Notes\n\n### Abstract\n\nWhile Transformer-based models such as BERT, GPT series, and T5 nail the NLP tasks, CV tasks remain dominated by CNN-based models. This paper applied a pure transformer encoder (same as BERT) to sequences of cut images and obtains a good classification result, especially with **supervised** pre-training on a large dataset then fine tuning on a mid-size dataset. Besides, fewer computational resources (meaning 2500 days of TPUv3) are need to attain good results, compared with CNN models.\n\n### Conclusion\n\nBesides the paraphrasing part, the conclusion part discusses the future work based on the ViT. And all of them have follow-up works.\n\n- Apply ViT to other CV tasks, given the promising performance of [DETR](https://arxiv.org/pdf/2005.12872.pdf,). Only 1 and a half month later, [ViT-FRCNN](https://arxiv.org/abs/2012.09958) and [SEDR](http://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.html) mange to apply ViT on detection and segmentation respectively. And after 3 months, [Swin Transformer](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.html) introduces hierarchical feature to transformer, making ViT more suitable to vision tasks.\n- Self-supervised pre-training, given the great results of BERT and GPT in the NLP field.  Initial explorations in the paper show a gap from the supervised pre-training. One year later,  [MAE](https://arxiv.org/abs/2111.06377) narrows the gap successfully by generative model.\n  - Besides, in the section of self-supervised learning, a contrastive learning is mentioned as well, and [MOCO v3](http://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html) and [DINO](http://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html) follow this line.\n- Further scaling up this model. Half year later, same group introduces [Vit-G](https://arxiv.org/pdf/2106.04560v1.pdf) with two billion parameters, attaining new SOTA on ImageNet of 90.45%.\n\n### Introduction\n\nSuccess of Transformer-based models on NLP tasks are firstly reviewed. And it is natural trying to apply such self-attention mechanism to vision. Yet here are one major obstacle:\n\n- How to transfer a 2D picture to a 1D sequence? \n\nOne intuitive thought is to flatten the picture directly and treat each pixel as an element. In this way, a medium size 224\\*224 picture will be converted to a 50,176 long sequence. However, the sequence length is quadratically related to model complexity. Morden hardware only supports input sequence length <1000 of a pure self-attention model. For example BERT only accepts input length of 512. \n\nYet the authors mange to incorporate the original transformer encoder in CV. In order to address the sequence length problem, they split the image into 16*16 patches, each patches denotes a sequence element (token). In this way, a 224\\*224 image can be converted as a sequence length of 16\\*16 with each element sized 14\\*14. Each element then gets linearised through a FC layer before being passed into the transformer encoder.\n\nAnd the afterwards experiments show that the new  model doesn't perform well on mid-size model. One explanation is that transformer model lack the image-related inductive bias of CNN (locality and translation equalisation). Yet with pre-training on large dataset such as JFT-300 and ImagNet-21K, a better result than CNN can be approached.\n\n### Related work\n\n*It is a detailed related work covering all the aspects in the original paper. I just pick few of them.*\n\nAll the related works aim at reducing the sequence length within the limitation caused by self-attention. Some try to combine CNN with self-attention. For example [Wang, X et al.'s work](http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.html) takes the feature map extracted by CNN as the input of transformer. Others try to replace the CNN with a special variation of self-attention. For example, [Ramachandran et al.'s work](https://proceedings.neurips.cc/paper/2019/hash/3416a75f4cea9109507cacd8e2f2aefc-Abstract.html) replaces all convolutional sublayers of the ResNet-50 model with self-attention layers. To reduce the computational cost, a local region of the image instead of the whole image is used as the receptive field of the self-attention layer, meaning each pixel only attends to its neighbours in a restricted area. In another work line, [Wang, H et.al's work](https://link.springer.com/chapter/10.1007/978-3-030-58548-8_7) factorising 2D self-attention into two 1D self-attentions to significantly reduce computation complexity. \n\nAnd there is a very similar [Cordonnier et al's work](https://arxiv.org/abs/1911.03584) also split the images before the self-attention layer. Yet the patch size is 2*2 and with the dataset only [CIFAR-10](https://paperswithcode.com/sota/image-classification-on-cifar-10). This paper  enlarges the model, apply it in big dataset, and shows the scalability.\n\nAnother related work image GPT([iGPT](http://proceedings.mlr.press/v119/chen20s.html)) trains a GPT-2 scale generative network. Yet the highest accuracy on ImageNet is 72%, way less than 88% of this paper. But in 2021, an afterwards generative network [MAE](https://arxiv.org/abs/2111.06377) shows a competitive result of 87.8%, with good transfer leaning capability on segmentation and object detection as well.\n\nBesides, works exploring transfer learning performance of CNN model on larger datasets such as ImageNet-21k and JFT-300M are mentioned. And this paper studies the transformer instead of the CNN.\n\n### Method\n\nThe whole big idea of the method part is leaving as much as possible the original transformer architecture in order to leverage the good feature and the existing mature efficient implementations of it.  \n\n#### Vision Transformer (VIT)\n\n<img src=\"VIT model overview.png\" alt=\"VIT model overview\" style=\"zoom:60%;\" />\n\n<img src=\"VIT algorithm.png\" alt=\"VIT algorithm\" style=\"zoom:40%;\" />\n\nFrom the overview, and the algorithm it should be called Vision BERT instead of Vision Transformer, given the pure encoder architecture and the extra \"classification token\". Assume a *224\\*224\\*3* image, after patching, the sequence length is *HW/P<sup>2</sup>=16\\*16=196* and the width is *14\\*14\\*3=768*. Given the hidden size of the model *D=768*, through linear projection layer (E), sequence *X [196\\*768]* are multiplied with weight *E [768\\*768]*. The resulting linear output *[196\\*768]* is then contacted with [cls], followed by adding standard 1D learnable positional embedding to be the transformer input *[197\\*768]*. After several transformer blocks, the output size does not change and the [cls] token is projected to a softmax classification layer\n\n#### Ablation experiments\n\nThe pre and post-processing are crucial for ViT given that the middle transformer encoder layers are kept as original. Multiple rounds of ablation experiments are carried out. \n\n- Position embedding schemes, 2D embedding and relative embedding are applied to compare with the standard 1D embedding, and no evident gain is spotted.\n\n  <img src=\"VIT positional embedding ablation.png\" alt=\"VIT positional embedding ablation\" style=\"zoom:30%;\" />\n\n- [cls] token vs average pooling, extra [cls] token is inherited from the Transformer model for text, and traditionally in CV, instead of an additional token, an average polling layer after the output layer is usually used as a classifier. The figure blow shows no both works. But in order to stick the original design as close as possible, [cls] token is applied.\n\n  <img src=\"VIT class token ablation.png\" alt=\"VIT class token ablation\" style=\"zoom:30%;\" />\n\nAnother analysis after the model description:\n\n**Inductive bias:** Less locality, translation equivariance and 2D neighbourhood structure are possessed by ViT, compared with CNN. \n\n**Hybrid Architecture:** CNN can be used as a special embedding, leveraging the inductive bias of the CNN model.\n\n#### Limitation on Fine-Tuning\n\nPre-train ViT at larger and higher resolution datasets is [proved](https://proceedings.neurips.cc/paper/2019/hash/d03a857a23b5285736c4d55e0bb067c8-Abstract.html) to be beneficial. Yet the input sequence lengths are different when training on two datasets with different resolutions, resulting in positional embeddings of different lengths. In this article, a 2D interpolation is applied to transfer a pre-trained positional embedding to another dataset to fine-tune. But the accuracy will loss if the resolution difference is too big.\n\n### Experiments\n\n#### Setup\n\nResNet, ViT, and the hybrid model are evaluated together and ViT wins taking account of the pre-training cost. Besides, a small self-supervision experiment is deployed and sees potential.\n\nTwo scales of ImageNet(1k and 21k) and JFT(303M) are used as pre-training dataset. Only classification tasks are evaluated with popular datasets.\n\n3 scales of ViT are designed with different patch size(inversely proportional to the amount of data). For example, ViT-L/16 means ViT-Large with 16 patches.\n\n<img src=\"ViT variants.png\" alt=\"ViT variants\" style=\"zoom:50%;\" />\n\n#### Comparison to SOTA\n\nAnd the best results are shown below:\n\n<img src=\"ViT results.png\" alt=\"ViT results\" style=\"zoom:60%;\" />\n\n#### Pre-training cost requirements\n\nFigure 3 and 4 shows the performance of the presented models on different sizes of per-training datasets.  ViT preforms competitive only starts from dataset 21k, and very well only on huge dataset.\n\nFigure 5 shows the transfer performances versus pre-training costs on JFT-300M of several models. And it shows that ViT is cheaper than ResNet. Interestingly, the Hybrid model is competitive on low pre-training cost.\n\n<img src=\"ViT ablation 2.png\" alt=\"ViT ablation 2\" style=\"zoom:55%;\" />\n\n#### Inspecting ViT\n\n<img src=\"ViT inspecting.png\" alt=\"ViT inspecting\" style=\"zoom:42%;\" />\n\n**Figure7 Left:** The learned linear projection weight matrix *E [768\\*768]* is inspected by PCA, and the first 28 components(modes) are visualised as embedding filters. They look pretty much similar to the early layer filters(kernels) of CNN (for example, the first layer of a CNN shown by [Brachnmann et.al](https://www.mdpi.com/2073-8994/8/12/144)). This similarity indicates that the linear patch embedding manages to represent the low-dimension structure of each patch. <img src=\"CNN first layer filters.png\" alt=\"CNN first layer filters\" style=\"zoom:40%;\" />\n\n**Figure7 mid:** Position embedding visualisation first shows that the spatial information is captured well by the E matrix, given that the similarity matrix between patches matches well with the distance relationships of patches. Second, patterns across rows (and columns) have similar representations, indicating the embedding layer has successful learned the row-column relationship. Overall, the 1D positional embedding has learned the 2D structure, coherent with the ablation experiment result. \n\n**Figure7 Right:** The receptive fields of the multi-head attention layers are evaluated by the mean attention distance. Compared with CNN whose receptive field increases linearly with the depth, the ViT attends the whole picture from the first layer, leveraging the natural advantage of transformer.\n\n#### Self-supervision\n\nA preliminary exploration on masked patch prediction for self-supervision (mimicking one of the BERT pre-training tasks) has been employed. But the result is not satisfying. And contrastive pre-training are mentioned as a future work.\n\n## Review\n\nThis is a concise-written, fundamental article. Just as presented in the conclusion part, it inspired many flow-up works from any direction in the CV area, such as applying to  more tasks, changing the architecture(tokenisation, transformer block([MLP-mixer](https://proceedings.neurips.cc/paper/2021/hash/cba0a4ee5ccd02fda0fe3f9a3e7b89fe-Abstract.html) changing multi-head attention layers to MLP , [meta-former](https://arxiv.org/abs/2111.11418): substituting multi-head attention layers to average pooling), changing objective function(self-supervised, contrastive learning), and multi modality. \n\nIt's still unclear whether convolution, attention or MLP will win this game.\n\n## Reference\n\n[Naseer, M. M., Ranasinghe, K., Khan, S. H., Hayat, M., Shahbaz Khan, F., & Yang, M. H. (2021). Intriguing properties of vision transformers. *Advances in Neural Information Processing Systems*, *34*.](https://proceedings.neurips.cc/paper/2021/hash/c404a5adbf90e09631678b13b05d9d7a-Abstract.html)\n\n[Beal, J., Kim, E., Tzeng, E., Park, D. H., Zhai, A., & Kislyuk, D. (2020). Toward transformer-based object detection. *arXiv preprint arXiv:2012.09958*.](https://arxiv.org/abs/2012.09958)\n\n[Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y., ... & Zhang, L. (2021). Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers. In *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition* (pp. 6881-6890).](http://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.html)\n\n[Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., ... & Guo, B. (2021). Swin transformer: Hierarchical vision transformer using shifted windows. In *Proceedings of the IEEE/CVF International Conference on Computer Vision* (pp. 10012-10022).](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.html)\n\n[Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., & Zagoruyko, S. (2020, August). End-to-end object detection with transformers. In *European conference on computer vision* (pp. 213-229). Springer, Cham.](https://arxiv.org/pdf/2005.12872.pdf,)\n\n[He, K., Chen, X., Xie, S., Li, Y., Dollr, P., & Girshick, R. (2021). Masked autoencoders are scalable vision learners. *arXiv preprint arXiv:2111.06377*.](https://arxiv.org/abs/2111.06377)\n\n[Chen, X., Xie, S., & He, K. (2021). An empirical study of training self-supervised vision transformers. In *Proceedings of the IEEE/CVF International Conference on Computer Vision* (pp. 9640-9649).](http://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html)\n\n[Caron, M., Touvron, H., Misra, I., Jgou, H., Mairal, J., Bojanowski, P., & Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In *Proceedings of the IEEE/CVF International Conference on Computer Vision* (pp. 9650-9660).](http://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html)\n\n[Zhai, X., Kolesnikov, A., Houlsby, N., & Beyer, L. (2021). Scaling Vision Transformers. *ArXiv, abs/2106.04560*.](https://arxiv.org/abs/2106.04560)\n\n[Wang, X., Girshick, R., Gupta, A., & He, K. (2018). Non-local neural networks. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 7794-7803).](http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.html)\n\n[Ramachandran, P., Parmar, N., Vaswani, A., Bello, I., Levskaya, A., & Shlens, J. (2019). Stand-alone self-attention in vision models. *Advances in Neural Information Processing Systems*, *32*.](https://proceedings.neurips.cc/paper/2019/hash/3416a75f4cea9109507cacd8e2f2aefc-Abstract.html)\n\n[Wang, H., Zhu, Y., Green, B., Adam, H., Yuille, A., & Chen, L. C. (2020, August). Axial-deeplab: Stand-alone axial-attention for panoptic segmentation. In *European Conference on Computer Vision* (pp. 108-126). Springer, Cham.](https://link.springer.com/chapter/10.1007/978-3-030-58548-8_7)\n\n[Cordonnier, J. B., Loukas, A., & Jaggi, M. (2019). On the relationship between self-attention and convolutional layers. *arXiv preprint arXiv:1911.03584*.](https://arxiv.org/abs/1911.03584)\n\n[Chen, Mark, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and Ilya Sutskever. \"Generative pretraining from pixels.\" In *International Conference on Machine Learning*, pp. 1691-1703. PMLR, 2020.](http://proceedings.mlr.press/v119/chen20s.html)\n\n[Touvron, H., Vedaldi, A., Douze, M., & Jgou, H. (2019). Fixing the train-test resolution discrepancy. *Advances in neural information processing systems*, *32*.](https://proceedings.neurips.cc/paper/2019/hash/d03a857a23b5285736c4d55e0bb067c8-Abstract.html)\n\n[Brachmann, A., & Redies, C. (2016). Using convolutional neural network filters to measure left-right mirror symmetry in images. *Symmetry*, *8*(12), 144.](https://www.mdpi.com/2073-8994/8/12/144)\n\n[Tolstikhin, I. O., Houlsby, N., Kolesnikov, A., Beyer, L., Zhai, X., Unterthiner, T., ... & Dosovitskiy, A. (2021). Mlp-mixer: An all-mlp architecture for vision. *Advances in Neural Information Processing Systems*, *34*.](https://proceedings.neurips.cc/paper/2021/hash/cba0a4ee5ccd02fda0fe3f9a3e7b89fe-Abstract.html)\n\n[Yu, W., Luo, M., Zhou, P., Si, C., Zhou, Y., Wang, X., ... & Yan, S. (2021). Metaformer is actually what you need for vision. arXiv preprint arXiv:2111.11418.](https://arxiv.org/abs/2111.11418)\n","source":"_posts/paper-reading-Vision-Transformer.md","raw":"---\ntitle: 'Vision Transformer'\nauthor: Ryan LI\ntoc: true\ndeclare: true\ndate: 2022-04-21 20:42:10\nindex_img: /index/paper-reading-ViT.png\ntags:\n  - paper reading\n  - deep learning \n---\n\n> Presented in 2021, the vision transformer model (ViT) is the most influential work in the CV field recent years. Its variants outperform the dominant convolutional networks in almost all CV tasks such as [classification](https://paperswithcode.com/sota/image-classification-on-imagenet) and [object detection](https://paperswithcode.com/sota/object-detection-on-coco). And it breaks the border of CV and NLP, providing new thoughts to CV and multi-model areas.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/),  hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\nPaper:\n\n[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929v2)\n\nUseful links:\n\nhttps://www.bilibili.com/video/BV15P4y137jb\n\nhttps://theaisummer.com/vision-transformer/\n\n<img src=\"VIT properties.png\" alt=\"VIT properties\" style=\"zoom:50%;\" />\n\nNot only Vision Transformer (ViT) performs better on traditional CV tasks, it has more impressive properties. As shown above, [Naseer et al.](https://proceedings.neurips.cc/paper/2021/hash/c404a5adbf90e09631678b13b05d9d7a-Abstract.html) demonstrate the tasks where ViT shows extra performance over CNN models, even over humans. \n\n## Notes\n\n### Abstract\n\nWhile Transformer-based models such as BERT, GPT series, and T5 nail the NLP tasks, CV tasks remain dominated by CNN-based models. This paper applied a pure transformer encoder (same as BERT) to sequences of cut images and obtains a good classification result, especially with **supervised** pre-training on a large dataset then fine tuning on a mid-size dataset. Besides, fewer computational resources (meaning 2500 days of TPUv3) are need to attain good results, compared with CNN models.\n\n### Conclusion\n\nBesides the paraphrasing part, the conclusion part discusses the future work based on the ViT. And all of them have follow-up works.\n\n- Apply ViT to other CV tasks, given the promising performance of [DETR](https://arxiv.org/pdf/2005.12872.pdf,). Only 1 and a half month later, [ViT-FRCNN](https://arxiv.org/abs/2012.09958) and [SEDR](http://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.html) mange to apply ViT on detection and segmentation respectively. And after 3 months, [Swin Transformer](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.html) introduces hierarchical feature to transformer, making ViT more suitable to vision tasks.\n- Self-supervised pre-training, given the great results of BERT and GPT in the NLP field.  Initial explorations in the paper show a gap from the supervised pre-training. One year later,  [MAE](https://arxiv.org/abs/2111.06377) narrows the gap successfully by generative model.\n  - Besides, in the section of self-supervised learning, a contrastive learning is mentioned as well, and [MOCO v3](http://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html) and [DINO](http://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html) follow this line.\n- Further scaling up this model. Half year later, same group introduces [Vit-G](https://arxiv.org/pdf/2106.04560v1.pdf) with two billion parameters, attaining new SOTA on ImageNet of 90.45%.\n\n### Introduction\n\nSuccess of Transformer-based models on NLP tasks are firstly reviewed. And it is natural trying to apply such self-attention mechanism to vision. Yet here are one major obstacle:\n\n- How to transfer a 2D picture to a 1D sequence? \n\nOne intuitive thought is to flatten the picture directly and treat each pixel as an element. In this way, a medium size 224\\*224 picture will be converted to a 50,176 long sequence. However, the sequence length is quadratically related to model complexity. Morden hardware only supports input sequence length <1000 of a pure self-attention model. For example BERT only accepts input length of 512. \n\nYet the authors mange to incorporate the original transformer encoder in CV. In order to address the sequence length problem, they split the image into 16*16 patches, each patches denotes a sequence element (token). In this way, a 224\\*224 image can be converted as a sequence length of 16\\*16 with each element sized 14\\*14. Each element then gets linearised through a FC layer before being passed into the transformer encoder.\n\nAnd the afterwards experiments show that the new  model doesn't perform well on mid-size model. One explanation is that transformer model lack the image-related inductive bias of CNN (locality and translation equalisation). Yet with pre-training on large dataset such as JFT-300 and ImagNet-21K, a better result than CNN can be approached.\n\n### Related work\n\n*It is a detailed related work covering all the aspects in the original paper. I just pick few of them.*\n\nAll the related works aim at reducing the sequence length within the limitation caused by self-attention. Some try to combine CNN with self-attention. For example [Wang, X et al.'s work](http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.html) takes the feature map extracted by CNN as the input of transformer. Others try to replace the CNN with a special variation of self-attention. For example, [Ramachandran et al.'s work](https://proceedings.neurips.cc/paper/2019/hash/3416a75f4cea9109507cacd8e2f2aefc-Abstract.html) replaces all convolutional sublayers of the ResNet-50 model with self-attention layers. To reduce the computational cost, a local region of the image instead of the whole image is used as the receptive field of the self-attention layer, meaning each pixel only attends to its neighbours in a restricted area. In another work line, [Wang, H et.al's work](https://link.springer.com/chapter/10.1007/978-3-030-58548-8_7) factorising 2D self-attention into two 1D self-attentions to significantly reduce computation complexity. \n\nAnd there is a very similar [Cordonnier et al's work](https://arxiv.org/abs/1911.03584) also split the images before the self-attention layer. Yet the patch size is 2*2 and with the dataset only [CIFAR-10](https://paperswithcode.com/sota/image-classification-on-cifar-10). This paper  enlarges the model, apply it in big dataset, and shows the scalability.\n\nAnother related work image GPT([iGPT](http://proceedings.mlr.press/v119/chen20s.html)) trains a GPT-2 scale generative network. Yet the highest accuracy on ImageNet is 72%, way less than 88% of this paper. But in 2021, an afterwards generative network [MAE](https://arxiv.org/abs/2111.06377) shows a competitive result of 87.8%, with good transfer leaning capability on segmentation and object detection as well.\n\nBesides, works exploring transfer learning performance of CNN model on larger datasets such as ImageNet-21k and JFT-300M are mentioned. And this paper studies the transformer instead of the CNN.\n\n### Method\n\nThe whole big idea of the method part is leaving as much as possible the original transformer architecture in order to leverage the good feature and the existing mature efficient implementations of it.  \n\n#### Vision Transformer (VIT)\n\n<img src=\"VIT model overview.png\" alt=\"VIT model overview\" style=\"zoom:60%;\" />\n\n<img src=\"VIT algorithm.png\" alt=\"VIT algorithm\" style=\"zoom:40%;\" />\n\nFrom the overview, and the algorithm it should be called Vision BERT instead of Vision Transformer, given the pure encoder architecture and the extra \"classification token\". Assume a *224\\*224\\*3* image, after patching, the sequence length is *HW/P<sup>2</sup>=16\\*16=196* and the width is *14\\*14\\*3=768*. Given the hidden size of the model *D=768*, through linear projection layer (E), sequence *X [196\\*768]* are multiplied with weight *E [768\\*768]*. The resulting linear output *[196\\*768]* is then contacted with [cls], followed by adding standard 1D learnable positional embedding to be the transformer input *[197\\*768]*. After several transformer blocks, the output size does not change and the [cls] token is projected to a softmax classification layer\n\n#### Ablation experiments\n\nThe pre and post-processing are crucial for ViT given that the middle transformer encoder layers are kept as original. Multiple rounds of ablation experiments are carried out. \n\n- Position embedding schemes, 2D embedding and relative embedding are applied to compare with the standard 1D embedding, and no evident gain is spotted.\n\n  <img src=\"VIT positional embedding ablation.png\" alt=\"VIT positional embedding ablation\" style=\"zoom:30%;\" />\n\n- [cls] token vs average pooling, extra [cls] token is inherited from the Transformer model for text, and traditionally in CV, instead of an additional token, an average polling layer after the output layer is usually used as a classifier. The figure blow shows no both works. But in order to stick the original design as close as possible, [cls] token is applied.\n\n  <img src=\"VIT class token ablation.png\" alt=\"VIT class token ablation\" style=\"zoom:30%;\" />\n\nAnother analysis after the model description:\n\n**Inductive bias:** Less locality, translation equivariance and 2D neighbourhood structure are possessed by ViT, compared with CNN. \n\n**Hybrid Architecture:** CNN can be used as a special embedding, leveraging the inductive bias of the CNN model.\n\n#### Limitation on Fine-Tuning\n\nPre-train ViT at larger and higher resolution datasets is [proved](https://proceedings.neurips.cc/paper/2019/hash/d03a857a23b5285736c4d55e0bb067c8-Abstract.html) to be beneficial. Yet the input sequence lengths are different when training on two datasets with different resolutions, resulting in positional embeddings of different lengths. In this article, a 2D interpolation is applied to transfer a pre-trained positional embedding to another dataset to fine-tune. But the accuracy will loss if the resolution difference is too big.\n\n### Experiments\n\n#### Setup\n\nResNet, ViT, and the hybrid model are evaluated together and ViT wins taking account of the pre-training cost. Besides, a small self-supervision experiment is deployed and sees potential.\n\nTwo scales of ImageNet(1k and 21k) and JFT(303M) are used as pre-training dataset. Only classification tasks are evaluated with popular datasets.\n\n3 scales of ViT are designed with different patch size(inversely proportional to the amount of data). For example, ViT-L/16 means ViT-Large with 16 patches.\n\n<img src=\"ViT variants.png\" alt=\"ViT variants\" style=\"zoom:50%;\" />\n\n#### Comparison to SOTA\n\nAnd the best results are shown below:\n\n<img src=\"ViT results.png\" alt=\"ViT results\" style=\"zoom:60%;\" />\n\n#### Pre-training cost requirements\n\nFigure 3 and 4 shows the performance of the presented models on different sizes of per-training datasets.  ViT preforms competitive only starts from dataset 21k, and very well only on huge dataset.\n\nFigure 5 shows the transfer performances versus pre-training costs on JFT-300M of several models. And it shows that ViT is cheaper than ResNet. Interestingly, the Hybrid model is competitive on low pre-training cost.\n\n<img src=\"ViT ablation 2.png\" alt=\"ViT ablation 2\" style=\"zoom:55%;\" />\n\n#### Inspecting ViT\n\n<img src=\"ViT inspecting.png\" alt=\"ViT inspecting\" style=\"zoom:42%;\" />\n\n**Figure7 Left:** The learned linear projection weight matrix *E [768\\*768]* is inspected by PCA, and the first 28 components(modes) are visualised as embedding filters. They look pretty much similar to the early layer filters(kernels) of CNN (for example, the first layer of a CNN shown by [Brachnmann et.al](https://www.mdpi.com/2073-8994/8/12/144)). This similarity indicates that the linear patch embedding manages to represent the low-dimension structure of each patch. <img src=\"CNN first layer filters.png\" alt=\"CNN first layer filters\" style=\"zoom:40%;\" />\n\n**Figure7 mid:** Position embedding visualisation first shows that the spatial information is captured well by the E matrix, given that the similarity matrix between patches matches well with the distance relationships of patches. Second, patterns across rows (and columns) have similar representations, indicating the embedding layer has successful learned the row-column relationship. Overall, the 1D positional embedding has learned the 2D structure, coherent with the ablation experiment result. \n\n**Figure7 Right:** The receptive fields of the multi-head attention layers are evaluated by the mean attention distance. Compared with CNN whose receptive field increases linearly with the depth, the ViT attends the whole picture from the first layer, leveraging the natural advantage of transformer.\n\n#### Self-supervision\n\nA preliminary exploration on masked patch prediction for self-supervision (mimicking one of the BERT pre-training tasks) has been employed. But the result is not satisfying. And contrastive pre-training are mentioned as a future work.\n\n## Review\n\nThis is a concise-written, fundamental article. Just as presented in the conclusion part, it inspired many flow-up works from any direction in the CV area, such as applying to  more tasks, changing the architecture(tokenisation, transformer block([MLP-mixer](https://proceedings.neurips.cc/paper/2021/hash/cba0a4ee5ccd02fda0fe3f9a3e7b89fe-Abstract.html) changing multi-head attention layers to MLP , [meta-former](https://arxiv.org/abs/2111.11418): substituting multi-head attention layers to average pooling), changing objective function(self-supervised, contrastive learning), and multi modality. \n\nIt's still unclear whether convolution, attention or MLP will win this game.\n\n## Reference\n\n[Naseer, M. M., Ranasinghe, K., Khan, S. H., Hayat, M., Shahbaz Khan, F., & Yang, M. H. (2021). Intriguing properties of vision transformers. *Advances in Neural Information Processing Systems*, *34*.](https://proceedings.neurips.cc/paper/2021/hash/c404a5adbf90e09631678b13b05d9d7a-Abstract.html)\n\n[Beal, J., Kim, E., Tzeng, E., Park, D. H., Zhai, A., & Kislyuk, D. (2020). Toward transformer-based object detection. *arXiv preprint arXiv:2012.09958*.](https://arxiv.org/abs/2012.09958)\n\n[Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y., ... & Zhang, L. (2021). Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers. In *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition* (pp. 6881-6890).](http://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.html)\n\n[Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., ... & Guo, B. (2021). Swin transformer: Hierarchical vision transformer using shifted windows. In *Proceedings of the IEEE/CVF International Conference on Computer Vision* (pp. 10012-10022).](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.html)\n\n[Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., & Zagoruyko, S. (2020, August). End-to-end object detection with transformers. In *European conference on computer vision* (pp. 213-229). Springer, Cham.](https://arxiv.org/pdf/2005.12872.pdf,)\n\n[He, K., Chen, X., Xie, S., Li, Y., Dollr, P., & Girshick, R. (2021). Masked autoencoders are scalable vision learners. *arXiv preprint arXiv:2111.06377*.](https://arxiv.org/abs/2111.06377)\n\n[Chen, X., Xie, S., & He, K. (2021). An empirical study of training self-supervised vision transformers. In *Proceedings of the IEEE/CVF International Conference on Computer Vision* (pp. 9640-9649).](http://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html)\n\n[Caron, M., Touvron, H., Misra, I., Jgou, H., Mairal, J., Bojanowski, P., & Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In *Proceedings of the IEEE/CVF International Conference on Computer Vision* (pp. 9650-9660).](http://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html)\n\n[Zhai, X., Kolesnikov, A., Houlsby, N., & Beyer, L. (2021). Scaling Vision Transformers. *ArXiv, abs/2106.04560*.](https://arxiv.org/abs/2106.04560)\n\n[Wang, X., Girshick, R., Gupta, A., & He, K. (2018). Non-local neural networks. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 7794-7803).](http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.html)\n\n[Ramachandran, P., Parmar, N., Vaswani, A., Bello, I., Levskaya, A., & Shlens, J. (2019). Stand-alone self-attention in vision models. *Advances in Neural Information Processing Systems*, *32*.](https://proceedings.neurips.cc/paper/2019/hash/3416a75f4cea9109507cacd8e2f2aefc-Abstract.html)\n\n[Wang, H., Zhu, Y., Green, B., Adam, H., Yuille, A., & Chen, L. C. (2020, August). Axial-deeplab: Stand-alone axial-attention for panoptic segmentation. In *European Conference on Computer Vision* (pp. 108-126). Springer, Cham.](https://link.springer.com/chapter/10.1007/978-3-030-58548-8_7)\n\n[Cordonnier, J. B., Loukas, A., & Jaggi, M. (2019). On the relationship between self-attention and convolutional layers. *arXiv preprint arXiv:1911.03584*.](https://arxiv.org/abs/1911.03584)\n\n[Chen, Mark, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and Ilya Sutskever. \"Generative pretraining from pixels.\" In *International Conference on Machine Learning*, pp. 1691-1703. PMLR, 2020.](http://proceedings.mlr.press/v119/chen20s.html)\n\n[Touvron, H., Vedaldi, A., Douze, M., & Jgou, H. (2019). Fixing the train-test resolution discrepancy. *Advances in neural information processing systems*, *32*.](https://proceedings.neurips.cc/paper/2019/hash/d03a857a23b5285736c4d55e0bb067c8-Abstract.html)\n\n[Brachmann, A., & Redies, C. (2016). Using convolutional neural network filters to measure left-right mirror symmetry in images. *Symmetry*, *8*(12), 144.](https://www.mdpi.com/2073-8994/8/12/144)\n\n[Tolstikhin, I. O., Houlsby, N., Kolesnikov, A., Beyer, L., Zhai, X., Unterthiner, T., ... & Dosovitskiy, A. (2021). Mlp-mixer: An all-mlp architecture for vision. *Advances in Neural Information Processing Systems*, *34*.](https://proceedings.neurips.cc/paper/2021/hash/cba0a4ee5ccd02fda0fe3f9a3e7b89fe-Abstract.html)\n\n[Yu, W., Luo, M., Zhou, P., Si, C., Zhou, Y., Wang, X., ... & Yan, S. (2021). Metaformer is actually what you need for vision. arXiv preprint arXiv:2111.11418.](https://arxiv.org/abs/2111.11418)\n","slug":"paper-reading-Vision-Transformer","published":1,"updated":"2022-06-09T10:25:25.381Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz2a0021l8ybgt06dl9g","content":"<blockquote>\n<p>Presented in 2021, the vision transformer model (ViT) is the most influential work in the CV field recent years. Its variants outperform the dominant convolutional networks in almost all CV tasks such as <a href=\"https://paperswithcode.com/sota/image-classification-on-imagenet\">classification</a> and <a href=\"https://paperswithcode.com/sota/object-detection-on-coco\">object detection</a>. And it breaks the border of CV and NLP, providing new thoughts to CV and multi-model areas.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>\n<span id=\"more\"></span>\n<p>Paper:</p>\n<p><a href=\"https://arxiv.org/abs/2010.11929v2\">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></p>\n<p>Useful links:</p>\n<p>https://www.bilibili.com/video/BV15P4y137jb</p>\n<p>https://theaisummer.com/vision-transformer/</p>\n<p><img src=\"VIT properties.png\" srcset=\"/img/loading.gif\" lazyload alt=\"VIT properties\" style=\"zoom:50%;\" /></p>\n<p>Not only Vision Transformer (ViT) performs better on traditional CV tasks, it has more impressive properties. As shown above, <a href=\"https://proceedings.neurips.cc/paper/2021/hash/c404a5adbf90e09631678b13b05d9d7a-Abstract.html\">Naseer et al.</a> demonstrate the tasks where ViT shows extra performance over CNN models, even over humans.</p>\n<h2 id=\"notes\">Notes</h2>\n<h3 id=\"abstract\">Abstract</h3>\n<p>While Transformer-based models such as BERT, GPT series, and T5 nail the NLP tasks, CV tasks remain dominated by CNN-based models. This paper applied a pure transformer encoder (same as BERT) to sequences of cut images and obtains a good classification result, especially with <strong>supervised</strong> pre-training on a large dataset then fine tuning on a mid-size dataset. Besides, fewer computational resources (meaning 2500 days of TPUv3) are need to attain good results, compared with CNN models.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>Besides the paraphrasing part, the conclusion part discusses the future work based on the ViT. And all of them have follow-up works.</p>\n<ul>\n<li>Apply ViT to other CV tasks, given the promising performance of <a href=\"https://arxiv.org/pdf/2005.12872.pdf,\">DETR</a>. Only 1 and a half month later, <a href=\"https://arxiv.org/abs/2012.09958\">ViT-FRCNN</a> and <a href=\"http://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.html\">SEDR</a> mange to apply ViT on detection and segmentation respectively. And after 3 months, <a href=\"https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.html\">Swin Transformer</a> introduces hierarchical feature to transformer, making ViT more suitable to vision tasks.</li>\n<li>Self-supervised pre-training, given the great results of BERT and GPT in the NLP field. Initial explorations in the paper show a gap from the supervised pre-training. One year later, <a href=\"https://arxiv.org/abs/2111.06377\">MAE</a> narrows the gap successfully by generative model.\n<ul>\n<li>Besides, in the section of self-supervised learning, a contrastive learning is mentioned as well, and <a href=\"http://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html\">MOCO v3</a> and <a href=\"http://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html\">DINO</a> follow this line.</li>\n</ul></li>\n<li>Further scaling up this model. Half year later, same group introduces <a href=\"https://arxiv.org/pdf/2106.04560v1.pdf\">Vit-G</a> with two billion parameters, attaining new SOTA on ImageNet of 90.45%.</li>\n</ul>\n<h3 id=\"introduction\">Introduction</h3>\n<p>Success of Transformer-based models on NLP tasks are firstly reviewed. And it is natural trying to apply such self-attention mechanism to vision. Yet here are one major obstacle:</p>\n<ul>\n<li>How to transfer a 2D picture to a 1D sequence?</li>\n</ul>\n<p>One intuitive thought is to flatten the picture directly and treat each pixel as an element. In this way, a medium size 224*224 picture will be converted to a 50,176 long sequence. However, the sequence length is quadratically related to model complexity. Morden hardware only supports input sequence length &lt;1000 of a pure self-attention model. For example BERT only accepts input length of 512.</p>\n<p>Yet the authors mange to incorporate the original transformer encoder in CV. In order to address the sequence length problem, they split the image into 16*16 patches, each patches denotes a sequence element (token). In this way, a 224*224 image can be converted as a sequence length of 16*16 with each element sized 14*14. Each element then gets linearised through a FC layer before being passed into the transformer encoder.</p>\n<p>And the afterwards experiments show that the new model doesn't perform well on mid-size model. One explanation is that transformer model lack the image-related inductive bias of CNN (locality and translation equalisation). Yet with pre-training on large dataset such as JFT-300 and ImagNet-21K, a better result than CNN can be approached.</p>\n<h3 id=\"related-work\">Related work</h3>\n<p><em>It is a detailed related work covering all the aspects in the original paper. I just pick few of them.</em></p>\n<p>All the related works aim at reducing the sequence length within the limitation caused by self-attention. Some try to combine CNN with self-attention. For example <a href=\"http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.html\">Wang, X et al.'s work</a> takes the feature map extracted by CNN as the input of transformer. Others try to replace the CNN with a special variation of self-attention. For example, <a href=\"https://proceedings.neurips.cc/paper/2019/hash/3416a75f4cea9109507cacd8e2f2aefc-Abstract.html\">Ramachandran et al.'s work</a> replaces all convolutional sublayers of the ResNet-50 model with self-attention layers. To reduce the computational cost, a local region of the image instead of the whole image is used as the receptive field of the self-attention layer, meaning each pixel only attends to its neighbours in a restricted area. In another work line, <a href=\"https://link.springer.com/chapter/10.1007/978-3-030-58548-8_7\">Wang, H et.al's work</a> factorising 2D self-attention into two 1D self-attentions to significantly reduce computation complexity.</p>\n<p>And there is a very similar <a href=\"https://arxiv.org/abs/1911.03584\">Cordonnier et al's work</a> also split the images before the self-attention layer. Yet the patch size is 2*2 and with the dataset only <a href=\"https://paperswithcode.com/sota/image-classification-on-cifar-10\">CIFAR-10</a>. This paper enlarges the model, apply it in big dataset, and shows the scalability.</p>\n<p>Another related work image GPT(<a href=\"http://proceedings.mlr.press/v119/chen20s.html\">iGPT</a>) trains a GPT-2 scale generative network. Yet the highest accuracy on ImageNet is 72%, way less than 88% of this paper. But in 2021, an afterwards generative network <a href=\"https://arxiv.org/abs/2111.06377\">MAE</a> shows a competitive result of 87.8%, with good transfer leaning capability on segmentation and object detection as well.</p>\n<p>Besides, works exploring transfer learning performance of CNN model on larger datasets such as ImageNet-21k and JFT-300M are mentioned. And this paper studies the transformer instead of the CNN.</p>\n<h3 id=\"method\">Method</h3>\n<p>The whole big idea of the method part is leaving as much as possible the original transformer architecture in order to leverage the good feature and the existing mature efficient implementations of it.</p>\n<h4 id=\"vision-transformer-vit\">Vision Transformer (VIT)</h4>\n<p><img src=\"VIT model overview.png\" srcset=\"/img/loading.gif\" lazyload alt=\"VIT model overview\" style=\"zoom:60%;\" /></p>\n<p><img src=\"VIT algorithm.png\" srcset=\"/img/loading.gif\" lazyload alt=\"VIT algorithm\" style=\"zoom:40%;\" /></p>\n<p>From the overview, and the algorithm it should be called Vision BERT instead of Vision Transformer, given the pure encoder architecture and the extra \"classification token\". Assume a <em>224*224*3</em> image, after patching, the sequence length is <em>HW/P<sup>2</sup>=16*16=196</em> and the width is <em>14*14*3=768</em>. Given the hidden size of the model <em>D=768</em>, through linear projection layer (E), sequence <em>X [196*768]</em> are multiplied with weight <em>E [768*768]</em>. The resulting linear output <em>[196*768]</em> is then contacted with [cls], followed by adding standard 1D learnable positional embedding to be the transformer input <em>[197*768]</em>. After several transformer blocks, the output size does not change and the [cls] token is projected to a softmax classification layer</p>\n<h4 id=\"ablation-experiments\">Ablation experiments</h4>\n<p>The pre and post-processing are crucial for ViT given that the middle transformer encoder layers are kept as original. Multiple rounds of ablation experiments are carried out.</p>\n<ul>\n<li><p>Position embedding schemes, 2D embedding and relative embedding are applied to compare with the standard 1D embedding, and no evident gain is spotted.</p>\n<p><img src=\"VIT positional embedding ablation.png\" srcset=\"/img/loading.gif\" lazyload alt=\"VIT positional embedding ablation\" style=\"zoom:30%;\" /></p></li>\n<li><p>[cls] token vs average pooling, extra [cls] token is inherited from the Transformer model for text, and traditionally in CV, instead of an additional token, an average polling layer after the output layer is usually used as a classifier. The figure blow shows no both works. But in order to stick the original design as close as possible, [cls] token is applied.</p>\n<p><img src=\"VIT class token ablation.png\" srcset=\"/img/loading.gif\" lazyload alt=\"VIT class token ablation\" style=\"zoom:30%;\" /></p></li>\n</ul>\n<p>Another analysis after the model description:</p>\n<p><strong>Inductive bias:</strong> Less locality, translation equivariance and 2D neighbourhood structure are possessed by ViT, compared with CNN.</p>\n<p><strong>Hybrid Architecture:</strong> CNN can be used as a special embedding, leveraging the inductive bias of the CNN model.</p>\n<h4 id=\"limitation-on-fine-tuning\">Limitation on Fine-Tuning</h4>\n<p>Pre-train ViT at larger and higher resolution datasets is <a href=\"https://proceedings.neurips.cc/paper/2019/hash/d03a857a23b5285736c4d55e0bb067c8-Abstract.html\">proved</a> to be beneficial. Yet the input sequence lengths are different when training on two datasets with different resolutions, resulting in positional embeddings of different lengths. In this article, a 2D interpolation is applied to transfer a pre-trained positional embedding to another dataset to fine-tune. But the accuracy will loss if the resolution difference is too big.</p>\n<h3 id=\"experiments\">Experiments</h3>\n<h4 id=\"setup\">Setup</h4>\n<p>ResNet, ViT, and the hybrid model are evaluated together and ViT wins taking account of the pre-training cost. Besides, a small self-supervision experiment is deployed and sees potential.</p>\n<p>Two scales of ImageNet(1k and 21k) and JFT(303M) are used as pre-training dataset. Only classification tasks are evaluated with popular datasets.</p>\n<p>3 scales of ViT are designed with different patch size(inversely proportional to the amount of data). For example, ViT-L/16 means ViT-Large with 16 patches.</p>\n<p><img src=\"ViT variants.png\" srcset=\"/img/loading.gif\" lazyload alt=\"ViT variants\" style=\"zoom:50%;\" /></p>\n<h4 id=\"comparison-to-sota\">Comparison to SOTA</h4>\n<p>And the best results are shown below:</p>\n<p><img src=\"ViT results.png\" srcset=\"/img/loading.gif\" lazyload alt=\"ViT results\" style=\"zoom:60%;\" /></p>\n<h4 id=\"pre-training-cost-requirements\">Pre-training cost requirements</h4>\n<p>Figure 3 and 4 shows the performance of the presented models on different sizes of per-training datasets. ViT preforms competitive only starts from dataset 21k, and very well only on huge dataset.</p>\n<p>Figure 5 shows the transfer performances versus pre-training costs on JFT-300M of several models. And it shows that ViT is cheaper than ResNet. Interestingly, the Hybrid model is competitive on low pre-training cost.</p>\n<p><img src=\"ViT ablation 2.png\" srcset=\"/img/loading.gif\" lazyload alt=\"ViT ablation 2\" style=\"zoom:55%;\" /></p>\n<h4 id=\"inspecting-vit\">Inspecting ViT</h4>\n<p><img src=\"ViT inspecting.png\" srcset=\"/img/loading.gif\" lazyload alt=\"ViT inspecting\" style=\"zoom:42%;\" /></p>\n<p><strong>Figure7 Left:</strong> The learned linear projection weight matrix <em>E [768*768]</em> is inspected by PCA, and the first 28 components(modes) are visualised as embedding filters. They look pretty much similar to the early layer filters(kernels) of CNN (for example, the first layer of a CNN shown by <a href=\"https://www.mdpi.com/2073-8994/8/12/144\">Brachnmann et.al</a>). This similarity indicates that the linear patch embedding manages to represent the low-dimension structure of each patch. <img src=\"CNN first layer filters.png\" srcset=\"/img/loading.gif\" lazyload alt=\"CNN first layer filters\" style=\"zoom:40%;\" /></p>\n<p><strong>Figure7 mid:</strong> Position embedding visualisation first shows that the spatial information is captured well by the E matrix, given that the similarity matrix between patches matches well with the distance relationships of patches. Second, patterns across rows (and columns) have similar representations, indicating the embedding layer has successful learned the row-column relationship. Overall, the 1D positional embedding has learned the 2D structure, coherent with the ablation experiment result.</p>\n<p><strong>Figure7 Right:</strong> The receptive fields of the multi-head attention layers are evaluated by the mean attention distance. Compared with CNN whose receptive field increases linearly with the depth, the ViT attends the whole picture from the first layer, leveraging the natural advantage of transformer.</p>\n<h4 id=\"self-supervision\">Self-supervision</h4>\n<p>A preliminary exploration on masked patch prediction for self-supervision (mimicking one of the BERT pre-training tasks) has been employed. But the result is not satisfying. And contrastive pre-training are mentioned as a future work.</p>\n<h2 id=\"review\">Review</h2>\n<p>This is a concise-written, fundamental article. Just as presented in the conclusion part, it inspired many flow-up works from any direction in the CV area, such as applying to more tasks, changing the architecture(tokenisation, transformer block(<a href=\"https://proceedings.neurips.cc/paper/2021/hash/cba0a4ee5ccd02fda0fe3f9a3e7b89fe-Abstract.html\">MLP-mixer</a> changing multi-head attention layers to MLP , <a href=\"https://arxiv.org/abs/2111.11418\">meta-former</a>: substituting multi-head attention layers to average pooling), changing objective function(self-supervised, contrastive learning), and multi modality.</p>\n<p>It's still unclear whether convolution, attention or MLP will win this game.</p>\n<h2 id=\"reference\">Reference</h2>\n<p><a href=\"https://proceedings.neurips.cc/paper/2021/hash/c404a5adbf90e09631678b13b05d9d7a-Abstract.html\">Naseer, M. M., Ranasinghe, K., Khan, S. H., Hayat, M., Shahbaz Khan, F., &amp; Yang, M. H. (2021). Intriguing properties of vision transformers. <em>Advances in Neural Information Processing Systems</em>, <em>34</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/2012.09958\">Beal, J., Kim, E., Tzeng, E., Park, D. H., Zhai, A., &amp; Kislyuk, D. (2020). Toward transformer-based object detection. <em>arXiv preprint arXiv:2012.09958</em>.</a></p>\n<p><a href=\"http://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.html\">Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y., ... &amp; Zhang, L. (2021). Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers. In <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em> (pp. 6881-6890).</a></p>\n<p><a href=\"https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.html\">Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., ... &amp; Guo, B. (2021). Swin transformer: Hierarchical vision transformer using shifted windows. In <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em> (pp. 10012-10022).</a></p>\n<p><a href=\"https://arxiv.org/pdf/2005.12872.pdf,\">Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., &amp; Zagoruyko, S. (2020, August). End-to-end object detection with transformers. In <em>European conference on computer vision</em> (pp. 213-229). Springer, Cham.</a></p>\n<p><a href=\"https://arxiv.org/abs/2111.06377\">He, K., Chen, X., Xie, S., Li, Y., Dollr, P., &amp; Girshick, R. (2021). Masked autoencoders are scalable vision learners. <em>arXiv preprint arXiv:2111.06377</em>.</a></p>\n<p><a href=\"http://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html\">Chen, X., Xie, S., &amp; He, K. (2021). An empirical study of training self-supervised vision transformers. In <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em> (pp. 9640-9649).</a></p>\n<p><a href=\"http://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html\">Caron, M., Touvron, H., Misra, I., Jgou, H., Mairal, J., Bojanowski, P., &amp; Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em> (pp. 9650-9660).</a></p>\n<p><a href=\"https://arxiv.org/abs/2106.04560\">Zhai, X., Kolesnikov, A., Houlsby, N., &amp; Beyer, L. (2021). Scaling Vision Transformers. <em>ArXiv, abs/2106.04560</em>.</a></p>\n<p><a href=\"http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.html\">Wang, X., Girshick, R., Gupta, A., &amp; He, K. (2018). Non-local neural networks. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp. 7794-7803).</a></p>\n<p><a href=\"https://proceedings.neurips.cc/paper/2019/hash/3416a75f4cea9109507cacd8e2f2aefc-Abstract.html\">Ramachandran, P., Parmar, N., Vaswani, A., Bello, I., Levskaya, A., &amp; Shlens, J. (2019). Stand-alone self-attention in vision models. <em>Advances in Neural Information Processing Systems</em>, <em>32</em>.</a></p>\n<p><a href=\"https://link.springer.com/chapter/10.1007/978-3-030-58548-8_7\">Wang, H., Zhu, Y., Green, B., Adam, H., Yuille, A., &amp; Chen, L. C. (2020, August). Axial-deeplab: Stand-alone axial-attention for panoptic segmentation. In <em>European Conference on Computer Vision</em> (pp. 108-126). Springer, Cham.</a></p>\n<p><a href=\"https://arxiv.org/abs/1911.03584\">Cordonnier, J. B., Loukas, A., &amp; Jaggi, M. (2019). On the relationship between self-attention and convolutional layers. <em>arXiv preprint arXiv:1911.03584</em>.</a></p>\n<p><a href=\"http://proceedings.mlr.press/v119/chen20s.html\">Chen, Mark, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and Ilya Sutskever. \"Generative pretraining from pixels.\" In <em>International Conference on Machine Learning</em>, pp. 1691-1703. PMLR, 2020.</a></p>\n<p><a href=\"https://proceedings.neurips.cc/paper/2019/hash/d03a857a23b5285736c4d55e0bb067c8-Abstract.html\">Touvron, H., Vedaldi, A., Douze, M., &amp; Jgou, H. (2019). Fixing the train-test resolution discrepancy. <em>Advances in neural information processing systems</em>, <em>32</em>.</a></p>\n<p><a href=\"https://www.mdpi.com/2073-8994/8/12/144\">Brachmann, A., &amp; Redies, C. (2016). Using convolutional neural network filters to measure left-right mirror symmetry in images. <em>Symmetry</em>, <em>8</em>(12), 144.</a></p>\n<p><a href=\"https://proceedings.neurips.cc/paper/2021/hash/cba0a4ee5ccd02fda0fe3f9a3e7b89fe-Abstract.html\">Tolstikhin, I. O., Houlsby, N., Kolesnikov, A., Beyer, L., Zhai, X., Unterthiner, T., ... &amp; Dosovitskiy, A. (2021). Mlp-mixer: An all-mlp architecture for vision. <em>Advances in Neural Information Processing Systems</em>, <em>34</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/2111.11418\">Yu, W., Luo, M., Zhou, P., Si, C., Zhou, Y., Wang, X., ... &amp; Yan, S. (2021). Metaformer is actually what you need for vision. arXiv preprint arXiv:2111.11418.</a></p>\n","site":{"data":{}},"wordcount":12278,"excerpt":"<blockquote>\n<p>Presented in 2021, the vision transformer model (ViT) is the most influential work in the CV field recent years. Its variants outperform the dominant convolutional networks in almost all CV tasks such as <a href=\"https://paperswithcode.com/sota/image-classification-on-imagenet\">classification</a> and <a href=\"https://paperswithcode.com/sota/object-detection-on-coco\">object detection</a>. And it breaks the border of CV and NLP, providing new thoughts to CV and multi-model areas.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>","more":"<p>Paper:</p>\n<p><a href=\"https://arxiv.org/abs/2010.11929v2\">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></p>\n<p>Useful links:</p>\n<p>https://www.bilibili.com/video/BV15P4y137jb</p>\n<p>https://theaisummer.com/vision-transformer/</p>\n<p><img src=\"VIT properties.png\" alt=\"VIT properties\" style=\"zoom:50%;\" /></p>\n<p>Not only Vision Transformer (ViT) performs better on traditional CV tasks, it has more impressive properties. As shown above, <a href=\"https://proceedings.neurips.cc/paper/2021/hash/c404a5adbf90e09631678b13b05d9d7a-Abstract.html\">Naseer et al.</a> demonstrate the tasks where ViT shows extra performance over CNN models, even over humans.</p>\n<h2 id=\"notes\">Notes</h2>\n<h3 id=\"abstract\">Abstract</h3>\n<p>While Transformer-based models such as BERT, GPT series, and T5 nail the NLP tasks, CV tasks remain dominated by CNN-based models. This paper applied a pure transformer encoder (same as BERT) to sequences of cut images and obtains a good classification result, especially with <strong>supervised</strong> pre-training on a large dataset then fine tuning on a mid-size dataset. Besides, fewer computational resources (meaning 2500 days of TPUv3) are need to attain good results, compared with CNN models.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>Besides the paraphrasing part, the conclusion part discusses the future work based on the ViT. And all of them have follow-up works.</p>\n<ul>\n<li>Apply ViT to other CV tasks, given the promising performance of <a href=\"https://arxiv.org/pdf/2005.12872.pdf,\">DETR</a>. Only 1 and a half month later, <a href=\"https://arxiv.org/abs/2012.09958\">ViT-FRCNN</a> and <a href=\"http://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.html\">SEDR</a> mange to apply ViT on detection and segmentation respectively. And after 3 months, <a href=\"https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.html\">Swin Transformer</a> introduces hierarchical feature to transformer, making ViT more suitable to vision tasks.</li>\n<li>Self-supervised pre-training, given the great results of BERT and GPT in the NLP field. Initial explorations in the paper show a gap from the supervised pre-training. One year later, <a href=\"https://arxiv.org/abs/2111.06377\">MAE</a> narrows the gap successfully by generative model.\n<ul>\n<li>Besides, in the section of self-supervised learning, a contrastive learning is mentioned as well, and <a href=\"http://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html\">MOCO v3</a> and <a href=\"http://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html\">DINO</a> follow this line.</li>\n</ul></li>\n<li>Further scaling up this model. Half year later, same group introduces <a href=\"https://arxiv.org/pdf/2106.04560v1.pdf\">Vit-G</a> with two billion parameters, attaining new SOTA on ImageNet of 90.45%.</li>\n</ul>\n<h3 id=\"introduction\">Introduction</h3>\n<p>Success of Transformer-based models on NLP tasks are firstly reviewed. And it is natural trying to apply such self-attention mechanism to vision. Yet here are one major obstacle:</p>\n<ul>\n<li>How to transfer a 2D picture to a 1D sequence?</li>\n</ul>\n<p>One intuitive thought is to flatten the picture directly and treat each pixel as an element. In this way, a medium size 224*224 picture will be converted to a 50,176 long sequence. However, the sequence length is quadratically related to model complexity. Morden hardware only supports input sequence length &lt;1000 of a pure self-attention model. For example BERT only accepts input length of 512.</p>\n<p>Yet the authors mange to incorporate the original transformer encoder in CV. In order to address the sequence length problem, they split the image into 16*16 patches, each patches denotes a sequence element (token). In this way, a 224*224 image can be converted as a sequence length of 16*16 with each element sized 14*14. Each element then gets linearised through a FC layer before being passed into the transformer encoder.</p>\n<p>And the afterwards experiments show that the new model doesn't perform well on mid-size model. One explanation is that transformer model lack the image-related inductive bias of CNN (locality and translation equalisation). Yet with pre-training on large dataset such as JFT-300 and ImagNet-21K, a better result than CNN can be approached.</p>\n<h3 id=\"related-work\">Related work</h3>\n<p><em>It is a detailed related work covering all the aspects in the original paper. I just pick few of them.</em></p>\n<p>All the related works aim at reducing the sequence length within the limitation caused by self-attention. Some try to combine CNN with self-attention. For example <a href=\"http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.html\">Wang, X et al.'s work</a> takes the feature map extracted by CNN as the input of transformer. Others try to replace the CNN with a special variation of self-attention. For example, <a href=\"https://proceedings.neurips.cc/paper/2019/hash/3416a75f4cea9109507cacd8e2f2aefc-Abstract.html\">Ramachandran et al.'s work</a> replaces all convolutional sublayers of the ResNet-50 model with self-attention layers. To reduce the computational cost, a local region of the image instead of the whole image is used as the receptive field of the self-attention layer, meaning each pixel only attends to its neighbours in a restricted area. In another work line, <a href=\"https://link.springer.com/chapter/10.1007/978-3-030-58548-8_7\">Wang, H et.al's work</a> factorising 2D self-attention into two 1D self-attentions to significantly reduce computation complexity.</p>\n<p>And there is a very similar <a href=\"https://arxiv.org/abs/1911.03584\">Cordonnier et al's work</a> also split the images before the self-attention layer. Yet the patch size is 2*2 and with the dataset only <a href=\"https://paperswithcode.com/sota/image-classification-on-cifar-10\">CIFAR-10</a>. This paper enlarges the model, apply it in big dataset, and shows the scalability.</p>\n<p>Another related work image GPT(<a href=\"http://proceedings.mlr.press/v119/chen20s.html\">iGPT</a>) trains a GPT-2 scale generative network. Yet the highest accuracy on ImageNet is 72%, way less than 88% of this paper. But in 2021, an afterwards generative network <a href=\"https://arxiv.org/abs/2111.06377\">MAE</a> shows a competitive result of 87.8%, with good transfer leaning capability on segmentation and object detection as well.</p>\n<p>Besides, works exploring transfer learning performance of CNN model on larger datasets such as ImageNet-21k and JFT-300M are mentioned. And this paper studies the transformer instead of the CNN.</p>\n<h3 id=\"method\">Method</h3>\n<p>The whole big idea of the method part is leaving as much as possible the original transformer architecture in order to leverage the good feature and the existing mature efficient implementations of it.</p>\n<h4 id=\"vision-transformer-vit\">Vision Transformer (VIT)</h4>\n<p><img src=\"VIT model overview.png\" alt=\"VIT model overview\" style=\"zoom:60%;\" /></p>\n<p><img src=\"VIT algorithm.png\" alt=\"VIT algorithm\" style=\"zoom:40%;\" /></p>\n<p>From the overview, and the algorithm it should be called Vision BERT instead of Vision Transformer, given the pure encoder architecture and the extra \"classification token\". Assume a <em>224*224*3</em> image, after patching, the sequence length is <em>HW/P<sup>2</sup>=16*16=196</em> and the width is <em>14*14*3=768</em>. Given the hidden size of the model <em>D=768</em>, through linear projection layer (E), sequence <em>X [196*768]</em> are multiplied with weight <em>E [768*768]</em>. The resulting linear output <em>[196*768]</em> is then contacted with [cls], followed by adding standard 1D learnable positional embedding to be the transformer input <em>[197*768]</em>. After several transformer blocks, the output size does not change and the [cls] token is projected to a softmax classification layer</p>\n<h4 id=\"ablation-experiments\">Ablation experiments</h4>\n<p>The pre and post-processing are crucial for ViT given that the middle transformer encoder layers are kept as original. Multiple rounds of ablation experiments are carried out.</p>\n<ul>\n<li><p>Position embedding schemes, 2D embedding and relative embedding are applied to compare with the standard 1D embedding, and no evident gain is spotted.</p>\n<p><img src=\"VIT positional embedding ablation.png\" alt=\"VIT positional embedding ablation\" style=\"zoom:30%;\" /></p></li>\n<li><p>[cls] token vs average pooling, extra [cls] token is inherited from the Transformer model for text, and traditionally in CV, instead of an additional token, an average polling layer after the output layer is usually used as a classifier. The figure blow shows no both works. But in order to stick the original design as close as possible, [cls] token is applied.</p>\n<p><img src=\"VIT class token ablation.png\" alt=\"VIT class token ablation\" style=\"zoom:30%;\" /></p></li>\n</ul>\n<p>Another analysis after the model description:</p>\n<p><strong>Inductive bias:</strong> Less locality, translation equivariance and 2D neighbourhood structure are possessed by ViT, compared with CNN.</p>\n<p><strong>Hybrid Architecture:</strong> CNN can be used as a special embedding, leveraging the inductive bias of the CNN model.</p>\n<h4 id=\"limitation-on-fine-tuning\">Limitation on Fine-Tuning</h4>\n<p>Pre-train ViT at larger and higher resolution datasets is <a href=\"https://proceedings.neurips.cc/paper/2019/hash/d03a857a23b5285736c4d55e0bb067c8-Abstract.html\">proved</a> to be beneficial. Yet the input sequence lengths are different when training on two datasets with different resolutions, resulting in positional embeddings of different lengths. In this article, a 2D interpolation is applied to transfer a pre-trained positional embedding to another dataset to fine-tune. But the accuracy will loss if the resolution difference is too big.</p>\n<h3 id=\"experiments\">Experiments</h3>\n<h4 id=\"setup\">Setup</h4>\n<p>ResNet, ViT, and the hybrid model are evaluated together and ViT wins taking account of the pre-training cost. Besides, a small self-supervision experiment is deployed and sees potential.</p>\n<p>Two scales of ImageNet(1k and 21k) and JFT(303M) are used as pre-training dataset. Only classification tasks are evaluated with popular datasets.</p>\n<p>3 scales of ViT are designed with different patch size(inversely proportional to the amount of data). For example, ViT-L/16 means ViT-Large with 16 patches.</p>\n<p><img src=\"ViT variants.png\" alt=\"ViT variants\" style=\"zoom:50%;\" /></p>\n<h4 id=\"comparison-to-sota\">Comparison to SOTA</h4>\n<p>And the best results are shown below:</p>\n<p><img src=\"ViT results.png\" alt=\"ViT results\" style=\"zoom:60%;\" /></p>\n<h4 id=\"pre-training-cost-requirements\">Pre-training cost requirements</h4>\n<p>Figure 3 and 4 shows the performance of the presented models on different sizes of per-training datasets. ViT preforms competitive only starts from dataset 21k, and very well only on huge dataset.</p>\n<p>Figure 5 shows the transfer performances versus pre-training costs on JFT-300M of several models. And it shows that ViT is cheaper than ResNet. Interestingly, the Hybrid model is competitive on low pre-training cost.</p>\n<p><img src=\"ViT ablation 2.png\" alt=\"ViT ablation 2\" style=\"zoom:55%;\" /></p>\n<h4 id=\"inspecting-vit\">Inspecting ViT</h4>\n<p><img src=\"ViT inspecting.png\" alt=\"ViT inspecting\" style=\"zoom:42%;\" /></p>\n<p><strong>Figure7 Left:</strong> The learned linear projection weight matrix <em>E [768*768]</em> is inspected by PCA, and the first 28 components(modes) are visualised as embedding filters. They look pretty much similar to the early layer filters(kernels) of CNN (for example, the first layer of a CNN shown by <a href=\"https://www.mdpi.com/2073-8994/8/12/144\">Brachnmann et.al</a>). This similarity indicates that the linear patch embedding manages to represent the low-dimension structure of each patch. <img src=\"CNN first layer filters.png\" alt=\"CNN first layer filters\" style=\"zoom:40%;\" /></p>\n<p><strong>Figure7 mid:</strong> Position embedding visualisation first shows that the spatial information is captured well by the E matrix, given that the similarity matrix between patches matches well with the distance relationships of patches. Second, patterns across rows (and columns) have similar representations, indicating the embedding layer has successful learned the row-column relationship. Overall, the 1D positional embedding has learned the 2D structure, coherent with the ablation experiment result.</p>\n<p><strong>Figure7 Right:</strong> The receptive fields of the multi-head attention layers are evaluated by the mean attention distance. Compared with CNN whose receptive field increases linearly with the depth, the ViT attends the whole picture from the first layer, leveraging the natural advantage of transformer.</p>\n<h4 id=\"self-supervision\">Self-supervision</h4>\n<p>A preliminary exploration on masked patch prediction for self-supervision (mimicking one of the BERT pre-training tasks) has been employed. But the result is not satisfying. And contrastive pre-training are mentioned as a future work.</p>\n<h2 id=\"review\">Review</h2>\n<p>This is a concise-written, fundamental article. Just as presented in the conclusion part, it inspired many flow-up works from any direction in the CV area, such as applying to more tasks, changing the architecture(tokenisation, transformer block(<a href=\"https://proceedings.neurips.cc/paper/2021/hash/cba0a4ee5ccd02fda0fe3f9a3e7b89fe-Abstract.html\">MLP-mixer</a> changing multi-head attention layers to MLP , <a href=\"https://arxiv.org/abs/2111.11418\">meta-former</a>: substituting multi-head attention layers to average pooling), changing objective function(self-supervised, contrastive learning), and multi modality.</p>\n<p>It's still unclear whether convolution, attention or MLP will win this game.</p>\n<h2 id=\"reference\">Reference</h2>\n<p><a href=\"https://proceedings.neurips.cc/paper/2021/hash/c404a5adbf90e09631678b13b05d9d7a-Abstract.html\">Naseer, M. M., Ranasinghe, K., Khan, S. H., Hayat, M., Shahbaz Khan, F., &amp; Yang, M. H. (2021). Intriguing properties of vision transformers. <em>Advances in Neural Information Processing Systems</em>, <em>34</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/2012.09958\">Beal, J., Kim, E., Tzeng, E., Park, D. H., Zhai, A., &amp; Kislyuk, D. (2020). Toward transformer-based object detection. <em>arXiv preprint arXiv:2012.09958</em>.</a></p>\n<p><a href=\"http://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.html\">Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y., ... &amp; Zhang, L. (2021). Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers. In <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em> (pp. 6881-6890).</a></p>\n<p><a href=\"https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.html\">Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., ... &amp; Guo, B. (2021). Swin transformer: Hierarchical vision transformer using shifted windows. In <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em> (pp. 10012-10022).</a></p>\n<p><a href=\"https://arxiv.org/pdf/2005.12872.pdf,\">Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., &amp; Zagoruyko, S. (2020, August). End-to-end object detection with transformers. In <em>European conference on computer vision</em> (pp. 213-229). Springer, Cham.</a></p>\n<p><a href=\"https://arxiv.org/abs/2111.06377\">He, K., Chen, X., Xie, S., Li, Y., Dollr, P., &amp; Girshick, R. (2021). Masked autoencoders are scalable vision learners. <em>arXiv preprint arXiv:2111.06377</em>.</a></p>\n<p><a href=\"http://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html\">Chen, X., Xie, S., &amp; He, K. (2021). An empirical study of training self-supervised vision transformers. In <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em> (pp. 9640-9649).</a></p>\n<p><a href=\"http://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html\">Caron, M., Touvron, H., Misra, I., Jgou, H., Mairal, J., Bojanowski, P., &amp; Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em> (pp. 9650-9660).</a></p>\n<p><a href=\"https://arxiv.org/abs/2106.04560\">Zhai, X., Kolesnikov, A., Houlsby, N., &amp; Beyer, L. (2021). Scaling Vision Transformers. <em>ArXiv, abs/2106.04560</em>.</a></p>\n<p><a href=\"http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.html\">Wang, X., Girshick, R., Gupta, A., &amp; He, K. (2018). Non-local neural networks. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp. 7794-7803).</a></p>\n<p><a href=\"https://proceedings.neurips.cc/paper/2019/hash/3416a75f4cea9109507cacd8e2f2aefc-Abstract.html\">Ramachandran, P., Parmar, N., Vaswani, A., Bello, I., Levskaya, A., &amp; Shlens, J. (2019). Stand-alone self-attention in vision models. <em>Advances in Neural Information Processing Systems</em>, <em>32</em>.</a></p>\n<p><a href=\"https://link.springer.com/chapter/10.1007/978-3-030-58548-8_7\">Wang, H., Zhu, Y., Green, B., Adam, H., Yuille, A., &amp; Chen, L. C. (2020, August). Axial-deeplab: Stand-alone axial-attention for panoptic segmentation. In <em>European Conference on Computer Vision</em> (pp. 108-126). Springer, Cham.</a></p>\n<p><a href=\"https://arxiv.org/abs/1911.03584\">Cordonnier, J. B., Loukas, A., &amp; Jaggi, M. (2019). On the relationship between self-attention and convolutional layers. <em>arXiv preprint arXiv:1911.03584</em>.</a></p>\n<p><a href=\"http://proceedings.mlr.press/v119/chen20s.html\">Chen, Mark, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and Ilya Sutskever. \"Generative pretraining from pixels.\" In <em>International Conference on Machine Learning</em>, pp. 1691-1703. PMLR, 2020.</a></p>\n<p><a href=\"https://proceedings.neurips.cc/paper/2019/hash/d03a857a23b5285736c4d55e0bb067c8-Abstract.html\">Touvron, H., Vedaldi, A., Douze, M., &amp; Jgou, H. (2019). Fixing the train-test resolution discrepancy. <em>Advances in neural information processing systems</em>, <em>32</em>.</a></p>\n<p><a href=\"https://www.mdpi.com/2073-8994/8/12/144\">Brachmann, A., &amp; Redies, C. (2016). Using convolutional neural network filters to measure left-right mirror symmetry in images. <em>Symmetry</em>, <em>8</em>(12), 144.</a></p>\n<p><a href=\"https://proceedings.neurips.cc/paper/2021/hash/cba0a4ee5ccd02fda0fe3f9a3e7b89fe-Abstract.html\">Tolstikhin, I. O., Houlsby, N., Kolesnikov, A., Beyer, L., Zhai, X., Unterthiner, T., ... &amp; Dosovitskiy, A. (2021). Mlp-mixer: An all-mlp architecture for vision. <em>Advances in Neural Information Processing Systems</em>, <em>34</em>.</a></p>\n<p><a href=\"https://arxiv.org/abs/2111.11418\">Yu, W., Luo, M., Zhou, P., Si, C., Zhou, Y., Wang, X., ... &amp; Yan, S. (2021). Metaformer is actually what you need for vision. arXiv preprint arXiv:2111.11418.</a></p>"},{"title":"Contrastive learning review","author":"Ryan LI","toc":true,"declare":true,"mermaid":true,"date":"2022-05-02T17:21:04.000Z","index_img":"/index/paper-reading-contrastive-learning-review.png","_content":"\n{% note primary %}\n\nAs a form of unsupervised learning, contrastive learning plays an ever more important role in deep learning. Here's a review of contrastive learning in CV since 2018, including 4 stages and 14 papers. This blog is written following the lead of this [review video](https://www.bilibili.com/video/BV19S4y1M7hm/).\n\n{% endnote%}\n\n<!-- more -->\n\n{% note secondary %}\nThis is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n{% endnote %}\n\nSince, 2018, the development of contrastive learning can be concluded in 4 stages, and an overview is shown below:\n\n{% markmap 300px %}\n\n- Wild growth\n  - InstDisc[^1]\n  - InvaSpread[^2]\n  - CPC[^3]\n  - CMC[^4]\n- Two heroes\n  - MoCo v1[^5]\n  - SimCLR v1[^6]\n  - MoCo v2[^7]\n  - SimCLR v2[^8]\n  - SwAV[^9]\n- No negative samples\n  - BYOL[^10]\n    - Explanation\n      - BYOL v2[^11]\n    \n  - SimSiam[^12]\n  \n- Transformer based\n  - MoCo v3[^13]\n  - DINO[^14]\n\n\n{% endmarkmap %}\n\n## Brief introduction\n\n> **Contrastive learning** is a machine learning technique used to learn *the general features* of a dataset **without labels** by teaching the model which data points are similar or different.\n\n<img src=\"contrastive learning illustration.png\" alt=\"contrastive learning illustration.png\" style=\"zoom:25%;\" />\n\nThe idea is intuitive, given 3 pictures above; 2 cats and 1 dog. The goal of contrastive learning is to discriminate the cats from the dog by comparing the pixel similarity of them. Dive into the model, inputing $X_{cat1}, X_{cat2}, X_{dog}$ to a neural network. The distance between the resulting latent features of the 2 cats $L(f_{cat1}, f_{cat2})$ should approach 0 while those between the cats and the dog $L(f_{cat}, f_{dog})$ should approach infinity.\n\nContrastive learning is a very portable and flexible technique. It can be used anywhere as long as you can design a rule (**preset task**) to define which data are similar (**positive sample**) and which are different (**negative sample**). In the above example, one defines the pictures of the same species as positive, and those of different species as negative.\n\nActually, although it is usually seen as an unsupervised technique, contrastive learning is not meant to be unsupervised. As we can see above, under that context (**preset task**), it is more like a supervised constrained clustering. The model still relies on labeled datasets containing pictures of each species. But people manage to make this technique unsupervised or self-supervised in CV by designing clever **preset tasks**. For example, the **instance discrimination** we are about to see below.\n\nExcept from designing of the **preset task**, another key point is the design of **loss function**. The preset task sets the goal of training while the loss function defines how to do it. Unlike the loss functions that are often used in discrimination learning (cross entropy) or generative learning (L1-L2 loss), contrastive losses measure the similarity of each feature, which varies as the encoded features keep updating with epochs[^5] . Different kinds of loss functions are developed by follow up papers to improve the training efficiency and stability. \n\n## Stage 1: Wild growth(-2019mid)\n\nAt this stage, preset tasks, loss function, model and research area are not unified.\n\n### InstDisc[^1]\n\n#### Preset task\n\n<img src=\"Instdisc idea.png\" alt=\"Instdisc idea\" style=\"zoom:50%;\" />\n\nThe figure above perfectly explains the motive and goal of the instance discrimination. Just as the name suggests, it extends the discrimination task from the previous class level to the instance level i.e. every single instance is a class.\n\n#### Method\n\n<img src=\"Instdisc method.png\" alt=\"Instdisc method\" style=\"zoom:100%;\" />\n\nAs shown above, InstDisc[^1] proposes a CNN (ResNet50) based model that encodes a batch (batch size 256) of figures into a latent feature space(128D), where the distance between each figure are maximised. The way of training such a model is through contrastive learning. For one feature encoded from a particular image, the **positive samples** are the features encoded from the augmentations of the picture and the **negative samples** are obtained by sampling(4096) the set of features encoded from all the other images. In this way, the model becomes self-supervised. To modify the general example above, instance discrimination task can be illustrated as below.\n\n<img src=\"instance discrimination illustration.png\" alt=\"instance discrimination illustration\" style=\"zoom:27%;\" />\n\nBesides, in order to save all the negative features without blowing up the memory, a memory bank is proposed. In every epoch, 4098 negative features are sampled from the memory bank. And the memory bank is updated with features in each epoch, under a method of proximal regularisation.\n\n#### Loss function\n\n**Noise Contrastive Estimation**(NCE) loss is applied to push away the negatives while clustering the positives..\n\n#### Comment\n\nThis paper proposes the fundamental preset task instance discrimination. Together with the NCE loss, a fine result is achieved. Besides, the idea of saving a bounden of negative samples with other data structures, the proximal regularisation (momentum updated memory bank) method inspires the following queue method and the momentum updated decoder[^5] Even the super-parameter setting is also typical and a lot of work follows, including MoCo v1[^5]. \n\n### InvaSpread[^2]\n\nLess influential as it is, this paper can be seen as a preliminary work of the SimCLR v1[^6]. Unlike InstDisc[^1]with additional structure to save negative samples, the positive and negative samples in InvaSpread[^2] are from the same batch. And only one encoder is used to process the samples. \n\n#### Method\n\n<img src=\"InvaSpread illustration.png\" alt=\"InvaSpread illustration\" style=\"zoom:100%;\" />\n\nThe preset task is still instance discrimination, while the sampling is done in a different way. As shown above, assuming $x_1$ as the original, the positive sample is $[\\hat{x}_1]$, while the negative sample is $[x_2,x_3,\\hat{x}_2,\\hat{x}_3]$, which means taking batch size as 256, the resulting positive and negative sample sizes are $256$ and $(256-1)*2$ respectively. \n\nRecalling InstDisc[^1], the negative sample is from outside this batch and the size can be much larger. Yet the downside part of it is that it requires another encoder for the negatives. Whereas, with positive and negative in one batch, only one encoder is needed and the model thus becomes end-to-end.\n\nThe loss function employed is a variant of the NCL loss.\n\n#### Comment\n\nTogether with the SimCLR series, these papers stand for another route of contrastive learning, which is featured by:\n\n- End-to-end\n- Only one encoder\n- No reliance on extra data structures\n- Positive and negatives are in the same batch\n\nThis paper is very similar to SimCLR but has rather mediocre performance. There are several reasons:\n\n- The batch size is too small - only 256, not enough negative samples (no TPU, no money)\n- No powerful augmentations or the MLP projector that are proposed by SimCLR v1[^6]\n\n### CPC[^3]\n\nApart from instance discrimination, this paper proposes another **pretext task** - contrastive predictive coding, a reminiscence of the difference between discriminative and generative models. And this approach is generalisable enough to copes with audio, images, text, and even reinforcement learning.\n\n#### pretext task \n\n<img src=\"CPC illustration.png\" alt=\"CPC illustration\" style=\"zoom:100%;\" />\n\nGiven a temporal sequence, the encoded features of the sequence before time t are fed into an auto-regressive network (RNN or LSTM). The \"origin\" is defined as the RNN predicted features after time t $\\hat{z}_{t+1} - \\hat{z}_{t+4}$, the positive sample $z_{t+1} - z_{t+4}$, is defined as the features encoded from feature data $x_{t+1} - x_{t+4}$. The negative samples can be flexible, a typical way is the features encoded from data other than $x_{t+1} - x_{t+4}$.\n\nIn this way, the input $X$ can vary from picture patches, audio, video etc.\n\n### CMC[^4]\n\nCMC propose a more general way of defining positive sample, basically the different view of one instance can be defined as positive. \n\n#### Motivation\n\nIt is perfectly presented in the abstract, here is just a paraphrase. In the real world, information from different angle of view such as smell, sight and touch describe one thing together. Though these *sensory channels* might be different, the high level features such as physics, geometry and semantics tend to be same. And this preset task aims to train a view-invariant model.\n\n#### Pre-text task\n\n<img src=\"CMC illustration.png\" alt=\"CMC illustration\" style=\"zoom:30%;\" />\n\nAs the figure above illustrates, the representations of the same scene, no matter which view, are set as positive while representations from different scene as negative.\n\n#### Loss function\n\nThe contrastive Learning loss is designed to maximise the mutual information between features of different views.\n\n#### Comment\n\nCMC is one of the first works to apply contrastive learning to multi-view problems. It demonstrates the flexibility of contrastive learning, and the portability of applying it to multi-view problems. As a result, OpenAI developed the famous Clip[^16] model, where the image and its language description are seen as a positive pair. \n\nOne slight drawback of multi-view might be the need for different encoders to handle different views. For example, in Clip[^16], ViT and a large scale language model are applied to process different modes. Yet, given the various applications of transformer, this drawback may be addressed by processing multi-model problems via one single transformer model. Here is a example of doing it - MA-CLIP[^18].\n\n## Stage 2: Two heroes(2019mid-2020mid)\n\nTheir are MoCo and SimCLR. In this stage, the development is very fast. The time intervals between each works introduced below are typically 1-2 months, even less than 1 month. And the SOTA on imageNet were refreshed every month. And the model architecture (encoder then projection), loss function(infoNCE), momentum encoder setting, more powerful method augmentation and more epochs tend to come together. And the result trend to the supervised learning accuracy.\n\n### MoCo v1[^5]\n\nIt is the milestone of CV contrastive learning, and it is the first model that outperform supervised learning. It is a breakthrough that rise the confidence of unsupervised learning.\n\n#### Method\n\n<img src=\"Moco v1 illustration.png\" alt=\"Moco v1 illustration\" style=\"zoom:40%;\" />\n\nAs highlighted above, MoCo has two contributions: (1) momentum encoder (2) queue\n\nMoCo stands for momentum contrast. Compared with InstDisc[^1], MoCo updates the encoder with momentum to prevent the encoder changing too rapidly between two batches. Besides, the application of queue instead of memory bank makes sure to update the negative dictionary efficiently.\n\nFurther more, MoCo introduces another loss function called infoNCE, very similar to softmax.\n\n#### Comment\n\nActually, the details of MoCo almost follows exactly the InstDisc[^1], including backbone of ResNet 50, 128D of output size, L2-norm of outputs, 0.07 of loss temperature, the data augmentation setting, 0.03 learning rate and 200 epochs of training. It seems like MoCo is just make some improvements to InstDisc[^1].\n\nNevertheless, MoCo is classic. The reason may be the effectiveness and the influential of  the improvements. For example, the momentum encoder setting is inherited by following SimCLR [^6], BYOL[^10], even the latest work.\n\nFurthermore, the way of writing is just beautiful and the scope is much higher than an ordinary work. Instead of presenting those improvements that they made. The authors conclude the preliminary works as a task of dictionary look-up. Personally, I feel like I understand the contrastive learning only until I read through the introduction part of MoCO.\n\n### SimCLR v1[^6]\n\nSimCLR stands for Simple Contrastive learning,  it is easy to understand and often used as example in many introduction blogs. The only drawback is the requirement of large batch size.\n\n#### Method\n\n<img src=\"SimCLR v1 illustration.png\" alt=\"SimCLR v1 illustration\" style=\"zoom:40%;\" />\n\nIt is very similar to InvaSpread[^2], the positive size is $N$ While the negative size is $2(N-1)$ . The key contribution is a \"projection head(mlp with linear then RELU)\" after the shared encoder, only applied during the training process. The improvement results in a gain of the accuracy up to 10%.\n\nA loss function similar to infoNCE is used to maximise the agreement between positive and negative samples.\n\n#### Data augmentation ablation\n\n<img src=\"SimCLR aug.png\" alt=\"SimCLR aug\" style=\"zoom:100%;\" />\n\nSimCLR does a detailed ablation test searching the most effective augmentation method, as it is crucial for the contrastive learning. As shown above all kinds of augs are listed and studied. And the result, as concluded in the heat-map below, shows the best 2 augmentation methods are crop and colour.\n\n<img src=\"SimCLR aug result.png\" alt=\"SimCLR aug result\" style=\"zoom:30%;\" />\n\n#### Projection ablation\n\n<img src=\"SimCLR projection head.png\" alt=\"SimCLR projection head ablation\" style=\"zoom:30%;\" />\n\nTwo piece of information in this result:\n\n- The non-linear(linear with RELU) rise accuracy up by 10%\n- The output size makes less difference to the accuracy, so afterwards works tend to choose small size as well. 128 is enough.\n\n#### Comments\n\nThe full contributions compared with  InvaSpread[^2] are: \n\n- More data augmentatinon\n- Learnable projection head layer\n- Bigger batch size\n- More epoch\n\nThe authors are as humble as admitting most of these contributions are not novel in the later part of the article. \n\n> We note that almost all individual components of our framework have appeared in previous work, although the specific instantiations may be different. The superiority of our framework relative to previous work is not explained by any single design choice, but by their composition.\n\nHowever, similar to MoCo[^5], the contributions of this paper are also very influential. For example, the projection head after the encoder is adopted in following MoCo v2[^7] , SwAV[^9]and BYOL[^10]. And the data augmentation scheme is also widely applied. The the LARS optimiser for large batch size appears in BYOL[^10] as well.\n\nAnd because of the good results of MoCo[^5], and SimCLR, contrastive learning lead a dominant trend in deep learning from 2020. And ended until the proposing of Vision Transformer.\n\n### MoCo v2[^7]\n\nIt is technically a technical report. They note the effectiveness of the projection head and data augmentation method that SimCRL presented. After just less than 1 month, they merge these techniques into MoCo resulting in new SOTA on ImageNet.\n\n#### Results\n\n<img src=\"MoCo v2 ablation.png\" alt=\"MoCo v2 ablation\" style=\"zoom:40%;\" />\n\nFrom the ablation result above, it is notable that the acc gains 6% with only projection head. And a large number of epochs are useful. As a matter of fact, the trend of increasing epochs still keeps. Recall the new MAE, 1600 epochs are adopted and the accuracy keeps rising.\n\n<img src=\"MoCo v2 result.png\" alt=\"MoCo v2 result\" style=\"zoom:40%;\" />\n\nBesides, they present MoCo v2 outperforms SimCLAR from two angle of views\n\n- MoCo v2 is able to reach higher accuracy with less epochs\n- The memory and time cost of MoCo is much lower to get a good result\n\n#### Comment\n\nMoCo v2 may be the most memory friendly method to get a good result with contrastive learning. And it still very useful.\n\n### SimCLR v2[^8]\n\nActually most part of this paper focus on semi-supervised leaning. The SimCLR v2 part presented 3 points:\n\n- Bigger backbone model size, 153-layer SKnet\n- Deeper projection head, 2 layers MLP after a search of layer number\n- Momentum encoder inspired by MoCo[^6][^7], but less effective. And they claim the reason is that the batch size of SimCLR is already big.\n\n### SwAV[^9]\n\nSwAV abbreviates for Swapped Assignment Views. This another multi-view work, aiming at predicting one view's feature from another view. And it combines contrastive leaning with clustering. \n\n#### Method\n\n<img src=\"SwAV illustration.png\" alt=\"SwAV illustration\" style=\"zoom:100%;\" />\n\nUnlike the former contrastive task, instead of enacting contrastive loss between positive and sampled negative features, SwAV compares positive with all negative features via clustering and swap prediction. \n\n#### Multi-crop augmentation\n\nIn additional to the great clustering setting, SwAV proposes another type of augmentation, multi-crop. With multi-crop, the model manages to learn information not only from large scale but small scale of an image, with similar computation cost.\n\n<img src=\"SwAV multi crop.png\" alt=\"SwAV multi crop\" style=\"zoom:100%;\" />\n\nIt can be seen that the multi crop improve the accuracy on all the approaches, especially on the clustering related ones. And this technique can be seen as a critical contribution to reach SOTA. And it is adopted by a lot following models.\n\n#### Result\n\n<img src=\"SwAV result.png\" alt=\"SwAV result\" style=\"zoom:100%;\" />\n\nThe result of SwAV not only surpasses the preliminaries, but afters. It keeps SOTA that a convolutional backbone achieves until ViT models appear.\n\nAs shown above, with only linear probe (froze all but the last layer) the SwAV result is very near to the supervised baseline. And the result converges to the supervised result with the model size. \n\n##  Stage 3: No negative samples\n\nBasically around BYOL and at last SimSiam integrates all the contributions before and makes a closure for the CNN based contrastive learning era. \n\n### BYOL[^10]\n\nBootstrap Your Own Latent is the longer version. Negative samples are critical for preventing model collapsing (same output regardless the input, loss always 0, learn nothing). In this new approach, no negative is required.\n\n#### Model\n\n<img src=\"BYOL model.png\" alt=\"BYOL model\" style=\"zoom:100%;\" />\n\nThe approach is simple, after classical momentum encoder, and momentum projector, another layer (same architecture with projection) is added to the positive line. Then the model is trained to predict the negative output with the output of the positive line.\n\n#### Analysis\n\nThe result is truly surprising and it resulted in quite a topic. One of the most influencial analytical works is this blog: [Understanding Self-Supervised and Contrastive Learning with \"Bootstrap Your Own Latent\" (BYOL)](https://generallyintelligent.ai/blog/2020-08-24-understanding-self-supervised-contrastive-learning/).\n\n| Name               | Projection MLP Norm | Prediction MLP Norm | Loss Function | Contrastive | Performance [5](https://generallyintelligent.ai/blog/2020-08-24-understanding-self-supervised-contrastive-learning/#fn-5) |\n| ------------------ | ------------------- | ------------------- | ------------- | ----------- | ------------------------------------------------------------ |\n| Contrastive Loss   | None                | None                | Cross Entropy | Explicit    | 44.1                                                         |\n| BYOL               | Batch Norm          | Batch Norm          | L2            | Implicit    | 57.7                                                         |\n| Projection BN Only | Batch Norm          | None                | L2            | Implicit    | 55.3                                                         |\n| Prediction BN Only | None                | Batch Norm          | L2            | Implicit    | 48                                                           |\n| No Normalization   | None                | None                | L2            | None        | 28.3                                                         |\n| Layer Norm         | Layer Norm          | Layer Norm          | L2            | None        | 29.4                                                         |\n| Random             |                    |                    |              | None        | 28.8                                                         |\n\nThe blog author tried to reproduce the BYOL but got model collapsing all the time. So he checked the model and found the reason is one batch norm layer missing in his projection heads. And he did a series of ablation tests on batch normalisation and raise a hypnosis that BYOL leverage batch normal layers as a source of implicit \"negative\" samples. i.e. positive samples are not the only sample needed.\n\n> **the presence of batch normalisation implicitly causes a form of contrastive learning**.\n\n### BYOL v2[^11]\n\nThe previous blog made a huge influence and the conclusion was widely accepted, exceot the authors. As a result, another article was published entitled \"BYOL works *even* without batch statistics\"\n\n<img src=\"BYOL batch norm ablation.png\" alt=\"BYOL batch norm ablation\" style=\"zoom:100%;\" />\n\nIn this paper, a more detailed ablation experiment was applied. And it shows the batch norm works as it designed, just a method to improve the stability of training.\n\nBesides, the authors use a better initialisation (group normalisation) , and the model maintains a similar accuracy without any batch norm layer.\n\n### SimSiam[^12]\n\nAfter all these works, people found the contrastive learning's performance is accumulated by many techniques and tricks, a little too messy. In this context, He et al proposed a simple SimSiam network.\n\n<img src=\"SimSiam illustration.png\" alt=\"SimSiam illustration\" style=\"zoom:40%;\" />\n\nAs shown above, SimSiam is basically a BYOL excluding the momentum encoder.\n\n<img src=\"SimSiam result.png\" alt=\"SimSiam results\" style=\"zoom:100%;\" />\n\nAnd a detailed comparison of results are provided, including classification and downstream tasks. Note that SimCLR and MoCo v2 performs the best on downstream tasks.\n\n## Stage 4: Transformer based\n\nBecause of the popularity of vision transformer[^15], the backbones of the contrastive learning methods are substituted into transformer. And the works aim at analysing and solving the resulting unstable problem.\n\n### MoCo v3[^13]\n\nAlthough the title of MoCo v3 includes ViT, it is mostly a architecture that coping with all backbones. \n\n#### Method\n\nFrom the algorithm, the MoCo v3 is a combination of MoCo v2 and SimSam. From the big picture, a query encoder and momentum key encoder with the contrastive loss are inherited from MoCo v2, while in the detail, a prediction mlp layer after the projection layer, a symmetric loss function recall the SimSiam.\n\n#### Transformer based model instability\n\n<img src=\"MoCo v3 result.png\" alt=\"MoCo v3 result\" style=\"zoom:40%;\" />\n\nBecause of the popularity of ViT, they substitute the backbone as ViT and find instability in training process. As shown above, the training accuracy tend to drop severely then increase gradually especially with large batch size. In this condition, large batch size has a negative impact on accuracy.\n\n#### Trick\n\nTo alleviate the fluctuation, they retrieves the gradients of each layer and find the huge gradient change always occur on first layer (tokenisation patching layer). As a result, they try froze the first layer after random initialisation, and the problem solved. Note that this trick is useful for both MoCo v3 and BYOL with ViT.\n\n### DINO[^14]\n\nShort for self-**di**stillation with **no** labels, DINO is actually a follow-up work of BYOL. The student and teacher networks are same as the query and key network respectively. One contribution is the centring layer in the teacher network. And the algorithm is very similar to MoCo v3, same forward process with slightly different loss function.\n\n<img src=\"DINO illustration.png\" alt=\"DINO illustration\" style=\"zoom:100%;\" />\n\n## Conclusion\n\nThe relationships can be included in this diagram below:\n\n```mermaid\n\nclassDiagram\n\nInstDisc --|> MoCo v1\n\nInvaSpread --|> SimCLR v1\n\nCPC v1 --|> CPC v2\n\nCMC  --|> Info min\n\nMoCo v1 --|> MoCo v2\n\nSimCLR v1 --|> CPC v2\n\nSimCLR v1 --|> MoCo v2\n\nSimCLR v1 --|> SimCLR v2\n\nCPC v2 --|> Info min\n\nSimCLR v1 --|> Info min\n\nSimCLR v1 --|> BYOL\n\nBYOL --|> SimSiam\n\nBYOL  --|>  explanation\n\nexplanation  --|>  BYOL v2\n\nSimSiam --|> MoCo v3\n\ndeep cluster --|> SwAV\n\nMoCo v2 --|> MoCo v3\n\nSimSiam --|> DINO\n\nclass InstDisc{\n\n+ Instance discrimination\n\n+ Memory bank\n\n}\n\nclass InvaSpread{\n\n+ End to end\n\n- Limited by batch size\n\n}\n\nclass CPC v1{\n\n+ infoNCE loss\n+ Predictive preset, RNN based model\n+ CV, NLP, audio, RL\n\n}\n\nclass CMC{\n\n+ Muti view\n\n}\n\nclass deep cluster{\n\n+ Based on cluster\n\n- No contrastive\n\n}\n\nclass MoCo v1{\n\n+ memory bank -> queue\n+ Momentom encoder\n+ Outperform supervised\n\n}\n\nclass SimCLR v1{\n\n+ Bigger batch size\n+ More augmentations\n+ Projection head\n+ More epoch\n\n}\n\nclass CPC v2{\n\n+ Add the SimCLR tricks\n+ Gain by **30** \n\n}\n\nclass Info min{\n\n+ Conclude a rule\n- maximise mutual info\n+ minimise mutual info\n+ analytical work\n\n}\n\nclass MoCo v2{\n\n+ Add the SimCLR tricks\n\n}\n\nclass SimCLR v2{\n\nMainly half-supervised\n\n+ Bigger backbone\n+ 2-layer  projection head\n+ Momentom encoder\n\n}\n\nclass SwAV{\n\n+ Combine with contrastive\n+ Multi-crop trick\n\n}\n\nclass BYOL{\n\n+ No negative samples\n+ mse loss\n\n}\n\nclass explanation{\n\n+ BN is the key\n+ Implicit negative sample\n\n}\n\nclass BYOL v2{\n\n- BN is NOT the key\n+ Better initialisation\n\n}\n\nclass SimSiam{\n\n- Conclude and simplified\n- Smaller batch size\n- No momentom encoder\n- No negative sample\n\n+ Stop gradient -> EM\n\n}\n\nclass Barlos Twins{\n\n+ Diff target\n+ Not popular\n\n}\n\nclass MoCo v3{\n\n+ Transformer \n\n+ Freeze patch projection layer\n\n}\n\nclass DINO {\n\n+ Transformer \n\n+ Centring teacher network\n\n}\n\n```\n\n\n\n## Reference\n\n[^1]: [Wu, Z., Xiong, Y., Yu, S. X., & Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).](http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html)\n[^2]: [Ye, M., Zhang, X., Yuen, P. C., & Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition* (pp. 6210-6219).](http://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Unsupervised_Embedding_Learning_via_Invariant_and_Spreading_Instance_Feature_CVPR_2019_paper.html)\n[^3]: [Van den Oord, A., Li, Y., & Vinyals, O. (2018). Representation learning with contrastive predictive coding. *arXiv e-prints*, arXiv-1807.](https://ui.adsabs.harvard.edu/abs/2018arXiv180703748V/abstract)\n[^4]: [Tian, Y., Krishnan, D., & Isola, P. (2020, August). Contrastive multiview coding. In *European conference on computer vision* (pp. 776-794). Springer, Cham.](https://link.springer.com/chapter/10.1007/978-3-030-58621-8_45)\n[^5]: [He, K., Fan, H., Wu, Y., Xie, S., & Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition* (pp. 9729-9738).](http://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html)\n[^6]: [Chen, T., Kornblith, S., Norouzi, M., & Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In *International conference on machine learning* (pp. 1597-1607). PMLR.](http://proceedings.mlr.press/v119/chen20j.html)\n[^7]:[Chen, X., Fan, H., Girshick, R., & He, K. (2020). Improved baselines with momentum contrastive learning. *arXiv preprint arXiv:2003.04297*.](https://arxiv.org/abs/2003.04297)\n[^8]: [Chen, T., Kornblith, S., Swersky, K., Norouzi, M., & Hinton, G. E. (2020). Big self-supervised models are strong semi-supervised learners. *Advances in neural information processing systems*, *33*, 22243-22255.](https://proceedings.neurips.cc/paper/2020/hash/fcbc95ccdd551da181207c0c1400c655-Abstract.html)\n[^9]: [Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., & Joulin, A. (2020). Unsupervised learning of visual features by contrasting cluster assignments. *Advances in Neural Information Processing Systems*, *33*, 9912-9924.](https://proceedings.neurips.cc/paper/2020/hash/70feb62b69f16e0238f741fab228fec2-Abstract.html)\n[^10]: [Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... & Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. *Advances in Neural Information Processing Systems*, *33*, 21271-21284.](https://proceedings.neurips.cc/paper/2020/hash/f3ada80d5c4ee70142b17b8192b2958e-Abstract.html)\n[^11]: [Richemond, P. H., Grill, J. B., Altch, F., Tallec, C., Strub, F., Brock, A., ... & Valko, M. (2020). BYOL works even without batch statistics. *arXiv preprint arXiv:2010.10241*.](https://arxiv.org/abs/2010.10241)\n[^12]: [Chen, X., & He, K. (2021). Exploring simple siamese representation learning. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition* (pp. 15750-15758).](http://openaccess.thecvf.com/content/CVPR2021/html/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.html)\n[^13]: [Chen, X., Xie, S., & He, K. (2021). An empirical study of training self-supervised vision transformers. In *Proceedings of the IEEE/CVF International Conference on Computer Vision* (pp. 9640-9649).](http://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html)\n[^14]: [Caron, M., Touvron, H., Misra, I., Jgou, H., Mairal, J., Bojanowski, P., & Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In *Proceedings of the IEEE/CVF International Conference on Computer Vision* (pp. 9650-9660).](http://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html)\n[^15]:[Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. *arXiv preprint arXiv:2010.11929*.](https://arxiv.org/abs/2010.11929)\n[^16]:[Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... & Sutskever, I. (2021, July). Learning transferable visual models from natural language supervision. In *International Conference on Machine Learning* (pp. 8748-8763). PMLR](http://proceedings.mlr.press/v139/radford21a)\n[^17]:[Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. *arXiv preprint arXiv:2010.11929*.](https://arxiv.org/abs/2010.11929)\n[^18]: [You, H., Zhou, L., Xiao, B., Codella, N. C., Cheng, Y., Xu, R., ... & Yuan, L. (2021). MA-CLIP: Towards Modality-Agnostic Contrastive Language-Image Pre-training.](https://openreview.net/forum?id=ROteIE-4A6W)\n","source":"_posts/paper-reading-contrastive-learning-review.md","raw":"---\ntitle: 'Contrastive learning review'\nauthor: Ryan LI\ntoc: true\ndeclare: true\nmermaid: true\ndate: 2022-05-03 01:21:04\nindex_img: /index/paper-reading-contrastive-learning-review.png\ntags:\n  - paper reading\n  - deep learning\n---\n\n{% note primary %}\n\nAs a form of unsupervised learning, contrastive learning plays an ever more important role in deep learning. Here's a review of contrastive learning in CV since 2018, including 4 stages and 14 papers. This blog is written following the lead of this [review video](https://www.bilibili.com/video/BV19S4y1M7hm/).\n\n{% endnote%}\n\n<!-- more -->\n\n{% note secondary %}\nThis is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n{% endnote %}\n\nSince, 2018, the development of contrastive learning can be concluded in 4 stages, and an overview is shown below:\n\n{% markmap 300px %}\n\n- Wild growth\n  - InstDisc[^1]\n  - InvaSpread[^2]\n  - CPC[^3]\n  - CMC[^4]\n- Two heroes\n  - MoCo v1[^5]\n  - SimCLR v1[^6]\n  - MoCo v2[^7]\n  - SimCLR v2[^8]\n  - SwAV[^9]\n- No negative samples\n  - BYOL[^10]\n    - Explanation\n      - BYOL v2[^11]\n    \n  - SimSiam[^12]\n  \n- Transformer based\n  - MoCo v3[^13]\n  - DINO[^14]\n\n\n{% endmarkmap %}\n\n## Brief introduction\n\n> **Contrastive learning** is a machine learning technique used to learn *the general features* of a dataset **without labels** by teaching the model which data points are similar or different.\n\n<img src=\"contrastive learning illustration.png\" alt=\"contrastive learning illustration.png\" style=\"zoom:25%;\" />\n\nThe idea is intuitive, given 3 pictures above; 2 cats and 1 dog. The goal of contrastive learning is to discriminate the cats from the dog by comparing the pixel similarity of them. Dive into the model, inputing $X_{cat1}, X_{cat2}, X_{dog}$ to a neural network. The distance between the resulting latent features of the 2 cats $L(f_{cat1}, f_{cat2})$ should approach 0 while those between the cats and the dog $L(f_{cat}, f_{dog})$ should approach infinity.\n\nContrastive learning is a very portable and flexible technique. It can be used anywhere as long as you can design a rule (**preset task**) to define which data are similar (**positive sample**) and which are different (**negative sample**). In the above example, one defines the pictures of the same species as positive, and those of different species as negative.\n\nActually, although it is usually seen as an unsupervised technique, contrastive learning is not meant to be unsupervised. As we can see above, under that context (**preset task**), it is more like a supervised constrained clustering. The model still relies on labeled datasets containing pictures of each species. But people manage to make this technique unsupervised or self-supervised in CV by designing clever **preset tasks**. For example, the **instance discrimination** we are about to see below.\n\nExcept from designing of the **preset task**, another key point is the design of **loss function**. The preset task sets the goal of training while the loss function defines how to do it. Unlike the loss functions that are often used in discrimination learning (cross entropy) or generative learning (L1-L2 loss), contrastive losses measure the similarity of each feature, which varies as the encoded features keep updating with epochs[^5] . Different kinds of loss functions are developed by follow up papers to improve the training efficiency and stability. \n\n## Stage 1: Wild growth(-2019mid)\n\nAt this stage, preset tasks, loss function, model and research area are not unified.\n\n### InstDisc[^1]\n\n#### Preset task\n\n<img src=\"Instdisc idea.png\" alt=\"Instdisc idea\" style=\"zoom:50%;\" />\n\nThe figure above perfectly explains the motive and goal of the instance discrimination. Just as the name suggests, it extends the discrimination task from the previous class level to the instance level i.e. every single instance is a class.\n\n#### Method\n\n<img src=\"Instdisc method.png\" alt=\"Instdisc method\" style=\"zoom:100%;\" />\n\nAs shown above, InstDisc[^1] proposes a CNN (ResNet50) based model that encodes a batch (batch size 256) of figures into a latent feature space(128D), where the distance between each figure are maximised. The way of training such a model is through contrastive learning. For one feature encoded from a particular image, the **positive samples** are the features encoded from the augmentations of the picture and the **negative samples** are obtained by sampling(4096) the set of features encoded from all the other images. In this way, the model becomes self-supervised. To modify the general example above, instance discrimination task can be illustrated as below.\n\n<img src=\"instance discrimination illustration.png\" alt=\"instance discrimination illustration\" style=\"zoom:27%;\" />\n\nBesides, in order to save all the negative features without blowing up the memory, a memory bank is proposed. In every epoch, 4098 negative features are sampled from the memory bank. And the memory bank is updated with features in each epoch, under a method of proximal regularisation.\n\n#### Loss function\n\n**Noise Contrastive Estimation**(NCE) loss is applied to push away the negatives while clustering the positives..\n\n#### Comment\n\nThis paper proposes the fundamental preset task instance discrimination. Together with the NCE loss, a fine result is achieved. Besides, the idea of saving a bounden of negative samples with other data structures, the proximal regularisation (momentum updated memory bank) method inspires the following queue method and the momentum updated decoder[^5] Even the super-parameter setting is also typical and a lot of work follows, including MoCo v1[^5]. \n\n### InvaSpread[^2]\n\nLess influential as it is, this paper can be seen as a preliminary work of the SimCLR v1[^6]. Unlike InstDisc[^1]with additional structure to save negative samples, the positive and negative samples in InvaSpread[^2] are from the same batch. And only one encoder is used to process the samples. \n\n#### Method\n\n<img src=\"InvaSpread illustration.png\" alt=\"InvaSpread illustration\" style=\"zoom:100%;\" />\n\nThe preset task is still instance discrimination, while the sampling is done in a different way. As shown above, assuming $x_1$ as the original, the positive sample is $[\\hat{x}_1]$, while the negative sample is $[x_2,x_3,\\hat{x}_2,\\hat{x}_3]$, which means taking batch size as 256, the resulting positive and negative sample sizes are $256$ and $(256-1)*2$ respectively. \n\nRecalling InstDisc[^1], the negative sample is from outside this batch and the size can be much larger. Yet the downside part of it is that it requires another encoder for the negatives. Whereas, with positive and negative in one batch, only one encoder is needed and the model thus becomes end-to-end.\n\nThe loss function employed is a variant of the NCL loss.\n\n#### Comment\n\nTogether with the SimCLR series, these papers stand for another route of contrastive learning, which is featured by:\n\n- End-to-end\n- Only one encoder\n- No reliance on extra data structures\n- Positive and negatives are in the same batch\n\nThis paper is very similar to SimCLR but has rather mediocre performance. There are several reasons:\n\n- The batch size is too small - only 256, not enough negative samples (no TPU, no money)\n- No powerful augmentations or the MLP projector that are proposed by SimCLR v1[^6]\n\n### CPC[^3]\n\nApart from instance discrimination, this paper proposes another **pretext task** - contrastive predictive coding, a reminiscence of the difference between discriminative and generative models. And this approach is generalisable enough to copes with audio, images, text, and even reinforcement learning.\n\n#### pretext task \n\n<img src=\"CPC illustration.png\" alt=\"CPC illustration\" style=\"zoom:100%;\" />\n\nGiven a temporal sequence, the encoded features of the sequence before time t are fed into an auto-regressive network (RNN or LSTM). The \"origin\" is defined as the RNN predicted features after time t $\\hat{z}_{t+1} - \\hat{z}_{t+4}$, the positive sample $z_{t+1} - z_{t+4}$, is defined as the features encoded from feature data $x_{t+1} - x_{t+4}$. The negative samples can be flexible, a typical way is the features encoded from data other than $x_{t+1} - x_{t+4}$.\n\nIn this way, the input $X$ can vary from picture patches, audio, video etc.\n\n### CMC[^4]\n\nCMC propose a more general way of defining positive sample, basically the different view of one instance can be defined as positive. \n\n#### Motivation\n\nIt is perfectly presented in the abstract, here is just a paraphrase. In the real world, information from different angle of view such as smell, sight and touch describe one thing together. Though these *sensory channels* might be different, the high level features such as physics, geometry and semantics tend to be same. And this preset task aims to train a view-invariant model.\n\n#### Pre-text task\n\n<img src=\"CMC illustration.png\" alt=\"CMC illustration\" style=\"zoom:30%;\" />\n\nAs the figure above illustrates, the representations of the same scene, no matter which view, are set as positive while representations from different scene as negative.\n\n#### Loss function\n\nThe contrastive Learning loss is designed to maximise the mutual information between features of different views.\n\n#### Comment\n\nCMC is one of the first works to apply contrastive learning to multi-view problems. It demonstrates the flexibility of contrastive learning, and the portability of applying it to multi-view problems. As a result, OpenAI developed the famous Clip[^16] model, where the image and its language description are seen as a positive pair. \n\nOne slight drawback of multi-view might be the need for different encoders to handle different views. For example, in Clip[^16], ViT and a large scale language model are applied to process different modes. Yet, given the various applications of transformer, this drawback may be addressed by processing multi-model problems via one single transformer model. Here is a example of doing it - MA-CLIP[^18].\n\n## Stage 2: Two heroes(2019mid-2020mid)\n\nTheir are MoCo and SimCLR. In this stage, the development is very fast. The time intervals between each works introduced below are typically 1-2 months, even less than 1 month. And the SOTA on imageNet were refreshed every month. And the model architecture (encoder then projection), loss function(infoNCE), momentum encoder setting, more powerful method augmentation and more epochs tend to come together. And the result trend to the supervised learning accuracy.\n\n### MoCo v1[^5]\n\nIt is the milestone of CV contrastive learning, and it is the first model that outperform supervised learning. It is a breakthrough that rise the confidence of unsupervised learning.\n\n#### Method\n\n<img src=\"Moco v1 illustration.png\" alt=\"Moco v1 illustration\" style=\"zoom:40%;\" />\n\nAs highlighted above, MoCo has two contributions: (1) momentum encoder (2) queue\n\nMoCo stands for momentum contrast. Compared with InstDisc[^1], MoCo updates the encoder with momentum to prevent the encoder changing too rapidly between two batches. Besides, the application of queue instead of memory bank makes sure to update the negative dictionary efficiently.\n\nFurther more, MoCo introduces another loss function called infoNCE, very similar to softmax.\n\n#### Comment\n\nActually, the details of MoCo almost follows exactly the InstDisc[^1], including backbone of ResNet 50, 128D of output size, L2-norm of outputs, 0.07 of loss temperature, the data augmentation setting, 0.03 learning rate and 200 epochs of training. It seems like MoCo is just make some improvements to InstDisc[^1].\n\nNevertheless, MoCo is classic. The reason may be the effectiveness and the influential of  the improvements. For example, the momentum encoder setting is inherited by following SimCLR [^6], BYOL[^10], even the latest work.\n\nFurthermore, the way of writing is just beautiful and the scope is much higher than an ordinary work. Instead of presenting those improvements that they made. The authors conclude the preliminary works as a task of dictionary look-up. Personally, I feel like I understand the contrastive learning only until I read through the introduction part of MoCO.\n\n### SimCLR v1[^6]\n\nSimCLR stands for Simple Contrastive learning,  it is easy to understand and often used as example in many introduction blogs. The only drawback is the requirement of large batch size.\n\n#### Method\n\n<img src=\"SimCLR v1 illustration.png\" alt=\"SimCLR v1 illustration\" style=\"zoom:40%;\" />\n\nIt is very similar to InvaSpread[^2], the positive size is $N$ While the negative size is $2(N-1)$ . The key contribution is a \"projection head(mlp with linear then RELU)\" after the shared encoder, only applied during the training process. The improvement results in a gain of the accuracy up to 10%.\n\nA loss function similar to infoNCE is used to maximise the agreement between positive and negative samples.\n\n#### Data augmentation ablation\n\n<img src=\"SimCLR aug.png\" alt=\"SimCLR aug\" style=\"zoom:100%;\" />\n\nSimCLR does a detailed ablation test searching the most effective augmentation method, as it is crucial for the contrastive learning. As shown above all kinds of augs are listed and studied. And the result, as concluded in the heat-map below, shows the best 2 augmentation methods are crop and colour.\n\n<img src=\"SimCLR aug result.png\" alt=\"SimCLR aug result\" style=\"zoom:30%;\" />\n\n#### Projection ablation\n\n<img src=\"SimCLR projection head.png\" alt=\"SimCLR projection head ablation\" style=\"zoom:30%;\" />\n\nTwo piece of information in this result:\n\n- The non-linear(linear with RELU) rise accuracy up by 10%\n- The output size makes less difference to the accuracy, so afterwards works tend to choose small size as well. 128 is enough.\n\n#### Comments\n\nThe full contributions compared with  InvaSpread[^2] are: \n\n- More data augmentatinon\n- Learnable projection head layer\n- Bigger batch size\n- More epoch\n\nThe authors are as humble as admitting most of these contributions are not novel in the later part of the article. \n\n> We note that almost all individual components of our framework have appeared in previous work, although the specific instantiations may be different. The superiority of our framework relative to previous work is not explained by any single design choice, but by their composition.\n\nHowever, similar to MoCo[^5], the contributions of this paper are also very influential. For example, the projection head after the encoder is adopted in following MoCo v2[^7] , SwAV[^9]and BYOL[^10]. And the data augmentation scheme is also widely applied. The the LARS optimiser for large batch size appears in BYOL[^10] as well.\n\nAnd because of the good results of MoCo[^5], and SimCLR, contrastive learning lead a dominant trend in deep learning from 2020. And ended until the proposing of Vision Transformer.\n\n### MoCo v2[^7]\n\nIt is technically a technical report. They note the effectiveness of the projection head and data augmentation method that SimCRL presented. After just less than 1 month, they merge these techniques into MoCo resulting in new SOTA on ImageNet.\n\n#### Results\n\n<img src=\"MoCo v2 ablation.png\" alt=\"MoCo v2 ablation\" style=\"zoom:40%;\" />\n\nFrom the ablation result above, it is notable that the acc gains 6% with only projection head. And a large number of epochs are useful. As a matter of fact, the trend of increasing epochs still keeps. Recall the new MAE, 1600 epochs are adopted and the accuracy keeps rising.\n\n<img src=\"MoCo v2 result.png\" alt=\"MoCo v2 result\" style=\"zoom:40%;\" />\n\nBesides, they present MoCo v2 outperforms SimCLAR from two angle of views\n\n- MoCo v2 is able to reach higher accuracy with less epochs\n- The memory and time cost of MoCo is much lower to get a good result\n\n#### Comment\n\nMoCo v2 may be the most memory friendly method to get a good result with contrastive learning. And it still very useful.\n\n### SimCLR v2[^8]\n\nActually most part of this paper focus on semi-supervised leaning. The SimCLR v2 part presented 3 points:\n\n- Bigger backbone model size, 153-layer SKnet\n- Deeper projection head, 2 layers MLP after a search of layer number\n- Momentum encoder inspired by MoCo[^6][^7], but less effective. And they claim the reason is that the batch size of SimCLR is already big.\n\n### SwAV[^9]\n\nSwAV abbreviates for Swapped Assignment Views. This another multi-view work, aiming at predicting one view's feature from another view. And it combines contrastive leaning with clustering. \n\n#### Method\n\n<img src=\"SwAV illustration.png\" alt=\"SwAV illustration\" style=\"zoom:100%;\" />\n\nUnlike the former contrastive task, instead of enacting contrastive loss between positive and sampled negative features, SwAV compares positive with all negative features via clustering and swap prediction. \n\n#### Multi-crop augmentation\n\nIn additional to the great clustering setting, SwAV proposes another type of augmentation, multi-crop. With multi-crop, the model manages to learn information not only from large scale but small scale of an image, with similar computation cost.\n\n<img src=\"SwAV multi crop.png\" alt=\"SwAV multi crop\" style=\"zoom:100%;\" />\n\nIt can be seen that the multi crop improve the accuracy on all the approaches, especially on the clustering related ones. And this technique can be seen as a critical contribution to reach SOTA. And it is adopted by a lot following models.\n\n#### Result\n\n<img src=\"SwAV result.png\" alt=\"SwAV result\" style=\"zoom:100%;\" />\n\nThe result of SwAV not only surpasses the preliminaries, but afters. It keeps SOTA that a convolutional backbone achieves until ViT models appear.\n\nAs shown above, with only linear probe (froze all but the last layer) the SwAV result is very near to the supervised baseline. And the result converges to the supervised result with the model size. \n\n##  Stage 3: No negative samples\n\nBasically around BYOL and at last SimSiam integrates all the contributions before and makes a closure for the CNN based contrastive learning era. \n\n### BYOL[^10]\n\nBootstrap Your Own Latent is the longer version. Negative samples are critical for preventing model collapsing (same output regardless the input, loss always 0, learn nothing). In this new approach, no negative is required.\n\n#### Model\n\n<img src=\"BYOL model.png\" alt=\"BYOL model\" style=\"zoom:100%;\" />\n\nThe approach is simple, after classical momentum encoder, and momentum projector, another layer (same architecture with projection) is added to the positive line. Then the model is trained to predict the negative output with the output of the positive line.\n\n#### Analysis\n\nThe result is truly surprising and it resulted in quite a topic. One of the most influencial analytical works is this blog: [Understanding Self-Supervised and Contrastive Learning with \"Bootstrap Your Own Latent\" (BYOL)](https://generallyintelligent.ai/blog/2020-08-24-understanding-self-supervised-contrastive-learning/).\n\n| Name               | Projection MLP Norm | Prediction MLP Norm | Loss Function | Contrastive | Performance [5](https://generallyintelligent.ai/blog/2020-08-24-understanding-self-supervised-contrastive-learning/#fn-5) |\n| ------------------ | ------------------- | ------------------- | ------------- | ----------- | ------------------------------------------------------------ |\n| Contrastive Loss   | None                | None                | Cross Entropy | Explicit    | 44.1                                                         |\n| BYOL               | Batch Norm          | Batch Norm          | L2            | Implicit    | 57.7                                                         |\n| Projection BN Only | Batch Norm          | None                | L2            | Implicit    | 55.3                                                         |\n| Prediction BN Only | None                | Batch Norm          | L2            | Implicit    | 48                                                           |\n| No Normalization   | None                | None                | L2            | None        | 28.3                                                         |\n| Layer Norm         | Layer Norm          | Layer Norm          | L2            | None        | 29.4                                                         |\n| Random             |                    |                    |              | None        | 28.8                                                         |\n\nThe blog author tried to reproduce the BYOL but got model collapsing all the time. So he checked the model and found the reason is one batch norm layer missing in his projection heads. And he did a series of ablation tests on batch normalisation and raise a hypnosis that BYOL leverage batch normal layers as a source of implicit \"negative\" samples. i.e. positive samples are not the only sample needed.\n\n> **the presence of batch normalisation implicitly causes a form of contrastive learning**.\n\n### BYOL v2[^11]\n\nThe previous blog made a huge influence and the conclusion was widely accepted, exceot the authors. As a result, another article was published entitled \"BYOL works *even* without batch statistics\"\n\n<img src=\"BYOL batch norm ablation.png\" alt=\"BYOL batch norm ablation\" style=\"zoom:100%;\" />\n\nIn this paper, a more detailed ablation experiment was applied. And it shows the batch norm works as it designed, just a method to improve the stability of training.\n\nBesides, the authors use a better initialisation (group normalisation) , and the model maintains a similar accuracy without any batch norm layer.\n\n### SimSiam[^12]\n\nAfter all these works, people found the contrastive learning's performance is accumulated by many techniques and tricks, a little too messy. In this context, He et al proposed a simple SimSiam network.\n\n<img src=\"SimSiam illustration.png\" alt=\"SimSiam illustration\" style=\"zoom:40%;\" />\n\nAs shown above, SimSiam is basically a BYOL excluding the momentum encoder.\n\n<img src=\"SimSiam result.png\" alt=\"SimSiam results\" style=\"zoom:100%;\" />\n\nAnd a detailed comparison of results are provided, including classification and downstream tasks. Note that SimCLR and MoCo v2 performs the best on downstream tasks.\n\n## Stage 4: Transformer based\n\nBecause of the popularity of vision transformer[^15], the backbones of the contrastive learning methods are substituted into transformer. And the works aim at analysing and solving the resulting unstable problem.\n\n### MoCo v3[^13]\n\nAlthough the title of MoCo v3 includes ViT, it is mostly a architecture that coping with all backbones. \n\n#### Method\n\nFrom the algorithm, the MoCo v3 is a combination of MoCo v2 and SimSam. From the big picture, a query encoder and momentum key encoder with the contrastive loss are inherited from MoCo v2, while in the detail, a prediction mlp layer after the projection layer, a symmetric loss function recall the SimSiam.\n\n#### Transformer based model instability\n\n<img src=\"MoCo v3 result.png\" alt=\"MoCo v3 result\" style=\"zoom:40%;\" />\n\nBecause of the popularity of ViT, they substitute the backbone as ViT and find instability in training process. As shown above, the training accuracy tend to drop severely then increase gradually especially with large batch size. In this condition, large batch size has a negative impact on accuracy.\n\n#### Trick\n\nTo alleviate the fluctuation, they retrieves the gradients of each layer and find the huge gradient change always occur on first layer (tokenisation patching layer). As a result, they try froze the first layer after random initialisation, and the problem solved. Note that this trick is useful for both MoCo v3 and BYOL with ViT.\n\n### DINO[^14]\n\nShort for self-**di**stillation with **no** labels, DINO is actually a follow-up work of BYOL. The student and teacher networks are same as the query and key network respectively. One contribution is the centring layer in the teacher network. And the algorithm is very similar to MoCo v3, same forward process with slightly different loss function.\n\n<img src=\"DINO illustration.png\" alt=\"DINO illustration\" style=\"zoom:100%;\" />\n\n## Conclusion\n\nThe relationships can be included in this diagram below:\n\n```mermaid\n\nclassDiagram\n\nInstDisc --|> MoCo v1\n\nInvaSpread --|> SimCLR v1\n\nCPC v1 --|> CPC v2\n\nCMC  --|> Info min\n\nMoCo v1 --|> MoCo v2\n\nSimCLR v1 --|> CPC v2\n\nSimCLR v1 --|> MoCo v2\n\nSimCLR v1 --|> SimCLR v2\n\nCPC v2 --|> Info min\n\nSimCLR v1 --|> Info min\n\nSimCLR v1 --|> BYOL\n\nBYOL --|> SimSiam\n\nBYOL  --|>  explanation\n\nexplanation  --|>  BYOL v2\n\nSimSiam --|> MoCo v3\n\ndeep cluster --|> SwAV\n\nMoCo v2 --|> MoCo v3\n\nSimSiam --|> DINO\n\nclass InstDisc{\n\n+ Instance discrimination\n\n+ Memory bank\n\n}\n\nclass InvaSpread{\n\n+ End to end\n\n- Limited by batch size\n\n}\n\nclass CPC v1{\n\n+ infoNCE loss\n+ Predictive preset, RNN based model\n+ CV, NLP, audio, RL\n\n}\n\nclass CMC{\n\n+ Muti view\n\n}\n\nclass deep cluster{\n\n+ Based on cluster\n\n- No contrastive\n\n}\n\nclass MoCo v1{\n\n+ memory bank -> queue\n+ Momentom encoder\n+ Outperform supervised\n\n}\n\nclass SimCLR v1{\n\n+ Bigger batch size\n+ More augmentations\n+ Projection head\n+ More epoch\n\n}\n\nclass CPC v2{\n\n+ Add the SimCLR tricks\n+ Gain by **30** \n\n}\n\nclass Info min{\n\n+ Conclude a rule\n- maximise mutual info\n+ minimise mutual info\n+ analytical work\n\n}\n\nclass MoCo v2{\n\n+ Add the SimCLR tricks\n\n}\n\nclass SimCLR v2{\n\nMainly half-supervised\n\n+ Bigger backbone\n+ 2-layer  projection head\n+ Momentom encoder\n\n}\n\nclass SwAV{\n\n+ Combine with contrastive\n+ Multi-crop trick\n\n}\n\nclass BYOL{\n\n+ No negative samples\n+ mse loss\n\n}\n\nclass explanation{\n\n+ BN is the key\n+ Implicit negative sample\n\n}\n\nclass BYOL v2{\n\n- BN is NOT the key\n+ Better initialisation\n\n}\n\nclass SimSiam{\n\n- Conclude and simplified\n- Smaller batch size\n- No momentom encoder\n- No negative sample\n\n+ Stop gradient -> EM\n\n}\n\nclass Barlos Twins{\n\n+ Diff target\n+ Not popular\n\n}\n\nclass MoCo v3{\n\n+ Transformer \n\n+ Freeze patch projection layer\n\n}\n\nclass DINO {\n\n+ Transformer \n\n+ Centring teacher network\n\n}\n\n```\n\n\n\n## Reference\n\n[^1]: [Wu, Z., Xiong, Y., Yu, S. X., & Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).](http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html)\n[^2]: [Ye, M., Zhang, X., Yuen, P. C., & Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition* (pp. 6210-6219).](http://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Unsupervised_Embedding_Learning_via_Invariant_and_Spreading_Instance_Feature_CVPR_2019_paper.html)\n[^3]: [Van den Oord, A., Li, Y., & Vinyals, O. (2018). Representation learning with contrastive predictive coding. *arXiv e-prints*, arXiv-1807.](https://ui.adsabs.harvard.edu/abs/2018arXiv180703748V/abstract)\n[^4]: [Tian, Y., Krishnan, D., & Isola, P. (2020, August). Contrastive multiview coding. In *European conference on computer vision* (pp. 776-794). Springer, Cham.](https://link.springer.com/chapter/10.1007/978-3-030-58621-8_45)\n[^5]: [He, K., Fan, H., Wu, Y., Xie, S., & Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition* (pp. 9729-9738).](http://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html)\n[^6]: [Chen, T., Kornblith, S., Norouzi, M., & Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In *International conference on machine learning* (pp. 1597-1607). PMLR.](http://proceedings.mlr.press/v119/chen20j.html)\n[^7]:[Chen, X., Fan, H., Girshick, R., & He, K. (2020). Improved baselines with momentum contrastive learning. *arXiv preprint arXiv:2003.04297*.](https://arxiv.org/abs/2003.04297)\n[^8]: [Chen, T., Kornblith, S., Swersky, K., Norouzi, M., & Hinton, G. E. (2020). Big self-supervised models are strong semi-supervised learners. *Advances in neural information processing systems*, *33*, 22243-22255.](https://proceedings.neurips.cc/paper/2020/hash/fcbc95ccdd551da181207c0c1400c655-Abstract.html)\n[^9]: [Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., & Joulin, A. (2020). Unsupervised learning of visual features by contrasting cluster assignments. *Advances in Neural Information Processing Systems*, *33*, 9912-9924.](https://proceedings.neurips.cc/paper/2020/hash/70feb62b69f16e0238f741fab228fec2-Abstract.html)\n[^10]: [Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... & Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. *Advances in Neural Information Processing Systems*, *33*, 21271-21284.](https://proceedings.neurips.cc/paper/2020/hash/f3ada80d5c4ee70142b17b8192b2958e-Abstract.html)\n[^11]: [Richemond, P. H., Grill, J. B., Altch, F., Tallec, C., Strub, F., Brock, A., ... & Valko, M. (2020). BYOL works even without batch statistics. *arXiv preprint arXiv:2010.10241*.](https://arxiv.org/abs/2010.10241)\n[^12]: [Chen, X., & He, K. (2021). Exploring simple siamese representation learning. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition* (pp. 15750-15758).](http://openaccess.thecvf.com/content/CVPR2021/html/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.html)\n[^13]: [Chen, X., Xie, S., & He, K. (2021). An empirical study of training self-supervised vision transformers. In *Proceedings of the IEEE/CVF International Conference on Computer Vision* (pp. 9640-9649).](http://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html)\n[^14]: [Caron, M., Touvron, H., Misra, I., Jgou, H., Mairal, J., Bojanowski, P., & Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In *Proceedings of the IEEE/CVF International Conference on Computer Vision* (pp. 9650-9660).](http://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html)\n[^15]:[Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. *arXiv preprint arXiv:2010.11929*.](https://arxiv.org/abs/2010.11929)\n[^16]:[Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... & Sutskever, I. (2021, July). Learning transferable visual models from natural language supervision. In *International Conference on Machine Learning* (pp. 8748-8763). PMLR](http://proceedings.mlr.press/v139/radford21a)\n[^17]:[Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. *arXiv preprint arXiv:2010.11929*.](https://arxiv.org/abs/2010.11929)\n[^18]: [You, H., Zhou, L., Xiao, B., Codella, N. C., Cheng, Y., Xu, R., ... & Yuan, L. (2021). MA-CLIP: Towards Modality-Agnostic Contrastive Language-Image Pre-training.](https://openreview.net/forum?id=ROteIE-4A6W)\n","slug":"paper-reading-contrastive-learning-review","published":1,"updated":"2022-06-09T10:24:31.969Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz2b0023l8ybf03l6kuk","content":"<div class=\"note note-primary\">\n            <p>As a form of unsupervised learning, contrastive learning plays an ever more important role in deep learning. Here's a review of contrastive learning in CV since 2018, including 4 stages and 14 papers. This blog is written following the lead of this <a href=\"https://www.bilibili.com/video/BV19S4y1M7hm/\">review video</a>.</p>\n          </div>\n<span id=\"more\"></span>\n<div class=\"note note-secondary\">\n            <p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n          </div>\n<p>Since, 2018, the development of contrastive learning can be concluded in 4 stages, and an overview is shown below:</p>\n\n<div class=\"markmap-container\" style=\"height:300px\">\n  <svg data=\"{&quot;t&quot;:&quot;root&quot;,&quot;d&quot;:0,&quot;v&quot;:&quot;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[1,2]},&quot;v&quot;:&quot;Wild growth&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[2,4]},&quot;v&quot;:&quot;InstDisc&lt;sup id=\\&quot;fnref:1\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:1\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Wu, Z., Xiong, Y., Yu, S. X., &amp;amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\\n\\&quot;&gt;[1]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[4,6]},&quot;v&quot;:&quot;InvaSpread&lt;sup id=\\&quot;fnref:2\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:2\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Ye, M., Zhang, X., Yuen, P. C., &amp;amp; Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6210-6219).\\n\\&quot;&gt;[2]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[6,8]},&quot;v&quot;:&quot;CPC&lt;sup id=\\&quot;fnref:3\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:3\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Van den Oord, A., Li, Y., &amp;amp; Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv e-prints, arXiv-1807.\\n\\&quot;&gt;[3]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[8,10]},&quot;v&quot;:&quot;CMC&lt;sup id=\\&quot;fnref:4\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:4\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Tian, Y., Krishnan, D., &amp;amp; Isola, P. (2020, August). Contrastive multiview coding. In European conference on computer vision (pp. 776-794). Springer, Cham.\\n\\&quot;&gt;[4]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[10,11]},&quot;v&quot;:&quot;Two heroes&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[11,13]},&quot;v&quot;:&quot;MoCo v1&lt;sup id=\\&quot;fnref:5\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:5\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;He, K., Fan, H., Wu, Y., Xie, S., &amp;amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\\n\\&quot;&gt;[5]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[13,15]},&quot;v&quot;:&quot;SimCLR v1&lt;sup id=\\&quot;fnref:6\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:6\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Chen, T., Kornblith, S., Norouzi, M., &amp;amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.\\n\\&quot;&gt;[6]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[15,17]},&quot;v&quot;:&quot;MoCo v2&lt;sup id=\\&quot;fnref:7\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:7\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Chen, X., Fan, H., Girshick, R., &amp;amp; He, K. (2020). Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297.\\n\\&quot;&gt;[7]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[17,19]},&quot;v&quot;:&quot;SimCLR v2&lt;sup id=\\&quot;fnref:8\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:8\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Chen, T., Kornblith, S., Swersky, K., Norouzi, M., &amp;amp; Hinton, G. E. (2020). Big self-supervised models are strong semi-supervised learners. Advances in neural information processing systems, 33, 22243-22255.\\n\\&quot;&gt;[8]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[19,21]},&quot;v&quot;:&quot;SwAV&lt;sup id=\\&quot;fnref:9\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:9\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., &amp;amp; Joulin, A. (2020). Unsupervised learning of visual features by contrasting cluster assignments. Advances in Neural Information Processing Systems, 33, 9912-9924.\\n\\&quot;&gt;[9]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[21,22]},&quot;v&quot;:&quot;No negative samples&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[22,24]},&quot;v&quot;:&quot;BYOL&lt;sup id=\\&quot;fnref:10\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:10\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp;amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in Neural Information Processing Systems, 33, 21271-21284.\\n\\&quot;&gt;[10]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[24,25]},&quot;v&quot;:&quot;Explanation&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[25,27]},&quot;v&quot;:&quot;BYOL v2&lt;sup id=\\&quot;fnref:11\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:11\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Richemond, P. H., Grill, J. B., Altch, F., Tallec, C., Strub, F., Brock, A., ... &amp;amp; Valko, M. (2020). BYOL works even without batch statistics. arXiv preprint arXiv:2010.10241.\\n\\&quot;&gt;[11]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[28,30]},&quot;v&quot;:&quot;SimSiam&lt;sup id=\\&quot;fnref:12\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:12\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Chen, X., &amp;amp; He, K. (2021). Exploring simple siamese representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 15750-15758).\\n\\&quot;&gt;[12]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[31,32]},&quot;v&quot;:&quot;Transformer based&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[32,34]},&quot;v&quot;:&quot;MoCo v3&lt;sup id=\\&quot;fnref:13\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:13\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Chen, X., Xie, S., &amp;amp; He, K. (2021). An empirical study of training self-supervised vision transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 9640-9649).\\n\\&quot;&gt;[13]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[34,36]},&quot;v&quot;:&quot;DINO&lt;sup id=\\&quot;fnref:14\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:14\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Caron, M., Touvron, H., Misra, I., Jgou, H., Mairal, J., Bojanowski, P., &amp;amp; Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 9650-9660).\\n\\&quot;&gt;[14]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]}],&quot;p&quot;:{}}\"></svg>\n</div>\n\n<h2 id=\"brief-introduction\">Brief introduction</h2>\n<blockquote>\n<p><strong>Contrastive learning</strong> is a machine learning technique used to learn <em>the general features</em> of a dataset <strong>without labels</strong> by teaching the model which data points are similar or different.</p>\n</blockquote>\n<p><img src=\"contrastive learning illustration.png\" srcset=\"/img/loading.gif\" lazyload alt=\"contrastive learning illustration.png\" style=\"zoom:25%;\" /></p>\n<p>The idea is intuitive, given 3 pictures above; 2 cats and 1 dog. The goal of contrastive learning is to discriminate the cats from the dog by comparing the pixel similarity of them. Dive into the model, inputing <span class=\"math inline\">\\(X_{cat1}, X_{cat2}, X_{dog}\\)</span> to a neural network. The distance between the resulting latent features of the 2 cats <span class=\"math inline\">\\(L(f_{cat1}, f_{cat2})\\)</span> should approach 0 while those between the cats and the dog <span class=\"math inline\">\\(L(f_{cat}, f_{dog})\\)</span> should approach infinity.</p>\n<p>Contrastive learning is a very portable and flexible technique. It can be used anywhere as long as you can design a rule (<strong>preset task</strong>) to define which data are similar (<strong>positive sample</strong>) and which are different (<strong>negative sample</strong>). In the above example, one defines the pictures of the same species as positive, and those of different species as negative.</p>\n<p>Actually, although it is usually seen as an unsupervised technique, contrastive learning is not meant to be unsupervised. As we can see above, under that context (<strong>preset task</strong>), it is more like a supervised constrained clustering. The model still relies on labeled datasets containing pictures of each species. But people manage to make this technique unsupervised or self-supervised in CV by designing clever <strong>preset tasks</strong>. For example, the <strong>instance discrimination</strong> we are about to see below.</p>\n<p>Except from designing of the <strong>preset task</strong>, another key point is the design of <strong>loss function</strong>. The preset task sets the goal of training while the loss function defines how to do it. Unlike the loss functions that are often used in discrimination learning (cross entropy) or generative learning (L1-L2 loss), contrastive losses measure the similarity of each feature, which varies as the encoded features keep updating with epochs<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[5]</span></a></sup> . Different kinds of loss functions are developed by follow up papers to improve the training efficiency and stability.</p>\n<h2 id=\"stage-1-wild-growth-2019mid\">Stage 1: Wild growth(-2019mid)</h2>\n<p>At this stage, preset tasks, loss function, model and research area are not unified.</p>\n<h3 id=\"instdisc1\">InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup></h3>\n<h4 id=\"preset-task\">Preset task</h4>\n<p><img src=\"Instdisc idea.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Instdisc idea\" style=\"zoom:50%;\" /></p>\n<p>The figure above perfectly explains the motive and goal of the instance discrimination. Just as the name suggests, it extends the discrimination task from the previous class level to the instance level i.e. every single instance is a class.</p>\n<h4 id=\"method\">Method</h4>\n<p><img src=\"Instdisc method.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Instdisc method\" style=\"zoom:100%;\" /></p>\n<p>As shown above, InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup> proposes a CNN (ResNet50) based model that encodes a batch (batch size 256) of figures into a latent feature space(128D), where the distance between each figure are maximised. The way of training such a model is through contrastive learning. For one feature encoded from a particular image, the <strong>positive samples</strong> are the features encoded from the augmentations of the picture and the <strong>negative samples</strong> are obtained by sampling(4096) the set of features encoded from all the other images. In this way, the model becomes self-supervised. To modify the general example above, instance discrimination task can be illustrated as below.</p>\n<p><img src=\"instance discrimination illustration.png\" srcset=\"/img/loading.gif\" lazyload alt=\"instance discrimination illustration\" style=\"zoom:27%;\" /></p>\n<p>Besides, in order to save all the negative features without blowing up the memory, a memory bank is proposed. In every epoch, 4098 negative features are sampled from the memory bank. And the memory bank is updated with features in each epoch, under a method of proximal regularisation.</p>\n<h4 id=\"loss-function\">Loss function</h4>\n<p><strong>Noise Contrastive Estimation</strong>(NCE) loss is applied to push away the negatives while clustering the positives..</p>\n<h4 id=\"comment\">Comment</h4>\n<p>This paper proposes the fundamental preset task instance discrimination. Together with the NCE loss, a fine result is achieved. Besides, the idea of saving a bounden of negative samples with other data structures, the proximal regularisation (momentum updated memory bank) method inspires the following queue method and the momentum updated decoder<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[5]</span></a></sup> Even the super-parameter setting is also typical and a lot of work follows, including MoCo v1<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[5]</span></a></sup>.</p>\n<h3 id=\"invaspread2\">InvaSpread<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Ye, M., Zhang, X., Yuen, P. C., &amp; Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6210-6219).\n\">[2]</span></a></sup></h3>\n<p>Less influential as it is, this paper can be seen as a preliminary work of the SimCLR v1<sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.\n\">[6]</span></a></sup>. Unlike InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup>with additional structure to save negative samples, the positive and negative samples in InvaSpread<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Ye, M., Zhang, X., Yuen, P. C., &amp; Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6210-6219).\n\">[2]</span></a></sup> are from the same batch. And only one encoder is used to process the samples.</p>\n<h4 id=\"method-1\">Method</h4>\n<p><img src=\"InvaSpread illustration.png\" srcset=\"/img/loading.gif\" lazyload alt=\"InvaSpread illustration\" style=\"zoom:100%;\" /></p>\n<p>The preset task is still instance discrimination, while the sampling is done in a different way. As shown above, assuming <span class=\"math inline\">\\(x_1\\)</span> as the original, the positive sample is <span class=\"math inline\">\\([\\hat{x}_1]\\)</span>, while the negative sample is <span class=\"math inline\">\\([x_2,x_3,\\hat{x}_2,\\hat{x}_3]\\)</span>, which means taking batch size as 256, the resulting positive and negative sample sizes are <span class=\"math inline\">\\(256\\)</span> and <span class=\"math inline\">\\((256-1)*2\\)</span> respectively.</p>\n<p>Recalling InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup>, the negative sample is from outside this batch and the size can be much larger. Yet the downside part of it is that it requires another encoder for the negatives. Whereas, with positive and negative in one batch, only one encoder is needed and the model thus becomes end-to-end.</p>\n<p>The loss function employed is a variant of the NCL loss.</p>\n<h4 id=\"comment-1\">Comment</h4>\n<p>Together with the SimCLR series, these papers stand for another route of contrastive learning, which is featured by:</p>\n<ul>\n<li>End-to-end</li>\n<li>Only one encoder</li>\n<li>No reliance on extra data structures</li>\n<li>Positive and negatives are in the same batch</li>\n</ul>\n<p>This paper is very similar to SimCLR but has rather mediocre performance. There are several reasons:</p>\n<ul>\n<li>The batch size is too small - only 256, not enough negative samples (no TPU, no money)</li>\n<li>No powerful augmentations or the MLP projector that are proposed by SimCLR v1<sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.\n\">[6]</span></a></sup></li>\n</ul>\n<h3 id=\"cpc3\">CPC<sup id=\"fnref:3\" class=\"footnote-ref\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Van den Oord, A., Li, Y., &amp; Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv e-prints, arXiv-1807.\n\">[3]</span></a></sup></h3>\n<p>Apart from instance discrimination, this paper proposes another <strong>pretext task</strong> - contrastive predictive coding, a reminiscence of the difference between discriminative and generative models. And this approach is generalisable enough to copes with audio, images, text, and even reinforcement learning.</p>\n<h4 id=\"pretext-task\">pretext task</h4>\n<p><img src=\"CPC illustration.png\" srcset=\"/img/loading.gif\" lazyload alt=\"CPC illustration\" style=\"zoom:100%;\" /></p>\n<p>Given a temporal sequence, the encoded features of the sequence before time t are fed into an auto-regressive network (RNN or LSTM). The \"origin\" is defined as the RNN predicted features after time t <span class=\"math inline\">\\(\\hat{z}_{t+1} - \\hat{z}_{t+4}\\)</span>, the positive sample <span class=\"math inline\">\\(z_{t+1} - z_{t+4}\\)</span>, is defined as the features encoded from feature data <span class=\"math inline\">\\(x_{t+1} - x_{t+4}\\)</span>. The negative samples can be flexible, a typical way is the features encoded from data other than <span class=\"math inline\">\\(x_{t+1} - x_{t+4}\\)</span>.</p>\n<p>In this way, the input <span class=\"math inline\">\\(X\\)</span> can vary from picture patches, audio, video etc.</p>\n<h3 id=\"cmc4\">CMC<sup id=\"fnref:4\" class=\"footnote-ref\"><a href=\"#fn:4\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Tian, Y., Krishnan, D., &amp; Isola, P. (2020, August). Contrastive multiview coding. In European conference on computer vision (pp. 776-794). Springer, Cham.\n\">[4]</span></a></sup></h3>\n<p>CMC propose a more general way of defining positive sample, basically the different view of one instance can be defined as positive.</p>\n<h4 id=\"motivation\">Motivation</h4>\n<p>It is perfectly presented in the abstract, here is just a paraphrase. In the real world, information from different angle of view such as smell, sight and touch describe one thing together. Though these <em>sensory channels</em> might be different, the high level features such as physics, geometry and semantics tend to be same. And this preset task aims to train a view-invariant model.</p>\n<h4 id=\"pre-text-task\">Pre-text task</h4>\n<p><img src=\"CMC illustration.png\" srcset=\"/img/loading.gif\" lazyload alt=\"CMC illustration\" style=\"zoom:30%;\" /></p>\n<p>As the figure above illustrates, the representations of the same scene, no matter which view, are set as positive while representations from different scene as negative.</p>\n<h4 id=\"loss-function-1\">Loss function</h4>\n<p>The contrastive Learning loss is designed to maximise the mutual information between features of different views.</p>\n<h4 id=\"comment-2\">Comment</h4>\n<p>CMC is one of the first works to apply contrastive learning to multi-view problems. It demonstrates the flexibility of contrastive learning, and the portability of applying it to multi-view problems. As a result, OpenAI developed the famous Clip<sup id=\"fnref:16\" class=\"footnote-ref\"><a href=\"#fn:16\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... &amp; Sutskever, I. (2021, July). Learning transferable visual models from natural language supervision. In International Conference on Machine Learning (pp. 8748-8763). PMLR\n\">[16]</span></a></sup> model, where the image and its language description are seen as a positive pair.</p>\n<p>One slight drawback of multi-view might be the need for different encoders to handle different views. For example, in Clip<sup id=\"fnref:16\" class=\"footnote-ref\"><a href=\"#fn:16\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... &amp; Sutskever, I. (2021, July). Learning transferable visual models from natural language supervision. In International Conference on Machine Learning (pp. 8748-8763). PMLR\n\">[16]</span></a></sup>, ViT and a large scale language model are applied to process different modes. Yet, given the various applications of transformer, this drawback may be addressed by processing multi-model problems via one single transformer model. Here is a example of doing it - MA-CLIP<sup id=\"fnref:18\" class=\"footnote-ref\"><a href=\"#fn:18\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"You, H., Zhou, L., Xiao, B., Codella, N. C., Cheng, Y., Xu, R., ... &amp; Yuan, L. (2021). MA-CLIP: Towards Modality-Agnostic Contrastive Language-Image Pre-training.\n\">[18]</span></a></sup>.</p>\n<h2 id=\"stage-2-two-heroes2019mid-2020mid\">Stage 2: Two heroes(2019mid-2020mid)</h2>\n<p>Their are MoCo and SimCLR. In this stage, the development is very fast. The time intervals between each works introduced below are typically 1-2 months, even less than 1 month. And the SOTA on imageNet were refreshed every month. And the model architecture (encoder then projection), loss function(infoNCE), momentum encoder setting, more powerful method augmentation and more epochs tend to come together. And the result trend to the supervised learning accuracy.</p>\n<h3 id=\"moco-v15\">MoCo v1<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[5]</span></a></sup></h3>\n<p>It is the milestone of CV contrastive learning, and it is the first model that outperform supervised learning. It is a breakthrough that rise the confidence of unsupervised learning.</p>\n<h4 id=\"method-2\">Method</h4>\n<p><img src=\"Moco v1 illustration.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Moco v1 illustration\" style=\"zoom:40%;\" /></p>\n<p>As highlighted above, MoCo has two contributions: (1) momentum encoder (2) queue</p>\n<p>MoCo stands for momentum contrast. Compared with InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup>, MoCo updates the encoder with momentum to prevent the encoder changing too rapidly between two batches. Besides, the application of queue instead of memory bank makes sure to update the negative dictionary efficiently.</p>\n<p>Further more, MoCo introduces another loss function called infoNCE, very similar to softmax.</p>\n<h4 id=\"comment-3\">Comment</h4>\n<p>Actually, the details of MoCo almost follows exactly the InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup>, including backbone of ResNet 50, 128D of output size, L2-norm of outputs, 0.07 of loss temperature, the data augmentation setting, 0.03 learning rate and 200 epochs of training. It seems like MoCo is just make some improvements to InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup>.</p>\n<p>Nevertheless, MoCo is classic. The reason may be the effectiveness and the influential of the improvements. For example, the momentum encoder setting is inherited by following SimCLR <sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.\n\">[6]</span></a></sup>, BYOL<sup id=\"fnref:10\" class=\"footnote-ref\"><a href=\"#fn:10\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in Neural Information Processing Systems, 33, 21271-21284.\n\">[10]</span></a></sup>, even the latest work.</p>\n<p>Furthermore, the way of writing is just beautiful and the scope is much higher than an ordinary work. Instead of presenting those improvements that they made. The authors conclude the preliminary works as a task of dictionary look-up. Personally, I feel like I understand the contrastive learning only until I read through the introduction part of MoCO.</p>\n<h3 id=\"simclr-v16\">SimCLR v1<sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.\n\">[6]</span></a></sup></h3>\n<p>SimCLR stands for Simple Contrastive learning, it is easy to understand and often used as example in many introduction blogs. The only drawback is the requirement of large batch size.</p>\n<h4 id=\"method-3\">Method</h4>\n<p><img src=\"SimCLR v1 illustration.png\" srcset=\"/img/loading.gif\" lazyload alt=\"SimCLR v1 illustration\" style=\"zoom:40%;\" /></p>\n<p>It is very similar to InvaSpread<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Ye, M., Zhang, X., Yuen, P. C., &amp; Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6210-6219).\n\">[2]</span></a></sup>, the positive size is <span class=\"math inline\">\\(N\\)</span> While the negative size is <span class=\"math inline\">\\(2(N-1)\\)</span> . The key contribution is a \"projection head(mlp with linear then RELU)\" after the shared encoder, only applied during the training process. The improvement results in a gain of the accuracy up to 10%.</p>\n<p>A loss function similar to infoNCE is used to maximise the agreement between positive and negative samples.</p>\n<h4 id=\"data-augmentation-ablation\">Data augmentation ablation</h4>\n<p><img src=\"SimCLR aug.png\" srcset=\"/img/loading.gif\" lazyload alt=\"SimCLR aug\" style=\"zoom:100%;\" /></p>\n<p>SimCLR does a detailed ablation test searching the most effective augmentation method, as it is crucial for the contrastive learning. As shown above all kinds of augs are listed and studied. And the result, as concluded in the heat-map below, shows the best 2 augmentation methods are crop and colour.</p>\n<p><img src=\"SimCLR aug result.png\" srcset=\"/img/loading.gif\" lazyload alt=\"SimCLR aug result\" style=\"zoom:30%;\" /></p>\n<h4 id=\"projection-ablation\">Projection ablation</h4>\n<p><img src=\"SimCLR projection head.png\" srcset=\"/img/loading.gif\" lazyload alt=\"SimCLR projection head ablation\" style=\"zoom:30%;\" /></p>\n<p>Two piece of information in this result:</p>\n<ul>\n<li>The non-linear(linear with RELU) rise accuracy up by 10%</li>\n<li>The output size makes less difference to the accuracy, so afterwards works tend to choose small size as well. 128 is enough.</li>\n</ul>\n<h4 id=\"comments\" lazyload>Comments</h4>\n<p>The full contributions compared with InvaSpread<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Ye, M., Zhang, X., Yuen, P. C., &amp; Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6210-6219).\n\">[2]</span></a></sup> are:</p>\n<ul>\n<li>More data augmentatinon</li>\n<li>Learnable projection head layer</li>\n<li>Bigger batch size</li>\n<li>More epoch</li>\n</ul>\n<p>The authors are as humble as admitting most of these contributions are not novel in the later part of the article.</p>\n<blockquote>\n<p>We note that almost all individual components of our framework have appeared in previous work, although the specific instantiations may be different. The superiority of our framework relative to previous work is not explained by any single design choice, but by their composition.</p>\n</blockquote>\n<p>However, similar to MoCo<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[5]</span></a></sup>, the contributions of this paper are also very influential. For example, the projection head after the encoder is adopted in following MoCo v2<sup id=\"fnref:7\" class=\"footnote-ref\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, X., Fan, H., Girshick, R., &amp; He, K. (2020). Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297.\n\">[7]</span></a></sup> , SwAV<sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., &amp; Joulin, A. (2020). Unsupervised learning of visual features by contrasting cluster assignments. Advances in Neural Information Processing Systems, 33, 9912-9924.\n\">[9]</span></a></sup>and BYOL<sup id=\"fnref:10\" class=\"footnote-ref\"><a href=\"#fn:10\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in Neural Information Processing Systems, 33, 21271-21284.\n\">[10]</span></a></sup>. And the data augmentation scheme is also widely applied. The the LARS optimiser for large batch size appears in BYOL<sup id=\"fnref:10\" class=\"footnote-ref\"><a href=\"#fn:10\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in Neural Information Processing Systems, 33, 21271-21284.\n\">[10]</span></a></sup> as well.</p>\n<p>And because of the good results of MoCo<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[5]</span></a></sup>, and SimCLR, contrastive learning lead a dominant trend in deep learning from 2020. And ended until the proposing of Vision Transformer.</p>\n<h3 id=\"moco-v27\">MoCo v2<sup id=\"fnref:7\" class=\"footnote-ref\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, X., Fan, H., Girshick, R., &amp; He, K. (2020). Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297.\n\">[7]</span></a></sup></h3>\n<p>It is technically a technical report. They note the effectiveness of the projection head and data augmentation method that SimCRL presented. After just less than 1 month, they merge these techniques into MoCo resulting in new SOTA on ImageNet.</p>\n<h4 id=\"results\">Results</h4>\n<p><img src=\"MoCo v2 ablation.png\" srcset=\"/img/loading.gif\" lazyload alt=\"MoCo v2 ablation\" style=\"zoom:40%;\" /></p>\n<p>From the ablation result above, it is notable that the acc gains 6% with only projection head. And a large number of epochs are useful. As a matter of fact, the trend of increasing epochs still keeps. Recall the new MAE, 1600 epochs are adopted and the accuracy keeps rising.</p>\n<p><img src=\"MoCo v2 result.png\" srcset=\"/img/loading.gif\" lazyload alt=\"MoCo v2 result\" style=\"zoom:40%;\" /></p>\n<p>Besides, they present MoCo v2 outperforms SimCLAR from two angle of views</p>\n<ul>\n<li>MoCo v2 is able to reach higher accuracy with less epochs</li>\n<li>The memory and time cost of MoCo is much lower to get a good result</li>\n</ul>\n<h4 id=\"comment-4\">Comment</h4>\n<p>MoCo v2 may be the most memory friendly method to get a good result with contrastive learning. And it still very useful.</p>\n<h3 id=\"simclr-v28\">SimCLR v2<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, T., Kornblith, S., Swersky, K., Norouzi, M., &amp; Hinton, G. E. (2020). Big self-supervised models are strong semi-supervised learners. Advances in neural information processing systems, 33, 22243-22255.\n\">[8]</span></a></sup></h3>\n<p>Actually most part of this paper focus on semi-supervised leaning. The SimCLR v2 part presented 3 points:</p>\n<ul>\n<li>Bigger backbone model size, 153-layer SKnet</li>\n<li>Deeper projection head, 2 layers MLP after a search of layer number</li>\n<li>Momentum encoder inspired by MoCo<sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.\n\">[6]</span></a></sup><sup id=\"fnref:7\" class=\"footnote-ref\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, X., Fan, H., Girshick, R., &amp; He, K. (2020). Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297.\n\">[7]</span></a></sup>, but less effective. And they claim the reason is that the batch size of SimCLR is already big.</li>\n</ul>\n<h3 id=\"swav9\">SwAV<sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., &amp; Joulin, A. (2020). Unsupervised learning of visual features by contrasting cluster assignments. Advances in Neural Information Processing Systems, 33, 9912-9924.\n\">[9]</span></a></sup></h3>\n<p>SwAV abbreviates for Swapped Assignment Views. This another multi-view work, aiming at predicting one view's feature from another view. And it combines contrastive leaning with clustering.</p>\n<h4 id=\"method-4\">Method</h4>\n<p><img src=\"SwAV illustration.png\" srcset=\"/img/loading.gif\" lazyload alt=\"SwAV illustration\" style=\"zoom:100%;\" /></p>\n<p>Unlike the former contrastive task, instead of enacting contrastive loss between positive and sampled negative features, SwAV compares positive with all negative features via clustering and swap prediction.</p>\n<h4 id=\"multi-crop-augmentation\">Multi-crop augmentation</h4>\n<p>In additional to the great clustering setting, SwAV proposes another type of augmentation, multi-crop. With multi-crop, the model manages to learn information not only from large scale but small scale of an image, with similar computation cost.</p>\n<p><img src=\"SwAV multi crop.png\" srcset=\"/img/loading.gif\" lazyload alt=\"SwAV multi crop\" style=\"zoom:100%;\" /></p>\n<p>It can be seen that the multi crop improve the accuracy on all the approaches, especially on the clustering related ones. And this technique can be seen as a critical contribution to reach SOTA. And it is adopted by a lot following models.</p>\n<h4 id=\"result\">Result</h4>\n<p><img src=\"SwAV result.png\" srcset=\"/img/loading.gif\" lazyload alt=\"SwAV result\" style=\"zoom:100%;\" /></p>\n<p>The result of SwAV not only surpasses the preliminaries, but afters. It keeps SOTA that a convolutional backbone achieves until ViT models appear.</p>\n<p>As shown above, with only linear probe (froze all but the last layer) the SwAV result is very near to the supervised baseline. And the result converges to the supervised result with the model size.</p>\n<h2 id=\"stage-3-no-negative-samples\">Stage 3: No negative samples</h2>\n<p>Basically around BYOL and at last SimSiam integrates all the contributions before and makes a closure for the CNN based contrastive learning era.</p>\n<h3 id=\"byol10\">BYOL<sup id=\"fnref:10\" class=\"footnote-ref\"><a href=\"#fn:10\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in Neural Information Processing Systems, 33, 21271-21284.\n\">[10]</span></a></sup></h3>\n<p>Bootstrap Your Own Latent is the longer version. Negative samples are critical for preventing model collapsing (same output regardless the input, loss always 0, learn nothing). In this new approach, no negative is required.</p>\n<h4 id=\"model\">Model</h4>\n<p><img src=\"BYOL model.png\" srcset=\"/img/loading.gif\" lazyload alt=\"BYOL model\" style=\"zoom:100%;\" /></p>\n<p>The approach is simple, after classical momentum encoder, and momentum projector, another layer (same architecture with projection) is added to the positive line. Then the model is trained to predict the negative output with the output of the positive line.</p>\n<h4 id=\"analysis\">Analysis</h4>\n<p>The result is truly surprising and it resulted in quite a topic. One of the most influencial analytical works is this blog: <a href=\"https://generallyintelligent.ai/blog/2020-08-24-understanding-self-supervised-contrastive-learning/\">Understanding Self-Supervised and Contrastive Learning with \"Bootstrap Your Own Latent\" (BYOL)</a>.</p>\n<table>\n<colgroup>\n<col style=\"width: 12%\" />\n<col style=\"width: 13%\" />\n<col style=\"width: 13%\" />\n<col style=\"width: 9%\" />\n<col style=\"width: 7%\" />\n<col style=\"width: 42%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th>Name</th>\n<th>Projection MLP Norm</th>\n<th>Prediction MLP Norm</th>\n<th>Loss Function</th>\n<th>Contrastive</th>\n<th>Performance <a href=\"https://generallyintelligent.ai/blog/2020-08-24-understanding-self-supervised-contrastive-learning/#fn-5\">5</a></th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>Contrastive Loss</td>\n<td>None</td>\n<td>None</td>\n<td>Cross Entropy</td>\n<td>Explicit</td>\n<td>44.1</td>\n</tr>\n<tr class=\"even\">\n<td>BYOL</td>\n<td>Batch Norm</td>\n<td>Batch Norm</td>\n<td>L2</td>\n<td>Implicit</td>\n<td>57.7</td>\n</tr>\n<tr class=\"odd\">\n<td>Projection BN Only</td>\n<td>Batch Norm</td>\n<td>None</td>\n<td>L2</td>\n<td>Implicit</td>\n<td>55.3</td>\n</tr>\n<tr class=\"even\">\n<td>Prediction BN Only</td>\n<td>None</td>\n<td>Batch Norm</td>\n<td>L2</td>\n<td>Implicit</td>\n<td>48</td>\n</tr>\n<tr class=\"odd\">\n<td>No Normalization</td>\n<td>None</td>\n<td>None</td>\n<td>L2</td>\n<td>None</td>\n<td>28.3</td>\n</tr>\n<tr class=\"even\">\n<td>Layer Norm</td>\n<td>Layer Norm</td>\n<td>Layer Norm</td>\n<td>L2</td>\n<td>None</td>\n<td>29.4</td>\n</tr>\n<tr class=\"odd\">\n<td>Random</td>\n<td></td>\n<td></td>\n<td></td>\n<td>None</td>\n<td>28.8</td>\n</tr>\n</tbody>\n</table>\n<p>The blog author tried to reproduce the BYOL but got model collapsing all the time. So he checked the model and found the reason is one batch norm layer missing in his projection heads. And he did a series of ablation tests on batch normalisation and raise a hypnosis that BYOL leverage batch normal layers as a source of implicit \"negative\" samples. i.e. positive samples are not the only sample needed.</p>\n<blockquote>\n<p><strong>the presence of batch normalisation implicitly causes a form of contrastive learning</strong>.</p>\n</blockquote>\n<h3 id=\"byol-v211\">BYOL v2<sup id=\"fnref:11\" class=\"footnote-ref\"><a href=\"#fn:11\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Richemond, P. H., Grill, J. B., Altch, F., Tallec, C., Strub, F., Brock, A., ... &amp; Valko, M. (2020). BYOL works even without batch statistics. arXiv preprint arXiv:2010.10241.\n\">[11]</span></a></sup></h3>\n<p>The previous blog made a huge influence and the conclusion was widely accepted, exceot the authors. As a result, another article was published entitled \"BYOL works <em>even</em> without batch statistics\"</p>\n<p><img src=\"BYOL batch norm ablation.png\" srcset=\"/img/loading.gif\" lazyload alt=\"BYOL batch norm ablation\" style=\"zoom:100%;\" /></p>\n<p>In this paper, a more detailed ablation experiment was applied. And it shows the batch norm works as it designed, just a method to improve the stability of training.</p>\n<p>Besides, the authors use a better initialisation (group normalisation) , and the model maintains a similar accuracy without any batch norm layer.</p>\n<h3 id=\"simsiam12\">SimSiam<sup id=\"fnref:12\" class=\"footnote-ref\"><a href=\"#fn:12\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, X., &amp; He, K. (2021). Exploring simple siamese representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 15750-15758).\n\">[12]</span></a></sup></h3>\n<p>After all these works, people found the contrastive learning's performance is accumulated by many techniques and tricks, a little too messy. In this context, He et al proposed a simple SimSiam network.</p>\n<p><img src=\"SimSiam illustration.png\" srcset=\"/img/loading.gif\" lazyload alt=\"SimSiam illustration\" style=\"zoom:40%;\" /></p>\n<p>As shown above, SimSiam is basically a BYOL excluding the momentum encoder.</p>\n<p><img src=\"SimSiam result.png\" srcset=\"/img/loading.gif\" lazyload alt=\"SimSiam results\" style=\"zoom:100%;\" /></p>\n<p>And a detailed comparison of results are provided, including classification and downstream tasks. Note that SimCLR and MoCo v2 performs the best on downstream tasks.</p>\n<h2 id=\"stage-4-transformer-based\">Stage 4: Transformer based</h2>\n<p>Because of the popularity of vision transformer<sup id=\"fnref:15\" class=\"footnote-ref\"><a href=\"#fn:15\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[15]</span></a></sup>, the backbones of the contrastive learning methods are substituted into transformer. And the works aim at analysing and solving the resulting unstable problem.</p>\n<h3 id=\"moco-v313\">MoCo v3<sup id=\"fnref:13\" class=\"footnote-ref\"><a href=\"#fn:13\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, X., Xie, S., &amp; He, K. (2021). An empirical study of training self-supervised vision transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 9640-9649).\n\">[13]</span></a></sup></h3>\n<p>Although the title of MoCo v3 includes ViT, it is mostly a architecture that coping with all backbones.</p>\n<h4 id=\"method-5\">Method</h4>\n<p>From the algorithm, the MoCo v3 is a combination of MoCo v2 and SimSam. From the big picture, a query encoder and momentum key encoder with the contrastive loss are inherited from MoCo v2, while in the detail, a prediction mlp layer after the projection layer, a symmetric loss function recall the SimSiam.</p>\n<h4 id=\"transformer-based-model-instability\">Transformer based model instability</h4>\n<p><img src=\"MoCo v3 result.png\" srcset=\"/img/loading.gif\" lazyload alt=\"MoCo v3 result\" style=\"zoom:40%;\" /></p>\n<p>Because of the popularity of ViT, they substitute the backbone as ViT and find instability in training process. As shown above, the training accuracy tend to drop severely then increase gradually especially with large batch size. In this condition, large batch size has a negative impact on accuracy.</p>\n<h4 id=\"trick\">Trick</h4>\n<p>To alleviate the fluctuation, they retrieves the gradients of each layer and find the huge gradient change always occur on first layer (tokenisation patching layer). As a result, they try froze the first layer after random initialisation, and the problem solved. Note that this trick is useful for both MoCo v3 and BYOL with ViT.</p>\n<h3 id=\"dino14\">DINO<sup id=\"fnref:14\" class=\"footnote-ref\"><a href=\"#fn:14\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Caron, M., Touvron, H., Misra, I., Jgou, H., Mairal, J., Bojanowski, P., &amp; Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 9650-9660).\n\">[14]</span></a></sup></h3>\n<p>Short for self-<strong>di</strong>stillation with <strong>no</strong> labels, DINO is actually a follow-up work of BYOL. The student and teacher networks are same as the query and key network respectively. One contribution is the centring layer in the teacher network. And the algorithm is very similar to MoCo v3, same forward process with slightly different loss function.</p>\n<p><img src=\"DINO illustration.png\" srcset=\"/img/loading.gif\" lazyload alt=\"DINO illustration\" style=\"zoom:100%;\" /></p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>The relationships can be included in this diagram below:</p>\n<pre><code class=\" mermaid\">\nclassDiagram\n\nInstDisc --|&gt; MoCo v1\n\nInvaSpread --|&gt; SimCLR v1\n\nCPC v1 --|&gt; CPC v2\n\nCMC  --|&gt; Info min\n\nMoCo v1 --|&gt; MoCo v2\n\nSimCLR v1 --|&gt; CPC v2\n\nSimCLR v1 --|&gt; MoCo v2\n\nSimCLR v1 --|&gt; SimCLR v2\n\nCPC v2 --|&gt; Info min\n\nSimCLR v1 --|&gt; Info min\n\nSimCLR v1 --|&gt; BYOL\n\nBYOL --|&gt; SimSiam\n\nBYOL  --|&gt;  explanation\n\nexplanation  --|&gt;  BYOL v2\n\nSimSiam --|&gt; MoCo v3\n\ndeep cluster --|&gt; SwAV\n\nMoCo v2 --|&gt; MoCo v3\n\nSimSiam --|&gt; DINO\n\nclass InstDisc&#123;\n\n+ Instance discrimination\n\n+ Memory bank\n\n&#125;\n\nclass InvaSpread&#123;\n\n+ End to end\n\n- Limited by batch size\n\n&#125;\n\nclass CPC v1&#123;\n\n+ infoNCE loss\n+ Predictive preset, RNN based model\n+ CV, NLP, audio, RL\n\n&#125;\n\nclass CMC&#123;\n\n+ Muti view\n\n&#125;\n\nclass deep cluster&#123;\n\n+ Based on cluster\n\n- No contrastive\n\n&#125;\n\nclass MoCo v1&#123;\n\n+ memory bank -&gt; queue\n+ Momentom encoder\n+ Outperform supervised\n\n&#125;\n\nclass SimCLR v1&#123;\n\n+ Bigger batch size\n+ More augmentations\n+ Projection head\n+ More epoch\n\n&#125;\n\nclass CPC v2&#123;\n\n+ Add the SimCLR tricks\n+ Gain by **30** \n\n&#125;\n\nclass Info min&#123;\n\n+ Conclude a rule\n- maximise mutual info\n+ minimise mutual info\n+ analytical work\n\n&#125;\n\nclass MoCo v2&#123;\n\n+ Add the SimCLR tricks\n\n&#125;\n\nclass SimCLR v2&#123;\n\nMainly half-supervised\n\n+ Bigger backbone\n+ 2-layer  projection head\n+ Momentom encoder\n\n&#125;\n\nclass SwAV&#123;\n\n+ Combine with contrastive\n+ Multi-crop trick\n\n&#125;\n\nclass BYOL&#123;\n\n+ No negative samples\n+ mse loss\n\n&#125;\n\nclass explanation&#123;\n\n+ BN is the key\n+ Implicit negative sample\n\n&#125;\n\nclass BYOL v2&#123;\n\n- BN is NOT the key\n+ Better initialisation\n\n&#125;\n\nclass SimSiam&#123;\n\n- Conclude and simplified\n- Smaller batch size\n- No momentom encoder\n- No negative sample\n\n+ Stop gradient -&gt; EM\n\n&#125;\n\nclass Barlos Twins&#123;\n\n+ Diff target\n+ Not popular\n\n&#125;\n\nclass MoCo v3&#123;\n\n+ Transformer \n\n+ Freeze patch projection layer\n\n&#125;\n\nclass DINO &#123;\n\n+ Transformer \n\n+ Centring teacher network\n\n&#125;\n</code></pre>\n<h2 id=\"reference\">Reference</h2>\n<section class=\"footnotes\">\n<div class=\"footnote-list\">\n<ol>\n<li>\n<span id=\"fn:1\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html\">Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).</a> <a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:2\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Unsupervised_Embedding_Learning_via_Invariant_and_Spreading_Instance_Feature_CVPR_2019_paper.html\">Ye, M., Zhang, X., Yuen, P. C., &amp; Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (pp. 6210-6219).</a> <a href=\"#fnref:2\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:3\" class=\"footnote-text\"><span><a href=\"https://ui.adsabs.harvard.edu/abs/2018arXiv180703748V/abstract\">Van den Oord, A., Li, Y., &amp; Vinyals, O. (2018). Representation learning with contrastive predictive coding. <em>arXiv e-prints</em>, arXiv-1807.</a> <a href=\"#fnref:3\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:4\" class=\"footnote-text\"><span><a href=\"https://link.springer.com/chapter/10.1007/978-3-030-58621-8_45\">Tian, Y., Krishnan, D., &amp; Isola, P. (2020, August). Contrastive multiview coding. In <em>European conference on computer vision</em> (pp. 776-794). Springer, Cham.</a> <a href=\"#fnref:4\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:5\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html\">He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em> (pp. 9729-9738).</a> <a href=\"#fnref:5\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:6\" class=\"footnote-text\"><span><a href=\"http://proceedings.mlr.press/v119/chen20j.html\">Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In <em>International conference on machine learning</em> (pp. 1597-1607). PMLR.</a> <a href=\"#fnref:6\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:7\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/2003.04297\">Chen, X., Fan, H., Girshick, R., &amp; He, K. (2020). Improved baselines with momentum contrastive learning. <em>arXiv preprint arXiv:2003.04297</em>.</a> <a href=\"#fnref:7\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:8\" class=\"footnote-text\"><span><a href=\"https://proceedings.neurips.cc/paper/2020/hash/fcbc95ccdd551da181207c0c1400c655-Abstract.html\">Chen, T., Kornblith, S., Swersky, K., Norouzi, M., &amp; Hinton, G. E. (2020). Big self-supervised models are strong semi-supervised learners. <em>Advances in neural information processing systems</em>, <em>33</em>, 22243-22255.</a> <a href=\"#fnref:8\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:9\" class=\"footnote-text\"><span><a href=\"https://proceedings.neurips.cc/paper/2020/hash/70feb62b69f16e0238f741fab228fec2-Abstract.html\">Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., &amp; Joulin, A. (2020). Unsupervised learning of visual features by contrasting cluster assignments. <em>Advances in Neural Information Processing Systems</em>, <em>33</em>, 9912-9924.</a> <a href=\"#fnref:9\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:10\" class=\"footnote-text\"><span><a href=\"https://proceedings.neurips.cc/paper/2020/hash/f3ada80d5c4ee70142b17b8192b2958e-Abstract.html\">Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. <em>Advances in Neural Information Processing Systems</em>, <em>33</em>, 21271-21284.</a> <a href=\"#fnref:10\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:11\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/2010.10241\">Richemond, P. H., Grill, J. B., Altch, F., Tallec, C., Strub, F., Brock, A., ... &amp; Valko, M. (2020). BYOL works even without batch statistics. <em>arXiv preprint arXiv:2010.10241</em>.</a> <a href=\"#fnref:11\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:12\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content/CVPR2021/html/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.html\">Chen, X., &amp; He, K. (2021). Exploring simple siamese representation learning. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (pp. 15750-15758).</a> <a href=\"#fnref:12\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:13\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html\">Chen, X., Xie, S., &amp; He, K. (2021). An empirical study of training self-supervised vision transformers. In <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em> (pp. 9640-9649).</a> <a href=\"#fnref:13\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:14\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html\">Caron, M., Touvron, H., Misra, I., Jgou, H., Mairal, J., Bojanowski, P., &amp; Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em> (pp. 9650-9660).</a> <a href=\"#fnref:14\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:15\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/2010.11929\">Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. <em>arXiv preprint arXiv:2010.11929</em>.</a> <a href=\"#fnref:15\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:16\" class=\"footnote-text\"><span><a href=\"http://proceedings.mlr.press/v139/radford21a\">Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... &amp; Sutskever, I. (2021, July). Learning transferable visual models from natural language supervision. In <em>International Conference on Machine Learning</em> (pp. 8748-8763). PMLR</a> <a href=\"#fnref:16\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:17\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/2010.11929\">Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. <em>arXiv preprint arXiv:2010.11929</em>.</a> <a href=\"#fnref:17\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:18\" class=\"footnote-text\"><span><a href=\"https://openreview.net/forum?id=ROteIE-4A6W\">You, H., Zhou, L., Xiao, B., Codella, N. C., Cheng, Y., Xu, R., ... &amp; Yuan, L. (2021). MA-CLIP: Towards Modality-Agnostic Contrastive Language-Image Pre-training.</a> <a href=\"#fnref:18\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n</ol>\n</div>\n</section>\n","site":{"data":{}},"wordcount":21543,"excerpt":"<div class=\"note note-primary\">\n            <p>As a form of unsupervised learning, contrastive learning plays an ever more important role in deep learning. Here's a review of contrastive learning in CV since 2018, including 4 stages and 14 papers. This blog is written following the lead of this <a href=\"https://www.bilibili.com/video/BV19S4y1M7hm/\">review video</a>.</p>\n          </div>","more":"<div class=\"note note-secondary\">\n            <p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n          </div>\n<p>Since, 2018, the development of contrastive learning can be concluded in 4 stages, and an overview is shown below:</p>\n\n<div class=\"markmap-container\" style=\"height:300px\">\n  <svg data=\"{&quot;t&quot;:&quot;root&quot;,&quot;d&quot;:0,&quot;v&quot;:&quot;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[1,2]},&quot;v&quot;:&quot;Wild growth&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[2,4]},&quot;v&quot;:&quot;InstDisc&lt;sup id=\\&quot;fnref:1\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:1\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Wu, Z., Xiong, Y., Yu, S. X., &amp;amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\\n\\&quot;&gt;[1]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[4,6]},&quot;v&quot;:&quot;InvaSpread&lt;sup id=\\&quot;fnref:2\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:2\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Ye, M., Zhang, X., Yuen, P. C., &amp;amp; Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6210-6219).\\n\\&quot;&gt;[2]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[6,8]},&quot;v&quot;:&quot;CPC&lt;sup id=\\&quot;fnref:3\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:3\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Van den Oord, A., Li, Y., &amp;amp; Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv e-prints, arXiv-1807.\\n\\&quot;&gt;[3]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[8,10]},&quot;v&quot;:&quot;CMC&lt;sup id=\\&quot;fnref:4\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:4\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Tian, Y., Krishnan, D., &amp;amp; Isola, P. (2020, August). Contrastive multiview coding. In European conference on computer vision (pp. 776-794). Springer, Cham.\\n\\&quot;&gt;[4]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[10,11]},&quot;v&quot;:&quot;Two heroes&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[11,13]},&quot;v&quot;:&quot;MoCo v1&lt;sup id=\\&quot;fnref:5\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:5\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;He, K., Fan, H., Wu, Y., Xie, S., &amp;amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\\n\\&quot;&gt;[5]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[13,15]},&quot;v&quot;:&quot;SimCLR v1&lt;sup id=\\&quot;fnref:6\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:6\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Chen, T., Kornblith, S., Norouzi, M., &amp;amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.\\n\\&quot;&gt;[6]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[15,17]},&quot;v&quot;:&quot;MoCo v2&lt;sup id=\\&quot;fnref:7\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:7\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Chen, X., Fan, H., Girshick, R., &amp;amp; He, K. (2020). Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297.\\n\\&quot;&gt;[7]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[17,19]},&quot;v&quot;:&quot;SimCLR v2&lt;sup id=\\&quot;fnref:8\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:8\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Chen, T., Kornblith, S., Swersky, K., Norouzi, M., &amp;amp; Hinton, G. E. (2020). Big self-supervised models are strong semi-supervised learners. Advances in neural information processing systems, 33, 22243-22255.\\n\\&quot;&gt;[8]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[19,21]},&quot;v&quot;:&quot;SwAV&lt;sup id=\\&quot;fnref:9\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:9\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., &amp;amp; Joulin, A. (2020). Unsupervised learning of visual features by contrasting cluster assignments. Advances in Neural Information Processing Systems, 33, 9912-9924.\\n\\&quot;&gt;[9]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[21,22]},&quot;v&quot;:&quot;No negative samples&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[22,24]},&quot;v&quot;:&quot;BYOL&lt;sup id=\\&quot;fnref:10\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:10\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp;amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in Neural Information Processing Systems, 33, 21271-21284.\\n\\&quot;&gt;[10]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[24,25]},&quot;v&quot;:&quot;Explanation&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[25,27]},&quot;v&quot;:&quot;BYOL v2&lt;sup id=\\&quot;fnref:11\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:11\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Richemond, P. H., Grill, J. B., Altch, F., Tallec, C., Strub, F., Brock, A., ... &amp;amp; Valko, M. (2020). BYOL works even without batch statistics. arXiv preprint arXiv:2010.10241.\\n\\&quot;&gt;[11]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[28,30]},&quot;v&quot;:&quot;SimSiam&lt;sup id=\\&quot;fnref:12\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:12\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Chen, X., &amp;amp; He, K. (2021). Exploring simple siamese representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 15750-15758).\\n\\&quot;&gt;[12]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[31,32]},&quot;v&quot;:&quot;Transformer based&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[32,34]},&quot;v&quot;:&quot;MoCo v3&lt;sup id=\\&quot;fnref:13\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:13\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Chen, X., Xie, S., &amp;amp; He, K. (2021). An empirical study of training self-supervised vision transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 9640-9649).\\n\\&quot;&gt;[13]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[34,36]},&quot;v&quot;:&quot;DINO&lt;sup id=\\&quot;fnref:14\\&quot; class=\\&quot;footnote-ref\\&quot;&gt;&lt;a href=\\&quot;#fn:14\\&quot; rel=\\&quot;footnote\\&quot;&gt;&lt;span class=\\&quot;hint--top hint--rounded\\&quot; aria-label=\\&quot;Caron, M., Touvron, H., Misra, I., Jgou, H., Mairal, J., Bojanowski, P., &amp;amp; Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 9650-9660).\\n\\&quot;&gt;[14]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&quot;}]}],&quot;p&quot;:{}}\"></svg>\n</div>\n\n<h2 id=\"brief-introduction\">Brief introduction</h2>\n<blockquote>\n<p><strong>Contrastive learning</strong> is a machine learning technique used to learn <em>the general features</em> of a dataset <strong>without labels</strong> by teaching the model which data points are similar or different.</p>\n</blockquote>\n<p><img src=\"contrastive learning illustration.png\" alt=\"contrastive learning illustration.png\" style=\"zoom:25%;\" /></p>\n<p>The idea is intuitive, given 3 pictures above; 2 cats and 1 dog. The goal of contrastive learning is to discriminate the cats from the dog by comparing the pixel similarity of them. Dive into the model, inputing <span class=\"math inline\">\\(X_{cat1}, X_{cat2}, X_{dog}\\)</span> to a neural network. The distance between the resulting latent features of the 2 cats <span class=\"math inline\">\\(L(f_{cat1}, f_{cat2})\\)</span> should approach 0 while those between the cats and the dog <span class=\"math inline\">\\(L(f_{cat}, f_{dog})\\)</span> should approach infinity.</p>\n<p>Contrastive learning is a very portable and flexible technique. It can be used anywhere as long as you can design a rule (<strong>preset task</strong>) to define which data are similar (<strong>positive sample</strong>) and which are different (<strong>negative sample</strong>). In the above example, one defines the pictures of the same species as positive, and those of different species as negative.</p>\n<p>Actually, although it is usually seen as an unsupervised technique, contrastive learning is not meant to be unsupervised. As we can see above, under that context (<strong>preset task</strong>), it is more like a supervised constrained clustering. The model still relies on labeled datasets containing pictures of each species. But people manage to make this technique unsupervised or self-supervised in CV by designing clever <strong>preset tasks</strong>. For example, the <strong>instance discrimination</strong> we are about to see below.</p>\n<p>Except from designing of the <strong>preset task</strong>, another key point is the design of <strong>loss function</strong>. The preset task sets the goal of training while the loss function defines how to do it. Unlike the loss functions that are often used in discrimination learning (cross entropy) or generative learning (L1-L2 loss), contrastive losses measure the similarity of each feature, which varies as the encoded features keep updating with epochs<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[5]</span></a></sup> . Different kinds of loss functions are developed by follow up papers to improve the training efficiency and stability.</p>\n<h2 id=\"stage-1-wild-growth-2019mid\">Stage 1: Wild growth(-2019mid)</h2>\n<p>At this stage, preset tasks, loss function, model and research area are not unified.</p>\n<h3 id=\"instdisc1\">InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup></h3>\n<h4 id=\"preset-task\">Preset task</h4>\n<p><img src=\"Instdisc idea.png\" alt=\"Instdisc idea\" style=\"zoom:50%;\" /></p>\n<p>The figure above perfectly explains the motive and goal of the instance discrimination. Just as the name suggests, it extends the discrimination task from the previous class level to the instance level i.e. every single instance is a class.</p>\n<h4 id=\"method\">Method</h4>\n<p><img src=\"Instdisc method.png\" alt=\"Instdisc method\" style=\"zoom:100%;\" /></p>\n<p>As shown above, InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup> proposes a CNN (ResNet50) based model that encodes a batch (batch size 256) of figures into a latent feature space(128D), where the distance between each figure are maximised. The way of training such a model is through contrastive learning. For one feature encoded from a particular image, the <strong>positive samples</strong> are the features encoded from the augmentations of the picture and the <strong>negative samples</strong> are obtained by sampling(4096) the set of features encoded from all the other images. In this way, the model becomes self-supervised. To modify the general example above, instance discrimination task can be illustrated as below.</p>\n<p><img src=\"instance discrimination illustration.png\" alt=\"instance discrimination illustration\" style=\"zoom:27%;\" /></p>\n<p>Besides, in order to save all the negative features without blowing up the memory, a memory bank is proposed. In every epoch, 4098 negative features are sampled from the memory bank. And the memory bank is updated with features in each epoch, under a method of proximal regularisation.</p>\n<h4 id=\"loss-function\">Loss function</h4>\n<p><strong>Noise Contrastive Estimation</strong>(NCE) loss is applied to push away the negatives while clustering the positives..</p>\n<h4 id=\"comment\">Comment</h4>\n<p>This paper proposes the fundamental preset task instance discrimination. Together with the NCE loss, a fine result is achieved. Besides, the idea of saving a bounden of negative samples with other data structures, the proximal regularisation (momentum updated memory bank) method inspires the following queue method and the momentum updated decoder<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[5]</span></a></sup> Even the super-parameter setting is also typical and a lot of work follows, including MoCo v1<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[5]</span></a></sup>.</p>\n<h3 id=\"invaspread2\">InvaSpread<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Ye, M., Zhang, X., Yuen, P. C., &amp; Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6210-6219).\n\">[2]</span></a></sup></h3>\n<p>Less influential as it is, this paper can be seen as a preliminary work of the SimCLR v1<sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.\n\">[6]</span></a></sup>. Unlike InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup>with additional structure to save negative samples, the positive and negative samples in InvaSpread<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Ye, M., Zhang, X., Yuen, P. C., &amp; Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6210-6219).\n\">[2]</span></a></sup> are from the same batch. And only one encoder is used to process the samples.</p>\n<h4 id=\"method-1\">Method</h4>\n<p><img src=\"InvaSpread illustration.png\" alt=\"InvaSpread illustration\" style=\"zoom:100%;\" /></p>\n<p>The preset task is still instance discrimination, while the sampling is done in a different way. As shown above, assuming <span class=\"math inline\">\\(x_1\\)</span> as the original, the positive sample is <span class=\"math inline\">\\([\\hat{x}_1]\\)</span>, while the negative sample is <span class=\"math inline\">\\([x_2,x_3,\\hat{x}_2,\\hat{x}_3]\\)</span>, which means taking batch size as 256, the resulting positive and negative sample sizes are <span class=\"math inline\">\\(256\\)</span> and <span class=\"math inline\">\\((256-1)*2\\)</span> respectively.</p>\n<p>Recalling InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup>, the negative sample is from outside this batch and the size can be much larger. Yet the downside part of it is that it requires another encoder for the negatives. Whereas, with positive and negative in one batch, only one encoder is needed and the model thus becomes end-to-end.</p>\n<p>The loss function employed is a variant of the NCL loss.</p>\n<h4 id=\"comment-1\">Comment</h4>\n<p>Together with the SimCLR series, these papers stand for another route of contrastive learning, which is featured by:</p>\n<ul>\n<li>End-to-end</li>\n<li>Only one encoder</li>\n<li>No reliance on extra data structures</li>\n<li>Positive and negatives are in the same batch</li>\n</ul>\n<p>This paper is very similar to SimCLR but has rather mediocre performance. There are several reasons:</p>\n<ul>\n<li>The batch size is too small - only 256, not enough negative samples (no TPU, no money)</li>\n<li>No powerful augmentations or the MLP projector that are proposed by SimCLR v1<sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.\n\">[6]</span></a></sup></li>\n</ul>\n<h3 id=\"cpc3\">CPC<sup id=\"fnref:3\" class=\"footnote-ref\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Van den Oord, A., Li, Y., &amp; Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv e-prints, arXiv-1807.\n\">[3]</span></a></sup></h3>\n<p>Apart from instance discrimination, this paper proposes another <strong>pretext task</strong> - contrastive predictive coding, a reminiscence of the difference between discriminative and generative models. And this approach is generalisable enough to copes with audio, images, text, and even reinforcement learning.</p>\n<h4 id=\"pretext-task\">pretext task</h4>\n<p><img src=\"CPC illustration.png\" alt=\"CPC illustration\" style=\"zoom:100%;\" /></p>\n<p>Given a temporal sequence, the encoded features of the sequence before time t are fed into an auto-regressive network (RNN or LSTM). The \"origin\" is defined as the RNN predicted features after time t <span class=\"math inline\">\\(\\hat{z}_{t+1} - \\hat{z}_{t+4}\\)</span>, the positive sample <span class=\"math inline\">\\(z_{t+1} - z_{t+4}\\)</span>, is defined as the features encoded from feature data <span class=\"math inline\">\\(x_{t+1} - x_{t+4}\\)</span>. The negative samples can be flexible, a typical way is the features encoded from data other than <span class=\"math inline\">\\(x_{t+1} - x_{t+4}\\)</span>.</p>\n<p>In this way, the input <span class=\"math inline\">\\(X\\)</span> can vary from picture patches, audio, video etc.</p>\n<h3 id=\"cmc4\">CMC<sup id=\"fnref:4\" class=\"footnote-ref\"><a href=\"#fn:4\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Tian, Y., Krishnan, D., &amp; Isola, P. (2020, August). Contrastive multiview coding. In European conference on computer vision (pp. 776-794). Springer, Cham.\n\">[4]</span></a></sup></h3>\n<p>CMC propose a more general way of defining positive sample, basically the different view of one instance can be defined as positive.</p>\n<h4 id=\"motivation\">Motivation</h4>\n<p>It is perfectly presented in the abstract, here is just a paraphrase. In the real world, information from different angle of view such as smell, sight and touch describe one thing together. Though these <em>sensory channels</em> might be different, the high level features such as physics, geometry and semantics tend to be same. And this preset task aims to train a view-invariant model.</p>\n<h4 id=\"pre-text-task\">Pre-text task</h4>\n<p><img src=\"CMC illustration.png\" alt=\"CMC illustration\" style=\"zoom:30%;\" /></p>\n<p>As the figure above illustrates, the representations of the same scene, no matter which view, are set as positive while representations from different scene as negative.</p>\n<h4 id=\"loss-function-1\">Loss function</h4>\n<p>The contrastive Learning loss is designed to maximise the mutual information between features of different views.</p>\n<h4 id=\"comment-2\">Comment</h4>\n<p>CMC is one of the first works to apply contrastive learning to multi-view problems. It demonstrates the flexibility of contrastive learning, and the portability of applying it to multi-view problems. As a result, OpenAI developed the famous Clip<sup id=\"fnref:16\" class=\"footnote-ref\"><a href=\"#fn:16\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... &amp; Sutskever, I. (2021, July). Learning transferable visual models from natural language supervision. In International Conference on Machine Learning (pp. 8748-8763). PMLR\n\">[16]</span></a></sup> model, where the image and its language description are seen as a positive pair.</p>\n<p>One slight drawback of multi-view might be the need for different encoders to handle different views. For example, in Clip<sup id=\"fnref:16\" class=\"footnote-ref\"><a href=\"#fn:16\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... &amp; Sutskever, I. (2021, July). Learning transferable visual models from natural language supervision. In International Conference on Machine Learning (pp. 8748-8763). PMLR\n\">[16]</span></a></sup>, ViT and a large scale language model are applied to process different modes. Yet, given the various applications of transformer, this drawback may be addressed by processing multi-model problems via one single transformer model. Here is a example of doing it - MA-CLIP<sup id=\"fnref:18\" class=\"footnote-ref\"><a href=\"#fn:18\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"You, H., Zhou, L., Xiao, B., Codella, N. C., Cheng, Y., Xu, R., ... &amp; Yuan, L. (2021). MA-CLIP: Towards Modality-Agnostic Contrastive Language-Image Pre-training.\n\">[18]</span></a></sup>.</p>\n<h2 id=\"stage-2-two-heroes2019mid-2020mid\">Stage 2: Two heroes(2019mid-2020mid)</h2>\n<p>Their are MoCo and SimCLR. In this stage, the development is very fast. The time intervals between each works introduced below are typically 1-2 months, even less than 1 month. And the SOTA on imageNet were refreshed every month. And the model architecture (encoder then projection), loss function(infoNCE), momentum encoder setting, more powerful method augmentation and more epochs tend to come together. And the result trend to the supervised learning accuracy.</p>\n<h3 id=\"moco-v15\">MoCo v1<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[5]</span></a></sup></h3>\n<p>It is the milestone of CV contrastive learning, and it is the first model that outperform supervised learning. It is a breakthrough that rise the confidence of unsupervised learning.</p>\n<h4 id=\"method-2\">Method</h4>\n<p><img src=\"Moco v1 illustration.png\" alt=\"Moco v1 illustration\" style=\"zoom:40%;\" /></p>\n<p>As highlighted above, MoCo has two contributions: (1) momentum encoder (2) queue</p>\n<p>MoCo stands for momentum contrast. Compared with InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup>, MoCo updates the encoder with momentum to prevent the encoder changing too rapidly between two batches. Besides, the application of queue instead of memory bank makes sure to update the negative dictionary efficiently.</p>\n<p>Further more, MoCo introduces another loss function called infoNCE, very similar to softmax.</p>\n<h4 id=\"comment-3\">Comment</h4>\n<p>Actually, the details of MoCo almost follows exactly the InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup>, including backbone of ResNet 50, 128D of output size, L2-norm of outputs, 0.07 of loss temperature, the data augmentation setting, 0.03 learning rate and 200 epochs of training. It seems like MoCo is just make some improvements to InstDisc<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).\n\">[1]</span></a></sup>.</p>\n<p>Nevertheless, MoCo is classic. The reason may be the effectiveness and the influential of the improvements. For example, the momentum encoder setting is inherited by following SimCLR <sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.\n\">[6]</span></a></sup>, BYOL<sup id=\"fnref:10\" class=\"footnote-ref\"><a href=\"#fn:10\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in Neural Information Processing Systems, 33, 21271-21284.\n\">[10]</span></a></sup>, even the latest work.</p>\n<p>Furthermore, the way of writing is just beautiful and the scope is much higher than an ordinary work. Instead of presenting those improvements that they made. The authors conclude the preliminary works as a task of dictionary look-up. Personally, I feel like I understand the contrastive learning only until I read through the introduction part of MoCO.</p>\n<h3 id=\"simclr-v16\">SimCLR v1<sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.\n\">[6]</span></a></sup></h3>\n<p>SimCLR stands for Simple Contrastive learning, it is easy to understand and often used as example in many introduction blogs. The only drawback is the requirement of large batch size.</p>\n<h4 id=\"method-3\">Method</h4>\n<p><img src=\"SimCLR v1 illustration.png\" alt=\"SimCLR v1 illustration\" style=\"zoom:40%;\" /></p>\n<p>It is very similar to InvaSpread<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Ye, M., Zhang, X., Yuen, P. C., &amp; Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6210-6219).\n\">[2]</span></a></sup>, the positive size is <span class=\"math inline\">\\(N\\)</span> While the negative size is <span class=\"math inline\">\\(2(N-1)\\)</span> . The key contribution is a \"projection head(mlp with linear then RELU)\" after the shared encoder, only applied during the training process. The improvement results in a gain of the accuracy up to 10%.</p>\n<p>A loss function similar to infoNCE is used to maximise the agreement between positive and negative samples.</p>\n<h4 id=\"data-augmentation-ablation\">Data augmentation ablation</h4>\n<p><img src=\"SimCLR aug.png\" alt=\"SimCLR aug\" style=\"zoom:100%;\" /></p>\n<p>SimCLR does a detailed ablation test searching the most effective augmentation method, as it is crucial for the contrastive learning. As shown above all kinds of augs are listed and studied. And the result, as concluded in the heat-map below, shows the best 2 augmentation methods are crop and colour.</p>\n<p><img src=\"SimCLR aug result.png\" alt=\"SimCLR aug result\" style=\"zoom:30%;\" /></p>\n<h4 id=\"projection-ablation\">Projection ablation</h4>\n<p><img src=\"SimCLR projection head.png\" alt=\"SimCLR projection head ablation\" style=\"zoom:30%;\" /></p>\n<p>Two piece of information in this result:</p>\n<ul>\n<li>The non-linear(linear with RELU) rise accuracy up by 10%</li>\n<li>The output size makes less difference to the accuracy, so afterwards works tend to choose small size as well. 128 is enough.</li>\n</ul>\n<h4 id=\"comments\">Comments</h4>\n<p>The full contributions compared with InvaSpread<sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Ye, M., Zhang, X., Yuen, P. C., &amp; Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6210-6219).\n\">[2]</span></a></sup> are:</p>\n<ul>\n<li>More data augmentatinon</li>\n<li>Learnable projection head layer</li>\n<li>Bigger batch size</li>\n<li>More epoch</li>\n</ul>\n<p>The authors are as humble as admitting most of these contributions are not novel in the later part of the article.</p>\n<blockquote>\n<p>We note that almost all individual components of our framework have appeared in previous work, although the specific instantiations may be different. The superiority of our framework relative to previous work is not explained by any single design choice, but by their composition.</p>\n</blockquote>\n<p>However, similar to MoCo<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[5]</span></a></sup>, the contributions of this paper are also very influential. For example, the projection head after the encoder is adopted in following MoCo v2<sup id=\"fnref:7\" class=\"footnote-ref\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, X., Fan, H., Girshick, R., &amp; He, K. (2020). Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297.\n\">[7]</span></a></sup> , SwAV<sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., &amp; Joulin, A. (2020). Unsupervised learning of visual features by contrasting cluster assignments. Advances in Neural Information Processing Systems, 33, 9912-9924.\n\">[9]</span></a></sup>and BYOL<sup id=\"fnref:10\" class=\"footnote-ref\"><a href=\"#fn:10\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in Neural Information Processing Systems, 33, 21271-21284.\n\">[10]</span></a></sup>. And the data augmentation scheme is also widely applied. The the LARS optimiser for large batch size appears in BYOL<sup id=\"fnref:10\" class=\"footnote-ref\"><a href=\"#fn:10\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in Neural Information Processing Systems, 33, 21271-21284.\n\">[10]</span></a></sup> as well.</p>\n<p>And because of the good results of MoCo<sup id=\"fnref:5\" class=\"footnote-ref\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).\n\">[5]</span></a></sup>, and SimCLR, contrastive learning lead a dominant trend in deep learning from 2020. And ended until the proposing of Vision Transformer.</p>\n<h3 id=\"moco-v27\">MoCo v2<sup id=\"fnref:7\" class=\"footnote-ref\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, X., Fan, H., Girshick, R., &amp; He, K. (2020). Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297.\n\">[7]</span></a></sup></h3>\n<p>It is technically a technical report. They note the effectiveness of the projection head and data augmentation method that SimCRL presented. After just less than 1 month, they merge these techniques into MoCo resulting in new SOTA on ImageNet.</p>\n<h4 id=\"results\">Results</h4>\n<p><img src=\"MoCo v2 ablation.png\" alt=\"MoCo v2 ablation\" style=\"zoom:40%;\" /></p>\n<p>From the ablation result above, it is notable that the acc gains 6% with only projection head. And a large number of epochs are useful. As a matter of fact, the trend of increasing epochs still keeps. Recall the new MAE, 1600 epochs are adopted and the accuracy keeps rising.</p>\n<p><img src=\"MoCo v2 result.png\" alt=\"MoCo v2 result\" style=\"zoom:40%;\" /></p>\n<p>Besides, they present MoCo v2 outperforms SimCLAR from two angle of views</p>\n<ul>\n<li>MoCo v2 is able to reach higher accuracy with less epochs</li>\n<li>The memory and time cost of MoCo is much lower to get a good result</li>\n</ul>\n<h4 id=\"comment-4\">Comment</h4>\n<p>MoCo v2 may be the most memory friendly method to get a good result with contrastive learning. And it still very useful.</p>\n<h3 id=\"simclr-v28\">SimCLR v2<sup id=\"fnref:8\" class=\"footnote-ref\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, T., Kornblith, S., Swersky, K., Norouzi, M., &amp; Hinton, G. E. (2020). Big self-supervised models are strong semi-supervised learners. Advances in neural information processing systems, 33, 22243-22255.\n\">[8]</span></a></sup></h3>\n<p>Actually most part of this paper focus on semi-supervised leaning. The SimCLR v2 part presented 3 points:</p>\n<ul>\n<li>Bigger backbone model size, 153-layer SKnet</li>\n<li>Deeper projection head, 2 layers MLP after a search of layer number</li>\n<li>Momentum encoder inspired by MoCo<sup id=\"fnref:6\" class=\"footnote-ref\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.\n\">[6]</span></a></sup><sup id=\"fnref:7\" class=\"footnote-ref\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, X., Fan, H., Girshick, R., &amp; He, K. (2020). Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297.\n\">[7]</span></a></sup>, but less effective. And they claim the reason is that the batch size of SimCLR is already big.</li>\n</ul>\n<h3 id=\"swav9\">SwAV<sup id=\"fnref:9\" class=\"footnote-ref\"><a href=\"#fn:9\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., &amp; Joulin, A. (2020). Unsupervised learning of visual features by contrasting cluster assignments. Advances in Neural Information Processing Systems, 33, 9912-9924.\n\">[9]</span></a></sup></h3>\n<p>SwAV abbreviates for Swapped Assignment Views. This another multi-view work, aiming at predicting one view's feature from another view. And it combines contrastive leaning with clustering.</p>\n<h4 id=\"method-4\">Method</h4>\n<p><img src=\"SwAV illustration.png\" alt=\"SwAV illustration\" style=\"zoom:100%;\" /></p>\n<p>Unlike the former contrastive task, instead of enacting contrastive loss between positive and sampled negative features, SwAV compares positive with all negative features via clustering and swap prediction.</p>\n<h4 id=\"multi-crop-augmentation\">Multi-crop augmentation</h4>\n<p>In additional to the great clustering setting, SwAV proposes another type of augmentation, multi-crop. With multi-crop, the model manages to learn information not only from large scale but small scale of an image, with similar computation cost.</p>\n<p><img src=\"SwAV multi crop.png\" alt=\"SwAV multi crop\" style=\"zoom:100%;\" /></p>\n<p>It can be seen that the multi crop improve the accuracy on all the approaches, especially on the clustering related ones. And this technique can be seen as a critical contribution to reach SOTA. And it is adopted by a lot following models.</p>\n<h4 id=\"result\">Result</h4>\n<p><img src=\"SwAV result.png\" alt=\"SwAV result\" style=\"zoom:100%;\" /></p>\n<p>The result of SwAV not only surpasses the preliminaries, but afters. It keeps SOTA that a convolutional backbone achieves until ViT models appear.</p>\n<p>As shown above, with only linear probe (froze all but the last layer) the SwAV result is very near to the supervised baseline. And the result converges to the supervised result with the model size.</p>\n<h2 id=\"stage-3-no-negative-samples\">Stage 3: No negative samples</h2>\n<p>Basically around BYOL and at last SimSiam integrates all the contributions before and makes a closure for the CNN based contrastive learning era.</p>\n<h3 id=\"byol10\">BYOL<sup id=\"fnref:10\" class=\"footnote-ref\"><a href=\"#fn:10\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in Neural Information Processing Systems, 33, 21271-21284.\n\">[10]</span></a></sup></h3>\n<p>Bootstrap Your Own Latent is the longer version. Negative samples are critical for preventing model collapsing (same output regardless the input, loss always 0, learn nothing). In this new approach, no negative is required.</p>\n<h4 id=\"model\">Model</h4>\n<p><img src=\"BYOL model.png\" alt=\"BYOL model\" style=\"zoom:100%;\" /></p>\n<p>The approach is simple, after classical momentum encoder, and momentum projector, another layer (same architecture with projection) is added to the positive line. Then the model is trained to predict the negative output with the output of the positive line.</p>\n<h4 id=\"analysis\">Analysis</h4>\n<p>The result is truly surprising and it resulted in quite a topic. One of the most influencial analytical works is this blog: <a href=\"https://generallyintelligent.ai/blog/2020-08-24-understanding-self-supervised-contrastive-learning/\">Understanding Self-Supervised and Contrastive Learning with \"Bootstrap Your Own Latent\" (BYOL)</a>.</p>\n<table>\n<colgroup>\n<col style=\"width: 12%\" />\n<col style=\"width: 13%\" />\n<col style=\"width: 13%\" />\n<col style=\"width: 9%\" />\n<col style=\"width: 7%\" />\n<col style=\"width: 42%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th>Name</th>\n<th>Projection MLP Norm</th>\n<th>Prediction MLP Norm</th>\n<th>Loss Function</th>\n<th>Contrastive</th>\n<th>Performance <a href=\"https://generallyintelligent.ai/blog/2020-08-24-understanding-self-supervised-contrastive-learning/#fn-5\">5</a></th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>Contrastive Loss</td>\n<td>None</td>\n<td>None</td>\n<td>Cross Entropy</td>\n<td>Explicit</td>\n<td>44.1</td>\n</tr>\n<tr class=\"even\">\n<td>BYOL</td>\n<td>Batch Norm</td>\n<td>Batch Norm</td>\n<td>L2</td>\n<td>Implicit</td>\n<td>57.7</td>\n</tr>\n<tr class=\"odd\">\n<td>Projection BN Only</td>\n<td>Batch Norm</td>\n<td>None</td>\n<td>L2</td>\n<td>Implicit</td>\n<td>55.3</td>\n</tr>\n<tr class=\"even\">\n<td>Prediction BN Only</td>\n<td>None</td>\n<td>Batch Norm</td>\n<td>L2</td>\n<td>Implicit</td>\n<td>48</td>\n</tr>\n<tr class=\"odd\">\n<td>No Normalization</td>\n<td>None</td>\n<td>None</td>\n<td>L2</td>\n<td>None</td>\n<td>28.3</td>\n</tr>\n<tr class=\"even\">\n<td>Layer Norm</td>\n<td>Layer Norm</td>\n<td>Layer Norm</td>\n<td>L2</td>\n<td>None</td>\n<td>29.4</td>\n</tr>\n<tr class=\"odd\">\n<td>Random</td>\n<td></td>\n<td></td>\n<td></td>\n<td>None</td>\n<td>28.8</td>\n</tr>\n</tbody>\n</table>\n<p>The blog author tried to reproduce the BYOL but got model collapsing all the time. So he checked the model and found the reason is one batch norm layer missing in his projection heads. And he did a series of ablation tests on batch normalisation and raise a hypnosis that BYOL leverage batch normal layers as a source of implicit \"negative\" samples. i.e. positive samples are not the only sample needed.</p>\n<blockquote>\n<p><strong>the presence of batch normalisation implicitly causes a form of contrastive learning</strong>.</p>\n</blockquote>\n<h3 id=\"byol-v211\">BYOL v2<sup id=\"fnref:11\" class=\"footnote-ref\"><a href=\"#fn:11\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Richemond, P. H., Grill, J. B., Altch, F., Tallec, C., Strub, F., Brock, A., ... &amp; Valko, M. (2020). BYOL works even without batch statistics. arXiv preprint arXiv:2010.10241.\n\">[11]</span></a></sup></h3>\n<p>The previous blog made a huge influence and the conclusion was widely accepted, exceot the authors. As a result, another article was published entitled \"BYOL works <em>even</em> without batch statistics\"</p>\n<p><img src=\"BYOL batch norm ablation.png\" alt=\"BYOL batch norm ablation\" style=\"zoom:100%;\" /></p>\n<p>In this paper, a more detailed ablation experiment was applied. And it shows the batch norm works as it designed, just a method to improve the stability of training.</p>\n<p>Besides, the authors use a better initialisation (group normalisation) , and the model maintains a similar accuracy without any batch norm layer.</p>\n<h3 id=\"simsiam12\">SimSiam<sup id=\"fnref:12\" class=\"footnote-ref\"><a href=\"#fn:12\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, X., &amp; He, K. (2021). Exploring simple siamese representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 15750-15758).\n\">[12]</span></a></sup></h3>\n<p>After all these works, people found the contrastive learning's performance is accumulated by many techniques and tricks, a little too messy. In this context, He et al proposed a simple SimSiam network.</p>\n<p><img src=\"SimSiam illustration.png\" alt=\"SimSiam illustration\" style=\"zoom:40%;\" /></p>\n<p>As shown above, SimSiam is basically a BYOL excluding the momentum encoder.</p>\n<p><img src=\"SimSiam result.png\" alt=\"SimSiam results\" style=\"zoom:100%;\" /></p>\n<p>And a detailed comparison of results are provided, including classification and downstream tasks. Note that SimCLR and MoCo v2 performs the best on downstream tasks.</p>\n<h2 id=\"stage-4-transformer-based\">Stage 4: Transformer based</h2>\n<p>Because of the popularity of vision transformer<sup id=\"fnref:15\" class=\"footnote-ref\"><a href=\"#fn:15\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n\">[15]</span></a></sup>, the backbones of the contrastive learning methods are substituted into transformer. And the works aim at analysing and solving the resulting unstable problem.</p>\n<h3 id=\"moco-v313\">MoCo v3<sup id=\"fnref:13\" class=\"footnote-ref\"><a href=\"#fn:13\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Chen, X., Xie, S., &amp; He, K. (2021). An empirical study of training self-supervised vision transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 9640-9649).\n\">[13]</span></a></sup></h3>\n<p>Although the title of MoCo v3 includes ViT, it is mostly a architecture that coping with all backbones.</p>\n<h4 id=\"method-5\">Method</h4>\n<p>From the algorithm, the MoCo v3 is a combination of MoCo v2 and SimSam. From the big picture, a query encoder and momentum key encoder with the contrastive loss are inherited from MoCo v2, while in the detail, a prediction mlp layer after the projection layer, a symmetric loss function recall the SimSiam.</p>\n<h4 id=\"transformer-based-model-instability\">Transformer based model instability</h4>\n<p><img src=\"MoCo v3 result.png\" alt=\"MoCo v3 result\" style=\"zoom:40%;\" /></p>\n<p>Because of the popularity of ViT, they substitute the backbone as ViT and find instability in training process. As shown above, the training accuracy tend to drop severely then increase gradually especially with large batch size. In this condition, large batch size has a negative impact on accuracy.</p>\n<h4 id=\"trick\">Trick</h4>\n<p>To alleviate the fluctuation, they retrieves the gradients of each layer and find the huge gradient change always occur on first layer (tokenisation patching layer). As a result, they try froze the first layer after random initialisation, and the problem solved. Note that this trick is useful for both MoCo v3 and BYOL with ViT.</p>\n<h3 id=\"dino14\">DINO<sup id=\"fnref:14\" class=\"footnote-ref\"><a href=\"#fn:14\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Caron, M., Touvron, H., Misra, I., Jgou, H., Mairal, J., Bojanowski, P., &amp; Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 9650-9660).\n\">[14]</span></a></sup></h3>\n<p>Short for self-<strong>di</strong>stillation with <strong>no</strong> labels, DINO is actually a follow-up work of BYOL. The student and teacher networks are same as the query and key network respectively. One contribution is the centring layer in the teacher network. And the algorithm is very similar to MoCo v3, same forward process with slightly different loss function.</p>\n<p><img src=\"DINO illustration.png\" alt=\"DINO illustration\" style=\"zoom:100%;\" /></p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>The relationships can be included in this diagram below:</p>\n<pre><code class=\"hljs mermaid\">\nclassDiagram\n\nInstDisc --|&gt; MoCo v1\n\nInvaSpread --|&gt; SimCLR v1\n\nCPC v1 --|&gt; CPC v2\n\nCMC  --|&gt; Info min\n\nMoCo v1 --|&gt; MoCo v2\n\nSimCLR v1 --|&gt; CPC v2\n\nSimCLR v1 --|&gt; MoCo v2\n\nSimCLR v1 --|&gt; SimCLR v2\n\nCPC v2 --|&gt; Info min\n\nSimCLR v1 --|&gt; Info min\n\nSimCLR v1 --|&gt; BYOL\n\nBYOL --|&gt; SimSiam\n\nBYOL  --|&gt;  explanation\n\nexplanation  --|&gt;  BYOL v2\n\nSimSiam --|&gt; MoCo v3\n\ndeep cluster --|&gt; SwAV\n\nMoCo v2 --|&gt; MoCo v3\n\nSimSiam --|&gt; DINO\n\nclass InstDisc&#123;\n\n+ Instance discrimination\n\n+ Memory bank\n\n&#125;\n\nclass InvaSpread&#123;\n\n+ End to end\n\n- Limited by batch size\n\n&#125;\n\nclass CPC v1&#123;\n\n+ infoNCE loss\n+ Predictive preset, RNN based model\n+ CV, NLP, audio, RL\n\n&#125;\n\nclass CMC&#123;\n\n+ Muti view\n\n&#125;\n\nclass deep cluster&#123;\n\n+ Based on cluster\n\n- No contrastive\n\n&#125;\n\nclass MoCo v1&#123;\n\n+ memory bank -&gt; queue\n+ Momentom encoder\n+ Outperform supervised\n\n&#125;\n\nclass SimCLR v1&#123;\n\n+ Bigger batch size\n+ More augmentations\n+ Projection head\n+ More epoch\n\n&#125;\n\nclass CPC v2&#123;\n\n+ Add the SimCLR tricks\n+ Gain by **30** \n\n&#125;\n\nclass Info min&#123;\n\n+ Conclude a rule\n- maximise mutual info\n+ minimise mutual info\n+ analytical work\n\n&#125;\n\nclass MoCo v2&#123;\n\n+ Add the SimCLR tricks\n\n&#125;\n\nclass SimCLR v2&#123;\n\nMainly half-supervised\n\n+ Bigger backbone\n+ 2-layer  projection head\n+ Momentom encoder\n\n&#125;\n\nclass SwAV&#123;\n\n+ Combine with contrastive\n+ Multi-crop trick\n\n&#125;\n\nclass BYOL&#123;\n\n+ No negative samples\n+ mse loss\n\n&#125;\n\nclass explanation&#123;\n\n+ BN is the key\n+ Implicit negative sample\n\n&#125;\n\nclass BYOL v2&#123;\n\n- BN is NOT the key\n+ Better initialisation\n\n&#125;\n\nclass SimSiam&#123;\n\n- Conclude and simplified\n- Smaller batch size\n- No momentom encoder\n- No negative sample\n\n+ Stop gradient -&gt; EM\n\n&#125;\n\nclass Barlos Twins&#123;\n\n+ Diff target\n+ Not popular\n\n&#125;\n\nclass MoCo v3&#123;\n\n+ Transformer \n\n+ Freeze patch projection layer\n\n&#125;\n\nclass DINO &#123;\n\n+ Transformer \n\n+ Centring teacher network\n\n&#125;\n</code></pre>\n<h2 id=\"reference\">Reference</h2>\n<section class=\"footnotes\">\n<div class=\"footnote-list\">\n<ol>\n<li>\n<span id=\"fn:1\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html\">Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3733-3742).</a> <a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:2\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Unsupervised_Embedding_Learning_via_Invariant_and_Spreading_Instance_Feature_CVPR_2019_paper.html\">Ye, M., Zhang, X., Yuen, P. C., &amp; Chang, S. F. (2019). Unsupervised embedding learning via invariant and spreading instance feature. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (pp. 6210-6219).</a> <a href=\"#fnref:2\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:3\" class=\"footnote-text\"><span><a href=\"https://ui.adsabs.harvard.edu/abs/2018arXiv180703748V/abstract\">Van den Oord, A., Li, Y., &amp; Vinyals, O. (2018). Representation learning with contrastive predictive coding. <em>arXiv e-prints</em>, arXiv-1807.</a> <a href=\"#fnref:3\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:4\" class=\"footnote-text\"><span><a href=\"https://link.springer.com/chapter/10.1007/978-3-030-58621-8_45\">Tian, Y., Krishnan, D., &amp; Isola, P. (2020, August). Contrastive multiview coding. In <em>European conference on computer vision</em> (pp. 776-794). Springer, Cham.</a> <a href=\"#fnref:4\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:5\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html\">He, K., Fan, H., Wu, Y., Xie, S., &amp; Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em> (pp. 9729-9738).</a> <a href=\"#fnref:5\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:6\" class=\"footnote-text\"><span><a href=\"http://proceedings.mlr.press/v119/chen20j.html\">Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). A simple framework for contrastive learning of visual representations. In <em>International conference on machine learning</em> (pp. 1597-1607). PMLR.</a> <a href=\"#fnref:6\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:7\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/2003.04297\">Chen, X., Fan, H., Girshick, R., &amp; He, K. (2020). Improved baselines with momentum contrastive learning. <em>arXiv preprint arXiv:2003.04297</em>.</a> <a href=\"#fnref:7\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:8\" class=\"footnote-text\"><span><a href=\"https://proceedings.neurips.cc/paper/2020/hash/fcbc95ccdd551da181207c0c1400c655-Abstract.html\">Chen, T., Kornblith, S., Swersky, K., Norouzi, M., &amp; Hinton, G. E. (2020). Big self-supervised models are strong semi-supervised learners. <em>Advances in neural information processing systems</em>, <em>33</em>, 22243-22255.</a> <a href=\"#fnref:8\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:9\" class=\"footnote-text\"><span><a href=\"https://proceedings.neurips.cc/paper/2020/hash/70feb62b69f16e0238f741fab228fec2-Abstract.html\">Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., &amp; Joulin, A. (2020). Unsupervised learning of visual features by contrasting cluster assignments. <em>Advances in Neural Information Processing Systems</em>, <em>33</em>, 9912-9924.</a> <a href=\"#fnref:9\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:10\" class=\"footnote-text\"><span><a href=\"https://proceedings.neurips.cc/paper/2020/hash/f3ada80d5c4ee70142b17b8192b2958e-Abstract.html\">Grill, J. B., Strub, F., Altch, F., Tallec, C., Richemond, P., Buchatskaya, E., ... &amp; Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. <em>Advances in Neural Information Processing Systems</em>, <em>33</em>, 21271-21284.</a> <a href=\"#fnref:10\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:11\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/2010.10241\">Richemond, P. H., Grill, J. B., Altch, F., Tallec, C., Strub, F., Brock, A., ... &amp; Valko, M. (2020). BYOL works even without batch statistics. <em>arXiv preprint arXiv:2010.10241</em>.</a> <a href=\"#fnref:11\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:12\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content/CVPR2021/html/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.html\">Chen, X., &amp; He, K. (2021). Exploring simple siamese representation learning. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (pp. 15750-15758).</a> <a href=\"#fnref:12\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:13\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content/ICCV2021/html/Chen_An_Empirical_Study_of_Training_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html\">Chen, X., Xie, S., &amp; He, K. (2021). An empirical study of training self-supervised vision transformers. In <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em> (pp. 9640-9649).</a> <a href=\"#fnref:13\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:14\" class=\"footnote-text\"><span><a href=\"http://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html\">Caron, M., Touvron, H., Misra, I., Jgou, H., Mairal, J., Bojanowski, P., &amp; Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em> (pp. 9650-9660).</a> <a href=\"#fnref:14\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:15\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/2010.11929\">Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. <em>arXiv preprint arXiv:2010.11929</em>.</a> <a href=\"#fnref:15\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:16\" class=\"footnote-text\"><span><a href=\"http://proceedings.mlr.press/v139/radford21a\">Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... &amp; Sutskever, I. (2021, July). Learning transferable visual models from natural language supervision. In <em>International Conference on Machine Learning</em> (pp. 8748-8763). PMLR</a> <a href=\"#fnref:16\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:17\" class=\"footnote-text\"><span><a href=\"https://arxiv.org/abs/2010.11929\">Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. <em>arXiv preprint arXiv:2010.11929</em>.</a> <a href=\"#fnref:17\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n<li>\n<span id=\"fn:18\" class=\"footnote-text\"><span><a href=\"https://openreview.net/forum?id=ROteIE-4A6W\">You, H., Zhou, L., Xiao, B., Codella, N. C., Cheng, Y., Xu, R., ... &amp; Yuan, L. (2021). MA-CLIP: Towards Modality-Agnostic Contrastive Language-Image Pre-training.</a> <a href=\"#fnref:18\" rev=\"footnote\" class=\"footnote-backref\"> </a></span></span>\n</li>\n</ol>\n</div>\n</section>"},{"title":"Transformer","author":"Ryan LI","toc":true,"declare":true,"date":"2022-04-12T15:31:21.000Z","index_img":"/index/paper-reading-transformer.png","_content":"\n> The transformer is the most important achievement in the last 5 years. It presents the fourth class of deep learning models besides MLP, CNN and RNN. And had a huge impact on the entire deep learning field, be it NLP or CV. Even the way the paper and network are named leads a trend.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\nPaper link: [Attention is all you need](https://proceedings.neurips.cc/paper/7181-attention-is-all-you-need) \n\nUseful link: https://www.bilibili.com/video/BV1pu411o7BE\n\n## Notes by sections\n\n### 0. Abstract \n\nAccording to the abstract, this work is first presented in the small field of machine translation, but because of the strong ability of generalisation. The transformer architecture has been extended in other fields such as CV and video.\n\n### 6. Conclusion\n\nIn the last part of the conclusion section, the future of transformer is partly predicted by the authors, though most of these future work is done by other researchers.\n\n### 1. Introduction\n\nFirstly, traditional RNN, or GRU has been introduced. Then after a brief description of the sequential nature of RNN based models, the main problems of them are presented. That is, poor ability of parallelising, and poor long-range dependencies.\n\nLater after the introduction of the attention framework and how to combine attention into RNN, transformer is presented.\n\n### 2. Background\n\nFirst, with the goal of gaining the ability to parallelise, the authors look back on using CNN for sequential data. With CNN, parallelising ability is in its nature and with multiple channels, multiple features can be learned through training. Likewise, the transformer is also parallelisable and Multi-Head Attention is designed with the ability to learn multiple features. But additionally the transformer is easier to learn dependencies between distant positions. \n\nAfterwards, related work on self-attention and memory network is mentioned. And both the connections and distinctions with transformer are elaborated.\n\n### 3. Model Architecture\n\nAfter introducing the basic idea of the encoder-decoder architecture, the key transformer architecture diagram is given. And each part of the model is briefly described. (The diagram in this blog below is not the original, but a combination of 3 diagrams in the paper.)\n\n<img src=\"transformer.png\" alt=\"transformer figure 1\" style=\"zoom:50%;\" />\n\n#### 3.1 encoder decoder stacks\n\n**Encoder:**\n\nIn addition to briefly describing the encoder architecture, the authors mention that in order to avoid the projection step on the residual connection layers, the same input and output dimension is chosen in each sublayer, which is different from what CNN normally does. And this simple design yields the super parameters of the encoder to 2: Nx - the number of the \"encoder block\" and d_model - the feature dimension of the output layers. And this design makes the follow-up work such as bert, GPT-3 simple as well.\n\nHere is one thing that has been ignored: the definition of layer norm. \n\n> Unlike [batch normalization](https://paperswithcode.com/method/batch-normalization), **Layer Normalization** directly estimates the normalization statistics from the summed inputs to the neurons within a hidden layer so the normalization does not introduce any new dependencies between training cases. \n\nMore is on https://paperswithcode.com/method/layer-normalization\n\n**Decoder:**\n\nBecause in the prediction mode, the decoder is self-regressing, meaning that when predict y_t, only x_0 to x_t are available. However, the self-attention layer is able to attend to all the data i.e. x_0 - x_n. To prevent this, a masked multi-head attention layer is introduced so that when predict y_t, x_t+1 - x_n are masked.\n\n#### 3.2 Attention\n\nSimilarly, after running over the definition of attention mechanism, the 2 modifications: scaled dot-product attention and \n\nMulti-head attention are described.\n\nAs we all known, there are two methods (attention scoring functions) of calculating the similarity of query and key(attention weights over the value). One is additive attention. It is complex but allows different length of key (dk) and query (qk). And Additive attention layer includes learnable parameters that can be tuned during training. Another one is dot-product attention, it is simply dot product of the transverse query and key matrix. It requires same length of query and key and no learnable parameters are introduced. \n\n**scaled dot-product attention**\n\nIt pretty much is the dot-product attention multiply with a scaling factor of 1/dk. And it is because for large dk, the deviation of the dot-product results might get too large, and the according gradient can get extremely small and hard to train.\n\nBut look the figure 2 of the paper, an optional mask node is shown in the computation graph. And the algorithm of mask is not described in detail. Basically when calculating q_t, in the mask node, the attention scores a_t+1 - a_t are substituted to a huge negative so that after softmax, the attention weight is 0 on values v_t+1 to v_n. And it is corresponding to the how the decoder works in the prediction mode.\n\n**multi-head attention**\n\nHow mutli-head works is introducing clearly in the paper:\n\n> linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional output values. These are concatenated and once again projected, resulting in the final values\n\nThe question is why doing that. First, no learnable parameters in the dot-product attention, and second, to mimic the CNN extracting the features from different perspectives.\n\n**Applications of Attention in our Model**\n\nIt is well shown on the whole architecture figure. In the figure it consists of 2 self-attention block and 1 attention block, where key-value is from the encoder and query is from the decoder.\n\n#### 3.3 Position-wise feed-forward networks\n\nIt is a simply an MLP with one hidden layer. And the hidden size is 4 times of the input and output size.\n\n#### 3.4 Embedding and softmax\n\nOne point is they multiply the weights byd_model. And first same reason with before, and second, with scaled weights, the scale matches the scale of positional encoding described below.\n\n#### 3.5 Positional Encoding\n\nDifferent with RNN, transformer architecture reads no sequence information. And the authors add the positional information in the input data.\n\n### 4 Why Self-Attention\n\nBasically it explains the table 1 below:\n\n<img src=\"transformer table1.png\" alt=\"transformer figure 1\" style=\"zoom:30%;\" />\n\nIt might be the case but it's not been accepted by some researchers. And the restricted self-attention is rarely used. The table shows that if n and d are the same, self-attention, RNN, and CNN possess the same complexity per layer, but self-attention outperforms them on the sequential operations and the max path length. But actually, a huge mount of layers and parameters  and data are required for a self-attention model achieving a similar result as RNN and CNN. And nowadays all models based on the transformer are very expensive. \n\n### 6 Results\n\n#### 6.2 Model Variations\n\n<img src=\"transformer table 3.png\" alt=\"transformer table 3\" style=\"zoom:30%;\" />\n\nFrom Table 3, we can see the hyper parameters are not so much, and this simple design benefits the follow-ups. For example Bert and GPT.\n\n## Reviews\n\nWriting: It is concise and neat. But if the possible, it's better to describe why of doing it, and show more thoughts on the model to make the paper \"deeper\". \n\nModel: Transformer change the NLP filed just like how CNN change the CV filed. Through after transformer based model such as BERT, it is possible to pretrain a huge model to rise all the NLP performance. Besides, in other fields such as CV and audio, transformer becomes a great rising point. And the fact that transformer may suitable for all the deep learning tasks gives a new thought of muti-model learning. Maybe a general model able to extracting video, pictures, audio into a same semetic space is coming soon.\n\nYet, despite the great experiment performance, we still can't fully understand why transformer works. For example, \n\nattention is not all one need, because the residual connection and MLP are all critical. We still don't know why.\n\nWhy without explicitly model the sequence or the space, transformer outperform RNN and CNN. One explanation is that it is because transformer's inductive bias is more relaxed than either recurrent or convolutional architectures. And that is why huge amount of data are needed for transformer to achieve a good result.\n","source":"_posts/paper-reading-transformer.md","raw":"---\ntitle: 'Transformer'\nauthor: Ryan LI\ntoc: true\ndeclare: true\ndate: 2022-04-12 23:31:21\nindex_img: /index/paper-reading-transformer.png\ntags:\n  - paper reading\n  - deep learning\n---\n\n> The transformer is the most important achievement in the last 5 years. It presents the fourth class of deep learning models besides MLP, CNN and RNN. And had a huge impact on the entire deep learning field, be it NLP or CV. Even the way the paper and network are named leads a trend.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\nPaper link: [Attention is all you need](https://proceedings.neurips.cc/paper/7181-attention-is-all-you-need) \n\nUseful link: https://www.bilibili.com/video/BV1pu411o7BE\n\n## Notes by sections\n\n### 0. Abstract \n\nAccording to the abstract, this work is first presented in the small field of machine translation, but because of the strong ability of generalisation. The transformer architecture has been extended in other fields such as CV and video.\n\n### 6. Conclusion\n\nIn the last part of the conclusion section, the future of transformer is partly predicted by the authors, though most of these future work is done by other researchers.\n\n### 1. Introduction\n\nFirstly, traditional RNN, or GRU has been introduced. Then after a brief description of the sequential nature of RNN based models, the main problems of them are presented. That is, poor ability of parallelising, and poor long-range dependencies.\n\nLater after the introduction of the attention framework and how to combine attention into RNN, transformer is presented.\n\n### 2. Background\n\nFirst, with the goal of gaining the ability to parallelise, the authors look back on using CNN for sequential data. With CNN, parallelising ability is in its nature and with multiple channels, multiple features can be learned through training. Likewise, the transformer is also parallelisable and Multi-Head Attention is designed with the ability to learn multiple features. But additionally the transformer is easier to learn dependencies between distant positions. \n\nAfterwards, related work on self-attention and memory network is mentioned. And both the connections and distinctions with transformer are elaborated.\n\n### 3. Model Architecture\n\nAfter introducing the basic idea of the encoder-decoder architecture, the key transformer architecture diagram is given. And each part of the model is briefly described. (The diagram in this blog below is not the original, but a combination of 3 diagrams in the paper.)\n\n<img src=\"transformer.png\" alt=\"transformer figure 1\" style=\"zoom:50%;\" />\n\n#### 3.1 encoder decoder stacks\n\n**Encoder:**\n\nIn addition to briefly describing the encoder architecture, the authors mention that in order to avoid the projection step on the residual connection layers, the same input and output dimension is chosen in each sublayer, which is different from what CNN normally does. And this simple design yields the super parameters of the encoder to 2: Nx - the number of the \"encoder block\" and d_model - the feature dimension of the output layers. And this design makes the follow-up work such as bert, GPT-3 simple as well.\n\nHere is one thing that has been ignored: the definition of layer norm. \n\n> Unlike [batch normalization](https://paperswithcode.com/method/batch-normalization), **Layer Normalization** directly estimates the normalization statistics from the summed inputs to the neurons within a hidden layer so the normalization does not introduce any new dependencies between training cases. \n\nMore is on https://paperswithcode.com/method/layer-normalization\n\n**Decoder:**\n\nBecause in the prediction mode, the decoder is self-regressing, meaning that when predict y_t, only x_0 to x_t are available. However, the self-attention layer is able to attend to all the data i.e. x_0 - x_n. To prevent this, a masked multi-head attention layer is introduced so that when predict y_t, x_t+1 - x_n are masked.\n\n#### 3.2 Attention\n\nSimilarly, after running over the definition of attention mechanism, the 2 modifications: scaled dot-product attention and \n\nMulti-head attention are described.\n\nAs we all known, there are two methods (attention scoring functions) of calculating the similarity of query and key(attention weights over the value). One is additive attention. It is complex but allows different length of key (dk) and query (qk). And Additive attention layer includes learnable parameters that can be tuned during training. Another one is dot-product attention, it is simply dot product of the transverse query and key matrix. It requires same length of query and key and no learnable parameters are introduced. \n\n**scaled dot-product attention**\n\nIt pretty much is the dot-product attention multiply with a scaling factor of 1/dk. And it is because for large dk, the deviation of the dot-product results might get too large, and the according gradient can get extremely small and hard to train.\n\nBut look the figure 2 of the paper, an optional mask node is shown in the computation graph. And the algorithm of mask is not described in detail. Basically when calculating q_t, in the mask node, the attention scores a_t+1 - a_t are substituted to a huge negative so that after softmax, the attention weight is 0 on values v_t+1 to v_n. And it is corresponding to the how the decoder works in the prediction mode.\n\n**multi-head attention**\n\nHow mutli-head works is introducing clearly in the paper:\n\n> linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional output values. These are concatenated and once again projected, resulting in the final values\n\nThe question is why doing that. First, no learnable parameters in the dot-product attention, and second, to mimic the CNN extracting the features from different perspectives.\n\n**Applications of Attention in our Model**\n\nIt is well shown on the whole architecture figure. In the figure it consists of 2 self-attention block and 1 attention block, where key-value is from the encoder and query is from the decoder.\n\n#### 3.3 Position-wise feed-forward networks\n\nIt is a simply an MLP with one hidden layer. And the hidden size is 4 times of the input and output size.\n\n#### 3.4 Embedding and softmax\n\nOne point is they multiply the weights byd_model. And first same reason with before, and second, with scaled weights, the scale matches the scale of positional encoding described below.\n\n#### 3.5 Positional Encoding\n\nDifferent with RNN, transformer architecture reads no sequence information. And the authors add the positional information in the input data.\n\n### 4 Why Self-Attention\n\nBasically it explains the table 1 below:\n\n<img src=\"transformer table1.png\" alt=\"transformer figure 1\" style=\"zoom:30%;\" />\n\nIt might be the case but it's not been accepted by some researchers. And the restricted self-attention is rarely used. The table shows that if n and d are the same, self-attention, RNN, and CNN possess the same complexity per layer, but self-attention outperforms them on the sequential operations and the max path length. But actually, a huge mount of layers and parameters  and data are required for a self-attention model achieving a similar result as RNN and CNN. And nowadays all models based on the transformer are very expensive. \n\n### 6 Results\n\n#### 6.2 Model Variations\n\n<img src=\"transformer table 3.png\" alt=\"transformer table 3\" style=\"zoom:30%;\" />\n\nFrom Table 3, we can see the hyper parameters are not so much, and this simple design benefits the follow-ups. For example Bert and GPT.\n\n## Reviews\n\nWriting: It is concise and neat. But if the possible, it's better to describe why of doing it, and show more thoughts on the model to make the paper \"deeper\". \n\nModel: Transformer change the NLP filed just like how CNN change the CV filed. Through after transformer based model such as BERT, it is possible to pretrain a huge model to rise all the NLP performance. Besides, in other fields such as CV and audio, transformer becomes a great rising point. And the fact that transformer may suitable for all the deep learning tasks gives a new thought of muti-model learning. Maybe a general model able to extracting video, pictures, audio into a same semetic space is coming soon.\n\nYet, despite the great experiment performance, we still can't fully understand why transformer works. For example, \n\nattention is not all one need, because the residual connection and MLP are all critical. We still don't know why.\n\nWhy without explicitly model the sequence or the space, transformer outperform RNN and CNN. One explanation is that it is because transformer's inductive bias is more relaxed than either recurrent or convolutional architectures. And that is why huge amount of data are needed for transformer to achieve a good result.\n","slug":"paper-reading-transformer","published":1,"updated":"2022-06-09T10:25:21.668Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz2b0025l8ybbqwmgvjj","content":"<blockquote>\n<p>The transformer is the most important achievement in the last 5 years. It presents the fourth class of deep learning models besides MLP, CNN and RNN. And had a huge impact on the entire deep learning field, be it NLP or CV. Even the way the paper and network are named leads a trend.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>\n<span id=\"more\"></span>\n<p>Paper link: <a href=\"https://proceedings.neurips.cc/paper/7181-attention-is-all-you-need\">Attention is all you need</a></p>\n<p>Useful link: https://www.bilibili.com/video/BV1pu411o7BE</p>\n<h2 id=\"notes-by-sections\">Notes by sections</h2>\n<h3 id=\"abstract\">0. Abstract</h3>\n<p>According to the abstract, this work is first presented in the small field of machine translation, but because of the strong ability of generalisation. The transformer architecture has been extended in other fields such as CV and video.</p>\n<h3 id=\"conclusion\">6. Conclusion</h3>\n<p>In the last part of the conclusion section, the future of transformer is partly predicted by the authors, though most of these future work is done by other researchers.</p>\n<h3 id=\"introduction\">1. Introduction</h3>\n<p>Firstly, traditional RNN, or GRU has been introduced. Then after a brief description of the sequential nature of RNN based models, the main problems of them are presented. That is, poor ability of parallelising, and poor long-range dependencies.</p>\n<p>Later after the introduction of the attention framework and how to combine attention into RNN, transformer is presented.</p>\n<h3 id=\"background\">2. Background</h3>\n<p>First, with the goal of gaining the ability to parallelise, the authors look back on using CNN for sequential data. With CNN, parallelising ability is in its nature and with multiple channels, multiple features can be learned through training. Likewise, the transformer is also parallelisable and Multi-Head Attention is designed with the ability to learn multiple features. But additionally the transformer is easier to learn dependencies between distant positions.</p>\n<p>Afterwards, related work on self-attention and memory network is mentioned. And both the connections and distinctions with transformer are elaborated.</p>\n<h3 id=\"model-architecture\">3. Model Architecture</h3>\n<p>After introducing the basic idea of the encoder-decoder architecture, the key transformer architecture diagram is given. And each part of the model is briefly described. (The diagram in this blog below is not the original, but a combination of 3 diagrams in the paper.)</p>\n<p><img src=\"transformer.png\" srcset=\"/img/loading.gif\" lazyload alt=\"transformer figure 1\" style=\"zoom:50%;\" /></p>\n<h4 id=\"encoder-decoder-stacks\">3.1 encoder decoder stacks</h4>\n<p><strong>Encoder:</strong></p>\n<p>In addition to briefly describing the encoder architecture, the authors mention that in order to avoid the projection step on the residual connection layers, the same input and output dimension is chosen in each sublayer, which is different from what CNN normally does. And this simple design yields the super parameters of the encoder to 2: Nx - the number of the \"encoder block\" and d_model - the feature dimension of the output layers. And this design makes the follow-up work such as bert, GPT-3 simple as well.</p>\n<p>Here is one thing that has been ignored: the definition of layer norm.</p>\n<blockquote>\n<p>Unlike <a href=\"https://paperswithcode.com/method/batch-normalization\">batch normalization</a>, <strong>Layer Normalization</strong> directly estimates the normalization statistics from the summed inputs to the neurons within a hidden layer so the normalization does not introduce any new dependencies between training cases.</p>\n</blockquote>\n<p>More is on https://paperswithcode.com/method/layer-normalization</p>\n<p><strong>Decoder:</strong></p>\n<p>Because in the prediction mode, the decoder is self-regressing, meaning that when predict y_t, only x_0 to x_t are available. However, the self-attention layer is able to attend to all the data i.e. x_0 - x_n. To prevent this, a masked multi-head attention layer is introduced so that when predict y_t, x_t+1 - x_n are masked.</p>\n<h4 id=\"attention\">3.2 Attention</h4>\n<p>Similarly, after running over the definition of attention mechanism, the 2 modifications: scaled dot-product attention and</p>\n<p>Multi-head attention are described.</p>\n<p>As we all known, there are two methods (attention scoring functions) of calculating the similarity of query and key(attention weights over the value). One is additive attention. It is complex but allows different length of key (dk) and query (qk). And Additive attention layer includes learnable parameters that can be tuned during training. Another one is dot-product attention, it is simply dot product of the transverse query and key matrix. It requires same length of query and key and no learnable parameters are introduced.</p>\n<p><strong>scaled dot-product attention</strong></p>\n<p>It pretty much is the dot-product attention multiply with a scaling factor of 1/dk. And it is because for large dk, the deviation of the dot-product results might get too large, and the according gradient can get extremely small and hard to train.</p>\n<p>But look the figure 2 of the paper, an optional mask node is shown in the computation graph. And the algorithm of mask is not described in detail. Basically when calculating q_t, in the mask node, the attention scores a_t+1 - a_t are substituted to a huge negative so that after softmax, the attention weight is 0 on values v_t+1 to v_n. And it is corresponding to the how the decoder works in the prediction mode.</p>\n<p><strong>multi-head attention</strong></p>\n<p>How mutli-head works is introducing clearly in the paper:</p>\n<blockquote>\n<p>linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional output values. These are concatenated and once again projected, resulting in the final values</p>\n</blockquote>\n<p>The question is why doing that. First, no learnable parameters in the dot-product attention, and second, to mimic the CNN extracting the features from different perspectives.</p>\n<p><strong>Applications of Attention in our Model</strong></p>\n<p>It is well shown on the whole architecture figure. In the figure it consists of 2 self-attention block and 1 attention block, where key-value is from the encoder and query is from the decoder.</p>\n<h4 id=\"position-wise-feed-forward-networks\">3.3 Position-wise feed-forward networks</h4>\n<p>It is a simply an MLP with one hidden layer. And the hidden size is 4 times of the input and output size.</p>\n<h4 id=\"embedding-and-softmax\">3.4 Embedding and softmax</h4>\n<p>One point is they multiply the weights byd_model. And first same reason with before, and second, with scaled weights, the scale matches the scale of positional encoding described below.</p>\n<h4 id=\"positional-encoding\">3.5 Positional Encoding</h4>\n<p>Different with RNN, transformer architecture reads no sequence information. And the authors add the positional information in the input data.</p>\n<h3 id=\"why-self-attention\">4 Why Self-Attention</h3>\n<p>Basically it explains the table 1 below:</p>\n<p><img src=\"transformer table1.png\" srcset=\"/img/loading.gif\" lazyload alt=\"transformer figure 1\" style=\"zoom:30%;\" /></p>\n<p>It might be the case but it's not been accepted by some researchers. And the restricted self-attention is rarely used. The table shows that if n and d are the same, self-attention, RNN, and CNN possess the same complexity per layer, but self-attention outperforms them on the sequential operations and the max path length. But actually, a huge mount of layers and parameters and data are required for a self-attention model achieving a similar result as RNN and CNN. And nowadays all models based on the transformer are very expensive.</p>\n<h3 id=\"results\">6 Results</h3>\n<h4 id=\"model-variations\">6.2 Model Variations</h4>\n<p><img src=\"transformer table 3.png\" srcset=\"/img/loading.gif\" lazyload alt=\"transformer table 3\" style=\"zoom:30%;\" /></p>\n<p>From Table 3, we can see the hyper parameters are not so much, and this simple design benefits the follow-ups. For example Bert and GPT.</p>\n<h2 id=\"reviews\">Reviews</h2>\n<p>Writing: It is concise and neat. But if the possible, it's better to describe why of doing it, and show more thoughts on the model to make the paper \"deeper\".</p>\n<p>Model: Transformer change the NLP filed just like how CNN change the CV filed. Through after transformer based model such as BERT, it is possible to pretrain a huge model to rise all the NLP performance. Besides, in other fields such as CV and audio, transformer becomes a great rising point. And the fact that transformer may suitable for all the deep learning tasks gives a new thought of muti-model learning. Maybe a general model able to extracting video, pictures, audio into a same semetic space is coming soon.</p>\n<p>Yet, despite the great experiment performance, we still can't fully understand why transformer works. For example,</p>\n<p>attention is not all one need, because the residual connection and MLP are all critical. We still don't know why.</p>\n<p>Why without explicitly model the sequence or the space, transformer outperform RNN and CNN. One explanation is that it is because transformer's inductive bias is more relaxed than either recurrent or convolutional architectures. And that is why huge amount of data are needed for transformer to achieve a good result.</p>\n","site":{"data":{}},"wordcount":6974,"excerpt":"<blockquote>\n<p>The transformer is the most important achievement in the last 5 years. It presents the fourth class of deep learning models besides MLP, CNN and RNN. And had a huge impact on the entire deep learning field, be it NLP or CV. Even the way the paper and network are named leads a trend.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>","more":"<p>Paper link: <a href=\"https://proceedings.neurips.cc/paper/7181-attention-is-all-you-need\">Attention is all you need</a></p>\n<p>Useful link: https://www.bilibili.com/video/BV1pu411o7BE</p>\n<h2 id=\"notes-by-sections\">Notes by sections</h2>\n<h3 id=\"abstract\">0. Abstract</h3>\n<p>According to the abstract, this work is first presented in the small field of machine translation, but because of the strong ability of generalisation. The transformer architecture has been extended in other fields such as CV and video.</p>\n<h3 id=\"conclusion\">6. Conclusion</h3>\n<p>In the last part of the conclusion section, the future of transformer is partly predicted by the authors, though most of these future work is done by other researchers.</p>\n<h3 id=\"introduction\">1. Introduction</h3>\n<p>Firstly, traditional RNN, or GRU has been introduced. Then after a brief description of the sequential nature of RNN based models, the main problems of them are presented. That is, poor ability of parallelising, and poor long-range dependencies.</p>\n<p>Later after the introduction of the attention framework and how to combine attention into RNN, transformer is presented.</p>\n<h3 id=\"background\">2. Background</h3>\n<p>First, with the goal of gaining the ability to parallelise, the authors look back on using CNN for sequential data. With CNN, parallelising ability is in its nature and with multiple channels, multiple features can be learned through training. Likewise, the transformer is also parallelisable and Multi-Head Attention is designed with the ability to learn multiple features. But additionally the transformer is easier to learn dependencies between distant positions.</p>\n<p>Afterwards, related work on self-attention and memory network is mentioned. And both the connections and distinctions with transformer are elaborated.</p>\n<h3 id=\"model-architecture\">3. Model Architecture</h3>\n<p>After introducing the basic idea of the encoder-decoder architecture, the key transformer architecture diagram is given. And each part of the model is briefly described. (The diagram in this blog below is not the original, but a combination of 3 diagrams in the paper.)</p>\n<p><img src=\"transformer.png\" alt=\"transformer figure 1\" style=\"zoom:50%;\" /></p>\n<h4 id=\"encoder-decoder-stacks\">3.1 encoder decoder stacks</h4>\n<p><strong>Encoder:</strong></p>\n<p>In addition to briefly describing the encoder architecture, the authors mention that in order to avoid the projection step on the residual connection layers, the same input and output dimension is chosen in each sublayer, which is different from what CNN normally does. And this simple design yields the super parameters of the encoder to 2: Nx - the number of the \"encoder block\" and d_model - the feature dimension of the output layers. And this design makes the follow-up work such as bert, GPT-3 simple as well.</p>\n<p>Here is one thing that has been ignored: the definition of layer norm.</p>\n<blockquote>\n<p>Unlike <a href=\"https://paperswithcode.com/method/batch-normalization\">batch normalization</a>, <strong>Layer Normalization</strong> directly estimates the normalization statistics from the summed inputs to the neurons within a hidden layer so the normalization does not introduce any new dependencies between training cases.</p>\n</blockquote>\n<p>More is on https://paperswithcode.com/method/layer-normalization</p>\n<p><strong>Decoder:</strong></p>\n<p>Because in the prediction mode, the decoder is self-regressing, meaning that when predict y_t, only x_0 to x_t are available. However, the self-attention layer is able to attend to all the data i.e. x_0 - x_n. To prevent this, a masked multi-head attention layer is introduced so that when predict y_t, x_t+1 - x_n are masked.</p>\n<h4 id=\"attention\">3.2 Attention</h4>\n<p>Similarly, after running over the definition of attention mechanism, the 2 modifications: scaled dot-product attention and</p>\n<p>Multi-head attention are described.</p>\n<p>As we all known, there are two methods (attention scoring functions) of calculating the similarity of query and key(attention weights over the value). One is additive attention. It is complex but allows different length of key (dk) and query (qk). And Additive attention layer includes learnable parameters that can be tuned during training. Another one is dot-product attention, it is simply dot product of the transverse query and key matrix. It requires same length of query and key and no learnable parameters are introduced.</p>\n<p><strong>scaled dot-product attention</strong></p>\n<p>It pretty much is the dot-product attention multiply with a scaling factor of 1/dk. And it is because for large dk, the deviation of the dot-product results might get too large, and the according gradient can get extremely small and hard to train.</p>\n<p>But look the figure 2 of the paper, an optional mask node is shown in the computation graph. And the algorithm of mask is not described in detail. Basically when calculating q_t, in the mask node, the attention scores a_t+1 - a_t are substituted to a huge negative so that after softmax, the attention weight is 0 on values v_t+1 to v_n. And it is corresponding to the how the decoder works in the prediction mode.</p>\n<p><strong>multi-head attention</strong></p>\n<p>How mutli-head works is introducing clearly in the paper:</p>\n<blockquote>\n<p>linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional output values. These are concatenated and once again projected, resulting in the final values</p>\n</blockquote>\n<p>The question is why doing that. First, no learnable parameters in the dot-product attention, and second, to mimic the CNN extracting the features from different perspectives.</p>\n<p><strong>Applications of Attention in our Model</strong></p>\n<p>It is well shown on the whole architecture figure. In the figure it consists of 2 self-attention block and 1 attention block, where key-value is from the encoder and query is from the decoder.</p>\n<h4 id=\"position-wise-feed-forward-networks\">3.3 Position-wise feed-forward networks</h4>\n<p>It is a simply an MLP with one hidden layer. And the hidden size is 4 times of the input and output size.</p>\n<h4 id=\"embedding-and-softmax\">3.4 Embedding and softmax</h4>\n<p>One point is they multiply the weights byd_model. And first same reason with before, and second, with scaled weights, the scale matches the scale of positional encoding described below.</p>\n<h4 id=\"positional-encoding\">3.5 Positional Encoding</h4>\n<p>Different with RNN, transformer architecture reads no sequence information. And the authors add the positional information in the input data.</p>\n<h3 id=\"why-self-attention\">4 Why Self-Attention</h3>\n<p>Basically it explains the table 1 below:</p>\n<p><img src=\"transformer table1.png\" alt=\"transformer figure 1\" style=\"zoom:30%;\" /></p>\n<p>It might be the case but it's not been accepted by some researchers. And the restricted self-attention is rarely used. The table shows that if n and d are the same, self-attention, RNN, and CNN possess the same complexity per layer, but self-attention outperforms them on the sequential operations and the max path length. But actually, a huge mount of layers and parameters and data are required for a self-attention model achieving a similar result as RNN and CNN. And nowadays all models based on the transformer are very expensive.</p>\n<h3 id=\"results\">6 Results</h3>\n<h4 id=\"model-variations\">6.2 Model Variations</h4>\n<p><img src=\"transformer table 3.png\" alt=\"transformer table 3\" style=\"zoom:30%;\" /></p>\n<p>From Table 3, we can see the hyper parameters are not so much, and this simple design benefits the follow-ups. For example Bert and GPT.</p>\n<h2 id=\"reviews\">Reviews</h2>\n<p>Writing: It is concise and neat. But if the possible, it's better to describe why of doing it, and show more thoughts on the model to make the paper \"deeper\".</p>\n<p>Model: Transformer change the NLP filed just like how CNN change the CV filed. Through after transformer based model such as BERT, it is possible to pretrain a huge model to rise all the NLP performance. Besides, in other fields such as CV and audio, transformer becomes a great rising point. And the fact that transformer may suitable for all the deep learning tasks gives a new thought of muti-model learning. Maybe a general model able to extracting video, pictures, audio into a same semetic space is coming soon.</p>\n<p>Yet, despite the great experiment performance, we still can't fully understand why transformer works. For example,</p>\n<p>attention is not all one need, because the residual connection and MLP are all critical. We still don't know why.</p>\n<p>Why without explicitly model the sequence or the space, transformer outperform RNN and CNN. One explanation is that it is because transformer's inductive bias is more relaxed than either recurrent or convolutional architectures. And that is why huge amount of data are needed for transformer to achieve a good result.</p>"},{"title":"Bert","author":"Ryan LI","toc":true,"declare":true,"date":"2022-04-15T10:01:32.000Z","index_img":"/index/paper-reading-bert.png","_content":">The BERT is the most important achievement in the NLP field in the last 4 years. It makes the transfer learning of NLP tasks possible and the transformer framework dominant the NLP field.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\nPaper link: [Bert: Pre-training of deep bidirectional transformers for language understanding](https://arxiv.org/abs/1810.04805)\n\nUseful links: https://www.bilibili.com/video/BV1PL411M7eQ\n\n\t\t\t\t\thttps://youtu.be/UYPa347-DdE\n\n\t\t\t\t\t[Deep contextualized word representations - arXiv](https://arxiv.org/abs/1802.05365)\n\n## Notes by sections\n\n### 0. Abstract \n\n*The name of BERT might come from one of its important related work, ELMo. And Elmo and Bert are both characters in a TV show Sesame Street.*\n\nThe abstract focus on the two related work, ELMo and GPT. The bidirectional feature is in contrast to the unidirectional GPT model. And the \"without substantial task specific architecture modifications\" feature compares with the RNN-based ELMo model, whose architecture might get modified when training downstream tasks. Yet the ELMo model is bidirectional and GPT model is easy to use.\n\nWhen claiming a model is great, it is good to provide both the absolute accuracy and the relative accuracy compared with others. Just like this paper does.\n\n### 6. Conclusion \n\nTo summarise, this is a classical **A+B** type of research. The idea of BERT is simple, combine the advantages of the bidirectional network with a rather old RNN base (ELMo), and the unidirectional network with a transformer base (GPT). And in detail, 2 pre-training tasks are designed. \n\nThe main contribution of this network is showing that bidirectional information is important.\n\n### 1. Introduction\n\nFrom the history introduction, it turns out BERT is not the first to apply pre-training on NLP. It's been a while. But BERT makes it popular. \n\n### 2. Related work\n\n**2.3 Transfer Learning from Supervised data**\n\nThis is what the CV area does most often. Yet it is not effective in NLP. It is partly because of the lacking of data. Another reason might be the existing labeled data focus only on language inference and machine translation, which are too different from other NLP tasks. So BERT and GPT use unlabelled data to pre-train and prove that unsupervised pre-train on a massive data is more effective than supervised pre-train on a relatively small data set. And, interestingly, this trend in NLP gradually effects the CV world. Nowadays unsupervised fine-tuning is becoming more and more popular in CV area.\n\n### 3. Bert\n\nIn the first part, the pre-training and fine-tuning framework is briefly covered. A paper should be self-consistent, meaning that if a mechanic is fundamental in your area and essential to your work. It is a good habit to briefly introduce it, even if all the people in the area know it.\n\n**Model Architecture**\n\nAnd the architecture is as simple as just take the encoder part of the transformer model.\n\n> number of layers (i.e., Transformer blocks) as L, the hidden size as H, and the number of self-attention heads as A.\n>\n> BERTBASE(L=12, H=768, A=12, Total Parameters=110M) and BERTLARGE(L=24, H=1024, A=16, Total Parameters=340M).\n\nBecause the hidden size of each multi-head attention sublayer is set as 64. And in transformer tradition, H = A * 64. So the multi-head number A actually depends on the hidden size H. As a result, the way of calculating the number of parameters is shown below.\n\n<img src=\"BERT learnable paramters.png\" alt=\"BERT learnable paramters\" style=\"zoom:48%;\" />\n\n**Input/Output Representations**\n\nWhy Bert need a pair of sentence to handle downstream tasks such as Machine Translation, unlike its predecessor Transformer?\n\nBecause in Transformer, the input is a pair of sequences, taken by encoder and decoder respectively. But Bert is only an encoder. In English-Chinese Translation task for example, for transformer, the encoder take the English version and the decoder take the Chinese version, for Bert, the English version and Chinese version are glued with a special token [sept] then be inputed to the model. \n\nBesides the [sept] token, another embedding is introduced into the embedding layer, the sequence model. Details are shown below.\n\n<img src=\"BERT segment embedding.png\" alt=\"BERT segment embedding\" style=\"zoom:50%;\" />\n\n**3.1 Pre-training BERT**\n\nThe paper provides an example of each task in Appendix section **Masked LM and the Masking Procedure**, just go for it and have a look if don't understand.\n\n> Next Sentence Prediction The next sentence prediction task can be illustrated in the following examples. \n>\n> Input = [CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP] \n>\n> Label = IsNext \n>\n> Input = [CLS] the man [MASK] to the store [SEP] penguin [MASK] are **flight ##less** birds [SEP] \n>\n> Label = NotNext\n\nThe \"flight ##less\" is because of the WordPiece embedding method that Bert uses. \"##\" means this token is split from last token, in this case, flightless is the original token. Because flightless is rarely used, the WordPiece embedding split this word into two.\n\n**3.2 Fine-tuning BERT**\n\nBert's architecture has one advantage over the transformer's, the self-attention allows model look both the two sentences. And the encoder-decoder model can't do that. As a result, the fine-tuning can be a little bit hazy.\n\n### 4 Experiments\n\n**4.2 SQuAD v1.1**\n\n> We fine-tune for 3 epochs with a learning rate of 5e-5 and a batch size of 32.\n\nThis misleads the people for a while. People found when fine-tuning with Bert, the variance of each results are high i.e. the result of fine-tuning is unstable. Then people found it is because 3 epochs are not enough. Besides, the optimiser that the original Bert model used is an incomplete version of Adam which is not stable for small epoch number. And the follow-ups change it into the original Adam.\n\nFrom the processes of the 3 experiments, it can be seen it is easy for BERT to be applied to downstream tasks. Just need to modify the input data in the form of the Bert sequence, and add another output layer. As a result, with BERT, massive number of tasks can be trained under a rather simple architecture.\n\n### 5 Ablation Studies\n\n<img src=\"BERT alibation study 1.png\" alt=\"BERT alibation study 1\" style=\"zoom:30%;\" />\n\nIt is obvious the 4th architecture BiLSTM is from the idea of ELMO. And all the variation lead to a deterioration of the acc, especially in the MRPC task.\n\n> **Microsoft Research Paraphrase Corpus (MRPC) Dataset**\n>\n> Created by Dolan et al. at 2005, the Microsoft Research Paraphrase Corpus (MRPC) Dataset contains pairs of sentences which have been extracted from news sources on the web, along with human annotations indicating whether each pair captures a paraphrase/semantic equivalence relationship., in English language. Containing 5,8 in Text file format.\n\n\n\n<img src=\"model size graph.webp\" alt=\"model size graph\" style=\"zoom:50%;\" />\n\nIn the Effect of model size part, they claim with a large model size, huge improvement can be reached.  And this leads a trend of increasing the model size in NLP, for example, the 100 billon GPT-3, and 500 billion model Megatron-Turing Natural Language Generation (MT-NLG). The boundary of NLP will be push further. \n\n## Reviews\n\nWriting: The biggest sell point in this paper is chosen as the \"bidirectional\". From today's view, the contributions of BERT are so more than this. Besides, when say to choose a feature, it is better to discuss both the pros and the cons of the choice. For example, compared with GPT, the encoder is used instead of the decoder. The pros are the bidirectional feature, but the cons is the resulting difficulty in applying on generative tasks such as the machine translation. \n\nBesides, BERT follows a whole ideal path of solving deep learning problems. That is after pre-training on a deep and huge model on a huge unlabelled dataset, the model can be applied to many small tasks with a few steps of fine tuning.\n","source":"_posts/paper-reading-bert.md","raw":"---\ntitle: 'Bert'\nauthor: Ryan LI\ntoc: true\ndeclare: true\ndate: 2022-04-15 18:01:32\nindex_img: /index/paper-reading-bert.png\ntags:\n  - paper reading\n  - deep learning\n---\n>The BERT is the most important achievement in the NLP field in the last 4 years. It makes the transfer learning of NLP tasks possible and the transformer framework dominant the NLP field.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\nPaper link: [Bert: Pre-training of deep bidirectional transformers for language understanding](https://arxiv.org/abs/1810.04805)\n\nUseful links: https://www.bilibili.com/video/BV1PL411M7eQ\n\n\t\t\t\t\thttps://youtu.be/UYPa347-DdE\n\n\t\t\t\t\t[Deep contextualized word representations - arXiv](https://arxiv.org/abs/1802.05365)\n\n## Notes by sections\n\n### 0. Abstract \n\n*The name of BERT might come from one of its important related work, ELMo. And Elmo and Bert are both characters in a TV show Sesame Street.*\n\nThe abstract focus on the two related work, ELMo and GPT. The bidirectional feature is in contrast to the unidirectional GPT model. And the \"without substantial task specific architecture modifications\" feature compares with the RNN-based ELMo model, whose architecture might get modified when training downstream tasks. Yet the ELMo model is bidirectional and GPT model is easy to use.\n\nWhen claiming a model is great, it is good to provide both the absolute accuracy and the relative accuracy compared with others. Just like this paper does.\n\n### 6. Conclusion \n\nTo summarise, this is a classical **A+B** type of research. The idea of BERT is simple, combine the advantages of the bidirectional network with a rather old RNN base (ELMo), and the unidirectional network with a transformer base (GPT). And in detail, 2 pre-training tasks are designed. \n\nThe main contribution of this network is showing that bidirectional information is important.\n\n### 1. Introduction\n\nFrom the history introduction, it turns out BERT is not the first to apply pre-training on NLP. It's been a while. But BERT makes it popular. \n\n### 2. Related work\n\n**2.3 Transfer Learning from Supervised data**\n\nThis is what the CV area does most often. Yet it is not effective in NLP. It is partly because of the lacking of data. Another reason might be the existing labeled data focus only on language inference and machine translation, which are too different from other NLP tasks. So BERT and GPT use unlabelled data to pre-train and prove that unsupervised pre-train on a massive data is more effective than supervised pre-train on a relatively small data set. And, interestingly, this trend in NLP gradually effects the CV world. Nowadays unsupervised fine-tuning is becoming more and more popular in CV area.\n\n### 3. Bert\n\nIn the first part, the pre-training and fine-tuning framework is briefly covered. A paper should be self-consistent, meaning that if a mechanic is fundamental in your area and essential to your work. It is a good habit to briefly introduce it, even if all the people in the area know it.\n\n**Model Architecture**\n\nAnd the architecture is as simple as just take the encoder part of the transformer model.\n\n> number of layers (i.e., Transformer blocks) as L, the hidden size as H, and the number of self-attention heads as A.\n>\n> BERTBASE(L=12, H=768, A=12, Total Parameters=110M) and BERTLARGE(L=24, H=1024, A=16, Total Parameters=340M).\n\nBecause the hidden size of each multi-head attention sublayer is set as 64. And in transformer tradition, H = A * 64. So the multi-head number A actually depends on the hidden size H. As a result, the way of calculating the number of parameters is shown below.\n\n<img src=\"BERT learnable paramters.png\" alt=\"BERT learnable paramters\" style=\"zoom:48%;\" />\n\n**Input/Output Representations**\n\nWhy Bert need a pair of sentence to handle downstream tasks such as Machine Translation, unlike its predecessor Transformer?\n\nBecause in Transformer, the input is a pair of sequences, taken by encoder and decoder respectively. But Bert is only an encoder. In English-Chinese Translation task for example, for transformer, the encoder take the English version and the decoder take the Chinese version, for Bert, the English version and Chinese version are glued with a special token [sept] then be inputed to the model. \n\nBesides the [sept] token, another embedding is introduced into the embedding layer, the sequence model. Details are shown below.\n\n<img src=\"BERT segment embedding.png\" alt=\"BERT segment embedding\" style=\"zoom:50%;\" />\n\n**3.1 Pre-training BERT**\n\nThe paper provides an example of each task in Appendix section **Masked LM and the Masking Procedure**, just go for it and have a look if don't understand.\n\n> Next Sentence Prediction The next sentence prediction task can be illustrated in the following examples. \n>\n> Input = [CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP] \n>\n> Label = IsNext \n>\n> Input = [CLS] the man [MASK] to the store [SEP] penguin [MASK] are **flight ##less** birds [SEP] \n>\n> Label = NotNext\n\nThe \"flight ##less\" is because of the WordPiece embedding method that Bert uses. \"##\" means this token is split from last token, in this case, flightless is the original token. Because flightless is rarely used, the WordPiece embedding split this word into two.\n\n**3.2 Fine-tuning BERT**\n\nBert's architecture has one advantage over the transformer's, the self-attention allows model look both the two sentences. And the encoder-decoder model can't do that. As a result, the fine-tuning can be a little bit hazy.\n\n### 4 Experiments\n\n**4.2 SQuAD v1.1**\n\n> We fine-tune for 3 epochs with a learning rate of 5e-5 and a batch size of 32.\n\nThis misleads the people for a while. People found when fine-tuning with Bert, the variance of each results are high i.e. the result of fine-tuning is unstable. Then people found it is because 3 epochs are not enough. Besides, the optimiser that the original Bert model used is an incomplete version of Adam which is not stable for small epoch number. And the follow-ups change it into the original Adam.\n\nFrom the processes of the 3 experiments, it can be seen it is easy for BERT to be applied to downstream tasks. Just need to modify the input data in the form of the Bert sequence, and add another output layer. As a result, with BERT, massive number of tasks can be trained under a rather simple architecture.\n\n### 5 Ablation Studies\n\n<img src=\"BERT alibation study 1.png\" alt=\"BERT alibation study 1\" style=\"zoom:30%;\" />\n\nIt is obvious the 4th architecture BiLSTM is from the idea of ELMO. And all the variation lead to a deterioration of the acc, especially in the MRPC task.\n\n> **Microsoft Research Paraphrase Corpus (MRPC) Dataset**\n>\n> Created by Dolan et al. at 2005, the Microsoft Research Paraphrase Corpus (MRPC) Dataset contains pairs of sentences which have been extracted from news sources on the web, along with human annotations indicating whether each pair captures a paraphrase/semantic equivalence relationship., in English language. Containing 5,8 in Text file format.\n\n\n\n<img src=\"model size graph.webp\" alt=\"model size graph\" style=\"zoom:50%;\" />\n\nIn the Effect of model size part, they claim with a large model size, huge improvement can be reached.  And this leads a trend of increasing the model size in NLP, for example, the 100 billon GPT-3, and 500 billion model Megatron-Turing Natural Language Generation (MT-NLG). The boundary of NLP will be push further. \n\n## Reviews\n\nWriting: The biggest sell point in this paper is chosen as the \"bidirectional\". From today's view, the contributions of BERT are so more than this. Besides, when say to choose a feature, it is better to discuss both the pros and the cons of the choice. For example, compared with GPT, the encoder is used instead of the decoder. The pros are the bidirectional feature, but the cons is the resulting difficulty in applying on generative tasks such as the machine translation. \n\nBesides, BERT follows a whole ideal path of solving deep learning problems. That is after pre-training on a deep and huge model on a huge unlabelled dataset, the model can be applied to many small tasks with a few steps of fine tuning.\n","slug":"paper-reading-bert","published":1,"updated":"2022-06-09T10:24:26.184Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz2b0027l8yb8rbu7bkx","content":"<blockquote>\n<p>The BERT is the most important achievement in the NLP field in the last 4 years. It makes the transfer learning of NLP tasks possible and the transformer framework dominant the NLP field.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>\n<span id=\"more\"></span>\n<p>Paper link: <a href=\"https://arxiv.org/abs/1810.04805\">Bert: Pre-training of deep bidirectional transformers for language understanding</a></p>\n<p>Useful links: https://www.bilibili.com/video/BV1PL411M7eQ</p>\n<p> https://youtu.be/UYPa347-DdE</p>\n<p> <a href=\"https://arxiv.org/abs/1802.05365\">Deep contextualized word representations - arXiv</a></p>\n<h2 id=\"notes-by-sections\">Notes by sections</h2>\n<h3 id=\"abstract\">0. Abstract</h3>\n<p><em>The name of BERT might come from one of its important related work, ELMo. And Elmo and Bert are both characters in a TV show Sesame Street.</em></p>\n<p>The abstract focus on the two related work, ELMo and GPT. The bidirectional feature is in contrast to the unidirectional GPT model. And the \"without substantial task specific architecture modifications\" feature compares with the RNN-based ELMo model, whose architecture might get modified when training downstream tasks. Yet the ELMo model is bidirectional and GPT model is easy to use.</p>\n<p>When claiming a model is great, it is good to provide both the absolute accuracy and the relative accuracy compared with others. Just like this paper does.</p>\n<h3 id=\"conclusion\">6. Conclusion</h3>\n<p>To summarise, this is a classical <strong>A+B</strong> type of research. The idea of BERT is simple, combine the advantages of the bidirectional network with a rather old RNN base (ELMo), and the unidirectional network with a transformer base (GPT). And in detail, 2 pre-training tasks are designed.</p>\n<p>The main contribution of this network is showing that bidirectional information is important.</p>\n<h3 id=\"introduction\">1. Introduction</h3>\n<p>From the history introduction, it turns out BERT is not the first to apply pre-training on NLP. It's been a while. But BERT makes it popular.</p>\n<h3 id=\"related-work\">2. Related work</h3>\n<p><strong>2.3 Transfer Learning from Supervised data</strong></p>\n<p>This is what the CV area does most often. Yet it is not effective in NLP. It is partly because of the lacking of data. Another reason might be the existing labeled data focus only on language inference and machine translation, which are too different from other NLP tasks. So BERT and GPT use unlabelled data to pre-train and prove that unsupervised pre-train on a massive data is more effective than supervised pre-train on a relatively small data set. And, interestingly, this trend in NLP gradually effects the CV world. Nowadays unsupervised fine-tuning is becoming more and more popular in CV area.</p>\n<h3 id=\"bert\">3. Bert</h3>\n<p>In the first part, the pre-training and fine-tuning framework is briefly covered. A paper should be self-consistent, meaning that if a mechanic is fundamental in your area and essential to your work. It is a good habit to briefly introduce it, even if all the people in the area know it.</p>\n<p><strong>Model Architecture</strong></p>\n<p>And the architecture is as simple as just take the encoder part of the transformer model.</p>\n<blockquote>\n<p>number of layers (i.e., Transformer blocks) as L, the hidden size as H, and the number of self-attention heads as A.</p>\n<p>BERTBASE(L=12, H=768, A=12, Total Parameters=110M) and BERTLARGE(L=24, H=1024, A=16, Total Parameters=340M).</p>\n</blockquote>\n<p>Because the hidden size of each multi-head attention sublayer is set as 64. And in transformer tradition, H = A * 64. So the multi-head number A actually depends on the hidden size H. As a result, the way of calculating the number of parameters is shown below.</p>\n<p><img src=\"BERT learnable paramters.png\" srcset=\"/img/loading.gif\" lazyload alt=\"BERT learnable paramters\" style=\"zoom:48%;\" /></p>\n<p><strong>Input/Output Representations</strong></p>\n<p>Why Bert need a pair of sentence to handle downstream tasks such as Machine Translation, unlike its predecessor Transformer?</p>\n<p>Because in Transformer, the input is a pair of sequences, taken by encoder and decoder respectively. But Bert is only an encoder. In English-Chinese Translation task for example, for transformer, the encoder take the English version and the decoder take the Chinese version, for Bert, the English version and Chinese version are glued with a special token [sept] then be inputed to the model.</p>\n<p>Besides the [sept] token, another embedding is introduced into the embedding layer, the sequence model. Details are shown below.</p>\n<p><img src=\"BERT segment embedding.png\" srcset=\"/img/loading.gif\" lazyload alt=\"BERT segment embedding\" style=\"zoom:50%;\" /></p>\n<p><strong>3.1 Pre-training BERT</strong></p>\n<p>The paper provides an example of each task in Appendix section <strong>Masked LM and the Masking Procedure</strong>, just go for it and have a look if don't understand.</p>\n<blockquote>\n<p>Next Sentence Prediction The next sentence prediction task can be illustrated in the following examples.</p>\n<p>Input = [CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP]</p>\n<p>Label = IsNext</p>\n<p>Input = [CLS] the man [MASK] to the store [SEP] penguin [MASK] are <strong>flight ##less</strong> birds [SEP]</p>\n<p>Label = NotNext</p>\n</blockquote>\n<p>The \"flight ##less\" is because of the WordPiece embedding method that Bert uses. \"##\" means this token is split from last token, in this case, flightless is the original token. Because flightless is rarely used, the WordPiece embedding split this word into two.</p>\n<p><strong>3.2 Fine-tuning BERT</strong></p>\n<p>Bert's architecture has one advantage over the transformer's, the self-attention allows model look both the two sentences. And the encoder-decoder model can't do that. As a result, the fine-tuning can be a little bit hazy.</p>\n<h3 id=\"experiments\">4 Experiments</h3>\n<p><strong>4.2 SQuAD v1.1</strong></p>\n<blockquote>\n<p>We fine-tune for 3 epochs with a learning rate of 5e-5 and a batch size of 32.</p>\n</blockquote>\n<p>This misleads the people for a while. People found when fine-tuning with Bert, the variance of each results are high i.e. the result of fine-tuning is unstable. Then people found it is because 3 epochs are not enough. Besides, the optimiser that the original Bert model used is an incomplete version of Adam which is not stable for small epoch number. And the follow-ups change it into the original Adam.</p>\n<p>From the processes of the 3 experiments, it can be seen it is easy for BERT to be applied to downstream tasks. Just need to modify the input data in the form of the Bert sequence, and add another output layer. As a result, with BERT, massive number of tasks can be trained under a rather simple architecture.</p>\n<h3 id=\"ablation-studies\">5 Ablation Studies</h3>\n<p><img src=\"BERT alibation study 1.png\" srcset=\"/img/loading.gif\" lazyload alt=\"BERT alibation study 1\" style=\"zoom:30%;\" /></p>\n<p>It is obvious the 4th architecture BiLSTM is from the idea of ELMO. And all the variation lead to a deterioration of the acc, especially in the MRPC task.</p>\n<blockquote>\n<p><strong>Microsoft Research Paraphrase Corpus (MRPC) Dataset</strong></p>\n<p>Created by Dolan et al. at 2005, the Microsoft Research Paraphrase Corpus (MRPC) Dataset contains pairs of sentences which have been extracted from news sources on the web, along with human annotations indicating whether each pair captures a paraphrase/semantic equivalence relationship., in English language. Containing 5,8 in Text file format.</p>\n</blockquote>\n<p><img src=\"model size graph.webp\" srcset=\"/img/loading.gif\" lazyload alt=\"model size graph\" style=\"zoom:50%;\" /></p>\n<p>In the Effect of model size part, they claim with a large model size, huge improvement can be reached. And this leads a trend of increasing the model size in NLP, for example, the 100 billon GPT-3, and 500 billion model Megatron-Turing Natural Language Generation (MT-NLG). The boundary of NLP will be push further.</p>\n<h2 id=\"reviews\">Reviews</h2>\n<p>Writing: The biggest sell point in this paper is chosen as the \"bidirectional\". From today's view, the contributions of BERT are so more than this. Besides, when say to choose a feature, it is better to discuss both the pros and the cons of the choice. For example, compared with GPT, the encoder is used instead of the decoder. The pros are the bidirectional feature, but the cons is the resulting difficulty in applying on generative tasks such as the machine translation.</p>\n<p>Besides, BERT follows a whole ideal path of solving deep learning problems. That is after pre-training on a deep and huge model on a huge unlabelled dataset, the model can be applied to many small tasks with a few steps of fine tuning.</p>\n","site":{"data":{}},"wordcount":6231,"excerpt":"<blockquote>\n<p>The BERT is the most important achievement in the NLP field in the last 4 years. It makes the transfer learning of NLP tasks possible and the transformer framework dominant the NLP field.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>","more":"<p>Paper link: <a href=\"https://arxiv.org/abs/1810.04805\">Bert: Pre-training of deep bidirectional transformers for language understanding</a></p>\n<p>Useful links: https://www.bilibili.com/video/BV1PL411M7eQ</p>\n<p> https://youtu.be/UYPa347-DdE</p>\n<p> <a href=\"https://arxiv.org/abs/1802.05365\">Deep contextualized word representations - arXiv</a></p>\n<h2 id=\"notes-by-sections\">Notes by sections</h2>\n<h3 id=\"abstract\">0. Abstract</h3>\n<p><em>The name of BERT might come from one of its important related work, ELMo. And Elmo and Bert are both characters in a TV show Sesame Street.</em></p>\n<p>The abstract focus on the two related work, ELMo and GPT. The bidirectional feature is in contrast to the unidirectional GPT model. And the \"without substantial task specific architecture modifications\" feature compares with the RNN-based ELMo model, whose architecture might get modified when training downstream tasks. Yet the ELMo model is bidirectional and GPT model is easy to use.</p>\n<p>When claiming a model is great, it is good to provide both the absolute accuracy and the relative accuracy compared with others. Just like this paper does.</p>\n<h3 id=\"conclusion\">6. Conclusion</h3>\n<p>To summarise, this is a classical <strong>A+B</strong> type of research. The idea of BERT is simple, combine the advantages of the bidirectional network with a rather old RNN base (ELMo), and the unidirectional network with a transformer base (GPT). And in detail, 2 pre-training tasks are designed.</p>\n<p>The main contribution of this network is showing that bidirectional information is important.</p>\n<h3 id=\"introduction\">1. Introduction</h3>\n<p>From the history introduction, it turns out BERT is not the first to apply pre-training on NLP. It's been a while. But BERT makes it popular.</p>\n<h3 id=\"related-work\">2. Related work</h3>\n<p><strong>2.3 Transfer Learning from Supervised data</strong></p>\n<p>This is what the CV area does most often. Yet it is not effective in NLP. It is partly because of the lacking of data. Another reason might be the existing labeled data focus only on language inference and machine translation, which are too different from other NLP tasks. So BERT and GPT use unlabelled data to pre-train and prove that unsupervised pre-train on a massive data is more effective than supervised pre-train on a relatively small data set. And, interestingly, this trend in NLP gradually effects the CV world. Nowadays unsupervised fine-tuning is becoming more and more popular in CV area.</p>\n<h3 id=\"bert\">3. Bert</h3>\n<p>In the first part, the pre-training and fine-tuning framework is briefly covered. A paper should be self-consistent, meaning that if a mechanic is fundamental in your area and essential to your work. It is a good habit to briefly introduce it, even if all the people in the area know it.</p>\n<p><strong>Model Architecture</strong></p>\n<p>And the architecture is as simple as just take the encoder part of the transformer model.</p>\n<blockquote>\n<p>number of layers (i.e., Transformer blocks) as L, the hidden size as H, and the number of self-attention heads as A.</p>\n<p>BERTBASE(L=12, H=768, A=12, Total Parameters=110M) and BERTLARGE(L=24, H=1024, A=16, Total Parameters=340M).</p>\n</blockquote>\n<p>Because the hidden size of each multi-head attention sublayer is set as 64. And in transformer tradition, H = A * 64. So the multi-head number A actually depends on the hidden size H. As a result, the way of calculating the number of parameters is shown below.</p>\n<p><img src=\"BERT learnable paramters.png\" alt=\"BERT learnable paramters\" style=\"zoom:48%;\" /></p>\n<p><strong>Input/Output Representations</strong></p>\n<p>Why Bert need a pair of sentence to handle downstream tasks such as Machine Translation, unlike its predecessor Transformer?</p>\n<p>Because in Transformer, the input is a pair of sequences, taken by encoder and decoder respectively. But Bert is only an encoder. In English-Chinese Translation task for example, for transformer, the encoder take the English version and the decoder take the Chinese version, for Bert, the English version and Chinese version are glued with a special token [sept] then be inputed to the model.</p>\n<p>Besides the [sept] token, another embedding is introduced into the embedding layer, the sequence model. Details are shown below.</p>\n<p><img src=\"BERT segment embedding.png\" alt=\"BERT segment embedding\" style=\"zoom:50%;\" /></p>\n<p><strong>3.1 Pre-training BERT</strong></p>\n<p>The paper provides an example of each task in Appendix section <strong>Masked LM and the Masking Procedure</strong>, just go for it and have a look if don't understand.</p>\n<blockquote>\n<p>Next Sentence Prediction The next sentence prediction task can be illustrated in the following examples.</p>\n<p>Input = [CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP]</p>\n<p>Label = IsNext</p>\n<p>Input = [CLS] the man [MASK] to the store [SEP] penguin [MASK] are <strong>flight ##less</strong> birds [SEP]</p>\n<p>Label = NotNext</p>\n</blockquote>\n<p>The \"flight ##less\" is because of the WordPiece embedding method that Bert uses. \"##\" means this token is split from last token, in this case, flightless is the original token. Because flightless is rarely used, the WordPiece embedding split this word into two.</p>\n<p><strong>3.2 Fine-tuning BERT</strong></p>\n<p>Bert's architecture has one advantage over the transformer's, the self-attention allows model look both the two sentences. And the encoder-decoder model can't do that. As a result, the fine-tuning can be a little bit hazy.</p>\n<h3 id=\"experiments\">4 Experiments</h3>\n<p><strong>4.2 SQuAD v1.1</strong></p>\n<blockquote>\n<p>We fine-tune for 3 epochs with a learning rate of 5e-5 and a batch size of 32.</p>\n</blockquote>\n<p>This misleads the people for a while. People found when fine-tuning with Bert, the variance of each results are high i.e. the result of fine-tuning is unstable. Then people found it is because 3 epochs are not enough. Besides, the optimiser that the original Bert model used is an incomplete version of Adam which is not stable for small epoch number. And the follow-ups change it into the original Adam.</p>\n<p>From the processes of the 3 experiments, it can be seen it is easy for BERT to be applied to downstream tasks. Just need to modify the input data in the form of the Bert sequence, and add another output layer. As a result, with BERT, massive number of tasks can be trained under a rather simple architecture.</p>\n<h3 id=\"ablation-studies\">5 Ablation Studies</h3>\n<p><img src=\"BERT alibation study 1.png\" alt=\"BERT alibation study 1\" style=\"zoom:30%;\" /></p>\n<p>It is obvious the 4th architecture BiLSTM is from the idea of ELMO. And all the variation lead to a deterioration of the acc, especially in the MRPC task.</p>\n<blockquote>\n<p><strong>Microsoft Research Paraphrase Corpus (MRPC) Dataset</strong></p>\n<p>Created by Dolan et al. at 2005, the Microsoft Research Paraphrase Corpus (MRPC) Dataset contains pairs of sentences which have been extracted from news sources on the web, along with human annotations indicating whether each pair captures a paraphrase/semantic equivalence relationship., in English language. Containing 5,8 in Text file format.</p>\n</blockquote>\n<p><img src=\"model size graph.webp\" alt=\"model size graph\" style=\"zoom:50%;\" /></p>\n<p>In the Effect of model size part, they claim with a large model size, huge improvement can be reached. And this leads a trend of increasing the model size in NLP, for example, the 100 billon GPT-3, and 500 billion model Megatron-Turing Natural Language Generation (MT-NLG). The boundary of NLP will be push further.</p>\n<h2 id=\"reviews\">Reviews</h2>\n<p>Writing: The biggest sell point in this paper is chosen as the \"bidirectional\". From today's view, the contributions of BERT are so more than this. Besides, when say to choose a feature, it is better to discuss both the pros and the cons of the choice. For example, compared with GPT, the encoder is used instead of the decoder. The pros are the bidirectional feature, but the cons is the resulting difficulty in applying on generative tasks such as the machine translation.</p>\n<p>Besides, BERT follows a whole ideal path of solving deep learning problems. That is after pre-training on a deep and huge model on a huge unlabelled dataset, the model can be applied to many small tasks with a few steps of fine tuning.</p>"},{"title":"Swin transformer","author":"Ryan LI","toc":true,"declare":true,"index_img":"/index/paper-reading-Swin-transformer.png","date":"2022-05-09T03:37:19.000Z","_content":"\n{% note primary %}\n\nAfter ViT, Swin-transformer further demonstrated the potential of transformer in CV. This work has swept all major CV tasks since its publication, including [COCO](https://paperswithcode.com/sota/object-detection-on-coco) and [ADE20K](https://paperswithcode.com/sota/semantic-segmentation-on-ade20k). And it's awarded as best paper by [ICCV2021](https://iccv2021.thecvf.com/iccv-2021-paper-awards).\n\n{% endnote %}\n\n<!-- more -->\n\n{% note secondary %}\nThis is a [series of paper reading notes](/2022/04/02/paper-reading-start/),  hopefully, to push me to read paper casually and to leave some record of what I've learned.\n{% endnote %}\n\n<img src=\"CoCo and ADE20K SOTA.png\" alt=\"CoCo and ADE20K SOTA\" style=\"zoom:100%;\" />\n\n*Paper link:*\n\n [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)(newer version on arXiv)\n\n*Useful links:*\n\n[Paper explanation video](https://www.bilibili.com/video/BV13L4y1475U?share_source=copy_web)\n\n[Official Github](https://github.com/microsoft/Swin-Transformer)\n\n### Abstract\n\n### Conclusion\n\n### Key figures\n\n### Introduction\n","source":"_posts/paper-reading-Swin-transformer.md","raw":"---\ntitle: 'Swin transformer'\nauthor: Ryan LI\ntoc: true\ndeclare: true\nindex_img: /index/paper-reading-Swin-transformer.png\ntags:\n  - deep learning\n  - paper reading\ndate: 2022-05-09 11:37:19\n---\n\n{% note primary %}\n\nAfter ViT, Swin-transformer further demonstrated the potential of transformer in CV. This work has swept all major CV tasks since its publication, including [COCO](https://paperswithcode.com/sota/object-detection-on-coco) and [ADE20K](https://paperswithcode.com/sota/semantic-segmentation-on-ade20k). And it's awarded as best paper by [ICCV2021](https://iccv2021.thecvf.com/iccv-2021-paper-awards).\n\n{% endnote %}\n\n<!-- more -->\n\n{% note secondary %}\nThis is a [series of paper reading notes](/2022/04/02/paper-reading-start/),  hopefully, to push me to read paper casually and to leave some record of what I've learned.\n{% endnote %}\n\n<img src=\"CoCo and ADE20K SOTA.png\" alt=\"CoCo and ADE20K SOTA\" style=\"zoom:100%;\" />\n\n*Paper link:*\n\n [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)(newer version on arXiv)\n\n*Useful links:*\n\n[Paper explanation video](https://www.bilibili.com/video/BV13L4y1475U?share_source=copy_web)\n\n[Official Github](https://github.com/microsoft/Swin-Transformer)\n\n### Abstract\n\n### Conclusion\n\n### Key figures\n\n### Introduction\n","slug":"paper-reading-Swin-transformer","published":1,"updated":"2022-06-09T10:25:16.671Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz2b0029l8ybatnhfiuf","content":"<div class=\"note note-primary\">\n            <p>After ViT, Swin-transformer further demonstrated the potential of transformer in CV. This work has swept all major CV tasks since its publication, including <a href=\"https://paperswithcode.com/sota/object-detection-on-coco\">COCO</a> and <a href=\"https://paperswithcode.com/sota/semantic-segmentation-on-ade20k\">ADE20K</a>. And it's awarded as best paper by <a href=\"https://iccv2021.thecvf.com/iccv-2021-paper-awards\">ICCV2021</a>.</p>\n          </div>\n<span id=\"more\"></span>\n<div class=\"note note-secondary\">\n            <p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n          </div>\n<p><img src=\"CoCo and ADE20K SOTA.png\" srcset=\"/img/loading.gif\" lazyload alt=\"CoCo and ADE20K SOTA\" style=\"zoom:100%;\" /></p>\n<p><em>Paper link:</em></p>\n<p><a href=\"https://arxiv.org/abs/2103.14030\">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</a>(newer version on arXiv)</p>\n<p><em>Useful links:</em></p>\n<p><a href=\"https://www.bilibili.com/video/BV13L4y1475U?share_source=copy_web\">Paper explanation video</a></p>\n<p><a href=\"https://github.com/microsoft/Swin-Transformer\">Official Github</a></p>\n<h3 id=\"abstract\">Abstract</h3>\n<h3 id=\"conclusion\">Conclusion</h3>\n<h3 id=\"key-figures\">Key figures</h3>\n<h3 id=\"introduction\">Introduction</h3>\n","site":{"data":{}},"wordcount":474,"excerpt":"<div class=\"note note-primary\">\n            <p>After ViT, Swin-transformer further demonstrated the potential of transformer in CV. This work has swept all major CV tasks since its publication, including <a href=\"https://paperswithcode.com/sota/object-detection-on-coco\">COCO</a> and <a href=\"https://paperswithcode.com/sota/semantic-segmentation-on-ade20k\">ADE20K</a>. And it's awarded as best paper by <a href=\"https://iccv2021.thecvf.com/iccv-2021-paper-awards\">ICCV2021</a>.</p>\n          </div>","more":"<div class=\"note note-secondary\">\n            <p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n          </div>\n<p><img src=\"CoCo and ADE20K SOTA.png\" alt=\"CoCo and ADE20K SOTA\" style=\"zoom:100%;\" /></p>\n<p><em>Paper link:</em></p>\n<p><a href=\"https://arxiv.org/abs/2103.14030\">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</a>(newer version on arXiv)</p>\n<p><em>Useful links:</em></p>\n<p><a href=\"https://www.bilibili.com/video/BV13L4y1475U?share_source=copy_web\">Paper explanation video</a></p>\n<p><a href=\"https://github.com/microsoft/Swin-Transformer\">Official Github</a></p>\n<h3 id=\"abstract\">Abstract</h3>\n<h3 id=\"conclusion\">Conclusion</h3>\n<h3 id=\"key-figures\">Key figures</h3>\n<h3 id=\"introduction\">Introduction</h3>"},{"title":"paper reading: start","author":"Ryan LI","declare":true,"date":"2022-04-02T13:49:37.000Z","index_img":"/index/paper-reading.png","_content":"\n> This is a brief description of the 3-step method of reading a paper. And a reading list.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\n###  Mindmap for quick indexing\n\n{% markmap 300px %}\n\n- Classic\n  - Vision\n    - [AlexNet](/2022/04/07/paper-reading-AlexNet/)\n    - [ResNet](/2022/04/09/paper-reading-ResNet/)\n- [Transformer](/2022/04/12/paper-reading-transformer/)\n  - NLP\n    - [BERT](/2022/04/15/paper-reading-bert/)\n    - [GPT1-3](/2022/04/18/paper-reading-GPT1-3/)\n  - Vision\n    - [ViT](/2022/04/21/paper-reading-Vision-Transformer/)\n      - [MAE](/2022/04/27/paper-reading-MAE/)\n- Novel \n  - [ GNN intro](/2022/04/14/paper-reading-A-gentle-introduction-to-graph-neural-networks/)\n  - [Constructive learning review](/2022/05/03/paper-reading-contrastive-learning-review/)\n    - Moco\n\n{%endmarkmap%}\n\n### How to read a paper\n\nThe method is inspired by [Andrew Ng's lecutre on Stanford](https://youtu.be/733m6qBH-jI) and [Mu Li's online lecutre](https://www.bilibili.com/video/BV1H44y1t75x)\n\n#### Up to 3 passes for one paper:\n\n| Section       | 1st pass          | 2nd pass            | 3rd pass     |\n| ------------- | ----------------- | ------------------- | ------------ |\n| 1. Title      |                  |                     |              |\n| 2. Abstruct   |                  |                     |              |\n| 3. Intro      |                   | criticle references |              |\n| 4.Method      | key pics & tables | key pics & tables   | how to apply |\n| 5. Expriment  | key pics & tables | key pics & tables   | how to do it |\n| 6. Conclusion |                  |                     |              |\n\n**First pass:** title, abstract, conclusion. Take a look at important figures and tables in the Methods and Experiments section. In this way, you can spend less than 15 minutes to understand whether the paper is suitable for your research direction.\n\n**Second pass:** After confirming that the paper is worth reading, you can quickly go through the whole paper. You dont need to know all the details. You need to understand important figures and tables, know what each part is doing, and circle the relevant literature. If you think the article is too difficult, you can read the cited literature.\n\n**The third pass:** what problem was asked. How to solve this problem. How to apply the experiment. Close the article and recall what each section is about.\n\n#### Some rules:  \n\n- Efficient high informative content first then the harder material \n- Skip the parts which do not make sense unless trying to do deep research on it\n- The related work part is often unimportant\n\n#### Questions that keep in mind:\n\n- what the authors try to accomplish\n- what are the key elements of the approach\n- what can you use yourself\n- what other references do you want to follow\n\n### List of papers\n\n[paper reading: AlexNet](/2022/04/07/paper-reading-AlexNet/)\n\n[paper reading: ResNet](/2022/04/09/paper-reading-ResNet/)\n\n[paper reading: transformer](/2022/04/12/paper-reading-transformer/)\n\n[paper reading: Introduction to GNN](/2022/04/14/paper-reading-A-gentle-introduction-to-graph-neural-networks/)\n\n[paper reading: bert](/2022/04/15/paper-reading-bert/)\n\n[paper reading: GPT1-3](/2022/04/18/paper-reading-GPT1-3/)\n\n[paper reading: Vision Transformer](/2022/04/21/paper-reading-Vision-Transformer/)\n\n[paper reading: MAE](/2022/04/27/paper-reading-MAE/)\n\n[Paper reading: Constructive learning review](/2022/05/03/paper-reading-contrastive-learning-review/)\n","source":"_posts/paper-reading-start.md","raw":"---\ntitle: 'paper reading: start'\nauthor: Ryan LI\ndeclare: true\ndate: 2022-04-02 21:49:37\nindex_img: /index/paper-reading.png\ntags: \n  - paper reading\n  - deep learning\n---\n\n> This is a brief description of the 3-step method of reading a paper. And a reading list.\n\n> This is a [series of paper reading notes](/2022/04/02/paper-reading-start/), hopefully, to push me to read paper casually and to leave some record of what I've learned.\n\n<!-- more -->\n\n###  Mindmap for quick indexing\n\n{% markmap 300px %}\n\n- Classic\n  - Vision\n    - [AlexNet](/2022/04/07/paper-reading-AlexNet/)\n    - [ResNet](/2022/04/09/paper-reading-ResNet/)\n- [Transformer](/2022/04/12/paper-reading-transformer/)\n  - NLP\n    - [BERT](/2022/04/15/paper-reading-bert/)\n    - [GPT1-3](/2022/04/18/paper-reading-GPT1-3/)\n  - Vision\n    - [ViT](/2022/04/21/paper-reading-Vision-Transformer/)\n      - [MAE](/2022/04/27/paper-reading-MAE/)\n- Novel \n  - [ GNN intro](/2022/04/14/paper-reading-A-gentle-introduction-to-graph-neural-networks/)\n  - [Constructive learning review](/2022/05/03/paper-reading-contrastive-learning-review/)\n    - Moco\n\n{%endmarkmap%}\n\n### How to read a paper\n\nThe method is inspired by [Andrew Ng's lecutre on Stanford](https://youtu.be/733m6qBH-jI) and [Mu Li's online lecutre](https://www.bilibili.com/video/BV1H44y1t75x)\n\n#### Up to 3 passes for one paper:\n\n| Section       | 1st pass          | 2nd pass            | 3rd pass     |\n| ------------- | ----------------- | ------------------- | ------------ |\n| 1. Title      |                  |                     |              |\n| 2. Abstruct   |                  |                     |              |\n| 3. Intro      |                   | criticle references |              |\n| 4.Method      | key pics & tables | key pics & tables   | how to apply |\n| 5. Expriment  | key pics & tables | key pics & tables   | how to do it |\n| 6. Conclusion |                  |                     |              |\n\n**First pass:** title, abstract, conclusion. Take a look at important figures and tables in the Methods and Experiments section. In this way, you can spend less than 15 minutes to understand whether the paper is suitable for your research direction.\n\n**Second pass:** After confirming that the paper is worth reading, you can quickly go through the whole paper. You dont need to know all the details. You need to understand important figures and tables, know what each part is doing, and circle the relevant literature. If you think the article is too difficult, you can read the cited literature.\n\n**The third pass:** what problem was asked. How to solve this problem. How to apply the experiment. Close the article and recall what each section is about.\n\n#### Some rules:  \n\n- Efficient high informative content first then the harder material \n- Skip the parts which do not make sense unless trying to do deep research on it\n- The related work part is often unimportant\n\n#### Questions that keep in mind:\n\n- what the authors try to accomplish\n- what are the key elements of the approach\n- what can you use yourself\n- what other references do you want to follow\n\n### List of papers\n\n[paper reading: AlexNet](/2022/04/07/paper-reading-AlexNet/)\n\n[paper reading: ResNet](/2022/04/09/paper-reading-ResNet/)\n\n[paper reading: transformer](/2022/04/12/paper-reading-transformer/)\n\n[paper reading: Introduction to GNN](/2022/04/14/paper-reading-A-gentle-introduction-to-graph-neural-networks/)\n\n[paper reading: bert](/2022/04/15/paper-reading-bert/)\n\n[paper reading: GPT1-3](/2022/04/18/paper-reading-GPT1-3/)\n\n[paper reading: Vision Transformer](/2022/04/21/paper-reading-Vision-Transformer/)\n\n[paper reading: MAE](/2022/04/27/paper-reading-MAE/)\n\n[Paper reading: Constructive learning review](/2022/05/03/paper-reading-contrastive-learning-review/)\n","slug":"paper-reading-start","published":1,"updated":"2022-05-03T02:33:47.634Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4r5iz2b002bl8ybg54vf58w","content":"<blockquote>\n<p>This is a brief description of the 3-step method of reading a paper. And a reading list.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>\n<span id=\"more\"></span>\n<h3 id=\"mindmap-for-quick-indexing\"> Mindmap for quick indexing</h3>\n\n<div class=\"markmap-container\" style=\"height:300px\">\n  <svg data=\"{&quot;t&quot;:&quot;root&quot;,&quot;d&quot;:0,&quot;v&quot;:&quot;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[1,2]},&quot;v&quot;:&quot;Classic&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[2,3]},&quot;v&quot;:&quot;Vision&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[3,4]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/07/paper-reading-AlexNet/\\&quot;&gt;AlexNet&lt;/a&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[4,5]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/09/paper-reading-ResNet/\\&quot;&gt;ResNet&lt;/a&gt;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[5,6]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/12/paper-reading-transformer/\\&quot;&gt;Transformer&lt;/a&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[6,7]},&quot;v&quot;:&quot;NLP&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[7,8]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/15/paper-reading-bert/\\&quot;&gt;BERT&lt;/a&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[8,9]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/18/paper-reading-GPT1-3/\\&quot;&gt;GPT1-3&lt;/a&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[9,10]},&quot;v&quot;:&quot;Vision&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[10,11]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/21/paper-reading-Vision-Transformer/\\&quot;&gt;ViT&lt;/a&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[11,12]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/27/paper-reading-MAE/\\&quot;&gt;MAE&lt;/a&gt;&quot;}]}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[12,13]},&quot;v&quot;:&quot;Novel&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[13,14]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/14/paper-reading-A-gentle-introduction-to-graph-neural-networks/\\&quot;&gt; GNN intro&lt;/a&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[14,15]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/05/03/paper-reading-contrastive-learning-review/\\&quot;&gt;Constructive learning review&lt;/a&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[15,16]},&quot;v&quot;:&quot;Moco&quot;}]}]}],&quot;p&quot;:{}}\"></svg>\n</div>\n\n<h3 id=\"how-to-read-a-paper\">How to read a paper</h3>\n<p>The method is inspired by <a href=\"https://youtu.be/733m6qBH-jI\">Andrew Ng's lecutre on Stanford</a> and <a href=\"https://www.bilibili.com/video/BV1H44y1t75x\">Mu Li's online lecutre</a></p>\n<h4 id=\"up-to-3-passes-for-one-paper\">Up to 3 passes for one paper:</h4>\n<table>\n<thead>\n<tr class=\"header\">\n<th>Section</th>\n<th>1st pass</th>\n<th>2nd pass</th>\n<th>3rd pass</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>1. Title</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr class=\"even\">\n<td>2. Abstruct</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr class=\"odd\">\n<td>3. Intro</td>\n<td></td>\n<td>criticle references</td>\n<td></td>\n</tr>\n<tr class=\"even\">\n<td>4.Method</td>\n<td>key pics &amp; tables</td>\n<td>key pics &amp; tables</td>\n<td>how to apply</td>\n</tr>\n<tr class=\"odd\">\n<td>5. Expriment</td>\n<td>key pics &amp; tables</td>\n<td>key pics &amp; tables</td>\n<td>how to do it</td>\n</tr>\n<tr class=\"even\">\n<td>6. Conclusion</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p><strong>First pass:</strong> title, abstract, conclusion. Take a look at important figures and tables in the Methods and Experiments section. In this way, you can spend less than 15 minutes to understand whether the paper is suitable for your research direction.</p>\n<p><strong>Second pass:</strong> After confirming that the paper is worth reading, you can quickly go through the whole paper. You dont need to know all the details. You need to understand important figures and tables, know what each part is doing, and circle the relevant literature. If you think the article is too difficult, you can read the cited literature.</p>\n<p><strong>The third pass:</strong> what problem was asked. How to solve this problem. How to apply the experiment. Close the article and recall what each section is about.</p>\n<h4 id=\"some-rules\">Some rules:</h4>\n<ul>\n<li>Efficient high informative content first then the harder material</li>\n<li>Skip the parts which do not make sense unless trying to do deep research on it</li>\n<li>The related work part is often unimportant</li>\n</ul>\n<h4 id=\"questions-that-keep-in-mind\">Questions that keep in mind:</h4>\n<ul>\n<li>what the authors try to accomplish</li>\n<li>what are the key elements of the approach</li>\n<li>what can you use yourself</li>\n<li>what other references do you want to follow</li>\n</ul>\n<h3 id=\"list-of-papers\">List of papers</h3>\n<p><a href=\"/2022/04/07/paper-reading-AlexNet/\">paper reading: AlexNet</a></p>\n<p><a href=\"/2022/04/09/paper-reading-ResNet/\">paper reading: ResNet</a></p>\n<p><a href=\"/2022/04/12/paper-reading-transformer/\">paper reading: transformer</a></p>\n<p><a href=\"/2022/04/14/paper-reading-A-gentle-introduction-to-graph-neural-networks/\">paper reading: Introduction to GNN</a></p>\n<p><a href=\"/2022/04/15/paper-reading-bert/\">paper reading: bert</a></p>\n<p><a href=\"/2022/04/18/paper-reading-GPT1-3/\">paper reading: GPT1-3</a></p>\n<p><a href=\"/2022/04/21/paper-reading-Vision-Transformer/\">paper reading: Vision Transformer</a></p>\n<p><a href=\"/2022/04/27/paper-reading-MAE/\">paper reading: MAE</a></p>\n<p><a href=\"/2022/05/03/paper-reading-contrastive-learning-review/\">Paper reading: Constructive learning review</a></p>\n","site":{"data":{}},"wordcount":1661,"excerpt":"<blockquote>\n<p>This is a brief description of the 3-step method of reading a paper. And a reading list.</p>\n</blockquote>\n<blockquote>\n<p>This is a <a href=\"/2022/04/02/paper-reading-start/\">series of paper reading notes</a>, hopefully, to push me to read paper casually and to leave some record of what I've learned.</p>\n</blockquote>","more":"<h3 id=\"mindmap-for-quick-indexing\"> Mindmap for quick indexing</h3>\n\n<div class=\"markmap-container\" style=\"height:300px\">\n  <svg data=\"{&quot;t&quot;:&quot;root&quot;,&quot;d&quot;:0,&quot;v&quot;:&quot;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[1,2]},&quot;v&quot;:&quot;Classic&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[2,3]},&quot;v&quot;:&quot;Vision&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[3,4]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/07/paper-reading-AlexNet/\\&quot;&gt;AlexNet&lt;/a&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[4,5]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/09/paper-reading-ResNet/\\&quot;&gt;ResNet&lt;/a&gt;&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[5,6]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/12/paper-reading-transformer/\\&quot;&gt;Transformer&lt;/a&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[6,7]},&quot;v&quot;:&quot;NLP&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[7,8]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/15/paper-reading-bert/\\&quot;&gt;BERT&lt;/a&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[8,9]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/18/paper-reading-GPT1-3/\\&quot;&gt;GPT1-3&lt;/a&gt;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[9,10]},&quot;v&quot;:&quot;Vision&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[10,11]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/21/paper-reading-Vision-Transformer/\\&quot;&gt;ViT&lt;/a&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:8,&quot;p&quot;:{&quot;lines&quot;:[11,12]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/27/paper-reading-MAE/\\&quot;&gt;MAE&lt;/a&gt;&quot;}]}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[12,13]},&quot;v&quot;:&quot;Novel&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[13,14]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/04/14/paper-reading-A-gentle-introduction-to-graph-neural-networks/\\&quot;&gt; GNN intro&lt;/a&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[14,15]},&quot;v&quot;:&quot;&lt;a href=\\&quot;/2022/05/03/paper-reading-contrastive-learning-review/\\&quot;&gt;Constructive learning review&lt;/a&gt;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:6,&quot;p&quot;:{&quot;lines&quot;:[15,16]},&quot;v&quot;:&quot;Moco&quot;}]}]}],&quot;p&quot;:{}}\"></svg>\n</div>\n\n<h3 id=\"how-to-read-a-paper\">How to read a paper</h3>\n<p>The method is inspired by <a href=\"https://youtu.be/733m6qBH-jI\">Andrew Ng's lecutre on Stanford</a> and <a href=\"https://www.bilibili.com/video/BV1H44y1t75x\">Mu Li's online lecutre</a></p>\n<h4 id=\"up-to-3-passes-for-one-paper\">Up to 3 passes for one paper:</h4>\n<table>\n<thead>\n<tr class=\"header\">\n<th>Section</th>\n<th>1st pass</th>\n<th>2nd pass</th>\n<th>3rd pass</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>1. Title</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr class=\"even\">\n<td>2. Abstruct</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr class=\"odd\">\n<td>3. Intro</td>\n<td></td>\n<td>criticle references</td>\n<td></td>\n</tr>\n<tr class=\"even\">\n<td>4.Method</td>\n<td>key pics &amp; tables</td>\n<td>key pics &amp; tables</td>\n<td>how to apply</td>\n</tr>\n<tr class=\"odd\">\n<td>5. Expriment</td>\n<td>key pics &amp; tables</td>\n<td>key pics &amp; tables</td>\n<td>how to do it</td>\n</tr>\n<tr class=\"even\">\n<td>6. Conclusion</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p><strong>First pass:</strong> title, abstract, conclusion. Take a look at important figures and tables in the Methods and Experiments section. In this way, you can spend less than 15 minutes to understand whether the paper is suitable for your research direction.</p>\n<p><strong>Second pass:</strong> After confirming that the paper is worth reading, you can quickly go through the whole paper. You dont need to know all the details. You need to understand important figures and tables, know what each part is doing, and circle the relevant literature. If you think the article is too difficult, you can read the cited literature.</p>\n<p><strong>The third pass:</strong> what problem was asked. How to solve this problem. How to apply the experiment. Close the article and recall what each section is about.</p>\n<h4 id=\"some-rules\">Some rules:</h4>\n<ul>\n<li>Efficient high informative content first then the harder material</li>\n<li>Skip the parts which do not make sense unless trying to do deep research on it</li>\n<li>The related work part is often unimportant</li>\n</ul>\n<h4 id=\"questions-that-keep-in-mind\">Questions that keep in mind:</h4>\n<ul>\n<li>what the authors try to accomplish</li>\n<li>what are the key elements of the approach</li>\n<li>what can you use yourself</li>\n<li>what other references do you want to follow</li>\n</ul>\n<h3 id=\"list-of-papers\">List of papers</h3>\n<p><a href=\"/2022/04/07/paper-reading-AlexNet/\">paper reading: AlexNet</a></p>\n<p><a href=\"/2022/04/09/paper-reading-ResNet/\">paper reading: ResNet</a></p>\n<p><a href=\"/2022/04/12/paper-reading-transformer/\">paper reading: transformer</a></p>\n<p><a href=\"/2022/04/14/paper-reading-A-gentle-introduction-to-graph-neural-networks/\">paper reading: Introduction to GNN</a></p>\n<p><a href=\"/2022/04/15/paper-reading-bert/\">paper reading: bert</a></p>\n<p><a href=\"/2022/04/18/paper-reading-GPT1-3/\">paper reading: GPT1-3</a></p>\n<p><a href=\"/2022/04/21/paper-reading-Vision-Transformer/\">paper reading: Vision Transformer</a></p>\n<p><a href=\"/2022/04/27/paper-reading-MAE/\">paper reading: MAE</a></p>\n<p><a href=\"/2022/05/03/paper-reading-contrastive-learning-review/\">Paper reading: Constructive learning review</a></p>"},{"title":"Numerical schemes fundamentals","author":"Ryan LI","toc":true,"declare":true,"index_img":"/index/fvm_schemes.png","date":"2022-06-18T10:08:24.000Z","_content":"\n{% note primary %}\n\nThis is the **essence** of CFD, advecting with the discontinuities due to inviscid fluid PDEs. Several computational schemes dealing with them are introduced then tested in OpenFOAM on the 1D shockTube case.\n\n{% endnote%}\n\n<!-- more -->\n\n{% note secondary %}\n\nThis is a review of my graduate CFD course and the application of the theory to CFD software. The aim is to further the understanding of finite volume method and the `fvscheme` dict in OpenFOAM.\n\n{% endnote%}\n\n**Reference books:**\n\nE.F. Toro, Riemann Solvers and Numerical Methods for Fluid Dynamics, Springer-Verlag.\n\nR.J. LeVeque, Finite Volume Methods for Hyperbolic Problems, Cambridge University Press.\n\n**Overview:**\n\n{% markmap 300px %}\n\n- Scalar conservation laws\n  - conservation vs non-conservative\n  - 1D simple Riemann problem for Burgers' equation\n  - characteristics discontinuities and jump conditions\n  - weak solutions and entropy condition\n- Numerical schemes for 1D discontinuities\n  - practical examples on one conservation law\n  - \n\n- System of conservation laws\n  - add complexity, system of conservation laws\n\n{% endmarkmap %}\n\n## Scalar conservation laws\n\n{% note info %}\n\n1-D theory. Examples of 1-D hyperbolic conservation laws. Characteristics discontinuities and jump conditions. Weak solutions and entropy condition. Linear versus non-linear advection\n\n{% endnote%}\n\n### Challenges\n\nAs we all know, flow fluids are governed by 3 hyperbolic PDEs (conservation of mass, momentum and energy). These equations are highly non-linear and they can lead to discontinuities even with a smooth initial conditions, which is very difficult to solve numerically. Simple FDM will definitely fail on these discontinuities and shocks.\n\nRecall the incompressible NS equation that we've learned in the kindergarten:\n$$\n\\frac{\\partial \\mathbf{V}}{\\partial t} + \\underbrace{\\left(\\boldsymbol{\\nabla}\\cdot\\mathbf{V}\\right)\\mathbf{V}}_{\\text{convection}} = \\frac{\\nabla p}{\\rho} + \\mathbf{g}+ \\underbrace{\\nu \\boldsymbol{\\nabla}^2\\mathbf{V}}_{\\text{diffusion}}\n$$\nthe viscous diffusion term in the equation leads to parabolic equations with smooth solutions, which will save our life. But with very high $Re$, the equation reduces to pure <font color=#75147c>hyperbolic inviscid Euler Equation</font>, and the resultant discontinuity is a nightmare for most of the numerical schemes. \n\nThe presence of discontinuities requires <font color=#75147c>weak solutions</font>, as oppose to <font color=#75147c>strong solutions</font>.\n\nHowever, the weak solutions give up the uniqueness in math, i.e there exist a large number of solutions that may not be physical acceptable, i.e. extra conditions are needed to justify the solution. They are:\n\n- <font color=#75147c>Rankine-Hugoniot</font> condition deals with the discontinuity\n- <font color=#75147c>Entropy</font> condition satisfies the physics\n\n{% note info %}\n\nJust here to remind that we are dealing with inviscid flow, shocks, nothing to do with turbulence.\n\n{% endnote%}\n\n### Scalar conservation laws\n\n#### 1D law\n\n<img src=\"1D scalar convection.png\" alt=\"1D scalar convection control volume\" style=\"zoom:70%;\" />\n\nFirst let's introduce a simple example to present the problem: consider an 1D control volume $[a,b]$, during the time interval $[t_1,t_2]$ . The scalar conservation law can be stated as that during $[t_1,t_2]$ , change in total conserved quantity in $[a,b]$ equals to the net flux through the boundaries $a$, $b$:\n\n$$\n\\frac{d}{dt}\\int_a^bu(x,t) = -\\left[f(u(b,t))-f(u(a,t))\\right]\n$$\nwhere $u(x,t)$ is called the conserved quantity while $f$ denotes the flux. This equation often describes the <font color=#75147c>transport phenomena</font>.\n\n{% note info %}\n\nYou can not create, you can not destroy.\n\n{% endnote %}\n\n#### Integral, differential conservative and primitive forms\n\n<img src=\"2D scalar convection control volume.png\" alt=\"2D scalar convection control volume\" style=\"zoom:48%;\" />\n\nThe 1D law can be extended in 2D with the relation, in <font color=#75147c>integral form</font>.\n$$\n\\frac{d}{d t} \\int_{\\Omega} \\mathbf{u} d \\Omega+\\int_{\\Gamma} \\mathbf{f}(\\mathbf{u}) \\cdot \\mathbf{n} d \\Gamma=0\n$$\n{% note info %}\n\nThe FVM and FEM solves the integral form, while the FDM solves the primitive form.\n\n{% endnote %}\n\nApply the Gauss divergence theorem the relation can be represented as <font color=#75147c>differential form</font>:\n$$\n\\begin{aligned}\n\\int_{\\Omega}\\left\\{\\frac{\\partial \\mathbf{u}}{\\partial t}+\\nabla \\cdot \\mathbf{f}(\\mathbf{u})\\right\\} d \\Omega=0&  \\\\ \n\\Rightarrow \n\\color{purple}{\n\\forall \\Omega,\\quad \\frac{\\partial \\mathbf{u}}{\\partial t}+\\nabla \\cdot \\mathbf{f}(\\mathbf{u})=0} &\n\\end{aligned}\n$$\nabove is called the <font color=#75147c>differential conservative form</font>. The only $u$ changed in time is due to the flux $f$. There is no extra assumptions introduced.\n\nIn comparison, with an assumption of $\\mathbf{a} =  \\frac{d\\mathbf{f}}{d\\mathbf{u}}$, the equation can be rewritten with the chain rule, as the <font color=#75147c>differential primitive form</font> :\n$$\n\\quad \\frac{\\partial \\mathbf{u}}{\\partial t}+\\mathbf{a}(\\mathbf{u})\\nabla \\cdot \\mathbf{u}=0, \\quad \\text{where }\\mathbf{a} =  \\frac{d\\mathbf{f}}{d\\mathbf{u}}\n$$\nThis form is identical to above in mathematics, but it will lead to problems numerically when dealing with discontinuities (to be discussed later).\n\n#### Rankine-Hugoniot Jump condition\n\n<img src=\"shock wave.png\" alt=\"1D jump discontinuity illustration\" style=\"zoom:70%;\" />\n\nWhen dealing with discontinuities, the integral form is well defined, but not the differential forms. The differential solvers can't deal with the drastic derivatives so instead they solve an extra <font color=#75147c>jump condition</font> which can be derived from the well-defined integral form (discussed later).\n\nFor an 1D jump discontinuity travelling at the speed $s$:\n$$\nf(u_r)-f(u_l) = s(u_r-u_s)\n$$\nwhere $u_r$, $u_l$ represent the speeds just at the left and the right of the discontinuity. \n\n### 1D Euler equations\n\nIts time to introduce the 1D Euler equations: NS equations with 0 viscosity or heat conduction terms:\n$$\n\\frac{\\partial}{\\partial t}\\left[\\begin{array}{l}\n\\rho \\\\\n\\rho u \\\\\n\\rho E\n\\end{array}\\right]+\\frac{\\partial}{\\partial x}\\left[\\begin{array}{l}\n\\rho u \\\\\n\\rho u^{2}+P \\\\\n\\rho u\\left(E+\\frac{P}{\\rho}\\right)\n\\end{array}\\right]=0\n$$\nAnd the conservation form is:\n$$\n\\frac{\\partial \\mathbf{q}}{\\partial t}+\\frac{\\partial \\mathbf{F}(\\mathbf{q})}{\\partial x}=0\n$$\nfor the quantity vector $\\mathbf{q}$ with the flux vector $\\mathbf{F}$.\n\n#### Conservation vs non-conservation form\n\nSimilar to before, with terms in a form of $\\partial_x{uv}$:\n$$\n\\frac{\\partial uv}{\\partial x} \\neq u\\frac{\\partial v}{\\partial x}+ v\\frac{\\partial u}{\\partial x}\n$$\nWhen dealing with the discontinuities, the conservative LHS locates the shock directly, while the non-conservative RHS does not. (to be discussed later)\n\n#### Close the Euler equation\n\nUnlike the well-posed NS equation, in Euler equation, we have 4 unknowns but only 3 equations. So an extra state equation, i.e. extra assumption of the gas state is needed. Sometimes it's the idea gas assumption $p = \\rho RT$, but for high $Re$ compressible flows, equations of state are required to describe the relation between $p, \\rho \\text{ and }T$.\n\n{% note primary %}\n\nWe are going to use the 1D Euler equations to evaluate the numerical methods.\n\n{% endnote %}\n\n### Analytical solutions of Euler equations\n\n#### Linear Advection Equation\n\nIn 1D, the linear advection law for $u(x,t)$ is:\n$$\n\\color{purple}\n\\frac{\\partial u }{\\partial t} + a(u)\\frac{\\partial u }{\\partial x} = 0\n$$\nwhere $a(u)$ denotes the advection speed. Plus an <font color=#75147c>initial condition</font> $u(x,0)$ and <font color=#75147c>boundary condition</font> (discuss later).\n\n##### solution\n\nThis is a simple 2-variable PDE and we can apply the method of characteristics:\n\n1. Imagine a characteristic line $s$, we have the chain rule:\n   $$\n   \\frac{d u(x,t)}{d s} = \\frac{d t}{d s}\\frac{\\partial u}{\\partial t} + \\frac{d x}{d s} \\frac{\\partial u}{\\partial x}\n   $$\n\n2. As a result we can construct, \n   $$\n   \\begin{aligned}\n   \\frac{d u(x,t)}{d s} = 0,\\quad\\frac{d t}{d s}=1, \\quad \\frac{d x}{d s}= a \\\\\n   \\Rightarrow \\quad \\frac{d u}{0}=\\frac{d t}{1}=\\frac{d x}{a}= d s\n   \\end{aligned}\n   $$\n\n3. Select the available equations we have the characteristic equation:\n   $$\n   \\begin{aligned}\n   \\frac{d x}{d t} &= a \\\\\n   \\Rightarrow\\quad x &= x_0 + a(u)t\n   \\end{aligned}\n   $$\n   If $u(x_0,0)=u_0$, then $\\frac{dx}{dt}=a(u_0)$, the characteristic equation is therefore:\n   $$\n   \\color{purple}\n   x = x_0 + a(u_0)t\n   $$\n\n4. And the solution to the problem is:\n   $$\n   u(x,t) = f(x_0) = f(x-a(u_0)t)\n   $$\n\n#### Linear Advection Equation Example\n\nSolve the following advection equation where $a = 0.5$\n$$\n\\frac{\\partial u}{\\partial t} + a \\frac{\\partial u}{\\partial x }= 0\n$$\nwith initial condition \n$$\nu(x,0) = exp(-32x^2)\n$$\n\n##### solution\n\nThe characteristics are straight lines in the $(x,t)$ plane:\n$$\nx = 0.5t+x_0\n$$\nAnd the solutions are therefore:\n$$\nu(x,t) = f(x_0) = exp(-32(x-0.5t)^2)\n$$\n<img src=\"Linear Advection Solutions.png\" alt=\"Linear Advection Characteristic Lines and Solutions, From my graduate course slides\" style=\"zoom:28%;\" />\n\n#### Inviscid Burgers' equation\n\nIn 1D, the inviscid Burgers' equation for $u(x,t)$ is:\n$$\n\\color{purple}\n\\frac{\\partial u }{\\partial t} + \\frac{f(u) }{\\partial x} = 0,\\quad\\text{where }f(u)=\\frac{1}{2}u^2\n$$\nThe conservative form for this equation\n$$\n\\frac{\\partial u }{\\partial t} + \\frac{\\partial(\\frac{1}{2}u^2) }{\\partial x} = 0\n$$\nand the primitive form:\n$$\n\\frac{\\partial u }{\\partial t} + u\\frac{\\partial u }{\\partial x} = 0\n$$\nsame form as the 1D linear advection equation with $a(u)=u$.\n\n#### Burgers' equation Example\n\nSolve the advection equation:\n$$\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }= 0\n$$\nwith initial condition:\n$$\nu(x,0) = 1-\\cos(x)\n$$\n\n##### solution\n\nSimilarly, the characteristics are described by:\n$$\nx = x_0 + ut\n$$\nand the solution:\n$$\nu = 1-\\cos(x-ut)\n$$\nwhich is *<u>implicit</u>*. It is can be plotted anyway:\n\n<img src=\"Inviscid Burgers' equation Solutions.png\" alt=\"Inviscid Burgers' equation Solutions, From my graduate course slides\" style=\"zoom:28%;\" />\n\n##### discussion\n\nFor non-linear conservation laws, the characteristics may cross within finite time.\nThis would suggest a multi-valued solution which does not make sense physically.\n\nWhere the characteristics start crossing, the solution become discontinuous. And the formation of discontinuities is possible even for smooth initial data. So the differential primitive form of the equations is no longer valid \n\n$\\Rightarrow$ only the integral form can deal with discontinuities. And the differential form can be completed by a <font color=#75147c>jump condition</font> derived from the integral form. \n\n$\\Rightarrow$ we need <font color=#75147c>weak solutions</font>. The mathematical theory of partial differential equations introduces the concept of weak solutions.\n\n### Rankine-Hugoniot condition\n\n#### The Riemann Problem\n\n{% note info %}\n\nIn order to understand the behaviour of the solution at discontinuities, it is useful to start with a simplified problem. \n\n{% endnote %}\n\nThe Riemann problem is a conservation law with a single discontinuity.\n$$\n\\color{purple}\n\\frac{\\partial u}{\\partial t} + \\frac{\\partial f(u)}{\\partial x} = 0\n$$\nwith\n$$\n\\color{purple}\nu(x, 0)= \\begin{cases}u_{L} & x \\leq 0 \\\\ u_{R} & x>0\\end{cases}\n$$\n<img src=\"Riemann problem illustration.png\" alt=\"Riemann problem illustration\" style=\"zoom:48%;\" />\n\n#### Shock Path\n\n<img src=\"shock path control volume.png\" alt=\"shock path control volume\" style=\"zoom:80%;\" />\n\nTake the control volume between boundaries $x_L$ and $x_R$, which are taken sufficient close to the shock so that spatial variations of the solution become unimportant. and are taken sufficient apart from the shock so that the boundary will note interfere with the shock motion over time interval $\\delta t$.\n\nRecall the integral function:\n$$\n\\frac{d}{dt}\\int_{x_L}^{x_R}udx = f(u_L)-f(u_R)\n$$\nIf the position of the shock is $x = X(t)$, with $x_L< X (t) <x_R$,  the values of $u(x,t)$ inside the integral are close to the constants $u_L$ and $u_R$ and we can write:\n$$\n\\begin{aligned}\n\\frac{d}{dt}\\int_{x_L}^{X}u_Ldx + \\frac{d}{dt}\\int_{X}^{x_R}u_Rdx= f(u_L)-f(u_R)\\\\\n\\frac{d}{dt}\\left[(x_L-X)u_L + (X-x_R)u_R\\right]= f(u_L)-f(u_R)\\\\\n\\end{aligned}\n$$\n\nGiven the shock speed (slope of the shock path) $s = \\frac{dX}{dt}$, we have:\n$$\n\\begin{aligned}\ns\\left(u_L - u_R\\right)&= f(u_L)-f(u_R)\\\\\n\\color{purple}\ns= \\frac{dX}{dt}&\\color{purple}\n= \\frac{f(u_L)-f(u_R)}{\\left(u_L - u_R\\right)}= \\frac{f(u_R)-f(u_L)}{\\left(u_R - u_L\\right)}\n\\end{aligned}\n$$\nThe equation above is the <font color=#75147c>Rankine-Hugoniot condition</font>, also called the \"jump condition\".\n\nCorrespondingly, <font color=#75147c>weak solutions</font> represents the solutions of the PDE where the solution is smooth and of a Rankine-Hugoniot condition at discontinuities. And they are <font color=#75147c>not unique</font>.\n\n{% note info %}\n\nStrong solution $\\Rightarrow$ weak solution\n\nWeak solution $\\nLeftarrow$ Strong solution\n\n{% endnote %}\n\n### Non-uniqueness of weak solutions\n\n#### Example of Riemann Problem with Burgers's equation\n\nConsider the [Burgers' equation](#inviscid-burgers-equation) under a [Riemann Problem](#the-riemann-problem):\n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&= 0, \\\\\n\\text{with }\nu(x, 0)&= \\begin{cases}1 & x \\leq 0 \\\\ 0 & x>0\\end{cases}\n\\end{aligned}\n$$\nThe characteristics are of the form: $x = x_0 + ut$ \n\nIn $x-t$ plane, the characteristics line:\n$$\n\\begin{cases} x = t - x_0 & x_0 \\leq 0 \\\\ x = x_0 & x_0 > 0\\end{cases}\n$$\nAnd the according to the Rankine-Hugonoit condition, the speed of the shock is:\n$$\ns = \\frac{f(u_L)-f(u_R)}{\\left(u_L - u_R\\right)}= \\frac{-1/2-0}{\\left(1-0\\right)} = \\frac{1}{2}\n$$\nand the shock path is:\n$$\nx = \\frac{1}{2} t\n$$\ntherefore,  the solution is:\n$$\nu(x,t) = \\begin{cases} 1 & x \\leq \\frac{1}{2}t \\\\ 0 & x> \\frac{1}{2}t\\end{cases}\n$$\n<img src=\"Burgers's equation under Riemann Problem with uL = 1, uR=0.png\" alt=\"General solution (left) and characteristics (right) of Burgers's equation under Riemann Problem. From my graduate course slides\" style=\"zoom:50%;\" />\n\n#### Upwind Riemann Problem with Burgers's equation\n\nFor the upwind case:\n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&= 0, \\\\\n\\text{with }\nu(x, 0)&= \\begin{cases}u_L & x \\leq 0 \\\\ u_R & x>0\\end{cases}\n\\end{aligned}\n$$\nwith $u_L>u_R$.\n\nAnd the shock is created with a speed:\n$$\ns = \\frac{1}{2}(u_R+u_L)\n$$\nand the solution:\n$$\nu(x,t) = \\begin{cases} u_L & x \\leq \\frac{1}{2}t \\\\ u_R & x> \\frac{1}{2}t\\end{cases}\n$$\n<img src=\"Burgers's equation under Riemann Problem general solution.png\" alt=\"Solution (left) and characteristics (right) of Burgers's equation under Riemann Problem with uL = 1, uR=0. From my graduate course slides\" style=\"zoom:50%;\" />\n\n#### Example of non-unique downwind Riemann Problem with Burgers's equation\n\nReverse the initial condition in the previous example:\n\n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&= 0, \\\\\n\\text{with }\nu(x, 0)&= \\begin{cases}0 & x \\leq 0 \\\\ 1 & x>0\\end{cases}\n\\end{aligned}\n$$\nthe characteristics become:\n\n<img src=\"Burgers's equation under Riemann Problem with uL = 0, uR=1.png\" alt=\"Solution (left) and characteristics (right) of Burgers's equation under Riemann Problem with uL = 1, uR=0. From my graduate course slides\" style=\"zoom:50%;\" />\n\nSolution in the blue area ($0<x<t$) is not defined. So here proposes 2 possible solutions, both are mathematical acceptable:\n\nSolution A:\n$$\nu(x, t)= \\begin{cases}0 & \\text { if } \\quad \\frac{x}{t}<s(=0.5) \\\\ 1 & \\text { if } \\quad \\frac{x}{t}>s(=0.5)\\end{cases}\n$$\n<img src=\"Expansion shock solution to the Riemann Problem.png\" alt=\"Expansion shock solution to the Riemann Problem\" style=\"zoom:50%;\" />\n\nSolution B:\n$$\nu(x, t)=\\left\\{\\begin{array}{ccc}\n0 & \\text { if } & \\frac{x}{t}<0 \\\\\n\\frac{x}{t} & \\text { if } & 0<\\frac{x}{t}<1 \\\\\n1 & \\text { if } & \\frac{x}{t}>1\n\\end{array}\\right.\n$$\n<img src=\"Rarefaction wave solution to the Riemann Problem.png\" alt=\"Rarefaction wave solution to the Riemann Problem\" style=\"zoom:50%;\" />\n\n{% note info %}\n\nA little spoiler alert there: Solution B is physical, discussed in the [next section](#non-uniqueness-and-entropy-conditions).\n\n{% endnote %}\n\n#### Exact solution to Riemann Problem with Burgers's equation\n\nIn conclusion,  \n\nFor the Riemann Problem with Burgers's equation:\n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&= 0, \\\\\n\\text{with }\nu(x, 0)&= \\begin{cases}u_L & x \\leq 0 \\\\ u_R & x>0\\end{cases}\n\\end{aligned}\n$$\n\n- with $u_L>u_R$\n\n  A shock wave is created with a speed:\n  $$\n  V_s = \\frac{u_L+u_R}{2}\n  $$\n  and the exact solution is:\n  $$\n  u(x, t)=\\left\\{\\begin{array}{ccc}\n  u_L & \\text { if } & \\frac{x}{t}\\leq V_s \\\\\n  u_R & \\text { if } & \\frac{x}{t}>V_s\n  \\end{array}\\right.\n  $$\n\n- with $u_L<u_R$\n\n  the exact solution is the rarefaction wave:\n  $$\n  u(x, t)=\\left\\{\\begin{array}{ccc}\n  u_L & \\text { if } & \\frac{x}{t}<0 \\\\\n  \\frac{x}{t} & \\text { if } & 0<\\frac{x}{t}<1 \\\\\n  u_R & \\text { if } & \\frac{x}{t}>1\n  \\end{array}\\right.\n  $$\n  if $u_L = -u_R$, we have a sonic rarefaction wave.\n\n### Entropy Conditions\n\nWhy solution A is wrong? we need to impose additional conditions. There are two ways.\n\n- Add a small diffusion term (2 <sup>nd</sup> order) manually on the RHS to remove the discontinuity. The weak solution then must satisfy:\n  $$\n  \\frac{\\partial u^\\epsilon}{\\partial t} + \\frac{\\partial f(u^\\epsilon)}{\\partial x} = \\epsilon\\frac{\\partial^2u^\\epsilon}{\\partial x^\\epsilon}\n  $$\n  where $\\epsilon$ is the <font color=#75147c>viscosity coefficient</font>, it introduces the dissipation, known as the vanishing viscosity concept, into the equation to smooth the solution. A little bit cheating but most of people do this.\n\n- Add the <font color=#75147c>entropy solution</font>\n\n  {% note info %}\n\n  I first hearted Entropy back in my undergraduate thermodynamic course. But I still don't know what is Entropy. So here are some answers:\n\n  In gas dynamics, entropy is a constant physical quantity along particles in smooth flow which can jump to a higher value through a shock.\n\n  The second law of thermodynamics says that entropy can never go down.\n\n  For an evolution equation the information should always flow from the initial data.\n\n  We can see it is very difficult to define it, but in order to translate the defination into the entropy condition, we see entropy as the extra amount of energy that is not available to the system.\n\n  {% endnote %}\n\n  There are again two options of entropy condition:\n\n  - <font color=#75147c>Convex (concave) fluxes / Lax entropy condition</font> \n    $$\n    f'(u_L) > s > f'(u_R)\n    $$\n    and the characteristics must run into the shock, not emerge from it.\n\n  - <font color=#75147c>Oleinik entropy condition</font>\n\n    Similar to Lax entropy condition, it says:\n    $$\n    \\frac{f(u)-f(u_L)}{u-u_L}\\geq s \\geq \\frac{f(u_R)-f(u)}{u_R-u}\n    $$\n\n  and Lax and Oleinik are equivalent if $f(u)$ is strictly convex i.e. $f''(u)<0$.\n\n## Numerical representation of discontinuities\n\n{% note info %}\n\nRequirements on numerical schemes. Conservative discretisation: Lax-Wendroff theorem. First versus second order schemes. Representation of discontinuities: physical aspects, shock fitting/capturing.\n\n{% endnote %}\n\n### Problems with Lax Equivalence Theorem\n\nThere are 3 fundamental properties of a numerical scheme:\n\n- Consistency: how good you approximate operators and functions.\n\n- Convergence: error between the exact and discrete solutions converges to zero.\n- Stability: solution of the difference equation is not too sensitive to small perturbations.\n\n\n\nThe convergence needs to be evaluated with exact solutions. So we always need analytical solutions to verify it. If we don't have access to the analytical solutions,  we have a <font color=#75147c>Lax Equivalence Theorem</font>says\n$$\n\\text{consistency + stability $\\Rightarrow$ convergence}\n$$\nIt is a fundamental convergence theorem but \n\n- it is valid <font color=#75147c>only for linear PDEs</font> and there is no non-linear equivalent theorem\n- this theorem <font color=#75147c>does not tell if the weak solution physically acceptable or not</font>.\n\nFor non-linear PDEs, we only have one experience, \n\nIf a scheme is stable on linear PDEs, it will often (not all the time) be stable on non-linear PDEs. If a scheme is unstable on linear, it won't be stable on non-linear.\n\nSo the work flow is, 1. Given a non-linear PDE, 2. Linearise it to explore the stabilities of schemes on it. 3. Test the winners on non-linear PDEs.\n\n### 1D linear convection equation\n\nFirst we consider a <font color=#75147c>linear</font> case, linear convection equation:\n$$\n\\frac{\\partial u}{\\partial t} + a\\frac{\\partial u}{\\partial x} = 0\n$$\nwith $a$ a positive scalar constant, representing the wave speed. So we have:\n$$\nf(u) = au\n$$\n\n##### Numerical scheme\n\ntry to solve it numerically, with finite difference, forward difference in time and central difference in space. we have:\n$$\n\\frac{u^{n+1}_i-u^n_i}{\\Delta t} + a \\frac{u^n_{i+1}-u^n_{i-1}}{2\\Delta x} = 0\n$$\n\n$$\nu^{n+1}_i = u^n_i - \\frac{a\\Delta t}{\\Delta x}\\left(\\frac{u^n_{i+1}-u^n_{i-1}}{2} \\right) = 0\n$$\n\nIt is consistency, and the Von Neumann analysis shows it is stable if the CFL condition (Courant number $a\\frac{\\Delta t}{\\Delta x}<1$) is satisfied. It should converge to the exact solution.\n\n##### Numerical practice\n\n\n\n\n\n## Systems of conservation laws\n\n{% note info %}\n\nJacobian matrices, linearized equations, conservative and characteristic variables.\nRankine-Hugoniot jump conditions. Boundary conditions.\n\n{% endnote%}\n\n\n\n## Numerical schemes for non-linear conservation laws\n\n{% note info %}\n\nIt is still an active research area and these are the classical methods:\n\nCentred schemes: one-step and two-step Lax Wendroff, MacCormack predictor-corrector. Artificial dissipation.\nUpwind schemes: flux vector and flux difference splitting. Monotone schemes: Godunov and Harten theorems. Exact and approximate Riemann solvers.\nHigh-order upwind schemes: the TVD property. The construction of TVD schemes using slope and flux limiters.\nWENO schemes: weighted essentially non-oscillatory methods\n\n{% endnote %}\n\n\n\n## Numerical schemes for multi-dimensional problems\n\n{% note info %}\n\nFinite differences and finite volume. Computational domain and boundary conditions.\n\n{% endnote %}\n\n\n\n## OpenFOAM demo on shockwave\n\n{% echarts 400 '85%' %}\nlet legends = ['exact', 'linear', 'upwind', 'linearUpwind', 'QUICK', 'TVD-vanLeer', 'TVD-Minmod', 'TVD-SuperBee']\nlet xaxis = [0.0005, 0.0015, 0.0025, 0.0035, 0.0045, 0.0055, 0.0065, 0.0075, 0.0085, 0.0095, 0.0105, 0.0115, 0.0125, 0.0135, 0.0145, 0.0155, 0.0165, 0.0175, 0.0185, 0.0195, 0.0205, 0.0215, 0.0225, 0.0235, 0.0245, 0.0255, 0.0265, 0.0275, 0.0285, 0.0295, 0.0305, 0.0315, 0.0325, 0.0335, 0.0345, 0.0355, 0.0365, 0.0375, 0.0385, 0.0395, 0.0405, 0.0415, 0.0425, 0.0435, 0.0445, 0.0455, 0.0465, 0.0475, 0.0485, 0.0495, 0.0505, 0.0515, 0.0525, 0.0535, 0.0545, 0.0555, 0.0565, 0.0575, 0.0585, 0.0595, 0.0605, 0.0615, 0.0625, 0.0635, 0.0645, 0.0655, 0.0665, 0.0675, 0.0685, 0.0695, 0.0705, 0.0715, 0.0725, 0.0735, 0.0745, 0.0755, 0.0765, 0.0775, 0.0785, 0.0795, 0.0805, 0.0815, 0.0825, 0.0835, 0.0845, 0.0855, 0.0865, 0.0875, 0.0885, 0.0895, 0.0905, 0.0915, 0.0925, 0.0935, 0.0945, 0.0955, 0.0965, 0.0975, 0.0985, 0.0995, 0.1005, 0.1015, 0.1025, 0.1035, 0.1045, 0.1055, 0.1065, 0.1075, 0.1085, 0.1095, 0.1105, 0.1115, 0.1125, 0.1135, 0.1145, 0.1155, 0.1165, 0.1175, 0.1185, 0.1195, 0.1205, 0.1215, 0.1225, 0.1235, 0.1245, 0.1255, 0.1265, 0.1275, 0.1285, 0.1295, 0.1305, 0.1315, 0.1325, 0.1335, 0.1345, 0.1355, 0.1365, 0.1375, 0.1385, 0.1395, 0.1405, 0.1415, 0.1425, 0.1435, 0.1445, 0.1455, 0.1465, 0.1475, 0.1485, 0.1495, 0.1505, 0.1515, 0.1525, 0.1535, 0.1545, 0.1555, 0.1565, 0.1575, 0.1585, 0.1595, 0.1605, 0.1615, 0.1625, 0.1635, 0.1645, 0.1655, 0.1665, 0.1675, 0.1685, 0.1695, 0.1705, 0.1715, 0.1725, 0.1735, 0.1745, 0.1755, 0.1765, 0.1775, 0.1785, 0.1795, 0.1805, 0.1815, 0.1825, 0.1835, 0.1845, 0.1855, 0.1865, 0.1875, 0.1885, 0.1895, 0.1905, 0.1915, 0.1925, 0.1935, 0.1945, 0.1955, 0.1965, 0.1975, 0.1985, 0.1995, 0.2005, 0.2015, 0.2025, 0.2035, 0.2045, 0.2055, 0.2065, 0.2075, 0.2085, 0.2095, 0.2105, 0.2115, 0.2125, 0.2135, 0.2145, 0.2155, 0.2165, 0.2175, 0.2185, 0.2195, 0.2205, 0.2215, 0.2225, 0.2235, 0.2245, 0.2255, 0.2265, 0.2275, 0.2285, 0.2295, 0.2305, 0.2315, 0.2325, 0.2335, 0.2345, 0.2355, 0.2365, 0.2375, 0.2385, 0.2395, 0.2405, 0.2415, 0.2425, 0.2435, 0.2445, 0.2455, 0.2465, 0.2475, 0.2485, 0.2495, 0.2505, 0.2515, 0.2525, 0.2535, 0.2545, 0.2555, 0.2565, 0.2575, 0.2585, 0.2595, 0.2605, 0.2615, 0.2625, 0.2635, 0.2645, 0.2655, 0.2665, 0.2675, 0.2685, 0.2695, 0.2705, 0.2715, 0.2725, 0.2735, 0.2745, 0.2755, 0.2765, 0.2775, 0.2785, 0.2795, 0.2805, 0.2815, 0.2825, 0.2835, 0.2845, 0.2855, 0.2865, 0.2875, 0.2885, 0.2895, 0.2905, 0.2915, 0.2925, 0.2935, 0.2945, 0.2955, 0.2965, 0.2975, 0.2985, 0.2995, 0.3005, 0.3015, 0.3025, 0.3035, 0.3045, 0.3055, 0.3065, 0.3075, 0.3085, 0.3095, 0.3105, 0.3115, 0.3125, 0.3135, 0.3145, 0.3155, 0.3165, 0.3175, 0.3185, 0.3195, 0.3205, 0.3215, 0.3225, 0.3235, 0.3245, 0.3255, 0.3265, 0.3275, 0.3285, 0.3295, 0.3305, 0.3315, 0.3325, 0.3335, 0.3345, 0.3355, 0.3365, 0.3375, 0.3385, 0.3395, 0.3405, 0.3415, 0.3425, 0.3435, 0.3445, 0.3455, 0.3465, 0.3475, 0.3485, 0.3495, 0.3505, 0.3515, 0.3525, 0.3535, 0.3545, 0.3555, 0.3565, 0.3575, 0.3585, 0.3595, 0.3605, 0.3615, 0.3625, 0.3635, 0.3645, 0.3655, 0.3665, 0.3675, 0.3685, 0.3695, 0.3705, 0.3715, 0.3725, 0.3735, 0.3745, 0.3755, 0.3765, 0.3775, 0.3785, 0.3795, 0.3805, 0.3815, 0.3825, 0.3835, 0.3845, 0.3855, 0.3865, 0.3875, 0.3885, 0.3895, 0.3905, 0.3915, 0.3925, 0.3935, 0.3945, 0.3955, 0.3965, 0.3975, 0.3985, 0.3995, 0.4005, 0.4015, 0.4025, 0.4035, 0.4045, 0.4055, 0.4065, 0.4075, 0.4085, 0.4095, 0.4105, 0.4115, 0.4125, 0.4135, 0.4145, 0.4155, 0.4165, 0.4175, 0.4185, 0.4195, 0.4205, 0.4215, 0.4225, 0.4235, 0.4245, 0.4255, 0.4265, 0.4275, 0.4285, 0.4295, 0.4305, 0.4315, 0.4325, 0.4335, 0.4345, 0.4355, 0.4365, 0.4375, 0.4385, 0.4395, 0.4405, 0.4415, 0.4425, 0.4435, 0.4445, 0.4455, 0.4465, 0.4475, 0.4485, 0.4495, 0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585, 0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675, 0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765, 0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855, 0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945, 0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035, 0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125, 0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215, 0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305, 0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395, 0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485, 0.5495, 0.5505, 0.5515, 0.5525, 0.5535, 0.5545, 0.5555, 0.5565, 0.5575, 0.5585, 0.5595, 0.5605, 0.5615, 0.5625, 0.5635, 0.5645, 0.5655, 0.5665, 0.5675, 0.5685, 0.5695, 0.5705, 0.5715, 0.5725, 0.5735, 0.5745, 0.5755, 0.5765, 0.5775, 0.5785, 0.5795, 0.5805, 0.5815, 0.5825, 0.5835, 0.5845, 0.5855, 0.5865, 0.5875, 0.5885, 0.5895, 0.5905, 0.5915, 0.5925, 0.5935, 0.5945, 0.5955, 0.5965, 0.5975, 0.5985, 0.5995, 0.6005, 0.6015, 0.6025, 0.6035, 0.6045, 0.6055, 0.6065, 0.6075, 0.6085, 0.6095, 0.6105, 0.6115, 0.6125, 0.6135, 0.6145, 0.6155, 0.6165, 0.6175, 0.6185, 0.6195, 0.6205, 0.6215, 0.6225, 0.6235, 0.6245, 0.6255, 0.6265, 0.6275, 0.6285, 0.6295, 0.6305, 0.6315, 0.6325, 0.6335, 0.6345, 0.6355, 0.6365, 0.6375, 0.6385, 0.6395, 0.6405, 0.6415, 0.6425, 0.6435, 0.6445, 0.6455, 0.6465, 0.6475, 0.6485, 0.6495, 0.6505, 0.6515, 0.6525, 0.6535, 0.6545, 0.6555, 0.6565, 0.6575, 0.6585, 0.6595, 0.6605, 0.6615, 0.6625, 0.6635, 0.6645, 0.6655, 0.6665, 0.6675, 0.6685, 0.6695, 0.6705, 0.6715, 0.6725, 0.6735, 0.6745, 0.6755, 0.6765, 0.6775, 0.6785, 0.6795, 0.6805, 0.6815, 0.6825, 0.6835, 0.6845, 0.6855, 0.6865, 0.6875, 0.6885, 0.6895, 0.6905, 0.6915, 0.6925, 0.6935, 0.6945, 0.6955, 0.6965, 0.6975, 0.6985, 0.6995, 0.7005, 0.7015, 0.7025, 0.7035, 0.7045, 0.7055, 0.7065, 0.7075, 0.7085, 0.7095, 0.7105, 0.7115, 0.7125, 0.7135, 0.7145, 0.7155, 0.7165, 0.7175, 0.7185, 0.7195, 0.7205, 0.7215, 0.7225, 0.7235, 0.7245, 0.7255, 0.7265, 0.7275, 0.7285, 0.7295, 0.7305, 0.7315, 0.7325, 0.7335, 0.7345, 0.7355, 0.7365, 0.7375, 0.7385, 0.7395, 0.7405, 0.7415, 0.7425, 0.7435, 0.7445, 0.7455, 0.7465, 0.7475, 0.7485, 0.7495, 0.7505, 0.7515, 0.7525, 0.7535, 0.7545, 0.7555, 0.7565, 0.7575, 0.7585, 0.7595, 0.7605, 0.7615, 0.7625, 0.7635, 0.7645, 0.7655, 0.7665, 0.7675, 0.7685, 0.7695, 0.7705, 0.7715, 0.7725, 0.7735, 0.7745, 0.7755, 0.7765, 0.7775, 0.7785, 0.7795, 0.7805, 0.7815, 0.7825, 0.7835, 0.7845, 0.7855, 0.7865, 0.7875, 0.7885, 0.7895, 0.7905, 0.7915, 0.7925, 0.7935, 0.7945, 0.7955, 0.7965, 0.7975, 0.7985, 0.7995, 0.8005, 0.8015, 0.8025, 0.8035, 0.8045, 0.8055, 0.8065, 0.8075, 0.8085, 0.8095, 0.8105, 0.8115, 0.8125, 0.8135, 0.8145, 0.8155, 0.8165, 0.8175, 0.8185, 0.8195, 0.8205, 0.8215, 0.8225, 0.8235, 0.8245, 0.8255, 0.8265, 0.8275, 0.8285, 0.8295, 0.8305, 0.8315, 0.8325, 0.8335, 0.8345, 0.8355, 0.8365, 0.8375, 0.8385, 0.8395, 0.8405, 0.8415, 0.8425, 0.8435, 0.8445, 0.8455, 0.8465, 0.8475, 0.8485, 0.8495, 0.8505, 0.8515, 0.8525, 0.8535, 0.8545, 0.8555, 0.8565, 0.8575, 0.8585, 0.8595, 0.8605, 0.8615, 0.8625, 0.8635, 0.8645, 0.8655, 0.8665, 0.8675, 0.8685, 0.8695, 0.8705, 0.8715, 0.8725, 0.8735, 0.8745, 0.8755, 0.8765, 0.8775, 0.8785, 0.8795, 0.8805, 0.8815, 0.8825, 0.8835, 0.8845, 0.8855, 0.8865, 0.8875, 0.8885, 0.8895, 0.8905, 0.8915, 0.8925, 0.8935, 0.8945, 0.8955, 0.8965, 0.8975, 0.8985, 0.8995, 0.9005, 0.9015, 0.9025, 0.9035, 0.9045, 0.9055, 0.9065, 0.9075, 0.9085, 0.9095, 0.9105, 0.9115, 0.9125, 0.9135, 0.9145, 0.9155, 0.9165, 0.9175, 0.9185, 0.9195, 0.9205, 0.9215, 0.9225, 0.9235, 0.9245, 0.9255, 0.9265, 0.9275, 0.9285, 0.9295, 0.9305, 0.9315, 0.9325, 0.9335, 0.9345, 0.9355, 0.9365, 0.9375, 0.9385, 0.9395, 0.9405, 0.9415, 0.9425, 0.9435, 0.9445, 0.9455, 0.9465, 0.9475, 0.9485, 0.9495, 0.9505, 0.9515, 0.9525, 0.9535, 0.9545, 0.9555, 0.9565, 0.9575, 0.9585, 0.9595, 0.9605, 0.9615, 0.9625, 0.9635, 0.9645, 0.9655, 0.9665, 0.9675, 0.9685, 0.9695, 0.9705, 0.9715, 0.9725, 0.9735, 0.9745, 0.9755, 0.9765, 0.9775, 0.9785, 0.9795, 0.9805, 0.9815, 0.9825, 0.9835, 0.9845, 0.9855, 0.9865, 0.9875, 0.9885, 0.9895, 0.9905, 0.9915, 0.9925, 0.9935, 0.9945, 0.9955, 0.9965, 0.9975, 0.9985, 0.9995];\nlet data0 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0068466305166028, 0.01517996384993614, 0.023513297183269482, 0.031846630516602824, 0.04017996384993616, 0.04851329718326951, 0.056846630516602846, 0.06517996384993618, 0.07351329718326953, 0.08184663051660288, 0.0901799638499362, 0.09851329718326955, 0.1068466305166029, 0.11517996384993623, 0.12351329718326957, 0.13184663051660292, 0.14017996384993625, 0.1485132971832696, 0.15684663051660286, 0.1651799638499362, 0.17351329718326952, 0.18184663051660288, 0.1901799638499362, 0.19851329718326954, 0.2068466305166029, 0.21517996384993623, 0.22351329718326957, 0.23184663051660293, 0.24017996384993626, 0.2485132971832696, 0.25684663051660295, 0.2651799638499363, 0.2735132971832696, 0.28184663051660297, 0.29017996384993583, 0.2985132971832692, 0.30684663051660255, 0.31517996384993585, 0.3235132971832692, 0.33184663051660257, 0.3401799638499359, 0.34851329718326923, 0.3568466305166026, 0.3651799638499359, 0.37351329718326925, 0.3818466305166026, 0.3901799638499359, 0.3985132971832693, 0.40684663051660264, 0.41517996384993594, 0.4235132971832693, 0.43184663051660266, 0.44017996384993596, 0.4485132971832693, 0.4568466305166027, 0.465179963849936, 0.47351329718326934, 0.4818466305166027, 0.490179963849936, 0.49851329718326937, 0.5068466305166027, 0.515179963849936, 0.5235132971832694, 0.5318466305166027, 0.540179963849936, 0.5485132971832695, 0.5568466305166028, 0.5651799638499361, 0.5735132971832695, 0.5818466305166028, 0.5901799638499361, 0.5985132971832695, 0.6068466305166028, 0.6151799638499361, 0.6235132971832695, 0.6318466305166028, 0.6401799638499361, 0.6485132971832696, 0.6568466305166029, 0.6651799638499362, 0.6735132971832696, 0.6818466305166029, 0.6901799638499362, 0.6985132971832696, 0.7068466305166029, 0.7151799638499362, 0.7235132971832696, 0.7318466305166029, 0.7401799638499362, 0.7485132971832696, 0.756846630516603, 0.7651799638499363, 0.7735132971832697, 0.781846630516603, 0.7901799638499363, 0.7985132971832697, 0.806846630516603, 0.8151799638499363, 0.8235132971832692, 0.8318466305166026, 0.840179963849936, 0.8485132971832692, 0.8568466305166027, 0.8651799638499358, 0.8735132971832693, 0.8818466305166025, 0.890179963849936, 0.8985132971832692, 0.9068466305166027, 0.9151799638499358, 0.9235132971832694, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];\nlet data1 = [4.7497782e-21, 1.2236753e-11, 1.4130822e-11, 1.4288661e-11, 3.4924231e-11, 2.9147543e-11, 3.5115528e-11, 4.4161819e-11, 3.215849e-11, 5.8045656e-11, 5.6981576e-11, 7.4404121e-11, 5.3422194e-11, 5.1797341e-11, 3.9958742e-11, 4.3513123e-11, 4.3012595e-11, 2.8551867e-11, 1.0164615e-11, 3.6251191e-11, 1.5676756e-11, 4.3760219e-11, 2.087822e-11, 3.2388469e-11, 1.0404042e-13, 2.2323671e-11, 5.9775439e-12, 1.5878278e-11, 2.5413204e-12, 1.3496131e-11, 9.0037193e-12, 6.4866305e-12, 3.0908672e-12, 9.3806435e-12, 1.8018999e-11, 3.9618166e-11, 3.3207453e-11, 3.636568e-11, 1.6921461e-11, 2.4158606e-11, 1.5541036e-11, 2.1612839e-11, 2.2662135e-12, 3.6244967e-11, 2.1388863e-11, 4.0860982e-11, 2.0243752e-11, 4.4159152e-11, 3.7287927e-11, 4.503816e-11, 4.2794622e-11, 3.2505514e-11, 3.5482004e-11, 3.3629729e-11, 5.203321e-11, 3.059744e-11, 3.5895609e-11, 2.4423153e-11, 2.8592995e-11, 9.0477364e-12, 1.1918963e-11, 1.11291e-11, 9.5233656e-12, 1.9686646e-11, 1.4684259e-11, 1.0456061e-11, 1.326493e-11, 1.6252424e-11, 1.8960364e-11, 1.2528977e-11, 1.0733391e-11, 7.5758314e-12, 1.6704377e-11, 3.1431097e-12, 2.2738832e-12, 1.7303387e-12, 6.4157141e-12, 6.9744867e-12, 1.1955532e-11, 1.2810531e-12, 2.9376966e-12, 5.1365506e-12, 6.5088614e-12, 5.6347441e-12, 8.9720403e-12, 5.0112797e-12, 1.8458058e-11, 3.0491843e-12, 6.0556854e-12, 1.5169225e-12, 1.0354577e-11, 1.6511413e-11, 1.0133936e-12, 1.1652192e-11, 3.9020711e-12, 7.5887253e-12, 1.191296e-11, 1.6945582e-11, 6.168507e-12, 3.7362289e-12, 1.430978e-11, 1.3481458e-11, 1.6208962e-11, 1.5379529e-11, 1.7487792e-11, 1.6227303e-11, 2.3599166e-11, 2.3986428e-11, 2.2877441e-11, 2.8995818e-11, 2.9717098e-12, 1.2812643e-11, 3.9682079e-12, 8.8532164e-12, 1.4168058e-11, 1.9919292e-11, 2.080119e-11, 3.3138871e-11, 2.4218295e-11, 2.2538532e-11, 1.2056572e-11, 2.2702373e-11, 2.0471618e-11, 2.1337621e-11, 9.2228044e-12, 1.1923409e-11, 1.0586334e-12, 7.2505939e-13, 2.3409092e-13, 9.9634254e-12, 1.9138767e-11, 2.1332952e-11, 3.4972806e-11, 1.2183732e-11, 2.5995097e-11, 4.4557306e-12, 1.2136936e-11, 5.6049548e-12, 2.6847761e-11, 8.9601469e-13, 2.9922622e-11, 2.5058955e-11, 1.8621566e-11, 9.110872e-12, 1.7125318e-11, 1.9371191e-11, 1.1349964e-12, 1.0734169e-12, 3.3798683e-12, 2.0197289e-11, 9.8479361e-12, 8.9555895e-12, 4.0984808e-12, 1.52756e-11, 2.0106143e-11, 4.3018931e-12, 3.1851594e-11, 1.9488014e-11, 2.5790573e-11, 1.2311893e-11, 1.3165891e-11, 4.6352448e-12, 1.1384311e-11, 5.0336217e-12, 4.7395075e-12, 1.0127489e-11, 2.3451887e-11, 2.9249694e-11, 2.1945746e-11, 2.2225633e-11, 8.1962946e-12, 3.4067677e-12, 1.1086306e-11, 1.9424656e-11, 1.276318e-11, 4.0311213e-11, 4.1533465e-11, 2.0941134e-11, 3.2442712e-11, 1.8077688e-11, 3.7180997e-11, 1.4652802e-11, 1.8750616e-11, 1.1626293e-11, 3.7798014e-12, 3.7143316e-12, 1.4391923e-11, 4.6232401e-12, 1.3459005e-11, 6.2703243e-12, 1.3369415e-11, 2.2801078e-12, 1.1086528e-11, 1.4684592e-12, 1.151425e-11, 1.0592781e-11, 2.7326391e-11, 1.7531254e-11, 1.7685202e-11, 5.8771716e-12, 4.6834857e-12, 1.7814919e-11, 1.283832e-13, 2.6063234e-11, 8.4499487e-12, 3.4453048e-11, 2.7307051e-11, 2.5739331e-11, 2.6164607e-11, 1.5238919e-11, 2.7857709e-11, 2.8230743e-11, 2.3899394e-11, 4.5124193e-11, 2.07684e-11, 2.5994874e-11, 1.2769738e-11, 7.5410401e-12, 4.1377182e-12, 9.3713065e-12, 7.1242115e-12, 1.8334232e-11, 3.5548474e-11, 1.4479624e-11, 2.4772844e-11, 3.0732159e-11, 2.7721323e-11, 2.8178611e-11, 2.0658579e-11, 3.5832584e-11, 3.0355346e-11, 2.908852e-11, 2.9166884e-12, 2.6237079e-11, 1.2974706e-11, 2.4185616e-11, 1.540943e-11, 2.5027499e-11, 5.3102848e-12, 2.6987816e-11, 2.0652577e-11, 3.3621837e-11, 2.9035055e-11, 3.0026996e-11, 1.9403536e-11, 2.2531196e-11, 2.1464448e-11, 1.056188e-11, 1.4717828e-11, 4.7268359e-12, 1.2038342e-11, 8.5823334e-12, 1.8288437e-11, 1.9149215e-11, 8.5026358e-12, 1.7856269e-11, 6.8202046e-12, 1.0678592e-12, 1.3995325e-11, 1.7243698e-11, 2.3217129e-11, 1.1335292e-11, 1.1618179e-11, 5.3917608e-12, 2.3009937e-11, 1.0752732e-11, 3.0797629e-11, 1.3905401e-11, 2.3099861e-11, 8.8703342e-12, 1.6012664e-11, 1.2647023e-11, 1.0079582e-11, 1.6073021e-11, 2.722613e-12, 2.6127481e-11, 1.3952975e-11, 5.9724308e-12, 7.044625e-12, 1.5309391e-11, 1.3658194e-11, 8.9471418e-12, 2.529249e-11, 4.328459e-12, 2.3591385e-11, 5.059743e-12, 1.1537704e-11, 1.247918e-11, 9.452338e-12, 2.4481175e-11, 2.0175058e-11, 2.3537142e-11, 6.6256846e-11, 6.1706634e-11, 1.2504701e-10, 1.3924097e-10, 2.4660067e-10, 3.2732035e-10, 5.094611e-10, 7.2167552e-10, 1.0844473e-09, 1.5062619e-09, 2.1630591e-09, 3.0315697e-09, 4.2715788e-09, 5.9608509e-09, 8.3437843e-09, 1.1625095e-08, 1.6157491e-08, 2.237713e-08, 3.0939687e-08, 4.2591514e-08, 5.8554935e-08, 8.0188008e-08, 1.0956633e-07, 1.4918876e-07, 2.027e-07, 2.7453773e-07, 3.7079022e-07, 4.9929447e-07, 6.7032184e-07, 8.9726275e-07, 1.1974227e-06, 1.5931029e-06, 2.1130083e-06, 2.7938138e-06, 3.6823602e-06, 4.8380822e-06, 6.336126e-06, 8.27101e-06, 1.0761312e-05, 1.3954958e-05, 1.8035783e-05, 2.3230923e-05, 2.9820083e-05, 3.8145661e-05, 4.8625074e-05, 6.1764365e-05, 7.8173982e-05, 9.8586305e-05, 0.00012387544, 0.00015507864, 0.0001934198, 0.00024033476, 0.0002974976, 0.00036684837, 0.00045062101, 0.00055137138, 0.00067200382, 0.00081579642, 0.00098642278, 0.0011879702, 0.0014249526, 0.0017023168, 0.002025442, 0.0024001302, 0.0028325882, 0.0033293991, 0.0038974847, 0.0045440572, 0.005276562, 0.0061026118, 0.0070299137, 0.0080661894, 0.0092190931, 0.010496126, 0.011904552, 0.013451315, 0.015142962, 0.016985572, 0.018984691, 0.021145281, 0.023471678, 0.025967555, 0.028635909, 0.031479046, 0.034498587, 0.037695476, 0.041070007, 0.044621845, 0.04835007, 0.052253211, 0.056329295, 0.060575892, 0.064990167, 0.069568924, 0.074308664, 0.079205625, 0.084255833, 0.089455144, 0.094799285, 0.10028389, 0.10590454, 0.11165678, 0.11753617, 0.12353828, 0.12965873, 0.13589322, 0.14223751, 0.14868746, 0.15523903, 0.1618883, 0.16863145, 0.1754648, 0.18238479, 0.18938797, 0.19647105, 0.20363084, 0.21086428, 0.21816844, 0.22554052, 0.23297781, 0.24047775, 0.24803786, 0.2556558, 0.2633293, 0.27105622, 0.27883449, 0.28666216, 0.29453734, 0.30245824, 0.31042314, 0.31843041, 0.32647848, 0.33456586, 0.3426911, 0.35085286, 0.35904979, 0.36728075, 0.37554428, 0.38383987, 0.39216506, 0.40052173, 0.40890302, 0.41731947, 0.42574855, 0.43422869, 0.44269034, 0.45124763, 0.45971518, 0.46837279, 0.47681342, 0.48558203, 0.49399581, 0.50280125, 0.51131554, 0.51987967, 0.52886102, 0.53664995, 0.54668062, 0.55314771, 0.56469983, 0.56982903, 0.5827048, 0.58713623, 0.59985871, 0.60559039, 0.61618948, 0.62421812, 0.63250928, 0.64190155, 0.64973676, 0.65867379, 0.66728178, 0.67543557, 0.68436249, 0.69251268, 0.70116246, 0.70940041, 0.71803499, 0.72591586, 0.73465007, 0.7421754, 0.75064661, 0.75785453, 0.76589282, 0.77257401, 0.78002765, 0.78616575, 0.79272695, 0.79838116, 0.80388596, 0.80906539, 0.81353354, 0.81825345, 0.82185202, 0.82608446, 0.82915378, 0.83282197, 0.83569667, 0.83878624, 0.84172396, 0.84429782, 0.84742436, 0.84965847, 0.85300593, 0.85521123, 0.85880565, 0.86132943, 0.86516801, 0.86828684, 0.8723899, 0.87638194, 0.88097185, 0.88619249, 0.89157407, 0.89817, 0.90433351, 0.91190589, 0.91831494, 0.92592112, 0.9316993, 0.9380621, 0.94212677, 0.94587885, 0.94717707, 0.94742498, 0.94767951, 0.94780527, 0.94803564, 0.94820734, 0.94830276, 0.94855132, 0.94874752, 0.94888718, 0.94845965, 0.94872855, 0.94879579, 0.94921478, 0.94945263, 0.94948663, 0.95001979, 0.9507142, 0.94977329, 0.95073316, 0.95280442, 0.94948042, 0.95051732, 0.95976221, 0.94700999, 0.92703429, 0.92353142, 0.92139847, 0.92149921, 0.92694969, 0.93111875, 0.93134918, 0.93179552, 0.9317036, 0.93019943, 0.92913487, 0.92907245, 0.92909259, 0.9291059, 0.9291442, 0.92915769, 0.92922451, 0.92924203, 0.92911433, 0.92899133, 0.92898409, 0.92899886, 0.92900657, 0.92900604, 0.92900255, 0.92900176, 0.92900006, 0.92899903, 0.92899627, 0.92899873, 0.92900462, 0.9290154, 0.92902768, 0.92904411, 0.92906035, 0.9290786, 0.92909653, 0.9291185, 0.92914032, 0.92916527, 0.92919056, 0.9292208, 0.92925171, 0.92928876, 0.92933076, 0.92937489, 0.92942012, 0.92947584, 0.92953381, 0.9295991, 0.92966776, 0.92974198, 0.92981911, 0.92989924, 0.92998185, 0.93006832, 0.93015723, 0.930241, 0.93032401, 0.93040384, 0.93048168, 0.93054887, 0.93061051, 0.93066871, 0.93073158, 0.93079108, 0.93084464, 0.93089778, 0.93094338, 0.93099075, 0.93103015, 0.93107199, 0.93110975, 0.93114968, 0.93118829, 0.93122538, 0.93126367, 0.93129719, 0.93133572, 0.93136851, 0.93140868, 0.93144301, 0.93148121, 0.93151575, 0.93155226, 0.93158905, 0.93162476, 0.93166393, 0.93169731, 0.93173935, 0.93177342, 0.9318156, 0.93185112, 0.93189142, 0.93192729, 0.93196446, 0.93200387, 0.93203979, 0.93208172, 0.93211479, 0.93215424, 0.93218187, 0.93221582, 0.93224005, 0.9322631, 0.93227917, 0.93228247, 0.93227121, 0.93224052, 0.93218199, 0.93208667, 0.93194139, 0.93172852, 0.9314245, 0.93099797, 0.93040702, 0.92959603, 0.92849123, 0.92699517, 0.92497967, 0.92227668, 0.91866727, 0.91386765, 0.90751276, 0.89913639, 0.88814896, 0.87381251, 0.85521555, 0.83125048, 0.80060084, 0.76175515, 0.71307468, 0.65297275, 0.58034371, 0.49543106, 0.40111096, 0.30400643, 0.21385279, 0.13973194, 0.085672249, 0.050029818, 0.028248231, 0.01561467, 0.0085251238, 0.0046229516, 0.0024979795, 0.0013473218, 0.00072604692, 0.00039108398, 0.00021061359, 0.00011341244, 6.1068151e-05, 3.2881948e-05, 1.7704928e-05, 9.5328448e-06, 5.1327199e-06, 2.7634876e-06, 1.487836e-06, 8.0098752e-07, 4.3120483e-07, 2.3210337e-07, 1.2492882e-07, 6.7187527e-08, 3.6127854e-08, 1.9352349e-08, 1.0404359e-08, 5.5210503e-09, 2.9529626e-09, 1.5346396e-09, 7.9428198e-10, 3.6861033e-10, 1.2419183e-10, 4.3436841e-11, 1.3257637e-11, 1.4870166e-11, 1.0206285e-11, 2.4490177e-11, 2.4370081e-11, 1.9556357e-11, 3.4978943e-11, 2.4217574e-11, 2.8594202e-11, 2.1797559e-11, 2.6848701e-11, 2.4967454e-11, 4.3702007e-11, 1.6981616e-11, 1.2151798e-11, 3.6970075e-12, 3.3598392e-11, 6.8825519e-12, 2.0689279e-11, 1.3582629e-11, 3.5937048e-11, 2.1156788e-11, 3.1031754e-11, 3.8754867e-11, 5.7551244e-11, 1.2017272e-11, 3.1834355e-12, 7.7792771e-12, 5.2228499e-12, 8.825401e-12, 2.2278166e-11, 2.3018056e-11, 1.0137468e-11, 2.6215477e-11, 1.8272039e-11, 1.0712309e-11, 7.3875772e-12, 1.0804989e-11, 8.8561465e-12, 3.9837509e-11, 2.3096973e-11, 6.3352043e-11, 2.9827795e-11, 7.8074697e-11, 3.5060857e-11, 6.8725291e-11, 6.4160861e-11, 4.8119258e-11, 4.3734306e-11, 5.0335154e-11, 8.2433787e-11, 2.8126692e-11, 5.3756784e-11, 1.8430428e-11, 2.9340196e-11, 3.4874053e-11, 1.5347553e-11, 1.4757284e-11, 2.7799813e-11, 5.3875659e-12, 1.7271756e-11, 2.7111536e-11, 1.7808525e-11, 1.3187377e-11, 6.0115774e-12, 2.0383045e-11, 3.0349248e-11, 6.6302612e-12, 1.3277616e-11, 1.5641245e-11, 2.5366146e-11, 1.2476235e-11, 1.1086805e-11, 9.6080238e-12, 2.9373495e-11, 5.0011937e-12, 3.4103085e-12, 7.4496232e-12, 2.1377889e-11, 1.5513601e-11, 3.2097745e-11, 2.0315671e-11, 1.5045981e-11, 6.3766385e-13, 5.3094257e-12, 2.071847e-11, 6.0062497e-12, 5.9049116e-12, 4.2392826e-11, 1.8420105e-11, 2.1885356e-11, 8.4259315e-12, 2.8205943e-11, 2.5683036e-12, 2.7446629e-11, 3.480124e-12, 3.6805801e-13, 3.8837336e-11, 8.7038619e-12, 2.6307602e-11, 1.5869117e-11, 7.3966789e-13, 1.2958395e-11, 1.394325e-11, 4.6496739e-12, 1.5903303e-11, 2.8199838e-11, 2.5214417e-11, 8.5717784e-12, 2.6207041e-11, 6.0112444e-12, 4.0859325e-11, 2.4191602e-11, 3.8050274e-11, 2.4840254e-11, 2.8883342e-11, 2.9577836e-12, 8.4301493e-12, 1.0224377e-11, 2.481528e-11, 2.9430213e-11, 1.1148851e-11, 2.2952014e-11, 5.6299781e-12, 2.6766898e-11, 4.9046285e-12, 5.1555983e-11, 1.0087076e-11, 4.4939041e-11, 1.4179447e-11, 2.3963397e-11, 2.3591898e-12, 1.9854821e-11, 1.3202472e-11, 3.1101791e-11, 1.3970666e-11, 2.8291852e-11, 3.9392531e-11, 1.6398339e-12, 1.9717077e-12, 3.3493946e-11, 1.4251482e-11, 2.225519e-11, 3.5135667e-11, 3.6623549e-11, 5.2043471e-11, 2.0132197e-11, 1.4937762e-11, 7.5046765e-12, 1.3253197e-11, 5.6778167e-12, 1.659369e-11, 7.4506221e-12, 8.1147027e-12, 1.4139045e-11, 2.3932651e-12, 4.2783971e-12, 2.1105952e-11, 5.3867889e-12, 1.8312441e-11, 9.8047062e-12, 9.3391949e-12, 3.6215311e-12, 1.3048523e-11, 4.0050618e-11, 1.8217429e-11, 1.684487e-11, 2.7428204e-11, 1.2258796e-11, 2.2140089e-11, 2.0840342e-11, 4.178391e-12, 1.6649631e-11, 1.2855725e-11, 3.9175537e-12, 1.789277e-11, 2.852261e-11, 3.6098545e-11, 6.5570048e-12, 3.2203301e-11, 9.8111439e-12, 1.2932422e-11, 2.8110487e-12, 1.2827977e-11, 7.5176629e-12, 2.5976061e-11, 2.329077e-11, 3.8056933e-11, 4.690975e-11, 3.7367213e-11, 5.2457148e-11, 3.9460349e-11, 4.9403576e-11, 6.3205752e-11, 7.2271235e-11, 4.9367614e-11, 4.5474479e-11, 1.1120325e-11, 1.9082965e-11, 9.2018946e-12, 2.3865167e-11, 4.1185538e-11, 3.977624e-11, 1.6751302e-11, 8.4957471e-12, 3.4906463e-11, 2.2628576e-11, 2.4532244e-11, 4.0878083e-11, 4.5074011e-11, 1.5930275e-11, 8.4807628e-12, 2.2477734e-11, 9.4470816e-12, 3.760119e-11, 2.9787615e-12, 4.1064887e-11, 1.2349257e-12, 2.1885134e-11, 1.5716833e-12, 8.662683e-12, 1.085083e-11, 6.3942867e-12, 1.9193516e-11, 3.2279888e-11, 2.5822778e-11, 4.105412e-11, 1.8547638e-11, 2.2644559e-11, 4.7690819e-11, 2.1394316e-11, 6.6005036e-11, 9.6874959e-12, 1.498449e-11, 1.0487767e-11, 4.0695719e-11, 5.1100795e-12, 3.0456913e-13, 2.4637023e-11, 3.9656476e-11, 2.8627056e-11, 5.2256026e-11, 2.4325572e-11, 3.5351108e-11, 3.4459932e-11, 2.6888215e-11, 3.1180264e-11, 7.3392391e-11, 4.5273468e-11, 2.3238491e-11, 4.5416429e-11, 4.9126201e-12, 6.8129583e-12, 4.7035063e-12, 8.8010932e-12, 3.6449177e-11, 3.57498e-11, 6.8845498e-11, 6.3584799e-11, 6.4005468e-11, 4.7890387e-11, 4.5425864e-11, 3.9753042e-11, 5.3676979e-11, 7.4143047e-11, 5.9449474e-11, 7.5752469e-11, 7.8523892e-11, 5.5389292e-11, 6.6257437e-11, 2.5778935e-11, 4.8051218e-11, 2.9114655e-11, 2.0579061e-11, 3.7228137e-11, 1.9723736e-13, 1.6788374e-11, 1.5427803e-11, 3.2430951e-11, 1.5089269e-11, 8.6060757e-12, 4.2812829e-12, 1.4006628e-11, 3.3064175e-12, 1.1991854e-12, 1.1020541e-11, 1.2967097e-20];\nlet data2 = [3.1587274e-21, 1.3862829e-11, 1.646295e-11, 3.2144263e-11, 1.5146772e-11, 4.8599543e-11, 1.5956976e-11, 4.5079954e-11, 1.1164003e-11, 2.375367e-11, 8.4472809e-12, 9.1891247e-12, 1.5533811e-11, 1.4210519e-11, 3.0230631e-11, 5.3723755e-11, 1.8964366e-11, 3.6470387e-11, 1.7343736e-11, 2.657321e-11, 1.6595779e-11, 2.8922344e-12, 2.2643239e-12, 7.9208543e-13, 1.0798639e-11, 4.4303875e-12, 1.3237586e-11, 3.0215069e-11, 3.847939e-12, 3.3845368e-11, 1.968798e-11, 2.5638958e-11, 3.1805576e-11, 1.4100588e-11, 4.2181828e-11, 9.1871239e-12, 5.4263521e-11, 2.6657799e-11, 2.9521244e-11, 2.6140709e-11, 3.6060228e-11, 3.9825691e-11, 3.693768e-11, 7.9510883e-12, 5.2393906e-11, 7.6993238e-12, 2.9091077e-11, 9.7627919e-12, 2.3350514e-11, 7.4785714e-12, 3.1269923e-11, 1.6848099e-11, 2.0900673e-11, 3.1482227e-12, 1.9616508e-11, 1.3593057e-11, 3.2383244e-11, 2.9686864e-11, 4.1839584e-11, 2.1039505e-11, 4.4363009e-11, 4.5567699e-11, 5.1585925e-11, 5.0254408e-11, 3.1628285e-11, 4.9054942e-11, 6.1561022e-11, 3.6102133e-11, 2.0040228e-11, 1.4764401e-11, 2.1241917e-11, 2.5835813e-11, 3.5030384e-11, 4.1158653e-11, 3.5126977e-11, 4.6989584e-11, 3.8374905e-11, 5.3902491e-11, 2.2804858e-11, 4.116799e-11, 2.2078131e-11, 2.9711651e-11, 2.7927514e-12, 3.6848534e-11, 4.8283198e-12, 1.5137768e-11, 1.8658358e-12, 5.5483772e-12, 4.8572199e-12, 7.2834956e-12, 4.3929285e-12, 9.2330306e-12, 1.2192069e-11, 1.0106481e-11, 1.2977151e-11, 5.4687908e-13, 2.7688531e-13, 5.1474437e-12, 9.0471806e-12, 7.2589305e-12, 1.1016835e-11, 1.5147217e-11, 7.1979068e-12, 1.6878222e-11, 2.5077518e-12, 1.3794247e-11, 2.3397977e-12, 3.3936292e-11, 4.4505064e-12, 4.141553e-11, 2.6810636e-11, 1.4511192e-11, 3.50435e-11, 2.6215738e-12, 1.6870441e-11, 1.6199848e-11, 7.5394839e-12, 4.3516901e-13, 1.8329341e-13, 2.6110141e-13, 3.3873156e-12, 1.4211298e-11, 5.7610154e-12, 2.4711376e-11, 1.6844209e-11, 1.1221025e-11, 1.4642687e-11, 1.7884391e-11, 5.9851024e-12, 1.7921405e-11, 1.2904123e-11, 1.9490681e-11, 1.8598891e-11, 1.2063686e-11, 1.8508411e-11, 3.2205064e-11, 1.1345184e-11, 1.8744058e-11, 2.3708653e-11, 3.811736e-11, 2.6724824e-12, 4.3599156e-11, 2.0617119e-11, 5.1319933e-11, 3.0725823e-11, 5.1442091e-11, 2.3753115e-11, 6.2107567e-11, 3.1677192e-11, 5.5339939e-11, 3.4040666e-11, 2.5940742e-11, 4.6395909e-11, 3.6795625e-11, 3.4361235e-11, 2.2750948e-11, 3.1149432e-11, 2.7081963e-11, 3.2067789e-11, 8.3646933e-12, 4.675705e-11, 9.3488534e-12, 1.7650189e-12, 1.4368581e-11, 1.7560154e-11, 9.1522214e-12, 5.3022816e-12, 5.1575583e-14, 7.4349989e-12, 4.3805903e-12, 1.007169e-11, 7.4106559e-13, 1.807591e-12, 1.2629572e-11, 4.3775891e-12, 1.3309947e-11, 9.9894355e-12, 1.6843987e-11, 1.3354187e-11, 5.8228171e-12, 3.1425539e-12, 2.8588437e-11, 2.262212e-12, 5.8623881e-12, 7.9196316e-12, 5.8783943e-12, 1.2594558e-11, 2.3195342e-11, 1.5702765e-12, 3.1104303e-11, 8.5607694e-12, 4.3086735e-12, 1.2531867e-11, 1.2554209e-11, 1.8647243e-12, 9.3182859e-12, 5.2836077e-12, 2.6260533e-11, 5.2642671e-13, 2.6149379e-11, 6.5936721e-12, 5.6280749e-12, 1.2302667e-11, 1.50195e-11, 3.4461163e-12, 2.4724603e-11, 1.2550652e-11, 1.7924073e-11, 2.4092246e-11, 3.1099635e-11, 3.2873213e-11, 1.9854823e-11, 1.2604229e-11, 7.9728745e-12, 2.7277039e-11, 8.5136401e-12, 1.9863048e-11, 3.4652904e-11, 1.1901511e-11, 2.5563929e-11, 1.2166726e-11, 2.461745e-11, 1.3254037e-12, 7.839267e-12, 9.9509761e-12, 6.5985629e-12, 3.8159266e-12, 9.5138063e-12, 3.7557921e-12, 1.6593e-11, 1.3511137e-11, 7.505693e-12, 4.7188328e-12, 1.596798e-11, 3.1650071e-12, 5.7689072e-13, 4.2908888e-12, 1.1663197e-11, 6.9723748e-12, 2.1425766e-11, 7.5927268e-12, 1.5739669e-11, 6.1834017e-12, 7.7385613e-13, 2.4608447e-12, 1.8791743e-12, 2.8075349e-12, 1.061968e-12, 8.6929319e-12, 1.971688e-11, 3.1628729e-11, 4.7778446e-11, 3.5523798e-11, 3.331405e-11, 3.4131257e-11, 3.3807687e-11, 3.3272812e-11, 2.7870714e-11, 3.199665e-11, 2.726659e-11, 1.8468729e-11, 3.5013599e-11, 4.2273197e-11, 3.6007874e-11, 3.1525578e-11, 1.2414044e-11, 1.5876389e-11, 3.6948795e-12, 3.3746107e-11, 2.5809358e-11, 2.4112477e-11, 4.4271084e-11, 2.9867156e-11, 3.1420648e-11, 1.7371303e-11, 2.4465836e-11, 4.0992588e-12, 2.6491401e-12, 8.1303801e-12, 8.5713292e-12, 2.3663635e-12, 1.5372526e-11, 2.8357792e-11, 1.1904735e-11, 1.3772349e-11, 5.2911662e-12, 1.6268652e-11, 1.8988709e-11, 4.6916e-12, 1.0875669e-11, 1.3120318e-11, 2.6141042e-11, 7.6080661e-11, 9.5989838e-11, 1.4489528e-10, 2.0154195e-10, 3.0967917e-10, 4.3345436e-10, 6.3358286e-10, 8.8771735e-10, 1.2741231e-09, 1.7645955e-09, 2.5038187e-09, 3.4686766e-09, 4.8671167e-09, 6.7767861e-09, 9.4414534e-09, 1.3159652e-08, 1.8246835e-08, 2.5266961e-08, 3.487059e-08, 4.8017711e-08, 6.5968252e-08, 9.0295516e-08, 1.2330064e-07, 1.6787384e-07, 2.2790804e-07, 3.0853965e-07, 4.1644473e-07, 5.6052828e-07, 7.5213878e-07, 1.0063065e-06, 1.3422031e-06, 1.7847702e-06, 2.3659374e-06, 3.1264883e-06, 4.1185031e-06, 5.4079356e-06, 7.0781943e-06, 9.234058e-06, 1.2006817e-05, 1.5560174e-05, 2.0097201e-05, 2.5868814e-05, 3.3183366e-05, 4.2418174e-05, 5.403248e-05, 6.8582362e-05, 8.6737913e-05, 0.00010930182, 0.00013723087, 0.00017165865, 0.00021392091, 0.00026558174, 0.00032846207, 0.00040466801, 0.00049662036, 0.0006070829, 0.0007391898, 0.00089647036, 0.0010828703, 0.0013027684, 0.0015609871, 0.0018627962, 0.0022139076, 0.0026204618, 0.0030890034, 0.0036264471, 0.0042400316, 0.004937265, 0.0057258587, 0.0066136536, 0.0076085392, 0.0087183668, 0.0099508598, 0.011313523, 0.012813554, 0.014457756, 0.016252461, 0.018203457, 0.020315928, 0.022594403, 0.02504272, 0.027663998, 0.030460627, 0.033434265, 0.036585855, 0.039915638, 0.043423192, 0.047107468, 0.050966832, 0.05499912, 0.059201687, 0.063571465, 0.068105018, 0.072798595, 0.077648185, 0.082649568, 0.087798357, 0.093090051, 0.098520067, 0.10408378, 0.10977655, 0.11559376, 0.12153083, 0.12758323, 0.13374653, 0.14001638, 0.14638853, 0.15285883, 0.15942327, 0.16607796, 0.1728191, 0.17964307, 0.18654633, 0.19352548, 0.20057725, 0.20769849, 0.21488617, 0.22213736, 0.22944927, 0.2368192, 0.24424456, 0.25172287, 0.25925174, 0.26682889, 0.2744521, 0.28211929, 0.28982841, 0.29757751, 0.30536475, 0.3131883, 0.32104646, 0.32893756, 0.33686, 0.34481224, 0.35279281, 0.36080028, 0.36883326, 0.37689044, 0.38497053, 0.39307229, 0.40119452, 0.40933606, 0.41749581, 0.42567269, 0.43386567, 0.44207375, 0.45029603, 0.45853158, 0.46677972, 0.47503945, 0.4833107, 0.49159204, 0.49988463, 0.50818626, 0.5164997, 0.52482283, 0.53315832, 0.54150894, 0.5498738, 0.5582359, 0.5665362, 0.57494469, 0.58311624, 0.59136317, 0.59958707, 0.60776687, 0.6159676, 0.624232, 0.6323957, 0.6405601, 0.64871327, 0.65688165, 0.66508144, 0.673247, 0.68143447, 0.68964666, 0.69798511, 0.70610249, 0.71427091, 0.72235892, 0.73037817, 0.73833991, 0.74625126, 0.75411165, 0.76191705, 0.76966278, 0.77734373, 0.78495423, 0.79248781, 0.79993689, 0.80729313, 0.81454716, 0.82168897, 0.82870754, 0.83559096, 0.84232631, 0.84889968, 0.85529632, 0.86150056, 0.86749612, 0.87326608, 0.87879326, 0.88406045, 0.88905082, 0.89374843, 0.89813868, 0.9022091, 0.90594978, 0.90935421, 0.91241975, 0.91514819, 0.91754603, 0.91962462, 0.9214, 0.92289244, 0.92412584, 0.92512669, 0.92592309, 0.92654356, 0.92701596, 0.92736647, 0.92761863, 0.92779284, 0.92791107, 0.9279828, 0.92801901, 0.92802639, 0.92803187, 0.92801278, 0.92799155, 0.9279374, 0.92788026, 0.92781863, 0.92775834, 0.92770019, 0.9276448, 0.92759277, 0.92754454, 0.92750042, 0.92746044, 0.92742444, 0.92739211, 0.92736302, 0.92733674, 0.92731283, 0.9272909, 0.92727063, 0.92725175, 0.92723405, 0.92721737, 0.92720159, 0.92718663, 0.92717241, 0.92715889, 0.92714602, 0.92713376, 0.92712205, 0.92711087, 0.92710016, 0.92708987, 0.92707996, 0.92707038, 0.92706111, 0.92705212, 0.92704341, 0.92703496, 0.92702678, 0.9270189, 0.92701128, 0.92700388, 0.92699672, 0.92698978, 0.92698311, 0.92697697, 0.92697102, 0.9269644, 0.92695882, 0.92695257, 0.92694634, 0.92694042, 0.92693453, 0.92692853, 0.92692233, 0.92691583, 0.92690895, 0.92690158, 0.92689368, 0.92688513, 0.92687566, 0.9268651, 0.92685345, 0.92684118, 0.92682992, 0.92681909, 0.92680727, 0.92679675, 0.92678714, 0.92677884, 0.92677221, 0.9267674, 0.92676447, 0.92676321, 0.92676338, 0.92676473, 0.92676685, 0.92676937, 0.92677188, 0.92677402, 0.92677561, 0.92677665, 0.92677714, 0.92677547, 0.92677222, 0.92676995, 0.92676664, 0.92676285, 0.92675868, 0.92675421, 0.92674948, 0.92674448, 0.92673922, 0.92673375, 0.92672829, 0.92672287, 0.92671729, 0.92671144, 0.92670515, 0.92670037, 0.9266956, 0.9266888, 0.92668168, 0.92667323, 0.92666665, 0.92666105, 0.92665279, 0.92664626, 0.92663888, 0.92663016, 0.92662086, 0.92661089, 0.9266001, 0.92658832, 0.92657535, 0.92656091, 0.92654466, 0.92652616, 0.92650484, 0.92647999, 0.92645069, 0.92641577, 0.92637373, 0.92632266, 0.92626013, 0.92618306, 0.92608752, 0.92596852, 0.92581972, 0.92563309, 0.92539845, 0.92510291, 0.92473014, 0.92425951, 0.92366491, 0.92291337, 0.92196323, 0.92076189, 0.91924297, 0.91732274, 0.91489558, 0.91182839, 0.90795347, 0.90305973, 0.89688164, 0.88908574, 0.87925393, 0.86686358, 0.85126424, 0.83165196, 0.80704406, 0.77626142, 0.73793377, 0.69055942, 0.63268039, 0.56327591, 0.48250857, 0.39285097, 0.30012158, 0.21309309, 0.14045218, 0.086688654, 0.050828674, 0.028729114, 0.015849886, 0.00861729, 0.0046467978, 0.0024949216, 0.0013366319, 0.0007153302, 0.00038263615, 0.00020462933, 0.00010942248, 5.850937e-05, 3.1284829e-05, 1.6727594e-05, 8.9439202e-06, 4.7819894e-06, 2.5567432e-06, 1.3669313e-06, 7.308132e-07, 3.9068546e-07, 2.0884449e-07, 1.1162505e-07, 5.9670655e-08, 3.1888187e-08, 1.7047214e-08, 9.0987698e-09, 4.8644519e-09, 2.5910582e-09, 1.4090592e-09, 7.3607532e-10, 3.7363817e-10, 1.7609201e-10, 6.9859433e-11, 6.505581e-11, 1.1719474e-11, 4.888612e-11, 2.3601888e-12, 3.4779596e-11, 1.1009219e-11, 1.7066971e-11, 4.3198424e-11, 1.6923455e-11, 2.9291692e-11, 6.9220659e-12, 9.226979e-13, 1.9257449e-11, 2.1512192e-11, 2.9423553e-12, 1.0852717e-11, 3.749397e-13, 2.8956266e-11, 2.7232853e-11, 1.094118e-11, 2.3079547e-11, 3.5580423e-12, 8.7943225e-12, 3.5617162e-11, 3.3684635e-12, 1.2529068e-11, 1.9249346e-11, 3.1177378e-11, 1.2765265e-11, 2.028881e-11, 1.8367383e-12, 3.5656121e-11, 1.7748588e-11, 1.607812e-11, 1.6635646e-11, 2.148844e-11, 1.3817604e-11, 2.4028995e-11, 7.6920353e-12, 2.2070828e-11, 2.0256067e-11, 8.1556597e-12, 4.0443095e-12, 1.4599117e-11, 3.5777882e-11, 1.215202e-11, 3.2232604e-11, 1.05194e-11, 1.4869943e-12, 3.0990797e-12, 2.8712522e-11, 1.0117711e-11, 7.1187483e-12, 1.8899935e-11, 2.1021929e-11, 1.7956037e-11, 3.8355509e-11, 4.8117261e-12, 3.4119731e-13, 6.755352e-12, 2.2086811e-11, 1.8748094e-12, 2.1405527e-11, 2.1825197e-11, 1.3863227e-13, 8.1193644e-12, 6.0514244e-12, 1.3537343e-11, 2.5115964e-11, 1.3615816e-11, 3.6313542e-11, 3.1876534e-12, 5.0612307e-11, 1.4525195e-11, 4.9153061e-11, 5.0610199e-12, 3.5477641e-11, 2.0070373e-11, 1.2292317e-11, 2.257996e-11, 2.6219695e-11, 3.3177057e-11, 3.3918834e-11, 2.0201124e-11, 2.9929022e-11, 2.0404911e-11, 1.7744481e-11, 4.564097e-13, 3.0670022e-12, 6.1093637e-12, 4.9195239e-11, 5.3775764e-12, 3.2420629e-11, 3.2356918e-11, 1.1203127e-11, 2.1044239e-11, 7.0392762e-12, 1.0964045e-11, 2.4331011e-11, 1.1977203e-11, 2.7525213e-11, 2.2182711e-11, 3.4249153e-11, 2.6882887e-12, 3.8139957e-12, 1.3752339e-11, 2.0393922e-11, 1.8775732e-11, 1.6146492e-11, 8.4262645e-12, 2.6534919e-11, 1.1913936e-11, 3.2594002e-11, 1.6710789e-11, 2.4528359e-11, 1.5794528e-12, 3.0703987e-11, 1.9988459e-11, 4.2636903e-11, 2.9170263e-11, 1.5225348e-11, 2.5626762e-11, 4.4411928e-11, 1.589842e-11, 4.5259483e-11, 2.0439208e-11, 2.6341012e-11, 1.347341e-11, 2.1255684e-11, 1.0629729e-11, 3.9437928e-11, 2.9967427e-12, 3.1947237e-11, 6.9956554e-12, 6.1998242e-12, 2.0789284e-12, 2.0116436e-11, 4.647676e-12, 1.6522098e-11, 9.3896974e-12, 6.0516465e-12, 8.3840866e-12, 2.1797115e-11, 1.0969372e-11, 1.4066343e-12, 7.4723771e-12, 1.508716e-11, 2.572588e-11, 3.1789957e-11, 3.7379645e-12, 1.4661163e-11, 3.0160668e-11, 3.8229419e-11, 2.3631412e-11, 3.3269737e-11, 1.1988414e-11, 3.4363256e-11, 2.2416021e-11, 1.1728131e-11, 9.317551e-12, 9.889617e-12, 2.6019238e-11, 5.4338506e-12, 3.9482659e-11, 1.4534407e-11, 5.2454928e-11, 5.7924963e-11, 5.1665202e-11, 7.6479705e-11, 5.8635218e-11, 6.9449863e-11, 4.4034991e-11, 3.6424314e-11, 4.3910566e-11, 3.1681627e-11, 2.2541112e-11, 1.4644958e-11, 1.2643947e-11, 1.8225976e-11, 1.0744275e-11, 1.0612192e-11, 2.0740669e-11, 4.3798572e-11, 3.0136138e-11, 1.6759738e-11, 2.4857014e-11, 5.8160049e-12, 1.1487828e-11, 7.7568561e-12, 1.3198587e-11, 4.9671184e-12, 1.9774128e-11, 4.5795254e-12, 1.0955387e-11, 2.7193117e-11, 2.7553294e-12, 2.3722427e-11, 4.8546809e-12, 1.5726156e-11, 1.0720633e-11, 9.6529766e-12, 2.9908599e-12, 2.6848257e-11, 3.5884548e-13, 3.1516578e-11, 5.297738e-11, 3.3170952e-11, 4.9748325e-11, 1.0841063e-11, 5.7032789e-11, 4.068695e-11, 5.5832715e-11, 3.2919771e-11, 4.6057423e-11, 2.3108183e-11, 4.1595996e-11, 1.170904e-11, 1.0863594e-11, 1.5928055e-11, 2.1407081e-11, 1.4800017e-12, 2.8126359e-11, 4.7800593e-11, 5.4824441e-11, 2.0990407e-11, 5.1780192e-11, 1.1011772e-11, 2.5747635e-11, 1.1905057e-11, 1.7807748e-11, 3.2342156e-11, 9.8929469e-12, 1.1113443e-11, 6.7752201e-12, 1.8121308e-11, 6.0684066e-12, 3.6823562e-11, 3.2676027e-11, 3.8488147e-11, 4.7162818e-11, 2.817775e-11, 4.1453479e-11, 3.4595678e-11, 3.2416078e-11, 5.5118354e-11, 5.5519489e-12, 5.4331847e-11, 3.5331795e-12, 3.1377169e-11, 3.4956633e-12, 2.5582031e-11, 2.1050122e-11, 3.4838313e-11, 6.7041836e-12, 3.0708981e-11, 1.1507141e-11, 1.392205e-12, 2.4646346e-12, 2.9236638e-11, 1.18631e-12, 2.1137697e-11, 1.0209059e-11, 7.883501e-12, 6.1566473e-12, 4.3042588e-12, 3.0403524e-11, 2.3630743e-13, 2.2504595e-11, 1.8515117e-11, 1.5644797e-11, 3.6540082e-11, 3.5870451e-11, 3.4634194e-11, 1.2553487e-12, 2.1674356e-11, 2.6223579e-12, 2.6899536e-12, 1.6752412e-11, 1.2854726e-11, 2.237007e-11, 4.7813135e-12, 1.7285852e-11, 6.1368907e-13, 2.2063613e-11, 2.356861e-20];\nlet data3 = [6.9688318e-22, 1.644272e-11, 6.314786e-12, 3.2875102e-11, 9.8260368e-14, 2.3936075e-11, 2.694969e-11, 4.2087013e-11, 4.6329106e-11, 2.3309053e-11, 3.7687305e-11, 6.6659224e-12, 4.6838192e-12, 9.6655319e-12, 2.0671807e-11, 2.8959359e-11, 2.2623343e-11, 3.6969137e-11, 2.1388752e-11, 3.5699199e-11, 2.9340507e-11, 1.772255e-11, 8.2035196e-12, 1.8482512e-11, 2.4174501e-11, 1.7265261e-11, 2.2804302e-11, 3.1309939e-12, 6.693711e-12, 2.5666191e-11, 2.6720934e-11, 1.9686869e-11, 6.4094895e-12, 2.6156381e-11, 1.178002e-11, 2.1946524e-11, 1.5986765e-11, 4.5602823e-11, 4.2158819e-11, 5.0142253e-11, 3.0869434e-11, 2.972888e-11, 2.2426155e-11, 3.9049945e-11, 2.5087744e-11, 5.3440423e-11, 3.8887215e-11, 6.2241064e-11, 5.2624773e-11, 7.1175534e-11, 4.66878e-11, 4.4403358e-11, 4.6373456e-11, 4.1789009e-11, 4.2431703e-11, 3.5016267e-11, 4.5389963e-11, 4.1522905e-11, 5.6982577e-11, 4.5454432e-11, 6.0826959e-11, 2.1750226e-11, 2.9669301e-11, 1.1971094e-11, 3.0990037e-11, 1.1845156e-11, 2.3249141e-11, 7.7532336e-12, 1.9204681e-11, 3.0587436e-12, 1.4002994e-11, 2.5361628e-11, 9.4072093e-12, 1.9982205e-12, 5.6142917e-12, 8.5617698e-12, 2.0093693e-11, 1.1226582e-12, 1.1819035e-12, 1.1260151e-11, 7.7041034e-12, 6.2246287e-15, 1.140354e-11, 7.8352655e-13, 1.0221303e-11, 2.1752893e-12, 1.9166222e-11, 2.1780015e-11, 1.1090419e-11, 3.5089073e-11, 1.0938137e-11, 2.4513521e-11, 6.9846017e-12, 8.5136401e-12, 1.1986322e-11, 2.5332061e-12, 1.8469396e-12, 9.5819439e-12, 1.2684482e-11, 4.9295813e-12, 1.0067243e-11, 1.4625681e-11, 3.0977587e-12, 1.4397592e-11, 1.1447335e-11, 2.3799577e-11, 5.6455261e-12, 3.5564147e-11, 2.6856209e-11, 3.0241857e-11, 2.6844426e-11, 2.438536e-11, 1.8498852e-11, 1.5597614e-11, 1.3305279e-11, 8.4438352e-12, 1.2783854e-12, 1.7306833e-11, 2.4847206e-11, 9.7293345e-12, 2.3259701e-11, 6.1117071e-12, 2.1805469e-11, 4.1434982e-12, 2.0206737e-11, 1.071116e-11, 8.3765868e-12, 3.1402197e-12, 9.787357e-12, 1.4450279e-11, 1.1241922e-11, 1.0742283e-11, 4.307562e-12, 1.8921794e-12, 1.7633849e-11, 5.7883593e-12, 1.06129e-11, 8.7511769e-13, 1.374067e-11, 8.8962331e-12, 3.0052673e-11, 5.1190994e-12, 1.807691e-11, 2.3518579e-11, 2.1319836e-11, 4.4795191e-14, 1.0434831e-11, 8.6904865e-12, 2.1587385e-11, 4.3709199e-12, 2.9441991e-11, 1.0720275e-11, 7.4697902e-12, 1.0809754e-11, 1.4696486e-11, 1.8840651e-13, 1.442049e-11, 1.9502353e-11, 2.7316276e-11, 1.128316e-11, 9.0713011e-12, 1.2080803e-11, 3.0674025e-11, 3.5719429e-11, 1.915833e-11, 3.1539917e-11, 1.1264042e-11, 1.2411821e-11, 1.2584888e-12, 1.6417377e-11, 1.2998382e-12, 8.0154466e-12, 6.880339e-12, 2.9339062e-11, 2.0188063e-11, 2.6760505e-11, 3.110786e-11, 3.7842921e-11, 1.6658693e-11, 2.7987093e-11, 2.6125925e-11, 2.0261203e-11, 1.1568827e-11, 1.0462064e-11, 6.349355e-12, 1.5180229e-11, 2.04246e-12, 1.7739112e-12, 2.6350346e-11, 8.2377551e-12, 2.5672971e-11, 2.1312055e-11, 2.3692647e-11, 1.5997325e-12, 4.1161543e-12, 9.3535218e-12, 7.0731917e-12, 2.2783516e-11, 2.787416e-12, 1.0895343e-12, 1.0061575e-11, 5.620961e-12, 5.1491111e-12, 9.7073259e-12, 2.690156e-12, 7.136105e-12, 3.9105189e-12, 2.305262e-11, 9.1106498e-12, 1.7891949e-11, 1.515811e-11, 2.2325894e-11, 1.4907234e-11, 3.9668407e-11, 2.296881e-11, 2.0173391e-11, 2.3783237e-11, 1.961962e-11, 3.8646121e-12, 1.466025e-11, 1.2476068e-11, 4.1588375e-12, 1.4916349e-11, 7.0600755e-12, 1.0899789e-12, 1.9369746e-12, 8.2886638e-12, 1.4640909e-11, 6.0101121e-12, 1.5824368e-11, 6.2542069e-12, 3.9383074e-12, 4.4448375e-12, 1.3129099e-11, 5.8919551e-12, 2.6262423e-12, 9.3675273e-12, 7.495578e-12, 9.0743023e-12, 1.9489792e-12, 4.1585041e-12, 1.1289385e-11, 3.254264e-12, 2.727615e-11, 2.6855208e-11, 3.0241524e-11, 1.5608951e-11, 6.0245621e-13, 1.2463396e-11, 2.1251699e-11, 4.9694857e-12, 1.8488292e-11, 1.7308167e-11, 2.8451051e-12, 3.8551974e-11, 7.7724633e-12, 2.0788852e-11, 1.4494296e-11, 1.0015112e-11, 1.7135544e-12, 2.2126038e-11, 1.0695043e-11, 3.7801571e-11, 1.9514913e-11, 1.7230915e-11, 3.0993482e-11, 1.6909679e-11, 3.4409142e-11, 4.2537633e-12, 2.2227744e-11, 3.6879213e-11, 2.2517635e-11, 2.2170278e-11, 7.1939054e-13, 4.0701364e-12, 2.1823143e-11, 8.1009242e-12, 2.3839704e-11, 5.1708973e-12, 1.1727444e-11, 6.3424634e-12, 1.2382143e-11, 3.5569378e-14, 7.6585302e-12, 2.4730716e-12, 7.9594248e-12, 9.8192583e-12, 1.0134825e-11, 9.5584903e-12, 8.8383217e-12, 2.6082353e-12, 1.8433826e-11, 3.5326054e-11, 4.4339666e-11, 1.2091719e-10, 1.7084625e-10, 2.5967619e-10, 3.634545e-10, 5.5290375e-10, 7.9605286e-10, 1.1043283e-09, 1.5812387e-09, 2.2285323e-09, 3.1469275e-09, 4.4479603e-09, 6.2269566e-09, 8.6930763e-09, 1.2104844e-08, 1.6837257e-08, 2.3295801e-08, 3.2212568e-08, 4.4334733e-08, 6.0893725e-08, 8.337456e-08, 1.1391194e-07, 1.5513682e-07, 2.1066381e-07, 2.8526479e-07, 3.8513473e-07, 5.184716e-07, 6.9585825e-07, 9.3118369e-07, 1.2422554e-06, 1.6522398e-06, 2.1907008e-06, 2.8955934e-06, 3.8152406e-06, 5.0109495e-06, 6.5602045e-06, 8.560473e-06, 1.1133904e-05, 1.4432841e-05, 1.864643e-05, 2.4008378e-05, 3.0806173e-05, 3.939168e-05, 5.0193482e-05, 6.373087e-05, 8.0629924e-05, 0.00010164123, 0.00012766014, 0.00015974814, 0.00019915717, 0.00024735442, 0.00030604959, 0.00037722223, 0.00046314986, 0.0005664359, 0.00069003607, 0.00083728324, 0.0010119086, 0.0012180594, 0.0014603103, 0.0017436691, 0.0020735744, 0.0024558851, 0.0028968594, 0.0034031258, 0.003981642, 0.004639646, 0.0053845953, 0.0062241002, 0.0071658477, 0.0082175215, 0.0093867167, 0.010680855, 0.012107097, 0.013672263, 0.015382752, 0.017244475, 0.019262788, 0.021442444, 0.023787554, 0.026301551, 0.028987178, 0.031846482, 0.034880815, 0.038090856, 0.041476629, 0.045037541, 0.048772415, 0.052679542, 0.056756722, 0.061001318, 0.065410308, 0.069980336, 0.074707762, 0.079588712, 0.084619126, 0.089794796, 0.095111412, 0.1005646, 0.10614993, 0.11186299, 0.11769939, 0.12365474, 0.12972476, 0.13590521, 0.14219195, 0.14858094, 0.15506823, 0.16164999, 0.16832252, 0.1750822, 0.18192558, 0.18884927, 0.19585005, 0.20292479, 0.21007048, 0.21728423, 0.22456326, 0.23190489, 0.23930656, 0.2467658, 0.25428023, 0.2618476, 0.26946571, 0.27713249, 0.28484593, 0.2926041, 0.30040517, 0.30824737, 0.31612901, 0.32404845, 0.33200415, 0.33999461, 0.34801838, 0.3560741, 0.36416044, 0.37227612, 0.38041992, 0.38859065, 0.39678719, 0.40500842, 0.4132533, 0.42152079, 0.42980991, 0.4381197, 0.44644922, 0.45479757, 0.46316387, 0.47154727, 0.47994692, 0.48836204, 0.49679172, 0.50523546, 0.5136919, 0.52216136, 0.53064128, 0.53913374, 0.54763397, 0.55614653, 0.56466445, 0.57319362, 0.58172722, 0.59026928, 0.59881622, 0.60736834, 0.61592511, 0.62448513, 0.63304813, 0.64161313, 0.65017946, 0.65874591, 0.6673123, 0.67587697, 0.68443953, 0.69299866, 0.70155352, 0.71010264, 0.71864521, 0.72717945, 0.73570421, 0.74421761, 0.75271796, 0.76120312, 0.76967072, 0.77811816, 0.78654216, 0.79493922, 0.8033049, 0.81163417, 0.81992079, 0.82815731, 0.83633452, 0.84444109, 0.85246275, 0.86038162, 0.86817472, 0.8758128, 0.88325778, 0.89046056, 0.89735742, 0.90386671, 0.90988573, 0.91528921, 0.91993422, 0.92366278, 0.92634106, 0.92784161, 0.92829757, 0.9282984, 0.9282713, 0.92826961, 0.92826595, 0.92826551, 0.92826812, 0.92827398, 0.92827656, 0.92827988, 0.92828388, 0.92829462, 0.92829526, 0.928294, 0.92829365, 0.92829214, 0.92828957, 0.92828995, 0.92828473, 0.92825203, 0.92821711, 0.92810413, 0.92797596, 0.92781776, 0.92765406, 0.92748905, 0.92733948, 0.92722197, 0.92714752, 0.92712163, 0.92711871, 0.92711722, 0.92711593, 0.92711253, 0.92710873, 0.92709741, 0.92708225, 0.92705974, 0.92703606, 0.92701366, 0.9269948, 0.92697989, 0.92696832, 0.92695887, 0.92695033, 0.92694183, 0.92693296, 0.92692374, 0.92691443, 0.92690531, 0.92689663, 0.92688847, 0.92688082, 0.92687357, 0.92686657, 0.92685967, 0.92685275, 0.92684576, 0.92683874, 0.92683178, 0.92682498, 0.92681835, 0.92681197, 0.92680587, 0.92680037, 0.92679479, 0.9267895, 0.9267835, 0.92677779, 0.92677267, 0.92676776, 0.92676293, 0.92675801, 0.92675287, 0.92674735, 0.92674134, 0.92673479, 0.92672762, 0.92671977, 0.92671123, 0.92670216, 0.92669224, 0.92668065, 0.92666776, 0.92665596, 0.9266461, 0.92663748, 0.92662607, 0.9266169, 0.92660872, 0.9266022, 0.92659765, 0.9265949, 0.92659375, 0.92659388, 0.92659495, 0.92659702, 0.92659938, 0.926602, 0.92660442, 0.92660629, 0.92660738, 0.92660746, 0.92660629, 0.92660383, 0.9266003, 0.92659594, 0.92659129, 0.92658667, 0.92658204, 0.92657723, 0.92657201, 0.92656638, 0.92656039, 0.92655414, 0.92654714, 0.92653966, 0.92653448, 0.92652956, 0.92652316, 0.92651643, 0.92650962, 0.9265021, 0.92649434, 0.9264865, 0.92647784, 0.9264687, 0.92645885, 0.9264501, 0.9264418, 0.92643157, 0.92642051, 0.92640881, 0.92639628, 0.92638275, 0.92636804, 0.92635188, 0.92633396, 0.92631386, 0.92629103, 0.9262648, 0.92623425, 0.92619825, 0.92615529, 0.92610345, 0.92604026, 0.9259625, 0.92586606, 0.92574562, 0.92559432, 0.92540335, 0.92516138, 0.92485383, 0.92446195, 0.92396167, 0.92332208, 0.92250349, 0.92145494, 0.92011106, 0.91838798, 0.91617815, 0.91334364, 0.9097076, 0.90504345, 0.8990609, 0.89138843, 0.88155109, 0.86894299, 0.85279399, 0.83213126, 0.80573957, 0.77213127, 0.72955327, 0.67609096, 0.60999109, 0.53041726, 0.43882191, 0.34056529, 0.24517568, 0.1632928, 0.1014608, 0.059707787, 0.033806, 0.018665709, 0.010154046, 0.005479122, 0.0029441638, 0.0015787208, 0.00084568651, 0.00045280042, 0.00024238724, 0.00012973898, 6.9440429e-05, 3.7165985e-05, 1.9891759e-05, 1.064624e-05, 5.6978887e-06, 3.049471e-06, 1.6320517e-06, 8.7343127e-07, 4.6743332e-07, 2.5014952e-07, 1.3384814e-07, 7.1615183e-08, 3.8302331e-08, 2.0481096e-08, 1.0948229e-08, 5.8510068e-09, 3.1322059e-09, 1.6631885e-09, 8.57237e-10, 4.4180893e-10, 2.3606094e-10, 1.0653837e-10, 4.8445804e-11, 3.8261163e-11, 4.5305767e-12, 3.0781683e-11, 1.9434374e-11, 1.4308533e-11, 1.6763067e-11, 1.0900001e-11, 7.5461885e-12, 2.7021852e-11, 5.7774899e-12, 7.0599212e-12, 6.0658537e-12, 1.4065233e-11, 2.1357799e-11, 2.7991834e-11, 3.1688949e-13, 5.4280789e-12, 1.650667e-11, 4.0891069e-11, 5.6260599e-11, 3.8895053e-11, 2.5336844e-11, 3.9860262e-11, 1.6378804e-11, 1.7282189e-11, 1.3859227e-11, 1.4629087e-13, 8.4004028e-12, 2.5132947e-11, 2.0514684e-11, 5.5260427e-11, 5.613007e-11, 8.2709276e-11, 4.497345e-11, 5.2929541e-11, 5.7110263e-11, 6.9544209e-11, 7.4599235e-11, 3.1559311e-11, 6.120341e-11, 2.6694862e-11, 2.024641e-11, 1.515409e-11, 1.5751907e-11, 1.5740807e-11, 4.6726499e-12, 4.2641121e-11, 3.1802278e-11, 5.9698102e-11, 2.4635248e-12, 1.1014436e-11, 5.2965502e-12, 1.8254279e-11, 1.4623092e-11, 3.7850483e-11, 1.9546146e-12, 4.8512512e-11, 1.8027185e-11, 4.4816947e-11, 1.7458116e-11, 6.9470286e-11, 4.9698711e-11, 6.6345123e-11, 3.3800291e-11, 7.1974213e-11, 3.7158654e-11, 8.4838374e-11, 1.3432009e-11, 8.3507327e-11, 3.8679835e-11, 6.5401114e-11, 1.2362687e-11, 7.8441534e-11, 2.1142137e-11, 3.1710818e-11, 5.3928159e-11, 5.3182054e-11, 4.5290117e-11, 2.5674045e-11, 5.923259e-11, 4.5728657e-11, 5.7957485e-11, 2.930157e-11, 6.1021046e-11, 4.9183585e-11, 8.4027003e-11, 2.2707049e-11, 5.8156498e-11, 4.7588149e-11, 5.6304331e-11, 2.8830176e-11, 5.8142069e-11, 2.744907e-11, 2.3922773e-11, 5.1634678e-12, 3.7483424e-11, 2.7852314e-11, 1.821976e-12, 1.8758099e-14, 7.2568256e-12, 5.5144882e-11, 2.234554e-11, 3.6724e-11, 2.7349841e-11, 3.4800685e-11, 5.3074278e-12, 1.20751e-11, 1.5684422e-11, 3.8380594e-11, 2.5202207e-11, 5.6174357e-11, 1.8072359e-11, 2.6781216e-11, 1.4482462e-11, 8.3793138e-12, 1.3220897e-11, 1.6602569e-12, 3.0230928e-11, 3.3592287e-11, 5.5116578e-11, 6.3377683e-11, 7.4435962e-11, 5.0469568e-11, 4.3236495e-11, 3.3662436e-11, 1.3699395e-11, 5.1504926e-11, 4.373253e-11, 3.3496388e-11, 2.4427687e-11, 3.8436202e-11, 3.5448894e-11, 3.257369e-11, 2.7977294e-11, 2.8831508e-11, 1.2698557e-11, 2.5001751e-11, 1.3384836e-11, 1.971075e-11, 1.2994357e-11, 1.3088148e-11, 1.6582923e-11, 8.1139258e-12, 3.5938158e-11, 1.4750514e-11, 9.3928053e-12, 1.7985562e-12, 1.590963e-11, 4.7555628e-12, 3.5563773e-12, 1.7015469e-12, 8.9185254e-12, 1.5699961e-11, 5.2750174e-12, 1.1218555e-11, 1.7849038e-12, 1.03296e-11, 4.5309097e-12, 2.6763013e-11, 4.5335736e-12, 1.0454357e-11, 3.0471342e-11, 3.211051e-11, 6.2507818e-11, 2.9848218e-11, 6.2961897e-11, 7.356532e-11, 6.8332703e-11, 1.0839231e-10, 7.1992638e-11, 8.1141477e-11, 8.1786356e-11, 7.4219744e-11, 6.9918038e-11, 5.0034581e-11, 3.6349171e-11, 3.1050956e-11, 4.2421795e-11, 2.0902277e-11, 5.2895244e-11, 1.9525611e-11, 3.3844467e-12, 4.1533062e-11, 1.4276123e-12, 1.8104215e-11, 4.7198225e-12, 3.7571221e-11, 1.4317191e-11, 2.9038957e-11, 7.6348731e-12, 4.6844152e-12, 1.2681686e-11, 3.2787799e-12, 1.2783024e-11, 1.5131891e-12, 2.1837961e-11, 1.92186e-11, 2.6969464e-12, 3.3476409e-11, 1.9815418e-11, 4.5208647e-11, 3.9951056e-11, 5.1660762e-11, 2.2907727e-11, 9.1554989e-12, 1.1622131e-11, 7.3245325e-13, 1.5328351e-12, 1.4989152e-11, 1.7662567e-12, 4.8820966e-12, 4.0439765e-12, 5.3799072e-13, 8.3456824e-12, 1.4397107e-12, 1.3843466e-11, 1.4267576e-11, 2.6067188e-11, 7.6877066e-12, 1.781463e-12, 1.741505e-13, 7.2234163e-12, 5.1667977e-12, 9.0937859e-12, 1.0709645e-11, 1.1865432e-11, 3.2584679e-12, 2.2026874e-11, 3.0745489e-14, 2.639551e-11, 1.0207727e-11, 1.4503662e-12, 1.5962685e-11, 2.4756564e-11, 7.4725991e-12, 1.5719829e-11, 5.8238855e-13, 9.3606168e-12, 1.618523e-12, 3.9659917e-11, 1.3356755e-11, 3.2485339e-11, 4.5040491e-12, 9.7542039e-13, 1.4630528e-11, 2.525604e-11, 2.6123684e-11, 5.2356587e-11, 4.3091204e-11, 5.4287227e-11, 1.4033045e-11, 4.9993291e-11, 2.206439e-11, 5.5926728e-11, 3.1548655e-11, 4.8612296e-11, 4.2891746e-11, 3.7626385e-11, 6.0400808e-11, 4.8195178e-11, 4.3433289e-11, 4.8251453e-11, 4.4334343e-11, 3.9629061e-11, 5.6315542e-11, 5.0820089e-11, 2.6441018e-11, 7.3309811e-11, 2.3628415e-11, 2.9492814e-11, 2.7083565e-11, 4.0127648e-11, 2.8342355e-11, 5.2944525e-11, 4.2551659e-11, 3.3472302e-11, 3.773072e-11, 4.7997164e-11, 2.9040733e-11, 5.0418622e-11, 3.3453877e-11, 1.0104946e-12, 2.723363e-12, 4.1511973e-12, 1.8644792e-20];\nlet data5 = [8.8755469e-22, 1.8272653e-11, 1.0733613e-11, 2.7953635e-11, 4.0261304e-11, 4.0519627e-11, 2.6162828e-11, 1.8507411e-11, 3.7509347e-11, 1.2686038e-12, 4.4012317e-11, 1.0528311e-11, 3.9979306e-11, 7.1194322e-13, 3.1690309e-11, 1.1239254e-11, 2.5174778e-11, 9.4864624e-12, 3.0043224e-11, 7.6723133e-12, 4.0573981e-11, 8.6146793e-12, 1.1601506e-11, 9.6370764e-12, 2.5131094e-11, 1.7846932e-12, 8.4477253e-13, 1.0806197e-11, 3.1424205e-11, 1.6773181e-12, 4.5035937e-11, 1.64286e-13, 2.3256255e-11, 4.8283198e-12, 2.2983149e-11, 1.3398093e-11, 8.522977e-12, 1.1698655e-11, 8.3994846e-12, 1.9472119e-11, 9.1014239e-12, 1.4485737e-11, 2.5002155e-11, 2.4439826e-11, 1.9087858e-11, 1.7320616e-11, 1.3126209e-11, 1.3104534e-11, 1.6955919e-11, 1.3026837e-11, 4.9831132e-11, 2.7873382e-11, 2.1826589e-11, 1.7490015e-11, 1.2527421e-11, 1.3321285e-11, 8.621682e-12, 1.0819202e-11, 6.0263407e-12, 2.0526639e-11, 1.3794247e-11, 6.3775882e-12, 8.5345371e-12, 1.1445557e-12, 1.5747005e-11, 7.6131792e-12, 1.3336847e-11, 3.2547086e-12, 1.1789246e-11, 2.1615173e-11, 1.3106757e-11, 2.0772179e-11, 5.7986967e-12, 2.3010048e-11, 4.2337555e-12, 3.3382188e-11, 2.4994819e-11, 2.4757838e-11, 9.6001732e-12, 2.5441437e-11, 1.2652692e-11, 7.9859907e-12, 1.3192346e-11, 1.3035396e-11, 1.2489296e-12, 1.3751119e-11, 8.4677333e-13, 2.0941467e-13, 9.1730073e-12, 1.1213022e-11, 3.2567093e-12, 1.4686371e-11, 9.470345e-13, 8.1800661e-12, 9.6435234e-12, 8.1576129e-13, 8.6654768e-12, 7.5295912e-13, 2.0637238e-11, 8.718942e-12, 1.378202e-11, 1.1651748e-11, 7.9914372e-12, 2.2589885e-12, 4.1193777e-13, 3.5602716e-13, 2.0938799e-11, 2.5269481e-11, 1.4724497e-11, 2.2813083e-11, 2.8044115e-11, 3.1476003e-11, 5.1240791e-11, 3.116077e-11, 4.8701916e-11, 1.4031005e-12, 4.8881208e-11, 1.3291496e-11, 3.5871044e-11, 1.2820202e-11, 2.3258256e-11, 2.273772e-12, 2.8150934e-11, 1.1085417e-12, 1.6619122e-11, 4.5584372e-12, 4.3841473e-12, 2.1139322e-12, 3.0644124e-12, 1.1742783e-11, 4.1777338e-12, 1.7036172e-11, 5.4652338e-12, 3.793529e-11, 1.9054957e-11, 2.8574321e-11, 1.9084857e-11, 8.7654045e-12, 9.5515988e-12, 3.4541194e-12, 1.4369359e-11, 2.913465e-12, 1.5769125e-11, 2.4605112e-12, 1.4840209e-12, 2.4542532e-11, 7.2936106e-12, 2.9159214e-11, 3.3566371e-12, 1.9202681e-11, 1.3955643e-11, 1.1239477e-11, 2.3841371e-11, 1.4453503e-11, 1.159417e-11, 6.5890036e-12, 2.2701706e-11, 3.6958577e-11, 3.4684249e-11, 2.9639512e-11, 2.7414648e-11, 4.862233e-11, 2.9069958e-11, 3.5153987e-11, 3.4429039e-11, 2.6555981e-11, 4.0850644e-11, 3.0675804e-11, 5.1219449e-11, 4.77441e-12, 2.655398e-11, 3.1386969e-11, 3.4213511e-11, 3.624141e-11, 1.6622679e-11, 2.5780791e-11, 2.4026665e-11, 3.4672912e-11, 3.4961802e-11, 4.0297207e-11, 1.2481292e-11, 2.0136821e-11, 1.155471e-11, 6.5982295e-12, 1.4902899e-11, 5.9878813e-12, 8.4771815e-12, 3.4797627e-11, 1.4078135e-11, 1.2861551e-11, 1.4217078e-11, 2.1404981e-12, 1.2843099e-11, 6.4858527e-13, 1.2323787e-11, 1.2841877e-11, 3.1050505e-11, 4.7659733e-11, 1.9660414e-11, 5.4314429e-11, 2.442382e-11, 5.7484994e-11, 1.7082524e-11, 2.6238524e-11, 2.5719323e-11, 3.2529301e-12, 1.2547429e-11, 2.1220464e-12, 1.3222358e-11, 5.7659062e-12, 2.8632788e-11, 6.9821563e-12, 8.9501429e-12, 3.6701033e-11, 9.392537e-12, 2.6822418e-11, 2.0672807e-11, 3.2724488e-11, 2.9320499e-11, 1.7357964e-11, 2.0273208e-11, 5.9623159e-13, 3.8840641e-12, 1.1987434e-11, 1.1992325e-11, 1.167987e-11, 1.5016833e-11, 6.9690401e-12, 1.071016e-11, 5.2178044e-12, 1.2835207e-11, 3.3371851e-12, 1.4056015e-11, 1.9366189e-11, 1.4011331e-11, 2.3000156e-11, 5.0676683e-11, 3.700215e-12, 3.983914e-11, 2.8753501e-11, 4.2976137e-11, 3.1558369e-11, 4.0128364e-11, 2.7488788e-11, 4.5937731e-11, 3.1377521e-11, 3.7956298e-11, 2.371899e-11, 3.973121e-11, 1.0394926e-11, 2.6689255e-11, 1.6875999e-11, 2.4361129e-11, 5.4975797e-12, 3.1841145e-11, 1.5992656e-11, 1.7503243e-11, 1.3029505e-11, 1.2633018e-11, 1.9364521e-11, 9.046736e-12, 4.2479833e-12, 3.8152596e-12, 3.0043891e-12, 1.8084357e-11, 1.1009721e-11, 2.5575378e-11, 2.2657022e-11, 2.4589551e-11, 2.361206e-11, 2.7337952e-11, 2.7915287e-11, 7.6091777e-12, 8.3942603e-12, 2.236024e-11, 1.2721719e-11, 1.8846431e-11, 2.3197232e-11, 1.0804974e-11, 1.9368745e-11, 4.2606548e-12, 7.4951334e-13, 1.3374862e-11, 4.3480221e-12, 1.0584111e-11, 1.3272933e-12, 1.8003215e-11, 1.7960198e-11, 2.2397699e-11, 3.3285484e-11, 3.7689861e-11, 5.3303481e-11, 9.9480416e-11, 7.7390503e-11, 1.7477177e-10, 2.272775e-10, 3.0180055e-10, 4.3190998e-10, 6.1628025e-10, 8.5127097e-10, 1.2009967e-09, 1.6950411e-09, 2.3772034e-09, 3.3206575e-09, 4.6423437e-09, 6.4769579e-09, 9.0289383e-09, 1.2518788e-08, 1.7366293e-08, 2.3993656e-08, 3.3123488e-08, 4.5587198e-08, 6.2621576e-08, 8.5697329e-08, 1.1700797e-07, 1.5926845e-07, 2.1624124e-07, 2.9268777e-07, 3.9509373e-07, 5.31683e-07, 7.1341492e-07, 9.5435111e-07, 1.2728411e-06, 1.6923936e-06, 2.2433017e-06, 2.9642088e-06, 3.9044963e-06, 5.1265713e-06, 6.7095317e-06, 8.7526142e-06, 1.1380275e-05, 1.4747547e-05, 1.9046987e-05, 2.4516235e-05, 3.1447689e-05, 4.0198829e-05, 5.120511e-05, 6.499374e-05, 8.2200111e-05, 0.0001035856, 0.0001300579, 0.0001626927, 0.00020275786, 0.0002517386, 0.00031136464, 0.00038363743, 0.00047085867, 0.0005756576, 0.00070101771, 0.00085030094, 0.0010272691, 0.0012361002, 0.0014814008, 0.0017682101, 0.0021019974, 0.0024886507, 0.0029344562, 0.0034460673, 0.0040304647, 0.0046949055, 0.0054468639, 0.0062939633, 0.0072439014, 0.0083043699, 0.0094829708, 0.010787131, 0.012224019, 0.013800462, 0.015522872, 0.017397174, 0.019428746, 0.02162237, 0.023982191, 0.026511687, 0.029213656, 0.032090202, 0.03514275, 0.038372053, 0.041778217, 0.045360735, 0.04911852, 0.053049949, 0.057152909, 0.061424846, 0.06586281, 0.070463511, 0.075223362, 0.080138533, 0.085204989, 0.090418541, 0.09577488, 0.10126961, 0.1068983, 0.11265649, 0.11853973, 0.12454359, 0.13066372, 0.13689581, 0.14323565, 0.14967913, 0.15622222, 0.16286103, 0.16959178, 0.17641082, 0.1833146, 0.19029974, 0.19736295, 0.20450109, 0.21171115, 0.21899023, 0.22633556, 0.23374448, 0.24121448, 0.24874313, 0.25632813, 0.26396728, 0.27165847, 0.27939973, 0.28718915, 0.29502494, 0.30290538, 0.31082886, 0.31879385, 0.32679891, 0.33484267, 0.34292387, 0.35104133, 0.35919394, 0.36738069, 0.37560068, 0.3838531, 0.39213724, 0.40045251, 0.40879849, 0.41717482, 0.42558146, 0.43401829, 0.442486, 0.45098432, 0.45951561, 0.46807855, 0.47667818, 0.48531154, 0.49398337, 0.50269278, 0.51142777, 0.52019435, 0.52894898, 0.53767062, 0.54619037, 0.55499055, 0.56387567, 0.57088999, 0.58186201, 0.5861534, 0.60021703, 0.60134738, 0.61785314, 0.61911379, 0.63651665, 0.63678505, 0.65784138, 0.6578795, 0.68603009, 0.68845669, 0.71563473, 0.7134741, 0.71776554, 0.72108445, 0.72489199, 0.72923484, 0.73324986, 0.73173841, 0.73678235, 0.73840361, 0.74979991, 0.75581631, 0.77310827, 0.7704936, 0.78042619, 0.78220028, 0.7940975, 0.79340896, 0.80760385, 0.81136595, 0.80745767, 0.80743041, 0.80738714, 0.8133333, 0.81768179, 0.83020585, 0.83392377, 0.84706516, 0.84821172, 0.84909587, 0.85421756, 0.85347514, 0.86521386, 0.86563354, 0.88757134, 0.88371381, 0.89109113, 0.89310991, 0.89495336, 0.89530943, 0.90088965, 0.9056695, 0.90624354, 0.90462222, 0.90913183, 0.90974483, 0.91466033, 0.91320631, 0.91956892, 0.91835912, 0.92343729, 0.92382604, 0.92693279, 0.92690753, 0.92814953, 0.92854157, 0.92852411, 0.92780793, 0.92735543, 0.92691682, 0.92688725, 0.9267973, 0.92683193, 0.92684918, 0.92670024, 0.92654014, 0.92619538, 0.92608007, 0.92586642, 0.92592779, 0.92550746, 0.92549336, 0.92519671, 0.92510795, 0.92486953, 0.92480406, 0.92477448, 0.92478989, 0.92478722, 0.92486421, 0.92485254, 0.92500294, 0.92502212, 0.92520048, 0.92511055, 0.92517063, 0.92517352, 0.92527893, 0.92528055, 0.92535972, 0.92536251, 0.92539352, 0.92544885, 0.92554893, 0.92559441, 0.92564226, 0.92546138, 0.92548614, 0.92552699, 0.92546651, 0.92542342, 0.92534365, 0.92535393, 0.92537345, 0.92523031, 0.9252568, 0.92505143, 0.9249375, 0.92487305, 0.92485538, 0.92463872, 0.92422622, 0.92384466, 0.92351762, 0.92330762, 0.92339761, 0.92297597, 0.92342119, 0.92266706, 0.92357812, 0.92389217, 0.92388786, 0.92420779, 0.92468576, 0.92435758, 0.92440925, 0.92437358, 0.92438647, 0.92439618, 0.9243746, 0.92442331, 0.92447101, 0.92455341, 0.92467416, 0.92476762, 0.92486624, 0.92492277, 0.92502235, 0.92511518, 0.92534355, 0.92523595, 0.92525984, 0.92497355, 0.92495751, 0.92494348, 0.92493844, 0.92494037, 0.9249994, 0.92507841, 0.92526106, 0.92523889, 0.92552905, 0.92556646, 0.92580527, 0.92587979, 0.92601391, 0.9260997, 0.92623408, 0.92650175, 0.92670573, 0.92672, 0.9264975, 0.92642097, 0.92643383, 0.92653644, 0.92657195, 0.92656547, 0.92653991, 0.92654973, 0.92677317, 0.92675649, 0.92710071, 0.92713023, 0.92744911, 0.92763419, 0.92775855, 0.92771742, 0.92759541, 0.92761257, 0.92770025, 0.92775435, 0.92774143, 0.92765611, 0.92784568, 0.92794316, 0.92835903, 0.92857216, 0.92895711, 0.92898694, 0.92887355, 0.92885884, 0.92890899, 0.92882222, 0.92849467, 0.92815199, 0.92705378, 0.92504573, 0.92195214, 0.91754425, 0.91146947, 0.90331449, 0.89244729, 0.87812935, 0.85940026, 0.83510999, 0.80387083, 0.7640899, 0.7140365, 0.65203482, 0.57693332, 0.48907501, 0.39176494, 0.29237997, 0.20176242, 0.12922921, 0.077781305, 0.04470325, 0.024914804, 0.013636957, 0.0073884694, 0.0039820163, 0.0021403102, 0.0011488503, 0.0006162604, 0.00033046778, 0.0001771866, 9.4995694e-05, 5.0928843e-05, 2.7303412e-05, 1.4637492e-05, 7.8471456e-06, 4.2068227e-06, 2.2552263e-06, 1.2090172e-06, 6.4813081e-07, 3.4746604e-07, 1.8628374e-07, 9.9837153e-08, 5.3508618e-08, 2.8684448e-08, 1.5368512e-08, 8.2270942e-09, 4.4169899e-09, 2.3592016e-09, 1.2645366e-09, 6.5020614e-10, 3.5471392e-10, 1.6778529e-10, 1.0050526e-10, 5.1615698e-11, 1.0800772e-11, 1.7813076e-11, 4.995311e-11, 3.1669195e-11, 3.3961344e-11, 1.1708041e-11, 2.5872614e-11, 1.0639829e-11, 1.9704757e-11, 4.8069532e-12, 1.7319594e-11, 2.2914165e-11, 8.8837842e-12, 1.4515871e-12, 4.1505313e-12, 1.3497718e-11, 2.0270718e-11, 3.6340735e-12, 4.1322172e-12, 2.1671026e-11, 5.2655829e-12, 2.0408351e-11, 1.8707248e-11, 2.5831435e-11, 8.2879649e-13, 1.7264541e-11, 2.4574207e-13, 1.8723787e-11, 5.4721549e-11, 5.3244099e-12, 4.0799387e-12, 3.1560754e-11, 1.171348e-11, 1.5634696e-11, 1.064105e-12, 1.6620661e-11, 1.1558643e-11, 1.7717288e-11, 1.1078591e-11, 1.8877403e-11, 2.0996179e-11, 1.401018e-11, 1.9477884e-11, 1.7053762e-11, 2.1874811e-12, 2.624145e-11, 6.7389027e-11, 4.4233116e-11, 2.6371202e-11, 1.7523158e-11, 1.1761985e-11, 1.7927844e-11, 5.71389e-12, 1.9180751e-11, 1.1333324e-11, 1.6342287e-11, 1.9778013e-11, 1.501457e-11, 2.0305681e-11, 2.9919033e-11, 4.83337e-12, 3.7838718e-11, 4.8999667e-12, 4.1883472e-11, 2.0392146e-11, 3.8322654e-11, 6.206606e-11, 4.4075393e-11, 3.2064669e-11, 5.9149122e-11, 5.2948188e-11, 6.3164129e-11, 8.962113e-11, 4.4416146e-11, 1.0008559e-10, 3.4554944e-11, 7.4140605e-11, 1.188985e-11, 6.6591309e-11, 3.9916093e-11, 5.8978968e-11, 4.1150352e-11, 1.2497435e-11, 9.8640881e-13, 1.3660214e-11, 1.4786143e-11, 1.1291035e-11, 2.8940616e-11, 2.9410234e-12, 3.2128269e-11, 2.2550769e-11, 2.3148697e-11, 4.3842193e-11, 2.3608103e-11, 6.6996661e-11, 2.563664e-11, 8.4134335e-11, 2.7177578e-11, 8.6780779e-11, 7.6754528e-11, 9.3666772e-11, 7.6846209e-11, 4.7693483e-11, 3.9477664e-11, 3.5640137e-11, 3.4006408e-11, 1.3857673e-12, 2.7787826e-11, 1.7218922e-11, 8.4016237e-12, 1.8166372e-11, 2.496257e-11, 7.3955687e-13, 2.7269148e-11, 2.6721834e-11, 1.790276e-11, 1.3086927e-11, 4.7405896e-11, 4.2377064e-11, 1.2679133e-11, 4.8221706e-11, 5.814562e-12, 1.7775671e-11, 2.2400926e-12, 5.3610382e-13, 3.6900148e-12, 5.3574531e-11, 1.0308511e-11, 3.1199244e-11, 1.5624707e-11, 1.2150577e-12, 1.1282599e-11, 1.3037423e-12, 3.3328342e-12, 3.5065297e-11, 2.928148e-12, 1.0302739e-11, 1.7476874e-11, 2.517457e-11, 5.6404116e-12, 6.4988436e-11, 3.1622356e-11, 7.7872687e-11, 4.7857644e-11, 7.8295132e-11, 4.5235286e-11, 4.5798916e-11, 2.2290264e-11, 3.8032182e-11, 3.4512877e-11, 5.2836861e-11, 4.524805e-11, 7.8457073e-11, 3.9417283e-11, 6.1127601e-11, 4.0157173e-11, 3.5567658e-11, 2.9153947e-11, 1.1805273e-11, 2.9678064e-11, 5.7686103e-12, 5.7457454e-12, 3.2302197e-11, 4.9529666e-11, 4.6999878e-11, 5.174534e-11, 1.7997327e-11, 2.8981795e-11, 5.713224e-12, 7.3452883e-12, 1.7813853e-11, 8.047995e-12, 2.8741158e-11, 1.1843011e-11, 3.2613315e-11, 3.2346595e-11, 1.4849854e-11, 3.6456059e-11, 3.2138592e-11, 2.9605806e-11, 4.3727425e-12, 3.0369671e-11, 2.1015048e-11, 3.601652e-11, 1.1914491e-11, 1.3487728e-11, 3.9754928e-12, 1.0703429e-11, 7.4307541e-12, 4.1479785e-12, 1.0173985e-11, 2.0516016e-11, 1.3770764e-11, 1.0646267e-11, 1.7800534e-11, 3.2188317e-11, 3.6530203e-11, 6.5765398e-12, 2.0016763e-12, 1.8334085e-12, 1.0266888e-11, 1.4851519e-11, 2.2044189e-11, 6.0457638e-12, 2.5460048e-11, 1.4669155e-11, 2.4177394e-11, 5.8807037e-11, 6.2834032e-12, 6.6183848e-12, 1.6271806e-13, 1.8075134e-11, 2.2461973e-12, 5.3903408e-12, 1.6028505e-11, 4.0313232e-13, 3.2548272e-11, 4.1948181e-12, 1.1798724e-12, 6.5309211e-12, 6.6507952e-12, 8.8736836e-12, 1.6863184e-11, 1.6735319e-11, 1.9874467e-11, 1.2464469e-11, 2.6440019e-12, 9.8318998e-12, 2.0435212e-12, 1.1405914e-11, 1.9396969e-11, 1.3411475e-12, 8.558903e-12, 1.631254e-11, 8.5403669e-12, 4.0904832e-12, 8.2904072e-12, 1.7191951e-12, 5.3472749e-12, 2.5418536e-11, 1.5305265e-11, 7.2793575e-12, 5.020973e-11, 1.3790522e-11, 2.0260951e-12, 7.3462872e-12, 1.5602508e-12, 1.2291651e-11, 1.3710272e-11, 5.3200812e-12, 7.043827e-12, 8.1839633e-12, 3.117982e-11, 1.4296324e-11, 3.3934817e-11, 9.2874715e-12, 1.71975e-11, 1.5451111e-11, 2.1490771e-12, 1.0344473e-11, 4.5709788e-12, 6.2577634e-12, 2.0089797e-11, 4.5736648e-11, 3.6199883e-11, 2.7324757e-11, 5.4422973e-11, 3.1747225e-11, 3.6302997e-11, 4.2841466e-11, 5.7356338e-11, 5.2325509e-11, 5.2084095e-11, 3.44798e-11, 9.686164e-12, 1.4551611e-11, 4.7665845e-11, 4.0686173e-12, 1.1008331e-11, 2.4060184e-11, 1.879005e-11, 2.6862908e-11, 3.4303985e-12, 7.5572879e-12, 1.8099951e-20];\nlet data4 = [2.9640062e-21, 9.3329583e-12, 2.7505128e-12, 1.2046123e-11, 9.4759025e-13, 1.3365413e-11, 2.8670914e-11, 2.0633236e-11, 2.3636847e-11, 3.4316662e-12, 2.0934353e-11, 2.3455777e-12, 5.9056272e-12, 1.0987934e-11, 1.5653969e-11, 2.2826977e-11, 1.0468955e-11, 6.6778159e-12, 7.2381446e-12, 8.0519052e-12, 1.0072245e-11, 4.5852253e-12, 9.4651207e-12, 1.260145e-11, 3.3677525e-12, 6.1690628e-12, 4.4931896e-12, 2.3751447e-12, 7.724e-12, 1.3185121e-12, 1.6603671e-11, 1.4090473e-11, 8.0091108e-12, 2.9737105e-12, 4.5938954e-12, 1.2772628e-11, 2.4963029e-12, 4.7423975e-12, 1.1312616e-11, 1.2850213e-11, 1.2648024e-11, 1.9927407e-11, 5.9455315e-12, 1.6689038e-11, 2.1524916e-11, 3.2399806e-11, 1.0232752e-11, 7.1952391e-12, 6.7022699e-12, 1.3764457e-11, 1.1613733e-11, 1.7275043e-11, 1.6410819e-12, 2.666369e-12, 3.8416032e-12, 1.6578661e-12, 1.1866276e-11, 6.4615097e-12, 8.1140404e-12, 3.4703479e-12, 1.5422657e-12, 3.8004761e-12, 1.1784577e-12, 1.2324898e-11, 1.3230583e-11, 3.6088461e-12, 1.758383e-11, 1.4494518e-13, 1.2159945e-11, 1.0882004e-12, 1.4816533e-11, 8.6553618e-12, 1.9557374e-11, 2.2128373e-11, 3.168564e-12, 1.1052737e-11, 7.2584859e-12, 1.0890897e-12, 1.6109479e-11, 4.9710419e-12, 1.3393535e-11, 1.7507244e-11, 7.0728583e-12, 3.611725e-11, 7.3771987e-12, 1.8627457e-11, 2.3087856e-12, 2.7133872e-12, 4.2321994e-12, 2.7794684e-11, 6.4452812e-12, 2.5169665e-11, 8.9348037e-12, 1.2712715e-12, 1.5921295e-11, 1.0449725e-11, 6.3035594e-13, 1.2070577e-11, 1.1566381e-11, 3.5177663e-11, 1.4124486e-11, 4.1937956e-11, 1.7787131e-11, 4.9642726e-11, 2.4534752e-11, 3.7980641e-11, 3.7185554e-12, 2.2332341e-11, 4.5134197e-12, 2.1476786e-11, 1.8698596e-11, 1.5798803e-11, 3.1917953e-12, 1.737775e-11, 1.1408987e-11, 7.2948333e-12, 1.8829758e-11, 4.0927008e-12, 3.0558536e-11, 4.9908286e-14, 2.5212015e-11, 1.9438661e-11, 2.7429542e-12, 1.734985e-11, 1.2607119e-12, 1.4012776e-11, 2.0970145e-11, 3.2229629e-11, 2.7516688e-11, 3.1972752e-11, 3.8435373e-11, 1.5694985e-11, 2.1617841e-11, 3.5497899e-11, 2.7793128e-11, 3.0138373e-11, 1.1688318e-11, 4.4370122e-11, 3.9459771e-12, 2.8765617e-11, 5.9882147e-12, 1.1967093e-11, 1.1350186e-11, 2.7869714e-12, 3.1948409e-11, 1.1738559e-11, 3.4116584e-12, 1.1020503e-11, 1.8829537e-13, 1.7159998e-11, 2.3805913e-12, 8.3825892e-12, 7.3541897e-12, 1.4197737e-11, 6.3963733e-12, 1.9021833e-11, 1.0141939e-11, 3.5838587e-11, 1.2702378e-11, 6.4226057e-12, 1.1199794e-11, 1.5978428e-12, 1.847851e-11, 9.7903582e-12, 2.389328e-11, 1.1467788e-12, 1.2559545e-11, 8.4380551e-12, 5.9497553e-12, 8.2975561e-12, 1.7023279e-12, 6.496301e-12, 2.0455723e-12, 3.3916618e-11, 1.1009943e-11, 2.0572546e-11, 7.4501159e-12, 1.6909234e-11, 1.3017278e-12, 2.511242e-11, 1.2519307e-11, 1.3066964e-11, 9.6181802e-12, 2.9619282e-12, 8.4008185e-12, 6.7134964e-12, 6.4966344e-12, 3.0185057e-12, 9.5896135e-12, 5.3267356e-12, 2.0195844e-11, 5.2957235e-12, 1.6285881e-11, 4.8516622e-12, 1.6781518e-11, 4.7132751e-12, 1.7246921e-11, 3.1046836e-11, 3.3466221e-11, 4.5161096e-11, 2.7890166e-11, 4.8981358e-11, 1.9105087e-11, 3.9502787e-11, 4.4925449e-11, 1.3337403e-11, 2.8367462e-11, 3.8099576e-11, 3.391584e-11, 2.2406369e-11, 4.5648174e-11, 3.0683362e-11, 1.1119319e-11, 2.2178503e-11, 3.9817688e-11, 4.3980638e-11, 4.2083457e-11, 3.1904503e-11, 3.5951408e-11, 2.0441495e-11, 3.4121142e-11, 2.3310165e-11, 4.710474e-11, 6.8178703e-12, 1.8060793e-11, 4.0326774e-12, 2.5641959e-11, 9.9446403e-12, 1.5113203e-11, 3.1063176e-12, 1.5865162e-11, 2.2517079e-11, 1.3830149e-11, 1.5724997e-12, 1.6482735e-11, 6.9053487e-12, 2.8235633e-11, 5.6019536e-12, 9.9887685e-12, 1.6630682e-11, 1.2960591e-13, 3.5512682e-12, 1.0279659e-11, 1.9133098e-11, 1.8250644e-11, 2.2588773e-12, 2.7064401e-11, 1.0553543e-11, 1.6625013e-11, 2.5463223e-12, 1.8596112e-11, 4.1845142e-12, 1.1992991e-11, 2.5180225e-11, 1.9251144e-11, 7.6910983e-12, 2.1652188e-11, 2.3425098e-11, 6.2203049e-12, 9.2353648e-12, 5.592172e-12, 1.6659804e-11, 1.4916794e-11, 8.5797769e-12, 2.5034946e-11, 2.176701e-11, 1.3789356e-11, 1.8613452e-11, 6.2498719e-12, 3.7386743e-12, 1.1784355e-11, 5.3595261e-12, 1.5875055e-12, 2.5069737e-11, 1.8245976e-12, 1.5287716e-11, 1.2674923e-12, 1.5658749e-11, 4.4738488e-12, 1.0064131e-11, 2.1842484e-11, 1.1868499e-11, 3.7473221e-11, 5.8434918e-12, 1.7942524e-11, 5.2399241e-12, 2.1522137e-11, 2.8356569e-12, 1.2945806e-11, 7.3661946e-13, 2.1775121e-13, 2.5093969e-11, 2.5642182e-11, 5.9632939e-11, 9.0133341e-11, 1.6135389e-10, 2.3653087e-10, 3.4442833e-10, 5.2040302e-10, 7.5668623e-10, 1.0945064e-09, 1.5515373e-09, 2.1963396e-09, 3.1317283e-09, 4.3789956e-09, 6.1486076e-09, 8.5833479e-09, 1.19644e-08, 1.6609804e-08, 2.3053427e-08, 3.1830126e-08, 4.3877079e-08, 6.0203165e-08, 8.2486321e-08, 1.1266521e-07, 1.5346586e-07, 2.0842465e-07, 2.8222683e-07, 3.8105991e-07, 5.1301255e-07, 6.8860458e-07, 9.2150284e-07, 1.2294442e-06, 1.6352882e-06, 2.1683996e-06, 2.8662775e-06, 3.7768487e-06, 4.960847e-06, 6.4950875e-06, 8.4761234e-06, 1.1025082e-05, 1.4292922e-05, 1.8467174e-05, 2.3779574e-05, 3.0515209e-05, 3.9023052e-05, 4.9728285e-05, 6.3146081e-05, 7.9897671e-05, 0.00010072802, 0.00012652577, 0.00015834491, 0.0001974285, 0.00024523382, 0.00030345928, 0.00037407188, 0.00045933524, 0.00056183756, 0.00068451808, 0.00083069205, 0.0010040722, 0.0012087865, 0.0014493903, 0.0017308722, 0.0020586523, 0.0024385723, 0.0028768758, 0.0033801792, 0.0039554328, 0.0046098717, 0.0053509572, 0.0061863106, 0.0071236385, 0.0081706536, 0.0093349915, 0.010624125, 0.012045281, 0.013605355, 0.01531084, 0.01716775, 0.019181563, 0.021357164, 0.023698808, 0.026210085, 0.028893907, 0.031752493, 0.03478738, 0.037999428, 0.041388851, 0.044955238, 0.048697596, 0.052614388, 0.056703578, 0.060962683, 0.065388817, 0.069978743, 0.074728923, 0.079635565, 0.084694668, 0.08990207, 0.095253481, 0.10074453, 0.10637077, 0.11212778, 0.11801109, 0.12401628, 0.13013899, 0.13637492, 0.14271983, 0.1491696, 0.15572022, 0.16236776, 0.16910843, 0.17593856, 0.18285462, 0.18985317, 0.19693094, 0.20408476, 0.2113116, 0.21860854, 0.2259728, 0.23340171, 0.24089272, 0.24844338, 0.25605136, 0.26371444, 0.27143049, 0.27919747, 0.28701346, 0.2948766, 0.30278512, 0.31073734, 0.31873165, 0.32676651, 0.33484045, 0.34295207, 0.35110001, 0.35928299, 0.36749977, 0.37574917, 0.38403004, 0.39234128, 0.40068184, 0.4090507, 0.41744686, 0.42586937, 0.43431733, 0.44278987, 0.4512863, 0.45980599, 0.46834908, 0.47691568, 0.48550833, 0.49412819, 0.50277771, 0.51145706, 0.52012893, 0.52870413, 0.53745872, 0.54569641, 0.55388735, 0.56171361, 0.5703083, 0.57884008, 0.58839631, 0.5996874, 0.61464584, 0.63299906, 0.65300355, 0.66843974, 0.67260683, 0.67187109, 0.67378822, 0.67461145, 0.68013213, 0.68891798, 0.69906228, 0.71024186, 0.72634787, 0.72348441, 0.72350901, 0.72400258, 0.72931793, 0.73820286, 0.73928349, 0.74211056, 0.74537831, 0.74721972, 0.75008908, 0.75974998, 0.77083627, 0.77855188, 0.78093807, 0.77979187, 0.78006009, 0.78150724, 0.78188001, 0.78078482, 0.78972435, 0.80253125, 0.81073706, 0.81642665, 0.82116291, 0.82579555, 0.83115008, 0.83771477, 0.84467652, 0.85217798, 0.85965702, 0.86636392, 0.87269061, 0.87912294, 0.8857938, 0.89319124, 0.90139898, 0.90847588, 0.91591374, 0.92256061, 0.92905685, 0.93537009, 0.94484613, 0.95172695, 0.96261748, 0.96689615, 0.97052233, 0.96835432, 0.96371894, 0.95353748, 0.94646765, 0.93869513, 0.93300715, 0.92707869, 0.92303702, 0.91664736, 0.91744421, 0.91719413, 0.91974339, 0.92136019, 0.92451412, 0.92669603, 0.92989174, 0.93016046, 0.93012549, 0.93004485, 0.92979559, 0.92964667, 0.92934676, 0.92917201, 0.92833142, 0.92825144, 0.92832679, 0.92894541, 0.928823, 0.9286215, 0.92814636, 0.92772128, 0.92714753, 0.92684216, 0.92646554, 0.92618261, 0.92590351, 0.92572693, 0.92561247, 0.925564, 0.92557124, 0.92559663, 0.92590674, 0.92589498, 0.9258723, 0.92548199, 0.92527586, 0.92514624, 0.92517072, 0.92519455, 0.92517294, 0.92511427, 0.92507073, 0.92508099, 0.9251498, 0.92523651, 0.92531842, 0.92532105, 0.92534056, 0.92546288, 0.92567932, 0.92587718, 0.92603413, 0.92630519, 0.92622569, 0.92618911, 0.9260881, 0.92611963, 0.92617353, 0.92629568, 0.92638431, 0.92644902, 0.92639186, 0.92632513, 0.92625433, 0.92626243, 0.92623303, 0.92622917, 0.92625492, 0.92623275, 0.92630611, 0.92630213, 0.92631903, 0.92629826, 0.92631528, 0.92630902, 0.92627638, 0.92626638, 0.92621553, 0.92630114, 0.92641228, 0.92647963, 0.92653698, 0.92665872, 0.92689599, 0.92705079, 0.92742487, 0.92732687, 0.9273452, 0.9272198, 0.92721382, 0.92703998, 0.92694653, 0.92701832, 0.92741031, 0.92757705, 0.92722499, 0.9266838, 0.92646418, 0.9263108, 0.92630487, 0.92665255, 0.92756567, 0.92795025, 0.92775351, 0.92732948, 0.92723394, 0.92680679, 0.92634006, 0.92634952, 0.92671698, 0.92693975, 0.92722617, 0.92694944, 0.9269312, 0.92720149, 0.92852329, 0.93030914, 0.93027955, 0.92985191, 0.92960996, 0.92935124, 0.92847124, 0.92810666, 0.92809806, 0.92914492, 0.93069296, 0.93146786, 0.93042349, 0.93049376, 0.93052707, 0.93109751, 0.93098899, 0.93069666, 0.93047184, 0.9297293, 0.92802123, 0.92532139, 0.92149254, 0.91629255, 0.90932378, 0.90007065, 0.88787749, 0.87192529, 0.85120664, 0.82450355, 0.79038292, 0.747226, 0.69333741, 0.6272038, 0.5481055, 0.45723604, 0.35909776, 0.26221379, 0.1771453, 0.11142655, 0.066168553, 0.037697689, 0.020907893, 0.011417705, 0.0061818558, 0.0033325675, 0.0017925853, 0.00096317242, 0.00051724591, 0.00027770297, 0.00014907787, 8.0024386e-05, 4.2955751e-05, 2.3057529e-05, 1.2376637e-05, 6.6433276e-06, 3.5659077e-06, 1.9140184e-06, 1.0273475e-06, 5.5140358e-07, 2.9595236e-07, 1.5884068e-07, 8.5240279e-08, 4.5735953e-08, 2.4536113e-08, 1.3110006e-08, 7.0446593e-09, 3.7344034e-09, 2.0400243e-09, 1.0665481e-09, 5.4378742e-10, 2.7004349e-10, 1.5812854e-10, 7.4338287e-11, 3.3561209e-11, 2.8333919e-11, 8.868467e-13, 3.0858713e-12, 3.5963354e-12, 3.4917785e-12, 1.017121e-11, 2.2028983e-11, 4.0346086e-11, 1.7580209e-11, 4.2501933e-11, 1.4422969e-11, 1.8196895e-11, 4.8419165e-12, 1.6136947e-11, 1.9557134e-11, 1.3521138e-11, 2.5140272e-11, 2.0023977e-11, 3.3199034e-11, 4.6221473e-11, 6.582134e-11, 1.3640679e-11, 1.8451073e-11, 2.6909526e-12, 2.8481986e-11, 3.7241345e-11, 2.7911807e-11, 3.1812378e-11, 2.4314584e-11, 3.0230262e-11, 8.3786478e-12, 3.2504762e-12, 2.3156355e-11, 2.5427859e-11, 1.8178248e-11, 2.6479089e-11, 2.9286697e-11, 6.2549886e-12, 2.2235655e-11, 9.7529828e-12, 8.7256168e-12, 2.3332615e-11, 7.4472923e-12, 3.7661016e-11, 3.9459128e-11, 4.3172452e-11, 4.6146551e-11, 7.0674356e-11, 3.8188906e-11, 2.234998e-11, 1.691735e-11, 2.136912e-11, 1.0642604e-11, 2.3709996e-11, 1.7593085e-11, 4.2050074e-11, 5.7920745e-11, 2.3162904e-11, 2.0006773e-11, 4.6649913e-12, 2.0054834e-11, 3.429455e-11, 4.7810915e-12, 1.6627987e-11, 3.419521e-12, 3.9087851e-12, 2.5789369e-11, 8.5253827e-12, 4.5741865e-11, 3.9988016e-12, 4.2880647e-11, 4.4876219e-12, 5.7759137e-11, 1.0324161e-11, 4.5343838e-11, 1.571317e-11, 4.2209574e-11, 3.6910248e-11, 4.0849557e-11, 1.7327808e-11, 6.036085e-11, 3.0158338e-12, 6.5229405e-11, 2.2726917e-11, 1.035959e-10, 1.3112123e-11, 7.8468617e-11, 2.6461552e-11, 9.2848187e-11, 4.8677117e-11, 7.3172067e-11, 3.0248465e-11, 2.8176973e-11, 3.4641409e-13, 4.5031611e-12, 1.198919e-11, 5.4409543e-12, 2.3406093e-11, 3.6406222e-12, 5.9825856e-11, 5.5350777e-11, 6.1321841e-11, 7.566667e-11, 4.7177247e-11, 1.7426815e-11, 3.9422611e-11, 3.2878814e-12, 1.7982232e-12, 2.9966761e-11, 1.5093043e-12, 3.8254837e-11, 6.3659832e-12, 5.8671402e-11, 3.0131144e-11, 3.1009222e-11, 2.9751986e-11, 2.6061527e-12, 1.7776004e-11, 1.8748538e-11, 2.6435912e-11, 8.2280281e-13, 3.9124035e-11, 2.5456274e-11, 6.8715634e-12, 3.539384e-11, 5.4937877e-12, 4.8476439e-11, 3.7622612e-11, 1.7812965e-11, 3.2490666e-11, 1.3793518e-11, 3.0020593e-11, 1.0668244e-11, 3.3360087e-11, 6.4262532e-12, 3.2945411e-11, 5.8499693e-12, 1.1105896e-11, 1.2388216e-11, 1.3703169e-11, 1.0369113e-12, 5.5859132e-12, 1.8173365e-11, 1.6084224e-12, 2.9652202e-11, 1.3880982e-12, 3.0761038e-12, 2.2155628e-12, 1.2362909e-11, 8.4855356e-12, 2.2690733e-11, 1.6411326e-11, 1.5741251e-11, 3.9831626e-11, 9.5729495e-12, 1.8957319e-11, 7.9878359e-12, 7.3632694e-12, 1.4530301e-12, 2.3316964e-11, 1.4322851e-11, 1.6770726e-11, 2.1865821e-11, 3.0555143e-11, 2.9852991e-11, 1.0491763e-11, 3.8597699e-11, 1.0835291e-12, 5.5185839e-11, 7.7102384e-12, 4.2228443e-11, 2.6358549e-11, 7.4350274e-11, 3.3509153e-11, 7.2135821e-11, 3.9783121e-11, 7.1883087e-11, 6.8346466e-11, 1.0074878e-10, 4.945419e-11, 7.1265513e-11, 4.4255093e-11, 4.7498021e-11, 2.0786621e-11, 2.3789135e-11, 1.531259e-11, 4.4703844e-11, 2.086687e-11, 1.5181173e-11, 3.7472991e-11, 5.671046e-12, 1.4036486e-11, 2.6176185e-11, 3.2143364e-11, 2.0150622e-11, 1.6476923e-11, 5.9871808e-11, 4.4838036e-11, 8.377327e-11, 4.2277835e-11, 6.7988065e-11, 2.0570736e-11, 5.2125163e-11, 7.5326471e-12, 4.0375055e-11, 5.1529011e-11, 5.4923447e-12, 5.0088968e-11, 8.3812007e-12, 5.7186738e-11, 4.427485e-11, 4.3078328e-11, 4.2777533e-11, 6.7281806e-11, 2.7674279e-11, 6.5181123e-11, 2.0746774e-11, 4.5545405e-11, 1.2051347e-11, 4.6774892e-11, 3.5612056e-11, 1.0890677e-11, 3.2721868e-11, 2.6763013e-12, 2.1213284e-11, 2.694682e-11, 4.6181182e-11, 3.9528389e-11, 5.5938493e-11, 7.7387863e-11, 4.8343023e-11, 4.6970464e-11, 3.0434492e-11, 2.6478534e-11, 3.7708521e-11, 7.0224384e-11, 5.3415919e-11, 7.0918877e-11, 3.5120794e-11, 4.0638334e-11, 3.359029e-11, 1.6493795e-11, 1.6370813e-11, 1.2935419e-11, 8.2199256e-12, 5.8821577e-12, 2.9659417e-11, 1.4651276e-14, 3.7516168e-12, 2.661539e-12, 1.2588561e-11, 4.1916659e-11, 6.7540424e-11, 2.2157182e-11, 6.5171355e-11, 2.284557e-11, 5.3456321e-11, 6.3659832e-12, 2.8300288e-11, 3.3745682e-12, 3.498305e-11, 6.4931823e-14, 5.2362803e-12, 5.407445e-11, 7.3582746e-12, 3.4267578e-11, 1.3745568e-12, 4.2672865e-11, 1.9696543e-11, 4.5940767e-11, 3.1288928e-11, 1.7027012e-11, 1.6064467e-11, 2.6515051e-11, 1.1543436e-13, 2.1729409e-12, 2.676046e-11, 1.3155522e-11, 7.0774583e-12, 3.9662803e-12, 2.8672231e-11, 1.7701194e-11, 2.2506038e-11, 1.5213916e-11, 2.1611318e-20];\nlet data7 = [2.8477683e-20, 1.9817254e-11, 2.1635317e-10, 1.809108e-10, 3.3037479e-10, 3.1952347e-10, 8.4635997e-11, 6.7923694e-11, 8.1165126e-11, 3.8541257e-11, 2.1220779e-10, 8.8978506e-11, 1.5024543e-10, 1.0109516e-10, 1.1924985e-10, 1.5972819e-10, 1.3589799e-10, 5.5968904e-11, 5.9218579e-11, 1.4418632e-10, 6.8115023e-11, 1.4655948e-10, 2.5399996e-11, 2.3202602e-10, 1.9469538e-11, 2.6029821e-10, 2.6356826e-10, 2.0576201e-10, 2.9054878e-10, 9.7460678e-11, 5.1290831e-10, 2.0877626e-10, 4.8137136e-10, 2.3414674e-10, 4.9323768e-10, 1.7236458e-10, 2.7703685e-10, 2.1815489e-10, 2.2927159e-10, 2.9775453e-10, 3.7796739e-10, 4.2749079e-10, 3.3366027e-10, 3.1802514e-10, 2.4735136e-10, 3.6288265e-10, 3.0970653e-10, 3.5424183e-10, 2.1602941e-10, 2.4179075e-10, 2.952367e-10, 3.8359151e-10, 4.9834974e-10, 4.3116471e-10, 3.7808902e-10, 3.6538443e-10, 5.1141341e-10, 5.2062858e-10, 5.2599717e-10, 5.2491092e-10, 4.512288e-10, 4.7755334e-10, 3.6242088e-10, 3.3089726e-10, 3.088043e-10, 2.425945e-10, 3.1302036e-10, 1.9574006e-10, 3.6476364e-10, 1.7781339e-10, 3.4295644e-10, 1.4802614e-10, 2.1914047e-10, 1.0554173e-10, 2.5820686e-10, 1.8239021e-10, 2.0159706e-10, 2.0936174e-11, 2.02232e-10, 7.9556056e-11, 2.7654249e-10, 1.1959572e-10, 2.5486029e-10, 7.5607268e-12, 1.6671328e-10, 1.8532479e-10, 1.6790936e-10, 2.5386076e-10, 1.3592029e-10, 1.90552e-10, 1.312331e-10, 2.3270266e-10, 5.3277926e-11, 8.607033e-11, 5.2760181e-11, 2.2919825e-11, 1.2535519e-10, 1.6959737e-10, 1.049109e-10, 2.782024e-11, 6.1551883e-11, 4.8213281e-11, 1.0873528e-10, 8.0136791e-11, 1.4437715e-10, 1.7885345e-11, 2.2846276e-10, 2.3411295e-11, 3.2771467e-10, 1.1241968e-10, 3.5625737e-10, 8.5255682e-11, 2.3003975e-10, 7.3182836e-11, 8.2392924e-11, 8.2526453e-11, 2.8599207e-11, 3.3357279e-11, 3.2393904e-11, 6.0353097e-11, 1.6471975e-11, 2.7220928e-11, 6.7487991e-11, 3.4596827e-11, 1.4466908e-10, 1.0913542e-10, 3.886743e-11, 1.7155191e-10, 1.9649472e-10, 3.0039176e-10, 2.1706912e-10, 1.7937359e-10, 5.2531302e-12, 7.9055027e-12, 1.5239417e-10, 6.7756783e-11, 1.0415159e-10, 2.3479438e-10, 7.9120719e-11, 1.484773e-10, 7.5912829e-11, 1.993482e-11, 2.4164178e-10, 2.9148732e-11, 1.3744549e-11, 2.2941906e-10, 2.774089e-10, 2.1098422e-10, 1.3233328e-10, 1.5952605e-10, 1.9464789e-10, 4.7715155e-11, 1.5999093e-10, 7.649121e-11, 2.1009985e-10, 1.452682e-10, 2.0044788e-10, 7.6618975e-12, 3.6200604e-11, 1.8525448e-10, 9.7877338e-11, 2.8069348e-12, 2.0239038e-11, 1.9796622e-11, 1.3152776e-11, 1.9356596e-10, 2.6752626e-11, 2.3772909e-10, 1.430706e-11, 3.2829193e-10, 3.419622e-11, 4.3060049e-10, 1.0813806e-10, 3.7939735e-10, 9.8199581e-11, 3.2751842e-10, 6.5516255e-11, 6.6882809e-11, 1.0962431e-10, 2.4312811e-10, 3.511733e-10, 1.8942962e-10, 2.2945665e-10, 1.4616836e-10, 4.5135341e-11, 9.7068791e-11, 3.8640586e-11, 1.2930635e-10, 8.1348505e-11, 9.5416082e-11, 1.8570819e-10, 1.1855809e-10, 1.9283651e-10, 1.0581354e-10, 1.0844812e-10, 9.5097879e-11, 1.3290397e-10, 3.5893166e-10, 2.5249281e-11, 5.4991348e-10, 9.0886239e-11, 4.3684268e-10, 1.4355966e-10, 5.3188724e-10, 1.2617057e-10, 3.7926679e-10, 1.3789329e-10, 1.6742864e-10, 4.1086368e-11, 7.0177179e-11, 1.2346572e-11, 5.9132882e-14, 7.8648206e-13, 7.0490142e-12, 3.6924912e-12, 5.6042079e-11, 7.2597309e-11, 2.0615028e-10, 2.7642091e-10, 2.6228259e-10, 9.9983201e-11, 2.1552475e-12, 4.8360516e-11, 2.0368089e-11, 8.7008727e-11, 3.7743871e-11, 1.0942598e-10, 1.6518165e-10, 1.242478e-10, 1.4404817e-10, 1.6390056e-10, 3.4234109e-10, 1.440687e-10, 2.7340136e-10, 5.2112998e-11, 1.0796456e-10, 4.6046917e-11, 1.6697214e-10, 6.8456262e-12, 1.0125462e-10, 4.7842905e-11, 2.1396614e-10, 3.5911615e-11, 2.9679157e-10, 1.3415511e-10, 2.7936568e-10, 2.1178514e-10, 4.3080251e-10, 4.2927147e-10, 5.0658213e-10, 4.6356507e-10, 6.5276704e-10, 4.8260318e-10, 6.6818873e-10, 5.6053824e-10, 5.2016442e-10, 5.9334532e-10, 5.4408245e-10, 5.1616447e-10, 4.7639677e-10, 5.8710287e-10, 5.7388639e-10, 5.4723248e-10, 5.8585824e-10, 6.392226e-10, 7.1603609e-10, 6.2675589e-10, 7.8034298e-10, 6.5468454e-10, 7.7678248e-10, 5.9770753e-10, 7.3561387e-10, 5.091355e-10, 5.7069555e-10, 4.4704192e-10, 4.5896522e-10, 5.2184403e-10, 6.2306429e-10, 5.872771e-10, 6.9971574e-10, 6.8471009e-10, 6.7302519e-10, 4.6299314e-10, 6.3234335e-10, 4.7836513e-10, 7.4206463e-10, 5.6813867e-10, 8.0981043e-10, 6.6875664e-10, 7.3005264e-10, 7.0932665e-10, 6.8507835e-10, 6.2430738e-10, 6.9547164e-10, 6.5583485e-10, 5.1924179e-10, 7.0097115e-10, 5.2655282e-10, 6.563908e-10, 5.5960659e-10, 6.619308e-10, 4.9482656e-10, 5.3791057e-10, 4.4873093e-10, 4.3237599e-10, 3.2823616e-10, 4.3226711e-10, 2.2101743e-10, 2.6649277e-10, 1.6903861e-10, 2.1312479e-10, 1.7537258e-10, 1.7326172e-10, 5.3140063e-11, 1.7270464e-11, 2.6298704e-11, 1.2999494e-11, 1.1822559e-11, 1.4736385e-10, 1.4860663e-10, 1.1970659e-10, 4.6003957e-11, 1.29762e-10, 1.6484604e-10, 2.2191799e-10, 7.8584122e-11, 1.1429746e-10, 2.6841091e-11, 1.3831702e-10, 2.2084829e-10, 1.6325195e-10, 2.4149503e-10, 6.1705914e-11, 3.6353002e-10, 9.8185172e-11, 3.4585628e-10, 6.2212222e-12, 1.398224e-10, 6.0760331e-12, 1.6543115e-10, 4.8727664e-11, 3.6482602e-10, 2.8267297e-10, 4.6532468e-10, 1.9670647e-10, 4.4901017e-10, 1.2678165e-10, 4.1018904e-10, 1.8250552e-09, 4.1534681e-09, 9.4402826e-09, 1.9585692e-08, 4.0855308e-08, 8.2272735e-08, 1.637779e-07, 3.2005018e-07, 6.1731524e-07, 1.1731282e-06, 2.1975343e-06, 4.0552083e-06, 7.3716991e-06, 1.3194619e-05, 2.3245815e-05, 4.0291446e-05, 6.867536e-05, 0.00011505047, 0.00018933885, 0.00030591933, 0.00048498838, 0.00075396411, 0.0011487021, 0.0017141973, 0.0025043679, 0.0035805309, 0.0050081363, 0.006852056, 0.0091706344, 0.012009175, 0.01539368, 0.019325493, 0.023778893, 0.028706448, 0.03405052, 0.039752921, 0.045760023, 0.052024883, 0.058507644, 0.065175076, 0.071999732, 0.078959028, 0.086034375, 0.093210427, 0.10047445, 0.10781579, 0.11522552, 0.12269605, 0.1302209, 0.13779453, 0.1454121, 0.15306944, 0.16076286, 0.16848914, 0.1762454, 0.18402908, 0.19183791, 0.19966982, 0.20752299, 0.21539573, 0.22328651, 0.23119396, 0.23911681, 0.24705388, 0.25500412, 0.26296652, 0.27094019, 0.27892425, 0.28691792, 0.29492045, 0.30293117, 0.31094941, 0.31897457, 0.32700609, 0.33504346, 0.34308619, 0.35113386, 0.35918609, 0.36724252, 0.37530278, 0.3833665, 0.39143312, 0.39950231, 0.40757347, 0.41564732, 0.42372248, 0.43180034, 0.43987062, 0.44793718, 0.45597733, 0.46403705, 0.4720927, 0.48028065, 0.4885131, 0.49695726, 0.5053638, 0.51370983, 0.52166575, 0.52911717, 0.53630063, 0.54350976, 0.55065175, 0.5576987, 0.56515963, 0.57414881, 0.58581203, 0.60106133, 0.61920826, 0.63441176, 0.64444496, 0.65045212, 0.6552307, 0.6599221, 0.6650715, 0.67001146, 0.67061167, 0.67113711, 0.67315375, 0.67797767, 0.68199324, 0.68571826, 0.69335833, 0.70237947, 0.70950038, 0.71685984, 0.7241968, 0.73129851, 0.73900574, 0.75115207, 0.75963027, 0.76905855, 0.78322163, 0.79159857, 0.79245248, 0.79107474, 0.78888644, 0.78973313, 0.79291809, 0.80155304, 0.81233827, 0.82142127, 0.82650645, 0.82950388, 0.83326463, 0.83366361, 0.83176001, 0.83146794, 0.83202915, 0.83384987, 0.83933199, 0.84790874, 0.85610776, 0.86331973, 0.86895249, 0.87437673, 0.87886068, 0.88107721, 0.88256128, 0.88637201, 0.8903003, 0.89170068, 0.8913573, 0.88855065, 0.88565698, 0.88533144, 0.88606156, 0.88671645, 0.88791243, 0.88913495, 0.8891744, 0.88764162, 0.88782382, 0.88955391, 0.89185602, 0.89196857, 0.89173273, 0.89275971, 0.89683466, 0.90014227, 0.90019847, 0.89987414, 0.89742712, 0.89417066, 0.89250583, 0.89142793, 0.89044687, 0.89000899, 0.89008642, 0.8905574, 0.89235167, 0.89543507, 0.89656239, 0.89636287, 0.89559705, 0.89308331, 0.89015943, 0.88955618, 0.88997233, 0.8915667, 0.89541263, 0.89933524, 0.90012366, 0.89982421, 0.89974462, 0.89953149, 0.89852051, 0.89717144, 0.8962689, 0.89562133, 0.89390928, 0.88979206, 0.88653296, 0.88673392, 0.88801113, 0.8919161, 0.89805037, 0.90365521, 0.90506388, 0.90454156, 0.90286096, 0.89988196, 0.89693817, 0.89508255, 0.89482766, 0.89446222, 0.8935049, 0.89149568, 0.89126409, 0.89133746, 0.89155296, 0.891861, 0.89210393, 0.89241619, 0.89270213, 0.89185516, 0.8909092, 0.89204971, 0.89389175, 0.89439182, 0.89561993, 0.89863491, 0.89857581, 0.89790874, 0.89807274, 0.8975778, 0.89576727, 0.89454615, 0.89394598, 0.89344243, 0.89313787, 0.89326778, 0.89456251, 0.89627034, 0.89716934, 0.89706067, 0.89644184, 0.8951939, 0.89524545, 0.8955355, 0.89648327, 0.89645648, 0.89620751, 0.89535335, 0.89266434, 0.89107604, 0.89119897, 0.89146252, 0.89201422, 0.89367523, 0.89515785, 0.89514318, 0.89468989, 0.8936907, 0.89203612, 0.89111186, 0.89147443, 0.89267491, 0.89616509, 0.89965218, 0.90041286, 0.90012019, 0.89926374, 0.89733478, 0.89248269, 0.88868208, 0.88865755, 0.88955456, 0.8911347, 0.89408624, 0.89764004, 0.8976562, 0.89715549, 0.8955327, 0.890238, 0.88822536, 0.88957124, 0.89035779, 0.89214842, 0.89442469, 0.90050315, 0.90013322, 0.89675555, 0.88715024, 0.87840912, 0.86407897, 0.85519389, 0.86034735, 0.87677547, 0.89883519, 0.91619161, 0.914784, 0.91060943, 0.90052024, 0.88406818, 0.85282057, 0.8092647, 0.77598062, 0.76502665, 0.74142894, 0.63055733, 0.2403422, 0.024533632, 0.0019871171, 0.00015601923, 1.2184269e-05, 9.5273907e-07, 7.4937229e-08, 5.953439e-09, 4.8536166e-10, 3.6191332e-10, 3.4116245e-10, 3.3277232e-10, 2.2153077e-10, 3.2855396e-10, 8.620493e-11, 8.181629e-11, 3.5578282e-10, 2.3914764e-11, 4.8847353e-10, 2.7332507e-10, 4.7721934e-10, 3.6431553e-10, 2.2384307e-10, 3.9855979e-10, 3.8645977e-10, 3.5036318e-10, 1.726803e-10, 2.9928474e-10, 1.9461675e-10, 3.7171756e-10, 1.7373108e-10, 3.7679966e-10, 4.8863157e-10, 3.8452728e-10, 4.2056852e-10, 3.3878678e-10, 3.6588632e-10, 3.3653803e-10, 1.6154007e-10, 3.2305978e-10, 2.7894117e-10, 6.7424967e-11, 1.0233268e-11, 4.5023441e-11, 8.146e-11, 1.1299926e-10, 7.1518314e-11, 5.3754675e-11, 7.0855331e-11, 1.2622738e-11, 7.8869489e-13, 1.4741204e-10, 5.0156919e-11, 9.4527367e-11, 3.6979398e-11, 1.6238011e-10, 3.9140888e-10, 9.6569923e-11, 4.8952982e-11, 1.125599e-10, 6.9977177e-11, 9.3216288e-11, 8.5504999e-12, 1.6346375e-10, 3.3393236e-10, 1.215359e-10, 1.2327146e-11, 3.1730176e-11, 3.9845058e-12, 1.4821947e-10, 5.8621841e-11, 4.0178273e-11, 8.2939545e-11, 1.962649e-10, 2.6365975e-10, 4.681282e-10, 3.1397343e-10, 1.725423e-10, 3.385972e-10, 1.1452388e-10, 1.2711137e-10, 1.0347447e-10, 9.8208115e-11, 3.625952e-11, 4.4265293e-11, 1.0968569e-10, 1.833644e-10, 1.8868279e-11, 6.4592718e-11, 1.77071e-10, 5.7097743e-11, 7.5745921e-11, 2.433641e-10, 2.6176833e-10, 1.9938034e-10, 7.8585294e-11, 1.7420073e-10, 1.5080546e-10, 7.284895e-11, 1.3081094e-10, 8.2025894e-11, 4.0778175e-12, 2.7453699e-10, 8.3939684e-11, 8.6642635e-11, 4.5338077e-11, 7.5067079e-12, 1.7119446e-10, 4.3341007e-11, 2.2271518e-11, 8.4149852e-11, 2.1526762e-10, 1.1833779e-10, 3.1246775e-10, 1.4383031e-10, 1.5289642e-10, 2.8087521e-11, 2.2263925e-11, 2.8324233e-10, 2.1168632e-10, 2.0249857e-10, 2.7185546e-10, 2.6738573e-10, 2.8651923e-10, 2.1367628e-10, 2.4703077e-11, 3.8862975e-10, 2.8921211e-10, 1.4230467e-10, 4.1436828e-11, 3.7256349e-11, 3.0538214e-10, 4.5553487e-11, 1.5740043e-10, 2.8861295e-10, 3.3890142e-10, 4.2071341e-11, 2.2142564e-10, 1.0395009e-10, 4.7673354e-10, 1.4339627e-10, 5.8287293e-10, 3.3438255e-11, 5.5037913e-10, 3.3458078e-11, 3.7407164e-10, 3.854368e-10, 2.4011775e-10, 4.5061275e-10, 5.4182422e-10, 3.8275743e-10, 2.9087651e-10, 1.220687e-10, 3.0405937e-10, 7.2546675e-11, 3.2877402e-11, 1.3158057e-10, 3.4092286e-10, 2.2212738e-10, 3.3963692e-10, 2.106994e-10, 4.455069e-10, 2.6300736e-10, 1.3576514e-10, 1.1298729e-10, 3.8279119e-10, 1.8344209e-11, 1.172805e-10, 3.006375e-11, 1.700625e-10, 1.9673638e-10, 1.2044465e-10, 2.5815689e-10, 4.2112812e-10, 5.1276697e-11, 6.7210226e-11, 5.7983457e-11, 1.089576e-10, 3.2672554e-11, 2.7578965e-10, 1.468722e-10, 2.9628548e-10, 3.9326858e-10, 4.8068342e-10, 3.7565781e-10, 3.241546e-10, 2.2195177e-10, 4.566839e-10, 4.1441796e-10, 2.0261894e-10, 3.0922788e-10, 1.225869e-10, 3.1332938e-11, 1.8846258e-10, 4.1431616e-10, 2.4652404e-10, 3.3884929e-10, 4.3479405e-10, 3.2627362e-10, 2.5278098e-10, 3.3640669e-10, 3.5546187e-10, 3.7988848e-10, 5.767901e-11, 7.0454888e-11, 4.3509946e-10, 2.1841129e-10, 4.475982e-10, 2.8222015e-10, 5.4257885e-10, 2.8392429e-10, 6.8963281e-10, 3.1406001e-10, 2.7907842e-10, 2.3343131e-10, 3.4284524e-10, 3.6977625e-10, 2.5203559e-10, 1.8537896e-10, 2.9391517e-10, 7.8858797e-11, 1.3702003e-10, 2.4885264e-10, 2.4011127e-10, 4.10332e-10, 4.5736337e-10, 5.3042462e-10, 6.7751041e-11, 3.1341871e-10, 8.3023325e-11, 1.8255445e-10, 3.4044546e-10, 4.3011966e-11, 2.6184625e-10, 5.8955461e-11, 4.8949175e-10, 2.2769705e-10, 2.7286237e-10, 1.112853e-10, 1.7151728e-10, 8.9115615e-11, 4.1614266e-11, 2.5054228e-10, 1.8822545e-10, 6.7626191e-11, 2.1285241e-11, 5.7091015e-11, 4.433511e-10, 3.1274912e-10, 2.2601838e-10, 6.2294587e-11, 3.1449292e-11, 4.4388366e-10, 1.0949398e-10, 2.5631037e-10, 6.2711095e-11, 5.8124669e-10, 4.1696024e-10, 6.5950828e-10, 1.6011349e-10, 3.2415787e-10, 9.7031873e-11, 1.6982715e-10, 6.3710753e-11, 2.1660822e-10, 5.5002667e-11, 4.6249485e-10, 3.5534175e-10, 4.0977061e-10, 1.1044674e-10, 4.1232996e-10, 1.7613872e-10, 4.7531882e-10, 1.4800221e-10, 5.4628135e-10, 8.7973527e-11, 3.8900734e-10, 4.1719918e-11, 3.5080572e-10, 6.1888695e-12, 5.6905546e-11, 1.0672898e-10, 6.678153e-11, 2.1756497e-10, 9.6035733e-12, 4.9392453e-11, 9.1473808e-11, 4.521796e-11, 1.0588006e-10, 7.3530424e-11, 1.4769092e-10, 1.8944487e-11, 7.2548502e-11, 4.0307835e-10, 2.1403273e-10, 3.4677373e-10, 3.4571903e-10, 2.6744556e-10, 2.3754971e-11, 8.9804591e-12, 1.1953095e-11, 1.2903551e-10, 4.1469275e-11, 1.7462034e-11, 2.2420991e-10, 3.2052671e-11, 1.9999565e-10, 3.9288371e-11, 3.8543651e-12, 3.3792944e-11, 6.5628575e-11, 1.7551484e-10, 1.7002088e-10, 2.8506586e-10, 2.4517918e-10, 3.7002737e-11, 6.9367117e-11, 3.875388e-11, 1.3229345e-11, 1.3489459e-11, 1.9190398e-10, 1.0360143e-11, 1.2232169e-11, 7.9270097e-12, 1.782311e-10, 6.749101e-11, 1.1641828e-10, 1.5052055e-10, 1.0297067e-10, 4.3455144e-12, 1.311254e-10, 2.2328563e-18];\nlet data6 = [2.4736089e-21, 3.557215e-11, 1.4491517e-11, 3.1926845e-12, 9.8094767e-12, 6.4086002e-12, 1.0635131e-11, 1.7253035e-11, 7.2617091e-13, 7.0434024e-12, 9.7921366e-12, 5.3706415e-12, 2.0734942e-11, 1.8722161e-11, 1.6536423e-12, 2.9744887e-12, 6.7616262e-12, 4.6114578e-12, 1.6889115e-11, 1.3241588e-11, 6.2568747e-12, 5.2398129e-12, 2.3631512e-11, 1.5845265e-11, 3.2267866e-11, 3.7653514e-12, 2.8384247e-11, 5.9523119e-12, 4.0711368e-12, 3.092868e-12, 1.645528e-12, 1.4564101e-11, 1.4103256e-11, 1.1685094e-11, 2.1664859e-11, 3.3110082e-11, 5.1585703e-11, 3.3429429e-11, 6.1477878e-11, 2.8549978e-11, 6.3940724e-11, 4.2923005e-11, 6.7488102e-11, 4.6114911e-11, 7.38638e-11, 6.2954229e-11, 5.8148252e-11, 5.1998196e-11, 6.2571525e-11, 6.3686069e-11, 6.6297973e-11, 5.5396516e-11, 3.8656236e-11, 3.7013154e-11, 2.5425876e-11, 5.928347e-11, 1.4655137e-11, 1.3775906e-11, 7.3402954e-12, 1.9464115e-11, 1.3586944e-11, 3.222585e-12, 3.1207677e-12, 7.4854629e-12, 1.5714993e-12, 1.0029451e-12, 1.8254646e-11, 1.6622901e-11, 2.7060288e-11, 2.7576044e-11, 2.2113367e-11, 3.7476556e-11, 2.8651462e-11, 1.0359023e-11, 1.8422378e-11, 2.0315446e-11, 1.144978e-11, 1.2722942e-11, 1.2541982e-11, 1.7565045e-11, 1.1307058e-11, 1.0880448e-11, 3.1376187e-11, 1.5549373e-11, 2.7908618e-11, 1.3636074e-11, 2.6978256e-11, 2.4016439e-11, 3.3378853e-11, 6.3285692e-12, 9.4646761e-12, 1.1684983e-11, 8.3919261e-12, 7.3647494e-12, 4.2612106e-12, 4.1272697e-12, 5.051073e-12, 6.0162256e-12, 5.2336994e-12, 9.1067593e-12, 8.3596914e-12, 2.3193786e-11, 2.4675139e-12, 1.96822e-11, 7.0787494e-12, 1.5689872e-11, 1.3103645e-11, 1.2901678e-11, 5.1338829e-12, 3.0584879e-11, 2.4636347e-11, 4.084931e-11, 1.8863771e-11, 1.7808806e-11, 1.0670256e-11, 2.2720714e-11, 6.5158642e-12, 1.4889783e-11, 1.3300166e-11, 2.1428323e-11, 5.7082171e-12, 1.5145549e-11, 2.9703648e-11, 3.2818747e-11, 5.7270022e-11, 3.4523965e-11, 3.5275701e-11, 3.0865322e-12, 1.1147552e-11, 1.3170782e-11, 2.0258313e-11, 8.1201539e-12, 1.8948693e-11, 4.3070062e-12, 2.0004436e-12, 2.087144e-12, 1.278541e-11, 1.4894674e-12, 7.7514551e-12, 7.6359658e-12, 4.8564418e-12, 1.2659361e-12, 2.5807135e-11, 1.9168779e-11, 2.2039671e-12, 9.3736407e-13, 3.4295543e-12, 8.5977838e-13, 2.1398089e-11, 4.11093e-12, 2.9779344e-12, 9.9719843e-12, 1.2265875e-12, 2.3258256e-11, 2.7452885e-12, 3.5525243e-11, 4.9341387e-13, 2.516055e-11, 3.9548695e-13, 2.2922348e-11, 1.2079136e-12, 1.486344e-11, 2.8566095e-11, 1.1704213e-11, 1.3646523e-11, 3.290667e-11, 1.1824593e-11, 1.9435993e-11, 1.4976484e-11, 6.4421688e-12, 3.1013157e-12, 1.4837763e-11, 2.4438825e-11, 1.8236083e-11, 1.5704544e-11, 1.0533647e-11, 7.9248558e-12, 8.2939992e-12, 1.8438273e-11, 2.6298214e-11, 3.3018713e-11, 4.3504675e-12, 1.2537536e-11, 1.660645e-12, 1.8246976e-11, 9.6453018e-12, 2.9774898e-12, 4.012225e-12, 1.3658638e-11, 4.5602156e-12, 8.7537333e-12, 1.76214e-11, 1.7859048e-11, 1.0328901e-11, 1.946067e-11, 1.7977872e-11, 1.3260373e-11, 8.0306747e-12, 3.7705756e-12, 1.5674755e-11, 2.0868439e-11, 1.0141161e-11, 9.1175413e-12, 2.7824474e-11, 1.8477955e-11, 3.1111084e-11, 1.8002659e-11, 4.4133253e-11, 2.1554261e-11, 3.4529856e-11, 1.7164445e-12, 4.1950516e-11, 1.9599501e-11, 5.5902602e-11, 2.3968198e-11, 5.3617381e-11, 3.4065898e-11, 5.772631e-11, 4.3247909e-11, 2.910964e-11, 3.540753e-11, 2.7571931e-11, 1.1315284e-11, 1.8592999e-11, 2.5544255e-11, 1.6387143e-11, 1.5040508e-11, 2.2639905e-11, 5.4360002e-12, 8.6666995e-12, 5.6874312e-12, 1.5383751e-13, 8.4142681e-12, 2.35447e-12, 1.4626348e-11, 3.7153319e-12, 1.3556488e-11, 3.5347063e-14, 1.3290495e-11, 1.0186957e-11, 6.1501665e-12, 8.5577683e-13, 1.3072633e-11, 1.0210744e-11, 2.2636236e-11, 2.474839e-11, 2.8420038e-11, 4.5050942e-11, 2.2227633e-11, 3.1792015e-11, 3.6332556e-11, 3.8697586e-11, 4.2348893e-11, 3.2118253e-11, 2.8153046e-11, 2.4457277e-11, 1.9662081e-11, 2.1734997e-11, 6.8804476e-14, 1.1115651e-11, 4.9918277e-12, 1.8982929e-12, 1.1247702e-11, 2.0770401e-11, 3.5807463e-11, 8.5853346e-12, 2.4645239e-11, 2.9784902e-12, 3.769364e-11, 1.2267098e-11, 3.746344e-11, 1.1964203e-11, 3.5184555e-11, 1.8121038e-11, 3.9607495e-11, 3.9379517e-11, 3.7426425e-11, 3.3673968e-11, 4.049684e-12, 2.1577381e-11, 1.3780908e-11, 2.3483121e-11, 2.7510908e-11, 1.4425381e-11, 3.1311828e-11, 3.6918784e-11, 1.8378583e-11, 2.2417929e-11, 9.0246163e-12, 6.4247186e-14, 9.9341918e-12, 7.702325e-12, 4.1842474e-11, 6.886208e-11, 9.5465635e-11, 1.6657403e-10, 2.5517066e-10, 3.8494351e-10, 5.6399439e-10, 8.0096699e-10, 1.1594728e-09, 1.6400004e-09, 2.3573629e-09, 3.2925991e-09, 4.651614e-09, 6.4904372e-09, 9.0606513e-09, 1.2616985e-08, 1.750877e-08, 2.4246208e-08, 3.3509402e-08, 4.6136119e-08, 6.3343107e-08, 8.6727815e-08, 1.1841186e-07, 1.6118977e-07, 2.1885078e-07, 2.9625965e-07, 3.9988425e-07, 5.3816045e-07, 7.2207441e-07, 9.6595904e-07, 1.2882465e-06, 1.7128436e-06, 2.2702853e-06, 2.9998008e-06, 3.9511764e-06, 5.1876766e-06, 6.7891422e-06, 8.8560828e-06, 1.1514183e-05, 1.4920328e-05, 1.9269039e-05, 2.4800646e-05, 3.1810529e-05, 4.0660049e-05, 5.1789098e-05, 6.5730358e-05, 8.3125583e-05, 0.00010474378, 0.00013150143, 0.00016448458, 0.00020497294, 0.00025446541, 0.00031470709, 0.00038771704, 0.00047581629, 0.00058165571, 0.00070824225, 0.00085896345, 0.0010376082, 0.0012483837, 0.0014959262, 0.0017853056, 0.0021220223, 0.0025119947, 0.0029615384, 0.0034773344, 0.0040663876, 0.0047359764, 0.0054935914, 0.0063468671, 0.007303506, 0.0083711979, 0.0095575358, 0.01086993, 0.012315523, 0.013901112, 0.015633065, 0.017517262, 0.019559027, 0.021763082, 0.024133505, 0.026673708, 0.029386413, 0.032273654, 0.035336779, 0.038576467, 0.04199275, 0.045585049, 0.049352209, 0.053292541, 0.05740387, 0.061683583, 0.066128679, 0.070735817, 0.075501368, 0.08042146, 0.085492024, 0.090708839, 0.096067568, 0.1015638, 0.10719306, 0.11295089, 0.11883282, 0.12483441, 0.13095128, 0.13717913, 0.14351373, 0.14995096, 0.15648679, 0.16311732, 0.16983875, 0.17664742, 0.1835398, 0.19051247, 0.19756214, 0.20468567, 0.21188001, 0.21914228, 0.22646967, 0.23385953, 0.24130932, 0.2488166, 0.25637904, 0.26399444, 0.27166068, 0.27937575, 0.28713777, 0.29494488, 0.30279546, 0.31068767, 0.31862067, 0.32659107, 0.33460296, 0.34264136, 0.3507378, 0.35882029, 0.36702912, 0.37510944, 0.38346982, 0.39151817, 0.40002843, 0.40807226, 0.41671242, 0.42477037, 0.43354705, 0.44164824, 0.4504208, 0.45880128, 0.46731437, 0.47564069, 0.48422064, 0.49218235, 0.50114621, 0.50900396, 0.518143, 0.52591298, 0.5352627, 0.54287413, 0.55237234, 0.55994548, 0.56971587, 0.57701518, 0.58720775, 0.59417315, 0.60464393, 0.61157174, 0.62223854, 0.62896741, 0.63994151, 0.6463752, 0.65756992, 0.66373256, 0.67507394, 0.68084696, 0.69222455, 0.69760447, 0.70898071, 0.71394469, 0.7252862, 0.72979015, 0.74095639, 0.74500105, 0.75577082, 0.75958339, 0.77002512, 0.77383606, 0.78382725, 0.78789691, 0.79706106, 0.80153898, 0.80944065, 0.81447886, 0.82092838, 0.82676051, 0.83227023, 0.84016694, 0.84345249, 0.85416931, 0.85538181, 0.86689314, 0.87031671, 0.88113769, 0.88503948, 0.89266435, 0.89726632, 0.90207678, 0.90609692, 0.90963674, 0.91258655, 0.91502049, 0.91694533, 0.9185455, 0.91993565, 0.92127913, 0.92250348, 0.9236348, 0.92449581, 0.92534573, 0.92593932, 0.926508, 0.92681627, 0.92684728, 0.92684988, 0.92681491, 0.92675624, 0.92662322, 0.92641057, 0.92621132, 0.92590999, 0.92573187, 0.92555097, 0.92539485, 0.92529249, 0.9251848, 0.92514504, 0.92503605, 0.9249758, 0.92487104, 0.92480741, 0.92477195, 0.92475021, 0.92474446, 0.92473058, 0.92466689, 0.92464599, 0.92459863, 0.92455818, 0.92454052, 0.9245201, 0.92451419, 0.92451885, 0.92448997, 0.92448865, 0.92451428, 0.92451891, 0.9246874, 0.92476524, 0.92500648, 0.92509177, 0.92524675, 0.92532686, 0.92542361, 0.92548585, 0.9255706, 0.92561766, 0.92567513, 0.92568916, 0.92568702, 0.92568594, 0.92568644, 0.92568731, 0.92568733, 0.92568538, 0.92568545, 0.92568528, 0.92568663, 0.9256866, 0.92568528, 0.92568502, 0.92567256, 0.92566365, 0.92565065, 0.92563364, 0.92563023, 0.92560237, 0.92558626, 0.92558102, 0.92556718, 0.92556095, 0.92553352, 0.92552234, 0.92551443, 0.92551346, 0.92553188, 0.92554215, 0.92553593, 0.92551216, 0.9254981, 0.92548397, 0.92545191, 0.9254438, 0.92546047, 0.92545948, 0.92545321, 0.92546942, 0.92546893, 0.92548178, 0.9254962, 0.92550577, 0.92551064, 0.92551861, 0.92551255, 0.92551154, 0.92550125, 0.9254909, 0.92547777, 0.92546059, 0.9254376, 0.92542317, 0.92541357, 0.92540004, 0.92539003, 0.92539268, 0.92539484, 0.92539319, 0.92538687, 0.92537376, 0.92536217, 0.92533494, 0.92532182, 0.92530103, 0.92529295, 0.92528055, 0.9252808, 0.92528141, 0.92527479, 0.92526564, 0.92523915, 0.92522498, 0.92519033, 0.92516932, 0.92514302, 0.92513574, 0.92510167, 0.92508319, 0.92504168, 0.92502395, 0.92498993, 0.92496413, 0.92494274, 0.92494213, 0.92495041, 0.9249836, 0.92499667, 0.92499782, 0.92498454, 0.92497894, 0.92492624, 0.92489385, 0.92487897, 0.92509758, 0.92504302, 0.92491965, 0.92467987, 0.92444044, 0.92344321, 0.92290962, 0.92093694, 0.92008582, 0.9162359, 0.91463478, 0.90802769, 0.90425492, 0.89399229, 0.88607405, 0.86898745, 0.85620349, 0.82452756, 0.80408067, 0.75438196, 0.71474921, 0.64709112, 0.57709269, 0.48776217, 0.39181642, 0.29379284, 0.20417154, 0.13180417, 0.079941381, 0.046261304, 0.025928858, 0.014247258, 0.0077397344, 0.0041786383, 0.0022487831, 0.0012082535, 0.00064867088, 0.00034811725, 0.00018678768, 0.00010021515, 5.3764932e-05, 2.884384e-05, 1.5473854e-05, 8.3011042e-06, 4.4531444e-06, 2.3888279e-06, 1.2814482e-06, 6.8740462e-07, 3.6877249e-07, 1.9781662e-07, 1.0612857e-07, 5.6907018e-08, 3.0530822e-08, 1.6362161e-08, 8.775146e-09, 4.6521183e-09, 2.5235309e-09, 1.3190337e-09, 7.1714996e-10, 3.3889165e-10, 1.8756574e-10, 7.8574173e-11, 2.5481803e-11, 6.9994292e-12, 1.247901e-11, 4.1408415e-11, 4.7442414e-12, 4.0464184e-11, 1.6622659e-11, 2.5161139e-11, 2.3042919e-11, 2.7545969e-11, 2.1857719e-11, 1.0317612e-11, 3.6101653e-11, 8.1525515e-13, 1.4730091e-12, 4.1200966e-11, 2.1666919e-11, 2.549046e-11, 1.2807665e-11, 1.5924281e-11, 1.1008553e-11, 3.9694991e-11, 2.012476e-11, 2.4571647e-11, 6.2012669e-13, 3.3875435e-11, 1.7536811e-11, 3.5456885e-11, 9.438868e-12, 1.5482856e-11, 1.2117833e-11, 1.2255133e-11, 3.2043691e-11, 4.9047395e-12, 5.9504194e-13, 2.3257249e-11, 9.3155531e-12, 4.0251407e-11, 1.6236398e-11, 2.031778e-11, 5.1861107e-12, 4.9291028e-11, 8.2434564e-12, 9.2215406e-12, 2.4410372e-11, 1.5256538e-11, 5.7015363e-11, 3.3725704e-12, 5.4832432e-11, 5.1818707e-11, 4.5330519e-11, 3.5841038e-11, 3.9551697e-11, 4.6543135e-11, 6.3229727e-11, 4.3508543e-11, 3.6803361e-11, 2.5596571e-11, 5.6237735e-11, 2.0785067e-11, 5.3363974e-11, 4.6250331e-12, 5.7681996e-11, 1.4312085e-11, 3.4661054e-11, 1.451132e-11, 4.1207626e-11, 2.0039405e-11, 5.1141307e-11, 5.7767129e-11, 6.5028949e-11, 6.081504e-11, 6.6510061e-11, 6.9528559e-11, 5.3917837e-11, 3.3359199e-11, 3.1915825e-11, 2.4460763e-11, 2.6618498e-11, 1.9054772e-11, 2.2080929e-11, 2.1238369e-11, 4.8883122e-12, 2.9346301e-11, 3.8926909e-12, 1.8546972e-11, 3.352447e-11, 7.7369881e-12, 2.0904608e-11, 5.2964393e-11, 3.7098162e-11, 3.698628e-11, 5.4720328e-12, 1.7230799e-12, 1.4661718e-11, 3.0158781e-11, 8.727504e-13, 7.4551729e-12, 9.6010311e-12, 9.7009263e-12, 4.6964914e-11, 1.7044439e-11, 3.1317343e-11, 4.2369517e-11, 3.8669623e-11, 1.3587734e-11, 4.0327661e-11, 2.2638121e-11, 2.0275824e-11, 2.1832634e-12, 2.6967021e-11, 3.5043653e-11, 8.9498259e-12, 1.7058757e-11, 3.7238681e-12, 4.9141296e-11, 1.4965288e-11, 6.4129671e-11, 9.1424014e-12, 5.4471811e-11, 1.130724e-11, 1.602795e-11, 3.6961417e-11, 5.9972591e-12, 2.417473e-11, 3.6010304e-11, 2.7460281e-11, 1.8913365e-11, 2.2333219e-12, 9.1835805e-12, 1.0674682e-11, 2.0343309e-11, 1.0621071e-11, 2.5540186e-11, 1.0256232e-11, 4.1173994e-11, 4.7592922e-11, 3.8839778e-11, 5.586668e-11, 4.5768393e-11, 5.4112521e-11, 1.3272288e-11, 1.3262631e-11, 2.1268781e-12, 2.0194243e-11, 4.7091671e-12, 3.7831725e-11, 1.5198377e-11, 9.3552891e-12, 3.8123752e-11, 9.7382204e-12, 2.1738621e-11, 1.7108705e-12, 5.4503888e-12, 3.0085081e-12, 2.2196696e-12, 1.3662545e-11, 1.8426765e-11, 6.4032773e-12, 2.0263392e-11, 3.1608037e-11, 4.4126672e-11, 2.1159896e-11, 3.9597982e-11, 1.1844232e-11, 1.6582368e-11, 9.2536177e-13, 2.2899403e-11, 6.6586758e-12, 1.3248202e-11, 1.8486591e-11, 4.3278784e-11, 3.2563479e-11, 1.3640346e-11, 1.2093747e-11, 3.9193296e-12, 1.6752745e-11, 6.6797648e-12, 1.0561134e-11, 1.7613841e-11, 6.0695166e-12, 3.1665977e-11, 1.3746124e-11, 2.4588629e-12, 2.1681015e-11, 1.1307129e-11, 5.1117999e-11, 1.8270707e-11, 3.9627285e-12, 8.1229163e-12, 3.1189482e-14, 8.6509177e-13, 2.0935576e-11, 1.1765536e-11, 3.1098461e-11, 5.3431792e-11, 4.5414209e-11, 3.6909915e-11, 5.9130031e-11, 3.0514297e-11, 5.9756929e-11, 5.2456704e-11, 3.5227349e-11, 4.0291587e-11, 1.2385774e-11, 1.3110236e-11, 1.0282982e-11, 3.7945717e-12, 1.1037634e-11, 9.5456448e-12, 1.2120386e-11, 3.4301765e-11, 2.9848773e-11, 2.483648e-11, 1.5567101e-11, 1.8956764e-11, 3.6095881e-11, 5.7025684e-12, 1.6939771e-11, 3.0161445e-11, 6.3281338e-12, 1.0585664e-11, 1.3458537e-11, 1.4699567e-11, 2.6314706e-11, 7.8859428e-12, 2.2798398e-11, 1.1018876e-11, 1.6363931e-11, 6.347669e-12, 1.6589916e-11, 2.0036741e-12, 1.6865848e-11, 5.4995594e-12, 5.0944292e-12, 1.3116007e-11, 2.4353432e-11, 3.5570433e-12, 6.7930902e-12, 2.3220066e-12, 9.9536609e-12, 1.8856536e-11, 8.7824461e-12, 7.618224e-12, 1.6572712e-11, 5.5821394e-12, 2.3594118e-12, 1.351692e-11, 1.9621733e-11, 2.3416193e-11, 8.477988e-12, 1.7558232e-12, 1.3480181e-11, 1.6566829e-11, 8.3494562e-12, 1.0927638e-11, 4.0086691e-11, 1.6651962e-11, 2.7324424e-11, 3.4887816e-12, 1.3475297e-11, 2.1159452e-11, 5.2683577e-12, 1.3745236e-11, 3.5893205e-11, 3.4344276e-11, 4.7905261e-12, 2.1948068e-11, 4.4536575e-12, 5.2116617e-11, 3.6534865e-11, 6.9206452e-11, 3.8344298e-11, 4.4512489e-11, 2.1158231e-11, 1.856573e-11, 1.5882214e-12, 1.1754437e-11, 1.8347626e-11, 2.3172338e-11, 2.9199233e-11, 4.1969381e-11, 3.6500567e-11, 4.019036e-11, 5.0911105e-11, 3.4911625e-20];\n\noption = {\n  dataZoom: [\n    {\n      type: 'slider',\n      minSpan: 1\n    },\n    {\n      type: 'inside',\n      minSpan: 1\n    }\n  ],\n  tooltip: {\n      trigger: 'axis',\n      formatter: function (params) {\n          let newParams = [];\n          let tooltipString = [];\n          newParams = [...params];\n          newParams.sort((a,b) => {return b.value - a.value});\n          newParams.forEach((p) => {\n              const cont = p.marker + ' ' + p.seriesName + ': ' + p.value + '<br/>';\n              tooltipString.push(cont);\n          });\n          return tooltipString.join('');\n      }\n  },\n legend: {\n    data: legends\n  },\n  grid: {\n    left: '3%',\n    right: '4%',\n    bottom: '9%',\n    containLabel: true\n  },\n  // toolbox: {\n  //   feature: {\n  //     saveAsImage: {}\n  //   }\n  // },\n  xAxis: {\n    type: 'category',\n    boundaryGap: false,\n    data: xaxis\n  },\n  yAxis: {\n    min: 'dataMin',\n    type: 'value',\n    axisTick: {\n      alignWithLabel: true\n    },\n    scale: true,\n  },\n  series: [\n    {\n      name: legends[0],\n      type: 'line',\n      showSymbol: false,\n      data: data0\n    },\n    \n    {\n      name: legends[1],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data1\n    },\n    {\n      name: legends[2],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data2\n    },\n    {\n      name: legends[3],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data3\n    },\n    {\n      name: legends[4],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data4\n    },\n    {\n      name: legends[5],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data5\n    },\n    {\n      name: legends[6],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data6\n    },\n        {\n      name: legends[7],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data7\n    }\n  ]\n};\n{% endecharts %}\n\n\n\n","source":"_posts/FVM-schemes-fundamentals.md","raw":"---\ntitle: Numerical schemes fundamentals\nauthor: Ryan LI\ntoc: true\ndeclare: true\nindex_img: /index/fvm_schemes.png\ntags:\n  - fluid dynamics\n  - OpenFOAM\ndate: 2022-06-18 18:08:24\n---\n\n{% note primary %}\n\nThis is the **essence** of CFD, advecting with the discontinuities due to inviscid fluid PDEs. Several computational schemes dealing with them are introduced then tested in OpenFOAM on the 1D shockTube case.\n\n{% endnote%}\n\n<!-- more -->\n\n{% note secondary %}\n\nThis is a review of my graduate CFD course and the application of the theory to CFD software. The aim is to further the understanding of finite volume method and the `fvscheme` dict in OpenFOAM.\n\n{% endnote%}\n\n**Reference books:**\n\nE.F. Toro, Riemann Solvers and Numerical Methods for Fluid Dynamics, Springer-Verlag.\n\nR.J. LeVeque, Finite Volume Methods for Hyperbolic Problems, Cambridge University Press.\n\n**Overview:**\n\n{% markmap 300px %}\n\n- Scalar conservation laws\n  - conservation vs non-conservative\n  - 1D simple Riemann problem for Burgers' equation\n  - characteristics discontinuities and jump conditions\n  - weak solutions and entropy condition\n- Numerical schemes for 1D discontinuities\n  - practical examples on one conservation law\n  - \n\n- System of conservation laws\n  - add complexity, system of conservation laws\n\n{% endmarkmap %}\n\n## Scalar conservation laws\n\n{% note info %}\n\n1-D theory. Examples of 1-D hyperbolic conservation laws. Characteristics discontinuities and jump conditions. Weak solutions and entropy condition. Linear versus non-linear advection\n\n{% endnote%}\n\n### Challenges\n\nAs we all know, flow fluids are governed by 3 hyperbolic PDEs (conservation of mass, momentum and energy). These equations are highly non-linear and they can lead to discontinuities even with a smooth initial conditions, which is very difficult to solve numerically. Simple FDM will definitely fail on these discontinuities and shocks.\n\nRecall the incompressible NS equation that we've learned in the kindergarten:\n$$\n\\frac{\\partial \\mathbf{V}}{\\partial t} + \\underbrace{\\left(\\boldsymbol{\\nabla}\\cdot\\mathbf{V}\\right)\\mathbf{V}}_{\\text{convection}} = \\frac{\\nabla p}{\\rho} + \\mathbf{g}+ \\underbrace{\\nu \\boldsymbol{\\nabla}^2\\mathbf{V}}_{\\text{diffusion}}\n$$\nthe viscous diffusion term in the equation leads to parabolic equations with smooth solutions, which will save our life. But with very high $Re$, the equation reduces to pure <font color=#75147c>hyperbolic inviscid Euler Equation</font>, and the resultant discontinuity is a nightmare for most of the numerical schemes. \n\nThe presence of discontinuities requires <font color=#75147c>weak solutions</font>, as oppose to <font color=#75147c>strong solutions</font>.\n\nHowever, the weak solutions give up the uniqueness in math, i.e there exist a large number of solutions that may not be physical acceptable, i.e. extra conditions are needed to justify the solution. They are:\n\n- <font color=#75147c>Rankine-Hugoniot</font> condition deals with the discontinuity\n- <font color=#75147c>Entropy</font> condition satisfies the physics\n\n{% note info %}\n\nJust here to remind that we are dealing with inviscid flow, shocks, nothing to do with turbulence.\n\n{% endnote%}\n\n### Scalar conservation laws\n\n#### 1D law\n\n<img src=\"1D scalar convection.png\" alt=\"1D scalar convection control volume\" style=\"zoom:70%;\" />\n\nFirst let's introduce a simple example to present the problem: consider an 1D control volume $[a,b]$, during the time interval $[t_1,t_2]$ . The scalar conservation law can be stated as that during $[t_1,t_2]$ , change in total conserved quantity in $[a,b]$ equals to the net flux through the boundaries $a$, $b$:\n\n$$\n\\frac{d}{dt}\\int_a^bu(x,t) = -\\left[f(u(b,t))-f(u(a,t))\\right]\n$$\nwhere $u(x,t)$ is called the conserved quantity while $f$ denotes the flux. This equation often describes the <font color=#75147c>transport phenomena</font>.\n\n{% note info %}\n\nYou can not create, you can not destroy.\n\n{% endnote %}\n\n#### Integral, differential conservative and primitive forms\n\n<img src=\"2D scalar convection control volume.png\" alt=\"2D scalar convection control volume\" style=\"zoom:48%;\" />\n\nThe 1D law can be extended in 2D with the relation, in <font color=#75147c>integral form</font>.\n$$\n\\frac{d}{d t} \\int_{\\Omega} \\mathbf{u} d \\Omega+\\int_{\\Gamma} \\mathbf{f}(\\mathbf{u}) \\cdot \\mathbf{n} d \\Gamma=0\n$$\n{% note info %}\n\nThe FVM and FEM solves the integral form, while the FDM solves the primitive form.\n\n{% endnote %}\n\nApply the Gauss divergence theorem the relation can be represented as <font color=#75147c>differential form</font>:\n$$\n\\begin{aligned}\n\\int_{\\Omega}\\left\\{\\frac{\\partial \\mathbf{u}}{\\partial t}+\\nabla \\cdot \\mathbf{f}(\\mathbf{u})\\right\\} d \\Omega=0&  \\\\ \n\\Rightarrow \n\\color{purple}{\n\\forall \\Omega,\\quad \\frac{\\partial \\mathbf{u}}{\\partial t}+\\nabla \\cdot \\mathbf{f}(\\mathbf{u})=0} &\n\\end{aligned}\n$$\nabove is called the <font color=#75147c>differential conservative form</font>. The only $u$ changed in time is due to the flux $f$. There is no extra assumptions introduced.\n\nIn comparison, with an assumption of $\\mathbf{a} =  \\frac{d\\mathbf{f}}{d\\mathbf{u}}$, the equation can be rewritten with the chain rule, as the <font color=#75147c>differential primitive form</font> :\n$$\n\\quad \\frac{\\partial \\mathbf{u}}{\\partial t}+\\mathbf{a}(\\mathbf{u})\\nabla \\cdot \\mathbf{u}=0, \\quad \\text{where }\\mathbf{a} =  \\frac{d\\mathbf{f}}{d\\mathbf{u}}\n$$\nThis form is identical to above in mathematics, but it will lead to problems numerically when dealing with discontinuities (to be discussed later).\n\n#### Rankine-Hugoniot Jump condition\n\n<img src=\"shock wave.png\" alt=\"1D jump discontinuity illustration\" style=\"zoom:70%;\" />\n\nWhen dealing with discontinuities, the integral form is well defined, but not the differential forms. The differential solvers can't deal with the drastic derivatives so instead they solve an extra <font color=#75147c>jump condition</font> which can be derived from the well-defined integral form (discussed later).\n\nFor an 1D jump discontinuity travelling at the speed $s$:\n$$\nf(u_r)-f(u_l) = s(u_r-u_s)\n$$\nwhere $u_r$, $u_l$ represent the speeds just at the left and the right of the discontinuity. \n\n### 1D Euler equations\n\nIts time to introduce the 1D Euler equations: NS equations with 0 viscosity or heat conduction terms:\n$$\n\\frac{\\partial}{\\partial t}\\left[\\begin{array}{l}\n\\rho \\\\\n\\rho u \\\\\n\\rho E\n\\end{array}\\right]+\\frac{\\partial}{\\partial x}\\left[\\begin{array}{l}\n\\rho u \\\\\n\\rho u^{2}+P \\\\\n\\rho u\\left(E+\\frac{P}{\\rho}\\right)\n\\end{array}\\right]=0\n$$\nAnd the conservation form is:\n$$\n\\frac{\\partial \\mathbf{q}}{\\partial t}+\\frac{\\partial \\mathbf{F}(\\mathbf{q})}{\\partial x}=0\n$$\nfor the quantity vector $\\mathbf{q}$ with the flux vector $\\mathbf{F}$.\n\n#### Conservation vs non-conservation form\n\nSimilar to before, with terms in a form of $\\partial_x{uv}$:\n$$\n\\frac{\\partial uv}{\\partial x} \\neq u\\frac{\\partial v}{\\partial x}+ v\\frac{\\partial u}{\\partial x}\n$$\nWhen dealing with the discontinuities, the conservative LHS locates the shock directly, while the non-conservative RHS does not. (to be discussed later)\n\n#### Close the Euler equation\n\nUnlike the well-posed NS equation, in Euler equation, we have 4 unknowns but only 3 equations. So an extra state equation, i.e. extra assumption of the gas state is needed. Sometimes it's the idea gas assumption $p = \\rho RT$, but for high $Re$ compressible flows, equations of state are required to describe the relation between $p, \\rho \\text{ and }T$.\n\n{% note primary %}\n\nWe are going to use the 1D Euler equations to evaluate the numerical methods.\n\n{% endnote %}\n\n### Analytical solutions of Euler equations\n\n#### Linear Advection Equation\n\nIn 1D, the linear advection law for $u(x,t)$ is:\n$$\n\\color{purple}\n\\frac{\\partial u }{\\partial t} + a(u)\\frac{\\partial u }{\\partial x} = 0\n$$\nwhere $a(u)$ denotes the advection speed. Plus an <font color=#75147c>initial condition</font> $u(x,0)$ and <font color=#75147c>boundary condition</font> (discuss later).\n\n##### solution\n\nThis is a simple 2-variable PDE and we can apply the method of characteristics:\n\n1. Imagine a characteristic line $s$, we have the chain rule:\n   $$\n   \\frac{d u(x,t)}{d s} = \\frac{d t}{d s}\\frac{\\partial u}{\\partial t} + \\frac{d x}{d s} \\frac{\\partial u}{\\partial x}\n   $$\n\n2. As a result we can construct, \n   $$\n   \\begin{aligned}\n   \\frac{d u(x,t)}{d s} = 0,\\quad\\frac{d t}{d s}=1, \\quad \\frac{d x}{d s}= a \\\\\n   \\Rightarrow \\quad \\frac{d u}{0}=\\frac{d t}{1}=\\frac{d x}{a}= d s\n   \\end{aligned}\n   $$\n\n3. Select the available equations we have the characteristic equation:\n   $$\n   \\begin{aligned}\n   \\frac{d x}{d t} &= a \\\\\n   \\Rightarrow\\quad x &= x_0 + a(u)t\n   \\end{aligned}\n   $$\n   If $u(x_0,0)=u_0$, then $\\frac{dx}{dt}=a(u_0)$, the characteristic equation is therefore:\n   $$\n   \\color{purple}\n   x = x_0 + a(u_0)t\n   $$\n\n4. And the solution to the problem is:\n   $$\n   u(x,t) = f(x_0) = f(x-a(u_0)t)\n   $$\n\n#### Linear Advection Equation Example\n\nSolve the following advection equation where $a = 0.5$\n$$\n\\frac{\\partial u}{\\partial t} + a \\frac{\\partial u}{\\partial x }= 0\n$$\nwith initial condition \n$$\nu(x,0) = exp(-32x^2)\n$$\n\n##### solution\n\nThe characteristics are straight lines in the $(x,t)$ plane:\n$$\nx = 0.5t+x_0\n$$\nAnd the solutions are therefore:\n$$\nu(x,t) = f(x_0) = exp(-32(x-0.5t)^2)\n$$\n<img src=\"Linear Advection Solutions.png\" alt=\"Linear Advection Characteristic Lines and Solutions, From my graduate course slides\" style=\"zoom:28%;\" />\n\n#### Inviscid Burgers' equation\n\nIn 1D, the inviscid Burgers' equation for $u(x,t)$ is:\n$$\n\\color{purple}\n\\frac{\\partial u }{\\partial t} + \\frac{f(u) }{\\partial x} = 0,\\quad\\text{where }f(u)=\\frac{1}{2}u^2\n$$\nThe conservative form for this equation\n$$\n\\frac{\\partial u }{\\partial t} + \\frac{\\partial(\\frac{1}{2}u^2) }{\\partial x} = 0\n$$\nand the primitive form:\n$$\n\\frac{\\partial u }{\\partial t} + u\\frac{\\partial u }{\\partial x} = 0\n$$\nsame form as the 1D linear advection equation with $a(u)=u$.\n\n#### Burgers' equation Example\n\nSolve the advection equation:\n$$\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }= 0\n$$\nwith initial condition:\n$$\nu(x,0) = 1-\\cos(x)\n$$\n\n##### solution\n\nSimilarly, the characteristics are described by:\n$$\nx = x_0 + ut\n$$\nand the solution:\n$$\nu = 1-\\cos(x-ut)\n$$\nwhich is *<u>implicit</u>*. It is can be plotted anyway:\n\n<img src=\"Inviscid Burgers' equation Solutions.png\" alt=\"Inviscid Burgers' equation Solutions, From my graduate course slides\" style=\"zoom:28%;\" />\n\n##### discussion\n\nFor non-linear conservation laws, the characteristics may cross within finite time.\nThis would suggest a multi-valued solution which does not make sense physically.\n\nWhere the characteristics start crossing, the solution become discontinuous. And the formation of discontinuities is possible even for smooth initial data. So the differential primitive form of the equations is no longer valid \n\n$\\Rightarrow$ only the integral form can deal with discontinuities. And the differential form can be completed by a <font color=#75147c>jump condition</font> derived from the integral form. \n\n$\\Rightarrow$ we need <font color=#75147c>weak solutions</font>. The mathematical theory of partial differential equations introduces the concept of weak solutions.\n\n### Rankine-Hugoniot condition\n\n#### The Riemann Problem\n\n{% note info %}\n\nIn order to understand the behaviour of the solution at discontinuities, it is useful to start with a simplified problem. \n\n{% endnote %}\n\nThe Riemann problem is a conservation law with a single discontinuity.\n$$\n\\color{purple}\n\\frac{\\partial u}{\\partial t} + \\frac{\\partial f(u)}{\\partial x} = 0\n$$\nwith\n$$\n\\color{purple}\nu(x, 0)= \\begin{cases}u_{L} & x \\leq 0 \\\\ u_{R} & x>0\\end{cases}\n$$\n<img src=\"Riemann problem illustration.png\" alt=\"Riemann problem illustration\" style=\"zoom:48%;\" />\n\n#### Shock Path\n\n<img src=\"shock path control volume.png\" alt=\"shock path control volume\" style=\"zoom:80%;\" />\n\nTake the control volume between boundaries $x_L$ and $x_R$, which are taken sufficient close to the shock so that spatial variations of the solution become unimportant. and are taken sufficient apart from the shock so that the boundary will note interfere with the shock motion over time interval $\\delta t$.\n\nRecall the integral function:\n$$\n\\frac{d}{dt}\\int_{x_L}^{x_R}udx = f(u_L)-f(u_R)\n$$\nIf the position of the shock is $x = X(t)$, with $x_L< X (t) <x_R$,  the values of $u(x,t)$ inside the integral are close to the constants $u_L$ and $u_R$ and we can write:\n$$\n\\begin{aligned}\n\\frac{d}{dt}\\int_{x_L}^{X}u_Ldx + \\frac{d}{dt}\\int_{X}^{x_R}u_Rdx= f(u_L)-f(u_R)\\\\\n\\frac{d}{dt}\\left[(x_L-X)u_L + (X-x_R)u_R\\right]= f(u_L)-f(u_R)\\\\\n\\end{aligned}\n$$\n\nGiven the shock speed (slope of the shock path) $s = \\frac{dX}{dt}$, we have:\n$$\n\\begin{aligned}\ns\\left(u_L - u_R\\right)&= f(u_L)-f(u_R)\\\\\n\\color{purple}\ns= \\frac{dX}{dt}&\\color{purple}\n= \\frac{f(u_L)-f(u_R)}{\\left(u_L - u_R\\right)}= \\frac{f(u_R)-f(u_L)}{\\left(u_R - u_L\\right)}\n\\end{aligned}\n$$\nThe equation above is the <font color=#75147c>Rankine-Hugoniot condition</font>, also called the \"jump condition\".\n\nCorrespondingly, <font color=#75147c>weak solutions</font> represents the solutions of the PDE where the solution is smooth and of a Rankine-Hugoniot condition at discontinuities. And they are <font color=#75147c>not unique</font>.\n\n{% note info %}\n\nStrong solution $\\Rightarrow$ weak solution\n\nWeak solution $\\nLeftarrow$ Strong solution\n\n{% endnote %}\n\n### Non-uniqueness of weak solutions\n\n#### Example of Riemann Problem with Burgers's equation\n\nConsider the [Burgers' equation](#inviscid-burgers-equation) under a [Riemann Problem](#the-riemann-problem):\n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&= 0, \\\\\n\\text{with }\nu(x, 0)&= \\begin{cases}1 & x \\leq 0 \\\\ 0 & x>0\\end{cases}\n\\end{aligned}\n$$\nThe characteristics are of the form: $x = x_0 + ut$ \n\nIn $x-t$ plane, the characteristics line:\n$$\n\\begin{cases} x = t - x_0 & x_0 \\leq 0 \\\\ x = x_0 & x_0 > 0\\end{cases}\n$$\nAnd the according to the Rankine-Hugonoit condition, the speed of the shock is:\n$$\ns = \\frac{f(u_L)-f(u_R)}{\\left(u_L - u_R\\right)}= \\frac{-1/2-0}{\\left(1-0\\right)} = \\frac{1}{2}\n$$\nand the shock path is:\n$$\nx = \\frac{1}{2} t\n$$\ntherefore,  the solution is:\n$$\nu(x,t) = \\begin{cases} 1 & x \\leq \\frac{1}{2}t \\\\ 0 & x> \\frac{1}{2}t\\end{cases}\n$$\n<img src=\"Burgers's equation under Riemann Problem with uL = 1, uR=0.png\" alt=\"General solution (left) and characteristics (right) of Burgers's equation under Riemann Problem. From my graduate course slides\" style=\"zoom:50%;\" />\n\n#### Upwind Riemann Problem with Burgers's equation\n\nFor the upwind case:\n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&= 0, \\\\\n\\text{with }\nu(x, 0)&= \\begin{cases}u_L & x \\leq 0 \\\\ u_R & x>0\\end{cases}\n\\end{aligned}\n$$\nwith $u_L>u_R$.\n\nAnd the shock is created with a speed:\n$$\ns = \\frac{1}{2}(u_R+u_L)\n$$\nand the solution:\n$$\nu(x,t) = \\begin{cases} u_L & x \\leq \\frac{1}{2}t \\\\ u_R & x> \\frac{1}{2}t\\end{cases}\n$$\n<img src=\"Burgers's equation under Riemann Problem general solution.png\" alt=\"Solution (left) and characteristics (right) of Burgers's equation under Riemann Problem with uL = 1, uR=0. From my graduate course slides\" style=\"zoom:50%;\" />\n\n#### Example of non-unique downwind Riemann Problem with Burgers's equation\n\nReverse the initial condition in the previous example:\n\n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&= 0, \\\\\n\\text{with }\nu(x, 0)&= \\begin{cases}0 & x \\leq 0 \\\\ 1 & x>0\\end{cases}\n\\end{aligned}\n$$\nthe characteristics become:\n\n<img src=\"Burgers's equation under Riemann Problem with uL = 0, uR=1.png\" alt=\"Solution (left) and characteristics (right) of Burgers's equation under Riemann Problem with uL = 1, uR=0. From my graduate course slides\" style=\"zoom:50%;\" />\n\nSolution in the blue area ($0<x<t$) is not defined. So here proposes 2 possible solutions, both are mathematical acceptable:\n\nSolution A:\n$$\nu(x, t)= \\begin{cases}0 & \\text { if } \\quad \\frac{x}{t}<s(=0.5) \\\\ 1 & \\text { if } \\quad \\frac{x}{t}>s(=0.5)\\end{cases}\n$$\n<img src=\"Expansion shock solution to the Riemann Problem.png\" alt=\"Expansion shock solution to the Riemann Problem\" style=\"zoom:50%;\" />\n\nSolution B:\n$$\nu(x, t)=\\left\\{\\begin{array}{ccc}\n0 & \\text { if } & \\frac{x}{t}<0 \\\\\n\\frac{x}{t} & \\text { if } & 0<\\frac{x}{t}<1 \\\\\n1 & \\text { if } & \\frac{x}{t}>1\n\\end{array}\\right.\n$$\n<img src=\"Rarefaction wave solution to the Riemann Problem.png\" alt=\"Rarefaction wave solution to the Riemann Problem\" style=\"zoom:50%;\" />\n\n{% note info %}\n\nA little spoiler alert there: Solution B is physical, discussed in the [next section](#non-uniqueness-and-entropy-conditions).\n\n{% endnote %}\n\n#### Exact solution to Riemann Problem with Burgers's equation\n\nIn conclusion,  \n\nFor the Riemann Problem with Burgers's equation:\n$$\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&= 0, \\\\\n\\text{with }\nu(x, 0)&= \\begin{cases}u_L & x \\leq 0 \\\\ u_R & x>0\\end{cases}\n\\end{aligned}\n$$\n\n- with $u_L>u_R$\n\n  A shock wave is created with a speed:\n  $$\n  V_s = \\frac{u_L+u_R}{2}\n  $$\n  and the exact solution is:\n  $$\n  u(x, t)=\\left\\{\\begin{array}{ccc}\n  u_L & \\text { if } & \\frac{x}{t}\\leq V_s \\\\\n  u_R & \\text { if } & \\frac{x}{t}>V_s\n  \\end{array}\\right.\n  $$\n\n- with $u_L<u_R$\n\n  the exact solution is the rarefaction wave:\n  $$\n  u(x, t)=\\left\\{\\begin{array}{ccc}\n  u_L & \\text { if } & \\frac{x}{t}<0 \\\\\n  \\frac{x}{t} & \\text { if } & 0<\\frac{x}{t}<1 \\\\\n  u_R & \\text { if } & \\frac{x}{t}>1\n  \\end{array}\\right.\n  $$\n  if $u_L = -u_R$, we have a sonic rarefaction wave.\n\n### Entropy Conditions\n\nWhy solution A is wrong? we need to impose additional conditions. There are two ways.\n\n- Add a small diffusion term (2 <sup>nd</sup> order) manually on the RHS to remove the discontinuity. The weak solution then must satisfy:\n  $$\n  \\frac{\\partial u^\\epsilon}{\\partial t} + \\frac{\\partial f(u^\\epsilon)}{\\partial x} = \\epsilon\\frac{\\partial^2u^\\epsilon}{\\partial x^\\epsilon}\n  $$\n  where $\\epsilon$ is the <font color=#75147c>viscosity coefficient</font>, it introduces the dissipation, known as the vanishing viscosity concept, into the equation to smooth the solution. A little bit cheating but most of people do this.\n\n- Add the <font color=#75147c>entropy solution</font>\n\n  {% note info %}\n\n  I first hearted Entropy back in my undergraduate thermodynamic course. But I still don't know what is Entropy. So here are some answers:\n\n  In gas dynamics, entropy is a constant physical quantity along particles in smooth flow which can jump to a higher value through a shock.\n\n  The second law of thermodynamics says that entropy can never go down.\n\n  For an evolution equation the information should always flow from the initial data.\n\n  We can see it is very difficult to define it, but in order to translate the defination into the entropy condition, we see entropy as the extra amount of energy that is not available to the system.\n\n  {% endnote %}\n\n  There are again two options of entropy condition:\n\n  - <font color=#75147c>Convex (concave) fluxes / Lax entropy condition</font> \n    $$\n    f'(u_L) > s > f'(u_R)\n    $$\n    and the characteristics must run into the shock, not emerge from it.\n\n  - <font color=#75147c>Oleinik entropy condition</font>\n\n    Similar to Lax entropy condition, it says:\n    $$\n    \\frac{f(u)-f(u_L)}{u-u_L}\\geq s \\geq \\frac{f(u_R)-f(u)}{u_R-u}\n    $$\n\n  and Lax and Oleinik are equivalent if $f(u)$ is strictly convex i.e. $f''(u)<0$.\n\n## Numerical representation of discontinuities\n\n{% note info %}\n\nRequirements on numerical schemes. Conservative discretisation: Lax-Wendroff theorem. First versus second order schemes. Representation of discontinuities: physical aspects, shock fitting/capturing.\n\n{% endnote %}\n\n### Problems with Lax Equivalence Theorem\n\nThere are 3 fundamental properties of a numerical scheme:\n\n- Consistency: how good you approximate operators and functions.\n\n- Convergence: error between the exact and discrete solutions converges to zero.\n- Stability: solution of the difference equation is not too sensitive to small perturbations.\n\n\n\nThe convergence needs to be evaluated with exact solutions. So we always need analytical solutions to verify it. If we don't have access to the analytical solutions,  we have a <font color=#75147c>Lax Equivalence Theorem</font>says\n$$\n\\text{consistency + stability $\\Rightarrow$ convergence}\n$$\nIt is a fundamental convergence theorem but \n\n- it is valid <font color=#75147c>only for linear PDEs</font> and there is no non-linear equivalent theorem\n- this theorem <font color=#75147c>does not tell if the weak solution physically acceptable or not</font>.\n\nFor non-linear PDEs, we only have one experience, \n\nIf a scheme is stable on linear PDEs, it will often (not all the time) be stable on non-linear PDEs. If a scheme is unstable on linear, it won't be stable on non-linear.\n\nSo the work flow is, 1. Given a non-linear PDE, 2. Linearise it to explore the stabilities of schemes on it. 3. Test the winners on non-linear PDEs.\n\n### 1D linear convection equation\n\nFirst we consider a <font color=#75147c>linear</font> case, linear convection equation:\n$$\n\\frac{\\partial u}{\\partial t} + a\\frac{\\partial u}{\\partial x} = 0\n$$\nwith $a$ a positive scalar constant, representing the wave speed. So we have:\n$$\nf(u) = au\n$$\n\n##### Numerical scheme\n\ntry to solve it numerically, with finite difference, forward difference in time and central difference in space. we have:\n$$\n\\frac{u^{n+1}_i-u^n_i}{\\Delta t} + a \\frac{u^n_{i+1}-u^n_{i-1}}{2\\Delta x} = 0\n$$\n\n$$\nu^{n+1}_i = u^n_i - \\frac{a\\Delta t}{\\Delta x}\\left(\\frac{u^n_{i+1}-u^n_{i-1}}{2} \\right) = 0\n$$\n\nIt is consistency, and the Von Neumann analysis shows it is stable if the CFL condition (Courant number $a\\frac{\\Delta t}{\\Delta x}<1$) is satisfied. It should converge to the exact solution.\n\n##### Numerical practice\n\n\n\n\n\n## Systems of conservation laws\n\n{% note info %}\n\nJacobian matrices, linearized equations, conservative and characteristic variables.\nRankine-Hugoniot jump conditions. Boundary conditions.\n\n{% endnote%}\n\n\n\n## Numerical schemes for non-linear conservation laws\n\n{% note info %}\n\nIt is still an active research area and these are the classical methods:\n\nCentred schemes: one-step and two-step Lax Wendroff, MacCormack predictor-corrector. Artificial dissipation.\nUpwind schemes: flux vector and flux difference splitting. Monotone schemes: Godunov and Harten theorems. Exact and approximate Riemann solvers.\nHigh-order upwind schemes: the TVD property. The construction of TVD schemes using slope and flux limiters.\nWENO schemes: weighted essentially non-oscillatory methods\n\n{% endnote %}\n\n\n\n## Numerical schemes for multi-dimensional problems\n\n{% note info %}\n\nFinite differences and finite volume. Computational domain and boundary conditions.\n\n{% endnote %}\n\n\n\n## OpenFOAM demo on shockwave\n\n{% echarts 400 '85%' %}\nlet legends = ['exact', 'linear', 'upwind', 'linearUpwind', 'QUICK', 'TVD-vanLeer', 'TVD-Minmod', 'TVD-SuperBee']\nlet xaxis = [0.0005, 0.0015, 0.0025, 0.0035, 0.0045, 0.0055, 0.0065, 0.0075, 0.0085, 0.0095, 0.0105, 0.0115, 0.0125, 0.0135, 0.0145, 0.0155, 0.0165, 0.0175, 0.0185, 0.0195, 0.0205, 0.0215, 0.0225, 0.0235, 0.0245, 0.0255, 0.0265, 0.0275, 0.0285, 0.0295, 0.0305, 0.0315, 0.0325, 0.0335, 0.0345, 0.0355, 0.0365, 0.0375, 0.0385, 0.0395, 0.0405, 0.0415, 0.0425, 0.0435, 0.0445, 0.0455, 0.0465, 0.0475, 0.0485, 0.0495, 0.0505, 0.0515, 0.0525, 0.0535, 0.0545, 0.0555, 0.0565, 0.0575, 0.0585, 0.0595, 0.0605, 0.0615, 0.0625, 0.0635, 0.0645, 0.0655, 0.0665, 0.0675, 0.0685, 0.0695, 0.0705, 0.0715, 0.0725, 0.0735, 0.0745, 0.0755, 0.0765, 0.0775, 0.0785, 0.0795, 0.0805, 0.0815, 0.0825, 0.0835, 0.0845, 0.0855, 0.0865, 0.0875, 0.0885, 0.0895, 0.0905, 0.0915, 0.0925, 0.0935, 0.0945, 0.0955, 0.0965, 0.0975, 0.0985, 0.0995, 0.1005, 0.1015, 0.1025, 0.1035, 0.1045, 0.1055, 0.1065, 0.1075, 0.1085, 0.1095, 0.1105, 0.1115, 0.1125, 0.1135, 0.1145, 0.1155, 0.1165, 0.1175, 0.1185, 0.1195, 0.1205, 0.1215, 0.1225, 0.1235, 0.1245, 0.1255, 0.1265, 0.1275, 0.1285, 0.1295, 0.1305, 0.1315, 0.1325, 0.1335, 0.1345, 0.1355, 0.1365, 0.1375, 0.1385, 0.1395, 0.1405, 0.1415, 0.1425, 0.1435, 0.1445, 0.1455, 0.1465, 0.1475, 0.1485, 0.1495, 0.1505, 0.1515, 0.1525, 0.1535, 0.1545, 0.1555, 0.1565, 0.1575, 0.1585, 0.1595, 0.1605, 0.1615, 0.1625, 0.1635, 0.1645, 0.1655, 0.1665, 0.1675, 0.1685, 0.1695, 0.1705, 0.1715, 0.1725, 0.1735, 0.1745, 0.1755, 0.1765, 0.1775, 0.1785, 0.1795, 0.1805, 0.1815, 0.1825, 0.1835, 0.1845, 0.1855, 0.1865, 0.1875, 0.1885, 0.1895, 0.1905, 0.1915, 0.1925, 0.1935, 0.1945, 0.1955, 0.1965, 0.1975, 0.1985, 0.1995, 0.2005, 0.2015, 0.2025, 0.2035, 0.2045, 0.2055, 0.2065, 0.2075, 0.2085, 0.2095, 0.2105, 0.2115, 0.2125, 0.2135, 0.2145, 0.2155, 0.2165, 0.2175, 0.2185, 0.2195, 0.2205, 0.2215, 0.2225, 0.2235, 0.2245, 0.2255, 0.2265, 0.2275, 0.2285, 0.2295, 0.2305, 0.2315, 0.2325, 0.2335, 0.2345, 0.2355, 0.2365, 0.2375, 0.2385, 0.2395, 0.2405, 0.2415, 0.2425, 0.2435, 0.2445, 0.2455, 0.2465, 0.2475, 0.2485, 0.2495, 0.2505, 0.2515, 0.2525, 0.2535, 0.2545, 0.2555, 0.2565, 0.2575, 0.2585, 0.2595, 0.2605, 0.2615, 0.2625, 0.2635, 0.2645, 0.2655, 0.2665, 0.2675, 0.2685, 0.2695, 0.2705, 0.2715, 0.2725, 0.2735, 0.2745, 0.2755, 0.2765, 0.2775, 0.2785, 0.2795, 0.2805, 0.2815, 0.2825, 0.2835, 0.2845, 0.2855, 0.2865, 0.2875, 0.2885, 0.2895, 0.2905, 0.2915, 0.2925, 0.2935, 0.2945, 0.2955, 0.2965, 0.2975, 0.2985, 0.2995, 0.3005, 0.3015, 0.3025, 0.3035, 0.3045, 0.3055, 0.3065, 0.3075, 0.3085, 0.3095, 0.3105, 0.3115, 0.3125, 0.3135, 0.3145, 0.3155, 0.3165, 0.3175, 0.3185, 0.3195, 0.3205, 0.3215, 0.3225, 0.3235, 0.3245, 0.3255, 0.3265, 0.3275, 0.3285, 0.3295, 0.3305, 0.3315, 0.3325, 0.3335, 0.3345, 0.3355, 0.3365, 0.3375, 0.3385, 0.3395, 0.3405, 0.3415, 0.3425, 0.3435, 0.3445, 0.3455, 0.3465, 0.3475, 0.3485, 0.3495, 0.3505, 0.3515, 0.3525, 0.3535, 0.3545, 0.3555, 0.3565, 0.3575, 0.3585, 0.3595, 0.3605, 0.3615, 0.3625, 0.3635, 0.3645, 0.3655, 0.3665, 0.3675, 0.3685, 0.3695, 0.3705, 0.3715, 0.3725, 0.3735, 0.3745, 0.3755, 0.3765, 0.3775, 0.3785, 0.3795, 0.3805, 0.3815, 0.3825, 0.3835, 0.3845, 0.3855, 0.3865, 0.3875, 0.3885, 0.3895, 0.3905, 0.3915, 0.3925, 0.3935, 0.3945, 0.3955, 0.3965, 0.3975, 0.3985, 0.3995, 0.4005, 0.4015, 0.4025, 0.4035, 0.4045, 0.4055, 0.4065, 0.4075, 0.4085, 0.4095, 0.4105, 0.4115, 0.4125, 0.4135, 0.4145, 0.4155, 0.4165, 0.4175, 0.4185, 0.4195, 0.4205, 0.4215, 0.4225, 0.4235, 0.4245, 0.4255, 0.4265, 0.4275, 0.4285, 0.4295, 0.4305, 0.4315, 0.4325, 0.4335, 0.4345, 0.4355, 0.4365, 0.4375, 0.4385, 0.4395, 0.4405, 0.4415, 0.4425, 0.4435, 0.4445, 0.4455, 0.4465, 0.4475, 0.4485, 0.4495, 0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585, 0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675, 0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765, 0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855, 0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945, 0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035, 0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125, 0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215, 0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305, 0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395, 0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485, 0.5495, 0.5505, 0.5515, 0.5525, 0.5535, 0.5545, 0.5555, 0.5565, 0.5575, 0.5585, 0.5595, 0.5605, 0.5615, 0.5625, 0.5635, 0.5645, 0.5655, 0.5665, 0.5675, 0.5685, 0.5695, 0.5705, 0.5715, 0.5725, 0.5735, 0.5745, 0.5755, 0.5765, 0.5775, 0.5785, 0.5795, 0.5805, 0.5815, 0.5825, 0.5835, 0.5845, 0.5855, 0.5865, 0.5875, 0.5885, 0.5895, 0.5905, 0.5915, 0.5925, 0.5935, 0.5945, 0.5955, 0.5965, 0.5975, 0.5985, 0.5995, 0.6005, 0.6015, 0.6025, 0.6035, 0.6045, 0.6055, 0.6065, 0.6075, 0.6085, 0.6095, 0.6105, 0.6115, 0.6125, 0.6135, 0.6145, 0.6155, 0.6165, 0.6175, 0.6185, 0.6195, 0.6205, 0.6215, 0.6225, 0.6235, 0.6245, 0.6255, 0.6265, 0.6275, 0.6285, 0.6295, 0.6305, 0.6315, 0.6325, 0.6335, 0.6345, 0.6355, 0.6365, 0.6375, 0.6385, 0.6395, 0.6405, 0.6415, 0.6425, 0.6435, 0.6445, 0.6455, 0.6465, 0.6475, 0.6485, 0.6495, 0.6505, 0.6515, 0.6525, 0.6535, 0.6545, 0.6555, 0.6565, 0.6575, 0.6585, 0.6595, 0.6605, 0.6615, 0.6625, 0.6635, 0.6645, 0.6655, 0.6665, 0.6675, 0.6685, 0.6695, 0.6705, 0.6715, 0.6725, 0.6735, 0.6745, 0.6755, 0.6765, 0.6775, 0.6785, 0.6795, 0.6805, 0.6815, 0.6825, 0.6835, 0.6845, 0.6855, 0.6865, 0.6875, 0.6885, 0.6895, 0.6905, 0.6915, 0.6925, 0.6935, 0.6945, 0.6955, 0.6965, 0.6975, 0.6985, 0.6995, 0.7005, 0.7015, 0.7025, 0.7035, 0.7045, 0.7055, 0.7065, 0.7075, 0.7085, 0.7095, 0.7105, 0.7115, 0.7125, 0.7135, 0.7145, 0.7155, 0.7165, 0.7175, 0.7185, 0.7195, 0.7205, 0.7215, 0.7225, 0.7235, 0.7245, 0.7255, 0.7265, 0.7275, 0.7285, 0.7295, 0.7305, 0.7315, 0.7325, 0.7335, 0.7345, 0.7355, 0.7365, 0.7375, 0.7385, 0.7395, 0.7405, 0.7415, 0.7425, 0.7435, 0.7445, 0.7455, 0.7465, 0.7475, 0.7485, 0.7495, 0.7505, 0.7515, 0.7525, 0.7535, 0.7545, 0.7555, 0.7565, 0.7575, 0.7585, 0.7595, 0.7605, 0.7615, 0.7625, 0.7635, 0.7645, 0.7655, 0.7665, 0.7675, 0.7685, 0.7695, 0.7705, 0.7715, 0.7725, 0.7735, 0.7745, 0.7755, 0.7765, 0.7775, 0.7785, 0.7795, 0.7805, 0.7815, 0.7825, 0.7835, 0.7845, 0.7855, 0.7865, 0.7875, 0.7885, 0.7895, 0.7905, 0.7915, 0.7925, 0.7935, 0.7945, 0.7955, 0.7965, 0.7975, 0.7985, 0.7995, 0.8005, 0.8015, 0.8025, 0.8035, 0.8045, 0.8055, 0.8065, 0.8075, 0.8085, 0.8095, 0.8105, 0.8115, 0.8125, 0.8135, 0.8145, 0.8155, 0.8165, 0.8175, 0.8185, 0.8195, 0.8205, 0.8215, 0.8225, 0.8235, 0.8245, 0.8255, 0.8265, 0.8275, 0.8285, 0.8295, 0.8305, 0.8315, 0.8325, 0.8335, 0.8345, 0.8355, 0.8365, 0.8375, 0.8385, 0.8395, 0.8405, 0.8415, 0.8425, 0.8435, 0.8445, 0.8455, 0.8465, 0.8475, 0.8485, 0.8495, 0.8505, 0.8515, 0.8525, 0.8535, 0.8545, 0.8555, 0.8565, 0.8575, 0.8585, 0.8595, 0.8605, 0.8615, 0.8625, 0.8635, 0.8645, 0.8655, 0.8665, 0.8675, 0.8685, 0.8695, 0.8705, 0.8715, 0.8725, 0.8735, 0.8745, 0.8755, 0.8765, 0.8775, 0.8785, 0.8795, 0.8805, 0.8815, 0.8825, 0.8835, 0.8845, 0.8855, 0.8865, 0.8875, 0.8885, 0.8895, 0.8905, 0.8915, 0.8925, 0.8935, 0.8945, 0.8955, 0.8965, 0.8975, 0.8985, 0.8995, 0.9005, 0.9015, 0.9025, 0.9035, 0.9045, 0.9055, 0.9065, 0.9075, 0.9085, 0.9095, 0.9105, 0.9115, 0.9125, 0.9135, 0.9145, 0.9155, 0.9165, 0.9175, 0.9185, 0.9195, 0.9205, 0.9215, 0.9225, 0.9235, 0.9245, 0.9255, 0.9265, 0.9275, 0.9285, 0.9295, 0.9305, 0.9315, 0.9325, 0.9335, 0.9345, 0.9355, 0.9365, 0.9375, 0.9385, 0.9395, 0.9405, 0.9415, 0.9425, 0.9435, 0.9445, 0.9455, 0.9465, 0.9475, 0.9485, 0.9495, 0.9505, 0.9515, 0.9525, 0.9535, 0.9545, 0.9555, 0.9565, 0.9575, 0.9585, 0.9595, 0.9605, 0.9615, 0.9625, 0.9635, 0.9645, 0.9655, 0.9665, 0.9675, 0.9685, 0.9695, 0.9705, 0.9715, 0.9725, 0.9735, 0.9745, 0.9755, 0.9765, 0.9775, 0.9785, 0.9795, 0.9805, 0.9815, 0.9825, 0.9835, 0.9845, 0.9855, 0.9865, 0.9875, 0.9885, 0.9895, 0.9905, 0.9915, 0.9925, 0.9935, 0.9945, 0.9955, 0.9965, 0.9975, 0.9985, 0.9995];\nlet data0 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0068466305166028, 0.01517996384993614, 0.023513297183269482, 0.031846630516602824, 0.04017996384993616, 0.04851329718326951, 0.056846630516602846, 0.06517996384993618, 0.07351329718326953, 0.08184663051660288, 0.0901799638499362, 0.09851329718326955, 0.1068466305166029, 0.11517996384993623, 0.12351329718326957, 0.13184663051660292, 0.14017996384993625, 0.1485132971832696, 0.15684663051660286, 0.1651799638499362, 0.17351329718326952, 0.18184663051660288, 0.1901799638499362, 0.19851329718326954, 0.2068466305166029, 0.21517996384993623, 0.22351329718326957, 0.23184663051660293, 0.24017996384993626, 0.2485132971832696, 0.25684663051660295, 0.2651799638499363, 0.2735132971832696, 0.28184663051660297, 0.29017996384993583, 0.2985132971832692, 0.30684663051660255, 0.31517996384993585, 0.3235132971832692, 0.33184663051660257, 0.3401799638499359, 0.34851329718326923, 0.3568466305166026, 0.3651799638499359, 0.37351329718326925, 0.3818466305166026, 0.3901799638499359, 0.3985132971832693, 0.40684663051660264, 0.41517996384993594, 0.4235132971832693, 0.43184663051660266, 0.44017996384993596, 0.4485132971832693, 0.4568466305166027, 0.465179963849936, 0.47351329718326934, 0.4818466305166027, 0.490179963849936, 0.49851329718326937, 0.5068466305166027, 0.515179963849936, 0.5235132971832694, 0.5318466305166027, 0.540179963849936, 0.5485132971832695, 0.5568466305166028, 0.5651799638499361, 0.5735132971832695, 0.5818466305166028, 0.5901799638499361, 0.5985132971832695, 0.6068466305166028, 0.6151799638499361, 0.6235132971832695, 0.6318466305166028, 0.6401799638499361, 0.6485132971832696, 0.6568466305166029, 0.6651799638499362, 0.6735132971832696, 0.6818466305166029, 0.6901799638499362, 0.6985132971832696, 0.7068466305166029, 0.7151799638499362, 0.7235132971832696, 0.7318466305166029, 0.7401799638499362, 0.7485132971832696, 0.756846630516603, 0.7651799638499363, 0.7735132971832697, 0.781846630516603, 0.7901799638499363, 0.7985132971832697, 0.806846630516603, 0.8151799638499363, 0.8235132971832692, 0.8318466305166026, 0.840179963849936, 0.8485132971832692, 0.8568466305166027, 0.8651799638499358, 0.8735132971832693, 0.8818466305166025, 0.890179963849936, 0.8985132971832692, 0.9068466305166027, 0.9151799638499358, 0.9235132971832694, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];\nlet data1 = [4.7497782e-21, 1.2236753e-11, 1.4130822e-11, 1.4288661e-11, 3.4924231e-11, 2.9147543e-11, 3.5115528e-11, 4.4161819e-11, 3.215849e-11, 5.8045656e-11, 5.6981576e-11, 7.4404121e-11, 5.3422194e-11, 5.1797341e-11, 3.9958742e-11, 4.3513123e-11, 4.3012595e-11, 2.8551867e-11, 1.0164615e-11, 3.6251191e-11, 1.5676756e-11, 4.3760219e-11, 2.087822e-11, 3.2388469e-11, 1.0404042e-13, 2.2323671e-11, 5.9775439e-12, 1.5878278e-11, 2.5413204e-12, 1.3496131e-11, 9.0037193e-12, 6.4866305e-12, 3.0908672e-12, 9.3806435e-12, 1.8018999e-11, 3.9618166e-11, 3.3207453e-11, 3.636568e-11, 1.6921461e-11, 2.4158606e-11, 1.5541036e-11, 2.1612839e-11, 2.2662135e-12, 3.6244967e-11, 2.1388863e-11, 4.0860982e-11, 2.0243752e-11, 4.4159152e-11, 3.7287927e-11, 4.503816e-11, 4.2794622e-11, 3.2505514e-11, 3.5482004e-11, 3.3629729e-11, 5.203321e-11, 3.059744e-11, 3.5895609e-11, 2.4423153e-11, 2.8592995e-11, 9.0477364e-12, 1.1918963e-11, 1.11291e-11, 9.5233656e-12, 1.9686646e-11, 1.4684259e-11, 1.0456061e-11, 1.326493e-11, 1.6252424e-11, 1.8960364e-11, 1.2528977e-11, 1.0733391e-11, 7.5758314e-12, 1.6704377e-11, 3.1431097e-12, 2.2738832e-12, 1.7303387e-12, 6.4157141e-12, 6.9744867e-12, 1.1955532e-11, 1.2810531e-12, 2.9376966e-12, 5.1365506e-12, 6.5088614e-12, 5.6347441e-12, 8.9720403e-12, 5.0112797e-12, 1.8458058e-11, 3.0491843e-12, 6.0556854e-12, 1.5169225e-12, 1.0354577e-11, 1.6511413e-11, 1.0133936e-12, 1.1652192e-11, 3.9020711e-12, 7.5887253e-12, 1.191296e-11, 1.6945582e-11, 6.168507e-12, 3.7362289e-12, 1.430978e-11, 1.3481458e-11, 1.6208962e-11, 1.5379529e-11, 1.7487792e-11, 1.6227303e-11, 2.3599166e-11, 2.3986428e-11, 2.2877441e-11, 2.8995818e-11, 2.9717098e-12, 1.2812643e-11, 3.9682079e-12, 8.8532164e-12, 1.4168058e-11, 1.9919292e-11, 2.080119e-11, 3.3138871e-11, 2.4218295e-11, 2.2538532e-11, 1.2056572e-11, 2.2702373e-11, 2.0471618e-11, 2.1337621e-11, 9.2228044e-12, 1.1923409e-11, 1.0586334e-12, 7.2505939e-13, 2.3409092e-13, 9.9634254e-12, 1.9138767e-11, 2.1332952e-11, 3.4972806e-11, 1.2183732e-11, 2.5995097e-11, 4.4557306e-12, 1.2136936e-11, 5.6049548e-12, 2.6847761e-11, 8.9601469e-13, 2.9922622e-11, 2.5058955e-11, 1.8621566e-11, 9.110872e-12, 1.7125318e-11, 1.9371191e-11, 1.1349964e-12, 1.0734169e-12, 3.3798683e-12, 2.0197289e-11, 9.8479361e-12, 8.9555895e-12, 4.0984808e-12, 1.52756e-11, 2.0106143e-11, 4.3018931e-12, 3.1851594e-11, 1.9488014e-11, 2.5790573e-11, 1.2311893e-11, 1.3165891e-11, 4.6352448e-12, 1.1384311e-11, 5.0336217e-12, 4.7395075e-12, 1.0127489e-11, 2.3451887e-11, 2.9249694e-11, 2.1945746e-11, 2.2225633e-11, 8.1962946e-12, 3.4067677e-12, 1.1086306e-11, 1.9424656e-11, 1.276318e-11, 4.0311213e-11, 4.1533465e-11, 2.0941134e-11, 3.2442712e-11, 1.8077688e-11, 3.7180997e-11, 1.4652802e-11, 1.8750616e-11, 1.1626293e-11, 3.7798014e-12, 3.7143316e-12, 1.4391923e-11, 4.6232401e-12, 1.3459005e-11, 6.2703243e-12, 1.3369415e-11, 2.2801078e-12, 1.1086528e-11, 1.4684592e-12, 1.151425e-11, 1.0592781e-11, 2.7326391e-11, 1.7531254e-11, 1.7685202e-11, 5.8771716e-12, 4.6834857e-12, 1.7814919e-11, 1.283832e-13, 2.6063234e-11, 8.4499487e-12, 3.4453048e-11, 2.7307051e-11, 2.5739331e-11, 2.6164607e-11, 1.5238919e-11, 2.7857709e-11, 2.8230743e-11, 2.3899394e-11, 4.5124193e-11, 2.07684e-11, 2.5994874e-11, 1.2769738e-11, 7.5410401e-12, 4.1377182e-12, 9.3713065e-12, 7.1242115e-12, 1.8334232e-11, 3.5548474e-11, 1.4479624e-11, 2.4772844e-11, 3.0732159e-11, 2.7721323e-11, 2.8178611e-11, 2.0658579e-11, 3.5832584e-11, 3.0355346e-11, 2.908852e-11, 2.9166884e-12, 2.6237079e-11, 1.2974706e-11, 2.4185616e-11, 1.540943e-11, 2.5027499e-11, 5.3102848e-12, 2.6987816e-11, 2.0652577e-11, 3.3621837e-11, 2.9035055e-11, 3.0026996e-11, 1.9403536e-11, 2.2531196e-11, 2.1464448e-11, 1.056188e-11, 1.4717828e-11, 4.7268359e-12, 1.2038342e-11, 8.5823334e-12, 1.8288437e-11, 1.9149215e-11, 8.5026358e-12, 1.7856269e-11, 6.8202046e-12, 1.0678592e-12, 1.3995325e-11, 1.7243698e-11, 2.3217129e-11, 1.1335292e-11, 1.1618179e-11, 5.3917608e-12, 2.3009937e-11, 1.0752732e-11, 3.0797629e-11, 1.3905401e-11, 2.3099861e-11, 8.8703342e-12, 1.6012664e-11, 1.2647023e-11, 1.0079582e-11, 1.6073021e-11, 2.722613e-12, 2.6127481e-11, 1.3952975e-11, 5.9724308e-12, 7.044625e-12, 1.5309391e-11, 1.3658194e-11, 8.9471418e-12, 2.529249e-11, 4.328459e-12, 2.3591385e-11, 5.059743e-12, 1.1537704e-11, 1.247918e-11, 9.452338e-12, 2.4481175e-11, 2.0175058e-11, 2.3537142e-11, 6.6256846e-11, 6.1706634e-11, 1.2504701e-10, 1.3924097e-10, 2.4660067e-10, 3.2732035e-10, 5.094611e-10, 7.2167552e-10, 1.0844473e-09, 1.5062619e-09, 2.1630591e-09, 3.0315697e-09, 4.2715788e-09, 5.9608509e-09, 8.3437843e-09, 1.1625095e-08, 1.6157491e-08, 2.237713e-08, 3.0939687e-08, 4.2591514e-08, 5.8554935e-08, 8.0188008e-08, 1.0956633e-07, 1.4918876e-07, 2.027e-07, 2.7453773e-07, 3.7079022e-07, 4.9929447e-07, 6.7032184e-07, 8.9726275e-07, 1.1974227e-06, 1.5931029e-06, 2.1130083e-06, 2.7938138e-06, 3.6823602e-06, 4.8380822e-06, 6.336126e-06, 8.27101e-06, 1.0761312e-05, 1.3954958e-05, 1.8035783e-05, 2.3230923e-05, 2.9820083e-05, 3.8145661e-05, 4.8625074e-05, 6.1764365e-05, 7.8173982e-05, 9.8586305e-05, 0.00012387544, 0.00015507864, 0.0001934198, 0.00024033476, 0.0002974976, 0.00036684837, 0.00045062101, 0.00055137138, 0.00067200382, 0.00081579642, 0.00098642278, 0.0011879702, 0.0014249526, 0.0017023168, 0.002025442, 0.0024001302, 0.0028325882, 0.0033293991, 0.0038974847, 0.0045440572, 0.005276562, 0.0061026118, 0.0070299137, 0.0080661894, 0.0092190931, 0.010496126, 0.011904552, 0.013451315, 0.015142962, 0.016985572, 0.018984691, 0.021145281, 0.023471678, 0.025967555, 0.028635909, 0.031479046, 0.034498587, 0.037695476, 0.041070007, 0.044621845, 0.04835007, 0.052253211, 0.056329295, 0.060575892, 0.064990167, 0.069568924, 0.074308664, 0.079205625, 0.084255833, 0.089455144, 0.094799285, 0.10028389, 0.10590454, 0.11165678, 0.11753617, 0.12353828, 0.12965873, 0.13589322, 0.14223751, 0.14868746, 0.15523903, 0.1618883, 0.16863145, 0.1754648, 0.18238479, 0.18938797, 0.19647105, 0.20363084, 0.21086428, 0.21816844, 0.22554052, 0.23297781, 0.24047775, 0.24803786, 0.2556558, 0.2633293, 0.27105622, 0.27883449, 0.28666216, 0.29453734, 0.30245824, 0.31042314, 0.31843041, 0.32647848, 0.33456586, 0.3426911, 0.35085286, 0.35904979, 0.36728075, 0.37554428, 0.38383987, 0.39216506, 0.40052173, 0.40890302, 0.41731947, 0.42574855, 0.43422869, 0.44269034, 0.45124763, 0.45971518, 0.46837279, 0.47681342, 0.48558203, 0.49399581, 0.50280125, 0.51131554, 0.51987967, 0.52886102, 0.53664995, 0.54668062, 0.55314771, 0.56469983, 0.56982903, 0.5827048, 0.58713623, 0.59985871, 0.60559039, 0.61618948, 0.62421812, 0.63250928, 0.64190155, 0.64973676, 0.65867379, 0.66728178, 0.67543557, 0.68436249, 0.69251268, 0.70116246, 0.70940041, 0.71803499, 0.72591586, 0.73465007, 0.7421754, 0.75064661, 0.75785453, 0.76589282, 0.77257401, 0.78002765, 0.78616575, 0.79272695, 0.79838116, 0.80388596, 0.80906539, 0.81353354, 0.81825345, 0.82185202, 0.82608446, 0.82915378, 0.83282197, 0.83569667, 0.83878624, 0.84172396, 0.84429782, 0.84742436, 0.84965847, 0.85300593, 0.85521123, 0.85880565, 0.86132943, 0.86516801, 0.86828684, 0.8723899, 0.87638194, 0.88097185, 0.88619249, 0.89157407, 0.89817, 0.90433351, 0.91190589, 0.91831494, 0.92592112, 0.9316993, 0.9380621, 0.94212677, 0.94587885, 0.94717707, 0.94742498, 0.94767951, 0.94780527, 0.94803564, 0.94820734, 0.94830276, 0.94855132, 0.94874752, 0.94888718, 0.94845965, 0.94872855, 0.94879579, 0.94921478, 0.94945263, 0.94948663, 0.95001979, 0.9507142, 0.94977329, 0.95073316, 0.95280442, 0.94948042, 0.95051732, 0.95976221, 0.94700999, 0.92703429, 0.92353142, 0.92139847, 0.92149921, 0.92694969, 0.93111875, 0.93134918, 0.93179552, 0.9317036, 0.93019943, 0.92913487, 0.92907245, 0.92909259, 0.9291059, 0.9291442, 0.92915769, 0.92922451, 0.92924203, 0.92911433, 0.92899133, 0.92898409, 0.92899886, 0.92900657, 0.92900604, 0.92900255, 0.92900176, 0.92900006, 0.92899903, 0.92899627, 0.92899873, 0.92900462, 0.9290154, 0.92902768, 0.92904411, 0.92906035, 0.9290786, 0.92909653, 0.9291185, 0.92914032, 0.92916527, 0.92919056, 0.9292208, 0.92925171, 0.92928876, 0.92933076, 0.92937489, 0.92942012, 0.92947584, 0.92953381, 0.9295991, 0.92966776, 0.92974198, 0.92981911, 0.92989924, 0.92998185, 0.93006832, 0.93015723, 0.930241, 0.93032401, 0.93040384, 0.93048168, 0.93054887, 0.93061051, 0.93066871, 0.93073158, 0.93079108, 0.93084464, 0.93089778, 0.93094338, 0.93099075, 0.93103015, 0.93107199, 0.93110975, 0.93114968, 0.93118829, 0.93122538, 0.93126367, 0.93129719, 0.93133572, 0.93136851, 0.93140868, 0.93144301, 0.93148121, 0.93151575, 0.93155226, 0.93158905, 0.93162476, 0.93166393, 0.93169731, 0.93173935, 0.93177342, 0.9318156, 0.93185112, 0.93189142, 0.93192729, 0.93196446, 0.93200387, 0.93203979, 0.93208172, 0.93211479, 0.93215424, 0.93218187, 0.93221582, 0.93224005, 0.9322631, 0.93227917, 0.93228247, 0.93227121, 0.93224052, 0.93218199, 0.93208667, 0.93194139, 0.93172852, 0.9314245, 0.93099797, 0.93040702, 0.92959603, 0.92849123, 0.92699517, 0.92497967, 0.92227668, 0.91866727, 0.91386765, 0.90751276, 0.89913639, 0.88814896, 0.87381251, 0.85521555, 0.83125048, 0.80060084, 0.76175515, 0.71307468, 0.65297275, 0.58034371, 0.49543106, 0.40111096, 0.30400643, 0.21385279, 0.13973194, 0.085672249, 0.050029818, 0.028248231, 0.01561467, 0.0085251238, 0.0046229516, 0.0024979795, 0.0013473218, 0.00072604692, 0.00039108398, 0.00021061359, 0.00011341244, 6.1068151e-05, 3.2881948e-05, 1.7704928e-05, 9.5328448e-06, 5.1327199e-06, 2.7634876e-06, 1.487836e-06, 8.0098752e-07, 4.3120483e-07, 2.3210337e-07, 1.2492882e-07, 6.7187527e-08, 3.6127854e-08, 1.9352349e-08, 1.0404359e-08, 5.5210503e-09, 2.9529626e-09, 1.5346396e-09, 7.9428198e-10, 3.6861033e-10, 1.2419183e-10, 4.3436841e-11, 1.3257637e-11, 1.4870166e-11, 1.0206285e-11, 2.4490177e-11, 2.4370081e-11, 1.9556357e-11, 3.4978943e-11, 2.4217574e-11, 2.8594202e-11, 2.1797559e-11, 2.6848701e-11, 2.4967454e-11, 4.3702007e-11, 1.6981616e-11, 1.2151798e-11, 3.6970075e-12, 3.3598392e-11, 6.8825519e-12, 2.0689279e-11, 1.3582629e-11, 3.5937048e-11, 2.1156788e-11, 3.1031754e-11, 3.8754867e-11, 5.7551244e-11, 1.2017272e-11, 3.1834355e-12, 7.7792771e-12, 5.2228499e-12, 8.825401e-12, 2.2278166e-11, 2.3018056e-11, 1.0137468e-11, 2.6215477e-11, 1.8272039e-11, 1.0712309e-11, 7.3875772e-12, 1.0804989e-11, 8.8561465e-12, 3.9837509e-11, 2.3096973e-11, 6.3352043e-11, 2.9827795e-11, 7.8074697e-11, 3.5060857e-11, 6.8725291e-11, 6.4160861e-11, 4.8119258e-11, 4.3734306e-11, 5.0335154e-11, 8.2433787e-11, 2.8126692e-11, 5.3756784e-11, 1.8430428e-11, 2.9340196e-11, 3.4874053e-11, 1.5347553e-11, 1.4757284e-11, 2.7799813e-11, 5.3875659e-12, 1.7271756e-11, 2.7111536e-11, 1.7808525e-11, 1.3187377e-11, 6.0115774e-12, 2.0383045e-11, 3.0349248e-11, 6.6302612e-12, 1.3277616e-11, 1.5641245e-11, 2.5366146e-11, 1.2476235e-11, 1.1086805e-11, 9.6080238e-12, 2.9373495e-11, 5.0011937e-12, 3.4103085e-12, 7.4496232e-12, 2.1377889e-11, 1.5513601e-11, 3.2097745e-11, 2.0315671e-11, 1.5045981e-11, 6.3766385e-13, 5.3094257e-12, 2.071847e-11, 6.0062497e-12, 5.9049116e-12, 4.2392826e-11, 1.8420105e-11, 2.1885356e-11, 8.4259315e-12, 2.8205943e-11, 2.5683036e-12, 2.7446629e-11, 3.480124e-12, 3.6805801e-13, 3.8837336e-11, 8.7038619e-12, 2.6307602e-11, 1.5869117e-11, 7.3966789e-13, 1.2958395e-11, 1.394325e-11, 4.6496739e-12, 1.5903303e-11, 2.8199838e-11, 2.5214417e-11, 8.5717784e-12, 2.6207041e-11, 6.0112444e-12, 4.0859325e-11, 2.4191602e-11, 3.8050274e-11, 2.4840254e-11, 2.8883342e-11, 2.9577836e-12, 8.4301493e-12, 1.0224377e-11, 2.481528e-11, 2.9430213e-11, 1.1148851e-11, 2.2952014e-11, 5.6299781e-12, 2.6766898e-11, 4.9046285e-12, 5.1555983e-11, 1.0087076e-11, 4.4939041e-11, 1.4179447e-11, 2.3963397e-11, 2.3591898e-12, 1.9854821e-11, 1.3202472e-11, 3.1101791e-11, 1.3970666e-11, 2.8291852e-11, 3.9392531e-11, 1.6398339e-12, 1.9717077e-12, 3.3493946e-11, 1.4251482e-11, 2.225519e-11, 3.5135667e-11, 3.6623549e-11, 5.2043471e-11, 2.0132197e-11, 1.4937762e-11, 7.5046765e-12, 1.3253197e-11, 5.6778167e-12, 1.659369e-11, 7.4506221e-12, 8.1147027e-12, 1.4139045e-11, 2.3932651e-12, 4.2783971e-12, 2.1105952e-11, 5.3867889e-12, 1.8312441e-11, 9.8047062e-12, 9.3391949e-12, 3.6215311e-12, 1.3048523e-11, 4.0050618e-11, 1.8217429e-11, 1.684487e-11, 2.7428204e-11, 1.2258796e-11, 2.2140089e-11, 2.0840342e-11, 4.178391e-12, 1.6649631e-11, 1.2855725e-11, 3.9175537e-12, 1.789277e-11, 2.852261e-11, 3.6098545e-11, 6.5570048e-12, 3.2203301e-11, 9.8111439e-12, 1.2932422e-11, 2.8110487e-12, 1.2827977e-11, 7.5176629e-12, 2.5976061e-11, 2.329077e-11, 3.8056933e-11, 4.690975e-11, 3.7367213e-11, 5.2457148e-11, 3.9460349e-11, 4.9403576e-11, 6.3205752e-11, 7.2271235e-11, 4.9367614e-11, 4.5474479e-11, 1.1120325e-11, 1.9082965e-11, 9.2018946e-12, 2.3865167e-11, 4.1185538e-11, 3.977624e-11, 1.6751302e-11, 8.4957471e-12, 3.4906463e-11, 2.2628576e-11, 2.4532244e-11, 4.0878083e-11, 4.5074011e-11, 1.5930275e-11, 8.4807628e-12, 2.2477734e-11, 9.4470816e-12, 3.760119e-11, 2.9787615e-12, 4.1064887e-11, 1.2349257e-12, 2.1885134e-11, 1.5716833e-12, 8.662683e-12, 1.085083e-11, 6.3942867e-12, 1.9193516e-11, 3.2279888e-11, 2.5822778e-11, 4.105412e-11, 1.8547638e-11, 2.2644559e-11, 4.7690819e-11, 2.1394316e-11, 6.6005036e-11, 9.6874959e-12, 1.498449e-11, 1.0487767e-11, 4.0695719e-11, 5.1100795e-12, 3.0456913e-13, 2.4637023e-11, 3.9656476e-11, 2.8627056e-11, 5.2256026e-11, 2.4325572e-11, 3.5351108e-11, 3.4459932e-11, 2.6888215e-11, 3.1180264e-11, 7.3392391e-11, 4.5273468e-11, 2.3238491e-11, 4.5416429e-11, 4.9126201e-12, 6.8129583e-12, 4.7035063e-12, 8.8010932e-12, 3.6449177e-11, 3.57498e-11, 6.8845498e-11, 6.3584799e-11, 6.4005468e-11, 4.7890387e-11, 4.5425864e-11, 3.9753042e-11, 5.3676979e-11, 7.4143047e-11, 5.9449474e-11, 7.5752469e-11, 7.8523892e-11, 5.5389292e-11, 6.6257437e-11, 2.5778935e-11, 4.8051218e-11, 2.9114655e-11, 2.0579061e-11, 3.7228137e-11, 1.9723736e-13, 1.6788374e-11, 1.5427803e-11, 3.2430951e-11, 1.5089269e-11, 8.6060757e-12, 4.2812829e-12, 1.4006628e-11, 3.3064175e-12, 1.1991854e-12, 1.1020541e-11, 1.2967097e-20];\nlet data2 = [3.1587274e-21, 1.3862829e-11, 1.646295e-11, 3.2144263e-11, 1.5146772e-11, 4.8599543e-11, 1.5956976e-11, 4.5079954e-11, 1.1164003e-11, 2.375367e-11, 8.4472809e-12, 9.1891247e-12, 1.5533811e-11, 1.4210519e-11, 3.0230631e-11, 5.3723755e-11, 1.8964366e-11, 3.6470387e-11, 1.7343736e-11, 2.657321e-11, 1.6595779e-11, 2.8922344e-12, 2.2643239e-12, 7.9208543e-13, 1.0798639e-11, 4.4303875e-12, 1.3237586e-11, 3.0215069e-11, 3.847939e-12, 3.3845368e-11, 1.968798e-11, 2.5638958e-11, 3.1805576e-11, 1.4100588e-11, 4.2181828e-11, 9.1871239e-12, 5.4263521e-11, 2.6657799e-11, 2.9521244e-11, 2.6140709e-11, 3.6060228e-11, 3.9825691e-11, 3.693768e-11, 7.9510883e-12, 5.2393906e-11, 7.6993238e-12, 2.9091077e-11, 9.7627919e-12, 2.3350514e-11, 7.4785714e-12, 3.1269923e-11, 1.6848099e-11, 2.0900673e-11, 3.1482227e-12, 1.9616508e-11, 1.3593057e-11, 3.2383244e-11, 2.9686864e-11, 4.1839584e-11, 2.1039505e-11, 4.4363009e-11, 4.5567699e-11, 5.1585925e-11, 5.0254408e-11, 3.1628285e-11, 4.9054942e-11, 6.1561022e-11, 3.6102133e-11, 2.0040228e-11, 1.4764401e-11, 2.1241917e-11, 2.5835813e-11, 3.5030384e-11, 4.1158653e-11, 3.5126977e-11, 4.6989584e-11, 3.8374905e-11, 5.3902491e-11, 2.2804858e-11, 4.116799e-11, 2.2078131e-11, 2.9711651e-11, 2.7927514e-12, 3.6848534e-11, 4.8283198e-12, 1.5137768e-11, 1.8658358e-12, 5.5483772e-12, 4.8572199e-12, 7.2834956e-12, 4.3929285e-12, 9.2330306e-12, 1.2192069e-11, 1.0106481e-11, 1.2977151e-11, 5.4687908e-13, 2.7688531e-13, 5.1474437e-12, 9.0471806e-12, 7.2589305e-12, 1.1016835e-11, 1.5147217e-11, 7.1979068e-12, 1.6878222e-11, 2.5077518e-12, 1.3794247e-11, 2.3397977e-12, 3.3936292e-11, 4.4505064e-12, 4.141553e-11, 2.6810636e-11, 1.4511192e-11, 3.50435e-11, 2.6215738e-12, 1.6870441e-11, 1.6199848e-11, 7.5394839e-12, 4.3516901e-13, 1.8329341e-13, 2.6110141e-13, 3.3873156e-12, 1.4211298e-11, 5.7610154e-12, 2.4711376e-11, 1.6844209e-11, 1.1221025e-11, 1.4642687e-11, 1.7884391e-11, 5.9851024e-12, 1.7921405e-11, 1.2904123e-11, 1.9490681e-11, 1.8598891e-11, 1.2063686e-11, 1.8508411e-11, 3.2205064e-11, 1.1345184e-11, 1.8744058e-11, 2.3708653e-11, 3.811736e-11, 2.6724824e-12, 4.3599156e-11, 2.0617119e-11, 5.1319933e-11, 3.0725823e-11, 5.1442091e-11, 2.3753115e-11, 6.2107567e-11, 3.1677192e-11, 5.5339939e-11, 3.4040666e-11, 2.5940742e-11, 4.6395909e-11, 3.6795625e-11, 3.4361235e-11, 2.2750948e-11, 3.1149432e-11, 2.7081963e-11, 3.2067789e-11, 8.3646933e-12, 4.675705e-11, 9.3488534e-12, 1.7650189e-12, 1.4368581e-11, 1.7560154e-11, 9.1522214e-12, 5.3022816e-12, 5.1575583e-14, 7.4349989e-12, 4.3805903e-12, 1.007169e-11, 7.4106559e-13, 1.807591e-12, 1.2629572e-11, 4.3775891e-12, 1.3309947e-11, 9.9894355e-12, 1.6843987e-11, 1.3354187e-11, 5.8228171e-12, 3.1425539e-12, 2.8588437e-11, 2.262212e-12, 5.8623881e-12, 7.9196316e-12, 5.8783943e-12, 1.2594558e-11, 2.3195342e-11, 1.5702765e-12, 3.1104303e-11, 8.5607694e-12, 4.3086735e-12, 1.2531867e-11, 1.2554209e-11, 1.8647243e-12, 9.3182859e-12, 5.2836077e-12, 2.6260533e-11, 5.2642671e-13, 2.6149379e-11, 6.5936721e-12, 5.6280749e-12, 1.2302667e-11, 1.50195e-11, 3.4461163e-12, 2.4724603e-11, 1.2550652e-11, 1.7924073e-11, 2.4092246e-11, 3.1099635e-11, 3.2873213e-11, 1.9854823e-11, 1.2604229e-11, 7.9728745e-12, 2.7277039e-11, 8.5136401e-12, 1.9863048e-11, 3.4652904e-11, 1.1901511e-11, 2.5563929e-11, 1.2166726e-11, 2.461745e-11, 1.3254037e-12, 7.839267e-12, 9.9509761e-12, 6.5985629e-12, 3.8159266e-12, 9.5138063e-12, 3.7557921e-12, 1.6593e-11, 1.3511137e-11, 7.505693e-12, 4.7188328e-12, 1.596798e-11, 3.1650071e-12, 5.7689072e-13, 4.2908888e-12, 1.1663197e-11, 6.9723748e-12, 2.1425766e-11, 7.5927268e-12, 1.5739669e-11, 6.1834017e-12, 7.7385613e-13, 2.4608447e-12, 1.8791743e-12, 2.8075349e-12, 1.061968e-12, 8.6929319e-12, 1.971688e-11, 3.1628729e-11, 4.7778446e-11, 3.5523798e-11, 3.331405e-11, 3.4131257e-11, 3.3807687e-11, 3.3272812e-11, 2.7870714e-11, 3.199665e-11, 2.726659e-11, 1.8468729e-11, 3.5013599e-11, 4.2273197e-11, 3.6007874e-11, 3.1525578e-11, 1.2414044e-11, 1.5876389e-11, 3.6948795e-12, 3.3746107e-11, 2.5809358e-11, 2.4112477e-11, 4.4271084e-11, 2.9867156e-11, 3.1420648e-11, 1.7371303e-11, 2.4465836e-11, 4.0992588e-12, 2.6491401e-12, 8.1303801e-12, 8.5713292e-12, 2.3663635e-12, 1.5372526e-11, 2.8357792e-11, 1.1904735e-11, 1.3772349e-11, 5.2911662e-12, 1.6268652e-11, 1.8988709e-11, 4.6916e-12, 1.0875669e-11, 1.3120318e-11, 2.6141042e-11, 7.6080661e-11, 9.5989838e-11, 1.4489528e-10, 2.0154195e-10, 3.0967917e-10, 4.3345436e-10, 6.3358286e-10, 8.8771735e-10, 1.2741231e-09, 1.7645955e-09, 2.5038187e-09, 3.4686766e-09, 4.8671167e-09, 6.7767861e-09, 9.4414534e-09, 1.3159652e-08, 1.8246835e-08, 2.5266961e-08, 3.487059e-08, 4.8017711e-08, 6.5968252e-08, 9.0295516e-08, 1.2330064e-07, 1.6787384e-07, 2.2790804e-07, 3.0853965e-07, 4.1644473e-07, 5.6052828e-07, 7.5213878e-07, 1.0063065e-06, 1.3422031e-06, 1.7847702e-06, 2.3659374e-06, 3.1264883e-06, 4.1185031e-06, 5.4079356e-06, 7.0781943e-06, 9.234058e-06, 1.2006817e-05, 1.5560174e-05, 2.0097201e-05, 2.5868814e-05, 3.3183366e-05, 4.2418174e-05, 5.403248e-05, 6.8582362e-05, 8.6737913e-05, 0.00010930182, 0.00013723087, 0.00017165865, 0.00021392091, 0.00026558174, 0.00032846207, 0.00040466801, 0.00049662036, 0.0006070829, 0.0007391898, 0.00089647036, 0.0010828703, 0.0013027684, 0.0015609871, 0.0018627962, 0.0022139076, 0.0026204618, 0.0030890034, 0.0036264471, 0.0042400316, 0.004937265, 0.0057258587, 0.0066136536, 0.0076085392, 0.0087183668, 0.0099508598, 0.011313523, 0.012813554, 0.014457756, 0.016252461, 0.018203457, 0.020315928, 0.022594403, 0.02504272, 0.027663998, 0.030460627, 0.033434265, 0.036585855, 0.039915638, 0.043423192, 0.047107468, 0.050966832, 0.05499912, 0.059201687, 0.063571465, 0.068105018, 0.072798595, 0.077648185, 0.082649568, 0.087798357, 0.093090051, 0.098520067, 0.10408378, 0.10977655, 0.11559376, 0.12153083, 0.12758323, 0.13374653, 0.14001638, 0.14638853, 0.15285883, 0.15942327, 0.16607796, 0.1728191, 0.17964307, 0.18654633, 0.19352548, 0.20057725, 0.20769849, 0.21488617, 0.22213736, 0.22944927, 0.2368192, 0.24424456, 0.25172287, 0.25925174, 0.26682889, 0.2744521, 0.28211929, 0.28982841, 0.29757751, 0.30536475, 0.3131883, 0.32104646, 0.32893756, 0.33686, 0.34481224, 0.35279281, 0.36080028, 0.36883326, 0.37689044, 0.38497053, 0.39307229, 0.40119452, 0.40933606, 0.41749581, 0.42567269, 0.43386567, 0.44207375, 0.45029603, 0.45853158, 0.46677972, 0.47503945, 0.4833107, 0.49159204, 0.49988463, 0.50818626, 0.5164997, 0.52482283, 0.53315832, 0.54150894, 0.5498738, 0.5582359, 0.5665362, 0.57494469, 0.58311624, 0.59136317, 0.59958707, 0.60776687, 0.6159676, 0.624232, 0.6323957, 0.6405601, 0.64871327, 0.65688165, 0.66508144, 0.673247, 0.68143447, 0.68964666, 0.69798511, 0.70610249, 0.71427091, 0.72235892, 0.73037817, 0.73833991, 0.74625126, 0.75411165, 0.76191705, 0.76966278, 0.77734373, 0.78495423, 0.79248781, 0.79993689, 0.80729313, 0.81454716, 0.82168897, 0.82870754, 0.83559096, 0.84232631, 0.84889968, 0.85529632, 0.86150056, 0.86749612, 0.87326608, 0.87879326, 0.88406045, 0.88905082, 0.89374843, 0.89813868, 0.9022091, 0.90594978, 0.90935421, 0.91241975, 0.91514819, 0.91754603, 0.91962462, 0.9214, 0.92289244, 0.92412584, 0.92512669, 0.92592309, 0.92654356, 0.92701596, 0.92736647, 0.92761863, 0.92779284, 0.92791107, 0.9279828, 0.92801901, 0.92802639, 0.92803187, 0.92801278, 0.92799155, 0.9279374, 0.92788026, 0.92781863, 0.92775834, 0.92770019, 0.9276448, 0.92759277, 0.92754454, 0.92750042, 0.92746044, 0.92742444, 0.92739211, 0.92736302, 0.92733674, 0.92731283, 0.9272909, 0.92727063, 0.92725175, 0.92723405, 0.92721737, 0.92720159, 0.92718663, 0.92717241, 0.92715889, 0.92714602, 0.92713376, 0.92712205, 0.92711087, 0.92710016, 0.92708987, 0.92707996, 0.92707038, 0.92706111, 0.92705212, 0.92704341, 0.92703496, 0.92702678, 0.9270189, 0.92701128, 0.92700388, 0.92699672, 0.92698978, 0.92698311, 0.92697697, 0.92697102, 0.9269644, 0.92695882, 0.92695257, 0.92694634, 0.92694042, 0.92693453, 0.92692853, 0.92692233, 0.92691583, 0.92690895, 0.92690158, 0.92689368, 0.92688513, 0.92687566, 0.9268651, 0.92685345, 0.92684118, 0.92682992, 0.92681909, 0.92680727, 0.92679675, 0.92678714, 0.92677884, 0.92677221, 0.9267674, 0.92676447, 0.92676321, 0.92676338, 0.92676473, 0.92676685, 0.92676937, 0.92677188, 0.92677402, 0.92677561, 0.92677665, 0.92677714, 0.92677547, 0.92677222, 0.92676995, 0.92676664, 0.92676285, 0.92675868, 0.92675421, 0.92674948, 0.92674448, 0.92673922, 0.92673375, 0.92672829, 0.92672287, 0.92671729, 0.92671144, 0.92670515, 0.92670037, 0.9266956, 0.9266888, 0.92668168, 0.92667323, 0.92666665, 0.92666105, 0.92665279, 0.92664626, 0.92663888, 0.92663016, 0.92662086, 0.92661089, 0.9266001, 0.92658832, 0.92657535, 0.92656091, 0.92654466, 0.92652616, 0.92650484, 0.92647999, 0.92645069, 0.92641577, 0.92637373, 0.92632266, 0.92626013, 0.92618306, 0.92608752, 0.92596852, 0.92581972, 0.92563309, 0.92539845, 0.92510291, 0.92473014, 0.92425951, 0.92366491, 0.92291337, 0.92196323, 0.92076189, 0.91924297, 0.91732274, 0.91489558, 0.91182839, 0.90795347, 0.90305973, 0.89688164, 0.88908574, 0.87925393, 0.86686358, 0.85126424, 0.83165196, 0.80704406, 0.77626142, 0.73793377, 0.69055942, 0.63268039, 0.56327591, 0.48250857, 0.39285097, 0.30012158, 0.21309309, 0.14045218, 0.086688654, 0.050828674, 0.028729114, 0.015849886, 0.00861729, 0.0046467978, 0.0024949216, 0.0013366319, 0.0007153302, 0.00038263615, 0.00020462933, 0.00010942248, 5.850937e-05, 3.1284829e-05, 1.6727594e-05, 8.9439202e-06, 4.7819894e-06, 2.5567432e-06, 1.3669313e-06, 7.308132e-07, 3.9068546e-07, 2.0884449e-07, 1.1162505e-07, 5.9670655e-08, 3.1888187e-08, 1.7047214e-08, 9.0987698e-09, 4.8644519e-09, 2.5910582e-09, 1.4090592e-09, 7.3607532e-10, 3.7363817e-10, 1.7609201e-10, 6.9859433e-11, 6.505581e-11, 1.1719474e-11, 4.888612e-11, 2.3601888e-12, 3.4779596e-11, 1.1009219e-11, 1.7066971e-11, 4.3198424e-11, 1.6923455e-11, 2.9291692e-11, 6.9220659e-12, 9.226979e-13, 1.9257449e-11, 2.1512192e-11, 2.9423553e-12, 1.0852717e-11, 3.749397e-13, 2.8956266e-11, 2.7232853e-11, 1.094118e-11, 2.3079547e-11, 3.5580423e-12, 8.7943225e-12, 3.5617162e-11, 3.3684635e-12, 1.2529068e-11, 1.9249346e-11, 3.1177378e-11, 1.2765265e-11, 2.028881e-11, 1.8367383e-12, 3.5656121e-11, 1.7748588e-11, 1.607812e-11, 1.6635646e-11, 2.148844e-11, 1.3817604e-11, 2.4028995e-11, 7.6920353e-12, 2.2070828e-11, 2.0256067e-11, 8.1556597e-12, 4.0443095e-12, 1.4599117e-11, 3.5777882e-11, 1.215202e-11, 3.2232604e-11, 1.05194e-11, 1.4869943e-12, 3.0990797e-12, 2.8712522e-11, 1.0117711e-11, 7.1187483e-12, 1.8899935e-11, 2.1021929e-11, 1.7956037e-11, 3.8355509e-11, 4.8117261e-12, 3.4119731e-13, 6.755352e-12, 2.2086811e-11, 1.8748094e-12, 2.1405527e-11, 2.1825197e-11, 1.3863227e-13, 8.1193644e-12, 6.0514244e-12, 1.3537343e-11, 2.5115964e-11, 1.3615816e-11, 3.6313542e-11, 3.1876534e-12, 5.0612307e-11, 1.4525195e-11, 4.9153061e-11, 5.0610199e-12, 3.5477641e-11, 2.0070373e-11, 1.2292317e-11, 2.257996e-11, 2.6219695e-11, 3.3177057e-11, 3.3918834e-11, 2.0201124e-11, 2.9929022e-11, 2.0404911e-11, 1.7744481e-11, 4.564097e-13, 3.0670022e-12, 6.1093637e-12, 4.9195239e-11, 5.3775764e-12, 3.2420629e-11, 3.2356918e-11, 1.1203127e-11, 2.1044239e-11, 7.0392762e-12, 1.0964045e-11, 2.4331011e-11, 1.1977203e-11, 2.7525213e-11, 2.2182711e-11, 3.4249153e-11, 2.6882887e-12, 3.8139957e-12, 1.3752339e-11, 2.0393922e-11, 1.8775732e-11, 1.6146492e-11, 8.4262645e-12, 2.6534919e-11, 1.1913936e-11, 3.2594002e-11, 1.6710789e-11, 2.4528359e-11, 1.5794528e-12, 3.0703987e-11, 1.9988459e-11, 4.2636903e-11, 2.9170263e-11, 1.5225348e-11, 2.5626762e-11, 4.4411928e-11, 1.589842e-11, 4.5259483e-11, 2.0439208e-11, 2.6341012e-11, 1.347341e-11, 2.1255684e-11, 1.0629729e-11, 3.9437928e-11, 2.9967427e-12, 3.1947237e-11, 6.9956554e-12, 6.1998242e-12, 2.0789284e-12, 2.0116436e-11, 4.647676e-12, 1.6522098e-11, 9.3896974e-12, 6.0516465e-12, 8.3840866e-12, 2.1797115e-11, 1.0969372e-11, 1.4066343e-12, 7.4723771e-12, 1.508716e-11, 2.572588e-11, 3.1789957e-11, 3.7379645e-12, 1.4661163e-11, 3.0160668e-11, 3.8229419e-11, 2.3631412e-11, 3.3269737e-11, 1.1988414e-11, 3.4363256e-11, 2.2416021e-11, 1.1728131e-11, 9.317551e-12, 9.889617e-12, 2.6019238e-11, 5.4338506e-12, 3.9482659e-11, 1.4534407e-11, 5.2454928e-11, 5.7924963e-11, 5.1665202e-11, 7.6479705e-11, 5.8635218e-11, 6.9449863e-11, 4.4034991e-11, 3.6424314e-11, 4.3910566e-11, 3.1681627e-11, 2.2541112e-11, 1.4644958e-11, 1.2643947e-11, 1.8225976e-11, 1.0744275e-11, 1.0612192e-11, 2.0740669e-11, 4.3798572e-11, 3.0136138e-11, 1.6759738e-11, 2.4857014e-11, 5.8160049e-12, 1.1487828e-11, 7.7568561e-12, 1.3198587e-11, 4.9671184e-12, 1.9774128e-11, 4.5795254e-12, 1.0955387e-11, 2.7193117e-11, 2.7553294e-12, 2.3722427e-11, 4.8546809e-12, 1.5726156e-11, 1.0720633e-11, 9.6529766e-12, 2.9908599e-12, 2.6848257e-11, 3.5884548e-13, 3.1516578e-11, 5.297738e-11, 3.3170952e-11, 4.9748325e-11, 1.0841063e-11, 5.7032789e-11, 4.068695e-11, 5.5832715e-11, 3.2919771e-11, 4.6057423e-11, 2.3108183e-11, 4.1595996e-11, 1.170904e-11, 1.0863594e-11, 1.5928055e-11, 2.1407081e-11, 1.4800017e-12, 2.8126359e-11, 4.7800593e-11, 5.4824441e-11, 2.0990407e-11, 5.1780192e-11, 1.1011772e-11, 2.5747635e-11, 1.1905057e-11, 1.7807748e-11, 3.2342156e-11, 9.8929469e-12, 1.1113443e-11, 6.7752201e-12, 1.8121308e-11, 6.0684066e-12, 3.6823562e-11, 3.2676027e-11, 3.8488147e-11, 4.7162818e-11, 2.817775e-11, 4.1453479e-11, 3.4595678e-11, 3.2416078e-11, 5.5118354e-11, 5.5519489e-12, 5.4331847e-11, 3.5331795e-12, 3.1377169e-11, 3.4956633e-12, 2.5582031e-11, 2.1050122e-11, 3.4838313e-11, 6.7041836e-12, 3.0708981e-11, 1.1507141e-11, 1.392205e-12, 2.4646346e-12, 2.9236638e-11, 1.18631e-12, 2.1137697e-11, 1.0209059e-11, 7.883501e-12, 6.1566473e-12, 4.3042588e-12, 3.0403524e-11, 2.3630743e-13, 2.2504595e-11, 1.8515117e-11, 1.5644797e-11, 3.6540082e-11, 3.5870451e-11, 3.4634194e-11, 1.2553487e-12, 2.1674356e-11, 2.6223579e-12, 2.6899536e-12, 1.6752412e-11, 1.2854726e-11, 2.237007e-11, 4.7813135e-12, 1.7285852e-11, 6.1368907e-13, 2.2063613e-11, 2.356861e-20];\nlet data3 = [6.9688318e-22, 1.644272e-11, 6.314786e-12, 3.2875102e-11, 9.8260368e-14, 2.3936075e-11, 2.694969e-11, 4.2087013e-11, 4.6329106e-11, 2.3309053e-11, 3.7687305e-11, 6.6659224e-12, 4.6838192e-12, 9.6655319e-12, 2.0671807e-11, 2.8959359e-11, 2.2623343e-11, 3.6969137e-11, 2.1388752e-11, 3.5699199e-11, 2.9340507e-11, 1.772255e-11, 8.2035196e-12, 1.8482512e-11, 2.4174501e-11, 1.7265261e-11, 2.2804302e-11, 3.1309939e-12, 6.693711e-12, 2.5666191e-11, 2.6720934e-11, 1.9686869e-11, 6.4094895e-12, 2.6156381e-11, 1.178002e-11, 2.1946524e-11, 1.5986765e-11, 4.5602823e-11, 4.2158819e-11, 5.0142253e-11, 3.0869434e-11, 2.972888e-11, 2.2426155e-11, 3.9049945e-11, 2.5087744e-11, 5.3440423e-11, 3.8887215e-11, 6.2241064e-11, 5.2624773e-11, 7.1175534e-11, 4.66878e-11, 4.4403358e-11, 4.6373456e-11, 4.1789009e-11, 4.2431703e-11, 3.5016267e-11, 4.5389963e-11, 4.1522905e-11, 5.6982577e-11, 4.5454432e-11, 6.0826959e-11, 2.1750226e-11, 2.9669301e-11, 1.1971094e-11, 3.0990037e-11, 1.1845156e-11, 2.3249141e-11, 7.7532336e-12, 1.9204681e-11, 3.0587436e-12, 1.4002994e-11, 2.5361628e-11, 9.4072093e-12, 1.9982205e-12, 5.6142917e-12, 8.5617698e-12, 2.0093693e-11, 1.1226582e-12, 1.1819035e-12, 1.1260151e-11, 7.7041034e-12, 6.2246287e-15, 1.140354e-11, 7.8352655e-13, 1.0221303e-11, 2.1752893e-12, 1.9166222e-11, 2.1780015e-11, 1.1090419e-11, 3.5089073e-11, 1.0938137e-11, 2.4513521e-11, 6.9846017e-12, 8.5136401e-12, 1.1986322e-11, 2.5332061e-12, 1.8469396e-12, 9.5819439e-12, 1.2684482e-11, 4.9295813e-12, 1.0067243e-11, 1.4625681e-11, 3.0977587e-12, 1.4397592e-11, 1.1447335e-11, 2.3799577e-11, 5.6455261e-12, 3.5564147e-11, 2.6856209e-11, 3.0241857e-11, 2.6844426e-11, 2.438536e-11, 1.8498852e-11, 1.5597614e-11, 1.3305279e-11, 8.4438352e-12, 1.2783854e-12, 1.7306833e-11, 2.4847206e-11, 9.7293345e-12, 2.3259701e-11, 6.1117071e-12, 2.1805469e-11, 4.1434982e-12, 2.0206737e-11, 1.071116e-11, 8.3765868e-12, 3.1402197e-12, 9.787357e-12, 1.4450279e-11, 1.1241922e-11, 1.0742283e-11, 4.307562e-12, 1.8921794e-12, 1.7633849e-11, 5.7883593e-12, 1.06129e-11, 8.7511769e-13, 1.374067e-11, 8.8962331e-12, 3.0052673e-11, 5.1190994e-12, 1.807691e-11, 2.3518579e-11, 2.1319836e-11, 4.4795191e-14, 1.0434831e-11, 8.6904865e-12, 2.1587385e-11, 4.3709199e-12, 2.9441991e-11, 1.0720275e-11, 7.4697902e-12, 1.0809754e-11, 1.4696486e-11, 1.8840651e-13, 1.442049e-11, 1.9502353e-11, 2.7316276e-11, 1.128316e-11, 9.0713011e-12, 1.2080803e-11, 3.0674025e-11, 3.5719429e-11, 1.915833e-11, 3.1539917e-11, 1.1264042e-11, 1.2411821e-11, 1.2584888e-12, 1.6417377e-11, 1.2998382e-12, 8.0154466e-12, 6.880339e-12, 2.9339062e-11, 2.0188063e-11, 2.6760505e-11, 3.110786e-11, 3.7842921e-11, 1.6658693e-11, 2.7987093e-11, 2.6125925e-11, 2.0261203e-11, 1.1568827e-11, 1.0462064e-11, 6.349355e-12, 1.5180229e-11, 2.04246e-12, 1.7739112e-12, 2.6350346e-11, 8.2377551e-12, 2.5672971e-11, 2.1312055e-11, 2.3692647e-11, 1.5997325e-12, 4.1161543e-12, 9.3535218e-12, 7.0731917e-12, 2.2783516e-11, 2.787416e-12, 1.0895343e-12, 1.0061575e-11, 5.620961e-12, 5.1491111e-12, 9.7073259e-12, 2.690156e-12, 7.136105e-12, 3.9105189e-12, 2.305262e-11, 9.1106498e-12, 1.7891949e-11, 1.515811e-11, 2.2325894e-11, 1.4907234e-11, 3.9668407e-11, 2.296881e-11, 2.0173391e-11, 2.3783237e-11, 1.961962e-11, 3.8646121e-12, 1.466025e-11, 1.2476068e-11, 4.1588375e-12, 1.4916349e-11, 7.0600755e-12, 1.0899789e-12, 1.9369746e-12, 8.2886638e-12, 1.4640909e-11, 6.0101121e-12, 1.5824368e-11, 6.2542069e-12, 3.9383074e-12, 4.4448375e-12, 1.3129099e-11, 5.8919551e-12, 2.6262423e-12, 9.3675273e-12, 7.495578e-12, 9.0743023e-12, 1.9489792e-12, 4.1585041e-12, 1.1289385e-11, 3.254264e-12, 2.727615e-11, 2.6855208e-11, 3.0241524e-11, 1.5608951e-11, 6.0245621e-13, 1.2463396e-11, 2.1251699e-11, 4.9694857e-12, 1.8488292e-11, 1.7308167e-11, 2.8451051e-12, 3.8551974e-11, 7.7724633e-12, 2.0788852e-11, 1.4494296e-11, 1.0015112e-11, 1.7135544e-12, 2.2126038e-11, 1.0695043e-11, 3.7801571e-11, 1.9514913e-11, 1.7230915e-11, 3.0993482e-11, 1.6909679e-11, 3.4409142e-11, 4.2537633e-12, 2.2227744e-11, 3.6879213e-11, 2.2517635e-11, 2.2170278e-11, 7.1939054e-13, 4.0701364e-12, 2.1823143e-11, 8.1009242e-12, 2.3839704e-11, 5.1708973e-12, 1.1727444e-11, 6.3424634e-12, 1.2382143e-11, 3.5569378e-14, 7.6585302e-12, 2.4730716e-12, 7.9594248e-12, 9.8192583e-12, 1.0134825e-11, 9.5584903e-12, 8.8383217e-12, 2.6082353e-12, 1.8433826e-11, 3.5326054e-11, 4.4339666e-11, 1.2091719e-10, 1.7084625e-10, 2.5967619e-10, 3.634545e-10, 5.5290375e-10, 7.9605286e-10, 1.1043283e-09, 1.5812387e-09, 2.2285323e-09, 3.1469275e-09, 4.4479603e-09, 6.2269566e-09, 8.6930763e-09, 1.2104844e-08, 1.6837257e-08, 2.3295801e-08, 3.2212568e-08, 4.4334733e-08, 6.0893725e-08, 8.337456e-08, 1.1391194e-07, 1.5513682e-07, 2.1066381e-07, 2.8526479e-07, 3.8513473e-07, 5.184716e-07, 6.9585825e-07, 9.3118369e-07, 1.2422554e-06, 1.6522398e-06, 2.1907008e-06, 2.8955934e-06, 3.8152406e-06, 5.0109495e-06, 6.5602045e-06, 8.560473e-06, 1.1133904e-05, 1.4432841e-05, 1.864643e-05, 2.4008378e-05, 3.0806173e-05, 3.939168e-05, 5.0193482e-05, 6.373087e-05, 8.0629924e-05, 0.00010164123, 0.00012766014, 0.00015974814, 0.00019915717, 0.00024735442, 0.00030604959, 0.00037722223, 0.00046314986, 0.0005664359, 0.00069003607, 0.00083728324, 0.0010119086, 0.0012180594, 0.0014603103, 0.0017436691, 0.0020735744, 0.0024558851, 0.0028968594, 0.0034031258, 0.003981642, 0.004639646, 0.0053845953, 0.0062241002, 0.0071658477, 0.0082175215, 0.0093867167, 0.010680855, 0.012107097, 0.013672263, 0.015382752, 0.017244475, 0.019262788, 0.021442444, 0.023787554, 0.026301551, 0.028987178, 0.031846482, 0.034880815, 0.038090856, 0.041476629, 0.045037541, 0.048772415, 0.052679542, 0.056756722, 0.061001318, 0.065410308, 0.069980336, 0.074707762, 0.079588712, 0.084619126, 0.089794796, 0.095111412, 0.1005646, 0.10614993, 0.11186299, 0.11769939, 0.12365474, 0.12972476, 0.13590521, 0.14219195, 0.14858094, 0.15506823, 0.16164999, 0.16832252, 0.1750822, 0.18192558, 0.18884927, 0.19585005, 0.20292479, 0.21007048, 0.21728423, 0.22456326, 0.23190489, 0.23930656, 0.2467658, 0.25428023, 0.2618476, 0.26946571, 0.27713249, 0.28484593, 0.2926041, 0.30040517, 0.30824737, 0.31612901, 0.32404845, 0.33200415, 0.33999461, 0.34801838, 0.3560741, 0.36416044, 0.37227612, 0.38041992, 0.38859065, 0.39678719, 0.40500842, 0.4132533, 0.42152079, 0.42980991, 0.4381197, 0.44644922, 0.45479757, 0.46316387, 0.47154727, 0.47994692, 0.48836204, 0.49679172, 0.50523546, 0.5136919, 0.52216136, 0.53064128, 0.53913374, 0.54763397, 0.55614653, 0.56466445, 0.57319362, 0.58172722, 0.59026928, 0.59881622, 0.60736834, 0.61592511, 0.62448513, 0.63304813, 0.64161313, 0.65017946, 0.65874591, 0.6673123, 0.67587697, 0.68443953, 0.69299866, 0.70155352, 0.71010264, 0.71864521, 0.72717945, 0.73570421, 0.74421761, 0.75271796, 0.76120312, 0.76967072, 0.77811816, 0.78654216, 0.79493922, 0.8033049, 0.81163417, 0.81992079, 0.82815731, 0.83633452, 0.84444109, 0.85246275, 0.86038162, 0.86817472, 0.8758128, 0.88325778, 0.89046056, 0.89735742, 0.90386671, 0.90988573, 0.91528921, 0.91993422, 0.92366278, 0.92634106, 0.92784161, 0.92829757, 0.9282984, 0.9282713, 0.92826961, 0.92826595, 0.92826551, 0.92826812, 0.92827398, 0.92827656, 0.92827988, 0.92828388, 0.92829462, 0.92829526, 0.928294, 0.92829365, 0.92829214, 0.92828957, 0.92828995, 0.92828473, 0.92825203, 0.92821711, 0.92810413, 0.92797596, 0.92781776, 0.92765406, 0.92748905, 0.92733948, 0.92722197, 0.92714752, 0.92712163, 0.92711871, 0.92711722, 0.92711593, 0.92711253, 0.92710873, 0.92709741, 0.92708225, 0.92705974, 0.92703606, 0.92701366, 0.9269948, 0.92697989, 0.92696832, 0.92695887, 0.92695033, 0.92694183, 0.92693296, 0.92692374, 0.92691443, 0.92690531, 0.92689663, 0.92688847, 0.92688082, 0.92687357, 0.92686657, 0.92685967, 0.92685275, 0.92684576, 0.92683874, 0.92683178, 0.92682498, 0.92681835, 0.92681197, 0.92680587, 0.92680037, 0.92679479, 0.9267895, 0.9267835, 0.92677779, 0.92677267, 0.92676776, 0.92676293, 0.92675801, 0.92675287, 0.92674735, 0.92674134, 0.92673479, 0.92672762, 0.92671977, 0.92671123, 0.92670216, 0.92669224, 0.92668065, 0.92666776, 0.92665596, 0.9266461, 0.92663748, 0.92662607, 0.9266169, 0.92660872, 0.9266022, 0.92659765, 0.9265949, 0.92659375, 0.92659388, 0.92659495, 0.92659702, 0.92659938, 0.926602, 0.92660442, 0.92660629, 0.92660738, 0.92660746, 0.92660629, 0.92660383, 0.9266003, 0.92659594, 0.92659129, 0.92658667, 0.92658204, 0.92657723, 0.92657201, 0.92656638, 0.92656039, 0.92655414, 0.92654714, 0.92653966, 0.92653448, 0.92652956, 0.92652316, 0.92651643, 0.92650962, 0.9265021, 0.92649434, 0.9264865, 0.92647784, 0.9264687, 0.92645885, 0.9264501, 0.9264418, 0.92643157, 0.92642051, 0.92640881, 0.92639628, 0.92638275, 0.92636804, 0.92635188, 0.92633396, 0.92631386, 0.92629103, 0.9262648, 0.92623425, 0.92619825, 0.92615529, 0.92610345, 0.92604026, 0.9259625, 0.92586606, 0.92574562, 0.92559432, 0.92540335, 0.92516138, 0.92485383, 0.92446195, 0.92396167, 0.92332208, 0.92250349, 0.92145494, 0.92011106, 0.91838798, 0.91617815, 0.91334364, 0.9097076, 0.90504345, 0.8990609, 0.89138843, 0.88155109, 0.86894299, 0.85279399, 0.83213126, 0.80573957, 0.77213127, 0.72955327, 0.67609096, 0.60999109, 0.53041726, 0.43882191, 0.34056529, 0.24517568, 0.1632928, 0.1014608, 0.059707787, 0.033806, 0.018665709, 0.010154046, 0.005479122, 0.0029441638, 0.0015787208, 0.00084568651, 0.00045280042, 0.00024238724, 0.00012973898, 6.9440429e-05, 3.7165985e-05, 1.9891759e-05, 1.064624e-05, 5.6978887e-06, 3.049471e-06, 1.6320517e-06, 8.7343127e-07, 4.6743332e-07, 2.5014952e-07, 1.3384814e-07, 7.1615183e-08, 3.8302331e-08, 2.0481096e-08, 1.0948229e-08, 5.8510068e-09, 3.1322059e-09, 1.6631885e-09, 8.57237e-10, 4.4180893e-10, 2.3606094e-10, 1.0653837e-10, 4.8445804e-11, 3.8261163e-11, 4.5305767e-12, 3.0781683e-11, 1.9434374e-11, 1.4308533e-11, 1.6763067e-11, 1.0900001e-11, 7.5461885e-12, 2.7021852e-11, 5.7774899e-12, 7.0599212e-12, 6.0658537e-12, 1.4065233e-11, 2.1357799e-11, 2.7991834e-11, 3.1688949e-13, 5.4280789e-12, 1.650667e-11, 4.0891069e-11, 5.6260599e-11, 3.8895053e-11, 2.5336844e-11, 3.9860262e-11, 1.6378804e-11, 1.7282189e-11, 1.3859227e-11, 1.4629087e-13, 8.4004028e-12, 2.5132947e-11, 2.0514684e-11, 5.5260427e-11, 5.613007e-11, 8.2709276e-11, 4.497345e-11, 5.2929541e-11, 5.7110263e-11, 6.9544209e-11, 7.4599235e-11, 3.1559311e-11, 6.120341e-11, 2.6694862e-11, 2.024641e-11, 1.515409e-11, 1.5751907e-11, 1.5740807e-11, 4.6726499e-12, 4.2641121e-11, 3.1802278e-11, 5.9698102e-11, 2.4635248e-12, 1.1014436e-11, 5.2965502e-12, 1.8254279e-11, 1.4623092e-11, 3.7850483e-11, 1.9546146e-12, 4.8512512e-11, 1.8027185e-11, 4.4816947e-11, 1.7458116e-11, 6.9470286e-11, 4.9698711e-11, 6.6345123e-11, 3.3800291e-11, 7.1974213e-11, 3.7158654e-11, 8.4838374e-11, 1.3432009e-11, 8.3507327e-11, 3.8679835e-11, 6.5401114e-11, 1.2362687e-11, 7.8441534e-11, 2.1142137e-11, 3.1710818e-11, 5.3928159e-11, 5.3182054e-11, 4.5290117e-11, 2.5674045e-11, 5.923259e-11, 4.5728657e-11, 5.7957485e-11, 2.930157e-11, 6.1021046e-11, 4.9183585e-11, 8.4027003e-11, 2.2707049e-11, 5.8156498e-11, 4.7588149e-11, 5.6304331e-11, 2.8830176e-11, 5.8142069e-11, 2.744907e-11, 2.3922773e-11, 5.1634678e-12, 3.7483424e-11, 2.7852314e-11, 1.821976e-12, 1.8758099e-14, 7.2568256e-12, 5.5144882e-11, 2.234554e-11, 3.6724e-11, 2.7349841e-11, 3.4800685e-11, 5.3074278e-12, 1.20751e-11, 1.5684422e-11, 3.8380594e-11, 2.5202207e-11, 5.6174357e-11, 1.8072359e-11, 2.6781216e-11, 1.4482462e-11, 8.3793138e-12, 1.3220897e-11, 1.6602569e-12, 3.0230928e-11, 3.3592287e-11, 5.5116578e-11, 6.3377683e-11, 7.4435962e-11, 5.0469568e-11, 4.3236495e-11, 3.3662436e-11, 1.3699395e-11, 5.1504926e-11, 4.373253e-11, 3.3496388e-11, 2.4427687e-11, 3.8436202e-11, 3.5448894e-11, 3.257369e-11, 2.7977294e-11, 2.8831508e-11, 1.2698557e-11, 2.5001751e-11, 1.3384836e-11, 1.971075e-11, 1.2994357e-11, 1.3088148e-11, 1.6582923e-11, 8.1139258e-12, 3.5938158e-11, 1.4750514e-11, 9.3928053e-12, 1.7985562e-12, 1.590963e-11, 4.7555628e-12, 3.5563773e-12, 1.7015469e-12, 8.9185254e-12, 1.5699961e-11, 5.2750174e-12, 1.1218555e-11, 1.7849038e-12, 1.03296e-11, 4.5309097e-12, 2.6763013e-11, 4.5335736e-12, 1.0454357e-11, 3.0471342e-11, 3.211051e-11, 6.2507818e-11, 2.9848218e-11, 6.2961897e-11, 7.356532e-11, 6.8332703e-11, 1.0839231e-10, 7.1992638e-11, 8.1141477e-11, 8.1786356e-11, 7.4219744e-11, 6.9918038e-11, 5.0034581e-11, 3.6349171e-11, 3.1050956e-11, 4.2421795e-11, 2.0902277e-11, 5.2895244e-11, 1.9525611e-11, 3.3844467e-12, 4.1533062e-11, 1.4276123e-12, 1.8104215e-11, 4.7198225e-12, 3.7571221e-11, 1.4317191e-11, 2.9038957e-11, 7.6348731e-12, 4.6844152e-12, 1.2681686e-11, 3.2787799e-12, 1.2783024e-11, 1.5131891e-12, 2.1837961e-11, 1.92186e-11, 2.6969464e-12, 3.3476409e-11, 1.9815418e-11, 4.5208647e-11, 3.9951056e-11, 5.1660762e-11, 2.2907727e-11, 9.1554989e-12, 1.1622131e-11, 7.3245325e-13, 1.5328351e-12, 1.4989152e-11, 1.7662567e-12, 4.8820966e-12, 4.0439765e-12, 5.3799072e-13, 8.3456824e-12, 1.4397107e-12, 1.3843466e-11, 1.4267576e-11, 2.6067188e-11, 7.6877066e-12, 1.781463e-12, 1.741505e-13, 7.2234163e-12, 5.1667977e-12, 9.0937859e-12, 1.0709645e-11, 1.1865432e-11, 3.2584679e-12, 2.2026874e-11, 3.0745489e-14, 2.639551e-11, 1.0207727e-11, 1.4503662e-12, 1.5962685e-11, 2.4756564e-11, 7.4725991e-12, 1.5719829e-11, 5.8238855e-13, 9.3606168e-12, 1.618523e-12, 3.9659917e-11, 1.3356755e-11, 3.2485339e-11, 4.5040491e-12, 9.7542039e-13, 1.4630528e-11, 2.525604e-11, 2.6123684e-11, 5.2356587e-11, 4.3091204e-11, 5.4287227e-11, 1.4033045e-11, 4.9993291e-11, 2.206439e-11, 5.5926728e-11, 3.1548655e-11, 4.8612296e-11, 4.2891746e-11, 3.7626385e-11, 6.0400808e-11, 4.8195178e-11, 4.3433289e-11, 4.8251453e-11, 4.4334343e-11, 3.9629061e-11, 5.6315542e-11, 5.0820089e-11, 2.6441018e-11, 7.3309811e-11, 2.3628415e-11, 2.9492814e-11, 2.7083565e-11, 4.0127648e-11, 2.8342355e-11, 5.2944525e-11, 4.2551659e-11, 3.3472302e-11, 3.773072e-11, 4.7997164e-11, 2.9040733e-11, 5.0418622e-11, 3.3453877e-11, 1.0104946e-12, 2.723363e-12, 4.1511973e-12, 1.8644792e-20];\nlet data5 = [8.8755469e-22, 1.8272653e-11, 1.0733613e-11, 2.7953635e-11, 4.0261304e-11, 4.0519627e-11, 2.6162828e-11, 1.8507411e-11, 3.7509347e-11, 1.2686038e-12, 4.4012317e-11, 1.0528311e-11, 3.9979306e-11, 7.1194322e-13, 3.1690309e-11, 1.1239254e-11, 2.5174778e-11, 9.4864624e-12, 3.0043224e-11, 7.6723133e-12, 4.0573981e-11, 8.6146793e-12, 1.1601506e-11, 9.6370764e-12, 2.5131094e-11, 1.7846932e-12, 8.4477253e-13, 1.0806197e-11, 3.1424205e-11, 1.6773181e-12, 4.5035937e-11, 1.64286e-13, 2.3256255e-11, 4.8283198e-12, 2.2983149e-11, 1.3398093e-11, 8.522977e-12, 1.1698655e-11, 8.3994846e-12, 1.9472119e-11, 9.1014239e-12, 1.4485737e-11, 2.5002155e-11, 2.4439826e-11, 1.9087858e-11, 1.7320616e-11, 1.3126209e-11, 1.3104534e-11, 1.6955919e-11, 1.3026837e-11, 4.9831132e-11, 2.7873382e-11, 2.1826589e-11, 1.7490015e-11, 1.2527421e-11, 1.3321285e-11, 8.621682e-12, 1.0819202e-11, 6.0263407e-12, 2.0526639e-11, 1.3794247e-11, 6.3775882e-12, 8.5345371e-12, 1.1445557e-12, 1.5747005e-11, 7.6131792e-12, 1.3336847e-11, 3.2547086e-12, 1.1789246e-11, 2.1615173e-11, 1.3106757e-11, 2.0772179e-11, 5.7986967e-12, 2.3010048e-11, 4.2337555e-12, 3.3382188e-11, 2.4994819e-11, 2.4757838e-11, 9.6001732e-12, 2.5441437e-11, 1.2652692e-11, 7.9859907e-12, 1.3192346e-11, 1.3035396e-11, 1.2489296e-12, 1.3751119e-11, 8.4677333e-13, 2.0941467e-13, 9.1730073e-12, 1.1213022e-11, 3.2567093e-12, 1.4686371e-11, 9.470345e-13, 8.1800661e-12, 9.6435234e-12, 8.1576129e-13, 8.6654768e-12, 7.5295912e-13, 2.0637238e-11, 8.718942e-12, 1.378202e-11, 1.1651748e-11, 7.9914372e-12, 2.2589885e-12, 4.1193777e-13, 3.5602716e-13, 2.0938799e-11, 2.5269481e-11, 1.4724497e-11, 2.2813083e-11, 2.8044115e-11, 3.1476003e-11, 5.1240791e-11, 3.116077e-11, 4.8701916e-11, 1.4031005e-12, 4.8881208e-11, 1.3291496e-11, 3.5871044e-11, 1.2820202e-11, 2.3258256e-11, 2.273772e-12, 2.8150934e-11, 1.1085417e-12, 1.6619122e-11, 4.5584372e-12, 4.3841473e-12, 2.1139322e-12, 3.0644124e-12, 1.1742783e-11, 4.1777338e-12, 1.7036172e-11, 5.4652338e-12, 3.793529e-11, 1.9054957e-11, 2.8574321e-11, 1.9084857e-11, 8.7654045e-12, 9.5515988e-12, 3.4541194e-12, 1.4369359e-11, 2.913465e-12, 1.5769125e-11, 2.4605112e-12, 1.4840209e-12, 2.4542532e-11, 7.2936106e-12, 2.9159214e-11, 3.3566371e-12, 1.9202681e-11, 1.3955643e-11, 1.1239477e-11, 2.3841371e-11, 1.4453503e-11, 1.159417e-11, 6.5890036e-12, 2.2701706e-11, 3.6958577e-11, 3.4684249e-11, 2.9639512e-11, 2.7414648e-11, 4.862233e-11, 2.9069958e-11, 3.5153987e-11, 3.4429039e-11, 2.6555981e-11, 4.0850644e-11, 3.0675804e-11, 5.1219449e-11, 4.77441e-12, 2.655398e-11, 3.1386969e-11, 3.4213511e-11, 3.624141e-11, 1.6622679e-11, 2.5780791e-11, 2.4026665e-11, 3.4672912e-11, 3.4961802e-11, 4.0297207e-11, 1.2481292e-11, 2.0136821e-11, 1.155471e-11, 6.5982295e-12, 1.4902899e-11, 5.9878813e-12, 8.4771815e-12, 3.4797627e-11, 1.4078135e-11, 1.2861551e-11, 1.4217078e-11, 2.1404981e-12, 1.2843099e-11, 6.4858527e-13, 1.2323787e-11, 1.2841877e-11, 3.1050505e-11, 4.7659733e-11, 1.9660414e-11, 5.4314429e-11, 2.442382e-11, 5.7484994e-11, 1.7082524e-11, 2.6238524e-11, 2.5719323e-11, 3.2529301e-12, 1.2547429e-11, 2.1220464e-12, 1.3222358e-11, 5.7659062e-12, 2.8632788e-11, 6.9821563e-12, 8.9501429e-12, 3.6701033e-11, 9.392537e-12, 2.6822418e-11, 2.0672807e-11, 3.2724488e-11, 2.9320499e-11, 1.7357964e-11, 2.0273208e-11, 5.9623159e-13, 3.8840641e-12, 1.1987434e-11, 1.1992325e-11, 1.167987e-11, 1.5016833e-11, 6.9690401e-12, 1.071016e-11, 5.2178044e-12, 1.2835207e-11, 3.3371851e-12, 1.4056015e-11, 1.9366189e-11, 1.4011331e-11, 2.3000156e-11, 5.0676683e-11, 3.700215e-12, 3.983914e-11, 2.8753501e-11, 4.2976137e-11, 3.1558369e-11, 4.0128364e-11, 2.7488788e-11, 4.5937731e-11, 3.1377521e-11, 3.7956298e-11, 2.371899e-11, 3.973121e-11, 1.0394926e-11, 2.6689255e-11, 1.6875999e-11, 2.4361129e-11, 5.4975797e-12, 3.1841145e-11, 1.5992656e-11, 1.7503243e-11, 1.3029505e-11, 1.2633018e-11, 1.9364521e-11, 9.046736e-12, 4.2479833e-12, 3.8152596e-12, 3.0043891e-12, 1.8084357e-11, 1.1009721e-11, 2.5575378e-11, 2.2657022e-11, 2.4589551e-11, 2.361206e-11, 2.7337952e-11, 2.7915287e-11, 7.6091777e-12, 8.3942603e-12, 2.236024e-11, 1.2721719e-11, 1.8846431e-11, 2.3197232e-11, 1.0804974e-11, 1.9368745e-11, 4.2606548e-12, 7.4951334e-13, 1.3374862e-11, 4.3480221e-12, 1.0584111e-11, 1.3272933e-12, 1.8003215e-11, 1.7960198e-11, 2.2397699e-11, 3.3285484e-11, 3.7689861e-11, 5.3303481e-11, 9.9480416e-11, 7.7390503e-11, 1.7477177e-10, 2.272775e-10, 3.0180055e-10, 4.3190998e-10, 6.1628025e-10, 8.5127097e-10, 1.2009967e-09, 1.6950411e-09, 2.3772034e-09, 3.3206575e-09, 4.6423437e-09, 6.4769579e-09, 9.0289383e-09, 1.2518788e-08, 1.7366293e-08, 2.3993656e-08, 3.3123488e-08, 4.5587198e-08, 6.2621576e-08, 8.5697329e-08, 1.1700797e-07, 1.5926845e-07, 2.1624124e-07, 2.9268777e-07, 3.9509373e-07, 5.31683e-07, 7.1341492e-07, 9.5435111e-07, 1.2728411e-06, 1.6923936e-06, 2.2433017e-06, 2.9642088e-06, 3.9044963e-06, 5.1265713e-06, 6.7095317e-06, 8.7526142e-06, 1.1380275e-05, 1.4747547e-05, 1.9046987e-05, 2.4516235e-05, 3.1447689e-05, 4.0198829e-05, 5.120511e-05, 6.499374e-05, 8.2200111e-05, 0.0001035856, 0.0001300579, 0.0001626927, 0.00020275786, 0.0002517386, 0.00031136464, 0.00038363743, 0.00047085867, 0.0005756576, 0.00070101771, 0.00085030094, 0.0010272691, 0.0012361002, 0.0014814008, 0.0017682101, 0.0021019974, 0.0024886507, 0.0029344562, 0.0034460673, 0.0040304647, 0.0046949055, 0.0054468639, 0.0062939633, 0.0072439014, 0.0083043699, 0.0094829708, 0.010787131, 0.012224019, 0.013800462, 0.015522872, 0.017397174, 0.019428746, 0.02162237, 0.023982191, 0.026511687, 0.029213656, 0.032090202, 0.03514275, 0.038372053, 0.041778217, 0.045360735, 0.04911852, 0.053049949, 0.057152909, 0.061424846, 0.06586281, 0.070463511, 0.075223362, 0.080138533, 0.085204989, 0.090418541, 0.09577488, 0.10126961, 0.1068983, 0.11265649, 0.11853973, 0.12454359, 0.13066372, 0.13689581, 0.14323565, 0.14967913, 0.15622222, 0.16286103, 0.16959178, 0.17641082, 0.1833146, 0.19029974, 0.19736295, 0.20450109, 0.21171115, 0.21899023, 0.22633556, 0.23374448, 0.24121448, 0.24874313, 0.25632813, 0.26396728, 0.27165847, 0.27939973, 0.28718915, 0.29502494, 0.30290538, 0.31082886, 0.31879385, 0.32679891, 0.33484267, 0.34292387, 0.35104133, 0.35919394, 0.36738069, 0.37560068, 0.3838531, 0.39213724, 0.40045251, 0.40879849, 0.41717482, 0.42558146, 0.43401829, 0.442486, 0.45098432, 0.45951561, 0.46807855, 0.47667818, 0.48531154, 0.49398337, 0.50269278, 0.51142777, 0.52019435, 0.52894898, 0.53767062, 0.54619037, 0.55499055, 0.56387567, 0.57088999, 0.58186201, 0.5861534, 0.60021703, 0.60134738, 0.61785314, 0.61911379, 0.63651665, 0.63678505, 0.65784138, 0.6578795, 0.68603009, 0.68845669, 0.71563473, 0.7134741, 0.71776554, 0.72108445, 0.72489199, 0.72923484, 0.73324986, 0.73173841, 0.73678235, 0.73840361, 0.74979991, 0.75581631, 0.77310827, 0.7704936, 0.78042619, 0.78220028, 0.7940975, 0.79340896, 0.80760385, 0.81136595, 0.80745767, 0.80743041, 0.80738714, 0.8133333, 0.81768179, 0.83020585, 0.83392377, 0.84706516, 0.84821172, 0.84909587, 0.85421756, 0.85347514, 0.86521386, 0.86563354, 0.88757134, 0.88371381, 0.89109113, 0.89310991, 0.89495336, 0.89530943, 0.90088965, 0.9056695, 0.90624354, 0.90462222, 0.90913183, 0.90974483, 0.91466033, 0.91320631, 0.91956892, 0.91835912, 0.92343729, 0.92382604, 0.92693279, 0.92690753, 0.92814953, 0.92854157, 0.92852411, 0.92780793, 0.92735543, 0.92691682, 0.92688725, 0.9267973, 0.92683193, 0.92684918, 0.92670024, 0.92654014, 0.92619538, 0.92608007, 0.92586642, 0.92592779, 0.92550746, 0.92549336, 0.92519671, 0.92510795, 0.92486953, 0.92480406, 0.92477448, 0.92478989, 0.92478722, 0.92486421, 0.92485254, 0.92500294, 0.92502212, 0.92520048, 0.92511055, 0.92517063, 0.92517352, 0.92527893, 0.92528055, 0.92535972, 0.92536251, 0.92539352, 0.92544885, 0.92554893, 0.92559441, 0.92564226, 0.92546138, 0.92548614, 0.92552699, 0.92546651, 0.92542342, 0.92534365, 0.92535393, 0.92537345, 0.92523031, 0.9252568, 0.92505143, 0.9249375, 0.92487305, 0.92485538, 0.92463872, 0.92422622, 0.92384466, 0.92351762, 0.92330762, 0.92339761, 0.92297597, 0.92342119, 0.92266706, 0.92357812, 0.92389217, 0.92388786, 0.92420779, 0.92468576, 0.92435758, 0.92440925, 0.92437358, 0.92438647, 0.92439618, 0.9243746, 0.92442331, 0.92447101, 0.92455341, 0.92467416, 0.92476762, 0.92486624, 0.92492277, 0.92502235, 0.92511518, 0.92534355, 0.92523595, 0.92525984, 0.92497355, 0.92495751, 0.92494348, 0.92493844, 0.92494037, 0.9249994, 0.92507841, 0.92526106, 0.92523889, 0.92552905, 0.92556646, 0.92580527, 0.92587979, 0.92601391, 0.9260997, 0.92623408, 0.92650175, 0.92670573, 0.92672, 0.9264975, 0.92642097, 0.92643383, 0.92653644, 0.92657195, 0.92656547, 0.92653991, 0.92654973, 0.92677317, 0.92675649, 0.92710071, 0.92713023, 0.92744911, 0.92763419, 0.92775855, 0.92771742, 0.92759541, 0.92761257, 0.92770025, 0.92775435, 0.92774143, 0.92765611, 0.92784568, 0.92794316, 0.92835903, 0.92857216, 0.92895711, 0.92898694, 0.92887355, 0.92885884, 0.92890899, 0.92882222, 0.92849467, 0.92815199, 0.92705378, 0.92504573, 0.92195214, 0.91754425, 0.91146947, 0.90331449, 0.89244729, 0.87812935, 0.85940026, 0.83510999, 0.80387083, 0.7640899, 0.7140365, 0.65203482, 0.57693332, 0.48907501, 0.39176494, 0.29237997, 0.20176242, 0.12922921, 0.077781305, 0.04470325, 0.024914804, 0.013636957, 0.0073884694, 0.0039820163, 0.0021403102, 0.0011488503, 0.0006162604, 0.00033046778, 0.0001771866, 9.4995694e-05, 5.0928843e-05, 2.7303412e-05, 1.4637492e-05, 7.8471456e-06, 4.2068227e-06, 2.2552263e-06, 1.2090172e-06, 6.4813081e-07, 3.4746604e-07, 1.8628374e-07, 9.9837153e-08, 5.3508618e-08, 2.8684448e-08, 1.5368512e-08, 8.2270942e-09, 4.4169899e-09, 2.3592016e-09, 1.2645366e-09, 6.5020614e-10, 3.5471392e-10, 1.6778529e-10, 1.0050526e-10, 5.1615698e-11, 1.0800772e-11, 1.7813076e-11, 4.995311e-11, 3.1669195e-11, 3.3961344e-11, 1.1708041e-11, 2.5872614e-11, 1.0639829e-11, 1.9704757e-11, 4.8069532e-12, 1.7319594e-11, 2.2914165e-11, 8.8837842e-12, 1.4515871e-12, 4.1505313e-12, 1.3497718e-11, 2.0270718e-11, 3.6340735e-12, 4.1322172e-12, 2.1671026e-11, 5.2655829e-12, 2.0408351e-11, 1.8707248e-11, 2.5831435e-11, 8.2879649e-13, 1.7264541e-11, 2.4574207e-13, 1.8723787e-11, 5.4721549e-11, 5.3244099e-12, 4.0799387e-12, 3.1560754e-11, 1.171348e-11, 1.5634696e-11, 1.064105e-12, 1.6620661e-11, 1.1558643e-11, 1.7717288e-11, 1.1078591e-11, 1.8877403e-11, 2.0996179e-11, 1.401018e-11, 1.9477884e-11, 1.7053762e-11, 2.1874811e-12, 2.624145e-11, 6.7389027e-11, 4.4233116e-11, 2.6371202e-11, 1.7523158e-11, 1.1761985e-11, 1.7927844e-11, 5.71389e-12, 1.9180751e-11, 1.1333324e-11, 1.6342287e-11, 1.9778013e-11, 1.501457e-11, 2.0305681e-11, 2.9919033e-11, 4.83337e-12, 3.7838718e-11, 4.8999667e-12, 4.1883472e-11, 2.0392146e-11, 3.8322654e-11, 6.206606e-11, 4.4075393e-11, 3.2064669e-11, 5.9149122e-11, 5.2948188e-11, 6.3164129e-11, 8.962113e-11, 4.4416146e-11, 1.0008559e-10, 3.4554944e-11, 7.4140605e-11, 1.188985e-11, 6.6591309e-11, 3.9916093e-11, 5.8978968e-11, 4.1150352e-11, 1.2497435e-11, 9.8640881e-13, 1.3660214e-11, 1.4786143e-11, 1.1291035e-11, 2.8940616e-11, 2.9410234e-12, 3.2128269e-11, 2.2550769e-11, 2.3148697e-11, 4.3842193e-11, 2.3608103e-11, 6.6996661e-11, 2.563664e-11, 8.4134335e-11, 2.7177578e-11, 8.6780779e-11, 7.6754528e-11, 9.3666772e-11, 7.6846209e-11, 4.7693483e-11, 3.9477664e-11, 3.5640137e-11, 3.4006408e-11, 1.3857673e-12, 2.7787826e-11, 1.7218922e-11, 8.4016237e-12, 1.8166372e-11, 2.496257e-11, 7.3955687e-13, 2.7269148e-11, 2.6721834e-11, 1.790276e-11, 1.3086927e-11, 4.7405896e-11, 4.2377064e-11, 1.2679133e-11, 4.8221706e-11, 5.814562e-12, 1.7775671e-11, 2.2400926e-12, 5.3610382e-13, 3.6900148e-12, 5.3574531e-11, 1.0308511e-11, 3.1199244e-11, 1.5624707e-11, 1.2150577e-12, 1.1282599e-11, 1.3037423e-12, 3.3328342e-12, 3.5065297e-11, 2.928148e-12, 1.0302739e-11, 1.7476874e-11, 2.517457e-11, 5.6404116e-12, 6.4988436e-11, 3.1622356e-11, 7.7872687e-11, 4.7857644e-11, 7.8295132e-11, 4.5235286e-11, 4.5798916e-11, 2.2290264e-11, 3.8032182e-11, 3.4512877e-11, 5.2836861e-11, 4.524805e-11, 7.8457073e-11, 3.9417283e-11, 6.1127601e-11, 4.0157173e-11, 3.5567658e-11, 2.9153947e-11, 1.1805273e-11, 2.9678064e-11, 5.7686103e-12, 5.7457454e-12, 3.2302197e-11, 4.9529666e-11, 4.6999878e-11, 5.174534e-11, 1.7997327e-11, 2.8981795e-11, 5.713224e-12, 7.3452883e-12, 1.7813853e-11, 8.047995e-12, 2.8741158e-11, 1.1843011e-11, 3.2613315e-11, 3.2346595e-11, 1.4849854e-11, 3.6456059e-11, 3.2138592e-11, 2.9605806e-11, 4.3727425e-12, 3.0369671e-11, 2.1015048e-11, 3.601652e-11, 1.1914491e-11, 1.3487728e-11, 3.9754928e-12, 1.0703429e-11, 7.4307541e-12, 4.1479785e-12, 1.0173985e-11, 2.0516016e-11, 1.3770764e-11, 1.0646267e-11, 1.7800534e-11, 3.2188317e-11, 3.6530203e-11, 6.5765398e-12, 2.0016763e-12, 1.8334085e-12, 1.0266888e-11, 1.4851519e-11, 2.2044189e-11, 6.0457638e-12, 2.5460048e-11, 1.4669155e-11, 2.4177394e-11, 5.8807037e-11, 6.2834032e-12, 6.6183848e-12, 1.6271806e-13, 1.8075134e-11, 2.2461973e-12, 5.3903408e-12, 1.6028505e-11, 4.0313232e-13, 3.2548272e-11, 4.1948181e-12, 1.1798724e-12, 6.5309211e-12, 6.6507952e-12, 8.8736836e-12, 1.6863184e-11, 1.6735319e-11, 1.9874467e-11, 1.2464469e-11, 2.6440019e-12, 9.8318998e-12, 2.0435212e-12, 1.1405914e-11, 1.9396969e-11, 1.3411475e-12, 8.558903e-12, 1.631254e-11, 8.5403669e-12, 4.0904832e-12, 8.2904072e-12, 1.7191951e-12, 5.3472749e-12, 2.5418536e-11, 1.5305265e-11, 7.2793575e-12, 5.020973e-11, 1.3790522e-11, 2.0260951e-12, 7.3462872e-12, 1.5602508e-12, 1.2291651e-11, 1.3710272e-11, 5.3200812e-12, 7.043827e-12, 8.1839633e-12, 3.117982e-11, 1.4296324e-11, 3.3934817e-11, 9.2874715e-12, 1.71975e-11, 1.5451111e-11, 2.1490771e-12, 1.0344473e-11, 4.5709788e-12, 6.2577634e-12, 2.0089797e-11, 4.5736648e-11, 3.6199883e-11, 2.7324757e-11, 5.4422973e-11, 3.1747225e-11, 3.6302997e-11, 4.2841466e-11, 5.7356338e-11, 5.2325509e-11, 5.2084095e-11, 3.44798e-11, 9.686164e-12, 1.4551611e-11, 4.7665845e-11, 4.0686173e-12, 1.1008331e-11, 2.4060184e-11, 1.879005e-11, 2.6862908e-11, 3.4303985e-12, 7.5572879e-12, 1.8099951e-20];\nlet data4 = [2.9640062e-21, 9.3329583e-12, 2.7505128e-12, 1.2046123e-11, 9.4759025e-13, 1.3365413e-11, 2.8670914e-11, 2.0633236e-11, 2.3636847e-11, 3.4316662e-12, 2.0934353e-11, 2.3455777e-12, 5.9056272e-12, 1.0987934e-11, 1.5653969e-11, 2.2826977e-11, 1.0468955e-11, 6.6778159e-12, 7.2381446e-12, 8.0519052e-12, 1.0072245e-11, 4.5852253e-12, 9.4651207e-12, 1.260145e-11, 3.3677525e-12, 6.1690628e-12, 4.4931896e-12, 2.3751447e-12, 7.724e-12, 1.3185121e-12, 1.6603671e-11, 1.4090473e-11, 8.0091108e-12, 2.9737105e-12, 4.5938954e-12, 1.2772628e-11, 2.4963029e-12, 4.7423975e-12, 1.1312616e-11, 1.2850213e-11, 1.2648024e-11, 1.9927407e-11, 5.9455315e-12, 1.6689038e-11, 2.1524916e-11, 3.2399806e-11, 1.0232752e-11, 7.1952391e-12, 6.7022699e-12, 1.3764457e-11, 1.1613733e-11, 1.7275043e-11, 1.6410819e-12, 2.666369e-12, 3.8416032e-12, 1.6578661e-12, 1.1866276e-11, 6.4615097e-12, 8.1140404e-12, 3.4703479e-12, 1.5422657e-12, 3.8004761e-12, 1.1784577e-12, 1.2324898e-11, 1.3230583e-11, 3.6088461e-12, 1.758383e-11, 1.4494518e-13, 1.2159945e-11, 1.0882004e-12, 1.4816533e-11, 8.6553618e-12, 1.9557374e-11, 2.2128373e-11, 3.168564e-12, 1.1052737e-11, 7.2584859e-12, 1.0890897e-12, 1.6109479e-11, 4.9710419e-12, 1.3393535e-11, 1.7507244e-11, 7.0728583e-12, 3.611725e-11, 7.3771987e-12, 1.8627457e-11, 2.3087856e-12, 2.7133872e-12, 4.2321994e-12, 2.7794684e-11, 6.4452812e-12, 2.5169665e-11, 8.9348037e-12, 1.2712715e-12, 1.5921295e-11, 1.0449725e-11, 6.3035594e-13, 1.2070577e-11, 1.1566381e-11, 3.5177663e-11, 1.4124486e-11, 4.1937956e-11, 1.7787131e-11, 4.9642726e-11, 2.4534752e-11, 3.7980641e-11, 3.7185554e-12, 2.2332341e-11, 4.5134197e-12, 2.1476786e-11, 1.8698596e-11, 1.5798803e-11, 3.1917953e-12, 1.737775e-11, 1.1408987e-11, 7.2948333e-12, 1.8829758e-11, 4.0927008e-12, 3.0558536e-11, 4.9908286e-14, 2.5212015e-11, 1.9438661e-11, 2.7429542e-12, 1.734985e-11, 1.2607119e-12, 1.4012776e-11, 2.0970145e-11, 3.2229629e-11, 2.7516688e-11, 3.1972752e-11, 3.8435373e-11, 1.5694985e-11, 2.1617841e-11, 3.5497899e-11, 2.7793128e-11, 3.0138373e-11, 1.1688318e-11, 4.4370122e-11, 3.9459771e-12, 2.8765617e-11, 5.9882147e-12, 1.1967093e-11, 1.1350186e-11, 2.7869714e-12, 3.1948409e-11, 1.1738559e-11, 3.4116584e-12, 1.1020503e-11, 1.8829537e-13, 1.7159998e-11, 2.3805913e-12, 8.3825892e-12, 7.3541897e-12, 1.4197737e-11, 6.3963733e-12, 1.9021833e-11, 1.0141939e-11, 3.5838587e-11, 1.2702378e-11, 6.4226057e-12, 1.1199794e-11, 1.5978428e-12, 1.847851e-11, 9.7903582e-12, 2.389328e-11, 1.1467788e-12, 1.2559545e-11, 8.4380551e-12, 5.9497553e-12, 8.2975561e-12, 1.7023279e-12, 6.496301e-12, 2.0455723e-12, 3.3916618e-11, 1.1009943e-11, 2.0572546e-11, 7.4501159e-12, 1.6909234e-11, 1.3017278e-12, 2.511242e-11, 1.2519307e-11, 1.3066964e-11, 9.6181802e-12, 2.9619282e-12, 8.4008185e-12, 6.7134964e-12, 6.4966344e-12, 3.0185057e-12, 9.5896135e-12, 5.3267356e-12, 2.0195844e-11, 5.2957235e-12, 1.6285881e-11, 4.8516622e-12, 1.6781518e-11, 4.7132751e-12, 1.7246921e-11, 3.1046836e-11, 3.3466221e-11, 4.5161096e-11, 2.7890166e-11, 4.8981358e-11, 1.9105087e-11, 3.9502787e-11, 4.4925449e-11, 1.3337403e-11, 2.8367462e-11, 3.8099576e-11, 3.391584e-11, 2.2406369e-11, 4.5648174e-11, 3.0683362e-11, 1.1119319e-11, 2.2178503e-11, 3.9817688e-11, 4.3980638e-11, 4.2083457e-11, 3.1904503e-11, 3.5951408e-11, 2.0441495e-11, 3.4121142e-11, 2.3310165e-11, 4.710474e-11, 6.8178703e-12, 1.8060793e-11, 4.0326774e-12, 2.5641959e-11, 9.9446403e-12, 1.5113203e-11, 3.1063176e-12, 1.5865162e-11, 2.2517079e-11, 1.3830149e-11, 1.5724997e-12, 1.6482735e-11, 6.9053487e-12, 2.8235633e-11, 5.6019536e-12, 9.9887685e-12, 1.6630682e-11, 1.2960591e-13, 3.5512682e-12, 1.0279659e-11, 1.9133098e-11, 1.8250644e-11, 2.2588773e-12, 2.7064401e-11, 1.0553543e-11, 1.6625013e-11, 2.5463223e-12, 1.8596112e-11, 4.1845142e-12, 1.1992991e-11, 2.5180225e-11, 1.9251144e-11, 7.6910983e-12, 2.1652188e-11, 2.3425098e-11, 6.2203049e-12, 9.2353648e-12, 5.592172e-12, 1.6659804e-11, 1.4916794e-11, 8.5797769e-12, 2.5034946e-11, 2.176701e-11, 1.3789356e-11, 1.8613452e-11, 6.2498719e-12, 3.7386743e-12, 1.1784355e-11, 5.3595261e-12, 1.5875055e-12, 2.5069737e-11, 1.8245976e-12, 1.5287716e-11, 1.2674923e-12, 1.5658749e-11, 4.4738488e-12, 1.0064131e-11, 2.1842484e-11, 1.1868499e-11, 3.7473221e-11, 5.8434918e-12, 1.7942524e-11, 5.2399241e-12, 2.1522137e-11, 2.8356569e-12, 1.2945806e-11, 7.3661946e-13, 2.1775121e-13, 2.5093969e-11, 2.5642182e-11, 5.9632939e-11, 9.0133341e-11, 1.6135389e-10, 2.3653087e-10, 3.4442833e-10, 5.2040302e-10, 7.5668623e-10, 1.0945064e-09, 1.5515373e-09, 2.1963396e-09, 3.1317283e-09, 4.3789956e-09, 6.1486076e-09, 8.5833479e-09, 1.19644e-08, 1.6609804e-08, 2.3053427e-08, 3.1830126e-08, 4.3877079e-08, 6.0203165e-08, 8.2486321e-08, 1.1266521e-07, 1.5346586e-07, 2.0842465e-07, 2.8222683e-07, 3.8105991e-07, 5.1301255e-07, 6.8860458e-07, 9.2150284e-07, 1.2294442e-06, 1.6352882e-06, 2.1683996e-06, 2.8662775e-06, 3.7768487e-06, 4.960847e-06, 6.4950875e-06, 8.4761234e-06, 1.1025082e-05, 1.4292922e-05, 1.8467174e-05, 2.3779574e-05, 3.0515209e-05, 3.9023052e-05, 4.9728285e-05, 6.3146081e-05, 7.9897671e-05, 0.00010072802, 0.00012652577, 0.00015834491, 0.0001974285, 0.00024523382, 0.00030345928, 0.00037407188, 0.00045933524, 0.00056183756, 0.00068451808, 0.00083069205, 0.0010040722, 0.0012087865, 0.0014493903, 0.0017308722, 0.0020586523, 0.0024385723, 0.0028768758, 0.0033801792, 0.0039554328, 0.0046098717, 0.0053509572, 0.0061863106, 0.0071236385, 0.0081706536, 0.0093349915, 0.010624125, 0.012045281, 0.013605355, 0.01531084, 0.01716775, 0.019181563, 0.021357164, 0.023698808, 0.026210085, 0.028893907, 0.031752493, 0.03478738, 0.037999428, 0.041388851, 0.044955238, 0.048697596, 0.052614388, 0.056703578, 0.060962683, 0.065388817, 0.069978743, 0.074728923, 0.079635565, 0.084694668, 0.08990207, 0.095253481, 0.10074453, 0.10637077, 0.11212778, 0.11801109, 0.12401628, 0.13013899, 0.13637492, 0.14271983, 0.1491696, 0.15572022, 0.16236776, 0.16910843, 0.17593856, 0.18285462, 0.18985317, 0.19693094, 0.20408476, 0.2113116, 0.21860854, 0.2259728, 0.23340171, 0.24089272, 0.24844338, 0.25605136, 0.26371444, 0.27143049, 0.27919747, 0.28701346, 0.2948766, 0.30278512, 0.31073734, 0.31873165, 0.32676651, 0.33484045, 0.34295207, 0.35110001, 0.35928299, 0.36749977, 0.37574917, 0.38403004, 0.39234128, 0.40068184, 0.4090507, 0.41744686, 0.42586937, 0.43431733, 0.44278987, 0.4512863, 0.45980599, 0.46834908, 0.47691568, 0.48550833, 0.49412819, 0.50277771, 0.51145706, 0.52012893, 0.52870413, 0.53745872, 0.54569641, 0.55388735, 0.56171361, 0.5703083, 0.57884008, 0.58839631, 0.5996874, 0.61464584, 0.63299906, 0.65300355, 0.66843974, 0.67260683, 0.67187109, 0.67378822, 0.67461145, 0.68013213, 0.68891798, 0.69906228, 0.71024186, 0.72634787, 0.72348441, 0.72350901, 0.72400258, 0.72931793, 0.73820286, 0.73928349, 0.74211056, 0.74537831, 0.74721972, 0.75008908, 0.75974998, 0.77083627, 0.77855188, 0.78093807, 0.77979187, 0.78006009, 0.78150724, 0.78188001, 0.78078482, 0.78972435, 0.80253125, 0.81073706, 0.81642665, 0.82116291, 0.82579555, 0.83115008, 0.83771477, 0.84467652, 0.85217798, 0.85965702, 0.86636392, 0.87269061, 0.87912294, 0.8857938, 0.89319124, 0.90139898, 0.90847588, 0.91591374, 0.92256061, 0.92905685, 0.93537009, 0.94484613, 0.95172695, 0.96261748, 0.96689615, 0.97052233, 0.96835432, 0.96371894, 0.95353748, 0.94646765, 0.93869513, 0.93300715, 0.92707869, 0.92303702, 0.91664736, 0.91744421, 0.91719413, 0.91974339, 0.92136019, 0.92451412, 0.92669603, 0.92989174, 0.93016046, 0.93012549, 0.93004485, 0.92979559, 0.92964667, 0.92934676, 0.92917201, 0.92833142, 0.92825144, 0.92832679, 0.92894541, 0.928823, 0.9286215, 0.92814636, 0.92772128, 0.92714753, 0.92684216, 0.92646554, 0.92618261, 0.92590351, 0.92572693, 0.92561247, 0.925564, 0.92557124, 0.92559663, 0.92590674, 0.92589498, 0.9258723, 0.92548199, 0.92527586, 0.92514624, 0.92517072, 0.92519455, 0.92517294, 0.92511427, 0.92507073, 0.92508099, 0.9251498, 0.92523651, 0.92531842, 0.92532105, 0.92534056, 0.92546288, 0.92567932, 0.92587718, 0.92603413, 0.92630519, 0.92622569, 0.92618911, 0.9260881, 0.92611963, 0.92617353, 0.92629568, 0.92638431, 0.92644902, 0.92639186, 0.92632513, 0.92625433, 0.92626243, 0.92623303, 0.92622917, 0.92625492, 0.92623275, 0.92630611, 0.92630213, 0.92631903, 0.92629826, 0.92631528, 0.92630902, 0.92627638, 0.92626638, 0.92621553, 0.92630114, 0.92641228, 0.92647963, 0.92653698, 0.92665872, 0.92689599, 0.92705079, 0.92742487, 0.92732687, 0.9273452, 0.9272198, 0.92721382, 0.92703998, 0.92694653, 0.92701832, 0.92741031, 0.92757705, 0.92722499, 0.9266838, 0.92646418, 0.9263108, 0.92630487, 0.92665255, 0.92756567, 0.92795025, 0.92775351, 0.92732948, 0.92723394, 0.92680679, 0.92634006, 0.92634952, 0.92671698, 0.92693975, 0.92722617, 0.92694944, 0.9269312, 0.92720149, 0.92852329, 0.93030914, 0.93027955, 0.92985191, 0.92960996, 0.92935124, 0.92847124, 0.92810666, 0.92809806, 0.92914492, 0.93069296, 0.93146786, 0.93042349, 0.93049376, 0.93052707, 0.93109751, 0.93098899, 0.93069666, 0.93047184, 0.9297293, 0.92802123, 0.92532139, 0.92149254, 0.91629255, 0.90932378, 0.90007065, 0.88787749, 0.87192529, 0.85120664, 0.82450355, 0.79038292, 0.747226, 0.69333741, 0.6272038, 0.5481055, 0.45723604, 0.35909776, 0.26221379, 0.1771453, 0.11142655, 0.066168553, 0.037697689, 0.020907893, 0.011417705, 0.0061818558, 0.0033325675, 0.0017925853, 0.00096317242, 0.00051724591, 0.00027770297, 0.00014907787, 8.0024386e-05, 4.2955751e-05, 2.3057529e-05, 1.2376637e-05, 6.6433276e-06, 3.5659077e-06, 1.9140184e-06, 1.0273475e-06, 5.5140358e-07, 2.9595236e-07, 1.5884068e-07, 8.5240279e-08, 4.5735953e-08, 2.4536113e-08, 1.3110006e-08, 7.0446593e-09, 3.7344034e-09, 2.0400243e-09, 1.0665481e-09, 5.4378742e-10, 2.7004349e-10, 1.5812854e-10, 7.4338287e-11, 3.3561209e-11, 2.8333919e-11, 8.868467e-13, 3.0858713e-12, 3.5963354e-12, 3.4917785e-12, 1.017121e-11, 2.2028983e-11, 4.0346086e-11, 1.7580209e-11, 4.2501933e-11, 1.4422969e-11, 1.8196895e-11, 4.8419165e-12, 1.6136947e-11, 1.9557134e-11, 1.3521138e-11, 2.5140272e-11, 2.0023977e-11, 3.3199034e-11, 4.6221473e-11, 6.582134e-11, 1.3640679e-11, 1.8451073e-11, 2.6909526e-12, 2.8481986e-11, 3.7241345e-11, 2.7911807e-11, 3.1812378e-11, 2.4314584e-11, 3.0230262e-11, 8.3786478e-12, 3.2504762e-12, 2.3156355e-11, 2.5427859e-11, 1.8178248e-11, 2.6479089e-11, 2.9286697e-11, 6.2549886e-12, 2.2235655e-11, 9.7529828e-12, 8.7256168e-12, 2.3332615e-11, 7.4472923e-12, 3.7661016e-11, 3.9459128e-11, 4.3172452e-11, 4.6146551e-11, 7.0674356e-11, 3.8188906e-11, 2.234998e-11, 1.691735e-11, 2.136912e-11, 1.0642604e-11, 2.3709996e-11, 1.7593085e-11, 4.2050074e-11, 5.7920745e-11, 2.3162904e-11, 2.0006773e-11, 4.6649913e-12, 2.0054834e-11, 3.429455e-11, 4.7810915e-12, 1.6627987e-11, 3.419521e-12, 3.9087851e-12, 2.5789369e-11, 8.5253827e-12, 4.5741865e-11, 3.9988016e-12, 4.2880647e-11, 4.4876219e-12, 5.7759137e-11, 1.0324161e-11, 4.5343838e-11, 1.571317e-11, 4.2209574e-11, 3.6910248e-11, 4.0849557e-11, 1.7327808e-11, 6.036085e-11, 3.0158338e-12, 6.5229405e-11, 2.2726917e-11, 1.035959e-10, 1.3112123e-11, 7.8468617e-11, 2.6461552e-11, 9.2848187e-11, 4.8677117e-11, 7.3172067e-11, 3.0248465e-11, 2.8176973e-11, 3.4641409e-13, 4.5031611e-12, 1.198919e-11, 5.4409543e-12, 2.3406093e-11, 3.6406222e-12, 5.9825856e-11, 5.5350777e-11, 6.1321841e-11, 7.566667e-11, 4.7177247e-11, 1.7426815e-11, 3.9422611e-11, 3.2878814e-12, 1.7982232e-12, 2.9966761e-11, 1.5093043e-12, 3.8254837e-11, 6.3659832e-12, 5.8671402e-11, 3.0131144e-11, 3.1009222e-11, 2.9751986e-11, 2.6061527e-12, 1.7776004e-11, 1.8748538e-11, 2.6435912e-11, 8.2280281e-13, 3.9124035e-11, 2.5456274e-11, 6.8715634e-12, 3.539384e-11, 5.4937877e-12, 4.8476439e-11, 3.7622612e-11, 1.7812965e-11, 3.2490666e-11, 1.3793518e-11, 3.0020593e-11, 1.0668244e-11, 3.3360087e-11, 6.4262532e-12, 3.2945411e-11, 5.8499693e-12, 1.1105896e-11, 1.2388216e-11, 1.3703169e-11, 1.0369113e-12, 5.5859132e-12, 1.8173365e-11, 1.6084224e-12, 2.9652202e-11, 1.3880982e-12, 3.0761038e-12, 2.2155628e-12, 1.2362909e-11, 8.4855356e-12, 2.2690733e-11, 1.6411326e-11, 1.5741251e-11, 3.9831626e-11, 9.5729495e-12, 1.8957319e-11, 7.9878359e-12, 7.3632694e-12, 1.4530301e-12, 2.3316964e-11, 1.4322851e-11, 1.6770726e-11, 2.1865821e-11, 3.0555143e-11, 2.9852991e-11, 1.0491763e-11, 3.8597699e-11, 1.0835291e-12, 5.5185839e-11, 7.7102384e-12, 4.2228443e-11, 2.6358549e-11, 7.4350274e-11, 3.3509153e-11, 7.2135821e-11, 3.9783121e-11, 7.1883087e-11, 6.8346466e-11, 1.0074878e-10, 4.945419e-11, 7.1265513e-11, 4.4255093e-11, 4.7498021e-11, 2.0786621e-11, 2.3789135e-11, 1.531259e-11, 4.4703844e-11, 2.086687e-11, 1.5181173e-11, 3.7472991e-11, 5.671046e-12, 1.4036486e-11, 2.6176185e-11, 3.2143364e-11, 2.0150622e-11, 1.6476923e-11, 5.9871808e-11, 4.4838036e-11, 8.377327e-11, 4.2277835e-11, 6.7988065e-11, 2.0570736e-11, 5.2125163e-11, 7.5326471e-12, 4.0375055e-11, 5.1529011e-11, 5.4923447e-12, 5.0088968e-11, 8.3812007e-12, 5.7186738e-11, 4.427485e-11, 4.3078328e-11, 4.2777533e-11, 6.7281806e-11, 2.7674279e-11, 6.5181123e-11, 2.0746774e-11, 4.5545405e-11, 1.2051347e-11, 4.6774892e-11, 3.5612056e-11, 1.0890677e-11, 3.2721868e-11, 2.6763013e-12, 2.1213284e-11, 2.694682e-11, 4.6181182e-11, 3.9528389e-11, 5.5938493e-11, 7.7387863e-11, 4.8343023e-11, 4.6970464e-11, 3.0434492e-11, 2.6478534e-11, 3.7708521e-11, 7.0224384e-11, 5.3415919e-11, 7.0918877e-11, 3.5120794e-11, 4.0638334e-11, 3.359029e-11, 1.6493795e-11, 1.6370813e-11, 1.2935419e-11, 8.2199256e-12, 5.8821577e-12, 2.9659417e-11, 1.4651276e-14, 3.7516168e-12, 2.661539e-12, 1.2588561e-11, 4.1916659e-11, 6.7540424e-11, 2.2157182e-11, 6.5171355e-11, 2.284557e-11, 5.3456321e-11, 6.3659832e-12, 2.8300288e-11, 3.3745682e-12, 3.498305e-11, 6.4931823e-14, 5.2362803e-12, 5.407445e-11, 7.3582746e-12, 3.4267578e-11, 1.3745568e-12, 4.2672865e-11, 1.9696543e-11, 4.5940767e-11, 3.1288928e-11, 1.7027012e-11, 1.6064467e-11, 2.6515051e-11, 1.1543436e-13, 2.1729409e-12, 2.676046e-11, 1.3155522e-11, 7.0774583e-12, 3.9662803e-12, 2.8672231e-11, 1.7701194e-11, 2.2506038e-11, 1.5213916e-11, 2.1611318e-20];\nlet data7 = [2.8477683e-20, 1.9817254e-11, 2.1635317e-10, 1.809108e-10, 3.3037479e-10, 3.1952347e-10, 8.4635997e-11, 6.7923694e-11, 8.1165126e-11, 3.8541257e-11, 2.1220779e-10, 8.8978506e-11, 1.5024543e-10, 1.0109516e-10, 1.1924985e-10, 1.5972819e-10, 1.3589799e-10, 5.5968904e-11, 5.9218579e-11, 1.4418632e-10, 6.8115023e-11, 1.4655948e-10, 2.5399996e-11, 2.3202602e-10, 1.9469538e-11, 2.6029821e-10, 2.6356826e-10, 2.0576201e-10, 2.9054878e-10, 9.7460678e-11, 5.1290831e-10, 2.0877626e-10, 4.8137136e-10, 2.3414674e-10, 4.9323768e-10, 1.7236458e-10, 2.7703685e-10, 2.1815489e-10, 2.2927159e-10, 2.9775453e-10, 3.7796739e-10, 4.2749079e-10, 3.3366027e-10, 3.1802514e-10, 2.4735136e-10, 3.6288265e-10, 3.0970653e-10, 3.5424183e-10, 2.1602941e-10, 2.4179075e-10, 2.952367e-10, 3.8359151e-10, 4.9834974e-10, 4.3116471e-10, 3.7808902e-10, 3.6538443e-10, 5.1141341e-10, 5.2062858e-10, 5.2599717e-10, 5.2491092e-10, 4.512288e-10, 4.7755334e-10, 3.6242088e-10, 3.3089726e-10, 3.088043e-10, 2.425945e-10, 3.1302036e-10, 1.9574006e-10, 3.6476364e-10, 1.7781339e-10, 3.4295644e-10, 1.4802614e-10, 2.1914047e-10, 1.0554173e-10, 2.5820686e-10, 1.8239021e-10, 2.0159706e-10, 2.0936174e-11, 2.02232e-10, 7.9556056e-11, 2.7654249e-10, 1.1959572e-10, 2.5486029e-10, 7.5607268e-12, 1.6671328e-10, 1.8532479e-10, 1.6790936e-10, 2.5386076e-10, 1.3592029e-10, 1.90552e-10, 1.312331e-10, 2.3270266e-10, 5.3277926e-11, 8.607033e-11, 5.2760181e-11, 2.2919825e-11, 1.2535519e-10, 1.6959737e-10, 1.049109e-10, 2.782024e-11, 6.1551883e-11, 4.8213281e-11, 1.0873528e-10, 8.0136791e-11, 1.4437715e-10, 1.7885345e-11, 2.2846276e-10, 2.3411295e-11, 3.2771467e-10, 1.1241968e-10, 3.5625737e-10, 8.5255682e-11, 2.3003975e-10, 7.3182836e-11, 8.2392924e-11, 8.2526453e-11, 2.8599207e-11, 3.3357279e-11, 3.2393904e-11, 6.0353097e-11, 1.6471975e-11, 2.7220928e-11, 6.7487991e-11, 3.4596827e-11, 1.4466908e-10, 1.0913542e-10, 3.886743e-11, 1.7155191e-10, 1.9649472e-10, 3.0039176e-10, 2.1706912e-10, 1.7937359e-10, 5.2531302e-12, 7.9055027e-12, 1.5239417e-10, 6.7756783e-11, 1.0415159e-10, 2.3479438e-10, 7.9120719e-11, 1.484773e-10, 7.5912829e-11, 1.993482e-11, 2.4164178e-10, 2.9148732e-11, 1.3744549e-11, 2.2941906e-10, 2.774089e-10, 2.1098422e-10, 1.3233328e-10, 1.5952605e-10, 1.9464789e-10, 4.7715155e-11, 1.5999093e-10, 7.649121e-11, 2.1009985e-10, 1.452682e-10, 2.0044788e-10, 7.6618975e-12, 3.6200604e-11, 1.8525448e-10, 9.7877338e-11, 2.8069348e-12, 2.0239038e-11, 1.9796622e-11, 1.3152776e-11, 1.9356596e-10, 2.6752626e-11, 2.3772909e-10, 1.430706e-11, 3.2829193e-10, 3.419622e-11, 4.3060049e-10, 1.0813806e-10, 3.7939735e-10, 9.8199581e-11, 3.2751842e-10, 6.5516255e-11, 6.6882809e-11, 1.0962431e-10, 2.4312811e-10, 3.511733e-10, 1.8942962e-10, 2.2945665e-10, 1.4616836e-10, 4.5135341e-11, 9.7068791e-11, 3.8640586e-11, 1.2930635e-10, 8.1348505e-11, 9.5416082e-11, 1.8570819e-10, 1.1855809e-10, 1.9283651e-10, 1.0581354e-10, 1.0844812e-10, 9.5097879e-11, 1.3290397e-10, 3.5893166e-10, 2.5249281e-11, 5.4991348e-10, 9.0886239e-11, 4.3684268e-10, 1.4355966e-10, 5.3188724e-10, 1.2617057e-10, 3.7926679e-10, 1.3789329e-10, 1.6742864e-10, 4.1086368e-11, 7.0177179e-11, 1.2346572e-11, 5.9132882e-14, 7.8648206e-13, 7.0490142e-12, 3.6924912e-12, 5.6042079e-11, 7.2597309e-11, 2.0615028e-10, 2.7642091e-10, 2.6228259e-10, 9.9983201e-11, 2.1552475e-12, 4.8360516e-11, 2.0368089e-11, 8.7008727e-11, 3.7743871e-11, 1.0942598e-10, 1.6518165e-10, 1.242478e-10, 1.4404817e-10, 1.6390056e-10, 3.4234109e-10, 1.440687e-10, 2.7340136e-10, 5.2112998e-11, 1.0796456e-10, 4.6046917e-11, 1.6697214e-10, 6.8456262e-12, 1.0125462e-10, 4.7842905e-11, 2.1396614e-10, 3.5911615e-11, 2.9679157e-10, 1.3415511e-10, 2.7936568e-10, 2.1178514e-10, 4.3080251e-10, 4.2927147e-10, 5.0658213e-10, 4.6356507e-10, 6.5276704e-10, 4.8260318e-10, 6.6818873e-10, 5.6053824e-10, 5.2016442e-10, 5.9334532e-10, 5.4408245e-10, 5.1616447e-10, 4.7639677e-10, 5.8710287e-10, 5.7388639e-10, 5.4723248e-10, 5.8585824e-10, 6.392226e-10, 7.1603609e-10, 6.2675589e-10, 7.8034298e-10, 6.5468454e-10, 7.7678248e-10, 5.9770753e-10, 7.3561387e-10, 5.091355e-10, 5.7069555e-10, 4.4704192e-10, 4.5896522e-10, 5.2184403e-10, 6.2306429e-10, 5.872771e-10, 6.9971574e-10, 6.8471009e-10, 6.7302519e-10, 4.6299314e-10, 6.3234335e-10, 4.7836513e-10, 7.4206463e-10, 5.6813867e-10, 8.0981043e-10, 6.6875664e-10, 7.3005264e-10, 7.0932665e-10, 6.8507835e-10, 6.2430738e-10, 6.9547164e-10, 6.5583485e-10, 5.1924179e-10, 7.0097115e-10, 5.2655282e-10, 6.563908e-10, 5.5960659e-10, 6.619308e-10, 4.9482656e-10, 5.3791057e-10, 4.4873093e-10, 4.3237599e-10, 3.2823616e-10, 4.3226711e-10, 2.2101743e-10, 2.6649277e-10, 1.6903861e-10, 2.1312479e-10, 1.7537258e-10, 1.7326172e-10, 5.3140063e-11, 1.7270464e-11, 2.6298704e-11, 1.2999494e-11, 1.1822559e-11, 1.4736385e-10, 1.4860663e-10, 1.1970659e-10, 4.6003957e-11, 1.29762e-10, 1.6484604e-10, 2.2191799e-10, 7.8584122e-11, 1.1429746e-10, 2.6841091e-11, 1.3831702e-10, 2.2084829e-10, 1.6325195e-10, 2.4149503e-10, 6.1705914e-11, 3.6353002e-10, 9.8185172e-11, 3.4585628e-10, 6.2212222e-12, 1.398224e-10, 6.0760331e-12, 1.6543115e-10, 4.8727664e-11, 3.6482602e-10, 2.8267297e-10, 4.6532468e-10, 1.9670647e-10, 4.4901017e-10, 1.2678165e-10, 4.1018904e-10, 1.8250552e-09, 4.1534681e-09, 9.4402826e-09, 1.9585692e-08, 4.0855308e-08, 8.2272735e-08, 1.637779e-07, 3.2005018e-07, 6.1731524e-07, 1.1731282e-06, 2.1975343e-06, 4.0552083e-06, 7.3716991e-06, 1.3194619e-05, 2.3245815e-05, 4.0291446e-05, 6.867536e-05, 0.00011505047, 0.00018933885, 0.00030591933, 0.00048498838, 0.00075396411, 0.0011487021, 0.0017141973, 0.0025043679, 0.0035805309, 0.0050081363, 0.006852056, 0.0091706344, 0.012009175, 0.01539368, 0.019325493, 0.023778893, 0.028706448, 0.03405052, 0.039752921, 0.045760023, 0.052024883, 0.058507644, 0.065175076, 0.071999732, 0.078959028, 0.086034375, 0.093210427, 0.10047445, 0.10781579, 0.11522552, 0.12269605, 0.1302209, 0.13779453, 0.1454121, 0.15306944, 0.16076286, 0.16848914, 0.1762454, 0.18402908, 0.19183791, 0.19966982, 0.20752299, 0.21539573, 0.22328651, 0.23119396, 0.23911681, 0.24705388, 0.25500412, 0.26296652, 0.27094019, 0.27892425, 0.28691792, 0.29492045, 0.30293117, 0.31094941, 0.31897457, 0.32700609, 0.33504346, 0.34308619, 0.35113386, 0.35918609, 0.36724252, 0.37530278, 0.3833665, 0.39143312, 0.39950231, 0.40757347, 0.41564732, 0.42372248, 0.43180034, 0.43987062, 0.44793718, 0.45597733, 0.46403705, 0.4720927, 0.48028065, 0.4885131, 0.49695726, 0.5053638, 0.51370983, 0.52166575, 0.52911717, 0.53630063, 0.54350976, 0.55065175, 0.5576987, 0.56515963, 0.57414881, 0.58581203, 0.60106133, 0.61920826, 0.63441176, 0.64444496, 0.65045212, 0.6552307, 0.6599221, 0.6650715, 0.67001146, 0.67061167, 0.67113711, 0.67315375, 0.67797767, 0.68199324, 0.68571826, 0.69335833, 0.70237947, 0.70950038, 0.71685984, 0.7241968, 0.73129851, 0.73900574, 0.75115207, 0.75963027, 0.76905855, 0.78322163, 0.79159857, 0.79245248, 0.79107474, 0.78888644, 0.78973313, 0.79291809, 0.80155304, 0.81233827, 0.82142127, 0.82650645, 0.82950388, 0.83326463, 0.83366361, 0.83176001, 0.83146794, 0.83202915, 0.83384987, 0.83933199, 0.84790874, 0.85610776, 0.86331973, 0.86895249, 0.87437673, 0.87886068, 0.88107721, 0.88256128, 0.88637201, 0.8903003, 0.89170068, 0.8913573, 0.88855065, 0.88565698, 0.88533144, 0.88606156, 0.88671645, 0.88791243, 0.88913495, 0.8891744, 0.88764162, 0.88782382, 0.88955391, 0.89185602, 0.89196857, 0.89173273, 0.89275971, 0.89683466, 0.90014227, 0.90019847, 0.89987414, 0.89742712, 0.89417066, 0.89250583, 0.89142793, 0.89044687, 0.89000899, 0.89008642, 0.8905574, 0.89235167, 0.89543507, 0.89656239, 0.89636287, 0.89559705, 0.89308331, 0.89015943, 0.88955618, 0.88997233, 0.8915667, 0.89541263, 0.89933524, 0.90012366, 0.89982421, 0.89974462, 0.89953149, 0.89852051, 0.89717144, 0.8962689, 0.89562133, 0.89390928, 0.88979206, 0.88653296, 0.88673392, 0.88801113, 0.8919161, 0.89805037, 0.90365521, 0.90506388, 0.90454156, 0.90286096, 0.89988196, 0.89693817, 0.89508255, 0.89482766, 0.89446222, 0.8935049, 0.89149568, 0.89126409, 0.89133746, 0.89155296, 0.891861, 0.89210393, 0.89241619, 0.89270213, 0.89185516, 0.8909092, 0.89204971, 0.89389175, 0.89439182, 0.89561993, 0.89863491, 0.89857581, 0.89790874, 0.89807274, 0.8975778, 0.89576727, 0.89454615, 0.89394598, 0.89344243, 0.89313787, 0.89326778, 0.89456251, 0.89627034, 0.89716934, 0.89706067, 0.89644184, 0.8951939, 0.89524545, 0.8955355, 0.89648327, 0.89645648, 0.89620751, 0.89535335, 0.89266434, 0.89107604, 0.89119897, 0.89146252, 0.89201422, 0.89367523, 0.89515785, 0.89514318, 0.89468989, 0.8936907, 0.89203612, 0.89111186, 0.89147443, 0.89267491, 0.89616509, 0.89965218, 0.90041286, 0.90012019, 0.89926374, 0.89733478, 0.89248269, 0.88868208, 0.88865755, 0.88955456, 0.8911347, 0.89408624, 0.89764004, 0.8976562, 0.89715549, 0.8955327, 0.890238, 0.88822536, 0.88957124, 0.89035779, 0.89214842, 0.89442469, 0.90050315, 0.90013322, 0.89675555, 0.88715024, 0.87840912, 0.86407897, 0.85519389, 0.86034735, 0.87677547, 0.89883519, 0.91619161, 0.914784, 0.91060943, 0.90052024, 0.88406818, 0.85282057, 0.8092647, 0.77598062, 0.76502665, 0.74142894, 0.63055733, 0.2403422, 0.024533632, 0.0019871171, 0.00015601923, 1.2184269e-05, 9.5273907e-07, 7.4937229e-08, 5.953439e-09, 4.8536166e-10, 3.6191332e-10, 3.4116245e-10, 3.3277232e-10, 2.2153077e-10, 3.2855396e-10, 8.620493e-11, 8.181629e-11, 3.5578282e-10, 2.3914764e-11, 4.8847353e-10, 2.7332507e-10, 4.7721934e-10, 3.6431553e-10, 2.2384307e-10, 3.9855979e-10, 3.8645977e-10, 3.5036318e-10, 1.726803e-10, 2.9928474e-10, 1.9461675e-10, 3.7171756e-10, 1.7373108e-10, 3.7679966e-10, 4.8863157e-10, 3.8452728e-10, 4.2056852e-10, 3.3878678e-10, 3.6588632e-10, 3.3653803e-10, 1.6154007e-10, 3.2305978e-10, 2.7894117e-10, 6.7424967e-11, 1.0233268e-11, 4.5023441e-11, 8.146e-11, 1.1299926e-10, 7.1518314e-11, 5.3754675e-11, 7.0855331e-11, 1.2622738e-11, 7.8869489e-13, 1.4741204e-10, 5.0156919e-11, 9.4527367e-11, 3.6979398e-11, 1.6238011e-10, 3.9140888e-10, 9.6569923e-11, 4.8952982e-11, 1.125599e-10, 6.9977177e-11, 9.3216288e-11, 8.5504999e-12, 1.6346375e-10, 3.3393236e-10, 1.215359e-10, 1.2327146e-11, 3.1730176e-11, 3.9845058e-12, 1.4821947e-10, 5.8621841e-11, 4.0178273e-11, 8.2939545e-11, 1.962649e-10, 2.6365975e-10, 4.681282e-10, 3.1397343e-10, 1.725423e-10, 3.385972e-10, 1.1452388e-10, 1.2711137e-10, 1.0347447e-10, 9.8208115e-11, 3.625952e-11, 4.4265293e-11, 1.0968569e-10, 1.833644e-10, 1.8868279e-11, 6.4592718e-11, 1.77071e-10, 5.7097743e-11, 7.5745921e-11, 2.433641e-10, 2.6176833e-10, 1.9938034e-10, 7.8585294e-11, 1.7420073e-10, 1.5080546e-10, 7.284895e-11, 1.3081094e-10, 8.2025894e-11, 4.0778175e-12, 2.7453699e-10, 8.3939684e-11, 8.6642635e-11, 4.5338077e-11, 7.5067079e-12, 1.7119446e-10, 4.3341007e-11, 2.2271518e-11, 8.4149852e-11, 2.1526762e-10, 1.1833779e-10, 3.1246775e-10, 1.4383031e-10, 1.5289642e-10, 2.8087521e-11, 2.2263925e-11, 2.8324233e-10, 2.1168632e-10, 2.0249857e-10, 2.7185546e-10, 2.6738573e-10, 2.8651923e-10, 2.1367628e-10, 2.4703077e-11, 3.8862975e-10, 2.8921211e-10, 1.4230467e-10, 4.1436828e-11, 3.7256349e-11, 3.0538214e-10, 4.5553487e-11, 1.5740043e-10, 2.8861295e-10, 3.3890142e-10, 4.2071341e-11, 2.2142564e-10, 1.0395009e-10, 4.7673354e-10, 1.4339627e-10, 5.8287293e-10, 3.3438255e-11, 5.5037913e-10, 3.3458078e-11, 3.7407164e-10, 3.854368e-10, 2.4011775e-10, 4.5061275e-10, 5.4182422e-10, 3.8275743e-10, 2.9087651e-10, 1.220687e-10, 3.0405937e-10, 7.2546675e-11, 3.2877402e-11, 1.3158057e-10, 3.4092286e-10, 2.2212738e-10, 3.3963692e-10, 2.106994e-10, 4.455069e-10, 2.6300736e-10, 1.3576514e-10, 1.1298729e-10, 3.8279119e-10, 1.8344209e-11, 1.172805e-10, 3.006375e-11, 1.700625e-10, 1.9673638e-10, 1.2044465e-10, 2.5815689e-10, 4.2112812e-10, 5.1276697e-11, 6.7210226e-11, 5.7983457e-11, 1.089576e-10, 3.2672554e-11, 2.7578965e-10, 1.468722e-10, 2.9628548e-10, 3.9326858e-10, 4.8068342e-10, 3.7565781e-10, 3.241546e-10, 2.2195177e-10, 4.566839e-10, 4.1441796e-10, 2.0261894e-10, 3.0922788e-10, 1.225869e-10, 3.1332938e-11, 1.8846258e-10, 4.1431616e-10, 2.4652404e-10, 3.3884929e-10, 4.3479405e-10, 3.2627362e-10, 2.5278098e-10, 3.3640669e-10, 3.5546187e-10, 3.7988848e-10, 5.767901e-11, 7.0454888e-11, 4.3509946e-10, 2.1841129e-10, 4.475982e-10, 2.8222015e-10, 5.4257885e-10, 2.8392429e-10, 6.8963281e-10, 3.1406001e-10, 2.7907842e-10, 2.3343131e-10, 3.4284524e-10, 3.6977625e-10, 2.5203559e-10, 1.8537896e-10, 2.9391517e-10, 7.8858797e-11, 1.3702003e-10, 2.4885264e-10, 2.4011127e-10, 4.10332e-10, 4.5736337e-10, 5.3042462e-10, 6.7751041e-11, 3.1341871e-10, 8.3023325e-11, 1.8255445e-10, 3.4044546e-10, 4.3011966e-11, 2.6184625e-10, 5.8955461e-11, 4.8949175e-10, 2.2769705e-10, 2.7286237e-10, 1.112853e-10, 1.7151728e-10, 8.9115615e-11, 4.1614266e-11, 2.5054228e-10, 1.8822545e-10, 6.7626191e-11, 2.1285241e-11, 5.7091015e-11, 4.433511e-10, 3.1274912e-10, 2.2601838e-10, 6.2294587e-11, 3.1449292e-11, 4.4388366e-10, 1.0949398e-10, 2.5631037e-10, 6.2711095e-11, 5.8124669e-10, 4.1696024e-10, 6.5950828e-10, 1.6011349e-10, 3.2415787e-10, 9.7031873e-11, 1.6982715e-10, 6.3710753e-11, 2.1660822e-10, 5.5002667e-11, 4.6249485e-10, 3.5534175e-10, 4.0977061e-10, 1.1044674e-10, 4.1232996e-10, 1.7613872e-10, 4.7531882e-10, 1.4800221e-10, 5.4628135e-10, 8.7973527e-11, 3.8900734e-10, 4.1719918e-11, 3.5080572e-10, 6.1888695e-12, 5.6905546e-11, 1.0672898e-10, 6.678153e-11, 2.1756497e-10, 9.6035733e-12, 4.9392453e-11, 9.1473808e-11, 4.521796e-11, 1.0588006e-10, 7.3530424e-11, 1.4769092e-10, 1.8944487e-11, 7.2548502e-11, 4.0307835e-10, 2.1403273e-10, 3.4677373e-10, 3.4571903e-10, 2.6744556e-10, 2.3754971e-11, 8.9804591e-12, 1.1953095e-11, 1.2903551e-10, 4.1469275e-11, 1.7462034e-11, 2.2420991e-10, 3.2052671e-11, 1.9999565e-10, 3.9288371e-11, 3.8543651e-12, 3.3792944e-11, 6.5628575e-11, 1.7551484e-10, 1.7002088e-10, 2.8506586e-10, 2.4517918e-10, 3.7002737e-11, 6.9367117e-11, 3.875388e-11, 1.3229345e-11, 1.3489459e-11, 1.9190398e-10, 1.0360143e-11, 1.2232169e-11, 7.9270097e-12, 1.782311e-10, 6.749101e-11, 1.1641828e-10, 1.5052055e-10, 1.0297067e-10, 4.3455144e-12, 1.311254e-10, 2.2328563e-18];\nlet data6 = [2.4736089e-21, 3.557215e-11, 1.4491517e-11, 3.1926845e-12, 9.8094767e-12, 6.4086002e-12, 1.0635131e-11, 1.7253035e-11, 7.2617091e-13, 7.0434024e-12, 9.7921366e-12, 5.3706415e-12, 2.0734942e-11, 1.8722161e-11, 1.6536423e-12, 2.9744887e-12, 6.7616262e-12, 4.6114578e-12, 1.6889115e-11, 1.3241588e-11, 6.2568747e-12, 5.2398129e-12, 2.3631512e-11, 1.5845265e-11, 3.2267866e-11, 3.7653514e-12, 2.8384247e-11, 5.9523119e-12, 4.0711368e-12, 3.092868e-12, 1.645528e-12, 1.4564101e-11, 1.4103256e-11, 1.1685094e-11, 2.1664859e-11, 3.3110082e-11, 5.1585703e-11, 3.3429429e-11, 6.1477878e-11, 2.8549978e-11, 6.3940724e-11, 4.2923005e-11, 6.7488102e-11, 4.6114911e-11, 7.38638e-11, 6.2954229e-11, 5.8148252e-11, 5.1998196e-11, 6.2571525e-11, 6.3686069e-11, 6.6297973e-11, 5.5396516e-11, 3.8656236e-11, 3.7013154e-11, 2.5425876e-11, 5.928347e-11, 1.4655137e-11, 1.3775906e-11, 7.3402954e-12, 1.9464115e-11, 1.3586944e-11, 3.222585e-12, 3.1207677e-12, 7.4854629e-12, 1.5714993e-12, 1.0029451e-12, 1.8254646e-11, 1.6622901e-11, 2.7060288e-11, 2.7576044e-11, 2.2113367e-11, 3.7476556e-11, 2.8651462e-11, 1.0359023e-11, 1.8422378e-11, 2.0315446e-11, 1.144978e-11, 1.2722942e-11, 1.2541982e-11, 1.7565045e-11, 1.1307058e-11, 1.0880448e-11, 3.1376187e-11, 1.5549373e-11, 2.7908618e-11, 1.3636074e-11, 2.6978256e-11, 2.4016439e-11, 3.3378853e-11, 6.3285692e-12, 9.4646761e-12, 1.1684983e-11, 8.3919261e-12, 7.3647494e-12, 4.2612106e-12, 4.1272697e-12, 5.051073e-12, 6.0162256e-12, 5.2336994e-12, 9.1067593e-12, 8.3596914e-12, 2.3193786e-11, 2.4675139e-12, 1.96822e-11, 7.0787494e-12, 1.5689872e-11, 1.3103645e-11, 1.2901678e-11, 5.1338829e-12, 3.0584879e-11, 2.4636347e-11, 4.084931e-11, 1.8863771e-11, 1.7808806e-11, 1.0670256e-11, 2.2720714e-11, 6.5158642e-12, 1.4889783e-11, 1.3300166e-11, 2.1428323e-11, 5.7082171e-12, 1.5145549e-11, 2.9703648e-11, 3.2818747e-11, 5.7270022e-11, 3.4523965e-11, 3.5275701e-11, 3.0865322e-12, 1.1147552e-11, 1.3170782e-11, 2.0258313e-11, 8.1201539e-12, 1.8948693e-11, 4.3070062e-12, 2.0004436e-12, 2.087144e-12, 1.278541e-11, 1.4894674e-12, 7.7514551e-12, 7.6359658e-12, 4.8564418e-12, 1.2659361e-12, 2.5807135e-11, 1.9168779e-11, 2.2039671e-12, 9.3736407e-13, 3.4295543e-12, 8.5977838e-13, 2.1398089e-11, 4.11093e-12, 2.9779344e-12, 9.9719843e-12, 1.2265875e-12, 2.3258256e-11, 2.7452885e-12, 3.5525243e-11, 4.9341387e-13, 2.516055e-11, 3.9548695e-13, 2.2922348e-11, 1.2079136e-12, 1.486344e-11, 2.8566095e-11, 1.1704213e-11, 1.3646523e-11, 3.290667e-11, 1.1824593e-11, 1.9435993e-11, 1.4976484e-11, 6.4421688e-12, 3.1013157e-12, 1.4837763e-11, 2.4438825e-11, 1.8236083e-11, 1.5704544e-11, 1.0533647e-11, 7.9248558e-12, 8.2939992e-12, 1.8438273e-11, 2.6298214e-11, 3.3018713e-11, 4.3504675e-12, 1.2537536e-11, 1.660645e-12, 1.8246976e-11, 9.6453018e-12, 2.9774898e-12, 4.012225e-12, 1.3658638e-11, 4.5602156e-12, 8.7537333e-12, 1.76214e-11, 1.7859048e-11, 1.0328901e-11, 1.946067e-11, 1.7977872e-11, 1.3260373e-11, 8.0306747e-12, 3.7705756e-12, 1.5674755e-11, 2.0868439e-11, 1.0141161e-11, 9.1175413e-12, 2.7824474e-11, 1.8477955e-11, 3.1111084e-11, 1.8002659e-11, 4.4133253e-11, 2.1554261e-11, 3.4529856e-11, 1.7164445e-12, 4.1950516e-11, 1.9599501e-11, 5.5902602e-11, 2.3968198e-11, 5.3617381e-11, 3.4065898e-11, 5.772631e-11, 4.3247909e-11, 2.910964e-11, 3.540753e-11, 2.7571931e-11, 1.1315284e-11, 1.8592999e-11, 2.5544255e-11, 1.6387143e-11, 1.5040508e-11, 2.2639905e-11, 5.4360002e-12, 8.6666995e-12, 5.6874312e-12, 1.5383751e-13, 8.4142681e-12, 2.35447e-12, 1.4626348e-11, 3.7153319e-12, 1.3556488e-11, 3.5347063e-14, 1.3290495e-11, 1.0186957e-11, 6.1501665e-12, 8.5577683e-13, 1.3072633e-11, 1.0210744e-11, 2.2636236e-11, 2.474839e-11, 2.8420038e-11, 4.5050942e-11, 2.2227633e-11, 3.1792015e-11, 3.6332556e-11, 3.8697586e-11, 4.2348893e-11, 3.2118253e-11, 2.8153046e-11, 2.4457277e-11, 1.9662081e-11, 2.1734997e-11, 6.8804476e-14, 1.1115651e-11, 4.9918277e-12, 1.8982929e-12, 1.1247702e-11, 2.0770401e-11, 3.5807463e-11, 8.5853346e-12, 2.4645239e-11, 2.9784902e-12, 3.769364e-11, 1.2267098e-11, 3.746344e-11, 1.1964203e-11, 3.5184555e-11, 1.8121038e-11, 3.9607495e-11, 3.9379517e-11, 3.7426425e-11, 3.3673968e-11, 4.049684e-12, 2.1577381e-11, 1.3780908e-11, 2.3483121e-11, 2.7510908e-11, 1.4425381e-11, 3.1311828e-11, 3.6918784e-11, 1.8378583e-11, 2.2417929e-11, 9.0246163e-12, 6.4247186e-14, 9.9341918e-12, 7.702325e-12, 4.1842474e-11, 6.886208e-11, 9.5465635e-11, 1.6657403e-10, 2.5517066e-10, 3.8494351e-10, 5.6399439e-10, 8.0096699e-10, 1.1594728e-09, 1.6400004e-09, 2.3573629e-09, 3.2925991e-09, 4.651614e-09, 6.4904372e-09, 9.0606513e-09, 1.2616985e-08, 1.750877e-08, 2.4246208e-08, 3.3509402e-08, 4.6136119e-08, 6.3343107e-08, 8.6727815e-08, 1.1841186e-07, 1.6118977e-07, 2.1885078e-07, 2.9625965e-07, 3.9988425e-07, 5.3816045e-07, 7.2207441e-07, 9.6595904e-07, 1.2882465e-06, 1.7128436e-06, 2.2702853e-06, 2.9998008e-06, 3.9511764e-06, 5.1876766e-06, 6.7891422e-06, 8.8560828e-06, 1.1514183e-05, 1.4920328e-05, 1.9269039e-05, 2.4800646e-05, 3.1810529e-05, 4.0660049e-05, 5.1789098e-05, 6.5730358e-05, 8.3125583e-05, 0.00010474378, 0.00013150143, 0.00016448458, 0.00020497294, 0.00025446541, 0.00031470709, 0.00038771704, 0.00047581629, 0.00058165571, 0.00070824225, 0.00085896345, 0.0010376082, 0.0012483837, 0.0014959262, 0.0017853056, 0.0021220223, 0.0025119947, 0.0029615384, 0.0034773344, 0.0040663876, 0.0047359764, 0.0054935914, 0.0063468671, 0.007303506, 0.0083711979, 0.0095575358, 0.01086993, 0.012315523, 0.013901112, 0.015633065, 0.017517262, 0.019559027, 0.021763082, 0.024133505, 0.026673708, 0.029386413, 0.032273654, 0.035336779, 0.038576467, 0.04199275, 0.045585049, 0.049352209, 0.053292541, 0.05740387, 0.061683583, 0.066128679, 0.070735817, 0.075501368, 0.08042146, 0.085492024, 0.090708839, 0.096067568, 0.1015638, 0.10719306, 0.11295089, 0.11883282, 0.12483441, 0.13095128, 0.13717913, 0.14351373, 0.14995096, 0.15648679, 0.16311732, 0.16983875, 0.17664742, 0.1835398, 0.19051247, 0.19756214, 0.20468567, 0.21188001, 0.21914228, 0.22646967, 0.23385953, 0.24130932, 0.2488166, 0.25637904, 0.26399444, 0.27166068, 0.27937575, 0.28713777, 0.29494488, 0.30279546, 0.31068767, 0.31862067, 0.32659107, 0.33460296, 0.34264136, 0.3507378, 0.35882029, 0.36702912, 0.37510944, 0.38346982, 0.39151817, 0.40002843, 0.40807226, 0.41671242, 0.42477037, 0.43354705, 0.44164824, 0.4504208, 0.45880128, 0.46731437, 0.47564069, 0.48422064, 0.49218235, 0.50114621, 0.50900396, 0.518143, 0.52591298, 0.5352627, 0.54287413, 0.55237234, 0.55994548, 0.56971587, 0.57701518, 0.58720775, 0.59417315, 0.60464393, 0.61157174, 0.62223854, 0.62896741, 0.63994151, 0.6463752, 0.65756992, 0.66373256, 0.67507394, 0.68084696, 0.69222455, 0.69760447, 0.70898071, 0.71394469, 0.7252862, 0.72979015, 0.74095639, 0.74500105, 0.75577082, 0.75958339, 0.77002512, 0.77383606, 0.78382725, 0.78789691, 0.79706106, 0.80153898, 0.80944065, 0.81447886, 0.82092838, 0.82676051, 0.83227023, 0.84016694, 0.84345249, 0.85416931, 0.85538181, 0.86689314, 0.87031671, 0.88113769, 0.88503948, 0.89266435, 0.89726632, 0.90207678, 0.90609692, 0.90963674, 0.91258655, 0.91502049, 0.91694533, 0.9185455, 0.91993565, 0.92127913, 0.92250348, 0.9236348, 0.92449581, 0.92534573, 0.92593932, 0.926508, 0.92681627, 0.92684728, 0.92684988, 0.92681491, 0.92675624, 0.92662322, 0.92641057, 0.92621132, 0.92590999, 0.92573187, 0.92555097, 0.92539485, 0.92529249, 0.9251848, 0.92514504, 0.92503605, 0.9249758, 0.92487104, 0.92480741, 0.92477195, 0.92475021, 0.92474446, 0.92473058, 0.92466689, 0.92464599, 0.92459863, 0.92455818, 0.92454052, 0.9245201, 0.92451419, 0.92451885, 0.92448997, 0.92448865, 0.92451428, 0.92451891, 0.9246874, 0.92476524, 0.92500648, 0.92509177, 0.92524675, 0.92532686, 0.92542361, 0.92548585, 0.9255706, 0.92561766, 0.92567513, 0.92568916, 0.92568702, 0.92568594, 0.92568644, 0.92568731, 0.92568733, 0.92568538, 0.92568545, 0.92568528, 0.92568663, 0.9256866, 0.92568528, 0.92568502, 0.92567256, 0.92566365, 0.92565065, 0.92563364, 0.92563023, 0.92560237, 0.92558626, 0.92558102, 0.92556718, 0.92556095, 0.92553352, 0.92552234, 0.92551443, 0.92551346, 0.92553188, 0.92554215, 0.92553593, 0.92551216, 0.9254981, 0.92548397, 0.92545191, 0.9254438, 0.92546047, 0.92545948, 0.92545321, 0.92546942, 0.92546893, 0.92548178, 0.9254962, 0.92550577, 0.92551064, 0.92551861, 0.92551255, 0.92551154, 0.92550125, 0.9254909, 0.92547777, 0.92546059, 0.9254376, 0.92542317, 0.92541357, 0.92540004, 0.92539003, 0.92539268, 0.92539484, 0.92539319, 0.92538687, 0.92537376, 0.92536217, 0.92533494, 0.92532182, 0.92530103, 0.92529295, 0.92528055, 0.9252808, 0.92528141, 0.92527479, 0.92526564, 0.92523915, 0.92522498, 0.92519033, 0.92516932, 0.92514302, 0.92513574, 0.92510167, 0.92508319, 0.92504168, 0.92502395, 0.92498993, 0.92496413, 0.92494274, 0.92494213, 0.92495041, 0.9249836, 0.92499667, 0.92499782, 0.92498454, 0.92497894, 0.92492624, 0.92489385, 0.92487897, 0.92509758, 0.92504302, 0.92491965, 0.92467987, 0.92444044, 0.92344321, 0.92290962, 0.92093694, 0.92008582, 0.9162359, 0.91463478, 0.90802769, 0.90425492, 0.89399229, 0.88607405, 0.86898745, 0.85620349, 0.82452756, 0.80408067, 0.75438196, 0.71474921, 0.64709112, 0.57709269, 0.48776217, 0.39181642, 0.29379284, 0.20417154, 0.13180417, 0.079941381, 0.046261304, 0.025928858, 0.014247258, 0.0077397344, 0.0041786383, 0.0022487831, 0.0012082535, 0.00064867088, 0.00034811725, 0.00018678768, 0.00010021515, 5.3764932e-05, 2.884384e-05, 1.5473854e-05, 8.3011042e-06, 4.4531444e-06, 2.3888279e-06, 1.2814482e-06, 6.8740462e-07, 3.6877249e-07, 1.9781662e-07, 1.0612857e-07, 5.6907018e-08, 3.0530822e-08, 1.6362161e-08, 8.775146e-09, 4.6521183e-09, 2.5235309e-09, 1.3190337e-09, 7.1714996e-10, 3.3889165e-10, 1.8756574e-10, 7.8574173e-11, 2.5481803e-11, 6.9994292e-12, 1.247901e-11, 4.1408415e-11, 4.7442414e-12, 4.0464184e-11, 1.6622659e-11, 2.5161139e-11, 2.3042919e-11, 2.7545969e-11, 2.1857719e-11, 1.0317612e-11, 3.6101653e-11, 8.1525515e-13, 1.4730091e-12, 4.1200966e-11, 2.1666919e-11, 2.549046e-11, 1.2807665e-11, 1.5924281e-11, 1.1008553e-11, 3.9694991e-11, 2.012476e-11, 2.4571647e-11, 6.2012669e-13, 3.3875435e-11, 1.7536811e-11, 3.5456885e-11, 9.438868e-12, 1.5482856e-11, 1.2117833e-11, 1.2255133e-11, 3.2043691e-11, 4.9047395e-12, 5.9504194e-13, 2.3257249e-11, 9.3155531e-12, 4.0251407e-11, 1.6236398e-11, 2.031778e-11, 5.1861107e-12, 4.9291028e-11, 8.2434564e-12, 9.2215406e-12, 2.4410372e-11, 1.5256538e-11, 5.7015363e-11, 3.3725704e-12, 5.4832432e-11, 5.1818707e-11, 4.5330519e-11, 3.5841038e-11, 3.9551697e-11, 4.6543135e-11, 6.3229727e-11, 4.3508543e-11, 3.6803361e-11, 2.5596571e-11, 5.6237735e-11, 2.0785067e-11, 5.3363974e-11, 4.6250331e-12, 5.7681996e-11, 1.4312085e-11, 3.4661054e-11, 1.451132e-11, 4.1207626e-11, 2.0039405e-11, 5.1141307e-11, 5.7767129e-11, 6.5028949e-11, 6.081504e-11, 6.6510061e-11, 6.9528559e-11, 5.3917837e-11, 3.3359199e-11, 3.1915825e-11, 2.4460763e-11, 2.6618498e-11, 1.9054772e-11, 2.2080929e-11, 2.1238369e-11, 4.8883122e-12, 2.9346301e-11, 3.8926909e-12, 1.8546972e-11, 3.352447e-11, 7.7369881e-12, 2.0904608e-11, 5.2964393e-11, 3.7098162e-11, 3.698628e-11, 5.4720328e-12, 1.7230799e-12, 1.4661718e-11, 3.0158781e-11, 8.727504e-13, 7.4551729e-12, 9.6010311e-12, 9.7009263e-12, 4.6964914e-11, 1.7044439e-11, 3.1317343e-11, 4.2369517e-11, 3.8669623e-11, 1.3587734e-11, 4.0327661e-11, 2.2638121e-11, 2.0275824e-11, 2.1832634e-12, 2.6967021e-11, 3.5043653e-11, 8.9498259e-12, 1.7058757e-11, 3.7238681e-12, 4.9141296e-11, 1.4965288e-11, 6.4129671e-11, 9.1424014e-12, 5.4471811e-11, 1.130724e-11, 1.602795e-11, 3.6961417e-11, 5.9972591e-12, 2.417473e-11, 3.6010304e-11, 2.7460281e-11, 1.8913365e-11, 2.2333219e-12, 9.1835805e-12, 1.0674682e-11, 2.0343309e-11, 1.0621071e-11, 2.5540186e-11, 1.0256232e-11, 4.1173994e-11, 4.7592922e-11, 3.8839778e-11, 5.586668e-11, 4.5768393e-11, 5.4112521e-11, 1.3272288e-11, 1.3262631e-11, 2.1268781e-12, 2.0194243e-11, 4.7091671e-12, 3.7831725e-11, 1.5198377e-11, 9.3552891e-12, 3.8123752e-11, 9.7382204e-12, 2.1738621e-11, 1.7108705e-12, 5.4503888e-12, 3.0085081e-12, 2.2196696e-12, 1.3662545e-11, 1.8426765e-11, 6.4032773e-12, 2.0263392e-11, 3.1608037e-11, 4.4126672e-11, 2.1159896e-11, 3.9597982e-11, 1.1844232e-11, 1.6582368e-11, 9.2536177e-13, 2.2899403e-11, 6.6586758e-12, 1.3248202e-11, 1.8486591e-11, 4.3278784e-11, 3.2563479e-11, 1.3640346e-11, 1.2093747e-11, 3.9193296e-12, 1.6752745e-11, 6.6797648e-12, 1.0561134e-11, 1.7613841e-11, 6.0695166e-12, 3.1665977e-11, 1.3746124e-11, 2.4588629e-12, 2.1681015e-11, 1.1307129e-11, 5.1117999e-11, 1.8270707e-11, 3.9627285e-12, 8.1229163e-12, 3.1189482e-14, 8.6509177e-13, 2.0935576e-11, 1.1765536e-11, 3.1098461e-11, 5.3431792e-11, 4.5414209e-11, 3.6909915e-11, 5.9130031e-11, 3.0514297e-11, 5.9756929e-11, 5.2456704e-11, 3.5227349e-11, 4.0291587e-11, 1.2385774e-11, 1.3110236e-11, 1.0282982e-11, 3.7945717e-12, 1.1037634e-11, 9.5456448e-12, 1.2120386e-11, 3.4301765e-11, 2.9848773e-11, 2.483648e-11, 1.5567101e-11, 1.8956764e-11, 3.6095881e-11, 5.7025684e-12, 1.6939771e-11, 3.0161445e-11, 6.3281338e-12, 1.0585664e-11, 1.3458537e-11, 1.4699567e-11, 2.6314706e-11, 7.8859428e-12, 2.2798398e-11, 1.1018876e-11, 1.6363931e-11, 6.347669e-12, 1.6589916e-11, 2.0036741e-12, 1.6865848e-11, 5.4995594e-12, 5.0944292e-12, 1.3116007e-11, 2.4353432e-11, 3.5570433e-12, 6.7930902e-12, 2.3220066e-12, 9.9536609e-12, 1.8856536e-11, 8.7824461e-12, 7.618224e-12, 1.6572712e-11, 5.5821394e-12, 2.3594118e-12, 1.351692e-11, 1.9621733e-11, 2.3416193e-11, 8.477988e-12, 1.7558232e-12, 1.3480181e-11, 1.6566829e-11, 8.3494562e-12, 1.0927638e-11, 4.0086691e-11, 1.6651962e-11, 2.7324424e-11, 3.4887816e-12, 1.3475297e-11, 2.1159452e-11, 5.2683577e-12, 1.3745236e-11, 3.5893205e-11, 3.4344276e-11, 4.7905261e-12, 2.1948068e-11, 4.4536575e-12, 5.2116617e-11, 3.6534865e-11, 6.9206452e-11, 3.8344298e-11, 4.4512489e-11, 2.1158231e-11, 1.856573e-11, 1.5882214e-12, 1.1754437e-11, 1.8347626e-11, 2.3172338e-11, 2.9199233e-11, 4.1969381e-11, 3.6500567e-11, 4.019036e-11, 5.0911105e-11, 3.4911625e-20];\n\noption = {\n  dataZoom: [\n    {\n      type: 'slider',\n      minSpan: 1\n    },\n    {\n      type: 'inside',\n      minSpan: 1\n    }\n  ],\n  tooltip: {\n      trigger: 'axis',\n      formatter: function (params) {\n          let newParams = [];\n          let tooltipString = [];\n          newParams = [...params];\n          newParams.sort((a,b) => {return b.value - a.value});\n          newParams.forEach((p) => {\n              const cont = p.marker + ' ' + p.seriesName + ': ' + p.value + '<br/>';\n              tooltipString.push(cont);\n          });\n          return tooltipString.join('');\n      }\n  },\n legend: {\n    data: legends\n  },\n  grid: {\n    left: '3%',\n    right: '4%',\n    bottom: '9%',\n    containLabel: true\n  },\n  // toolbox: {\n  //   feature: {\n  //     saveAsImage: {}\n  //   }\n  // },\n  xAxis: {\n    type: 'category',\n    boundaryGap: false,\n    data: xaxis\n  },\n  yAxis: {\n    min: 'dataMin',\n    type: 'value',\n    axisTick: {\n      alignWithLabel: true\n    },\n    scale: true,\n  },\n  series: [\n    {\n      name: legends[0],\n      type: 'line',\n      showSymbol: false,\n      data: data0\n    },\n    \n    {\n      name: legends[1],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data1\n    },\n    {\n      name: legends[2],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data2\n    },\n    {\n      name: legends[3],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data3\n    },\n    {\n      name: legends[4],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data4\n    },\n    {\n      name: legends[5],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data5\n    },\n    {\n      name: legends[6],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data6\n    },\n        {\n      name: legends[7],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data7\n    }\n  ]\n};\n{% endecharts %}\n\n\n\n","slug":"FVM-schemes-fundamentals","published":1,"updated":"2022-06-24T01:58:09.627Z","_id":"cl4r5iz2b002dl8yb3rxw15q6","comments":1,"layout":"post","photos":[],"link":"","content":"<div class=\"note note-primary\">\n            <p>This is the <strong>essence</strong> of CFD, advecting with the discontinuities due to inviscid fluid PDEs. Several computational schemes dealing with them are introduced then tested in OpenFOAM on the 1D shockTube case.</p>\n          </div>\n<span id=\"more\"></span>\n<div class=\"note note-secondary\">\n            <p>This is a review of my graduate CFD course and the application of the theory to CFD software. The aim is to further the understanding of finite volume method and the <code>fvscheme</code> dict in OpenFOAM.</p>\n          </div>\n<p><strong>Reference books:</strong></p>\n<p>E.F. Toro, Riemann Solvers and Numerical Methods for Fluid Dynamics, Springer-Verlag.</p>\n<p>R.J. LeVeque, Finite Volume Methods for Hyperbolic Problems, Cambridge University Press.</p>\n<p><strong>Overview:</strong></p>\n\n<div class=\"markmap-container\" style=\"height:300px\">\n  <svg data=\"{&quot;t&quot;:&quot;root&quot;,&quot;d&quot;:0,&quot;v&quot;:&quot;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[1,2]},&quot;v&quot;:&quot;Scalar conservation laws&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[2,3]},&quot;v&quot;:&quot;conservation vs non-conservative&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[3,4]},&quot;v&quot;:&quot;1D simple Riemann problem for Burgers&#39; equation&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[4,5]},&quot;v&quot;:&quot;characteristics discontinuities and jump conditions&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[5,6]},&quot;v&quot;:&quot;weak solutions and entropy condition&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[6,7]},&quot;v&quot;:&quot;Numerical schemes for 1D discontinuities&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[7,8]},&quot;v&quot;:&quot;practical examples on one conservation law&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[8,10]},&quot;v&quot;:&quot;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[10,11]},&quot;v&quot;:&quot;System of conservation laws&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[11,12]},&quot;v&quot;:&quot;add complexity, system of conservation laws&quot;}]}],&quot;p&quot;:{}}\"></svg>\n</div>\n\n<h2 id=\"scalar-conservation-laws\">Scalar conservation laws</h2>\n<div class=\"note note-info\">\n            <p>1-D theory. Examples of 1-D hyperbolic conservation laws. Characteristics discontinuities and jump conditions. Weak solutions and entropy condition. Linear versus non-linear advection</p>\n          </div>\n<h3 id=\"challenges\">Challenges</h3>\n<p>As we all know, flow fluids are governed by 3 hyperbolic PDEs (conservation of mass, momentum and energy). These equations are highly non-linear and they can lead to discontinuities even with a smooth initial conditions, which is very difficult to solve numerically. Simple FDM will definitely fail on these discontinuities and shocks.</p>\n<p>Recall the incompressible NS equation that we've learned in the kindergarten: <span class=\"math display\">\\[\n\\frac{\\partial \\mathbf{V}}{\\partial t} + \\underbrace{\\left(\\boldsymbol{\\nabla}\\cdot\\mathbf{V}\\right)\\mathbf{V}}_{\\text{convection}} = \\frac{\\nabla p}{\\rho} + \\mathbf{g}+ \\underbrace{\\nu \\boldsymbol{\\nabla}^2\\mathbf{V}}_{\\text{diffusion}}\n\\]</span> the viscous diffusion term in the equation leads to parabolic equations with smooth solutions, which will save our life. But with very high <span class=\"math inline\">\\(Re\\)</span>, the equation reduces to pure <font color=#75147c>hyperbolic inviscid Euler Equation</font>, and the resultant discontinuity is a nightmare for most of the numerical schemes.</p>\n<p>The presence of discontinuities requires <font color=#75147c>weak solutions</font>, as oppose to <font color=#75147c>strong solutions</font>.</p>\n<p>However, the weak solutions give up the uniqueness in math, i.e there exist a large number of solutions that may not be physical acceptable, i.e. extra conditions are needed to justify the solution. They are:</p>\n<ul>\n<li><font color=#75147c>Rankine-Hugoniot</font> condition deals with the discontinuity</li>\n<li><font color=#75147c>Entropy</font> condition satisfies the physics</li>\n</ul>\n<div class=\"note note-info\">\n            <p>Just here to remind that we are dealing with inviscid flow, shocks, nothing to do with turbulence.</p>\n          </div>\n<h3 id=\"scalar-conservation-laws-1\">Scalar conservation laws</h3>\n<h4 id=\"d-law\">1D law</h4>\n<p><img src=\"1D scalar convection.png\" srcset=\"/img/loading.gif\" lazyload alt=\"1D scalar convection control volume\" style=\"zoom:70%;\" /></p>\n<p>First let's introduce a simple example to present the problem: consider an 1D control volume <span class=\"math inline\">\\([a,b]\\)</span>, during the time interval <span class=\"math inline\">\\([t_1,t_2]\\)</span> . The scalar conservation law can be stated as that during <span class=\"math inline\">\\([t_1,t_2]\\)</span> , change in total conserved quantity in <span class=\"math inline\">\\([a,b]\\)</span> equals to the net flux through the boundaries <span class=\"math inline\">\\(a\\)</span>, <span class=\"math inline\">\\(b\\)</span>:</p>\n<p><span class=\"math display\">\\[\n\\frac{d}{dt}\\int_a^bu(x,t) = -\\left[f(u(b,t))-f(u(a,t))\\right]\n\\]</span> where <span class=\"math inline\">\\(u(x,t)\\)</span> is called the conserved quantity while <span class=\"math inline\">\\(f\\)</span> denotes the flux. This equation often describes the <font color=#75147c>transport phenomena</font>.</p>\n<div class=\"note note-info\">\n            <p>You can not create, you can not destroy.</p>\n          </div>\n<h4 id=\"integral-differential-conservative-and-primitive-forms\">Integral, differential conservative and primitive forms</h4>\n<p><img src=\"2D scalar convection control volume.png\" srcset=\"/img/loading.gif\" lazyload alt=\"2D scalar convection control volume\" style=\"zoom:48%;\" /></p>\n<p>The 1D law can be extended in 2D with the relation, in <font color=#75147c>integral form</font>. <span class=\"math display\">\\[\n\\frac{d}{d t} \\int_{\\Omega} \\mathbf{u} d \\Omega+\\int_{\\Gamma} \\mathbf{f}(\\mathbf{u}) \\cdot \\mathbf{n} d \\Gamma=0\n\\]</span> <div class=\"note note-info\">\n            <p>The FVM and FEM solves the integral form, while the FDM solves the primitive form.</p>\n          </div></p>\n<p>Apply the Gauss divergence theorem the relation can be represented as <font color=#75147c>differential form</font>: <span class=\"math display\">\\[\n\\begin{aligned}\n\\int_{\\Omega}\\left\\{\\frac{\\partial \\mathbf{u}}{\\partial t}+\\nabla \\cdot \\mathbf{f}(\\mathbf{u})\\right\\} d \\Omega=0&amp;  \\\\ \n\\Rightarrow \n\\color{purple}{\n\\forall \\Omega,\\quad \\frac{\\partial \\mathbf{u}}{\\partial t}+\\nabla \\cdot \\mathbf{f}(\\mathbf{u})=0} &amp;\n\\end{aligned}\n\\]</span> above is called the <font color=#75147c>differential conservative form</font>. The only <span class=\"math inline\">\\(u\\)</span> changed in time is due to the flux <span class=\"math inline\">\\(f\\)</span>. There is no extra assumptions introduced.</p>\n<p>In comparison, with an assumption of <span class=\"math inline\">\\(\\mathbf{a} = \\frac{d\\mathbf{f}}{d\\mathbf{u}}\\)</span>, the equation can be rewritten with the chain rule, as the <font color=#75147c>differential primitive form</font> : <span class=\"math display\">\\[\n\\quad \\frac{\\partial \\mathbf{u}}{\\partial t}+\\mathbf{a}(\\mathbf{u})\\nabla \\cdot \\mathbf{u}=0, \\quad \\text{where }\\mathbf{a} =  \\frac{d\\mathbf{f}}{d\\mathbf{u}}\n\\]</span> This form is identical to above in mathematics, but it will lead to problems numerically when dealing with discontinuities (to be discussed later).</p>\n<h4 id=\"rankine-hugoniot-jump-condition\">Rankine-Hugoniot Jump condition</h4>\n<p><img src=\"shock wave.png\" srcset=\"/img/loading.gif\" lazyload alt=\"1D jump discontinuity illustration\" style=\"zoom:70%;\" /></p>\n<p>When dealing with discontinuities, the integral form is well defined, but not the differential forms. The differential solvers can't deal with the drastic derivatives so instead they solve an extra <font color=#75147c>jump condition</font> which can be derived from the well-defined integral form (discussed later).</p>\n<p>For an 1D jump discontinuity travelling at the speed <span class=\"math inline\">\\(s\\)</span>: <span class=\"math display\">\\[\nf(u_r)-f(u_l) = s(u_r-u_s)\n\\]</span> where <span class=\"math inline\">\\(u_r\\)</span>, <span class=\"math inline\">\\(u_l\\)</span> represent the speeds just at the left and the right of the discontinuity.</p>\n<h3 id=\"d-euler-equations\">1D Euler equations</h3>\n<p>Its time to introduce the 1D Euler equations: NS equations with 0 viscosity or heat conduction terms: <span class=\"math display\">\\[\n\\frac{\\partial}{\\partial t}\\left[\\begin{array}{l}\n\\rho \\\\\n\\rho u \\\\\n\\rho E\n\\end{array}\\right]+\\frac{\\partial}{\\partial x}\\left[\\begin{array}{l}\n\\rho u \\\\\n\\rho u^{2}+P \\\\\n\\rho u\\left(E+\\frac{P}{\\rho}\\right)\n\\end{array}\\right]=0\n\\]</span> And the conservation form is: <span class=\"math display\">\\[\n\\frac{\\partial \\mathbf{q}}{\\partial t}+\\frac{\\partial \\mathbf{F}(\\mathbf{q})}{\\partial x}=0\n\\]</span> for the quantity vector <span class=\"math inline\">\\(\\mathbf{q}\\)</span> with the flux vector <span class=\"math inline\">\\(\\mathbf{F}\\)</span>.</p>\n<h4 id=\"conservation-vs-non-conservation-form\">Conservation vs non-conservation form</h4>\n<p>Similar to before, with terms in a form of <span class=\"math inline\">\\(\\partial_x{uv}\\)</span>: <span class=\"math display\">\\[\n\\frac{\\partial uv}{\\partial x} \\neq u\\frac{\\partial v}{\\partial x}+ v\\frac{\\partial u}{\\partial x}\n\\]</span> When dealing with the discontinuities, the conservative LHS locates the shock directly, while the non-conservative RHS does not. (to be discussed later)</p>\n<h4 id=\"close-the-euler-equation\">Close the Euler equation</h4>\n<p>Unlike the well-posed NS equation, in Euler equation, we have 4 unknowns but only 3 equations. So an extra state equation, i.e. extra assumption of the gas state is needed. Sometimes it's the idea gas assumption <span class=\"math inline\">\\(p = \\rho RT\\)</span>, but for high <span class=\"math inline\">\\(Re\\)</span> compressible flows, equations of state are required to describe the relation between <span class=\"math inline\">\\(p, \\rho \\text{ and }T\\)</span>.</p>\n<div class=\"note note-primary\">\n            <p>We are going to use the 1D Euler equations to evaluate the numerical methods.</p>\n          </div>\n<h3 id=\"analytical-solutions-of-euler-equations\">Analytical solutions of Euler equations</h3>\n<h4 id=\"linear-advection-equation\">Linear Advection Equation</h4>\n<p>In 1D, the linear advection law for <span class=\"math inline\">\\(u(x,t)\\)</span> is: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial u }{\\partial t} + a(u)\\frac{\\partial u }{\\partial x} = 0\n\\]</span> where <span class=\"math inline\">\\(a(u)\\)</span> denotes the advection speed. Plus an <font color=#75147c>initial condition</font> <span class=\"math inline\">\\(u(x,0)\\)</span> and <font color=#75147c>boundary condition</font> (discuss later).</p>\n<h5 id=\"solution\">solution</h5>\n<p>This is a simple 2-variable PDE and we can apply the method of characteristics:</p>\n<ol type=\"1\">\n<li><p>Imagine a characteristic line <span class=\"math inline\">\\(s\\)</span>, we have the chain rule: <span class=\"math display\">\\[\n\\frac{d u(x,t)}{d s} = \\frac{d t}{d s}\\frac{\\partial u}{\\partial t} + \\frac{d x}{d s} \\frac{\\partial u}{\\partial x}\n\\]</span></p></li>\n<li><p>As a result we can construct, <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{d u(x,t)}{d s} = 0,\\quad\\frac{d t}{d s}=1, \\quad \\frac{d x}{d s}= a \\\\\n\\Rightarrow \\quad \\frac{d u}{0}=\\frac{d t}{1}=\\frac{d x}{a}= d s\n\\end{aligned}\n\\]</span></p></li>\n<li><p>Select the available equations we have the characteristic equation: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{d x}{d t} &amp;= a \\\\\n\\Rightarrow\\quad x &amp;= x_0 + a(u)t\n\\end{aligned}\n\\]</span> If <span class=\"math inline\">\\(u(x_0,0)=u_0\\)</span>, then <span class=\"math inline\">\\(\\frac{dx}{dt}=a(u_0)\\)</span>, the characteristic equation is therefore: <span class=\"math display\">\\[\n\\color{purple}\nx = x_0 + a(u_0)t\n\\]</span></p></li>\n<li><p>And the solution to the problem is: <span class=\"math display\">\\[\nu(x,t) = f(x_0) = f(x-a(u_0)t)\n\\]</span></p></li>\n</ol>\n<h4 id=\"linear-advection-equation-example\">Linear Advection Equation Example</h4>\n<p>Solve the following advection equation where <span class=\"math inline\">\\(a = 0.5\\)</span> <span class=\"math display\">\\[\n\\frac{\\partial u}{\\partial t} + a \\frac{\\partial u}{\\partial x }= 0\n\\]</span> with initial condition <span class=\"math display\">\\[\nu(x,0) = exp(-32x^2)\n\\]</span></p>\n<h5 id=\"solution-1\">solution</h5>\n<p>The characteristics are straight lines in the <span class=\"math inline\">\\((x,t)\\)</span> plane: <span class=\"math display\">\\[\nx = 0.5t+x_0\n\\]</span> And the solutions are therefore: <span class=\"math display\">\\[\nu(x,t) = f(x_0) = exp(-32(x-0.5t)^2)\n\\]</span> <img src=\"Linear Advection Solutions.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Linear Advection Characteristic Lines and Solutions, From my graduate course slides\" style=\"zoom:28%;\" /></p>\n<h4 id=\"inviscid-burgers-equation\">Inviscid Burgers' equation</h4>\n<p>In 1D, the inviscid Burgers' equation for <span class=\"math inline\">\\(u(x,t)\\)</span> is: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial u }{\\partial t} + \\frac{f(u) }{\\partial x} = 0,\\quad\\text{where }f(u)=\\frac{1}{2}u^2\n\\]</span> The conservative form for this equation <span class=\"math display\">\\[\n\\frac{\\partial u }{\\partial t} + \\frac{\\partial(\\frac{1}{2}u^2) }{\\partial x} = 0\n\\]</span> and the primitive form: <span class=\"math display\">\\[\n\\frac{\\partial u }{\\partial t} + u\\frac{\\partial u }{\\partial x} = 0\n\\]</span> same form as the 1D linear advection equation with <span class=\"math inline\">\\(a(u)=u\\)</span>.</p>\n<h4 id=\"burgers-equation-example\">Burgers' equation Example</h4>\n<p>Solve the advection equation: <span class=\"math display\">\\[\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }= 0\n\\]</span> with initial condition: <span class=\"math display\">\\[\nu(x,0) = 1-\\cos(x)\n\\]</span></p>\n<h5 id=\"solution-2\">solution</h5>\n<p>Similarly, the characteristics are described by: <span class=\"math display\">\\[\nx = x_0 + ut\n\\]</span> and the solution: <span class=\"math display\">\\[\nu = 1-\\cos(x-ut)\n\\]</span> which is <em><u>implicit</u></em>. It is can be plotted anyway:</p>\n<p><img src=\"Inviscid Burgers' equation Solutions.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Inviscid Burgers' equation Solutions, From my graduate course slides\" style=\"zoom:28%;\" /></p>\n<h5 id=\"discussion\">discussion</h5>\n<p>For non-linear conservation laws, the characteristics may cross within finite time. This would suggest a multi-valued solution which does not make sense physically.</p>\n<p>Where the characteristics start crossing, the solution become discontinuous. And the formation of discontinuities is possible even for smooth initial data. So the differential primitive form of the equations is no longer valid</p>\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span> only the integral form can deal with discontinuities. And the differential form can be completed by a <font color=#75147c>jump condition</font> derived from the integral form.</p>\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span> we need <font color=#75147c>weak solutions</font>. The mathematical theory of partial differential equations introduces the concept of weak solutions.</p>\n<h3 id=\"rankine-hugoniot-condition\">Rankine-Hugoniot condition</h3>\n<h4 id=\"the-riemann-problem\">The Riemann Problem</h4>\n<div class=\"note note-info\">\n            <p>In order to understand the behaviour of the solution at discontinuities, it is useful to start with a simplified problem.</p>\n          </div>\n<p>The Riemann problem is a conservation law with a single discontinuity. <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial u}{\\partial t} + \\frac{\\partial f(u)}{\\partial x} = 0\n\\]</span> with <span class=\"math display\">\\[\n\\color{purple}\nu(x, 0)= \\begin{cases}u_{L} &amp; x \\leq 0 \\\\ u_{R} &amp; x&gt;0\\end{cases}\n\\]</span> <img src=\"Riemann problem illustration.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Riemann problem illustration\" style=\"zoom:48%;\" /></p>\n<h4 id=\"shock-path\">Shock Path</h4>\n<p><img src=\"shock path control volume.png\" srcset=\"/img/loading.gif\" lazyload alt=\"shock path control volume\" style=\"zoom:80%;\" /></p>\n<p>Take the control volume between boundaries <span class=\"math inline\">\\(x_L\\)</span> and <span class=\"math inline\">\\(x_R\\)</span>, which are taken sufficient close to the shock so that spatial variations of the solution become unimportant. and are taken sufficient apart from the shock so that the boundary will note interfere with the shock motion over time interval <span class=\"math inline\">\\(\\delta t\\)</span>.</p>\n<p>Recall the integral function: <span class=\"math display\">\\[\n\\frac{d}{dt}\\int_{x_L}^{x_R}udx = f(u_L)-f(u_R)\n\\]</span> If the position of the shock is <span class=\"math inline\">\\(x = X(t)\\)</span>, with <span class=\"math inline\">\\(x_L&lt; X (t) &lt;x_R\\)</span>, the values of <span class=\"math inline\">\\(u(x,t)\\)</span> inside the integral are close to the constants <span class=\"math inline\">\\(u_L\\)</span> and <span class=\"math inline\">\\(u_R\\)</span> and we can write: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{d}{dt}\\int_{x_L}^{X}u_Ldx + \\frac{d}{dt}\\int_{X}^{x_R}u_Rdx= f(u_L)-f(u_R)\\\\\n\\frac{d}{dt}\\left[(x_L-X)u_L + (X-x_R)u_R\\right]= f(u_L)-f(u_R)\\\\\n\\end{aligned}\n\\]</span></p>\n<p>Given the shock speed (slope of the shock path) <span class=\"math inline\">\\(s = \\frac{dX}{dt}\\)</span>, we have: <span class=\"math display\">\\[\n\\begin{aligned}\ns\\left(u_L - u_R\\right)&amp;= f(u_L)-f(u_R)\\\\\n\\color{purple}\ns= \\frac{dX}{dt}&amp;\\color{purple}\n= \\frac{f(u_L)-f(u_R)}{\\left(u_L - u_R\\right)}= \\frac{f(u_R)-f(u_L)}{\\left(u_R - u_L\\right)}\n\\end{aligned}\n\\]</span> The equation above is the <font color=#75147c>Rankine-Hugoniot condition</font>, also called the \"jump condition\".</p>\n<p>Correspondingly, <font color=#75147c>weak solutions</font> represents the solutions of the PDE where the solution is smooth and of a Rankine-Hugoniot condition at discontinuities. And they are <font color=#75147c>not unique</font>.</p>\n<div class=\"note note-info\">\n            <p>Strong solution <span class=\"math inline\">\\(\\Rightarrow\\)</span> weak solution</p><p>Weak solution <span class=\"math inline\">\\(\\nLeftarrow\\)</span> Strong solution</p>\n          </div>\n<h3 id=\"non-uniqueness-of-weak-solutions\">Non-uniqueness of weak solutions</h3>\n<h4 id=\"example-of-riemann-problem-with-burgerss-equation\">Example of Riemann Problem with Burgers's equation</h4>\n<p>Consider the <a href=\"#inviscid-burgers-equation\">Burgers' equation</a> under a <a href=\"#the-riemann-problem\">Riemann Problem</a>: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&amp;= 0, \\\\\n\\text{with }\nu(x, 0)&amp;= \\begin{cases}1 &amp; x \\leq 0 \\\\ 0 &amp; x&gt;0\\end{cases}\n\\end{aligned}\n\\]</span> The characteristics are of the form: <span class=\"math inline\">\\(x = x_0 + ut\\)</span></p>\n<p>In <span class=\"math inline\">\\(x-t\\)</span> plane, the characteristics line: <span class=\"math display\">\\[\n\\begin{cases} x = t - x_0 &amp; x_0 \\leq 0 \\\\ x = x_0 &amp; x_0 &gt; 0\\end{cases}\n\\]</span> And the according to the Rankine-Hugonoit condition, the speed of the shock is: <span class=\"math display\">\\[\ns = \\frac{f(u_L)-f(u_R)}{\\left(u_L - u_R\\right)}= \\frac{-1/2-0}{\\left(1-0\\right)} = \\frac{1}{2}\n\\]</span> and the shock path is: <span class=\"math display\">\\[\nx = \\frac{1}{2} t\n\\]</span> therefore, the solution is: <span class=\"math display\">\\[\nu(x,t) = \\begin{cases} 1 &amp; x \\leq \\frac{1}{2}t \\\\ 0 &amp; x&gt; \\frac{1}{2}t\\end{cases}\n\\]</span> <img src=\"Burgers's equation under Riemann Problem with uL = 1, uR=0.png\" srcset=\"/img/loading.gif\" lazyload alt=\"General solution (left) and characteristics (right) of Burgers's equation under Riemann Problem. From my graduate course slides\" style=\"zoom:50%;\" /></p>\n<h4 id=\"upwind-riemann-problem-with-burgerss-equation\">Upwind Riemann Problem with Burgers's equation</h4>\n<p>For the upwind case: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&amp;= 0, \\\\\n\\text{with }\nu(x, 0)&amp;= \\begin{cases}u_L &amp; x \\leq 0 \\\\ u_R &amp; x&gt;0\\end{cases}\n\\end{aligned}\n\\]</span> with <span class=\"math inline\">\\(u_L&gt;u_R\\)</span>.</p>\n<p>And the shock is created with a speed: <span class=\"math display\">\\[\ns = \\frac{1}{2}(u_R+u_L)\n\\]</span> and the solution: <span class=\"math display\">\\[\nu(x,t) = \\begin{cases} u_L &amp; x \\leq \\frac{1}{2}t \\\\ u_R &amp; x&gt; \\frac{1}{2}t\\end{cases}\n\\]</span> <img src=\"Burgers's equation under Riemann Problem general solution.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Solution (left) and characteristics (right) of Burgers's equation under Riemann Problem with uL = 1, uR=0. From my graduate course slides\" style=\"zoom:50%;\" /></p>\n<h4 id=\"example-of-non-unique-downwind-riemann-problem-with-burgerss-equation\">Example of non-unique downwind Riemann Problem with Burgers's equation</h4>\n<p>Reverse the initial condition in the previous example:</p>\n<p><span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&amp;= 0, \\\\\n\\text{with }\nu(x, 0)&amp;= \\begin{cases}0 &amp; x \\leq 0 \\\\ 1 &amp; x&gt;0\\end{cases}\n\\end{aligned}\n\\]</span> the characteristics become:</p>\n<p><img src=\"Burgers's equation under Riemann Problem with uL = 0, uR=1.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Solution (left) and characteristics (right) of Burgers's equation under Riemann Problem with uL = 1, uR=0. From my graduate course slides\" style=\"zoom:50%;\" /></p>\n<p>Solution in the blue area (<span class=\"math inline\">\\(0&lt;x&lt;t\\)</span>) is not defined. So here proposes 2 possible solutions, both are mathematical acceptable:</p>\n<p>Solution A: <span class=\"math display\">\\[\nu(x, t)= \\begin{cases}0 &amp; \\text { if } \\quad \\frac{x}{t}&lt;s(=0.5) \\\\ 1 &amp; \\text { if } \\quad \\frac{x}{t}&gt;s(=0.5)\\end{cases}\n\\]</span> <img src=\"Expansion shock solution to the Riemann Problem.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Expansion shock solution to the Riemann Problem\" style=\"zoom:50%;\" /></p>\n<p>Solution B: <span class=\"math display\">\\[\nu(x, t)=\\left\\{\\begin{array}{ccc}\n0 &amp; \\text { if } &amp; \\frac{x}{t}&lt;0 \\\\\n\\frac{x}{t} &amp; \\text { if } &amp; 0&lt;\\frac{x}{t}&lt;1 \\\\\n1 &amp; \\text { if } &amp; \\frac{x}{t}&gt;1\n\\end{array}\\right.\n\\]</span> <img src=\"Rarefaction wave solution to the Riemann Problem.png\" srcset=\"/img/loading.gif\" lazyload alt=\"Rarefaction wave solution to the Riemann Problem\" style=\"zoom:50%;\" /></p>\n<div class=\"note note-info\">\n            <p>A little spoiler alert there: Solution B is physical, discussed in the <a href=\"#non-uniqueness-and-entropy-conditions\">next section</a>.</p>\n          </div>\n<h4 id=\"exact-solution-to-riemann-problem-with-burgerss-equation\">Exact solution to Riemann Problem with Burgers's equation</h4>\n<p>In conclusion,</p>\n<p>For the Riemann Problem with Burgers's equation: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&amp;= 0, \\\\\n\\text{with }\nu(x, 0)&amp;= \\begin{cases}u_L &amp; x \\leq 0 \\\\ u_R &amp; x&gt;0\\end{cases}\n\\end{aligned}\n\\]</span></p>\n<ul>\n<li><p>with <span class=\"math inline\">\\(u_L&gt;u_R\\)</span></p>\n<p>A shock wave is created with a speed: <span class=\"math display\">\\[\nV_s = \\frac{u_L+u_R}{2}\n\\]</span> and the exact solution is: <span class=\"math display\">\\[\nu(x, t)=\\left\\{\\begin{array}{ccc}\nu_L &amp; \\text { if } &amp; \\frac{x}{t}\\leq V_s \\\\\nu_R &amp; \\text { if } &amp; \\frac{x}{t}&gt;V_s\n\\end{array}\\right.\n\\]</span></p></li>\n<li><p>with <span class=\"math inline\">\\(u_L&lt;u_R\\)</span></p>\n<p>the exact solution is the rarefaction wave: <span class=\"math display\">\\[\nu(x, t)=\\left\\{\\begin{array}{ccc}\nu_L &amp; \\text { if } &amp; \\frac{x}{t}&lt;0 \\\\\n\\frac{x}{t} &amp; \\text { if } &amp; 0&lt;\\frac{x}{t}&lt;1 \\\\\nu_R &amp; \\text { if } &amp; \\frac{x}{t}&gt;1\n\\end{array}\\right.\n\\]</span> if <span class=\"math inline\">\\(u_L = -u_R\\)</span>, we have a sonic rarefaction wave.</p></li>\n</ul>\n<h3 id=\"entropy-conditions\">Entropy Conditions</h3>\n<p>Why solution A is wrong? we need to impose additional conditions. There are two ways.</p>\n<ul>\n<li><p>Add a small diffusion term (2 <sup>nd</sup> order) manually on the RHS to remove the discontinuity. The weak solution then must satisfy: <span class=\"math display\">\\[\n\\frac{\\partial u^\\epsilon}{\\partial t} + \\frac{\\partial f(u^\\epsilon)}{\\partial x} = \\epsilon\\frac{\\partial^2u^\\epsilon}{\\partial x^\\epsilon}\n\\]</span> where <span class=\"math inline\">\\(\\epsilon\\)</span> is the <font color=#75147c>viscosity coefficient</font>, it introduces the dissipation, known as the vanishing viscosity concept, into the equation to smooth the solution. A little bit cheating but most of people do this.</p></li>\n<li><p>Add the <font color=#75147c>entropy solution</font></p>\n<div class=\"note note-info\">\n            <p>I first hearted Entropy back in my undergraduate thermodynamic course. But I still don't know what is Entropy. So here are some answers:</p><p>In gas dynamics, entropy is a constant physical quantity along particles in smooth flow which can jump to a higher value through a shock.</p><p>The second law of thermodynamics says that entropy can never go down.</p><p>For an evolution equation the information should always flow from the initial data.</p><p>We can see it is very difficult to define it, but in order to translate the defination into the entropy condition, we see entropy as the extra amount of energy that is not available to the system.</p>\n          </div>\n<p>There are again two options of entropy condition:</p>\n<ul>\n<li><p><font color=#75147c>Convex (concave) fluxes / Lax entropy condition</font> <span class=\"math display\">\\[\nf&#39;(u_L) &gt; s &gt; f&#39;(u_R)\n\\]</span> and the characteristics must run into the shock, not emerge from it.</p></li>\n<li><p><font color=#75147c>Oleinik entropy condition</font></p>\n<p>Similar to Lax entropy condition, it says: <span class=\"math display\">\\[\n\\frac{f(u)-f(u_L)}{u-u_L}\\geq s \\geq \\frac{f(u_R)-f(u)}{u_R-u}\n\\]</span></p></li>\n</ul>\n<p>and Lax and Oleinik are equivalent if <span class=\"math inline\">\\(f(u)\\)</span> is strictly convex i.e. <span class=\"math inline\">\\(f&#39;&#39;(u)&lt;0\\)</span>.</p></li>\n</ul>\n<h2 id=\"numerical-representation-of-discontinuities\">Numerical representation of discontinuities</h2>\n<div class=\"note note-info\">\n            <p>Requirements on numerical schemes. Conservative discretisation: Lax-Wendroff theorem. First versus second order schemes. Representation of discontinuities: physical aspects, shock fitting/capturing.</p>\n          </div>\n<h3 id=\"problems-with-lax-equivalence-theorem\">Problems with Lax Equivalence Theorem</h3>\n<p>There are 3 fundamental properties of a numerical scheme:</p>\n<ul>\n<li><p>Consistency: how good you approximate operators and functions.</p></li>\n<li><p>Convergence: error between the exact and discrete solutions converges to zero.</p></li>\n<li><p>Stability: solution of the difference equation is not too sensitive to small perturbations.</p></li>\n</ul>\n<p>The convergence needs to be evaluated with exact solutions. So we always need analytical solutions to verify it. If we don't have access to the analytical solutions, we have a <font color=#75147c>Lax Equivalence Theorem</font>says <span class=\"math display\">\\[\n\\text{consistency + stability $\\Rightarrow$ convergence}\n\\]</span> It is a fundamental convergence theorem but</p>\n<ul>\n<li>it is valid <font color=#75147c>only for linear PDEs</font> and there is no non-linear equivalent theorem</li>\n<li>this theorem <font color=#75147c>does not tell if the weak solution physically acceptable or not</font>.</li>\n</ul>\n<p>For non-linear PDEs, we only have one experience,</p>\n<p>If a scheme is stable on linear PDEs, it will often (not all the time) be stable on non-linear PDEs. If a scheme is unstable on linear, it won't be stable on non-linear.</p>\n<p>So the work flow is, 1. Given a non-linear PDE, 2. Linearise it to explore the stabilities of schemes on it. 3. Test the winners on non-linear PDEs.</p>\n<h3 id=\"d-linear-convection-equation\">1D linear convection equation</h3>\n<p>First we consider a <font color=#75147c>linear</font> case, linear convection equation: <span class=\"math display\">\\[\n\\frac{\\partial u}{\\partial t} + a\\frac{\\partial u}{\\partial x} = 0\n\\]</span> with <span class=\"math inline\">\\(a\\)</span> a positive scalar constant, representing the wave speed. So we have: <span class=\"math display\">\\[\nf(u) = au\n\\]</span></p>\n<h5 id=\"numerical-scheme\">Numerical scheme</h5>\n<p>try to solve it numerically, with finite difference, forward difference in time and central difference in space. we have: <span class=\"math display\">\\[\n\\frac{u^{n+1}_i-u^n_i}{\\Delta t} + a \\frac{u^n_{i+1}-u^n_{i-1}}{2\\Delta x} = 0\n\\]</span></p>\n<p><span class=\"math display\">\\[\nu^{n+1}_i = u^n_i - \\frac{a\\Delta t}{\\Delta x}\\left(\\frac{u^n_{i+1}-u^n_{i-1}}{2} \\right) = 0\n\\]</span></p>\n<p>It is consistency, and the Von Neumann analysis shows it is stable if the CFL condition (Courant number <span class=\"math inline\">\\(a\\frac{\\Delta t}{\\Delta x}&lt;1\\)</span>) is satisfied. It should converge to the exact solution.</p>\n<h5 id=\"numerical-practice\">Numerical practice</h5>\n<h2 id=\"systems-of-conservation-laws\">Systems of conservation laws</h2>\n<div class=\"note note-info\">\n            <p>Jacobian matrices, linearized equations, conservative and characteristic variables. Rankine-Hugoniot jump conditions. Boundary conditions.</p>\n          </div>\n<h2 id=\"numerical-schemes-for-non-linear-conservation-laws\">Numerical schemes for non-linear conservation laws</h2>\n<div class=\"note note-info\">\n            <p>It is still an active research area and these are the classical methods:</p><p>Centred schemes: one-step and two-step Lax Wendroff, MacCormack predictor-corrector. Artificial dissipation. Upwind schemes: flux vector and flux difference splitting. Monotone schemes: Godunov and Harten theorems. Exact and approximate Riemann solvers. High-order upwind schemes: the TVD property. The construction of TVD schemes using slope and flux limiters. WENO schemes: weighted essentially non-oscillatory methods</p>\n          </div>\n<h2 id=\"numerical-schemes-for-multi-dimensional-problems\">Numerical schemes for multi-dimensional problems</h2>\n<div class=\"note note-info\">\n            <p>Finite differences and finite volume. Computational domain and boundary conditions.</p>\n          </div>\n<h2 id=\"openfoam-demo-on-shockwave\">OpenFOAM demo on shockwave</h2>\n<div id=\"echarts5811\" style=\"width: 85%;height: 400px;margin: 0 auto\"></div>\n<script type=\"text/javascript\" src=\"https://cdn.bootcss.com/echarts/4.2.0-rc.2/echarts.min.js\"></script>\n<script type=\"text/javascript\" src=\"https://www.makeapie.com/dep/echarts/map/js/china.js\"></script>\n<script type=\"text/javascript\">\n  // domecharts\n  var myChart = echarts.init(document.getElementById('echarts5811'));\n  // \n  let legends = ['exact', 'linear', 'upwind', 'linearUpwind', 'QUICK', 'TVD-vanLeer', 'TVD-Minmod', 'TVD-SuperBee']\nlet xaxis = [0.0005, 0.0015, 0.0025, 0.0035, 0.0045, 0.0055, 0.0065, 0.0075, 0.0085, 0.0095, 0.0105, 0.0115, 0.0125, 0.0135, 0.0145, 0.0155, 0.0165, 0.0175, 0.0185, 0.0195, 0.0205, 0.0215, 0.0225, 0.0235, 0.0245, 0.0255, 0.0265, 0.0275, 0.0285, 0.0295, 0.0305, 0.0315, 0.0325, 0.0335, 0.0345, 0.0355, 0.0365, 0.0375, 0.0385, 0.0395, 0.0405, 0.0415, 0.0425, 0.0435, 0.0445, 0.0455, 0.0465, 0.0475, 0.0485, 0.0495, 0.0505, 0.0515, 0.0525, 0.0535, 0.0545, 0.0555, 0.0565, 0.0575, 0.0585, 0.0595, 0.0605, 0.0615, 0.0625, 0.0635, 0.0645, 0.0655, 0.0665, 0.0675, 0.0685, 0.0695, 0.0705, 0.0715, 0.0725, 0.0735, 0.0745, 0.0755, 0.0765, 0.0775, 0.0785, 0.0795, 0.0805, 0.0815, 0.0825, 0.0835, 0.0845, 0.0855, 0.0865, 0.0875, 0.0885, 0.0895, 0.0905, 0.0915, 0.0925, 0.0935, 0.0945, 0.0955, 0.0965, 0.0975, 0.0985, 0.0995, 0.1005, 0.1015, 0.1025, 0.1035, 0.1045, 0.1055, 0.1065, 0.1075, 0.1085, 0.1095, 0.1105, 0.1115, 0.1125, 0.1135, 0.1145, 0.1155, 0.1165, 0.1175, 0.1185, 0.1195, 0.1205, 0.1215, 0.1225, 0.1235, 0.1245, 0.1255, 0.1265, 0.1275, 0.1285, 0.1295, 0.1305, 0.1315, 0.1325, 0.1335, 0.1345, 0.1355, 0.1365, 0.1375, 0.1385, 0.1395, 0.1405, 0.1415, 0.1425, 0.1435, 0.1445, 0.1455, 0.1465, 0.1475, 0.1485, 0.1495, 0.1505, 0.1515, 0.1525, 0.1535, 0.1545, 0.1555, 0.1565, 0.1575, 0.1585, 0.1595, 0.1605, 0.1615, 0.1625, 0.1635, 0.1645, 0.1655, 0.1665, 0.1675, 0.1685, 0.1695, 0.1705, 0.1715, 0.1725, 0.1735, 0.1745, 0.1755, 0.1765, 0.1775, 0.1785, 0.1795, 0.1805, 0.1815, 0.1825, 0.1835, 0.1845, 0.1855, 0.1865, 0.1875, 0.1885, 0.1895, 0.1905, 0.1915, 0.1925, 0.1935, 0.1945, 0.1955, 0.1965, 0.1975, 0.1985, 0.1995, 0.2005, 0.2015, 0.2025, 0.2035, 0.2045, 0.2055, 0.2065, 0.2075, 0.2085, 0.2095, 0.2105, 0.2115, 0.2125, 0.2135, 0.2145, 0.2155, 0.2165, 0.2175, 0.2185, 0.2195, 0.2205, 0.2215, 0.2225, 0.2235, 0.2245, 0.2255, 0.2265, 0.2275, 0.2285, 0.2295, 0.2305, 0.2315, 0.2325, 0.2335, 0.2345, 0.2355, 0.2365, 0.2375, 0.2385, 0.2395, 0.2405, 0.2415, 0.2425, 0.2435, 0.2445, 0.2455, 0.2465, 0.2475, 0.2485, 0.2495, 0.2505, 0.2515, 0.2525, 0.2535, 0.2545, 0.2555, 0.2565, 0.2575, 0.2585, 0.2595, 0.2605, 0.2615, 0.2625, 0.2635, 0.2645, 0.2655, 0.2665, 0.2675, 0.2685, 0.2695, 0.2705, 0.2715, 0.2725, 0.2735, 0.2745, 0.2755, 0.2765, 0.2775, 0.2785, 0.2795, 0.2805, 0.2815, 0.2825, 0.2835, 0.2845, 0.2855, 0.2865, 0.2875, 0.2885, 0.2895, 0.2905, 0.2915, 0.2925, 0.2935, 0.2945, 0.2955, 0.2965, 0.2975, 0.2985, 0.2995, 0.3005, 0.3015, 0.3025, 0.3035, 0.3045, 0.3055, 0.3065, 0.3075, 0.3085, 0.3095, 0.3105, 0.3115, 0.3125, 0.3135, 0.3145, 0.3155, 0.3165, 0.3175, 0.3185, 0.3195, 0.3205, 0.3215, 0.3225, 0.3235, 0.3245, 0.3255, 0.3265, 0.3275, 0.3285, 0.3295, 0.3305, 0.3315, 0.3325, 0.3335, 0.3345, 0.3355, 0.3365, 0.3375, 0.3385, 0.3395, 0.3405, 0.3415, 0.3425, 0.3435, 0.3445, 0.3455, 0.3465, 0.3475, 0.3485, 0.3495, 0.3505, 0.3515, 0.3525, 0.3535, 0.3545, 0.3555, 0.3565, 0.3575, 0.3585, 0.3595, 0.3605, 0.3615, 0.3625, 0.3635, 0.3645, 0.3655, 0.3665, 0.3675, 0.3685, 0.3695, 0.3705, 0.3715, 0.3725, 0.3735, 0.3745, 0.3755, 0.3765, 0.3775, 0.3785, 0.3795, 0.3805, 0.3815, 0.3825, 0.3835, 0.3845, 0.3855, 0.3865, 0.3875, 0.3885, 0.3895, 0.3905, 0.3915, 0.3925, 0.3935, 0.3945, 0.3955, 0.3965, 0.3975, 0.3985, 0.3995, 0.4005, 0.4015, 0.4025, 0.4035, 0.4045, 0.4055, 0.4065, 0.4075, 0.4085, 0.4095, 0.4105, 0.4115, 0.4125, 0.4135, 0.4145, 0.4155, 0.4165, 0.4175, 0.4185, 0.4195, 0.4205, 0.4215, 0.4225, 0.4235, 0.4245, 0.4255, 0.4265, 0.4275, 0.4285, 0.4295, 0.4305, 0.4315, 0.4325, 0.4335, 0.4345, 0.4355, 0.4365, 0.4375, 0.4385, 0.4395, 0.4405, 0.4415, 0.4425, 0.4435, 0.4445, 0.4455, 0.4465, 0.4475, 0.4485, 0.4495, 0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585, 0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675, 0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765, 0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855, 0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945, 0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035, 0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125, 0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215, 0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305, 0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395, 0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485, 0.5495, 0.5505, 0.5515, 0.5525, 0.5535, 0.5545, 0.5555, 0.5565, 0.5575, 0.5585, 0.5595, 0.5605, 0.5615, 0.5625, 0.5635, 0.5645, 0.5655, 0.5665, 0.5675, 0.5685, 0.5695, 0.5705, 0.5715, 0.5725, 0.5735, 0.5745, 0.5755, 0.5765, 0.5775, 0.5785, 0.5795, 0.5805, 0.5815, 0.5825, 0.5835, 0.5845, 0.5855, 0.5865, 0.5875, 0.5885, 0.5895, 0.5905, 0.5915, 0.5925, 0.5935, 0.5945, 0.5955, 0.5965, 0.5975, 0.5985, 0.5995, 0.6005, 0.6015, 0.6025, 0.6035, 0.6045, 0.6055, 0.6065, 0.6075, 0.6085, 0.6095, 0.6105, 0.6115, 0.6125, 0.6135, 0.6145, 0.6155, 0.6165, 0.6175, 0.6185, 0.6195, 0.6205, 0.6215, 0.6225, 0.6235, 0.6245, 0.6255, 0.6265, 0.6275, 0.6285, 0.6295, 0.6305, 0.6315, 0.6325, 0.6335, 0.6345, 0.6355, 0.6365, 0.6375, 0.6385, 0.6395, 0.6405, 0.6415, 0.6425, 0.6435, 0.6445, 0.6455, 0.6465, 0.6475, 0.6485, 0.6495, 0.6505, 0.6515, 0.6525, 0.6535, 0.6545, 0.6555, 0.6565, 0.6575, 0.6585, 0.6595, 0.6605, 0.6615, 0.6625, 0.6635, 0.6645, 0.6655, 0.6665, 0.6675, 0.6685, 0.6695, 0.6705, 0.6715, 0.6725, 0.6735, 0.6745, 0.6755, 0.6765, 0.6775, 0.6785, 0.6795, 0.6805, 0.6815, 0.6825, 0.6835, 0.6845, 0.6855, 0.6865, 0.6875, 0.6885, 0.6895, 0.6905, 0.6915, 0.6925, 0.6935, 0.6945, 0.6955, 0.6965, 0.6975, 0.6985, 0.6995, 0.7005, 0.7015, 0.7025, 0.7035, 0.7045, 0.7055, 0.7065, 0.7075, 0.7085, 0.7095, 0.7105, 0.7115, 0.7125, 0.7135, 0.7145, 0.7155, 0.7165, 0.7175, 0.7185, 0.7195, 0.7205, 0.7215, 0.7225, 0.7235, 0.7245, 0.7255, 0.7265, 0.7275, 0.7285, 0.7295, 0.7305, 0.7315, 0.7325, 0.7335, 0.7345, 0.7355, 0.7365, 0.7375, 0.7385, 0.7395, 0.7405, 0.7415, 0.7425, 0.7435, 0.7445, 0.7455, 0.7465, 0.7475, 0.7485, 0.7495, 0.7505, 0.7515, 0.7525, 0.7535, 0.7545, 0.7555, 0.7565, 0.7575, 0.7585, 0.7595, 0.7605, 0.7615, 0.7625, 0.7635, 0.7645, 0.7655, 0.7665, 0.7675, 0.7685, 0.7695, 0.7705, 0.7715, 0.7725, 0.7735, 0.7745, 0.7755, 0.7765, 0.7775, 0.7785, 0.7795, 0.7805, 0.7815, 0.7825, 0.7835, 0.7845, 0.7855, 0.7865, 0.7875, 0.7885, 0.7895, 0.7905, 0.7915, 0.7925, 0.7935, 0.7945, 0.7955, 0.7965, 0.7975, 0.7985, 0.7995, 0.8005, 0.8015, 0.8025, 0.8035, 0.8045, 0.8055, 0.8065, 0.8075, 0.8085, 0.8095, 0.8105, 0.8115, 0.8125, 0.8135, 0.8145, 0.8155, 0.8165, 0.8175, 0.8185, 0.8195, 0.8205, 0.8215, 0.8225, 0.8235, 0.8245, 0.8255, 0.8265, 0.8275, 0.8285, 0.8295, 0.8305, 0.8315, 0.8325, 0.8335, 0.8345, 0.8355, 0.8365, 0.8375, 0.8385, 0.8395, 0.8405, 0.8415, 0.8425, 0.8435, 0.8445, 0.8455, 0.8465, 0.8475, 0.8485, 0.8495, 0.8505, 0.8515, 0.8525, 0.8535, 0.8545, 0.8555, 0.8565, 0.8575, 0.8585, 0.8595, 0.8605, 0.8615, 0.8625, 0.8635, 0.8645, 0.8655, 0.8665, 0.8675, 0.8685, 0.8695, 0.8705, 0.8715, 0.8725, 0.8735, 0.8745, 0.8755, 0.8765, 0.8775, 0.8785, 0.8795, 0.8805, 0.8815, 0.8825, 0.8835, 0.8845, 0.8855, 0.8865, 0.8875, 0.8885, 0.8895, 0.8905, 0.8915, 0.8925, 0.8935, 0.8945, 0.8955, 0.8965, 0.8975, 0.8985, 0.8995, 0.9005, 0.9015, 0.9025, 0.9035, 0.9045, 0.9055, 0.9065, 0.9075, 0.9085, 0.9095, 0.9105, 0.9115, 0.9125, 0.9135, 0.9145, 0.9155, 0.9165, 0.9175, 0.9185, 0.9195, 0.9205, 0.9215, 0.9225, 0.9235, 0.9245, 0.9255, 0.9265, 0.9275, 0.9285, 0.9295, 0.9305, 0.9315, 0.9325, 0.9335, 0.9345, 0.9355, 0.9365, 0.9375, 0.9385, 0.9395, 0.9405, 0.9415, 0.9425, 0.9435, 0.9445, 0.9455, 0.9465, 0.9475, 0.9485, 0.9495, 0.9505, 0.9515, 0.9525, 0.9535, 0.9545, 0.9555, 0.9565, 0.9575, 0.9585, 0.9595, 0.9605, 0.9615, 0.9625, 0.9635, 0.9645, 0.9655, 0.9665, 0.9675, 0.9685, 0.9695, 0.9705, 0.9715, 0.9725, 0.9735, 0.9745, 0.9755, 0.9765, 0.9775, 0.9785, 0.9795, 0.9805, 0.9815, 0.9825, 0.9835, 0.9845, 0.9855, 0.9865, 0.9875, 0.9885, 0.9895, 0.9905, 0.9915, 0.9925, 0.9935, 0.9945, 0.9955, 0.9965, 0.9975, 0.9985, 0.9995];\nlet data0 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0068466305166028, 0.01517996384993614, 0.023513297183269482, 0.031846630516602824, 0.04017996384993616, 0.04851329718326951, 0.056846630516602846, 0.06517996384993618, 0.07351329718326953, 0.08184663051660288, 0.0901799638499362, 0.09851329718326955, 0.1068466305166029, 0.11517996384993623, 0.12351329718326957, 0.13184663051660292, 0.14017996384993625, 0.1485132971832696, 0.15684663051660286, 0.1651799638499362, 0.17351329718326952, 0.18184663051660288, 0.1901799638499362, 0.19851329718326954, 0.2068466305166029, 0.21517996384993623, 0.22351329718326957, 0.23184663051660293, 0.24017996384993626, 0.2485132971832696, 0.25684663051660295, 0.2651799638499363, 0.2735132971832696, 0.28184663051660297, 0.29017996384993583, 0.2985132971832692, 0.30684663051660255, 0.31517996384993585, 0.3235132971832692, 0.33184663051660257, 0.3401799638499359, 0.34851329718326923, 0.3568466305166026, 0.3651799638499359, 0.37351329718326925, 0.3818466305166026, 0.3901799638499359, 0.3985132971832693, 0.40684663051660264, 0.41517996384993594, 0.4235132971832693, 0.43184663051660266, 0.44017996384993596, 0.4485132971832693, 0.4568466305166027, 0.465179963849936, 0.47351329718326934, 0.4818466305166027, 0.490179963849936, 0.49851329718326937, 0.5068466305166027, 0.515179963849936, 0.5235132971832694, 0.5318466305166027, 0.540179963849936, 0.5485132971832695, 0.5568466305166028, 0.5651799638499361, 0.5735132971832695, 0.5818466305166028, 0.5901799638499361, 0.5985132971832695, 0.6068466305166028, 0.6151799638499361, 0.6235132971832695, 0.6318466305166028, 0.6401799638499361, 0.6485132971832696, 0.6568466305166029, 0.6651799638499362, 0.6735132971832696, 0.6818466305166029, 0.6901799638499362, 0.6985132971832696, 0.7068466305166029, 0.7151799638499362, 0.7235132971832696, 0.7318466305166029, 0.7401799638499362, 0.7485132971832696, 0.756846630516603, 0.7651799638499363, 0.7735132971832697, 0.781846630516603, 0.7901799638499363, 0.7985132971832697, 0.806846630516603, 0.8151799638499363, 0.8235132971832692, 0.8318466305166026, 0.840179963849936, 0.8485132971832692, 0.8568466305166027, 0.8651799638499358, 0.8735132971832693, 0.8818466305166025, 0.890179963849936, 0.8985132971832692, 0.9068466305166027, 0.9151799638499358, 0.9235132971832694, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];\nlet data1 = [4.7497782e-21, 1.2236753e-11, 1.4130822e-11, 1.4288661e-11, 3.4924231e-11, 2.9147543e-11, 3.5115528e-11, 4.4161819e-11, 3.215849e-11, 5.8045656e-11, 5.6981576e-11, 7.4404121e-11, 5.3422194e-11, 5.1797341e-11, 3.9958742e-11, 4.3513123e-11, 4.3012595e-11, 2.8551867e-11, 1.0164615e-11, 3.6251191e-11, 1.5676756e-11, 4.3760219e-11, 2.087822e-11, 3.2388469e-11, 1.0404042e-13, 2.2323671e-11, 5.9775439e-12, 1.5878278e-11, 2.5413204e-12, 1.3496131e-11, 9.0037193e-12, 6.4866305e-12, 3.0908672e-12, 9.3806435e-12, 1.8018999e-11, 3.9618166e-11, 3.3207453e-11, 3.636568e-11, 1.6921461e-11, 2.4158606e-11, 1.5541036e-11, 2.1612839e-11, 2.2662135e-12, 3.6244967e-11, 2.1388863e-11, 4.0860982e-11, 2.0243752e-11, 4.4159152e-11, 3.7287927e-11, 4.503816e-11, 4.2794622e-11, 3.2505514e-11, 3.5482004e-11, 3.3629729e-11, 5.203321e-11, 3.059744e-11, 3.5895609e-11, 2.4423153e-11, 2.8592995e-11, 9.0477364e-12, 1.1918963e-11, 1.11291e-11, 9.5233656e-12, 1.9686646e-11, 1.4684259e-11, 1.0456061e-11, 1.326493e-11, 1.6252424e-11, 1.8960364e-11, 1.2528977e-11, 1.0733391e-11, 7.5758314e-12, 1.6704377e-11, 3.1431097e-12, 2.2738832e-12, 1.7303387e-12, 6.4157141e-12, 6.9744867e-12, 1.1955532e-11, 1.2810531e-12, 2.9376966e-12, 5.1365506e-12, 6.5088614e-12, 5.6347441e-12, 8.9720403e-12, 5.0112797e-12, 1.8458058e-11, 3.0491843e-12, 6.0556854e-12, 1.5169225e-12, 1.0354577e-11, 1.6511413e-11, 1.0133936e-12, 1.1652192e-11, 3.9020711e-12, 7.5887253e-12, 1.191296e-11, 1.6945582e-11, 6.168507e-12, 3.7362289e-12, 1.430978e-11, 1.3481458e-11, 1.6208962e-11, 1.5379529e-11, 1.7487792e-11, 1.6227303e-11, 2.3599166e-11, 2.3986428e-11, 2.2877441e-11, 2.8995818e-11, 2.9717098e-12, 1.2812643e-11, 3.9682079e-12, 8.8532164e-12, 1.4168058e-11, 1.9919292e-11, 2.080119e-11, 3.3138871e-11, 2.4218295e-11, 2.2538532e-11, 1.2056572e-11, 2.2702373e-11, 2.0471618e-11, 2.1337621e-11, 9.2228044e-12, 1.1923409e-11, 1.0586334e-12, 7.2505939e-13, 2.3409092e-13, 9.9634254e-12, 1.9138767e-11, 2.1332952e-11, 3.4972806e-11, 1.2183732e-11, 2.5995097e-11, 4.4557306e-12, 1.2136936e-11, 5.6049548e-12, 2.6847761e-11, 8.9601469e-13, 2.9922622e-11, 2.5058955e-11, 1.8621566e-11, 9.110872e-12, 1.7125318e-11, 1.9371191e-11, 1.1349964e-12, 1.0734169e-12, 3.3798683e-12, 2.0197289e-11, 9.8479361e-12, 8.9555895e-12, 4.0984808e-12, 1.52756e-11, 2.0106143e-11, 4.3018931e-12, 3.1851594e-11, 1.9488014e-11, 2.5790573e-11, 1.2311893e-11, 1.3165891e-11, 4.6352448e-12, 1.1384311e-11, 5.0336217e-12, 4.7395075e-12, 1.0127489e-11, 2.3451887e-11, 2.9249694e-11, 2.1945746e-11, 2.2225633e-11, 8.1962946e-12, 3.4067677e-12, 1.1086306e-11, 1.9424656e-11, 1.276318e-11, 4.0311213e-11, 4.1533465e-11, 2.0941134e-11, 3.2442712e-11, 1.8077688e-11, 3.7180997e-11, 1.4652802e-11, 1.8750616e-11, 1.1626293e-11, 3.7798014e-12, 3.7143316e-12, 1.4391923e-11, 4.6232401e-12, 1.3459005e-11, 6.2703243e-12, 1.3369415e-11, 2.2801078e-12, 1.1086528e-11, 1.4684592e-12, 1.151425e-11, 1.0592781e-11, 2.7326391e-11, 1.7531254e-11, 1.7685202e-11, 5.8771716e-12, 4.6834857e-12, 1.7814919e-11, 1.283832e-13, 2.6063234e-11, 8.4499487e-12, 3.4453048e-11, 2.7307051e-11, 2.5739331e-11, 2.6164607e-11, 1.5238919e-11, 2.7857709e-11, 2.8230743e-11, 2.3899394e-11, 4.5124193e-11, 2.07684e-11, 2.5994874e-11, 1.2769738e-11, 7.5410401e-12, 4.1377182e-12, 9.3713065e-12, 7.1242115e-12, 1.8334232e-11, 3.5548474e-11, 1.4479624e-11, 2.4772844e-11, 3.0732159e-11, 2.7721323e-11, 2.8178611e-11, 2.0658579e-11, 3.5832584e-11, 3.0355346e-11, 2.908852e-11, 2.9166884e-12, 2.6237079e-11, 1.2974706e-11, 2.4185616e-11, 1.540943e-11, 2.5027499e-11, 5.3102848e-12, 2.6987816e-11, 2.0652577e-11, 3.3621837e-11, 2.9035055e-11, 3.0026996e-11, 1.9403536e-11, 2.2531196e-11, 2.1464448e-11, 1.056188e-11, 1.4717828e-11, 4.7268359e-12, 1.2038342e-11, 8.5823334e-12, 1.8288437e-11, 1.9149215e-11, 8.5026358e-12, 1.7856269e-11, 6.8202046e-12, 1.0678592e-12, 1.3995325e-11, 1.7243698e-11, 2.3217129e-11, 1.1335292e-11, 1.1618179e-11, 5.3917608e-12, 2.3009937e-11, 1.0752732e-11, 3.0797629e-11, 1.3905401e-11, 2.3099861e-11, 8.8703342e-12, 1.6012664e-11, 1.2647023e-11, 1.0079582e-11, 1.6073021e-11, 2.722613e-12, 2.6127481e-11, 1.3952975e-11, 5.9724308e-12, 7.044625e-12, 1.5309391e-11, 1.3658194e-11, 8.9471418e-12, 2.529249e-11, 4.328459e-12, 2.3591385e-11, 5.059743e-12, 1.1537704e-11, 1.247918e-11, 9.452338e-12, 2.4481175e-11, 2.0175058e-11, 2.3537142e-11, 6.6256846e-11, 6.1706634e-11, 1.2504701e-10, 1.3924097e-10, 2.4660067e-10, 3.2732035e-10, 5.094611e-10, 7.2167552e-10, 1.0844473e-09, 1.5062619e-09, 2.1630591e-09, 3.0315697e-09, 4.2715788e-09, 5.9608509e-09, 8.3437843e-09, 1.1625095e-08, 1.6157491e-08, 2.237713e-08, 3.0939687e-08, 4.2591514e-08, 5.8554935e-08, 8.0188008e-08, 1.0956633e-07, 1.4918876e-07, 2.027e-07, 2.7453773e-07, 3.7079022e-07, 4.9929447e-07, 6.7032184e-07, 8.9726275e-07, 1.1974227e-06, 1.5931029e-06, 2.1130083e-06, 2.7938138e-06, 3.6823602e-06, 4.8380822e-06, 6.336126e-06, 8.27101e-06, 1.0761312e-05, 1.3954958e-05, 1.8035783e-05, 2.3230923e-05, 2.9820083e-05, 3.8145661e-05, 4.8625074e-05, 6.1764365e-05, 7.8173982e-05, 9.8586305e-05, 0.00012387544, 0.00015507864, 0.0001934198, 0.00024033476, 0.0002974976, 0.00036684837, 0.00045062101, 0.00055137138, 0.00067200382, 0.00081579642, 0.00098642278, 0.0011879702, 0.0014249526, 0.0017023168, 0.002025442, 0.0024001302, 0.0028325882, 0.0033293991, 0.0038974847, 0.0045440572, 0.005276562, 0.0061026118, 0.0070299137, 0.0080661894, 0.0092190931, 0.010496126, 0.011904552, 0.013451315, 0.015142962, 0.016985572, 0.018984691, 0.021145281, 0.023471678, 0.025967555, 0.028635909, 0.031479046, 0.034498587, 0.037695476, 0.041070007, 0.044621845, 0.04835007, 0.052253211, 0.056329295, 0.060575892, 0.064990167, 0.069568924, 0.074308664, 0.079205625, 0.084255833, 0.089455144, 0.094799285, 0.10028389, 0.10590454, 0.11165678, 0.11753617, 0.12353828, 0.12965873, 0.13589322, 0.14223751, 0.14868746, 0.15523903, 0.1618883, 0.16863145, 0.1754648, 0.18238479, 0.18938797, 0.19647105, 0.20363084, 0.21086428, 0.21816844, 0.22554052, 0.23297781, 0.24047775, 0.24803786, 0.2556558, 0.2633293, 0.27105622, 0.27883449, 0.28666216, 0.29453734, 0.30245824, 0.31042314, 0.31843041, 0.32647848, 0.33456586, 0.3426911, 0.35085286, 0.35904979, 0.36728075, 0.37554428, 0.38383987, 0.39216506, 0.40052173, 0.40890302, 0.41731947, 0.42574855, 0.43422869, 0.44269034, 0.45124763, 0.45971518, 0.46837279, 0.47681342, 0.48558203, 0.49399581, 0.50280125, 0.51131554, 0.51987967, 0.52886102, 0.53664995, 0.54668062, 0.55314771, 0.56469983, 0.56982903, 0.5827048, 0.58713623, 0.59985871, 0.60559039, 0.61618948, 0.62421812, 0.63250928, 0.64190155, 0.64973676, 0.65867379, 0.66728178, 0.67543557, 0.68436249, 0.69251268, 0.70116246, 0.70940041, 0.71803499, 0.72591586, 0.73465007, 0.7421754, 0.75064661, 0.75785453, 0.76589282, 0.77257401, 0.78002765, 0.78616575, 0.79272695, 0.79838116, 0.80388596, 0.80906539, 0.81353354, 0.81825345, 0.82185202, 0.82608446, 0.82915378, 0.83282197, 0.83569667, 0.83878624, 0.84172396, 0.84429782, 0.84742436, 0.84965847, 0.85300593, 0.85521123, 0.85880565, 0.86132943, 0.86516801, 0.86828684, 0.8723899, 0.87638194, 0.88097185, 0.88619249, 0.89157407, 0.89817, 0.90433351, 0.91190589, 0.91831494, 0.92592112, 0.9316993, 0.9380621, 0.94212677, 0.94587885, 0.94717707, 0.94742498, 0.94767951, 0.94780527, 0.94803564, 0.94820734, 0.94830276, 0.94855132, 0.94874752, 0.94888718, 0.94845965, 0.94872855, 0.94879579, 0.94921478, 0.94945263, 0.94948663, 0.95001979, 0.9507142, 0.94977329, 0.95073316, 0.95280442, 0.94948042, 0.95051732, 0.95976221, 0.94700999, 0.92703429, 0.92353142, 0.92139847, 0.92149921, 0.92694969, 0.93111875, 0.93134918, 0.93179552, 0.9317036, 0.93019943, 0.92913487, 0.92907245, 0.92909259, 0.9291059, 0.9291442, 0.92915769, 0.92922451, 0.92924203, 0.92911433, 0.92899133, 0.92898409, 0.92899886, 0.92900657, 0.92900604, 0.92900255, 0.92900176, 0.92900006, 0.92899903, 0.92899627, 0.92899873, 0.92900462, 0.9290154, 0.92902768, 0.92904411, 0.92906035, 0.9290786, 0.92909653, 0.9291185, 0.92914032, 0.92916527, 0.92919056, 0.9292208, 0.92925171, 0.92928876, 0.92933076, 0.92937489, 0.92942012, 0.92947584, 0.92953381, 0.9295991, 0.92966776, 0.92974198, 0.92981911, 0.92989924, 0.92998185, 0.93006832, 0.93015723, 0.930241, 0.93032401, 0.93040384, 0.93048168, 0.93054887, 0.93061051, 0.93066871, 0.93073158, 0.93079108, 0.93084464, 0.93089778, 0.93094338, 0.93099075, 0.93103015, 0.93107199, 0.93110975, 0.93114968, 0.93118829, 0.93122538, 0.93126367, 0.93129719, 0.93133572, 0.93136851, 0.93140868, 0.93144301, 0.93148121, 0.93151575, 0.93155226, 0.93158905, 0.93162476, 0.93166393, 0.93169731, 0.93173935, 0.93177342, 0.9318156, 0.93185112, 0.93189142, 0.93192729, 0.93196446, 0.93200387, 0.93203979, 0.93208172, 0.93211479, 0.93215424, 0.93218187, 0.93221582, 0.93224005, 0.9322631, 0.93227917, 0.93228247, 0.93227121, 0.93224052, 0.93218199, 0.93208667, 0.93194139, 0.93172852, 0.9314245, 0.93099797, 0.93040702, 0.92959603, 0.92849123, 0.92699517, 0.92497967, 0.92227668, 0.91866727, 0.91386765, 0.90751276, 0.89913639, 0.88814896, 0.87381251, 0.85521555, 0.83125048, 0.80060084, 0.76175515, 0.71307468, 0.65297275, 0.58034371, 0.49543106, 0.40111096, 0.30400643, 0.21385279, 0.13973194, 0.085672249, 0.050029818, 0.028248231, 0.01561467, 0.0085251238, 0.0046229516, 0.0024979795, 0.0013473218, 0.00072604692, 0.00039108398, 0.00021061359, 0.00011341244, 6.1068151e-05, 3.2881948e-05, 1.7704928e-05, 9.5328448e-06, 5.1327199e-06, 2.7634876e-06, 1.487836e-06, 8.0098752e-07, 4.3120483e-07, 2.3210337e-07, 1.2492882e-07, 6.7187527e-08, 3.6127854e-08, 1.9352349e-08, 1.0404359e-08, 5.5210503e-09, 2.9529626e-09, 1.5346396e-09, 7.9428198e-10, 3.6861033e-10, 1.2419183e-10, 4.3436841e-11, 1.3257637e-11, 1.4870166e-11, 1.0206285e-11, 2.4490177e-11, 2.4370081e-11, 1.9556357e-11, 3.4978943e-11, 2.4217574e-11, 2.8594202e-11, 2.1797559e-11, 2.6848701e-11, 2.4967454e-11, 4.3702007e-11, 1.6981616e-11, 1.2151798e-11, 3.6970075e-12, 3.3598392e-11, 6.8825519e-12, 2.0689279e-11, 1.3582629e-11, 3.5937048e-11, 2.1156788e-11, 3.1031754e-11, 3.8754867e-11, 5.7551244e-11, 1.2017272e-11, 3.1834355e-12, 7.7792771e-12, 5.2228499e-12, 8.825401e-12, 2.2278166e-11, 2.3018056e-11, 1.0137468e-11, 2.6215477e-11, 1.8272039e-11, 1.0712309e-11, 7.3875772e-12, 1.0804989e-11, 8.8561465e-12, 3.9837509e-11, 2.3096973e-11, 6.3352043e-11, 2.9827795e-11, 7.8074697e-11, 3.5060857e-11, 6.8725291e-11, 6.4160861e-11, 4.8119258e-11, 4.3734306e-11, 5.0335154e-11, 8.2433787e-11, 2.8126692e-11, 5.3756784e-11, 1.8430428e-11, 2.9340196e-11, 3.4874053e-11, 1.5347553e-11, 1.4757284e-11, 2.7799813e-11, 5.3875659e-12, 1.7271756e-11, 2.7111536e-11, 1.7808525e-11, 1.3187377e-11, 6.0115774e-12, 2.0383045e-11, 3.0349248e-11, 6.6302612e-12, 1.3277616e-11, 1.5641245e-11, 2.5366146e-11, 1.2476235e-11, 1.1086805e-11, 9.6080238e-12, 2.9373495e-11, 5.0011937e-12, 3.4103085e-12, 7.4496232e-12, 2.1377889e-11, 1.5513601e-11, 3.2097745e-11, 2.0315671e-11, 1.5045981e-11, 6.3766385e-13, 5.3094257e-12, 2.071847e-11, 6.0062497e-12, 5.9049116e-12, 4.2392826e-11, 1.8420105e-11, 2.1885356e-11, 8.4259315e-12, 2.8205943e-11, 2.5683036e-12, 2.7446629e-11, 3.480124e-12, 3.6805801e-13, 3.8837336e-11, 8.7038619e-12, 2.6307602e-11, 1.5869117e-11, 7.3966789e-13, 1.2958395e-11, 1.394325e-11, 4.6496739e-12, 1.5903303e-11, 2.8199838e-11, 2.5214417e-11, 8.5717784e-12, 2.6207041e-11, 6.0112444e-12, 4.0859325e-11, 2.4191602e-11, 3.8050274e-11, 2.4840254e-11, 2.8883342e-11, 2.9577836e-12, 8.4301493e-12, 1.0224377e-11, 2.481528e-11, 2.9430213e-11, 1.1148851e-11, 2.2952014e-11, 5.6299781e-12, 2.6766898e-11, 4.9046285e-12, 5.1555983e-11, 1.0087076e-11, 4.4939041e-11, 1.4179447e-11, 2.3963397e-11, 2.3591898e-12, 1.9854821e-11, 1.3202472e-11, 3.1101791e-11, 1.3970666e-11, 2.8291852e-11, 3.9392531e-11, 1.6398339e-12, 1.9717077e-12, 3.3493946e-11, 1.4251482e-11, 2.225519e-11, 3.5135667e-11, 3.6623549e-11, 5.2043471e-11, 2.0132197e-11, 1.4937762e-11, 7.5046765e-12, 1.3253197e-11, 5.6778167e-12, 1.659369e-11, 7.4506221e-12, 8.1147027e-12, 1.4139045e-11, 2.3932651e-12, 4.2783971e-12, 2.1105952e-11, 5.3867889e-12, 1.8312441e-11, 9.8047062e-12, 9.3391949e-12, 3.6215311e-12, 1.3048523e-11, 4.0050618e-11, 1.8217429e-11, 1.684487e-11, 2.7428204e-11, 1.2258796e-11, 2.2140089e-11, 2.0840342e-11, 4.178391e-12, 1.6649631e-11, 1.2855725e-11, 3.9175537e-12, 1.789277e-11, 2.852261e-11, 3.6098545e-11, 6.5570048e-12, 3.2203301e-11, 9.8111439e-12, 1.2932422e-11, 2.8110487e-12, 1.2827977e-11, 7.5176629e-12, 2.5976061e-11, 2.329077e-11, 3.8056933e-11, 4.690975e-11, 3.7367213e-11, 5.2457148e-11, 3.9460349e-11, 4.9403576e-11, 6.3205752e-11, 7.2271235e-11, 4.9367614e-11, 4.5474479e-11, 1.1120325e-11, 1.9082965e-11, 9.2018946e-12, 2.3865167e-11, 4.1185538e-11, 3.977624e-11, 1.6751302e-11, 8.4957471e-12, 3.4906463e-11, 2.2628576e-11, 2.4532244e-11, 4.0878083e-11, 4.5074011e-11, 1.5930275e-11, 8.4807628e-12, 2.2477734e-11, 9.4470816e-12, 3.760119e-11, 2.9787615e-12, 4.1064887e-11, 1.2349257e-12, 2.1885134e-11, 1.5716833e-12, 8.662683e-12, 1.085083e-11, 6.3942867e-12, 1.9193516e-11, 3.2279888e-11, 2.5822778e-11, 4.105412e-11, 1.8547638e-11, 2.2644559e-11, 4.7690819e-11, 2.1394316e-11, 6.6005036e-11, 9.6874959e-12, 1.498449e-11, 1.0487767e-11, 4.0695719e-11, 5.1100795e-12, 3.0456913e-13, 2.4637023e-11, 3.9656476e-11, 2.8627056e-11, 5.2256026e-11, 2.4325572e-11, 3.5351108e-11, 3.4459932e-11, 2.6888215e-11, 3.1180264e-11, 7.3392391e-11, 4.5273468e-11, 2.3238491e-11, 4.5416429e-11, 4.9126201e-12, 6.8129583e-12, 4.7035063e-12, 8.8010932e-12, 3.6449177e-11, 3.57498e-11, 6.8845498e-11, 6.3584799e-11, 6.4005468e-11, 4.7890387e-11, 4.5425864e-11, 3.9753042e-11, 5.3676979e-11, 7.4143047e-11, 5.9449474e-11, 7.5752469e-11, 7.8523892e-11, 5.5389292e-11, 6.6257437e-11, 2.5778935e-11, 4.8051218e-11, 2.9114655e-11, 2.0579061e-11, 3.7228137e-11, 1.9723736e-13, 1.6788374e-11, 1.5427803e-11, 3.2430951e-11, 1.5089269e-11, 8.6060757e-12, 4.2812829e-12, 1.4006628e-11, 3.3064175e-12, 1.1991854e-12, 1.1020541e-11, 1.2967097e-20];\nlet data2 = [3.1587274e-21, 1.3862829e-11, 1.646295e-11, 3.2144263e-11, 1.5146772e-11, 4.8599543e-11, 1.5956976e-11, 4.5079954e-11, 1.1164003e-11, 2.375367e-11, 8.4472809e-12, 9.1891247e-12, 1.5533811e-11, 1.4210519e-11, 3.0230631e-11, 5.3723755e-11, 1.8964366e-11, 3.6470387e-11, 1.7343736e-11, 2.657321e-11, 1.6595779e-11, 2.8922344e-12, 2.2643239e-12, 7.9208543e-13, 1.0798639e-11, 4.4303875e-12, 1.3237586e-11, 3.0215069e-11, 3.847939e-12, 3.3845368e-11, 1.968798e-11, 2.5638958e-11, 3.1805576e-11, 1.4100588e-11, 4.2181828e-11, 9.1871239e-12, 5.4263521e-11, 2.6657799e-11, 2.9521244e-11, 2.6140709e-11, 3.6060228e-11, 3.9825691e-11, 3.693768e-11, 7.9510883e-12, 5.2393906e-11, 7.6993238e-12, 2.9091077e-11, 9.7627919e-12, 2.3350514e-11, 7.4785714e-12, 3.1269923e-11, 1.6848099e-11, 2.0900673e-11, 3.1482227e-12, 1.9616508e-11, 1.3593057e-11, 3.2383244e-11, 2.9686864e-11, 4.1839584e-11, 2.1039505e-11, 4.4363009e-11, 4.5567699e-11, 5.1585925e-11, 5.0254408e-11, 3.1628285e-11, 4.9054942e-11, 6.1561022e-11, 3.6102133e-11, 2.0040228e-11, 1.4764401e-11, 2.1241917e-11, 2.5835813e-11, 3.5030384e-11, 4.1158653e-11, 3.5126977e-11, 4.6989584e-11, 3.8374905e-11, 5.3902491e-11, 2.2804858e-11, 4.116799e-11, 2.2078131e-11, 2.9711651e-11, 2.7927514e-12, 3.6848534e-11, 4.8283198e-12, 1.5137768e-11, 1.8658358e-12, 5.5483772e-12, 4.8572199e-12, 7.2834956e-12, 4.3929285e-12, 9.2330306e-12, 1.2192069e-11, 1.0106481e-11, 1.2977151e-11, 5.4687908e-13, 2.7688531e-13, 5.1474437e-12, 9.0471806e-12, 7.2589305e-12, 1.1016835e-11, 1.5147217e-11, 7.1979068e-12, 1.6878222e-11, 2.5077518e-12, 1.3794247e-11, 2.3397977e-12, 3.3936292e-11, 4.4505064e-12, 4.141553e-11, 2.6810636e-11, 1.4511192e-11, 3.50435e-11, 2.6215738e-12, 1.6870441e-11, 1.6199848e-11, 7.5394839e-12, 4.3516901e-13, 1.8329341e-13, 2.6110141e-13, 3.3873156e-12, 1.4211298e-11, 5.7610154e-12, 2.4711376e-11, 1.6844209e-11, 1.1221025e-11, 1.4642687e-11, 1.7884391e-11, 5.9851024e-12, 1.7921405e-11, 1.2904123e-11, 1.9490681e-11, 1.8598891e-11, 1.2063686e-11, 1.8508411e-11, 3.2205064e-11, 1.1345184e-11, 1.8744058e-11, 2.3708653e-11, 3.811736e-11, 2.6724824e-12, 4.3599156e-11, 2.0617119e-11, 5.1319933e-11, 3.0725823e-11, 5.1442091e-11, 2.3753115e-11, 6.2107567e-11, 3.1677192e-11, 5.5339939e-11, 3.4040666e-11, 2.5940742e-11, 4.6395909e-11, 3.6795625e-11, 3.4361235e-11, 2.2750948e-11, 3.1149432e-11, 2.7081963e-11, 3.2067789e-11, 8.3646933e-12, 4.675705e-11, 9.3488534e-12, 1.7650189e-12, 1.4368581e-11, 1.7560154e-11, 9.1522214e-12, 5.3022816e-12, 5.1575583e-14, 7.4349989e-12, 4.3805903e-12, 1.007169e-11, 7.4106559e-13, 1.807591e-12, 1.2629572e-11, 4.3775891e-12, 1.3309947e-11, 9.9894355e-12, 1.6843987e-11, 1.3354187e-11, 5.8228171e-12, 3.1425539e-12, 2.8588437e-11, 2.262212e-12, 5.8623881e-12, 7.9196316e-12, 5.8783943e-12, 1.2594558e-11, 2.3195342e-11, 1.5702765e-12, 3.1104303e-11, 8.5607694e-12, 4.3086735e-12, 1.2531867e-11, 1.2554209e-11, 1.8647243e-12, 9.3182859e-12, 5.2836077e-12, 2.6260533e-11, 5.2642671e-13, 2.6149379e-11, 6.5936721e-12, 5.6280749e-12, 1.2302667e-11, 1.50195e-11, 3.4461163e-12, 2.4724603e-11, 1.2550652e-11, 1.7924073e-11, 2.4092246e-11, 3.1099635e-11, 3.2873213e-11, 1.9854823e-11, 1.2604229e-11, 7.9728745e-12, 2.7277039e-11, 8.5136401e-12, 1.9863048e-11, 3.4652904e-11, 1.1901511e-11, 2.5563929e-11, 1.2166726e-11, 2.461745e-11, 1.3254037e-12, 7.839267e-12, 9.9509761e-12, 6.5985629e-12, 3.8159266e-12, 9.5138063e-12, 3.7557921e-12, 1.6593e-11, 1.3511137e-11, 7.505693e-12, 4.7188328e-12, 1.596798e-11, 3.1650071e-12, 5.7689072e-13, 4.2908888e-12, 1.1663197e-11, 6.9723748e-12, 2.1425766e-11, 7.5927268e-12, 1.5739669e-11, 6.1834017e-12, 7.7385613e-13, 2.4608447e-12, 1.8791743e-12, 2.8075349e-12, 1.061968e-12, 8.6929319e-12, 1.971688e-11, 3.1628729e-11, 4.7778446e-11, 3.5523798e-11, 3.331405e-11, 3.4131257e-11, 3.3807687e-11, 3.3272812e-11, 2.7870714e-11, 3.199665e-11, 2.726659e-11, 1.8468729e-11, 3.5013599e-11, 4.2273197e-11, 3.6007874e-11, 3.1525578e-11, 1.2414044e-11, 1.5876389e-11, 3.6948795e-12, 3.3746107e-11, 2.5809358e-11, 2.4112477e-11, 4.4271084e-11, 2.9867156e-11, 3.1420648e-11, 1.7371303e-11, 2.4465836e-11, 4.0992588e-12, 2.6491401e-12, 8.1303801e-12, 8.5713292e-12, 2.3663635e-12, 1.5372526e-11, 2.8357792e-11, 1.1904735e-11, 1.3772349e-11, 5.2911662e-12, 1.6268652e-11, 1.8988709e-11, 4.6916e-12, 1.0875669e-11, 1.3120318e-11, 2.6141042e-11, 7.6080661e-11, 9.5989838e-11, 1.4489528e-10, 2.0154195e-10, 3.0967917e-10, 4.3345436e-10, 6.3358286e-10, 8.8771735e-10, 1.2741231e-09, 1.7645955e-09, 2.5038187e-09, 3.4686766e-09, 4.8671167e-09, 6.7767861e-09, 9.4414534e-09, 1.3159652e-08, 1.8246835e-08, 2.5266961e-08, 3.487059e-08, 4.8017711e-08, 6.5968252e-08, 9.0295516e-08, 1.2330064e-07, 1.6787384e-07, 2.2790804e-07, 3.0853965e-07, 4.1644473e-07, 5.6052828e-07, 7.5213878e-07, 1.0063065e-06, 1.3422031e-06, 1.7847702e-06, 2.3659374e-06, 3.1264883e-06, 4.1185031e-06, 5.4079356e-06, 7.0781943e-06, 9.234058e-06, 1.2006817e-05, 1.5560174e-05, 2.0097201e-05, 2.5868814e-05, 3.3183366e-05, 4.2418174e-05, 5.403248e-05, 6.8582362e-05, 8.6737913e-05, 0.00010930182, 0.00013723087, 0.00017165865, 0.00021392091, 0.00026558174, 0.00032846207, 0.00040466801, 0.00049662036, 0.0006070829, 0.0007391898, 0.00089647036, 0.0010828703, 0.0013027684, 0.0015609871, 0.0018627962, 0.0022139076, 0.0026204618, 0.0030890034, 0.0036264471, 0.0042400316, 0.004937265, 0.0057258587, 0.0066136536, 0.0076085392, 0.0087183668, 0.0099508598, 0.011313523, 0.012813554, 0.014457756, 0.016252461, 0.018203457, 0.020315928, 0.022594403, 0.02504272, 0.027663998, 0.030460627, 0.033434265, 0.036585855, 0.039915638, 0.043423192, 0.047107468, 0.050966832, 0.05499912, 0.059201687, 0.063571465, 0.068105018, 0.072798595, 0.077648185, 0.082649568, 0.087798357, 0.093090051, 0.098520067, 0.10408378, 0.10977655, 0.11559376, 0.12153083, 0.12758323, 0.13374653, 0.14001638, 0.14638853, 0.15285883, 0.15942327, 0.16607796, 0.1728191, 0.17964307, 0.18654633, 0.19352548, 0.20057725, 0.20769849, 0.21488617, 0.22213736, 0.22944927, 0.2368192, 0.24424456, 0.25172287, 0.25925174, 0.26682889, 0.2744521, 0.28211929, 0.28982841, 0.29757751, 0.30536475, 0.3131883, 0.32104646, 0.32893756, 0.33686, 0.34481224, 0.35279281, 0.36080028, 0.36883326, 0.37689044, 0.38497053, 0.39307229, 0.40119452, 0.40933606, 0.41749581, 0.42567269, 0.43386567, 0.44207375, 0.45029603, 0.45853158, 0.46677972, 0.47503945, 0.4833107, 0.49159204, 0.49988463, 0.50818626, 0.5164997, 0.52482283, 0.53315832, 0.54150894, 0.5498738, 0.5582359, 0.5665362, 0.57494469, 0.58311624, 0.59136317, 0.59958707, 0.60776687, 0.6159676, 0.624232, 0.6323957, 0.6405601, 0.64871327, 0.65688165, 0.66508144, 0.673247, 0.68143447, 0.68964666, 0.69798511, 0.70610249, 0.71427091, 0.72235892, 0.73037817, 0.73833991, 0.74625126, 0.75411165, 0.76191705, 0.76966278, 0.77734373, 0.78495423, 0.79248781, 0.79993689, 0.80729313, 0.81454716, 0.82168897, 0.82870754, 0.83559096, 0.84232631, 0.84889968, 0.85529632, 0.86150056, 0.86749612, 0.87326608, 0.87879326, 0.88406045, 0.88905082, 0.89374843, 0.89813868, 0.9022091, 0.90594978, 0.90935421, 0.91241975, 0.91514819, 0.91754603, 0.91962462, 0.9214, 0.92289244, 0.92412584, 0.92512669, 0.92592309, 0.92654356, 0.92701596, 0.92736647, 0.92761863, 0.92779284, 0.92791107, 0.9279828, 0.92801901, 0.92802639, 0.92803187, 0.92801278, 0.92799155, 0.9279374, 0.92788026, 0.92781863, 0.92775834, 0.92770019, 0.9276448, 0.92759277, 0.92754454, 0.92750042, 0.92746044, 0.92742444, 0.92739211, 0.92736302, 0.92733674, 0.92731283, 0.9272909, 0.92727063, 0.92725175, 0.92723405, 0.92721737, 0.92720159, 0.92718663, 0.92717241, 0.92715889, 0.92714602, 0.92713376, 0.92712205, 0.92711087, 0.92710016, 0.92708987, 0.92707996, 0.92707038, 0.92706111, 0.92705212, 0.92704341, 0.92703496, 0.92702678, 0.9270189, 0.92701128, 0.92700388, 0.92699672, 0.92698978, 0.92698311, 0.92697697, 0.92697102, 0.9269644, 0.92695882, 0.92695257, 0.92694634, 0.92694042, 0.92693453, 0.92692853, 0.92692233, 0.92691583, 0.92690895, 0.92690158, 0.92689368, 0.92688513, 0.92687566, 0.9268651, 0.92685345, 0.92684118, 0.92682992, 0.92681909, 0.92680727, 0.92679675, 0.92678714, 0.92677884, 0.92677221, 0.9267674, 0.92676447, 0.92676321, 0.92676338, 0.92676473, 0.92676685, 0.92676937, 0.92677188, 0.92677402, 0.92677561, 0.92677665, 0.92677714, 0.92677547, 0.92677222, 0.92676995, 0.92676664, 0.92676285, 0.92675868, 0.92675421, 0.92674948, 0.92674448, 0.92673922, 0.92673375, 0.92672829, 0.92672287, 0.92671729, 0.92671144, 0.92670515, 0.92670037, 0.9266956, 0.9266888, 0.92668168, 0.92667323, 0.92666665, 0.92666105, 0.92665279, 0.92664626, 0.92663888, 0.92663016, 0.92662086, 0.92661089, 0.9266001, 0.92658832, 0.92657535, 0.92656091, 0.92654466, 0.92652616, 0.92650484, 0.92647999, 0.92645069, 0.92641577, 0.92637373, 0.92632266, 0.92626013, 0.92618306, 0.92608752, 0.92596852, 0.92581972, 0.92563309, 0.92539845, 0.92510291, 0.92473014, 0.92425951, 0.92366491, 0.92291337, 0.92196323, 0.92076189, 0.91924297, 0.91732274, 0.91489558, 0.91182839, 0.90795347, 0.90305973, 0.89688164, 0.88908574, 0.87925393, 0.86686358, 0.85126424, 0.83165196, 0.80704406, 0.77626142, 0.73793377, 0.69055942, 0.63268039, 0.56327591, 0.48250857, 0.39285097, 0.30012158, 0.21309309, 0.14045218, 0.086688654, 0.050828674, 0.028729114, 0.015849886, 0.00861729, 0.0046467978, 0.0024949216, 0.0013366319, 0.0007153302, 0.00038263615, 0.00020462933, 0.00010942248, 5.850937e-05, 3.1284829e-05, 1.6727594e-05, 8.9439202e-06, 4.7819894e-06, 2.5567432e-06, 1.3669313e-06, 7.308132e-07, 3.9068546e-07, 2.0884449e-07, 1.1162505e-07, 5.9670655e-08, 3.1888187e-08, 1.7047214e-08, 9.0987698e-09, 4.8644519e-09, 2.5910582e-09, 1.4090592e-09, 7.3607532e-10, 3.7363817e-10, 1.7609201e-10, 6.9859433e-11, 6.505581e-11, 1.1719474e-11, 4.888612e-11, 2.3601888e-12, 3.4779596e-11, 1.1009219e-11, 1.7066971e-11, 4.3198424e-11, 1.6923455e-11, 2.9291692e-11, 6.9220659e-12, 9.226979e-13, 1.9257449e-11, 2.1512192e-11, 2.9423553e-12, 1.0852717e-11, 3.749397e-13, 2.8956266e-11, 2.7232853e-11, 1.094118e-11, 2.3079547e-11, 3.5580423e-12, 8.7943225e-12, 3.5617162e-11, 3.3684635e-12, 1.2529068e-11, 1.9249346e-11, 3.1177378e-11, 1.2765265e-11, 2.028881e-11, 1.8367383e-12, 3.5656121e-11, 1.7748588e-11, 1.607812e-11, 1.6635646e-11, 2.148844e-11, 1.3817604e-11, 2.4028995e-11, 7.6920353e-12, 2.2070828e-11, 2.0256067e-11, 8.1556597e-12, 4.0443095e-12, 1.4599117e-11, 3.5777882e-11, 1.215202e-11, 3.2232604e-11, 1.05194e-11, 1.4869943e-12, 3.0990797e-12, 2.8712522e-11, 1.0117711e-11, 7.1187483e-12, 1.8899935e-11, 2.1021929e-11, 1.7956037e-11, 3.8355509e-11, 4.8117261e-12, 3.4119731e-13, 6.755352e-12, 2.2086811e-11, 1.8748094e-12, 2.1405527e-11, 2.1825197e-11, 1.3863227e-13, 8.1193644e-12, 6.0514244e-12, 1.3537343e-11, 2.5115964e-11, 1.3615816e-11, 3.6313542e-11, 3.1876534e-12, 5.0612307e-11, 1.4525195e-11, 4.9153061e-11, 5.0610199e-12, 3.5477641e-11, 2.0070373e-11, 1.2292317e-11, 2.257996e-11, 2.6219695e-11, 3.3177057e-11, 3.3918834e-11, 2.0201124e-11, 2.9929022e-11, 2.0404911e-11, 1.7744481e-11, 4.564097e-13, 3.0670022e-12, 6.1093637e-12, 4.9195239e-11, 5.3775764e-12, 3.2420629e-11, 3.2356918e-11, 1.1203127e-11, 2.1044239e-11, 7.0392762e-12, 1.0964045e-11, 2.4331011e-11, 1.1977203e-11, 2.7525213e-11, 2.2182711e-11, 3.4249153e-11, 2.6882887e-12, 3.8139957e-12, 1.3752339e-11, 2.0393922e-11, 1.8775732e-11, 1.6146492e-11, 8.4262645e-12, 2.6534919e-11, 1.1913936e-11, 3.2594002e-11, 1.6710789e-11, 2.4528359e-11, 1.5794528e-12, 3.0703987e-11, 1.9988459e-11, 4.2636903e-11, 2.9170263e-11, 1.5225348e-11, 2.5626762e-11, 4.4411928e-11, 1.589842e-11, 4.5259483e-11, 2.0439208e-11, 2.6341012e-11, 1.347341e-11, 2.1255684e-11, 1.0629729e-11, 3.9437928e-11, 2.9967427e-12, 3.1947237e-11, 6.9956554e-12, 6.1998242e-12, 2.0789284e-12, 2.0116436e-11, 4.647676e-12, 1.6522098e-11, 9.3896974e-12, 6.0516465e-12, 8.3840866e-12, 2.1797115e-11, 1.0969372e-11, 1.4066343e-12, 7.4723771e-12, 1.508716e-11, 2.572588e-11, 3.1789957e-11, 3.7379645e-12, 1.4661163e-11, 3.0160668e-11, 3.8229419e-11, 2.3631412e-11, 3.3269737e-11, 1.1988414e-11, 3.4363256e-11, 2.2416021e-11, 1.1728131e-11, 9.317551e-12, 9.889617e-12, 2.6019238e-11, 5.4338506e-12, 3.9482659e-11, 1.4534407e-11, 5.2454928e-11, 5.7924963e-11, 5.1665202e-11, 7.6479705e-11, 5.8635218e-11, 6.9449863e-11, 4.4034991e-11, 3.6424314e-11, 4.3910566e-11, 3.1681627e-11, 2.2541112e-11, 1.4644958e-11, 1.2643947e-11, 1.8225976e-11, 1.0744275e-11, 1.0612192e-11, 2.0740669e-11, 4.3798572e-11, 3.0136138e-11, 1.6759738e-11, 2.4857014e-11, 5.8160049e-12, 1.1487828e-11, 7.7568561e-12, 1.3198587e-11, 4.9671184e-12, 1.9774128e-11, 4.5795254e-12, 1.0955387e-11, 2.7193117e-11, 2.7553294e-12, 2.3722427e-11, 4.8546809e-12, 1.5726156e-11, 1.0720633e-11, 9.6529766e-12, 2.9908599e-12, 2.6848257e-11, 3.5884548e-13, 3.1516578e-11, 5.297738e-11, 3.3170952e-11, 4.9748325e-11, 1.0841063e-11, 5.7032789e-11, 4.068695e-11, 5.5832715e-11, 3.2919771e-11, 4.6057423e-11, 2.3108183e-11, 4.1595996e-11, 1.170904e-11, 1.0863594e-11, 1.5928055e-11, 2.1407081e-11, 1.4800017e-12, 2.8126359e-11, 4.7800593e-11, 5.4824441e-11, 2.0990407e-11, 5.1780192e-11, 1.1011772e-11, 2.5747635e-11, 1.1905057e-11, 1.7807748e-11, 3.2342156e-11, 9.8929469e-12, 1.1113443e-11, 6.7752201e-12, 1.8121308e-11, 6.0684066e-12, 3.6823562e-11, 3.2676027e-11, 3.8488147e-11, 4.7162818e-11, 2.817775e-11, 4.1453479e-11, 3.4595678e-11, 3.2416078e-11, 5.5118354e-11, 5.5519489e-12, 5.4331847e-11, 3.5331795e-12, 3.1377169e-11, 3.4956633e-12, 2.5582031e-11, 2.1050122e-11, 3.4838313e-11, 6.7041836e-12, 3.0708981e-11, 1.1507141e-11, 1.392205e-12, 2.4646346e-12, 2.9236638e-11, 1.18631e-12, 2.1137697e-11, 1.0209059e-11, 7.883501e-12, 6.1566473e-12, 4.3042588e-12, 3.0403524e-11, 2.3630743e-13, 2.2504595e-11, 1.8515117e-11, 1.5644797e-11, 3.6540082e-11, 3.5870451e-11, 3.4634194e-11, 1.2553487e-12, 2.1674356e-11, 2.6223579e-12, 2.6899536e-12, 1.6752412e-11, 1.2854726e-11, 2.237007e-11, 4.7813135e-12, 1.7285852e-11, 6.1368907e-13, 2.2063613e-11, 2.356861e-20];\nlet data3 = [6.9688318e-22, 1.644272e-11, 6.314786e-12, 3.2875102e-11, 9.8260368e-14, 2.3936075e-11, 2.694969e-11, 4.2087013e-11, 4.6329106e-11, 2.3309053e-11, 3.7687305e-11, 6.6659224e-12, 4.6838192e-12, 9.6655319e-12, 2.0671807e-11, 2.8959359e-11, 2.2623343e-11, 3.6969137e-11, 2.1388752e-11, 3.5699199e-11, 2.9340507e-11, 1.772255e-11, 8.2035196e-12, 1.8482512e-11, 2.4174501e-11, 1.7265261e-11, 2.2804302e-11, 3.1309939e-12, 6.693711e-12, 2.5666191e-11, 2.6720934e-11, 1.9686869e-11, 6.4094895e-12, 2.6156381e-11, 1.178002e-11, 2.1946524e-11, 1.5986765e-11, 4.5602823e-11, 4.2158819e-11, 5.0142253e-11, 3.0869434e-11, 2.972888e-11, 2.2426155e-11, 3.9049945e-11, 2.5087744e-11, 5.3440423e-11, 3.8887215e-11, 6.2241064e-11, 5.2624773e-11, 7.1175534e-11, 4.66878e-11, 4.4403358e-11, 4.6373456e-11, 4.1789009e-11, 4.2431703e-11, 3.5016267e-11, 4.5389963e-11, 4.1522905e-11, 5.6982577e-11, 4.5454432e-11, 6.0826959e-11, 2.1750226e-11, 2.9669301e-11, 1.1971094e-11, 3.0990037e-11, 1.1845156e-11, 2.3249141e-11, 7.7532336e-12, 1.9204681e-11, 3.0587436e-12, 1.4002994e-11, 2.5361628e-11, 9.4072093e-12, 1.9982205e-12, 5.6142917e-12, 8.5617698e-12, 2.0093693e-11, 1.1226582e-12, 1.1819035e-12, 1.1260151e-11, 7.7041034e-12, 6.2246287e-15, 1.140354e-11, 7.8352655e-13, 1.0221303e-11, 2.1752893e-12, 1.9166222e-11, 2.1780015e-11, 1.1090419e-11, 3.5089073e-11, 1.0938137e-11, 2.4513521e-11, 6.9846017e-12, 8.5136401e-12, 1.1986322e-11, 2.5332061e-12, 1.8469396e-12, 9.5819439e-12, 1.2684482e-11, 4.9295813e-12, 1.0067243e-11, 1.4625681e-11, 3.0977587e-12, 1.4397592e-11, 1.1447335e-11, 2.3799577e-11, 5.6455261e-12, 3.5564147e-11, 2.6856209e-11, 3.0241857e-11, 2.6844426e-11, 2.438536e-11, 1.8498852e-11, 1.5597614e-11, 1.3305279e-11, 8.4438352e-12, 1.2783854e-12, 1.7306833e-11, 2.4847206e-11, 9.7293345e-12, 2.3259701e-11, 6.1117071e-12, 2.1805469e-11, 4.1434982e-12, 2.0206737e-11, 1.071116e-11, 8.3765868e-12, 3.1402197e-12, 9.787357e-12, 1.4450279e-11, 1.1241922e-11, 1.0742283e-11, 4.307562e-12, 1.8921794e-12, 1.7633849e-11, 5.7883593e-12, 1.06129e-11, 8.7511769e-13, 1.374067e-11, 8.8962331e-12, 3.0052673e-11, 5.1190994e-12, 1.807691e-11, 2.3518579e-11, 2.1319836e-11, 4.4795191e-14, 1.0434831e-11, 8.6904865e-12, 2.1587385e-11, 4.3709199e-12, 2.9441991e-11, 1.0720275e-11, 7.4697902e-12, 1.0809754e-11, 1.4696486e-11, 1.8840651e-13, 1.442049e-11, 1.9502353e-11, 2.7316276e-11, 1.128316e-11, 9.0713011e-12, 1.2080803e-11, 3.0674025e-11, 3.5719429e-11, 1.915833e-11, 3.1539917e-11, 1.1264042e-11, 1.2411821e-11, 1.2584888e-12, 1.6417377e-11, 1.2998382e-12, 8.0154466e-12, 6.880339e-12, 2.9339062e-11, 2.0188063e-11, 2.6760505e-11, 3.110786e-11, 3.7842921e-11, 1.6658693e-11, 2.7987093e-11, 2.6125925e-11, 2.0261203e-11, 1.1568827e-11, 1.0462064e-11, 6.349355e-12, 1.5180229e-11, 2.04246e-12, 1.7739112e-12, 2.6350346e-11, 8.2377551e-12, 2.5672971e-11, 2.1312055e-11, 2.3692647e-11, 1.5997325e-12, 4.1161543e-12, 9.3535218e-12, 7.0731917e-12, 2.2783516e-11, 2.787416e-12, 1.0895343e-12, 1.0061575e-11, 5.620961e-12, 5.1491111e-12, 9.7073259e-12, 2.690156e-12, 7.136105e-12, 3.9105189e-12, 2.305262e-11, 9.1106498e-12, 1.7891949e-11, 1.515811e-11, 2.2325894e-11, 1.4907234e-11, 3.9668407e-11, 2.296881e-11, 2.0173391e-11, 2.3783237e-11, 1.961962e-11, 3.8646121e-12, 1.466025e-11, 1.2476068e-11, 4.1588375e-12, 1.4916349e-11, 7.0600755e-12, 1.0899789e-12, 1.9369746e-12, 8.2886638e-12, 1.4640909e-11, 6.0101121e-12, 1.5824368e-11, 6.2542069e-12, 3.9383074e-12, 4.4448375e-12, 1.3129099e-11, 5.8919551e-12, 2.6262423e-12, 9.3675273e-12, 7.495578e-12, 9.0743023e-12, 1.9489792e-12, 4.1585041e-12, 1.1289385e-11, 3.254264e-12, 2.727615e-11, 2.6855208e-11, 3.0241524e-11, 1.5608951e-11, 6.0245621e-13, 1.2463396e-11, 2.1251699e-11, 4.9694857e-12, 1.8488292e-11, 1.7308167e-11, 2.8451051e-12, 3.8551974e-11, 7.7724633e-12, 2.0788852e-11, 1.4494296e-11, 1.0015112e-11, 1.7135544e-12, 2.2126038e-11, 1.0695043e-11, 3.7801571e-11, 1.9514913e-11, 1.7230915e-11, 3.0993482e-11, 1.6909679e-11, 3.4409142e-11, 4.2537633e-12, 2.2227744e-11, 3.6879213e-11, 2.2517635e-11, 2.2170278e-11, 7.1939054e-13, 4.0701364e-12, 2.1823143e-11, 8.1009242e-12, 2.3839704e-11, 5.1708973e-12, 1.1727444e-11, 6.3424634e-12, 1.2382143e-11, 3.5569378e-14, 7.6585302e-12, 2.4730716e-12, 7.9594248e-12, 9.8192583e-12, 1.0134825e-11, 9.5584903e-12, 8.8383217e-12, 2.6082353e-12, 1.8433826e-11, 3.5326054e-11, 4.4339666e-11, 1.2091719e-10, 1.7084625e-10, 2.5967619e-10, 3.634545e-10, 5.5290375e-10, 7.9605286e-10, 1.1043283e-09, 1.5812387e-09, 2.2285323e-09, 3.1469275e-09, 4.4479603e-09, 6.2269566e-09, 8.6930763e-09, 1.2104844e-08, 1.6837257e-08, 2.3295801e-08, 3.2212568e-08, 4.4334733e-08, 6.0893725e-08, 8.337456e-08, 1.1391194e-07, 1.5513682e-07, 2.1066381e-07, 2.8526479e-07, 3.8513473e-07, 5.184716e-07, 6.9585825e-07, 9.3118369e-07, 1.2422554e-06, 1.6522398e-06, 2.1907008e-06, 2.8955934e-06, 3.8152406e-06, 5.0109495e-06, 6.5602045e-06, 8.560473e-06, 1.1133904e-05, 1.4432841e-05, 1.864643e-05, 2.4008378e-05, 3.0806173e-05, 3.939168e-05, 5.0193482e-05, 6.373087e-05, 8.0629924e-05, 0.00010164123, 0.00012766014, 0.00015974814, 0.00019915717, 0.00024735442, 0.00030604959, 0.00037722223, 0.00046314986, 0.0005664359, 0.00069003607, 0.00083728324, 0.0010119086, 0.0012180594, 0.0014603103, 0.0017436691, 0.0020735744, 0.0024558851, 0.0028968594, 0.0034031258, 0.003981642, 0.004639646, 0.0053845953, 0.0062241002, 0.0071658477, 0.0082175215, 0.0093867167, 0.010680855, 0.012107097, 0.013672263, 0.015382752, 0.017244475, 0.019262788, 0.021442444, 0.023787554, 0.026301551, 0.028987178, 0.031846482, 0.034880815, 0.038090856, 0.041476629, 0.045037541, 0.048772415, 0.052679542, 0.056756722, 0.061001318, 0.065410308, 0.069980336, 0.074707762, 0.079588712, 0.084619126, 0.089794796, 0.095111412, 0.1005646, 0.10614993, 0.11186299, 0.11769939, 0.12365474, 0.12972476, 0.13590521, 0.14219195, 0.14858094, 0.15506823, 0.16164999, 0.16832252, 0.1750822, 0.18192558, 0.18884927, 0.19585005, 0.20292479, 0.21007048, 0.21728423, 0.22456326, 0.23190489, 0.23930656, 0.2467658, 0.25428023, 0.2618476, 0.26946571, 0.27713249, 0.28484593, 0.2926041, 0.30040517, 0.30824737, 0.31612901, 0.32404845, 0.33200415, 0.33999461, 0.34801838, 0.3560741, 0.36416044, 0.37227612, 0.38041992, 0.38859065, 0.39678719, 0.40500842, 0.4132533, 0.42152079, 0.42980991, 0.4381197, 0.44644922, 0.45479757, 0.46316387, 0.47154727, 0.47994692, 0.48836204, 0.49679172, 0.50523546, 0.5136919, 0.52216136, 0.53064128, 0.53913374, 0.54763397, 0.55614653, 0.56466445, 0.57319362, 0.58172722, 0.59026928, 0.59881622, 0.60736834, 0.61592511, 0.62448513, 0.63304813, 0.64161313, 0.65017946, 0.65874591, 0.6673123, 0.67587697, 0.68443953, 0.69299866, 0.70155352, 0.71010264, 0.71864521, 0.72717945, 0.73570421, 0.74421761, 0.75271796, 0.76120312, 0.76967072, 0.77811816, 0.78654216, 0.79493922, 0.8033049, 0.81163417, 0.81992079, 0.82815731, 0.83633452, 0.84444109, 0.85246275, 0.86038162, 0.86817472, 0.8758128, 0.88325778, 0.89046056, 0.89735742, 0.90386671, 0.90988573, 0.91528921, 0.91993422, 0.92366278, 0.92634106, 0.92784161, 0.92829757, 0.9282984, 0.9282713, 0.92826961, 0.92826595, 0.92826551, 0.92826812, 0.92827398, 0.92827656, 0.92827988, 0.92828388, 0.92829462, 0.92829526, 0.928294, 0.92829365, 0.92829214, 0.92828957, 0.92828995, 0.92828473, 0.92825203, 0.92821711, 0.92810413, 0.92797596, 0.92781776, 0.92765406, 0.92748905, 0.92733948, 0.92722197, 0.92714752, 0.92712163, 0.92711871, 0.92711722, 0.92711593, 0.92711253, 0.92710873, 0.92709741, 0.92708225, 0.92705974, 0.92703606, 0.92701366, 0.9269948, 0.92697989, 0.92696832, 0.92695887, 0.92695033, 0.92694183, 0.92693296, 0.92692374, 0.92691443, 0.92690531, 0.92689663, 0.92688847, 0.92688082, 0.92687357, 0.92686657, 0.92685967, 0.92685275, 0.92684576, 0.92683874, 0.92683178, 0.92682498, 0.92681835, 0.92681197, 0.92680587, 0.92680037, 0.92679479, 0.9267895, 0.9267835, 0.92677779, 0.92677267, 0.92676776, 0.92676293, 0.92675801, 0.92675287, 0.92674735, 0.92674134, 0.92673479, 0.92672762, 0.92671977, 0.92671123, 0.92670216, 0.92669224, 0.92668065, 0.92666776, 0.92665596, 0.9266461, 0.92663748, 0.92662607, 0.9266169, 0.92660872, 0.9266022, 0.92659765, 0.9265949, 0.92659375, 0.92659388, 0.92659495, 0.92659702, 0.92659938, 0.926602, 0.92660442, 0.92660629, 0.92660738, 0.92660746, 0.92660629, 0.92660383, 0.9266003, 0.92659594, 0.92659129, 0.92658667, 0.92658204, 0.92657723, 0.92657201, 0.92656638, 0.92656039, 0.92655414, 0.92654714, 0.92653966, 0.92653448, 0.92652956, 0.92652316, 0.92651643, 0.92650962, 0.9265021, 0.92649434, 0.9264865, 0.92647784, 0.9264687, 0.92645885, 0.9264501, 0.9264418, 0.92643157, 0.92642051, 0.92640881, 0.92639628, 0.92638275, 0.92636804, 0.92635188, 0.92633396, 0.92631386, 0.92629103, 0.9262648, 0.92623425, 0.92619825, 0.92615529, 0.92610345, 0.92604026, 0.9259625, 0.92586606, 0.92574562, 0.92559432, 0.92540335, 0.92516138, 0.92485383, 0.92446195, 0.92396167, 0.92332208, 0.92250349, 0.92145494, 0.92011106, 0.91838798, 0.91617815, 0.91334364, 0.9097076, 0.90504345, 0.8990609, 0.89138843, 0.88155109, 0.86894299, 0.85279399, 0.83213126, 0.80573957, 0.77213127, 0.72955327, 0.67609096, 0.60999109, 0.53041726, 0.43882191, 0.34056529, 0.24517568, 0.1632928, 0.1014608, 0.059707787, 0.033806, 0.018665709, 0.010154046, 0.005479122, 0.0029441638, 0.0015787208, 0.00084568651, 0.00045280042, 0.00024238724, 0.00012973898, 6.9440429e-05, 3.7165985e-05, 1.9891759e-05, 1.064624e-05, 5.6978887e-06, 3.049471e-06, 1.6320517e-06, 8.7343127e-07, 4.6743332e-07, 2.5014952e-07, 1.3384814e-07, 7.1615183e-08, 3.8302331e-08, 2.0481096e-08, 1.0948229e-08, 5.8510068e-09, 3.1322059e-09, 1.6631885e-09, 8.57237e-10, 4.4180893e-10, 2.3606094e-10, 1.0653837e-10, 4.8445804e-11, 3.8261163e-11, 4.5305767e-12, 3.0781683e-11, 1.9434374e-11, 1.4308533e-11, 1.6763067e-11, 1.0900001e-11, 7.5461885e-12, 2.7021852e-11, 5.7774899e-12, 7.0599212e-12, 6.0658537e-12, 1.4065233e-11, 2.1357799e-11, 2.7991834e-11, 3.1688949e-13, 5.4280789e-12, 1.650667e-11, 4.0891069e-11, 5.6260599e-11, 3.8895053e-11, 2.5336844e-11, 3.9860262e-11, 1.6378804e-11, 1.7282189e-11, 1.3859227e-11, 1.4629087e-13, 8.4004028e-12, 2.5132947e-11, 2.0514684e-11, 5.5260427e-11, 5.613007e-11, 8.2709276e-11, 4.497345e-11, 5.2929541e-11, 5.7110263e-11, 6.9544209e-11, 7.4599235e-11, 3.1559311e-11, 6.120341e-11, 2.6694862e-11, 2.024641e-11, 1.515409e-11, 1.5751907e-11, 1.5740807e-11, 4.6726499e-12, 4.2641121e-11, 3.1802278e-11, 5.9698102e-11, 2.4635248e-12, 1.1014436e-11, 5.2965502e-12, 1.8254279e-11, 1.4623092e-11, 3.7850483e-11, 1.9546146e-12, 4.8512512e-11, 1.8027185e-11, 4.4816947e-11, 1.7458116e-11, 6.9470286e-11, 4.9698711e-11, 6.6345123e-11, 3.3800291e-11, 7.1974213e-11, 3.7158654e-11, 8.4838374e-11, 1.3432009e-11, 8.3507327e-11, 3.8679835e-11, 6.5401114e-11, 1.2362687e-11, 7.8441534e-11, 2.1142137e-11, 3.1710818e-11, 5.3928159e-11, 5.3182054e-11, 4.5290117e-11, 2.5674045e-11, 5.923259e-11, 4.5728657e-11, 5.7957485e-11, 2.930157e-11, 6.1021046e-11, 4.9183585e-11, 8.4027003e-11, 2.2707049e-11, 5.8156498e-11, 4.7588149e-11, 5.6304331e-11, 2.8830176e-11, 5.8142069e-11, 2.744907e-11, 2.3922773e-11, 5.1634678e-12, 3.7483424e-11, 2.7852314e-11, 1.821976e-12, 1.8758099e-14, 7.2568256e-12, 5.5144882e-11, 2.234554e-11, 3.6724e-11, 2.7349841e-11, 3.4800685e-11, 5.3074278e-12, 1.20751e-11, 1.5684422e-11, 3.8380594e-11, 2.5202207e-11, 5.6174357e-11, 1.8072359e-11, 2.6781216e-11, 1.4482462e-11, 8.3793138e-12, 1.3220897e-11, 1.6602569e-12, 3.0230928e-11, 3.3592287e-11, 5.5116578e-11, 6.3377683e-11, 7.4435962e-11, 5.0469568e-11, 4.3236495e-11, 3.3662436e-11, 1.3699395e-11, 5.1504926e-11, 4.373253e-11, 3.3496388e-11, 2.4427687e-11, 3.8436202e-11, 3.5448894e-11, 3.257369e-11, 2.7977294e-11, 2.8831508e-11, 1.2698557e-11, 2.5001751e-11, 1.3384836e-11, 1.971075e-11, 1.2994357e-11, 1.3088148e-11, 1.6582923e-11, 8.1139258e-12, 3.5938158e-11, 1.4750514e-11, 9.3928053e-12, 1.7985562e-12, 1.590963e-11, 4.7555628e-12, 3.5563773e-12, 1.7015469e-12, 8.9185254e-12, 1.5699961e-11, 5.2750174e-12, 1.1218555e-11, 1.7849038e-12, 1.03296e-11, 4.5309097e-12, 2.6763013e-11, 4.5335736e-12, 1.0454357e-11, 3.0471342e-11, 3.211051e-11, 6.2507818e-11, 2.9848218e-11, 6.2961897e-11, 7.356532e-11, 6.8332703e-11, 1.0839231e-10, 7.1992638e-11, 8.1141477e-11, 8.1786356e-11, 7.4219744e-11, 6.9918038e-11, 5.0034581e-11, 3.6349171e-11, 3.1050956e-11, 4.2421795e-11, 2.0902277e-11, 5.2895244e-11, 1.9525611e-11, 3.3844467e-12, 4.1533062e-11, 1.4276123e-12, 1.8104215e-11, 4.7198225e-12, 3.7571221e-11, 1.4317191e-11, 2.9038957e-11, 7.6348731e-12, 4.6844152e-12, 1.2681686e-11, 3.2787799e-12, 1.2783024e-11, 1.5131891e-12, 2.1837961e-11, 1.92186e-11, 2.6969464e-12, 3.3476409e-11, 1.9815418e-11, 4.5208647e-11, 3.9951056e-11, 5.1660762e-11, 2.2907727e-11, 9.1554989e-12, 1.1622131e-11, 7.3245325e-13, 1.5328351e-12, 1.4989152e-11, 1.7662567e-12, 4.8820966e-12, 4.0439765e-12, 5.3799072e-13, 8.3456824e-12, 1.4397107e-12, 1.3843466e-11, 1.4267576e-11, 2.6067188e-11, 7.6877066e-12, 1.781463e-12, 1.741505e-13, 7.2234163e-12, 5.1667977e-12, 9.0937859e-12, 1.0709645e-11, 1.1865432e-11, 3.2584679e-12, 2.2026874e-11, 3.0745489e-14, 2.639551e-11, 1.0207727e-11, 1.4503662e-12, 1.5962685e-11, 2.4756564e-11, 7.4725991e-12, 1.5719829e-11, 5.8238855e-13, 9.3606168e-12, 1.618523e-12, 3.9659917e-11, 1.3356755e-11, 3.2485339e-11, 4.5040491e-12, 9.7542039e-13, 1.4630528e-11, 2.525604e-11, 2.6123684e-11, 5.2356587e-11, 4.3091204e-11, 5.4287227e-11, 1.4033045e-11, 4.9993291e-11, 2.206439e-11, 5.5926728e-11, 3.1548655e-11, 4.8612296e-11, 4.2891746e-11, 3.7626385e-11, 6.0400808e-11, 4.8195178e-11, 4.3433289e-11, 4.8251453e-11, 4.4334343e-11, 3.9629061e-11, 5.6315542e-11, 5.0820089e-11, 2.6441018e-11, 7.3309811e-11, 2.3628415e-11, 2.9492814e-11, 2.7083565e-11, 4.0127648e-11, 2.8342355e-11, 5.2944525e-11, 4.2551659e-11, 3.3472302e-11, 3.773072e-11, 4.7997164e-11, 2.9040733e-11, 5.0418622e-11, 3.3453877e-11, 1.0104946e-12, 2.723363e-12, 4.1511973e-12, 1.8644792e-20];\nlet data5 = [8.8755469e-22, 1.8272653e-11, 1.0733613e-11, 2.7953635e-11, 4.0261304e-11, 4.0519627e-11, 2.6162828e-11, 1.8507411e-11, 3.7509347e-11, 1.2686038e-12, 4.4012317e-11, 1.0528311e-11, 3.9979306e-11, 7.1194322e-13, 3.1690309e-11, 1.1239254e-11, 2.5174778e-11, 9.4864624e-12, 3.0043224e-11, 7.6723133e-12, 4.0573981e-11, 8.6146793e-12, 1.1601506e-11, 9.6370764e-12, 2.5131094e-11, 1.7846932e-12, 8.4477253e-13, 1.0806197e-11, 3.1424205e-11, 1.6773181e-12, 4.5035937e-11, 1.64286e-13, 2.3256255e-11, 4.8283198e-12, 2.2983149e-11, 1.3398093e-11, 8.522977e-12, 1.1698655e-11, 8.3994846e-12, 1.9472119e-11, 9.1014239e-12, 1.4485737e-11, 2.5002155e-11, 2.4439826e-11, 1.9087858e-11, 1.7320616e-11, 1.3126209e-11, 1.3104534e-11, 1.6955919e-11, 1.3026837e-11, 4.9831132e-11, 2.7873382e-11, 2.1826589e-11, 1.7490015e-11, 1.2527421e-11, 1.3321285e-11, 8.621682e-12, 1.0819202e-11, 6.0263407e-12, 2.0526639e-11, 1.3794247e-11, 6.3775882e-12, 8.5345371e-12, 1.1445557e-12, 1.5747005e-11, 7.6131792e-12, 1.3336847e-11, 3.2547086e-12, 1.1789246e-11, 2.1615173e-11, 1.3106757e-11, 2.0772179e-11, 5.7986967e-12, 2.3010048e-11, 4.2337555e-12, 3.3382188e-11, 2.4994819e-11, 2.4757838e-11, 9.6001732e-12, 2.5441437e-11, 1.2652692e-11, 7.9859907e-12, 1.3192346e-11, 1.3035396e-11, 1.2489296e-12, 1.3751119e-11, 8.4677333e-13, 2.0941467e-13, 9.1730073e-12, 1.1213022e-11, 3.2567093e-12, 1.4686371e-11, 9.470345e-13, 8.1800661e-12, 9.6435234e-12, 8.1576129e-13, 8.6654768e-12, 7.5295912e-13, 2.0637238e-11, 8.718942e-12, 1.378202e-11, 1.1651748e-11, 7.9914372e-12, 2.2589885e-12, 4.1193777e-13, 3.5602716e-13, 2.0938799e-11, 2.5269481e-11, 1.4724497e-11, 2.2813083e-11, 2.8044115e-11, 3.1476003e-11, 5.1240791e-11, 3.116077e-11, 4.8701916e-11, 1.4031005e-12, 4.8881208e-11, 1.3291496e-11, 3.5871044e-11, 1.2820202e-11, 2.3258256e-11, 2.273772e-12, 2.8150934e-11, 1.1085417e-12, 1.6619122e-11, 4.5584372e-12, 4.3841473e-12, 2.1139322e-12, 3.0644124e-12, 1.1742783e-11, 4.1777338e-12, 1.7036172e-11, 5.4652338e-12, 3.793529e-11, 1.9054957e-11, 2.8574321e-11, 1.9084857e-11, 8.7654045e-12, 9.5515988e-12, 3.4541194e-12, 1.4369359e-11, 2.913465e-12, 1.5769125e-11, 2.4605112e-12, 1.4840209e-12, 2.4542532e-11, 7.2936106e-12, 2.9159214e-11, 3.3566371e-12, 1.9202681e-11, 1.3955643e-11, 1.1239477e-11, 2.3841371e-11, 1.4453503e-11, 1.159417e-11, 6.5890036e-12, 2.2701706e-11, 3.6958577e-11, 3.4684249e-11, 2.9639512e-11, 2.7414648e-11, 4.862233e-11, 2.9069958e-11, 3.5153987e-11, 3.4429039e-11, 2.6555981e-11, 4.0850644e-11, 3.0675804e-11, 5.1219449e-11, 4.77441e-12, 2.655398e-11, 3.1386969e-11, 3.4213511e-11, 3.624141e-11, 1.6622679e-11, 2.5780791e-11, 2.4026665e-11, 3.4672912e-11, 3.4961802e-11, 4.0297207e-11, 1.2481292e-11, 2.0136821e-11, 1.155471e-11, 6.5982295e-12, 1.4902899e-11, 5.9878813e-12, 8.4771815e-12, 3.4797627e-11, 1.4078135e-11, 1.2861551e-11, 1.4217078e-11, 2.1404981e-12, 1.2843099e-11, 6.4858527e-13, 1.2323787e-11, 1.2841877e-11, 3.1050505e-11, 4.7659733e-11, 1.9660414e-11, 5.4314429e-11, 2.442382e-11, 5.7484994e-11, 1.7082524e-11, 2.6238524e-11, 2.5719323e-11, 3.2529301e-12, 1.2547429e-11, 2.1220464e-12, 1.3222358e-11, 5.7659062e-12, 2.8632788e-11, 6.9821563e-12, 8.9501429e-12, 3.6701033e-11, 9.392537e-12, 2.6822418e-11, 2.0672807e-11, 3.2724488e-11, 2.9320499e-11, 1.7357964e-11, 2.0273208e-11, 5.9623159e-13, 3.8840641e-12, 1.1987434e-11, 1.1992325e-11, 1.167987e-11, 1.5016833e-11, 6.9690401e-12, 1.071016e-11, 5.2178044e-12, 1.2835207e-11, 3.3371851e-12, 1.4056015e-11, 1.9366189e-11, 1.4011331e-11, 2.3000156e-11, 5.0676683e-11, 3.700215e-12, 3.983914e-11, 2.8753501e-11, 4.2976137e-11, 3.1558369e-11, 4.0128364e-11, 2.7488788e-11, 4.5937731e-11, 3.1377521e-11, 3.7956298e-11, 2.371899e-11, 3.973121e-11, 1.0394926e-11, 2.6689255e-11, 1.6875999e-11, 2.4361129e-11, 5.4975797e-12, 3.1841145e-11, 1.5992656e-11, 1.7503243e-11, 1.3029505e-11, 1.2633018e-11, 1.9364521e-11, 9.046736e-12, 4.2479833e-12, 3.8152596e-12, 3.0043891e-12, 1.8084357e-11, 1.1009721e-11, 2.5575378e-11, 2.2657022e-11, 2.4589551e-11, 2.361206e-11, 2.7337952e-11, 2.7915287e-11, 7.6091777e-12, 8.3942603e-12, 2.236024e-11, 1.2721719e-11, 1.8846431e-11, 2.3197232e-11, 1.0804974e-11, 1.9368745e-11, 4.2606548e-12, 7.4951334e-13, 1.3374862e-11, 4.3480221e-12, 1.0584111e-11, 1.3272933e-12, 1.8003215e-11, 1.7960198e-11, 2.2397699e-11, 3.3285484e-11, 3.7689861e-11, 5.3303481e-11, 9.9480416e-11, 7.7390503e-11, 1.7477177e-10, 2.272775e-10, 3.0180055e-10, 4.3190998e-10, 6.1628025e-10, 8.5127097e-10, 1.2009967e-09, 1.6950411e-09, 2.3772034e-09, 3.3206575e-09, 4.6423437e-09, 6.4769579e-09, 9.0289383e-09, 1.2518788e-08, 1.7366293e-08, 2.3993656e-08, 3.3123488e-08, 4.5587198e-08, 6.2621576e-08, 8.5697329e-08, 1.1700797e-07, 1.5926845e-07, 2.1624124e-07, 2.9268777e-07, 3.9509373e-07, 5.31683e-07, 7.1341492e-07, 9.5435111e-07, 1.2728411e-06, 1.6923936e-06, 2.2433017e-06, 2.9642088e-06, 3.9044963e-06, 5.1265713e-06, 6.7095317e-06, 8.7526142e-06, 1.1380275e-05, 1.4747547e-05, 1.9046987e-05, 2.4516235e-05, 3.1447689e-05, 4.0198829e-05, 5.120511e-05, 6.499374e-05, 8.2200111e-05, 0.0001035856, 0.0001300579, 0.0001626927, 0.00020275786, 0.0002517386, 0.00031136464, 0.00038363743, 0.00047085867, 0.0005756576, 0.00070101771, 0.00085030094, 0.0010272691, 0.0012361002, 0.0014814008, 0.0017682101, 0.0021019974, 0.0024886507, 0.0029344562, 0.0034460673, 0.0040304647, 0.0046949055, 0.0054468639, 0.0062939633, 0.0072439014, 0.0083043699, 0.0094829708, 0.010787131, 0.012224019, 0.013800462, 0.015522872, 0.017397174, 0.019428746, 0.02162237, 0.023982191, 0.026511687, 0.029213656, 0.032090202, 0.03514275, 0.038372053, 0.041778217, 0.045360735, 0.04911852, 0.053049949, 0.057152909, 0.061424846, 0.06586281, 0.070463511, 0.075223362, 0.080138533, 0.085204989, 0.090418541, 0.09577488, 0.10126961, 0.1068983, 0.11265649, 0.11853973, 0.12454359, 0.13066372, 0.13689581, 0.14323565, 0.14967913, 0.15622222, 0.16286103, 0.16959178, 0.17641082, 0.1833146, 0.19029974, 0.19736295, 0.20450109, 0.21171115, 0.21899023, 0.22633556, 0.23374448, 0.24121448, 0.24874313, 0.25632813, 0.26396728, 0.27165847, 0.27939973, 0.28718915, 0.29502494, 0.30290538, 0.31082886, 0.31879385, 0.32679891, 0.33484267, 0.34292387, 0.35104133, 0.35919394, 0.36738069, 0.37560068, 0.3838531, 0.39213724, 0.40045251, 0.40879849, 0.41717482, 0.42558146, 0.43401829, 0.442486, 0.45098432, 0.45951561, 0.46807855, 0.47667818, 0.48531154, 0.49398337, 0.50269278, 0.51142777, 0.52019435, 0.52894898, 0.53767062, 0.54619037, 0.55499055, 0.56387567, 0.57088999, 0.58186201, 0.5861534, 0.60021703, 0.60134738, 0.61785314, 0.61911379, 0.63651665, 0.63678505, 0.65784138, 0.6578795, 0.68603009, 0.68845669, 0.71563473, 0.7134741, 0.71776554, 0.72108445, 0.72489199, 0.72923484, 0.73324986, 0.73173841, 0.73678235, 0.73840361, 0.74979991, 0.75581631, 0.77310827, 0.7704936, 0.78042619, 0.78220028, 0.7940975, 0.79340896, 0.80760385, 0.81136595, 0.80745767, 0.80743041, 0.80738714, 0.8133333, 0.81768179, 0.83020585, 0.83392377, 0.84706516, 0.84821172, 0.84909587, 0.85421756, 0.85347514, 0.86521386, 0.86563354, 0.88757134, 0.88371381, 0.89109113, 0.89310991, 0.89495336, 0.89530943, 0.90088965, 0.9056695, 0.90624354, 0.90462222, 0.90913183, 0.90974483, 0.91466033, 0.91320631, 0.91956892, 0.91835912, 0.92343729, 0.92382604, 0.92693279, 0.92690753, 0.92814953, 0.92854157, 0.92852411, 0.92780793, 0.92735543, 0.92691682, 0.92688725, 0.9267973, 0.92683193, 0.92684918, 0.92670024, 0.92654014, 0.92619538, 0.92608007, 0.92586642, 0.92592779, 0.92550746, 0.92549336, 0.92519671, 0.92510795, 0.92486953, 0.92480406, 0.92477448, 0.92478989, 0.92478722, 0.92486421, 0.92485254, 0.92500294, 0.92502212, 0.92520048, 0.92511055, 0.92517063, 0.92517352, 0.92527893, 0.92528055, 0.92535972, 0.92536251, 0.92539352, 0.92544885, 0.92554893, 0.92559441, 0.92564226, 0.92546138, 0.92548614, 0.92552699, 0.92546651, 0.92542342, 0.92534365, 0.92535393, 0.92537345, 0.92523031, 0.9252568, 0.92505143, 0.9249375, 0.92487305, 0.92485538, 0.92463872, 0.92422622, 0.92384466, 0.92351762, 0.92330762, 0.92339761, 0.92297597, 0.92342119, 0.92266706, 0.92357812, 0.92389217, 0.92388786, 0.92420779, 0.92468576, 0.92435758, 0.92440925, 0.92437358, 0.92438647, 0.92439618, 0.9243746, 0.92442331, 0.92447101, 0.92455341, 0.92467416, 0.92476762, 0.92486624, 0.92492277, 0.92502235, 0.92511518, 0.92534355, 0.92523595, 0.92525984, 0.92497355, 0.92495751, 0.92494348, 0.92493844, 0.92494037, 0.9249994, 0.92507841, 0.92526106, 0.92523889, 0.92552905, 0.92556646, 0.92580527, 0.92587979, 0.92601391, 0.9260997, 0.92623408, 0.92650175, 0.92670573, 0.92672, 0.9264975, 0.92642097, 0.92643383, 0.92653644, 0.92657195, 0.92656547, 0.92653991, 0.92654973, 0.92677317, 0.92675649, 0.92710071, 0.92713023, 0.92744911, 0.92763419, 0.92775855, 0.92771742, 0.92759541, 0.92761257, 0.92770025, 0.92775435, 0.92774143, 0.92765611, 0.92784568, 0.92794316, 0.92835903, 0.92857216, 0.92895711, 0.92898694, 0.92887355, 0.92885884, 0.92890899, 0.92882222, 0.92849467, 0.92815199, 0.92705378, 0.92504573, 0.92195214, 0.91754425, 0.91146947, 0.90331449, 0.89244729, 0.87812935, 0.85940026, 0.83510999, 0.80387083, 0.7640899, 0.7140365, 0.65203482, 0.57693332, 0.48907501, 0.39176494, 0.29237997, 0.20176242, 0.12922921, 0.077781305, 0.04470325, 0.024914804, 0.013636957, 0.0073884694, 0.0039820163, 0.0021403102, 0.0011488503, 0.0006162604, 0.00033046778, 0.0001771866, 9.4995694e-05, 5.0928843e-05, 2.7303412e-05, 1.4637492e-05, 7.8471456e-06, 4.2068227e-06, 2.2552263e-06, 1.2090172e-06, 6.4813081e-07, 3.4746604e-07, 1.8628374e-07, 9.9837153e-08, 5.3508618e-08, 2.8684448e-08, 1.5368512e-08, 8.2270942e-09, 4.4169899e-09, 2.3592016e-09, 1.2645366e-09, 6.5020614e-10, 3.5471392e-10, 1.6778529e-10, 1.0050526e-10, 5.1615698e-11, 1.0800772e-11, 1.7813076e-11, 4.995311e-11, 3.1669195e-11, 3.3961344e-11, 1.1708041e-11, 2.5872614e-11, 1.0639829e-11, 1.9704757e-11, 4.8069532e-12, 1.7319594e-11, 2.2914165e-11, 8.8837842e-12, 1.4515871e-12, 4.1505313e-12, 1.3497718e-11, 2.0270718e-11, 3.6340735e-12, 4.1322172e-12, 2.1671026e-11, 5.2655829e-12, 2.0408351e-11, 1.8707248e-11, 2.5831435e-11, 8.2879649e-13, 1.7264541e-11, 2.4574207e-13, 1.8723787e-11, 5.4721549e-11, 5.3244099e-12, 4.0799387e-12, 3.1560754e-11, 1.171348e-11, 1.5634696e-11, 1.064105e-12, 1.6620661e-11, 1.1558643e-11, 1.7717288e-11, 1.1078591e-11, 1.8877403e-11, 2.0996179e-11, 1.401018e-11, 1.9477884e-11, 1.7053762e-11, 2.1874811e-12, 2.624145e-11, 6.7389027e-11, 4.4233116e-11, 2.6371202e-11, 1.7523158e-11, 1.1761985e-11, 1.7927844e-11, 5.71389e-12, 1.9180751e-11, 1.1333324e-11, 1.6342287e-11, 1.9778013e-11, 1.501457e-11, 2.0305681e-11, 2.9919033e-11, 4.83337e-12, 3.7838718e-11, 4.8999667e-12, 4.1883472e-11, 2.0392146e-11, 3.8322654e-11, 6.206606e-11, 4.4075393e-11, 3.2064669e-11, 5.9149122e-11, 5.2948188e-11, 6.3164129e-11, 8.962113e-11, 4.4416146e-11, 1.0008559e-10, 3.4554944e-11, 7.4140605e-11, 1.188985e-11, 6.6591309e-11, 3.9916093e-11, 5.8978968e-11, 4.1150352e-11, 1.2497435e-11, 9.8640881e-13, 1.3660214e-11, 1.4786143e-11, 1.1291035e-11, 2.8940616e-11, 2.9410234e-12, 3.2128269e-11, 2.2550769e-11, 2.3148697e-11, 4.3842193e-11, 2.3608103e-11, 6.6996661e-11, 2.563664e-11, 8.4134335e-11, 2.7177578e-11, 8.6780779e-11, 7.6754528e-11, 9.3666772e-11, 7.6846209e-11, 4.7693483e-11, 3.9477664e-11, 3.5640137e-11, 3.4006408e-11, 1.3857673e-12, 2.7787826e-11, 1.7218922e-11, 8.4016237e-12, 1.8166372e-11, 2.496257e-11, 7.3955687e-13, 2.7269148e-11, 2.6721834e-11, 1.790276e-11, 1.3086927e-11, 4.7405896e-11, 4.2377064e-11, 1.2679133e-11, 4.8221706e-11, 5.814562e-12, 1.7775671e-11, 2.2400926e-12, 5.3610382e-13, 3.6900148e-12, 5.3574531e-11, 1.0308511e-11, 3.1199244e-11, 1.5624707e-11, 1.2150577e-12, 1.1282599e-11, 1.3037423e-12, 3.3328342e-12, 3.5065297e-11, 2.928148e-12, 1.0302739e-11, 1.7476874e-11, 2.517457e-11, 5.6404116e-12, 6.4988436e-11, 3.1622356e-11, 7.7872687e-11, 4.7857644e-11, 7.8295132e-11, 4.5235286e-11, 4.5798916e-11, 2.2290264e-11, 3.8032182e-11, 3.4512877e-11, 5.2836861e-11, 4.524805e-11, 7.8457073e-11, 3.9417283e-11, 6.1127601e-11, 4.0157173e-11, 3.5567658e-11, 2.9153947e-11, 1.1805273e-11, 2.9678064e-11, 5.7686103e-12, 5.7457454e-12, 3.2302197e-11, 4.9529666e-11, 4.6999878e-11, 5.174534e-11, 1.7997327e-11, 2.8981795e-11, 5.713224e-12, 7.3452883e-12, 1.7813853e-11, 8.047995e-12, 2.8741158e-11, 1.1843011e-11, 3.2613315e-11, 3.2346595e-11, 1.4849854e-11, 3.6456059e-11, 3.2138592e-11, 2.9605806e-11, 4.3727425e-12, 3.0369671e-11, 2.1015048e-11, 3.601652e-11, 1.1914491e-11, 1.3487728e-11, 3.9754928e-12, 1.0703429e-11, 7.4307541e-12, 4.1479785e-12, 1.0173985e-11, 2.0516016e-11, 1.3770764e-11, 1.0646267e-11, 1.7800534e-11, 3.2188317e-11, 3.6530203e-11, 6.5765398e-12, 2.0016763e-12, 1.8334085e-12, 1.0266888e-11, 1.4851519e-11, 2.2044189e-11, 6.0457638e-12, 2.5460048e-11, 1.4669155e-11, 2.4177394e-11, 5.8807037e-11, 6.2834032e-12, 6.6183848e-12, 1.6271806e-13, 1.8075134e-11, 2.2461973e-12, 5.3903408e-12, 1.6028505e-11, 4.0313232e-13, 3.2548272e-11, 4.1948181e-12, 1.1798724e-12, 6.5309211e-12, 6.6507952e-12, 8.8736836e-12, 1.6863184e-11, 1.6735319e-11, 1.9874467e-11, 1.2464469e-11, 2.6440019e-12, 9.8318998e-12, 2.0435212e-12, 1.1405914e-11, 1.9396969e-11, 1.3411475e-12, 8.558903e-12, 1.631254e-11, 8.5403669e-12, 4.0904832e-12, 8.2904072e-12, 1.7191951e-12, 5.3472749e-12, 2.5418536e-11, 1.5305265e-11, 7.2793575e-12, 5.020973e-11, 1.3790522e-11, 2.0260951e-12, 7.3462872e-12, 1.5602508e-12, 1.2291651e-11, 1.3710272e-11, 5.3200812e-12, 7.043827e-12, 8.1839633e-12, 3.117982e-11, 1.4296324e-11, 3.3934817e-11, 9.2874715e-12, 1.71975e-11, 1.5451111e-11, 2.1490771e-12, 1.0344473e-11, 4.5709788e-12, 6.2577634e-12, 2.0089797e-11, 4.5736648e-11, 3.6199883e-11, 2.7324757e-11, 5.4422973e-11, 3.1747225e-11, 3.6302997e-11, 4.2841466e-11, 5.7356338e-11, 5.2325509e-11, 5.2084095e-11, 3.44798e-11, 9.686164e-12, 1.4551611e-11, 4.7665845e-11, 4.0686173e-12, 1.1008331e-11, 2.4060184e-11, 1.879005e-11, 2.6862908e-11, 3.4303985e-12, 7.5572879e-12, 1.8099951e-20];\nlet data4 = [2.9640062e-21, 9.3329583e-12, 2.7505128e-12, 1.2046123e-11, 9.4759025e-13, 1.3365413e-11, 2.8670914e-11, 2.0633236e-11, 2.3636847e-11, 3.4316662e-12, 2.0934353e-11, 2.3455777e-12, 5.9056272e-12, 1.0987934e-11, 1.5653969e-11, 2.2826977e-11, 1.0468955e-11, 6.6778159e-12, 7.2381446e-12, 8.0519052e-12, 1.0072245e-11, 4.5852253e-12, 9.4651207e-12, 1.260145e-11, 3.3677525e-12, 6.1690628e-12, 4.4931896e-12, 2.3751447e-12, 7.724e-12, 1.3185121e-12, 1.6603671e-11, 1.4090473e-11, 8.0091108e-12, 2.9737105e-12, 4.5938954e-12, 1.2772628e-11, 2.4963029e-12, 4.7423975e-12, 1.1312616e-11, 1.2850213e-11, 1.2648024e-11, 1.9927407e-11, 5.9455315e-12, 1.6689038e-11, 2.1524916e-11, 3.2399806e-11, 1.0232752e-11, 7.1952391e-12, 6.7022699e-12, 1.3764457e-11, 1.1613733e-11, 1.7275043e-11, 1.6410819e-12, 2.666369e-12, 3.8416032e-12, 1.6578661e-12, 1.1866276e-11, 6.4615097e-12, 8.1140404e-12, 3.4703479e-12, 1.5422657e-12, 3.8004761e-12, 1.1784577e-12, 1.2324898e-11, 1.3230583e-11, 3.6088461e-12, 1.758383e-11, 1.4494518e-13, 1.2159945e-11, 1.0882004e-12, 1.4816533e-11, 8.6553618e-12, 1.9557374e-11, 2.2128373e-11, 3.168564e-12, 1.1052737e-11, 7.2584859e-12, 1.0890897e-12, 1.6109479e-11, 4.9710419e-12, 1.3393535e-11, 1.7507244e-11, 7.0728583e-12, 3.611725e-11, 7.3771987e-12, 1.8627457e-11, 2.3087856e-12, 2.7133872e-12, 4.2321994e-12, 2.7794684e-11, 6.4452812e-12, 2.5169665e-11, 8.9348037e-12, 1.2712715e-12, 1.5921295e-11, 1.0449725e-11, 6.3035594e-13, 1.2070577e-11, 1.1566381e-11, 3.5177663e-11, 1.4124486e-11, 4.1937956e-11, 1.7787131e-11, 4.9642726e-11, 2.4534752e-11, 3.7980641e-11, 3.7185554e-12, 2.2332341e-11, 4.5134197e-12, 2.1476786e-11, 1.8698596e-11, 1.5798803e-11, 3.1917953e-12, 1.737775e-11, 1.1408987e-11, 7.2948333e-12, 1.8829758e-11, 4.0927008e-12, 3.0558536e-11, 4.9908286e-14, 2.5212015e-11, 1.9438661e-11, 2.7429542e-12, 1.734985e-11, 1.2607119e-12, 1.4012776e-11, 2.0970145e-11, 3.2229629e-11, 2.7516688e-11, 3.1972752e-11, 3.8435373e-11, 1.5694985e-11, 2.1617841e-11, 3.5497899e-11, 2.7793128e-11, 3.0138373e-11, 1.1688318e-11, 4.4370122e-11, 3.9459771e-12, 2.8765617e-11, 5.9882147e-12, 1.1967093e-11, 1.1350186e-11, 2.7869714e-12, 3.1948409e-11, 1.1738559e-11, 3.4116584e-12, 1.1020503e-11, 1.8829537e-13, 1.7159998e-11, 2.3805913e-12, 8.3825892e-12, 7.3541897e-12, 1.4197737e-11, 6.3963733e-12, 1.9021833e-11, 1.0141939e-11, 3.5838587e-11, 1.2702378e-11, 6.4226057e-12, 1.1199794e-11, 1.5978428e-12, 1.847851e-11, 9.7903582e-12, 2.389328e-11, 1.1467788e-12, 1.2559545e-11, 8.4380551e-12, 5.9497553e-12, 8.2975561e-12, 1.7023279e-12, 6.496301e-12, 2.0455723e-12, 3.3916618e-11, 1.1009943e-11, 2.0572546e-11, 7.4501159e-12, 1.6909234e-11, 1.3017278e-12, 2.511242e-11, 1.2519307e-11, 1.3066964e-11, 9.6181802e-12, 2.9619282e-12, 8.4008185e-12, 6.7134964e-12, 6.4966344e-12, 3.0185057e-12, 9.5896135e-12, 5.3267356e-12, 2.0195844e-11, 5.2957235e-12, 1.6285881e-11, 4.8516622e-12, 1.6781518e-11, 4.7132751e-12, 1.7246921e-11, 3.1046836e-11, 3.3466221e-11, 4.5161096e-11, 2.7890166e-11, 4.8981358e-11, 1.9105087e-11, 3.9502787e-11, 4.4925449e-11, 1.3337403e-11, 2.8367462e-11, 3.8099576e-11, 3.391584e-11, 2.2406369e-11, 4.5648174e-11, 3.0683362e-11, 1.1119319e-11, 2.2178503e-11, 3.9817688e-11, 4.3980638e-11, 4.2083457e-11, 3.1904503e-11, 3.5951408e-11, 2.0441495e-11, 3.4121142e-11, 2.3310165e-11, 4.710474e-11, 6.8178703e-12, 1.8060793e-11, 4.0326774e-12, 2.5641959e-11, 9.9446403e-12, 1.5113203e-11, 3.1063176e-12, 1.5865162e-11, 2.2517079e-11, 1.3830149e-11, 1.5724997e-12, 1.6482735e-11, 6.9053487e-12, 2.8235633e-11, 5.6019536e-12, 9.9887685e-12, 1.6630682e-11, 1.2960591e-13, 3.5512682e-12, 1.0279659e-11, 1.9133098e-11, 1.8250644e-11, 2.2588773e-12, 2.7064401e-11, 1.0553543e-11, 1.6625013e-11, 2.5463223e-12, 1.8596112e-11, 4.1845142e-12, 1.1992991e-11, 2.5180225e-11, 1.9251144e-11, 7.6910983e-12, 2.1652188e-11, 2.3425098e-11, 6.2203049e-12, 9.2353648e-12, 5.592172e-12, 1.6659804e-11, 1.4916794e-11, 8.5797769e-12, 2.5034946e-11, 2.176701e-11, 1.3789356e-11, 1.8613452e-11, 6.2498719e-12, 3.7386743e-12, 1.1784355e-11, 5.3595261e-12, 1.5875055e-12, 2.5069737e-11, 1.8245976e-12, 1.5287716e-11, 1.2674923e-12, 1.5658749e-11, 4.4738488e-12, 1.0064131e-11, 2.1842484e-11, 1.1868499e-11, 3.7473221e-11, 5.8434918e-12, 1.7942524e-11, 5.2399241e-12, 2.1522137e-11, 2.8356569e-12, 1.2945806e-11, 7.3661946e-13, 2.1775121e-13, 2.5093969e-11, 2.5642182e-11, 5.9632939e-11, 9.0133341e-11, 1.6135389e-10, 2.3653087e-10, 3.4442833e-10, 5.2040302e-10, 7.5668623e-10, 1.0945064e-09, 1.5515373e-09, 2.1963396e-09, 3.1317283e-09, 4.3789956e-09, 6.1486076e-09, 8.5833479e-09, 1.19644e-08, 1.6609804e-08, 2.3053427e-08, 3.1830126e-08, 4.3877079e-08, 6.0203165e-08, 8.2486321e-08, 1.1266521e-07, 1.5346586e-07, 2.0842465e-07, 2.8222683e-07, 3.8105991e-07, 5.1301255e-07, 6.8860458e-07, 9.2150284e-07, 1.2294442e-06, 1.6352882e-06, 2.1683996e-06, 2.8662775e-06, 3.7768487e-06, 4.960847e-06, 6.4950875e-06, 8.4761234e-06, 1.1025082e-05, 1.4292922e-05, 1.8467174e-05, 2.3779574e-05, 3.0515209e-05, 3.9023052e-05, 4.9728285e-05, 6.3146081e-05, 7.9897671e-05, 0.00010072802, 0.00012652577, 0.00015834491, 0.0001974285, 0.00024523382, 0.00030345928, 0.00037407188, 0.00045933524, 0.00056183756, 0.00068451808, 0.00083069205, 0.0010040722, 0.0012087865, 0.0014493903, 0.0017308722, 0.0020586523, 0.0024385723, 0.0028768758, 0.0033801792, 0.0039554328, 0.0046098717, 0.0053509572, 0.0061863106, 0.0071236385, 0.0081706536, 0.0093349915, 0.010624125, 0.012045281, 0.013605355, 0.01531084, 0.01716775, 0.019181563, 0.021357164, 0.023698808, 0.026210085, 0.028893907, 0.031752493, 0.03478738, 0.037999428, 0.041388851, 0.044955238, 0.048697596, 0.052614388, 0.056703578, 0.060962683, 0.065388817, 0.069978743, 0.074728923, 0.079635565, 0.084694668, 0.08990207, 0.095253481, 0.10074453, 0.10637077, 0.11212778, 0.11801109, 0.12401628, 0.13013899, 0.13637492, 0.14271983, 0.1491696, 0.15572022, 0.16236776, 0.16910843, 0.17593856, 0.18285462, 0.18985317, 0.19693094, 0.20408476, 0.2113116, 0.21860854, 0.2259728, 0.23340171, 0.24089272, 0.24844338, 0.25605136, 0.26371444, 0.27143049, 0.27919747, 0.28701346, 0.2948766, 0.30278512, 0.31073734, 0.31873165, 0.32676651, 0.33484045, 0.34295207, 0.35110001, 0.35928299, 0.36749977, 0.37574917, 0.38403004, 0.39234128, 0.40068184, 0.4090507, 0.41744686, 0.42586937, 0.43431733, 0.44278987, 0.4512863, 0.45980599, 0.46834908, 0.47691568, 0.48550833, 0.49412819, 0.50277771, 0.51145706, 0.52012893, 0.52870413, 0.53745872, 0.54569641, 0.55388735, 0.56171361, 0.5703083, 0.57884008, 0.58839631, 0.5996874, 0.61464584, 0.63299906, 0.65300355, 0.66843974, 0.67260683, 0.67187109, 0.67378822, 0.67461145, 0.68013213, 0.68891798, 0.69906228, 0.71024186, 0.72634787, 0.72348441, 0.72350901, 0.72400258, 0.72931793, 0.73820286, 0.73928349, 0.74211056, 0.74537831, 0.74721972, 0.75008908, 0.75974998, 0.77083627, 0.77855188, 0.78093807, 0.77979187, 0.78006009, 0.78150724, 0.78188001, 0.78078482, 0.78972435, 0.80253125, 0.81073706, 0.81642665, 0.82116291, 0.82579555, 0.83115008, 0.83771477, 0.84467652, 0.85217798, 0.85965702, 0.86636392, 0.87269061, 0.87912294, 0.8857938, 0.89319124, 0.90139898, 0.90847588, 0.91591374, 0.92256061, 0.92905685, 0.93537009, 0.94484613, 0.95172695, 0.96261748, 0.96689615, 0.97052233, 0.96835432, 0.96371894, 0.95353748, 0.94646765, 0.93869513, 0.93300715, 0.92707869, 0.92303702, 0.91664736, 0.91744421, 0.91719413, 0.91974339, 0.92136019, 0.92451412, 0.92669603, 0.92989174, 0.93016046, 0.93012549, 0.93004485, 0.92979559, 0.92964667, 0.92934676, 0.92917201, 0.92833142, 0.92825144, 0.92832679, 0.92894541, 0.928823, 0.9286215, 0.92814636, 0.92772128, 0.92714753, 0.92684216, 0.92646554, 0.92618261, 0.92590351, 0.92572693, 0.92561247, 0.925564, 0.92557124, 0.92559663, 0.92590674, 0.92589498, 0.9258723, 0.92548199, 0.92527586, 0.92514624, 0.92517072, 0.92519455, 0.92517294, 0.92511427, 0.92507073, 0.92508099, 0.9251498, 0.92523651, 0.92531842, 0.92532105, 0.92534056, 0.92546288, 0.92567932, 0.92587718, 0.92603413, 0.92630519, 0.92622569, 0.92618911, 0.9260881, 0.92611963, 0.92617353, 0.92629568, 0.92638431, 0.92644902, 0.92639186, 0.92632513, 0.92625433, 0.92626243, 0.92623303, 0.92622917, 0.92625492, 0.92623275, 0.92630611, 0.92630213, 0.92631903, 0.92629826, 0.92631528, 0.92630902, 0.92627638, 0.92626638, 0.92621553, 0.92630114, 0.92641228, 0.92647963, 0.92653698, 0.92665872, 0.92689599, 0.92705079, 0.92742487, 0.92732687, 0.9273452, 0.9272198, 0.92721382, 0.92703998, 0.92694653, 0.92701832, 0.92741031, 0.92757705, 0.92722499, 0.9266838, 0.92646418, 0.9263108, 0.92630487, 0.92665255, 0.92756567, 0.92795025, 0.92775351, 0.92732948, 0.92723394, 0.92680679, 0.92634006, 0.92634952, 0.92671698, 0.92693975, 0.92722617, 0.92694944, 0.9269312, 0.92720149, 0.92852329, 0.93030914, 0.93027955, 0.92985191, 0.92960996, 0.92935124, 0.92847124, 0.92810666, 0.92809806, 0.92914492, 0.93069296, 0.93146786, 0.93042349, 0.93049376, 0.93052707, 0.93109751, 0.93098899, 0.93069666, 0.93047184, 0.9297293, 0.92802123, 0.92532139, 0.92149254, 0.91629255, 0.90932378, 0.90007065, 0.88787749, 0.87192529, 0.85120664, 0.82450355, 0.79038292, 0.747226, 0.69333741, 0.6272038, 0.5481055, 0.45723604, 0.35909776, 0.26221379, 0.1771453, 0.11142655, 0.066168553, 0.037697689, 0.020907893, 0.011417705, 0.0061818558, 0.0033325675, 0.0017925853, 0.00096317242, 0.00051724591, 0.00027770297, 0.00014907787, 8.0024386e-05, 4.2955751e-05, 2.3057529e-05, 1.2376637e-05, 6.6433276e-06, 3.5659077e-06, 1.9140184e-06, 1.0273475e-06, 5.5140358e-07, 2.9595236e-07, 1.5884068e-07, 8.5240279e-08, 4.5735953e-08, 2.4536113e-08, 1.3110006e-08, 7.0446593e-09, 3.7344034e-09, 2.0400243e-09, 1.0665481e-09, 5.4378742e-10, 2.7004349e-10, 1.5812854e-10, 7.4338287e-11, 3.3561209e-11, 2.8333919e-11, 8.868467e-13, 3.0858713e-12, 3.5963354e-12, 3.4917785e-12, 1.017121e-11, 2.2028983e-11, 4.0346086e-11, 1.7580209e-11, 4.2501933e-11, 1.4422969e-11, 1.8196895e-11, 4.8419165e-12, 1.6136947e-11, 1.9557134e-11, 1.3521138e-11, 2.5140272e-11, 2.0023977e-11, 3.3199034e-11, 4.6221473e-11, 6.582134e-11, 1.3640679e-11, 1.8451073e-11, 2.6909526e-12, 2.8481986e-11, 3.7241345e-11, 2.7911807e-11, 3.1812378e-11, 2.4314584e-11, 3.0230262e-11, 8.3786478e-12, 3.2504762e-12, 2.3156355e-11, 2.5427859e-11, 1.8178248e-11, 2.6479089e-11, 2.9286697e-11, 6.2549886e-12, 2.2235655e-11, 9.7529828e-12, 8.7256168e-12, 2.3332615e-11, 7.4472923e-12, 3.7661016e-11, 3.9459128e-11, 4.3172452e-11, 4.6146551e-11, 7.0674356e-11, 3.8188906e-11, 2.234998e-11, 1.691735e-11, 2.136912e-11, 1.0642604e-11, 2.3709996e-11, 1.7593085e-11, 4.2050074e-11, 5.7920745e-11, 2.3162904e-11, 2.0006773e-11, 4.6649913e-12, 2.0054834e-11, 3.429455e-11, 4.7810915e-12, 1.6627987e-11, 3.419521e-12, 3.9087851e-12, 2.5789369e-11, 8.5253827e-12, 4.5741865e-11, 3.9988016e-12, 4.2880647e-11, 4.4876219e-12, 5.7759137e-11, 1.0324161e-11, 4.5343838e-11, 1.571317e-11, 4.2209574e-11, 3.6910248e-11, 4.0849557e-11, 1.7327808e-11, 6.036085e-11, 3.0158338e-12, 6.5229405e-11, 2.2726917e-11, 1.035959e-10, 1.3112123e-11, 7.8468617e-11, 2.6461552e-11, 9.2848187e-11, 4.8677117e-11, 7.3172067e-11, 3.0248465e-11, 2.8176973e-11, 3.4641409e-13, 4.5031611e-12, 1.198919e-11, 5.4409543e-12, 2.3406093e-11, 3.6406222e-12, 5.9825856e-11, 5.5350777e-11, 6.1321841e-11, 7.566667e-11, 4.7177247e-11, 1.7426815e-11, 3.9422611e-11, 3.2878814e-12, 1.7982232e-12, 2.9966761e-11, 1.5093043e-12, 3.8254837e-11, 6.3659832e-12, 5.8671402e-11, 3.0131144e-11, 3.1009222e-11, 2.9751986e-11, 2.6061527e-12, 1.7776004e-11, 1.8748538e-11, 2.6435912e-11, 8.2280281e-13, 3.9124035e-11, 2.5456274e-11, 6.8715634e-12, 3.539384e-11, 5.4937877e-12, 4.8476439e-11, 3.7622612e-11, 1.7812965e-11, 3.2490666e-11, 1.3793518e-11, 3.0020593e-11, 1.0668244e-11, 3.3360087e-11, 6.4262532e-12, 3.2945411e-11, 5.8499693e-12, 1.1105896e-11, 1.2388216e-11, 1.3703169e-11, 1.0369113e-12, 5.5859132e-12, 1.8173365e-11, 1.6084224e-12, 2.9652202e-11, 1.3880982e-12, 3.0761038e-12, 2.2155628e-12, 1.2362909e-11, 8.4855356e-12, 2.2690733e-11, 1.6411326e-11, 1.5741251e-11, 3.9831626e-11, 9.5729495e-12, 1.8957319e-11, 7.9878359e-12, 7.3632694e-12, 1.4530301e-12, 2.3316964e-11, 1.4322851e-11, 1.6770726e-11, 2.1865821e-11, 3.0555143e-11, 2.9852991e-11, 1.0491763e-11, 3.8597699e-11, 1.0835291e-12, 5.5185839e-11, 7.7102384e-12, 4.2228443e-11, 2.6358549e-11, 7.4350274e-11, 3.3509153e-11, 7.2135821e-11, 3.9783121e-11, 7.1883087e-11, 6.8346466e-11, 1.0074878e-10, 4.945419e-11, 7.1265513e-11, 4.4255093e-11, 4.7498021e-11, 2.0786621e-11, 2.3789135e-11, 1.531259e-11, 4.4703844e-11, 2.086687e-11, 1.5181173e-11, 3.7472991e-11, 5.671046e-12, 1.4036486e-11, 2.6176185e-11, 3.2143364e-11, 2.0150622e-11, 1.6476923e-11, 5.9871808e-11, 4.4838036e-11, 8.377327e-11, 4.2277835e-11, 6.7988065e-11, 2.0570736e-11, 5.2125163e-11, 7.5326471e-12, 4.0375055e-11, 5.1529011e-11, 5.4923447e-12, 5.0088968e-11, 8.3812007e-12, 5.7186738e-11, 4.427485e-11, 4.3078328e-11, 4.2777533e-11, 6.7281806e-11, 2.7674279e-11, 6.5181123e-11, 2.0746774e-11, 4.5545405e-11, 1.2051347e-11, 4.6774892e-11, 3.5612056e-11, 1.0890677e-11, 3.2721868e-11, 2.6763013e-12, 2.1213284e-11, 2.694682e-11, 4.6181182e-11, 3.9528389e-11, 5.5938493e-11, 7.7387863e-11, 4.8343023e-11, 4.6970464e-11, 3.0434492e-11, 2.6478534e-11, 3.7708521e-11, 7.0224384e-11, 5.3415919e-11, 7.0918877e-11, 3.5120794e-11, 4.0638334e-11, 3.359029e-11, 1.6493795e-11, 1.6370813e-11, 1.2935419e-11, 8.2199256e-12, 5.8821577e-12, 2.9659417e-11, 1.4651276e-14, 3.7516168e-12, 2.661539e-12, 1.2588561e-11, 4.1916659e-11, 6.7540424e-11, 2.2157182e-11, 6.5171355e-11, 2.284557e-11, 5.3456321e-11, 6.3659832e-12, 2.8300288e-11, 3.3745682e-12, 3.498305e-11, 6.4931823e-14, 5.2362803e-12, 5.407445e-11, 7.3582746e-12, 3.4267578e-11, 1.3745568e-12, 4.2672865e-11, 1.9696543e-11, 4.5940767e-11, 3.1288928e-11, 1.7027012e-11, 1.6064467e-11, 2.6515051e-11, 1.1543436e-13, 2.1729409e-12, 2.676046e-11, 1.3155522e-11, 7.0774583e-12, 3.9662803e-12, 2.8672231e-11, 1.7701194e-11, 2.2506038e-11, 1.5213916e-11, 2.1611318e-20];\nlet data7 = [2.8477683e-20, 1.9817254e-11, 2.1635317e-10, 1.809108e-10, 3.3037479e-10, 3.1952347e-10, 8.4635997e-11, 6.7923694e-11, 8.1165126e-11, 3.8541257e-11, 2.1220779e-10, 8.8978506e-11, 1.5024543e-10, 1.0109516e-10, 1.1924985e-10, 1.5972819e-10, 1.3589799e-10, 5.5968904e-11, 5.9218579e-11, 1.4418632e-10, 6.8115023e-11, 1.4655948e-10, 2.5399996e-11, 2.3202602e-10, 1.9469538e-11, 2.6029821e-10, 2.6356826e-10, 2.0576201e-10, 2.9054878e-10, 9.7460678e-11, 5.1290831e-10, 2.0877626e-10, 4.8137136e-10, 2.3414674e-10, 4.9323768e-10, 1.7236458e-10, 2.7703685e-10, 2.1815489e-10, 2.2927159e-10, 2.9775453e-10, 3.7796739e-10, 4.2749079e-10, 3.3366027e-10, 3.1802514e-10, 2.4735136e-10, 3.6288265e-10, 3.0970653e-10, 3.5424183e-10, 2.1602941e-10, 2.4179075e-10, 2.952367e-10, 3.8359151e-10, 4.9834974e-10, 4.3116471e-10, 3.7808902e-10, 3.6538443e-10, 5.1141341e-10, 5.2062858e-10, 5.2599717e-10, 5.2491092e-10, 4.512288e-10, 4.7755334e-10, 3.6242088e-10, 3.3089726e-10, 3.088043e-10, 2.425945e-10, 3.1302036e-10, 1.9574006e-10, 3.6476364e-10, 1.7781339e-10, 3.4295644e-10, 1.4802614e-10, 2.1914047e-10, 1.0554173e-10, 2.5820686e-10, 1.8239021e-10, 2.0159706e-10, 2.0936174e-11, 2.02232e-10, 7.9556056e-11, 2.7654249e-10, 1.1959572e-10, 2.5486029e-10, 7.5607268e-12, 1.6671328e-10, 1.8532479e-10, 1.6790936e-10, 2.5386076e-10, 1.3592029e-10, 1.90552e-10, 1.312331e-10, 2.3270266e-10, 5.3277926e-11, 8.607033e-11, 5.2760181e-11, 2.2919825e-11, 1.2535519e-10, 1.6959737e-10, 1.049109e-10, 2.782024e-11, 6.1551883e-11, 4.8213281e-11, 1.0873528e-10, 8.0136791e-11, 1.4437715e-10, 1.7885345e-11, 2.2846276e-10, 2.3411295e-11, 3.2771467e-10, 1.1241968e-10, 3.5625737e-10, 8.5255682e-11, 2.3003975e-10, 7.3182836e-11, 8.2392924e-11, 8.2526453e-11, 2.8599207e-11, 3.3357279e-11, 3.2393904e-11, 6.0353097e-11, 1.6471975e-11, 2.7220928e-11, 6.7487991e-11, 3.4596827e-11, 1.4466908e-10, 1.0913542e-10, 3.886743e-11, 1.7155191e-10, 1.9649472e-10, 3.0039176e-10, 2.1706912e-10, 1.7937359e-10, 5.2531302e-12, 7.9055027e-12, 1.5239417e-10, 6.7756783e-11, 1.0415159e-10, 2.3479438e-10, 7.9120719e-11, 1.484773e-10, 7.5912829e-11, 1.993482e-11, 2.4164178e-10, 2.9148732e-11, 1.3744549e-11, 2.2941906e-10, 2.774089e-10, 2.1098422e-10, 1.3233328e-10, 1.5952605e-10, 1.9464789e-10, 4.7715155e-11, 1.5999093e-10, 7.649121e-11, 2.1009985e-10, 1.452682e-10, 2.0044788e-10, 7.6618975e-12, 3.6200604e-11, 1.8525448e-10, 9.7877338e-11, 2.8069348e-12, 2.0239038e-11, 1.9796622e-11, 1.3152776e-11, 1.9356596e-10, 2.6752626e-11, 2.3772909e-10, 1.430706e-11, 3.2829193e-10, 3.419622e-11, 4.3060049e-10, 1.0813806e-10, 3.7939735e-10, 9.8199581e-11, 3.2751842e-10, 6.5516255e-11, 6.6882809e-11, 1.0962431e-10, 2.4312811e-10, 3.511733e-10, 1.8942962e-10, 2.2945665e-10, 1.4616836e-10, 4.5135341e-11, 9.7068791e-11, 3.8640586e-11, 1.2930635e-10, 8.1348505e-11, 9.5416082e-11, 1.8570819e-10, 1.1855809e-10, 1.9283651e-10, 1.0581354e-10, 1.0844812e-10, 9.5097879e-11, 1.3290397e-10, 3.5893166e-10, 2.5249281e-11, 5.4991348e-10, 9.0886239e-11, 4.3684268e-10, 1.4355966e-10, 5.3188724e-10, 1.2617057e-10, 3.7926679e-10, 1.3789329e-10, 1.6742864e-10, 4.1086368e-11, 7.0177179e-11, 1.2346572e-11, 5.9132882e-14, 7.8648206e-13, 7.0490142e-12, 3.6924912e-12, 5.6042079e-11, 7.2597309e-11, 2.0615028e-10, 2.7642091e-10, 2.6228259e-10, 9.9983201e-11, 2.1552475e-12, 4.8360516e-11, 2.0368089e-11, 8.7008727e-11, 3.7743871e-11, 1.0942598e-10, 1.6518165e-10, 1.242478e-10, 1.4404817e-10, 1.6390056e-10, 3.4234109e-10, 1.440687e-10, 2.7340136e-10, 5.2112998e-11, 1.0796456e-10, 4.6046917e-11, 1.6697214e-10, 6.8456262e-12, 1.0125462e-10, 4.7842905e-11, 2.1396614e-10, 3.5911615e-11, 2.9679157e-10, 1.3415511e-10, 2.7936568e-10, 2.1178514e-10, 4.3080251e-10, 4.2927147e-10, 5.0658213e-10, 4.6356507e-10, 6.5276704e-10, 4.8260318e-10, 6.6818873e-10, 5.6053824e-10, 5.2016442e-10, 5.9334532e-10, 5.4408245e-10, 5.1616447e-10, 4.7639677e-10, 5.8710287e-10, 5.7388639e-10, 5.4723248e-10, 5.8585824e-10, 6.392226e-10, 7.1603609e-10, 6.2675589e-10, 7.8034298e-10, 6.5468454e-10, 7.7678248e-10, 5.9770753e-10, 7.3561387e-10, 5.091355e-10, 5.7069555e-10, 4.4704192e-10, 4.5896522e-10, 5.2184403e-10, 6.2306429e-10, 5.872771e-10, 6.9971574e-10, 6.8471009e-10, 6.7302519e-10, 4.6299314e-10, 6.3234335e-10, 4.7836513e-10, 7.4206463e-10, 5.6813867e-10, 8.0981043e-10, 6.6875664e-10, 7.3005264e-10, 7.0932665e-10, 6.8507835e-10, 6.2430738e-10, 6.9547164e-10, 6.5583485e-10, 5.1924179e-10, 7.0097115e-10, 5.2655282e-10, 6.563908e-10, 5.5960659e-10, 6.619308e-10, 4.9482656e-10, 5.3791057e-10, 4.4873093e-10, 4.3237599e-10, 3.2823616e-10, 4.3226711e-10, 2.2101743e-10, 2.6649277e-10, 1.6903861e-10, 2.1312479e-10, 1.7537258e-10, 1.7326172e-10, 5.3140063e-11, 1.7270464e-11, 2.6298704e-11, 1.2999494e-11, 1.1822559e-11, 1.4736385e-10, 1.4860663e-10, 1.1970659e-10, 4.6003957e-11, 1.29762e-10, 1.6484604e-10, 2.2191799e-10, 7.8584122e-11, 1.1429746e-10, 2.6841091e-11, 1.3831702e-10, 2.2084829e-10, 1.6325195e-10, 2.4149503e-10, 6.1705914e-11, 3.6353002e-10, 9.8185172e-11, 3.4585628e-10, 6.2212222e-12, 1.398224e-10, 6.0760331e-12, 1.6543115e-10, 4.8727664e-11, 3.6482602e-10, 2.8267297e-10, 4.6532468e-10, 1.9670647e-10, 4.4901017e-10, 1.2678165e-10, 4.1018904e-10, 1.8250552e-09, 4.1534681e-09, 9.4402826e-09, 1.9585692e-08, 4.0855308e-08, 8.2272735e-08, 1.637779e-07, 3.2005018e-07, 6.1731524e-07, 1.1731282e-06, 2.1975343e-06, 4.0552083e-06, 7.3716991e-06, 1.3194619e-05, 2.3245815e-05, 4.0291446e-05, 6.867536e-05, 0.00011505047, 0.00018933885, 0.00030591933, 0.00048498838, 0.00075396411, 0.0011487021, 0.0017141973, 0.0025043679, 0.0035805309, 0.0050081363, 0.006852056, 0.0091706344, 0.012009175, 0.01539368, 0.019325493, 0.023778893, 0.028706448, 0.03405052, 0.039752921, 0.045760023, 0.052024883, 0.058507644, 0.065175076, 0.071999732, 0.078959028, 0.086034375, 0.093210427, 0.10047445, 0.10781579, 0.11522552, 0.12269605, 0.1302209, 0.13779453, 0.1454121, 0.15306944, 0.16076286, 0.16848914, 0.1762454, 0.18402908, 0.19183791, 0.19966982, 0.20752299, 0.21539573, 0.22328651, 0.23119396, 0.23911681, 0.24705388, 0.25500412, 0.26296652, 0.27094019, 0.27892425, 0.28691792, 0.29492045, 0.30293117, 0.31094941, 0.31897457, 0.32700609, 0.33504346, 0.34308619, 0.35113386, 0.35918609, 0.36724252, 0.37530278, 0.3833665, 0.39143312, 0.39950231, 0.40757347, 0.41564732, 0.42372248, 0.43180034, 0.43987062, 0.44793718, 0.45597733, 0.46403705, 0.4720927, 0.48028065, 0.4885131, 0.49695726, 0.5053638, 0.51370983, 0.52166575, 0.52911717, 0.53630063, 0.54350976, 0.55065175, 0.5576987, 0.56515963, 0.57414881, 0.58581203, 0.60106133, 0.61920826, 0.63441176, 0.64444496, 0.65045212, 0.6552307, 0.6599221, 0.6650715, 0.67001146, 0.67061167, 0.67113711, 0.67315375, 0.67797767, 0.68199324, 0.68571826, 0.69335833, 0.70237947, 0.70950038, 0.71685984, 0.7241968, 0.73129851, 0.73900574, 0.75115207, 0.75963027, 0.76905855, 0.78322163, 0.79159857, 0.79245248, 0.79107474, 0.78888644, 0.78973313, 0.79291809, 0.80155304, 0.81233827, 0.82142127, 0.82650645, 0.82950388, 0.83326463, 0.83366361, 0.83176001, 0.83146794, 0.83202915, 0.83384987, 0.83933199, 0.84790874, 0.85610776, 0.86331973, 0.86895249, 0.87437673, 0.87886068, 0.88107721, 0.88256128, 0.88637201, 0.8903003, 0.89170068, 0.8913573, 0.88855065, 0.88565698, 0.88533144, 0.88606156, 0.88671645, 0.88791243, 0.88913495, 0.8891744, 0.88764162, 0.88782382, 0.88955391, 0.89185602, 0.89196857, 0.89173273, 0.89275971, 0.89683466, 0.90014227, 0.90019847, 0.89987414, 0.89742712, 0.89417066, 0.89250583, 0.89142793, 0.89044687, 0.89000899, 0.89008642, 0.8905574, 0.89235167, 0.89543507, 0.89656239, 0.89636287, 0.89559705, 0.89308331, 0.89015943, 0.88955618, 0.88997233, 0.8915667, 0.89541263, 0.89933524, 0.90012366, 0.89982421, 0.89974462, 0.89953149, 0.89852051, 0.89717144, 0.8962689, 0.89562133, 0.89390928, 0.88979206, 0.88653296, 0.88673392, 0.88801113, 0.8919161, 0.89805037, 0.90365521, 0.90506388, 0.90454156, 0.90286096, 0.89988196, 0.89693817, 0.89508255, 0.89482766, 0.89446222, 0.8935049, 0.89149568, 0.89126409, 0.89133746, 0.89155296, 0.891861, 0.89210393, 0.89241619, 0.89270213, 0.89185516, 0.8909092, 0.89204971, 0.89389175, 0.89439182, 0.89561993, 0.89863491, 0.89857581, 0.89790874, 0.89807274, 0.8975778, 0.89576727, 0.89454615, 0.89394598, 0.89344243, 0.89313787, 0.89326778, 0.89456251, 0.89627034, 0.89716934, 0.89706067, 0.89644184, 0.8951939, 0.89524545, 0.8955355, 0.89648327, 0.89645648, 0.89620751, 0.89535335, 0.89266434, 0.89107604, 0.89119897, 0.89146252, 0.89201422, 0.89367523, 0.89515785, 0.89514318, 0.89468989, 0.8936907, 0.89203612, 0.89111186, 0.89147443, 0.89267491, 0.89616509, 0.89965218, 0.90041286, 0.90012019, 0.89926374, 0.89733478, 0.89248269, 0.88868208, 0.88865755, 0.88955456, 0.8911347, 0.89408624, 0.89764004, 0.8976562, 0.89715549, 0.8955327, 0.890238, 0.88822536, 0.88957124, 0.89035779, 0.89214842, 0.89442469, 0.90050315, 0.90013322, 0.89675555, 0.88715024, 0.87840912, 0.86407897, 0.85519389, 0.86034735, 0.87677547, 0.89883519, 0.91619161, 0.914784, 0.91060943, 0.90052024, 0.88406818, 0.85282057, 0.8092647, 0.77598062, 0.76502665, 0.74142894, 0.63055733, 0.2403422, 0.024533632, 0.0019871171, 0.00015601923, 1.2184269e-05, 9.5273907e-07, 7.4937229e-08, 5.953439e-09, 4.8536166e-10, 3.6191332e-10, 3.4116245e-10, 3.3277232e-10, 2.2153077e-10, 3.2855396e-10, 8.620493e-11, 8.181629e-11, 3.5578282e-10, 2.3914764e-11, 4.8847353e-10, 2.7332507e-10, 4.7721934e-10, 3.6431553e-10, 2.2384307e-10, 3.9855979e-10, 3.8645977e-10, 3.5036318e-10, 1.726803e-10, 2.9928474e-10, 1.9461675e-10, 3.7171756e-10, 1.7373108e-10, 3.7679966e-10, 4.8863157e-10, 3.8452728e-10, 4.2056852e-10, 3.3878678e-10, 3.6588632e-10, 3.3653803e-10, 1.6154007e-10, 3.2305978e-10, 2.7894117e-10, 6.7424967e-11, 1.0233268e-11, 4.5023441e-11, 8.146e-11, 1.1299926e-10, 7.1518314e-11, 5.3754675e-11, 7.0855331e-11, 1.2622738e-11, 7.8869489e-13, 1.4741204e-10, 5.0156919e-11, 9.4527367e-11, 3.6979398e-11, 1.6238011e-10, 3.9140888e-10, 9.6569923e-11, 4.8952982e-11, 1.125599e-10, 6.9977177e-11, 9.3216288e-11, 8.5504999e-12, 1.6346375e-10, 3.3393236e-10, 1.215359e-10, 1.2327146e-11, 3.1730176e-11, 3.9845058e-12, 1.4821947e-10, 5.8621841e-11, 4.0178273e-11, 8.2939545e-11, 1.962649e-10, 2.6365975e-10, 4.681282e-10, 3.1397343e-10, 1.725423e-10, 3.385972e-10, 1.1452388e-10, 1.2711137e-10, 1.0347447e-10, 9.8208115e-11, 3.625952e-11, 4.4265293e-11, 1.0968569e-10, 1.833644e-10, 1.8868279e-11, 6.4592718e-11, 1.77071e-10, 5.7097743e-11, 7.5745921e-11, 2.433641e-10, 2.6176833e-10, 1.9938034e-10, 7.8585294e-11, 1.7420073e-10, 1.5080546e-10, 7.284895e-11, 1.3081094e-10, 8.2025894e-11, 4.0778175e-12, 2.7453699e-10, 8.3939684e-11, 8.6642635e-11, 4.5338077e-11, 7.5067079e-12, 1.7119446e-10, 4.3341007e-11, 2.2271518e-11, 8.4149852e-11, 2.1526762e-10, 1.1833779e-10, 3.1246775e-10, 1.4383031e-10, 1.5289642e-10, 2.8087521e-11, 2.2263925e-11, 2.8324233e-10, 2.1168632e-10, 2.0249857e-10, 2.7185546e-10, 2.6738573e-10, 2.8651923e-10, 2.1367628e-10, 2.4703077e-11, 3.8862975e-10, 2.8921211e-10, 1.4230467e-10, 4.1436828e-11, 3.7256349e-11, 3.0538214e-10, 4.5553487e-11, 1.5740043e-10, 2.8861295e-10, 3.3890142e-10, 4.2071341e-11, 2.2142564e-10, 1.0395009e-10, 4.7673354e-10, 1.4339627e-10, 5.8287293e-10, 3.3438255e-11, 5.5037913e-10, 3.3458078e-11, 3.7407164e-10, 3.854368e-10, 2.4011775e-10, 4.5061275e-10, 5.4182422e-10, 3.8275743e-10, 2.9087651e-10, 1.220687e-10, 3.0405937e-10, 7.2546675e-11, 3.2877402e-11, 1.3158057e-10, 3.4092286e-10, 2.2212738e-10, 3.3963692e-10, 2.106994e-10, 4.455069e-10, 2.6300736e-10, 1.3576514e-10, 1.1298729e-10, 3.8279119e-10, 1.8344209e-11, 1.172805e-10, 3.006375e-11, 1.700625e-10, 1.9673638e-10, 1.2044465e-10, 2.5815689e-10, 4.2112812e-10, 5.1276697e-11, 6.7210226e-11, 5.7983457e-11, 1.089576e-10, 3.2672554e-11, 2.7578965e-10, 1.468722e-10, 2.9628548e-10, 3.9326858e-10, 4.8068342e-10, 3.7565781e-10, 3.241546e-10, 2.2195177e-10, 4.566839e-10, 4.1441796e-10, 2.0261894e-10, 3.0922788e-10, 1.225869e-10, 3.1332938e-11, 1.8846258e-10, 4.1431616e-10, 2.4652404e-10, 3.3884929e-10, 4.3479405e-10, 3.2627362e-10, 2.5278098e-10, 3.3640669e-10, 3.5546187e-10, 3.7988848e-10, 5.767901e-11, 7.0454888e-11, 4.3509946e-10, 2.1841129e-10, 4.475982e-10, 2.8222015e-10, 5.4257885e-10, 2.8392429e-10, 6.8963281e-10, 3.1406001e-10, 2.7907842e-10, 2.3343131e-10, 3.4284524e-10, 3.6977625e-10, 2.5203559e-10, 1.8537896e-10, 2.9391517e-10, 7.8858797e-11, 1.3702003e-10, 2.4885264e-10, 2.4011127e-10, 4.10332e-10, 4.5736337e-10, 5.3042462e-10, 6.7751041e-11, 3.1341871e-10, 8.3023325e-11, 1.8255445e-10, 3.4044546e-10, 4.3011966e-11, 2.6184625e-10, 5.8955461e-11, 4.8949175e-10, 2.2769705e-10, 2.7286237e-10, 1.112853e-10, 1.7151728e-10, 8.9115615e-11, 4.1614266e-11, 2.5054228e-10, 1.8822545e-10, 6.7626191e-11, 2.1285241e-11, 5.7091015e-11, 4.433511e-10, 3.1274912e-10, 2.2601838e-10, 6.2294587e-11, 3.1449292e-11, 4.4388366e-10, 1.0949398e-10, 2.5631037e-10, 6.2711095e-11, 5.8124669e-10, 4.1696024e-10, 6.5950828e-10, 1.6011349e-10, 3.2415787e-10, 9.7031873e-11, 1.6982715e-10, 6.3710753e-11, 2.1660822e-10, 5.5002667e-11, 4.6249485e-10, 3.5534175e-10, 4.0977061e-10, 1.1044674e-10, 4.1232996e-10, 1.7613872e-10, 4.7531882e-10, 1.4800221e-10, 5.4628135e-10, 8.7973527e-11, 3.8900734e-10, 4.1719918e-11, 3.5080572e-10, 6.1888695e-12, 5.6905546e-11, 1.0672898e-10, 6.678153e-11, 2.1756497e-10, 9.6035733e-12, 4.9392453e-11, 9.1473808e-11, 4.521796e-11, 1.0588006e-10, 7.3530424e-11, 1.4769092e-10, 1.8944487e-11, 7.2548502e-11, 4.0307835e-10, 2.1403273e-10, 3.4677373e-10, 3.4571903e-10, 2.6744556e-10, 2.3754971e-11, 8.9804591e-12, 1.1953095e-11, 1.2903551e-10, 4.1469275e-11, 1.7462034e-11, 2.2420991e-10, 3.2052671e-11, 1.9999565e-10, 3.9288371e-11, 3.8543651e-12, 3.3792944e-11, 6.5628575e-11, 1.7551484e-10, 1.7002088e-10, 2.8506586e-10, 2.4517918e-10, 3.7002737e-11, 6.9367117e-11, 3.875388e-11, 1.3229345e-11, 1.3489459e-11, 1.9190398e-10, 1.0360143e-11, 1.2232169e-11, 7.9270097e-12, 1.782311e-10, 6.749101e-11, 1.1641828e-10, 1.5052055e-10, 1.0297067e-10, 4.3455144e-12, 1.311254e-10, 2.2328563e-18];\nlet data6 = [2.4736089e-21, 3.557215e-11, 1.4491517e-11, 3.1926845e-12, 9.8094767e-12, 6.4086002e-12, 1.0635131e-11, 1.7253035e-11, 7.2617091e-13, 7.0434024e-12, 9.7921366e-12, 5.3706415e-12, 2.0734942e-11, 1.8722161e-11, 1.6536423e-12, 2.9744887e-12, 6.7616262e-12, 4.6114578e-12, 1.6889115e-11, 1.3241588e-11, 6.2568747e-12, 5.2398129e-12, 2.3631512e-11, 1.5845265e-11, 3.2267866e-11, 3.7653514e-12, 2.8384247e-11, 5.9523119e-12, 4.0711368e-12, 3.092868e-12, 1.645528e-12, 1.4564101e-11, 1.4103256e-11, 1.1685094e-11, 2.1664859e-11, 3.3110082e-11, 5.1585703e-11, 3.3429429e-11, 6.1477878e-11, 2.8549978e-11, 6.3940724e-11, 4.2923005e-11, 6.7488102e-11, 4.6114911e-11, 7.38638e-11, 6.2954229e-11, 5.8148252e-11, 5.1998196e-11, 6.2571525e-11, 6.3686069e-11, 6.6297973e-11, 5.5396516e-11, 3.8656236e-11, 3.7013154e-11, 2.5425876e-11, 5.928347e-11, 1.4655137e-11, 1.3775906e-11, 7.3402954e-12, 1.9464115e-11, 1.3586944e-11, 3.222585e-12, 3.1207677e-12, 7.4854629e-12, 1.5714993e-12, 1.0029451e-12, 1.8254646e-11, 1.6622901e-11, 2.7060288e-11, 2.7576044e-11, 2.2113367e-11, 3.7476556e-11, 2.8651462e-11, 1.0359023e-11, 1.8422378e-11, 2.0315446e-11, 1.144978e-11, 1.2722942e-11, 1.2541982e-11, 1.7565045e-11, 1.1307058e-11, 1.0880448e-11, 3.1376187e-11, 1.5549373e-11, 2.7908618e-11, 1.3636074e-11, 2.6978256e-11, 2.4016439e-11, 3.3378853e-11, 6.3285692e-12, 9.4646761e-12, 1.1684983e-11, 8.3919261e-12, 7.3647494e-12, 4.2612106e-12, 4.1272697e-12, 5.051073e-12, 6.0162256e-12, 5.2336994e-12, 9.1067593e-12, 8.3596914e-12, 2.3193786e-11, 2.4675139e-12, 1.96822e-11, 7.0787494e-12, 1.5689872e-11, 1.3103645e-11, 1.2901678e-11, 5.1338829e-12, 3.0584879e-11, 2.4636347e-11, 4.084931e-11, 1.8863771e-11, 1.7808806e-11, 1.0670256e-11, 2.2720714e-11, 6.5158642e-12, 1.4889783e-11, 1.3300166e-11, 2.1428323e-11, 5.7082171e-12, 1.5145549e-11, 2.9703648e-11, 3.2818747e-11, 5.7270022e-11, 3.4523965e-11, 3.5275701e-11, 3.0865322e-12, 1.1147552e-11, 1.3170782e-11, 2.0258313e-11, 8.1201539e-12, 1.8948693e-11, 4.3070062e-12, 2.0004436e-12, 2.087144e-12, 1.278541e-11, 1.4894674e-12, 7.7514551e-12, 7.6359658e-12, 4.8564418e-12, 1.2659361e-12, 2.5807135e-11, 1.9168779e-11, 2.2039671e-12, 9.3736407e-13, 3.4295543e-12, 8.5977838e-13, 2.1398089e-11, 4.11093e-12, 2.9779344e-12, 9.9719843e-12, 1.2265875e-12, 2.3258256e-11, 2.7452885e-12, 3.5525243e-11, 4.9341387e-13, 2.516055e-11, 3.9548695e-13, 2.2922348e-11, 1.2079136e-12, 1.486344e-11, 2.8566095e-11, 1.1704213e-11, 1.3646523e-11, 3.290667e-11, 1.1824593e-11, 1.9435993e-11, 1.4976484e-11, 6.4421688e-12, 3.1013157e-12, 1.4837763e-11, 2.4438825e-11, 1.8236083e-11, 1.5704544e-11, 1.0533647e-11, 7.9248558e-12, 8.2939992e-12, 1.8438273e-11, 2.6298214e-11, 3.3018713e-11, 4.3504675e-12, 1.2537536e-11, 1.660645e-12, 1.8246976e-11, 9.6453018e-12, 2.9774898e-12, 4.012225e-12, 1.3658638e-11, 4.5602156e-12, 8.7537333e-12, 1.76214e-11, 1.7859048e-11, 1.0328901e-11, 1.946067e-11, 1.7977872e-11, 1.3260373e-11, 8.0306747e-12, 3.7705756e-12, 1.5674755e-11, 2.0868439e-11, 1.0141161e-11, 9.1175413e-12, 2.7824474e-11, 1.8477955e-11, 3.1111084e-11, 1.8002659e-11, 4.4133253e-11, 2.1554261e-11, 3.4529856e-11, 1.7164445e-12, 4.1950516e-11, 1.9599501e-11, 5.5902602e-11, 2.3968198e-11, 5.3617381e-11, 3.4065898e-11, 5.772631e-11, 4.3247909e-11, 2.910964e-11, 3.540753e-11, 2.7571931e-11, 1.1315284e-11, 1.8592999e-11, 2.5544255e-11, 1.6387143e-11, 1.5040508e-11, 2.2639905e-11, 5.4360002e-12, 8.6666995e-12, 5.6874312e-12, 1.5383751e-13, 8.4142681e-12, 2.35447e-12, 1.4626348e-11, 3.7153319e-12, 1.3556488e-11, 3.5347063e-14, 1.3290495e-11, 1.0186957e-11, 6.1501665e-12, 8.5577683e-13, 1.3072633e-11, 1.0210744e-11, 2.2636236e-11, 2.474839e-11, 2.8420038e-11, 4.5050942e-11, 2.2227633e-11, 3.1792015e-11, 3.6332556e-11, 3.8697586e-11, 4.2348893e-11, 3.2118253e-11, 2.8153046e-11, 2.4457277e-11, 1.9662081e-11, 2.1734997e-11, 6.8804476e-14, 1.1115651e-11, 4.9918277e-12, 1.8982929e-12, 1.1247702e-11, 2.0770401e-11, 3.5807463e-11, 8.5853346e-12, 2.4645239e-11, 2.9784902e-12, 3.769364e-11, 1.2267098e-11, 3.746344e-11, 1.1964203e-11, 3.5184555e-11, 1.8121038e-11, 3.9607495e-11, 3.9379517e-11, 3.7426425e-11, 3.3673968e-11, 4.049684e-12, 2.1577381e-11, 1.3780908e-11, 2.3483121e-11, 2.7510908e-11, 1.4425381e-11, 3.1311828e-11, 3.6918784e-11, 1.8378583e-11, 2.2417929e-11, 9.0246163e-12, 6.4247186e-14, 9.9341918e-12, 7.702325e-12, 4.1842474e-11, 6.886208e-11, 9.5465635e-11, 1.6657403e-10, 2.5517066e-10, 3.8494351e-10, 5.6399439e-10, 8.0096699e-10, 1.1594728e-09, 1.6400004e-09, 2.3573629e-09, 3.2925991e-09, 4.651614e-09, 6.4904372e-09, 9.0606513e-09, 1.2616985e-08, 1.750877e-08, 2.4246208e-08, 3.3509402e-08, 4.6136119e-08, 6.3343107e-08, 8.6727815e-08, 1.1841186e-07, 1.6118977e-07, 2.1885078e-07, 2.9625965e-07, 3.9988425e-07, 5.3816045e-07, 7.2207441e-07, 9.6595904e-07, 1.2882465e-06, 1.7128436e-06, 2.2702853e-06, 2.9998008e-06, 3.9511764e-06, 5.1876766e-06, 6.7891422e-06, 8.8560828e-06, 1.1514183e-05, 1.4920328e-05, 1.9269039e-05, 2.4800646e-05, 3.1810529e-05, 4.0660049e-05, 5.1789098e-05, 6.5730358e-05, 8.3125583e-05, 0.00010474378, 0.00013150143, 0.00016448458, 0.00020497294, 0.00025446541, 0.00031470709, 0.00038771704, 0.00047581629, 0.00058165571, 0.00070824225, 0.00085896345, 0.0010376082, 0.0012483837, 0.0014959262, 0.0017853056, 0.0021220223, 0.0025119947, 0.0029615384, 0.0034773344, 0.0040663876, 0.0047359764, 0.0054935914, 0.0063468671, 0.007303506, 0.0083711979, 0.0095575358, 0.01086993, 0.012315523, 0.013901112, 0.015633065, 0.017517262, 0.019559027, 0.021763082, 0.024133505, 0.026673708, 0.029386413, 0.032273654, 0.035336779, 0.038576467, 0.04199275, 0.045585049, 0.049352209, 0.053292541, 0.05740387, 0.061683583, 0.066128679, 0.070735817, 0.075501368, 0.08042146, 0.085492024, 0.090708839, 0.096067568, 0.1015638, 0.10719306, 0.11295089, 0.11883282, 0.12483441, 0.13095128, 0.13717913, 0.14351373, 0.14995096, 0.15648679, 0.16311732, 0.16983875, 0.17664742, 0.1835398, 0.19051247, 0.19756214, 0.20468567, 0.21188001, 0.21914228, 0.22646967, 0.23385953, 0.24130932, 0.2488166, 0.25637904, 0.26399444, 0.27166068, 0.27937575, 0.28713777, 0.29494488, 0.30279546, 0.31068767, 0.31862067, 0.32659107, 0.33460296, 0.34264136, 0.3507378, 0.35882029, 0.36702912, 0.37510944, 0.38346982, 0.39151817, 0.40002843, 0.40807226, 0.41671242, 0.42477037, 0.43354705, 0.44164824, 0.4504208, 0.45880128, 0.46731437, 0.47564069, 0.48422064, 0.49218235, 0.50114621, 0.50900396, 0.518143, 0.52591298, 0.5352627, 0.54287413, 0.55237234, 0.55994548, 0.56971587, 0.57701518, 0.58720775, 0.59417315, 0.60464393, 0.61157174, 0.62223854, 0.62896741, 0.63994151, 0.6463752, 0.65756992, 0.66373256, 0.67507394, 0.68084696, 0.69222455, 0.69760447, 0.70898071, 0.71394469, 0.7252862, 0.72979015, 0.74095639, 0.74500105, 0.75577082, 0.75958339, 0.77002512, 0.77383606, 0.78382725, 0.78789691, 0.79706106, 0.80153898, 0.80944065, 0.81447886, 0.82092838, 0.82676051, 0.83227023, 0.84016694, 0.84345249, 0.85416931, 0.85538181, 0.86689314, 0.87031671, 0.88113769, 0.88503948, 0.89266435, 0.89726632, 0.90207678, 0.90609692, 0.90963674, 0.91258655, 0.91502049, 0.91694533, 0.9185455, 0.91993565, 0.92127913, 0.92250348, 0.9236348, 0.92449581, 0.92534573, 0.92593932, 0.926508, 0.92681627, 0.92684728, 0.92684988, 0.92681491, 0.92675624, 0.92662322, 0.92641057, 0.92621132, 0.92590999, 0.92573187, 0.92555097, 0.92539485, 0.92529249, 0.9251848, 0.92514504, 0.92503605, 0.9249758, 0.92487104, 0.92480741, 0.92477195, 0.92475021, 0.92474446, 0.92473058, 0.92466689, 0.92464599, 0.92459863, 0.92455818, 0.92454052, 0.9245201, 0.92451419, 0.92451885, 0.92448997, 0.92448865, 0.92451428, 0.92451891, 0.9246874, 0.92476524, 0.92500648, 0.92509177, 0.92524675, 0.92532686, 0.92542361, 0.92548585, 0.9255706, 0.92561766, 0.92567513, 0.92568916, 0.92568702, 0.92568594, 0.92568644, 0.92568731, 0.92568733, 0.92568538, 0.92568545, 0.92568528, 0.92568663, 0.9256866, 0.92568528, 0.92568502, 0.92567256, 0.92566365, 0.92565065, 0.92563364, 0.92563023, 0.92560237, 0.92558626, 0.92558102, 0.92556718, 0.92556095, 0.92553352, 0.92552234, 0.92551443, 0.92551346, 0.92553188, 0.92554215, 0.92553593, 0.92551216, 0.9254981, 0.92548397, 0.92545191, 0.9254438, 0.92546047, 0.92545948, 0.92545321, 0.92546942, 0.92546893, 0.92548178, 0.9254962, 0.92550577, 0.92551064, 0.92551861, 0.92551255, 0.92551154, 0.92550125, 0.9254909, 0.92547777, 0.92546059, 0.9254376, 0.92542317, 0.92541357, 0.92540004, 0.92539003, 0.92539268, 0.92539484, 0.92539319, 0.92538687, 0.92537376, 0.92536217, 0.92533494, 0.92532182, 0.92530103, 0.92529295, 0.92528055, 0.9252808, 0.92528141, 0.92527479, 0.92526564, 0.92523915, 0.92522498, 0.92519033, 0.92516932, 0.92514302, 0.92513574, 0.92510167, 0.92508319, 0.92504168, 0.92502395, 0.92498993, 0.92496413, 0.92494274, 0.92494213, 0.92495041, 0.9249836, 0.92499667, 0.92499782, 0.92498454, 0.92497894, 0.92492624, 0.92489385, 0.92487897, 0.92509758, 0.92504302, 0.92491965, 0.92467987, 0.92444044, 0.92344321, 0.92290962, 0.92093694, 0.92008582, 0.9162359, 0.91463478, 0.90802769, 0.90425492, 0.89399229, 0.88607405, 0.86898745, 0.85620349, 0.82452756, 0.80408067, 0.75438196, 0.71474921, 0.64709112, 0.57709269, 0.48776217, 0.39181642, 0.29379284, 0.20417154, 0.13180417, 0.079941381, 0.046261304, 0.025928858, 0.014247258, 0.0077397344, 0.0041786383, 0.0022487831, 0.0012082535, 0.00064867088, 0.00034811725, 0.00018678768, 0.00010021515, 5.3764932e-05, 2.884384e-05, 1.5473854e-05, 8.3011042e-06, 4.4531444e-06, 2.3888279e-06, 1.2814482e-06, 6.8740462e-07, 3.6877249e-07, 1.9781662e-07, 1.0612857e-07, 5.6907018e-08, 3.0530822e-08, 1.6362161e-08, 8.775146e-09, 4.6521183e-09, 2.5235309e-09, 1.3190337e-09, 7.1714996e-10, 3.3889165e-10, 1.8756574e-10, 7.8574173e-11, 2.5481803e-11, 6.9994292e-12, 1.247901e-11, 4.1408415e-11, 4.7442414e-12, 4.0464184e-11, 1.6622659e-11, 2.5161139e-11, 2.3042919e-11, 2.7545969e-11, 2.1857719e-11, 1.0317612e-11, 3.6101653e-11, 8.1525515e-13, 1.4730091e-12, 4.1200966e-11, 2.1666919e-11, 2.549046e-11, 1.2807665e-11, 1.5924281e-11, 1.1008553e-11, 3.9694991e-11, 2.012476e-11, 2.4571647e-11, 6.2012669e-13, 3.3875435e-11, 1.7536811e-11, 3.5456885e-11, 9.438868e-12, 1.5482856e-11, 1.2117833e-11, 1.2255133e-11, 3.2043691e-11, 4.9047395e-12, 5.9504194e-13, 2.3257249e-11, 9.3155531e-12, 4.0251407e-11, 1.6236398e-11, 2.031778e-11, 5.1861107e-12, 4.9291028e-11, 8.2434564e-12, 9.2215406e-12, 2.4410372e-11, 1.5256538e-11, 5.7015363e-11, 3.3725704e-12, 5.4832432e-11, 5.1818707e-11, 4.5330519e-11, 3.5841038e-11, 3.9551697e-11, 4.6543135e-11, 6.3229727e-11, 4.3508543e-11, 3.6803361e-11, 2.5596571e-11, 5.6237735e-11, 2.0785067e-11, 5.3363974e-11, 4.6250331e-12, 5.7681996e-11, 1.4312085e-11, 3.4661054e-11, 1.451132e-11, 4.1207626e-11, 2.0039405e-11, 5.1141307e-11, 5.7767129e-11, 6.5028949e-11, 6.081504e-11, 6.6510061e-11, 6.9528559e-11, 5.3917837e-11, 3.3359199e-11, 3.1915825e-11, 2.4460763e-11, 2.6618498e-11, 1.9054772e-11, 2.2080929e-11, 2.1238369e-11, 4.8883122e-12, 2.9346301e-11, 3.8926909e-12, 1.8546972e-11, 3.352447e-11, 7.7369881e-12, 2.0904608e-11, 5.2964393e-11, 3.7098162e-11, 3.698628e-11, 5.4720328e-12, 1.7230799e-12, 1.4661718e-11, 3.0158781e-11, 8.727504e-13, 7.4551729e-12, 9.6010311e-12, 9.7009263e-12, 4.6964914e-11, 1.7044439e-11, 3.1317343e-11, 4.2369517e-11, 3.8669623e-11, 1.3587734e-11, 4.0327661e-11, 2.2638121e-11, 2.0275824e-11, 2.1832634e-12, 2.6967021e-11, 3.5043653e-11, 8.9498259e-12, 1.7058757e-11, 3.7238681e-12, 4.9141296e-11, 1.4965288e-11, 6.4129671e-11, 9.1424014e-12, 5.4471811e-11, 1.130724e-11, 1.602795e-11, 3.6961417e-11, 5.9972591e-12, 2.417473e-11, 3.6010304e-11, 2.7460281e-11, 1.8913365e-11, 2.2333219e-12, 9.1835805e-12, 1.0674682e-11, 2.0343309e-11, 1.0621071e-11, 2.5540186e-11, 1.0256232e-11, 4.1173994e-11, 4.7592922e-11, 3.8839778e-11, 5.586668e-11, 4.5768393e-11, 5.4112521e-11, 1.3272288e-11, 1.3262631e-11, 2.1268781e-12, 2.0194243e-11, 4.7091671e-12, 3.7831725e-11, 1.5198377e-11, 9.3552891e-12, 3.8123752e-11, 9.7382204e-12, 2.1738621e-11, 1.7108705e-12, 5.4503888e-12, 3.0085081e-12, 2.2196696e-12, 1.3662545e-11, 1.8426765e-11, 6.4032773e-12, 2.0263392e-11, 3.1608037e-11, 4.4126672e-11, 2.1159896e-11, 3.9597982e-11, 1.1844232e-11, 1.6582368e-11, 9.2536177e-13, 2.2899403e-11, 6.6586758e-12, 1.3248202e-11, 1.8486591e-11, 4.3278784e-11, 3.2563479e-11, 1.3640346e-11, 1.2093747e-11, 3.9193296e-12, 1.6752745e-11, 6.6797648e-12, 1.0561134e-11, 1.7613841e-11, 6.0695166e-12, 3.1665977e-11, 1.3746124e-11, 2.4588629e-12, 2.1681015e-11, 1.1307129e-11, 5.1117999e-11, 1.8270707e-11, 3.9627285e-12, 8.1229163e-12, 3.1189482e-14, 8.6509177e-13, 2.0935576e-11, 1.1765536e-11, 3.1098461e-11, 5.3431792e-11, 4.5414209e-11, 3.6909915e-11, 5.9130031e-11, 3.0514297e-11, 5.9756929e-11, 5.2456704e-11, 3.5227349e-11, 4.0291587e-11, 1.2385774e-11, 1.3110236e-11, 1.0282982e-11, 3.7945717e-12, 1.1037634e-11, 9.5456448e-12, 1.2120386e-11, 3.4301765e-11, 2.9848773e-11, 2.483648e-11, 1.5567101e-11, 1.8956764e-11, 3.6095881e-11, 5.7025684e-12, 1.6939771e-11, 3.0161445e-11, 6.3281338e-12, 1.0585664e-11, 1.3458537e-11, 1.4699567e-11, 2.6314706e-11, 7.8859428e-12, 2.2798398e-11, 1.1018876e-11, 1.6363931e-11, 6.347669e-12, 1.6589916e-11, 2.0036741e-12, 1.6865848e-11, 5.4995594e-12, 5.0944292e-12, 1.3116007e-11, 2.4353432e-11, 3.5570433e-12, 6.7930902e-12, 2.3220066e-12, 9.9536609e-12, 1.8856536e-11, 8.7824461e-12, 7.618224e-12, 1.6572712e-11, 5.5821394e-12, 2.3594118e-12, 1.351692e-11, 1.9621733e-11, 2.3416193e-11, 8.477988e-12, 1.7558232e-12, 1.3480181e-11, 1.6566829e-11, 8.3494562e-12, 1.0927638e-11, 4.0086691e-11, 1.6651962e-11, 2.7324424e-11, 3.4887816e-12, 1.3475297e-11, 2.1159452e-11, 5.2683577e-12, 1.3745236e-11, 3.5893205e-11, 3.4344276e-11, 4.7905261e-12, 2.1948068e-11, 4.4536575e-12, 5.2116617e-11, 3.6534865e-11, 6.9206452e-11, 3.8344298e-11, 4.4512489e-11, 2.1158231e-11, 1.856573e-11, 1.5882214e-12, 1.1754437e-11, 1.8347626e-11, 2.3172338e-11, 2.9199233e-11, 4.1969381e-11, 3.6500567e-11, 4.019036e-11, 5.0911105e-11, 3.4911625e-20];\n\noption = {\n  dataZoom: [\n    {\n      type: 'slider',\n      minSpan: 1\n    },\n    {\n      type: 'inside',\n      minSpan: 1\n    }\n  ],\n  tooltip: {\n      trigger: 'axis',\n      formatter: function (params) {\n          let newParams = [];\n          let tooltipString = [];\n          newParams = [...params];\n          newParams.sort((a,b) => {return b.value - a.value});\n          newParams.forEach((p) => {\n              const cont = p.marker + ' ' + p.seriesName + ': ' + p.value + '<br/>';\n              tooltipString.push(cont);\n          });\n          return tooltipString.join('');\n      }\n  },\n legend: {\n    data: legends\n  },\n  grid: {\n    left: '3%',\n    right: '4%',\n    bottom: '9%',\n    containLabel: true\n  },\n  // toolbox: {\n  //   feature: {\n  //     saveAsImage: {}\n  //   }\n  // },\n  xAxis: {\n    type: 'category',\n    boundaryGap: false,\n    data: xaxis\n  },\n  yAxis: {\n    min: 'dataMin',\n    type: 'value',\n    axisTick: {\n      alignWithLabel: true\n    },\n    scale: true,\n  },\n  series: [\n    {\n      name: legends[0],\n      type: 'line',\n      showSymbol: false,\n      data: data0\n    },\n    \n    {\n      name: legends[1],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data1\n    },\n    {\n      name: legends[2],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data2\n    },\n    {\n      name: legends[3],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data3\n    },\n    {\n      name: legends[4],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data4\n    },\n    {\n      name: legends[5],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data5\n    },\n    {\n      name: legends[6],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data6\n    },\n        {\n      name: legends[7],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data7\n    }\n  ]\n};\n  // \n  myChart.setOption(option);\n</script>\n\n","site":{"data":{}},"wordcount":124294,"excerpt":"<div class=\"note note-primary\">\n            <p>This is the <strong>essence</strong> of CFD, advecting with the discontinuities due to inviscid fluid PDEs. Several computational schemes dealing with them are introduced then tested in OpenFOAM on the 1D shockTube case.</p>\n          </div>","more":"<div class=\"note note-secondary\">\n            <p>This is a review of my graduate CFD course and the application of the theory to CFD software. The aim is to further the understanding of finite volume method and the <code>fvscheme</code> dict in OpenFOAM.</p>\n          </div>\n<p><strong>Reference books:</strong></p>\n<p>E.F. Toro, Riemann Solvers and Numerical Methods for Fluid Dynamics, Springer-Verlag.</p>\n<p>R.J. LeVeque, Finite Volume Methods for Hyperbolic Problems, Cambridge University Press.</p>\n<p><strong>Overview:</strong></p>\n\n<div class=\"markmap-container\" style=\"height:300px\">\n  <svg data=\"{&quot;t&quot;:&quot;root&quot;,&quot;d&quot;:0,&quot;v&quot;:&quot;&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[1,2]},&quot;v&quot;:&quot;Scalar conservation laws&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[2,3]},&quot;v&quot;:&quot;conservation vs non-conservative&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[3,4]},&quot;v&quot;:&quot;1D simple Riemann problem for Burgers&#39; equation&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[4,5]},&quot;v&quot;:&quot;characteristics discontinuities and jump conditions&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[5,6]},&quot;v&quot;:&quot;weak solutions and entropy condition&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[6,7]},&quot;v&quot;:&quot;Numerical schemes for 1D discontinuities&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[7,8]},&quot;v&quot;:&quot;practical examples on one conservation law&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[8,10]},&quot;v&quot;:&quot;&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[10,11]},&quot;v&quot;:&quot;System of conservation laws&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:4,&quot;p&quot;:{&quot;lines&quot;:[11,12]},&quot;v&quot;:&quot;add complexity, system of conservation laws&quot;}]}],&quot;p&quot;:{}}\"></svg>\n</div>\n\n<h2 id=\"scalar-conservation-laws\">Scalar conservation laws</h2>\n<div class=\"note note-info\">\n            <p>1-D theory. Examples of 1-D hyperbolic conservation laws. Characteristics discontinuities and jump conditions. Weak solutions and entropy condition. Linear versus non-linear advection</p>\n          </div>\n<h3 id=\"challenges\">Challenges</h3>\n<p>As we all know, flow fluids are governed by 3 hyperbolic PDEs (conservation of mass, momentum and energy). These equations are highly non-linear and they can lead to discontinuities even with a smooth initial conditions, which is very difficult to solve numerically. Simple FDM will definitely fail on these discontinuities and shocks.</p>\n<p>Recall the incompressible NS equation that we've learned in the kindergarten: <span class=\"math display\">\\[\n\\frac{\\partial \\mathbf{V}}{\\partial t} + \\underbrace{\\left(\\boldsymbol{\\nabla}\\cdot\\mathbf{V}\\right)\\mathbf{V}}_{\\text{convection}} = \\frac{\\nabla p}{\\rho} + \\mathbf{g}+ \\underbrace{\\nu \\boldsymbol{\\nabla}^2\\mathbf{V}}_{\\text{diffusion}}\n\\]</span> the viscous diffusion term in the equation leads to parabolic equations with smooth solutions, which will save our life. But with very high <span class=\"math inline\">\\(Re\\)</span>, the equation reduces to pure <font color=#75147c>hyperbolic inviscid Euler Equation</font>, and the resultant discontinuity is a nightmare for most of the numerical schemes.</p>\n<p>The presence of discontinuities requires <font color=#75147c>weak solutions</font>, as oppose to <font color=#75147c>strong solutions</font>.</p>\n<p>However, the weak solutions give up the uniqueness in math, i.e there exist a large number of solutions that may not be physical acceptable, i.e. extra conditions are needed to justify the solution. They are:</p>\n<ul>\n<li><font color=#75147c>Rankine-Hugoniot</font> condition deals with the discontinuity</li>\n<li><font color=#75147c>Entropy</font> condition satisfies the physics</li>\n</ul>\n<div class=\"note note-info\">\n            <p>Just here to remind that we are dealing with inviscid flow, shocks, nothing to do with turbulence.</p>\n          </div>\n<h3 id=\"scalar-conservation-laws-1\">Scalar conservation laws</h3>\n<h4 id=\"d-law\">1D law</h4>\n<p><img src=\"1D scalar convection.png\" alt=\"1D scalar convection control volume\" style=\"zoom:70%;\" /></p>\n<p>First let's introduce a simple example to present the problem: consider an 1D control volume <span class=\"math inline\">\\([a,b]\\)</span>, during the time interval <span class=\"math inline\">\\([t_1,t_2]\\)</span> . The scalar conservation law can be stated as that during <span class=\"math inline\">\\([t_1,t_2]\\)</span> , change in total conserved quantity in <span class=\"math inline\">\\([a,b]\\)</span> equals to the net flux through the boundaries <span class=\"math inline\">\\(a\\)</span>, <span class=\"math inline\">\\(b\\)</span>:</p>\n<p><span class=\"math display\">\\[\n\\frac{d}{dt}\\int_a^bu(x,t) = -\\left[f(u(b,t))-f(u(a,t))\\right]\n\\]</span> where <span class=\"math inline\">\\(u(x,t)\\)</span> is called the conserved quantity while <span class=\"math inline\">\\(f\\)</span> denotes the flux. This equation often describes the <font color=#75147c>transport phenomena</font>.</p>\n<div class=\"note note-info\">\n            <p>You can not create, you can not destroy.</p>\n          </div>\n<h4 id=\"integral-differential-conservative-and-primitive-forms\">Integral, differential conservative and primitive forms</h4>\n<p><img src=\"2D scalar convection control volume.png\" alt=\"2D scalar convection control volume\" style=\"zoom:48%;\" /></p>\n<p>The 1D law can be extended in 2D with the relation, in <font color=#75147c>integral form</font>. <span class=\"math display\">\\[\n\\frac{d}{d t} \\int_{\\Omega} \\mathbf{u} d \\Omega+\\int_{\\Gamma} \\mathbf{f}(\\mathbf{u}) \\cdot \\mathbf{n} d \\Gamma=0\n\\]</span> <div class=\"note note-info\">\n            <p>The FVM and FEM solves the integral form, while the FDM solves the primitive form.</p>\n          </div></p>\n<p>Apply the Gauss divergence theorem the relation can be represented as <font color=#75147c>differential form</font>: <span class=\"math display\">\\[\n\\begin{aligned}\n\\int_{\\Omega}\\left\\{\\frac{\\partial \\mathbf{u}}{\\partial t}+\\nabla \\cdot \\mathbf{f}(\\mathbf{u})\\right\\} d \\Omega=0&amp;  \\\\ \n\\Rightarrow \n\\color{purple}{\n\\forall \\Omega,\\quad \\frac{\\partial \\mathbf{u}}{\\partial t}+\\nabla \\cdot \\mathbf{f}(\\mathbf{u})=0} &amp;\n\\end{aligned}\n\\]</span> above is called the <font color=#75147c>differential conservative form</font>. The only <span class=\"math inline\">\\(u\\)</span> changed in time is due to the flux <span class=\"math inline\">\\(f\\)</span>. There is no extra assumptions introduced.</p>\n<p>In comparison, with an assumption of <span class=\"math inline\">\\(\\mathbf{a} = \\frac{d\\mathbf{f}}{d\\mathbf{u}}\\)</span>, the equation can be rewritten with the chain rule, as the <font color=#75147c>differential primitive form</font> : <span class=\"math display\">\\[\n\\quad \\frac{\\partial \\mathbf{u}}{\\partial t}+\\mathbf{a}(\\mathbf{u})\\nabla \\cdot \\mathbf{u}=0, \\quad \\text{where }\\mathbf{a} =  \\frac{d\\mathbf{f}}{d\\mathbf{u}}\n\\]</span> This form is identical to above in mathematics, but it will lead to problems numerically when dealing with discontinuities (to be discussed later).</p>\n<h4 id=\"rankine-hugoniot-jump-condition\">Rankine-Hugoniot Jump condition</h4>\n<p><img src=\"shock wave.png\" alt=\"1D jump discontinuity illustration\" style=\"zoom:70%;\" /></p>\n<p>When dealing with discontinuities, the integral form is well defined, but not the differential forms. The differential solvers can't deal with the drastic derivatives so instead they solve an extra <font color=#75147c>jump condition</font> which can be derived from the well-defined integral form (discussed later).</p>\n<p>For an 1D jump discontinuity travelling at the speed <span class=\"math inline\">\\(s\\)</span>: <span class=\"math display\">\\[\nf(u_r)-f(u_l) = s(u_r-u_s)\n\\]</span> where <span class=\"math inline\">\\(u_r\\)</span>, <span class=\"math inline\">\\(u_l\\)</span> represent the speeds just at the left and the right of the discontinuity.</p>\n<h3 id=\"d-euler-equations\">1D Euler equations</h3>\n<p>Its time to introduce the 1D Euler equations: NS equations with 0 viscosity or heat conduction terms: <span class=\"math display\">\\[\n\\frac{\\partial}{\\partial t}\\left[\\begin{array}{l}\n\\rho \\\\\n\\rho u \\\\\n\\rho E\n\\end{array}\\right]+\\frac{\\partial}{\\partial x}\\left[\\begin{array}{l}\n\\rho u \\\\\n\\rho u^{2}+P \\\\\n\\rho u\\left(E+\\frac{P}{\\rho}\\right)\n\\end{array}\\right]=0\n\\]</span> And the conservation form is: <span class=\"math display\">\\[\n\\frac{\\partial \\mathbf{q}}{\\partial t}+\\frac{\\partial \\mathbf{F}(\\mathbf{q})}{\\partial x}=0\n\\]</span> for the quantity vector <span class=\"math inline\">\\(\\mathbf{q}\\)</span> with the flux vector <span class=\"math inline\">\\(\\mathbf{F}\\)</span>.</p>\n<h4 id=\"conservation-vs-non-conservation-form\">Conservation vs non-conservation form</h4>\n<p>Similar to before, with terms in a form of <span class=\"math inline\">\\(\\partial_x{uv}\\)</span>: <span class=\"math display\">\\[\n\\frac{\\partial uv}{\\partial x} \\neq u\\frac{\\partial v}{\\partial x}+ v\\frac{\\partial u}{\\partial x}\n\\]</span> When dealing with the discontinuities, the conservative LHS locates the shock directly, while the non-conservative RHS does not. (to be discussed later)</p>\n<h4 id=\"close-the-euler-equation\">Close the Euler equation</h4>\n<p>Unlike the well-posed NS equation, in Euler equation, we have 4 unknowns but only 3 equations. So an extra state equation, i.e. extra assumption of the gas state is needed. Sometimes it's the idea gas assumption <span class=\"math inline\">\\(p = \\rho RT\\)</span>, but for high <span class=\"math inline\">\\(Re\\)</span> compressible flows, equations of state are required to describe the relation between <span class=\"math inline\">\\(p, \\rho \\text{ and }T\\)</span>.</p>\n<div class=\"note note-primary\">\n            <p>We are going to use the 1D Euler equations to evaluate the numerical methods.</p>\n          </div>\n<h3 id=\"analytical-solutions-of-euler-equations\">Analytical solutions of Euler equations</h3>\n<h4 id=\"linear-advection-equation\">Linear Advection Equation</h4>\n<p>In 1D, the linear advection law for <span class=\"math inline\">\\(u(x,t)\\)</span> is: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial u }{\\partial t} + a(u)\\frac{\\partial u }{\\partial x} = 0\n\\]</span> where <span class=\"math inline\">\\(a(u)\\)</span> denotes the advection speed. Plus an <font color=#75147c>initial condition</font> <span class=\"math inline\">\\(u(x,0)\\)</span> and <font color=#75147c>boundary condition</font> (discuss later).</p>\n<h5 id=\"solution\">solution</h5>\n<p>This is a simple 2-variable PDE and we can apply the method of characteristics:</p>\n<ol type=\"1\">\n<li><p>Imagine a characteristic line <span class=\"math inline\">\\(s\\)</span>, we have the chain rule: <span class=\"math display\">\\[\n\\frac{d u(x,t)}{d s} = \\frac{d t}{d s}\\frac{\\partial u}{\\partial t} + \\frac{d x}{d s} \\frac{\\partial u}{\\partial x}\n\\]</span></p></li>\n<li><p>As a result we can construct, <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{d u(x,t)}{d s} = 0,\\quad\\frac{d t}{d s}=1, \\quad \\frac{d x}{d s}= a \\\\\n\\Rightarrow \\quad \\frac{d u}{0}=\\frac{d t}{1}=\\frac{d x}{a}= d s\n\\end{aligned}\n\\]</span></p></li>\n<li><p>Select the available equations we have the characteristic equation: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{d x}{d t} &amp;= a \\\\\n\\Rightarrow\\quad x &amp;= x_0 + a(u)t\n\\end{aligned}\n\\]</span> If <span class=\"math inline\">\\(u(x_0,0)=u_0\\)</span>, then <span class=\"math inline\">\\(\\frac{dx}{dt}=a(u_0)\\)</span>, the characteristic equation is therefore: <span class=\"math display\">\\[\n\\color{purple}\nx = x_0 + a(u_0)t\n\\]</span></p></li>\n<li><p>And the solution to the problem is: <span class=\"math display\">\\[\nu(x,t) = f(x_0) = f(x-a(u_0)t)\n\\]</span></p></li>\n</ol>\n<h4 id=\"linear-advection-equation-example\">Linear Advection Equation Example</h4>\n<p>Solve the following advection equation where <span class=\"math inline\">\\(a = 0.5\\)</span> <span class=\"math display\">\\[\n\\frac{\\partial u}{\\partial t} + a \\frac{\\partial u}{\\partial x }= 0\n\\]</span> with initial condition <span class=\"math display\">\\[\nu(x,0) = exp(-32x^2)\n\\]</span></p>\n<h5 id=\"solution-1\">solution</h5>\n<p>The characteristics are straight lines in the <span class=\"math inline\">\\((x,t)\\)</span> plane: <span class=\"math display\">\\[\nx = 0.5t+x_0\n\\]</span> And the solutions are therefore: <span class=\"math display\">\\[\nu(x,t) = f(x_0) = exp(-32(x-0.5t)^2)\n\\]</span> <img src=\"Linear Advection Solutions.png\" alt=\"Linear Advection Characteristic Lines and Solutions, From my graduate course slides\" style=\"zoom:28%;\" /></p>\n<h4 id=\"inviscid-burgers-equation\">Inviscid Burgers' equation</h4>\n<p>In 1D, the inviscid Burgers' equation for <span class=\"math inline\">\\(u(x,t)\\)</span> is: <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial u }{\\partial t} + \\frac{f(u) }{\\partial x} = 0,\\quad\\text{where }f(u)=\\frac{1}{2}u^2\n\\]</span> The conservative form for this equation <span class=\"math display\">\\[\n\\frac{\\partial u }{\\partial t} + \\frac{\\partial(\\frac{1}{2}u^2) }{\\partial x} = 0\n\\]</span> and the primitive form: <span class=\"math display\">\\[\n\\frac{\\partial u }{\\partial t} + u\\frac{\\partial u }{\\partial x} = 0\n\\]</span> same form as the 1D linear advection equation with <span class=\"math inline\">\\(a(u)=u\\)</span>.</p>\n<h4 id=\"burgers-equation-example\">Burgers' equation Example</h4>\n<p>Solve the advection equation: <span class=\"math display\">\\[\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }= 0\n\\]</span> with initial condition: <span class=\"math display\">\\[\nu(x,0) = 1-\\cos(x)\n\\]</span></p>\n<h5 id=\"solution-2\">solution</h5>\n<p>Similarly, the characteristics are described by: <span class=\"math display\">\\[\nx = x_0 + ut\n\\]</span> and the solution: <span class=\"math display\">\\[\nu = 1-\\cos(x-ut)\n\\]</span> which is <em><u>implicit</u></em>. It is can be plotted anyway:</p>\n<p><img src=\"Inviscid Burgers' equation Solutions.png\" alt=\"Inviscid Burgers' equation Solutions, From my graduate course slides\" style=\"zoom:28%;\" /></p>\n<h5 id=\"discussion\">discussion</h5>\n<p>For non-linear conservation laws, the characteristics may cross within finite time. This would suggest a multi-valued solution which does not make sense physically.</p>\n<p>Where the characteristics start crossing, the solution become discontinuous. And the formation of discontinuities is possible even for smooth initial data. So the differential primitive form of the equations is no longer valid</p>\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span> only the integral form can deal with discontinuities. And the differential form can be completed by a <font color=#75147c>jump condition</font> derived from the integral form.</p>\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span> we need <font color=#75147c>weak solutions</font>. The mathematical theory of partial differential equations introduces the concept of weak solutions.</p>\n<h3 id=\"rankine-hugoniot-condition\">Rankine-Hugoniot condition</h3>\n<h4 id=\"the-riemann-problem\">The Riemann Problem</h4>\n<div class=\"note note-info\">\n            <p>In order to understand the behaviour of the solution at discontinuities, it is useful to start with a simplified problem.</p>\n          </div>\n<p>The Riemann problem is a conservation law with a single discontinuity. <span class=\"math display\">\\[\n\\color{purple}\n\\frac{\\partial u}{\\partial t} + \\frac{\\partial f(u)}{\\partial x} = 0\n\\]</span> with <span class=\"math display\">\\[\n\\color{purple}\nu(x, 0)= \\begin{cases}u_{L} &amp; x \\leq 0 \\\\ u_{R} &amp; x&gt;0\\end{cases}\n\\]</span> <img src=\"Riemann problem illustration.png\" alt=\"Riemann problem illustration\" style=\"zoom:48%;\" /></p>\n<h4 id=\"shock-path\">Shock Path</h4>\n<p><img src=\"shock path control volume.png\" alt=\"shock path control volume\" style=\"zoom:80%;\" /></p>\n<p>Take the control volume between boundaries <span class=\"math inline\">\\(x_L\\)</span> and <span class=\"math inline\">\\(x_R\\)</span>, which are taken sufficient close to the shock so that spatial variations of the solution become unimportant. and are taken sufficient apart from the shock so that the boundary will note interfere with the shock motion over time interval <span class=\"math inline\">\\(\\delta t\\)</span>.</p>\n<p>Recall the integral function: <span class=\"math display\">\\[\n\\frac{d}{dt}\\int_{x_L}^{x_R}udx = f(u_L)-f(u_R)\n\\]</span> If the position of the shock is <span class=\"math inline\">\\(x = X(t)\\)</span>, with <span class=\"math inline\">\\(x_L&lt; X (t) &lt;x_R\\)</span>, the values of <span class=\"math inline\">\\(u(x,t)\\)</span> inside the integral are close to the constants <span class=\"math inline\">\\(u_L\\)</span> and <span class=\"math inline\">\\(u_R\\)</span> and we can write: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{d}{dt}\\int_{x_L}^{X}u_Ldx + \\frac{d}{dt}\\int_{X}^{x_R}u_Rdx= f(u_L)-f(u_R)\\\\\n\\frac{d}{dt}\\left[(x_L-X)u_L + (X-x_R)u_R\\right]= f(u_L)-f(u_R)\\\\\n\\end{aligned}\n\\]</span></p>\n<p>Given the shock speed (slope of the shock path) <span class=\"math inline\">\\(s = \\frac{dX}{dt}\\)</span>, we have: <span class=\"math display\">\\[\n\\begin{aligned}\ns\\left(u_L - u_R\\right)&amp;= f(u_L)-f(u_R)\\\\\n\\color{purple}\ns= \\frac{dX}{dt}&amp;\\color{purple}\n= \\frac{f(u_L)-f(u_R)}{\\left(u_L - u_R\\right)}= \\frac{f(u_R)-f(u_L)}{\\left(u_R - u_L\\right)}\n\\end{aligned}\n\\]</span> The equation above is the <font color=#75147c>Rankine-Hugoniot condition</font>, also called the \"jump condition\".</p>\n<p>Correspondingly, <font color=#75147c>weak solutions</font> represents the solutions of the PDE where the solution is smooth and of a Rankine-Hugoniot condition at discontinuities. And they are <font color=#75147c>not unique</font>.</p>\n<div class=\"note note-info\">\n            <p>Strong solution <span class=\"math inline\">\\(\\Rightarrow\\)</span> weak solution</p><p>Weak solution <span class=\"math inline\">\\(\\nLeftarrow\\)</span> Strong solution</p>\n          </div>\n<h3 id=\"non-uniqueness-of-weak-solutions\">Non-uniqueness of weak solutions</h3>\n<h4 id=\"example-of-riemann-problem-with-burgerss-equation\">Example of Riemann Problem with Burgers's equation</h4>\n<p>Consider the <a href=\"#inviscid-burgers-equation\">Burgers' equation</a> under a <a href=\"#the-riemann-problem\">Riemann Problem</a>: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&amp;= 0, \\\\\n\\text{with }\nu(x, 0)&amp;= \\begin{cases}1 &amp; x \\leq 0 \\\\ 0 &amp; x&gt;0\\end{cases}\n\\end{aligned}\n\\]</span> The characteristics are of the form: <span class=\"math inline\">\\(x = x_0 + ut\\)</span></p>\n<p>In <span class=\"math inline\">\\(x-t\\)</span> plane, the characteristics line: <span class=\"math display\">\\[\n\\begin{cases} x = t - x_0 &amp; x_0 \\leq 0 \\\\ x = x_0 &amp; x_0 &gt; 0\\end{cases}\n\\]</span> And the according to the Rankine-Hugonoit condition, the speed of the shock is: <span class=\"math display\">\\[\ns = \\frac{f(u_L)-f(u_R)}{\\left(u_L - u_R\\right)}= \\frac{-1/2-0}{\\left(1-0\\right)} = \\frac{1}{2}\n\\]</span> and the shock path is: <span class=\"math display\">\\[\nx = \\frac{1}{2} t\n\\]</span> therefore, the solution is: <span class=\"math display\">\\[\nu(x,t) = \\begin{cases} 1 &amp; x \\leq \\frac{1}{2}t \\\\ 0 &amp; x&gt; \\frac{1}{2}t\\end{cases}\n\\]</span> <img src=\"Burgers's equation under Riemann Problem with uL = 1, uR=0.png\" alt=\"General solution (left) and characteristics (right) of Burgers's equation under Riemann Problem. From my graduate course slides\" style=\"zoom:50%;\" /></p>\n<h4 id=\"upwind-riemann-problem-with-burgerss-equation\">Upwind Riemann Problem with Burgers's equation</h4>\n<p>For the upwind case: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&amp;= 0, \\\\\n\\text{with }\nu(x, 0)&amp;= \\begin{cases}u_L &amp; x \\leq 0 \\\\ u_R &amp; x&gt;0\\end{cases}\n\\end{aligned}\n\\]</span> with <span class=\"math inline\">\\(u_L&gt;u_R\\)</span>.</p>\n<p>And the shock is created with a speed: <span class=\"math display\">\\[\ns = \\frac{1}{2}(u_R+u_L)\n\\]</span> and the solution: <span class=\"math display\">\\[\nu(x,t) = \\begin{cases} u_L &amp; x \\leq \\frac{1}{2}t \\\\ u_R &amp; x&gt; \\frac{1}{2}t\\end{cases}\n\\]</span> <img src=\"Burgers's equation under Riemann Problem general solution.png\" alt=\"Solution (left) and characteristics (right) of Burgers's equation under Riemann Problem with uL = 1, uR=0. From my graduate course slides\" style=\"zoom:50%;\" /></p>\n<h4 id=\"example-of-non-unique-downwind-riemann-problem-with-burgerss-equation\">Example of non-unique downwind Riemann Problem with Burgers's equation</h4>\n<p>Reverse the initial condition in the previous example:</p>\n<p><span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&amp;= 0, \\\\\n\\text{with }\nu(x, 0)&amp;= \\begin{cases}0 &amp; x \\leq 0 \\\\ 1 &amp; x&gt;0\\end{cases}\n\\end{aligned}\n\\]</span> the characteristics become:</p>\n<p><img src=\"Burgers's equation under Riemann Problem with uL = 0, uR=1.png\" alt=\"Solution (left) and characteristics (right) of Burgers's equation under Riemann Problem with uL = 1, uR=0. From my graduate course slides\" style=\"zoom:50%;\" /></p>\n<p>Solution in the blue area (<span class=\"math inline\">\\(0&lt;x&lt;t\\)</span>) is not defined. So here proposes 2 possible solutions, both are mathematical acceptable:</p>\n<p>Solution A: <span class=\"math display\">\\[\nu(x, t)= \\begin{cases}0 &amp; \\text { if } \\quad \\frac{x}{t}&lt;s(=0.5) \\\\ 1 &amp; \\text { if } \\quad \\frac{x}{t}&gt;s(=0.5)\\end{cases}\n\\]</span> <img src=\"Expansion shock solution to the Riemann Problem.png\" alt=\"Expansion shock solution to the Riemann Problem\" style=\"zoom:50%;\" /></p>\n<p>Solution B: <span class=\"math display\">\\[\nu(x, t)=\\left\\{\\begin{array}{ccc}\n0 &amp; \\text { if } &amp; \\frac{x}{t}&lt;0 \\\\\n\\frac{x}{t} &amp; \\text { if } &amp; 0&lt;\\frac{x}{t}&lt;1 \\\\\n1 &amp; \\text { if } &amp; \\frac{x}{t}&gt;1\n\\end{array}\\right.\n\\]</span> <img src=\"Rarefaction wave solution to the Riemann Problem.png\" alt=\"Rarefaction wave solution to the Riemann Problem\" style=\"zoom:50%;\" /></p>\n<div class=\"note note-info\">\n            <p>A little spoiler alert there: Solution B is physical, discussed in the <a href=\"#non-uniqueness-and-entropy-conditions\">next section</a>.</p>\n          </div>\n<h4 id=\"exact-solution-to-riemann-problem-with-burgerss-equation\">Exact solution to Riemann Problem with Burgers's equation</h4>\n<p>In conclusion,</p>\n<p>For the Riemann Problem with Burgers's equation: <span class=\"math display\">\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x }&amp;= 0, \\\\\n\\text{with }\nu(x, 0)&amp;= \\begin{cases}u_L &amp; x \\leq 0 \\\\ u_R &amp; x&gt;0\\end{cases}\n\\end{aligned}\n\\]</span></p>\n<ul>\n<li><p>with <span class=\"math inline\">\\(u_L&gt;u_R\\)</span></p>\n<p>A shock wave is created with a speed: <span class=\"math display\">\\[\nV_s = \\frac{u_L+u_R}{2}\n\\]</span> and the exact solution is: <span class=\"math display\">\\[\nu(x, t)=\\left\\{\\begin{array}{ccc}\nu_L &amp; \\text { if } &amp; \\frac{x}{t}\\leq V_s \\\\\nu_R &amp; \\text { if } &amp; \\frac{x}{t}&gt;V_s\n\\end{array}\\right.\n\\]</span></p></li>\n<li><p>with <span class=\"math inline\">\\(u_L&lt;u_R\\)</span></p>\n<p>the exact solution is the rarefaction wave: <span class=\"math display\">\\[\nu(x, t)=\\left\\{\\begin{array}{ccc}\nu_L &amp; \\text { if } &amp; \\frac{x}{t}&lt;0 \\\\\n\\frac{x}{t} &amp; \\text { if } &amp; 0&lt;\\frac{x}{t}&lt;1 \\\\\nu_R &amp; \\text { if } &amp; \\frac{x}{t}&gt;1\n\\end{array}\\right.\n\\]</span> if <span class=\"math inline\">\\(u_L = -u_R\\)</span>, we have a sonic rarefaction wave.</p></li>\n</ul>\n<h3 id=\"entropy-conditions\">Entropy Conditions</h3>\n<p>Why solution A is wrong? we need to impose additional conditions. There are two ways.</p>\n<ul>\n<li><p>Add a small diffusion term (2 <sup>nd</sup> order) manually on the RHS to remove the discontinuity. The weak solution then must satisfy: <span class=\"math display\">\\[\n\\frac{\\partial u^\\epsilon}{\\partial t} + \\frac{\\partial f(u^\\epsilon)}{\\partial x} = \\epsilon\\frac{\\partial^2u^\\epsilon}{\\partial x^\\epsilon}\n\\]</span> where <span class=\"math inline\">\\(\\epsilon\\)</span> is the <font color=#75147c>viscosity coefficient</font>, it introduces the dissipation, known as the vanishing viscosity concept, into the equation to smooth the solution. A little bit cheating but most of people do this.</p></li>\n<li><p>Add the <font color=#75147c>entropy solution</font></p>\n<div class=\"note note-info\">\n            <p>I first hearted Entropy back in my undergraduate thermodynamic course. But I still don't know what is Entropy. So here are some answers:</p><p>In gas dynamics, entropy is a constant physical quantity along particles in smooth flow which can jump to a higher value through a shock.</p><p>The second law of thermodynamics says that entropy can never go down.</p><p>For an evolution equation the information should always flow from the initial data.</p><p>We can see it is very difficult to define it, but in order to translate the defination into the entropy condition, we see entropy as the extra amount of energy that is not available to the system.</p>\n          </div>\n<p>There are again two options of entropy condition:</p>\n<ul>\n<li><p><font color=#75147c>Convex (concave) fluxes / Lax entropy condition</font> <span class=\"math display\">\\[\nf&#39;(u_L) &gt; s &gt; f&#39;(u_R)\n\\]</span> and the characteristics must run into the shock, not emerge from it.</p></li>\n<li><p><font color=#75147c>Oleinik entropy condition</font></p>\n<p>Similar to Lax entropy condition, it says: <span class=\"math display\">\\[\n\\frac{f(u)-f(u_L)}{u-u_L}\\geq s \\geq \\frac{f(u_R)-f(u)}{u_R-u}\n\\]</span></p></li>\n</ul>\n<p>and Lax and Oleinik are equivalent if <span class=\"math inline\">\\(f(u)\\)</span> is strictly convex i.e. <span class=\"math inline\">\\(f&#39;&#39;(u)&lt;0\\)</span>.</p></li>\n</ul>\n<h2 id=\"numerical-representation-of-discontinuities\">Numerical representation of discontinuities</h2>\n<div class=\"note note-info\">\n            <p>Requirements on numerical schemes. Conservative discretisation: Lax-Wendroff theorem. First versus second order schemes. Representation of discontinuities: physical aspects, shock fitting/capturing.</p>\n          </div>\n<h3 id=\"problems-with-lax-equivalence-theorem\">Problems with Lax Equivalence Theorem</h3>\n<p>There are 3 fundamental properties of a numerical scheme:</p>\n<ul>\n<li><p>Consistency: how good you approximate operators and functions.</p></li>\n<li><p>Convergence: error between the exact and discrete solutions converges to zero.</p></li>\n<li><p>Stability: solution of the difference equation is not too sensitive to small perturbations.</p></li>\n</ul>\n<p>The convergence needs to be evaluated with exact solutions. So we always need analytical solutions to verify it. If we don't have access to the analytical solutions, we have a <font color=#75147c>Lax Equivalence Theorem</font>says <span class=\"math display\">\\[\n\\text{consistency + stability $\\Rightarrow$ convergence}\n\\]</span> It is a fundamental convergence theorem but</p>\n<ul>\n<li>it is valid <font color=#75147c>only for linear PDEs</font> and there is no non-linear equivalent theorem</li>\n<li>this theorem <font color=#75147c>does not tell if the weak solution physically acceptable or not</font>.</li>\n</ul>\n<p>For non-linear PDEs, we only have one experience,</p>\n<p>If a scheme is stable on linear PDEs, it will often (not all the time) be stable on non-linear PDEs. If a scheme is unstable on linear, it won't be stable on non-linear.</p>\n<p>So the work flow is, 1. Given a non-linear PDE, 2. Linearise it to explore the stabilities of schemes on it. 3. Test the winners on non-linear PDEs.</p>\n<h3 id=\"d-linear-convection-equation\">1D linear convection equation</h3>\n<p>First we consider a <font color=#75147c>linear</font> case, linear convection equation: <span class=\"math display\">\\[\n\\frac{\\partial u}{\\partial t} + a\\frac{\\partial u}{\\partial x} = 0\n\\]</span> with <span class=\"math inline\">\\(a\\)</span> a positive scalar constant, representing the wave speed. So we have: <span class=\"math display\">\\[\nf(u) = au\n\\]</span></p>\n<h5 id=\"numerical-scheme\">Numerical scheme</h5>\n<p>try to solve it numerically, with finite difference, forward difference in time and central difference in space. we have: <span class=\"math display\">\\[\n\\frac{u^{n+1}_i-u^n_i}{\\Delta t} + a \\frac{u^n_{i+1}-u^n_{i-1}}{2\\Delta x} = 0\n\\]</span></p>\n<p><span class=\"math display\">\\[\nu^{n+1}_i = u^n_i - \\frac{a\\Delta t}{\\Delta x}\\left(\\frac{u^n_{i+1}-u^n_{i-1}}{2} \\right) = 0\n\\]</span></p>\n<p>It is consistency, and the Von Neumann analysis shows it is stable if the CFL condition (Courant number <span class=\"math inline\">\\(a\\frac{\\Delta t}{\\Delta x}&lt;1\\)</span>) is satisfied. It should converge to the exact solution.</p>\n<h5 id=\"numerical-practice\">Numerical practice</h5>\n<h2 id=\"systems-of-conservation-laws\">Systems of conservation laws</h2>\n<div class=\"note note-info\">\n            <p>Jacobian matrices, linearized equations, conservative and characteristic variables. Rankine-Hugoniot jump conditions. Boundary conditions.</p>\n          </div>\n<h2 id=\"numerical-schemes-for-non-linear-conservation-laws\">Numerical schemes for non-linear conservation laws</h2>\n<div class=\"note note-info\">\n            <p>It is still an active research area and these are the classical methods:</p><p>Centred schemes: one-step and two-step Lax Wendroff, MacCormack predictor-corrector. Artificial dissipation. Upwind schemes: flux vector and flux difference splitting. Monotone schemes: Godunov and Harten theorems. Exact and approximate Riemann solvers. High-order upwind schemes: the TVD property. The construction of TVD schemes using slope and flux limiters. WENO schemes: weighted essentially non-oscillatory methods</p>\n          </div>\n<h2 id=\"numerical-schemes-for-multi-dimensional-problems\">Numerical schemes for multi-dimensional problems</h2>\n<div class=\"note note-info\">\n            <p>Finite differences and finite volume. Computational domain and boundary conditions.</p>\n          </div>\n<h2 id=\"openfoam-demo-on-shockwave\">OpenFOAM demo on shockwave</h2>\n<div id=\"echarts5811\" style=\"width: 85%;height: 400px;margin: 0 auto\"></div>\n<script type=\"text/javascript\" src=\"https://cdn.bootcss.com/echarts/4.2.0-rc.2/echarts.min.js\"></script>\n<script type=\"text/javascript\" src=\"https://www.makeapie.com/dep/echarts/map/js/china.js\"></script>\n<script type=\"text/javascript\">\n  // domecharts\n  var myChart = echarts.init(document.getElementById('echarts5811'));\n  // \n  let legends = ['exact', 'linear', 'upwind', 'linearUpwind', 'QUICK', 'TVD-vanLeer', 'TVD-Minmod', 'TVD-SuperBee']\nlet xaxis = [0.0005, 0.0015, 0.0025, 0.0035, 0.0045, 0.0055, 0.0065, 0.0075, 0.0085, 0.0095, 0.0105, 0.0115, 0.0125, 0.0135, 0.0145, 0.0155, 0.0165, 0.0175, 0.0185, 0.0195, 0.0205, 0.0215, 0.0225, 0.0235, 0.0245, 0.0255, 0.0265, 0.0275, 0.0285, 0.0295, 0.0305, 0.0315, 0.0325, 0.0335, 0.0345, 0.0355, 0.0365, 0.0375, 0.0385, 0.0395, 0.0405, 0.0415, 0.0425, 0.0435, 0.0445, 0.0455, 0.0465, 0.0475, 0.0485, 0.0495, 0.0505, 0.0515, 0.0525, 0.0535, 0.0545, 0.0555, 0.0565, 0.0575, 0.0585, 0.0595, 0.0605, 0.0615, 0.0625, 0.0635, 0.0645, 0.0655, 0.0665, 0.0675, 0.0685, 0.0695, 0.0705, 0.0715, 0.0725, 0.0735, 0.0745, 0.0755, 0.0765, 0.0775, 0.0785, 0.0795, 0.0805, 0.0815, 0.0825, 0.0835, 0.0845, 0.0855, 0.0865, 0.0875, 0.0885, 0.0895, 0.0905, 0.0915, 0.0925, 0.0935, 0.0945, 0.0955, 0.0965, 0.0975, 0.0985, 0.0995, 0.1005, 0.1015, 0.1025, 0.1035, 0.1045, 0.1055, 0.1065, 0.1075, 0.1085, 0.1095, 0.1105, 0.1115, 0.1125, 0.1135, 0.1145, 0.1155, 0.1165, 0.1175, 0.1185, 0.1195, 0.1205, 0.1215, 0.1225, 0.1235, 0.1245, 0.1255, 0.1265, 0.1275, 0.1285, 0.1295, 0.1305, 0.1315, 0.1325, 0.1335, 0.1345, 0.1355, 0.1365, 0.1375, 0.1385, 0.1395, 0.1405, 0.1415, 0.1425, 0.1435, 0.1445, 0.1455, 0.1465, 0.1475, 0.1485, 0.1495, 0.1505, 0.1515, 0.1525, 0.1535, 0.1545, 0.1555, 0.1565, 0.1575, 0.1585, 0.1595, 0.1605, 0.1615, 0.1625, 0.1635, 0.1645, 0.1655, 0.1665, 0.1675, 0.1685, 0.1695, 0.1705, 0.1715, 0.1725, 0.1735, 0.1745, 0.1755, 0.1765, 0.1775, 0.1785, 0.1795, 0.1805, 0.1815, 0.1825, 0.1835, 0.1845, 0.1855, 0.1865, 0.1875, 0.1885, 0.1895, 0.1905, 0.1915, 0.1925, 0.1935, 0.1945, 0.1955, 0.1965, 0.1975, 0.1985, 0.1995, 0.2005, 0.2015, 0.2025, 0.2035, 0.2045, 0.2055, 0.2065, 0.2075, 0.2085, 0.2095, 0.2105, 0.2115, 0.2125, 0.2135, 0.2145, 0.2155, 0.2165, 0.2175, 0.2185, 0.2195, 0.2205, 0.2215, 0.2225, 0.2235, 0.2245, 0.2255, 0.2265, 0.2275, 0.2285, 0.2295, 0.2305, 0.2315, 0.2325, 0.2335, 0.2345, 0.2355, 0.2365, 0.2375, 0.2385, 0.2395, 0.2405, 0.2415, 0.2425, 0.2435, 0.2445, 0.2455, 0.2465, 0.2475, 0.2485, 0.2495, 0.2505, 0.2515, 0.2525, 0.2535, 0.2545, 0.2555, 0.2565, 0.2575, 0.2585, 0.2595, 0.2605, 0.2615, 0.2625, 0.2635, 0.2645, 0.2655, 0.2665, 0.2675, 0.2685, 0.2695, 0.2705, 0.2715, 0.2725, 0.2735, 0.2745, 0.2755, 0.2765, 0.2775, 0.2785, 0.2795, 0.2805, 0.2815, 0.2825, 0.2835, 0.2845, 0.2855, 0.2865, 0.2875, 0.2885, 0.2895, 0.2905, 0.2915, 0.2925, 0.2935, 0.2945, 0.2955, 0.2965, 0.2975, 0.2985, 0.2995, 0.3005, 0.3015, 0.3025, 0.3035, 0.3045, 0.3055, 0.3065, 0.3075, 0.3085, 0.3095, 0.3105, 0.3115, 0.3125, 0.3135, 0.3145, 0.3155, 0.3165, 0.3175, 0.3185, 0.3195, 0.3205, 0.3215, 0.3225, 0.3235, 0.3245, 0.3255, 0.3265, 0.3275, 0.3285, 0.3295, 0.3305, 0.3315, 0.3325, 0.3335, 0.3345, 0.3355, 0.3365, 0.3375, 0.3385, 0.3395, 0.3405, 0.3415, 0.3425, 0.3435, 0.3445, 0.3455, 0.3465, 0.3475, 0.3485, 0.3495, 0.3505, 0.3515, 0.3525, 0.3535, 0.3545, 0.3555, 0.3565, 0.3575, 0.3585, 0.3595, 0.3605, 0.3615, 0.3625, 0.3635, 0.3645, 0.3655, 0.3665, 0.3675, 0.3685, 0.3695, 0.3705, 0.3715, 0.3725, 0.3735, 0.3745, 0.3755, 0.3765, 0.3775, 0.3785, 0.3795, 0.3805, 0.3815, 0.3825, 0.3835, 0.3845, 0.3855, 0.3865, 0.3875, 0.3885, 0.3895, 0.3905, 0.3915, 0.3925, 0.3935, 0.3945, 0.3955, 0.3965, 0.3975, 0.3985, 0.3995, 0.4005, 0.4015, 0.4025, 0.4035, 0.4045, 0.4055, 0.4065, 0.4075, 0.4085, 0.4095, 0.4105, 0.4115, 0.4125, 0.4135, 0.4145, 0.4155, 0.4165, 0.4175, 0.4185, 0.4195, 0.4205, 0.4215, 0.4225, 0.4235, 0.4245, 0.4255, 0.4265, 0.4275, 0.4285, 0.4295, 0.4305, 0.4315, 0.4325, 0.4335, 0.4345, 0.4355, 0.4365, 0.4375, 0.4385, 0.4395, 0.4405, 0.4415, 0.4425, 0.4435, 0.4445, 0.4455, 0.4465, 0.4475, 0.4485, 0.4495, 0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585, 0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675, 0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765, 0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855, 0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945, 0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035, 0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125, 0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215, 0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305, 0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395, 0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485, 0.5495, 0.5505, 0.5515, 0.5525, 0.5535, 0.5545, 0.5555, 0.5565, 0.5575, 0.5585, 0.5595, 0.5605, 0.5615, 0.5625, 0.5635, 0.5645, 0.5655, 0.5665, 0.5675, 0.5685, 0.5695, 0.5705, 0.5715, 0.5725, 0.5735, 0.5745, 0.5755, 0.5765, 0.5775, 0.5785, 0.5795, 0.5805, 0.5815, 0.5825, 0.5835, 0.5845, 0.5855, 0.5865, 0.5875, 0.5885, 0.5895, 0.5905, 0.5915, 0.5925, 0.5935, 0.5945, 0.5955, 0.5965, 0.5975, 0.5985, 0.5995, 0.6005, 0.6015, 0.6025, 0.6035, 0.6045, 0.6055, 0.6065, 0.6075, 0.6085, 0.6095, 0.6105, 0.6115, 0.6125, 0.6135, 0.6145, 0.6155, 0.6165, 0.6175, 0.6185, 0.6195, 0.6205, 0.6215, 0.6225, 0.6235, 0.6245, 0.6255, 0.6265, 0.6275, 0.6285, 0.6295, 0.6305, 0.6315, 0.6325, 0.6335, 0.6345, 0.6355, 0.6365, 0.6375, 0.6385, 0.6395, 0.6405, 0.6415, 0.6425, 0.6435, 0.6445, 0.6455, 0.6465, 0.6475, 0.6485, 0.6495, 0.6505, 0.6515, 0.6525, 0.6535, 0.6545, 0.6555, 0.6565, 0.6575, 0.6585, 0.6595, 0.6605, 0.6615, 0.6625, 0.6635, 0.6645, 0.6655, 0.6665, 0.6675, 0.6685, 0.6695, 0.6705, 0.6715, 0.6725, 0.6735, 0.6745, 0.6755, 0.6765, 0.6775, 0.6785, 0.6795, 0.6805, 0.6815, 0.6825, 0.6835, 0.6845, 0.6855, 0.6865, 0.6875, 0.6885, 0.6895, 0.6905, 0.6915, 0.6925, 0.6935, 0.6945, 0.6955, 0.6965, 0.6975, 0.6985, 0.6995, 0.7005, 0.7015, 0.7025, 0.7035, 0.7045, 0.7055, 0.7065, 0.7075, 0.7085, 0.7095, 0.7105, 0.7115, 0.7125, 0.7135, 0.7145, 0.7155, 0.7165, 0.7175, 0.7185, 0.7195, 0.7205, 0.7215, 0.7225, 0.7235, 0.7245, 0.7255, 0.7265, 0.7275, 0.7285, 0.7295, 0.7305, 0.7315, 0.7325, 0.7335, 0.7345, 0.7355, 0.7365, 0.7375, 0.7385, 0.7395, 0.7405, 0.7415, 0.7425, 0.7435, 0.7445, 0.7455, 0.7465, 0.7475, 0.7485, 0.7495, 0.7505, 0.7515, 0.7525, 0.7535, 0.7545, 0.7555, 0.7565, 0.7575, 0.7585, 0.7595, 0.7605, 0.7615, 0.7625, 0.7635, 0.7645, 0.7655, 0.7665, 0.7675, 0.7685, 0.7695, 0.7705, 0.7715, 0.7725, 0.7735, 0.7745, 0.7755, 0.7765, 0.7775, 0.7785, 0.7795, 0.7805, 0.7815, 0.7825, 0.7835, 0.7845, 0.7855, 0.7865, 0.7875, 0.7885, 0.7895, 0.7905, 0.7915, 0.7925, 0.7935, 0.7945, 0.7955, 0.7965, 0.7975, 0.7985, 0.7995, 0.8005, 0.8015, 0.8025, 0.8035, 0.8045, 0.8055, 0.8065, 0.8075, 0.8085, 0.8095, 0.8105, 0.8115, 0.8125, 0.8135, 0.8145, 0.8155, 0.8165, 0.8175, 0.8185, 0.8195, 0.8205, 0.8215, 0.8225, 0.8235, 0.8245, 0.8255, 0.8265, 0.8275, 0.8285, 0.8295, 0.8305, 0.8315, 0.8325, 0.8335, 0.8345, 0.8355, 0.8365, 0.8375, 0.8385, 0.8395, 0.8405, 0.8415, 0.8425, 0.8435, 0.8445, 0.8455, 0.8465, 0.8475, 0.8485, 0.8495, 0.8505, 0.8515, 0.8525, 0.8535, 0.8545, 0.8555, 0.8565, 0.8575, 0.8585, 0.8595, 0.8605, 0.8615, 0.8625, 0.8635, 0.8645, 0.8655, 0.8665, 0.8675, 0.8685, 0.8695, 0.8705, 0.8715, 0.8725, 0.8735, 0.8745, 0.8755, 0.8765, 0.8775, 0.8785, 0.8795, 0.8805, 0.8815, 0.8825, 0.8835, 0.8845, 0.8855, 0.8865, 0.8875, 0.8885, 0.8895, 0.8905, 0.8915, 0.8925, 0.8935, 0.8945, 0.8955, 0.8965, 0.8975, 0.8985, 0.8995, 0.9005, 0.9015, 0.9025, 0.9035, 0.9045, 0.9055, 0.9065, 0.9075, 0.9085, 0.9095, 0.9105, 0.9115, 0.9125, 0.9135, 0.9145, 0.9155, 0.9165, 0.9175, 0.9185, 0.9195, 0.9205, 0.9215, 0.9225, 0.9235, 0.9245, 0.9255, 0.9265, 0.9275, 0.9285, 0.9295, 0.9305, 0.9315, 0.9325, 0.9335, 0.9345, 0.9355, 0.9365, 0.9375, 0.9385, 0.9395, 0.9405, 0.9415, 0.9425, 0.9435, 0.9445, 0.9455, 0.9465, 0.9475, 0.9485, 0.9495, 0.9505, 0.9515, 0.9525, 0.9535, 0.9545, 0.9555, 0.9565, 0.9575, 0.9585, 0.9595, 0.9605, 0.9615, 0.9625, 0.9635, 0.9645, 0.9655, 0.9665, 0.9675, 0.9685, 0.9695, 0.9705, 0.9715, 0.9725, 0.9735, 0.9745, 0.9755, 0.9765, 0.9775, 0.9785, 0.9795, 0.9805, 0.9815, 0.9825, 0.9835, 0.9845, 0.9855, 0.9865, 0.9875, 0.9885, 0.9895, 0.9905, 0.9915, 0.9925, 0.9935, 0.9945, 0.9955, 0.9965, 0.9975, 0.9985, 0.9995];\nlet data0 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0068466305166028, 0.01517996384993614, 0.023513297183269482, 0.031846630516602824, 0.04017996384993616, 0.04851329718326951, 0.056846630516602846, 0.06517996384993618, 0.07351329718326953, 0.08184663051660288, 0.0901799638499362, 0.09851329718326955, 0.1068466305166029, 0.11517996384993623, 0.12351329718326957, 0.13184663051660292, 0.14017996384993625, 0.1485132971832696, 0.15684663051660286, 0.1651799638499362, 0.17351329718326952, 0.18184663051660288, 0.1901799638499362, 0.19851329718326954, 0.2068466305166029, 0.21517996384993623, 0.22351329718326957, 0.23184663051660293, 0.24017996384993626, 0.2485132971832696, 0.25684663051660295, 0.2651799638499363, 0.2735132971832696, 0.28184663051660297, 0.29017996384993583, 0.2985132971832692, 0.30684663051660255, 0.31517996384993585, 0.3235132971832692, 0.33184663051660257, 0.3401799638499359, 0.34851329718326923, 0.3568466305166026, 0.3651799638499359, 0.37351329718326925, 0.3818466305166026, 0.3901799638499359, 0.3985132971832693, 0.40684663051660264, 0.41517996384993594, 0.4235132971832693, 0.43184663051660266, 0.44017996384993596, 0.4485132971832693, 0.4568466305166027, 0.465179963849936, 0.47351329718326934, 0.4818466305166027, 0.490179963849936, 0.49851329718326937, 0.5068466305166027, 0.515179963849936, 0.5235132971832694, 0.5318466305166027, 0.540179963849936, 0.5485132971832695, 0.5568466305166028, 0.5651799638499361, 0.5735132971832695, 0.5818466305166028, 0.5901799638499361, 0.5985132971832695, 0.6068466305166028, 0.6151799638499361, 0.6235132971832695, 0.6318466305166028, 0.6401799638499361, 0.6485132971832696, 0.6568466305166029, 0.6651799638499362, 0.6735132971832696, 0.6818466305166029, 0.6901799638499362, 0.6985132971832696, 0.7068466305166029, 0.7151799638499362, 0.7235132971832696, 0.7318466305166029, 0.7401799638499362, 0.7485132971832696, 0.756846630516603, 0.7651799638499363, 0.7735132971832697, 0.781846630516603, 0.7901799638499363, 0.7985132971832697, 0.806846630516603, 0.8151799638499363, 0.8235132971832692, 0.8318466305166026, 0.840179963849936, 0.8485132971832692, 0.8568466305166027, 0.8651799638499358, 0.8735132971832693, 0.8818466305166025, 0.890179963849936, 0.8985132971832692, 0.9068466305166027, 0.9151799638499358, 0.9235132971832694, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.9274526028125225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0];\nlet data1 = [4.7497782e-21, 1.2236753e-11, 1.4130822e-11, 1.4288661e-11, 3.4924231e-11, 2.9147543e-11, 3.5115528e-11, 4.4161819e-11, 3.215849e-11, 5.8045656e-11, 5.6981576e-11, 7.4404121e-11, 5.3422194e-11, 5.1797341e-11, 3.9958742e-11, 4.3513123e-11, 4.3012595e-11, 2.8551867e-11, 1.0164615e-11, 3.6251191e-11, 1.5676756e-11, 4.3760219e-11, 2.087822e-11, 3.2388469e-11, 1.0404042e-13, 2.2323671e-11, 5.9775439e-12, 1.5878278e-11, 2.5413204e-12, 1.3496131e-11, 9.0037193e-12, 6.4866305e-12, 3.0908672e-12, 9.3806435e-12, 1.8018999e-11, 3.9618166e-11, 3.3207453e-11, 3.636568e-11, 1.6921461e-11, 2.4158606e-11, 1.5541036e-11, 2.1612839e-11, 2.2662135e-12, 3.6244967e-11, 2.1388863e-11, 4.0860982e-11, 2.0243752e-11, 4.4159152e-11, 3.7287927e-11, 4.503816e-11, 4.2794622e-11, 3.2505514e-11, 3.5482004e-11, 3.3629729e-11, 5.203321e-11, 3.059744e-11, 3.5895609e-11, 2.4423153e-11, 2.8592995e-11, 9.0477364e-12, 1.1918963e-11, 1.11291e-11, 9.5233656e-12, 1.9686646e-11, 1.4684259e-11, 1.0456061e-11, 1.326493e-11, 1.6252424e-11, 1.8960364e-11, 1.2528977e-11, 1.0733391e-11, 7.5758314e-12, 1.6704377e-11, 3.1431097e-12, 2.2738832e-12, 1.7303387e-12, 6.4157141e-12, 6.9744867e-12, 1.1955532e-11, 1.2810531e-12, 2.9376966e-12, 5.1365506e-12, 6.5088614e-12, 5.6347441e-12, 8.9720403e-12, 5.0112797e-12, 1.8458058e-11, 3.0491843e-12, 6.0556854e-12, 1.5169225e-12, 1.0354577e-11, 1.6511413e-11, 1.0133936e-12, 1.1652192e-11, 3.9020711e-12, 7.5887253e-12, 1.191296e-11, 1.6945582e-11, 6.168507e-12, 3.7362289e-12, 1.430978e-11, 1.3481458e-11, 1.6208962e-11, 1.5379529e-11, 1.7487792e-11, 1.6227303e-11, 2.3599166e-11, 2.3986428e-11, 2.2877441e-11, 2.8995818e-11, 2.9717098e-12, 1.2812643e-11, 3.9682079e-12, 8.8532164e-12, 1.4168058e-11, 1.9919292e-11, 2.080119e-11, 3.3138871e-11, 2.4218295e-11, 2.2538532e-11, 1.2056572e-11, 2.2702373e-11, 2.0471618e-11, 2.1337621e-11, 9.2228044e-12, 1.1923409e-11, 1.0586334e-12, 7.2505939e-13, 2.3409092e-13, 9.9634254e-12, 1.9138767e-11, 2.1332952e-11, 3.4972806e-11, 1.2183732e-11, 2.5995097e-11, 4.4557306e-12, 1.2136936e-11, 5.6049548e-12, 2.6847761e-11, 8.9601469e-13, 2.9922622e-11, 2.5058955e-11, 1.8621566e-11, 9.110872e-12, 1.7125318e-11, 1.9371191e-11, 1.1349964e-12, 1.0734169e-12, 3.3798683e-12, 2.0197289e-11, 9.8479361e-12, 8.9555895e-12, 4.0984808e-12, 1.52756e-11, 2.0106143e-11, 4.3018931e-12, 3.1851594e-11, 1.9488014e-11, 2.5790573e-11, 1.2311893e-11, 1.3165891e-11, 4.6352448e-12, 1.1384311e-11, 5.0336217e-12, 4.7395075e-12, 1.0127489e-11, 2.3451887e-11, 2.9249694e-11, 2.1945746e-11, 2.2225633e-11, 8.1962946e-12, 3.4067677e-12, 1.1086306e-11, 1.9424656e-11, 1.276318e-11, 4.0311213e-11, 4.1533465e-11, 2.0941134e-11, 3.2442712e-11, 1.8077688e-11, 3.7180997e-11, 1.4652802e-11, 1.8750616e-11, 1.1626293e-11, 3.7798014e-12, 3.7143316e-12, 1.4391923e-11, 4.6232401e-12, 1.3459005e-11, 6.2703243e-12, 1.3369415e-11, 2.2801078e-12, 1.1086528e-11, 1.4684592e-12, 1.151425e-11, 1.0592781e-11, 2.7326391e-11, 1.7531254e-11, 1.7685202e-11, 5.8771716e-12, 4.6834857e-12, 1.7814919e-11, 1.283832e-13, 2.6063234e-11, 8.4499487e-12, 3.4453048e-11, 2.7307051e-11, 2.5739331e-11, 2.6164607e-11, 1.5238919e-11, 2.7857709e-11, 2.8230743e-11, 2.3899394e-11, 4.5124193e-11, 2.07684e-11, 2.5994874e-11, 1.2769738e-11, 7.5410401e-12, 4.1377182e-12, 9.3713065e-12, 7.1242115e-12, 1.8334232e-11, 3.5548474e-11, 1.4479624e-11, 2.4772844e-11, 3.0732159e-11, 2.7721323e-11, 2.8178611e-11, 2.0658579e-11, 3.5832584e-11, 3.0355346e-11, 2.908852e-11, 2.9166884e-12, 2.6237079e-11, 1.2974706e-11, 2.4185616e-11, 1.540943e-11, 2.5027499e-11, 5.3102848e-12, 2.6987816e-11, 2.0652577e-11, 3.3621837e-11, 2.9035055e-11, 3.0026996e-11, 1.9403536e-11, 2.2531196e-11, 2.1464448e-11, 1.056188e-11, 1.4717828e-11, 4.7268359e-12, 1.2038342e-11, 8.5823334e-12, 1.8288437e-11, 1.9149215e-11, 8.5026358e-12, 1.7856269e-11, 6.8202046e-12, 1.0678592e-12, 1.3995325e-11, 1.7243698e-11, 2.3217129e-11, 1.1335292e-11, 1.1618179e-11, 5.3917608e-12, 2.3009937e-11, 1.0752732e-11, 3.0797629e-11, 1.3905401e-11, 2.3099861e-11, 8.8703342e-12, 1.6012664e-11, 1.2647023e-11, 1.0079582e-11, 1.6073021e-11, 2.722613e-12, 2.6127481e-11, 1.3952975e-11, 5.9724308e-12, 7.044625e-12, 1.5309391e-11, 1.3658194e-11, 8.9471418e-12, 2.529249e-11, 4.328459e-12, 2.3591385e-11, 5.059743e-12, 1.1537704e-11, 1.247918e-11, 9.452338e-12, 2.4481175e-11, 2.0175058e-11, 2.3537142e-11, 6.6256846e-11, 6.1706634e-11, 1.2504701e-10, 1.3924097e-10, 2.4660067e-10, 3.2732035e-10, 5.094611e-10, 7.2167552e-10, 1.0844473e-09, 1.5062619e-09, 2.1630591e-09, 3.0315697e-09, 4.2715788e-09, 5.9608509e-09, 8.3437843e-09, 1.1625095e-08, 1.6157491e-08, 2.237713e-08, 3.0939687e-08, 4.2591514e-08, 5.8554935e-08, 8.0188008e-08, 1.0956633e-07, 1.4918876e-07, 2.027e-07, 2.7453773e-07, 3.7079022e-07, 4.9929447e-07, 6.7032184e-07, 8.9726275e-07, 1.1974227e-06, 1.5931029e-06, 2.1130083e-06, 2.7938138e-06, 3.6823602e-06, 4.8380822e-06, 6.336126e-06, 8.27101e-06, 1.0761312e-05, 1.3954958e-05, 1.8035783e-05, 2.3230923e-05, 2.9820083e-05, 3.8145661e-05, 4.8625074e-05, 6.1764365e-05, 7.8173982e-05, 9.8586305e-05, 0.00012387544, 0.00015507864, 0.0001934198, 0.00024033476, 0.0002974976, 0.00036684837, 0.00045062101, 0.00055137138, 0.00067200382, 0.00081579642, 0.00098642278, 0.0011879702, 0.0014249526, 0.0017023168, 0.002025442, 0.0024001302, 0.0028325882, 0.0033293991, 0.0038974847, 0.0045440572, 0.005276562, 0.0061026118, 0.0070299137, 0.0080661894, 0.0092190931, 0.010496126, 0.011904552, 0.013451315, 0.015142962, 0.016985572, 0.018984691, 0.021145281, 0.023471678, 0.025967555, 0.028635909, 0.031479046, 0.034498587, 0.037695476, 0.041070007, 0.044621845, 0.04835007, 0.052253211, 0.056329295, 0.060575892, 0.064990167, 0.069568924, 0.074308664, 0.079205625, 0.084255833, 0.089455144, 0.094799285, 0.10028389, 0.10590454, 0.11165678, 0.11753617, 0.12353828, 0.12965873, 0.13589322, 0.14223751, 0.14868746, 0.15523903, 0.1618883, 0.16863145, 0.1754648, 0.18238479, 0.18938797, 0.19647105, 0.20363084, 0.21086428, 0.21816844, 0.22554052, 0.23297781, 0.24047775, 0.24803786, 0.2556558, 0.2633293, 0.27105622, 0.27883449, 0.28666216, 0.29453734, 0.30245824, 0.31042314, 0.31843041, 0.32647848, 0.33456586, 0.3426911, 0.35085286, 0.35904979, 0.36728075, 0.37554428, 0.38383987, 0.39216506, 0.40052173, 0.40890302, 0.41731947, 0.42574855, 0.43422869, 0.44269034, 0.45124763, 0.45971518, 0.46837279, 0.47681342, 0.48558203, 0.49399581, 0.50280125, 0.51131554, 0.51987967, 0.52886102, 0.53664995, 0.54668062, 0.55314771, 0.56469983, 0.56982903, 0.5827048, 0.58713623, 0.59985871, 0.60559039, 0.61618948, 0.62421812, 0.63250928, 0.64190155, 0.64973676, 0.65867379, 0.66728178, 0.67543557, 0.68436249, 0.69251268, 0.70116246, 0.70940041, 0.71803499, 0.72591586, 0.73465007, 0.7421754, 0.75064661, 0.75785453, 0.76589282, 0.77257401, 0.78002765, 0.78616575, 0.79272695, 0.79838116, 0.80388596, 0.80906539, 0.81353354, 0.81825345, 0.82185202, 0.82608446, 0.82915378, 0.83282197, 0.83569667, 0.83878624, 0.84172396, 0.84429782, 0.84742436, 0.84965847, 0.85300593, 0.85521123, 0.85880565, 0.86132943, 0.86516801, 0.86828684, 0.8723899, 0.87638194, 0.88097185, 0.88619249, 0.89157407, 0.89817, 0.90433351, 0.91190589, 0.91831494, 0.92592112, 0.9316993, 0.9380621, 0.94212677, 0.94587885, 0.94717707, 0.94742498, 0.94767951, 0.94780527, 0.94803564, 0.94820734, 0.94830276, 0.94855132, 0.94874752, 0.94888718, 0.94845965, 0.94872855, 0.94879579, 0.94921478, 0.94945263, 0.94948663, 0.95001979, 0.9507142, 0.94977329, 0.95073316, 0.95280442, 0.94948042, 0.95051732, 0.95976221, 0.94700999, 0.92703429, 0.92353142, 0.92139847, 0.92149921, 0.92694969, 0.93111875, 0.93134918, 0.93179552, 0.9317036, 0.93019943, 0.92913487, 0.92907245, 0.92909259, 0.9291059, 0.9291442, 0.92915769, 0.92922451, 0.92924203, 0.92911433, 0.92899133, 0.92898409, 0.92899886, 0.92900657, 0.92900604, 0.92900255, 0.92900176, 0.92900006, 0.92899903, 0.92899627, 0.92899873, 0.92900462, 0.9290154, 0.92902768, 0.92904411, 0.92906035, 0.9290786, 0.92909653, 0.9291185, 0.92914032, 0.92916527, 0.92919056, 0.9292208, 0.92925171, 0.92928876, 0.92933076, 0.92937489, 0.92942012, 0.92947584, 0.92953381, 0.9295991, 0.92966776, 0.92974198, 0.92981911, 0.92989924, 0.92998185, 0.93006832, 0.93015723, 0.930241, 0.93032401, 0.93040384, 0.93048168, 0.93054887, 0.93061051, 0.93066871, 0.93073158, 0.93079108, 0.93084464, 0.93089778, 0.93094338, 0.93099075, 0.93103015, 0.93107199, 0.93110975, 0.93114968, 0.93118829, 0.93122538, 0.93126367, 0.93129719, 0.93133572, 0.93136851, 0.93140868, 0.93144301, 0.93148121, 0.93151575, 0.93155226, 0.93158905, 0.93162476, 0.93166393, 0.93169731, 0.93173935, 0.93177342, 0.9318156, 0.93185112, 0.93189142, 0.93192729, 0.93196446, 0.93200387, 0.93203979, 0.93208172, 0.93211479, 0.93215424, 0.93218187, 0.93221582, 0.93224005, 0.9322631, 0.93227917, 0.93228247, 0.93227121, 0.93224052, 0.93218199, 0.93208667, 0.93194139, 0.93172852, 0.9314245, 0.93099797, 0.93040702, 0.92959603, 0.92849123, 0.92699517, 0.92497967, 0.92227668, 0.91866727, 0.91386765, 0.90751276, 0.89913639, 0.88814896, 0.87381251, 0.85521555, 0.83125048, 0.80060084, 0.76175515, 0.71307468, 0.65297275, 0.58034371, 0.49543106, 0.40111096, 0.30400643, 0.21385279, 0.13973194, 0.085672249, 0.050029818, 0.028248231, 0.01561467, 0.0085251238, 0.0046229516, 0.0024979795, 0.0013473218, 0.00072604692, 0.00039108398, 0.00021061359, 0.00011341244, 6.1068151e-05, 3.2881948e-05, 1.7704928e-05, 9.5328448e-06, 5.1327199e-06, 2.7634876e-06, 1.487836e-06, 8.0098752e-07, 4.3120483e-07, 2.3210337e-07, 1.2492882e-07, 6.7187527e-08, 3.6127854e-08, 1.9352349e-08, 1.0404359e-08, 5.5210503e-09, 2.9529626e-09, 1.5346396e-09, 7.9428198e-10, 3.6861033e-10, 1.2419183e-10, 4.3436841e-11, 1.3257637e-11, 1.4870166e-11, 1.0206285e-11, 2.4490177e-11, 2.4370081e-11, 1.9556357e-11, 3.4978943e-11, 2.4217574e-11, 2.8594202e-11, 2.1797559e-11, 2.6848701e-11, 2.4967454e-11, 4.3702007e-11, 1.6981616e-11, 1.2151798e-11, 3.6970075e-12, 3.3598392e-11, 6.8825519e-12, 2.0689279e-11, 1.3582629e-11, 3.5937048e-11, 2.1156788e-11, 3.1031754e-11, 3.8754867e-11, 5.7551244e-11, 1.2017272e-11, 3.1834355e-12, 7.7792771e-12, 5.2228499e-12, 8.825401e-12, 2.2278166e-11, 2.3018056e-11, 1.0137468e-11, 2.6215477e-11, 1.8272039e-11, 1.0712309e-11, 7.3875772e-12, 1.0804989e-11, 8.8561465e-12, 3.9837509e-11, 2.3096973e-11, 6.3352043e-11, 2.9827795e-11, 7.8074697e-11, 3.5060857e-11, 6.8725291e-11, 6.4160861e-11, 4.8119258e-11, 4.3734306e-11, 5.0335154e-11, 8.2433787e-11, 2.8126692e-11, 5.3756784e-11, 1.8430428e-11, 2.9340196e-11, 3.4874053e-11, 1.5347553e-11, 1.4757284e-11, 2.7799813e-11, 5.3875659e-12, 1.7271756e-11, 2.7111536e-11, 1.7808525e-11, 1.3187377e-11, 6.0115774e-12, 2.0383045e-11, 3.0349248e-11, 6.6302612e-12, 1.3277616e-11, 1.5641245e-11, 2.5366146e-11, 1.2476235e-11, 1.1086805e-11, 9.6080238e-12, 2.9373495e-11, 5.0011937e-12, 3.4103085e-12, 7.4496232e-12, 2.1377889e-11, 1.5513601e-11, 3.2097745e-11, 2.0315671e-11, 1.5045981e-11, 6.3766385e-13, 5.3094257e-12, 2.071847e-11, 6.0062497e-12, 5.9049116e-12, 4.2392826e-11, 1.8420105e-11, 2.1885356e-11, 8.4259315e-12, 2.8205943e-11, 2.5683036e-12, 2.7446629e-11, 3.480124e-12, 3.6805801e-13, 3.8837336e-11, 8.7038619e-12, 2.6307602e-11, 1.5869117e-11, 7.3966789e-13, 1.2958395e-11, 1.394325e-11, 4.6496739e-12, 1.5903303e-11, 2.8199838e-11, 2.5214417e-11, 8.5717784e-12, 2.6207041e-11, 6.0112444e-12, 4.0859325e-11, 2.4191602e-11, 3.8050274e-11, 2.4840254e-11, 2.8883342e-11, 2.9577836e-12, 8.4301493e-12, 1.0224377e-11, 2.481528e-11, 2.9430213e-11, 1.1148851e-11, 2.2952014e-11, 5.6299781e-12, 2.6766898e-11, 4.9046285e-12, 5.1555983e-11, 1.0087076e-11, 4.4939041e-11, 1.4179447e-11, 2.3963397e-11, 2.3591898e-12, 1.9854821e-11, 1.3202472e-11, 3.1101791e-11, 1.3970666e-11, 2.8291852e-11, 3.9392531e-11, 1.6398339e-12, 1.9717077e-12, 3.3493946e-11, 1.4251482e-11, 2.225519e-11, 3.5135667e-11, 3.6623549e-11, 5.2043471e-11, 2.0132197e-11, 1.4937762e-11, 7.5046765e-12, 1.3253197e-11, 5.6778167e-12, 1.659369e-11, 7.4506221e-12, 8.1147027e-12, 1.4139045e-11, 2.3932651e-12, 4.2783971e-12, 2.1105952e-11, 5.3867889e-12, 1.8312441e-11, 9.8047062e-12, 9.3391949e-12, 3.6215311e-12, 1.3048523e-11, 4.0050618e-11, 1.8217429e-11, 1.684487e-11, 2.7428204e-11, 1.2258796e-11, 2.2140089e-11, 2.0840342e-11, 4.178391e-12, 1.6649631e-11, 1.2855725e-11, 3.9175537e-12, 1.789277e-11, 2.852261e-11, 3.6098545e-11, 6.5570048e-12, 3.2203301e-11, 9.8111439e-12, 1.2932422e-11, 2.8110487e-12, 1.2827977e-11, 7.5176629e-12, 2.5976061e-11, 2.329077e-11, 3.8056933e-11, 4.690975e-11, 3.7367213e-11, 5.2457148e-11, 3.9460349e-11, 4.9403576e-11, 6.3205752e-11, 7.2271235e-11, 4.9367614e-11, 4.5474479e-11, 1.1120325e-11, 1.9082965e-11, 9.2018946e-12, 2.3865167e-11, 4.1185538e-11, 3.977624e-11, 1.6751302e-11, 8.4957471e-12, 3.4906463e-11, 2.2628576e-11, 2.4532244e-11, 4.0878083e-11, 4.5074011e-11, 1.5930275e-11, 8.4807628e-12, 2.2477734e-11, 9.4470816e-12, 3.760119e-11, 2.9787615e-12, 4.1064887e-11, 1.2349257e-12, 2.1885134e-11, 1.5716833e-12, 8.662683e-12, 1.085083e-11, 6.3942867e-12, 1.9193516e-11, 3.2279888e-11, 2.5822778e-11, 4.105412e-11, 1.8547638e-11, 2.2644559e-11, 4.7690819e-11, 2.1394316e-11, 6.6005036e-11, 9.6874959e-12, 1.498449e-11, 1.0487767e-11, 4.0695719e-11, 5.1100795e-12, 3.0456913e-13, 2.4637023e-11, 3.9656476e-11, 2.8627056e-11, 5.2256026e-11, 2.4325572e-11, 3.5351108e-11, 3.4459932e-11, 2.6888215e-11, 3.1180264e-11, 7.3392391e-11, 4.5273468e-11, 2.3238491e-11, 4.5416429e-11, 4.9126201e-12, 6.8129583e-12, 4.7035063e-12, 8.8010932e-12, 3.6449177e-11, 3.57498e-11, 6.8845498e-11, 6.3584799e-11, 6.4005468e-11, 4.7890387e-11, 4.5425864e-11, 3.9753042e-11, 5.3676979e-11, 7.4143047e-11, 5.9449474e-11, 7.5752469e-11, 7.8523892e-11, 5.5389292e-11, 6.6257437e-11, 2.5778935e-11, 4.8051218e-11, 2.9114655e-11, 2.0579061e-11, 3.7228137e-11, 1.9723736e-13, 1.6788374e-11, 1.5427803e-11, 3.2430951e-11, 1.5089269e-11, 8.6060757e-12, 4.2812829e-12, 1.4006628e-11, 3.3064175e-12, 1.1991854e-12, 1.1020541e-11, 1.2967097e-20];\nlet data2 = [3.1587274e-21, 1.3862829e-11, 1.646295e-11, 3.2144263e-11, 1.5146772e-11, 4.8599543e-11, 1.5956976e-11, 4.5079954e-11, 1.1164003e-11, 2.375367e-11, 8.4472809e-12, 9.1891247e-12, 1.5533811e-11, 1.4210519e-11, 3.0230631e-11, 5.3723755e-11, 1.8964366e-11, 3.6470387e-11, 1.7343736e-11, 2.657321e-11, 1.6595779e-11, 2.8922344e-12, 2.2643239e-12, 7.9208543e-13, 1.0798639e-11, 4.4303875e-12, 1.3237586e-11, 3.0215069e-11, 3.847939e-12, 3.3845368e-11, 1.968798e-11, 2.5638958e-11, 3.1805576e-11, 1.4100588e-11, 4.2181828e-11, 9.1871239e-12, 5.4263521e-11, 2.6657799e-11, 2.9521244e-11, 2.6140709e-11, 3.6060228e-11, 3.9825691e-11, 3.693768e-11, 7.9510883e-12, 5.2393906e-11, 7.6993238e-12, 2.9091077e-11, 9.7627919e-12, 2.3350514e-11, 7.4785714e-12, 3.1269923e-11, 1.6848099e-11, 2.0900673e-11, 3.1482227e-12, 1.9616508e-11, 1.3593057e-11, 3.2383244e-11, 2.9686864e-11, 4.1839584e-11, 2.1039505e-11, 4.4363009e-11, 4.5567699e-11, 5.1585925e-11, 5.0254408e-11, 3.1628285e-11, 4.9054942e-11, 6.1561022e-11, 3.6102133e-11, 2.0040228e-11, 1.4764401e-11, 2.1241917e-11, 2.5835813e-11, 3.5030384e-11, 4.1158653e-11, 3.5126977e-11, 4.6989584e-11, 3.8374905e-11, 5.3902491e-11, 2.2804858e-11, 4.116799e-11, 2.2078131e-11, 2.9711651e-11, 2.7927514e-12, 3.6848534e-11, 4.8283198e-12, 1.5137768e-11, 1.8658358e-12, 5.5483772e-12, 4.8572199e-12, 7.2834956e-12, 4.3929285e-12, 9.2330306e-12, 1.2192069e-11, 1.0106481e-11, 1.2977151e-11, 5.4687908e-13, 2.7688531e-13, 5.1474437e-12, 9.0471806e-12, 7.2589305e-12, 1.1016835e-11, 1.5147217e-11, 7.1979068e-12, 1.6878222e-11, 2.5077518e-12, 1.3794247e-11, 2.3397977e-12, 3.3936292e-11, 4.4505064e-12, 4.141553e-11, 2.6810636e-11, 1.4511192e-11, 3.50435e-11, 2.6215738e-12, 1.6870441e-11, 1.6199848e-11, 7.5394839e-12, 4.3516901e-13, 1.8329341e-13, 2.6110141e-13, 3.3873156e-12, 1.4211298e-11, 5.7610154e-12, 2.4711376e-11, 1.6844209e-11, 1.1221025e-11, 1.4642687e-11, 1.7884391e-11, 5.9851024e-12, 1.7921405e-11, 1.2904123e-11, 1.9490681e-11, 1.8598891e-11, 1.2063686e-11, 1.8508411e-11, 3.2205064e-11, 1.1345184e-11, 1.8744058e-11, 2.3708653e-11, 3.811736e-11, 2.6724824e-12, 4.3599156e-11, 2.0617119e-11, 5.1319933e-11, 3.0725823e-11, 5.1442091e-11, 2.3753115e-11, 6.2107567e-11, 3.1677192e-11, 5.5339939e-11, 3.4040666e-11, 2.5940742e-11, 4.6395909e-11, 3.6795625e-11, 3.4361235e-11, 2.2750948e-11, 3.1149432e-11, 2.7081963e-11, 3.2067789e-11, 8.3646933e-12, 4.675705e-11, 9.3488534e-12, 1.7650189e-12, 1.4368581e-11, 1.7560154e-11, 9.1522214e-12, 5.3022816e-12, 5.1575583e-14, 7.4349989e-12, 4.3805903e-12, 1.007169e-11, 7.4106559e-13, 1.807591e-12, 1.2629572e-11, 4.3775891e-12, 1.3309947e-11, 9.9894355e-12, 1.6843987e-11, 1.3354187e-11, 5.8228171e-12, 3.1425539e-12, 2.8588437e-11, 2.262212e-12, 5.8623881e-12, 7.9196316e-12, 5.8783943e-12, 1.2594558e-11, 2.3195342e-11, 1.5702765e-12, 3.1104303e-11, 8.5607694e-12, 4.3086735e-12, 1.2531867e-11, 1.2554209e-11, 1.8647243e-12, 9.3182859e-12, 5.2836077e-12, 2.6260533e-11, 5.2642671e-13, 2.6149379e-11, 6.5936721e-12, 5.6280749e-12, 1.2302667e-11, 1.50195e-11, 3.4461163e-12, 2.4724603e-11, 1.2550652e-11, 1.7924073e-11, 2.4092246e-11, 3.1099635e-11, 3.2873213e-11, 1.9854823e-11, 1.2604229e-11, 7.9728745e-12, 2.7277039e-11, 8.5136401e-12, 1.9863048e-11, 3.4652904e-11, 1.1901511e-11, 2.5563929e-11, 1.2166726e-11, 2.461745e-11, 1.3254037e-12, 7.839267e-12, 9.9509761e-12, 6.5985629e-12, 3.8159266e-12, 9.5138063e-12, 3.7557921e-12, 1.6593e-11, 1.3511137e-11, 7.505693e-12, 4.7188328e-12, 1.596798e-11, 3.1650071e-12, 5.7689072e-13, 4.2908888e-12, 1.1663197e-11, 6.9723748e-12, 2.1425766e-11, 7.5927268e-12, 1.5739669e-11, 6.1834017e-12, 7.7385613e-13, 2.4608447e-12, 1.8791743e-12, 2.8075349e-12, 1.061968e-12, 8.6929319e-12, 1.971688e-11, 3.1628729e-11, 4.7778446e-11, 3.5523798e-11, 3.331405e-11, 3.4131257e-11, 3.3807687e-11, 3.3272812e-11, 2.7870714e-11, 3.199665e-11, 2.726659e-11, 1.8468729e-11, 3.5013599e-11, 4.2273197e-11, 3.6007874e-11, 3.1525578e-11, 1.2414044e-11, 1.5876389e-11, 3.6948795e-12, 3.3746107e-11, 2.5809358e-11, 2.4112477e-11, 4.4271084e-11, 2.9867156e-11, 3.1420648e-11, 1.7371303e-11, 2.4465836e-11, 4.0992588e-12, 2.6491401e-12, 8.1303801e-12, 8.5713292e-12, 2.3663635e-12, 1.5372526e-11, 2.8357792e-11, 1.1904735e-11, 1.3772349e-11, 5.2911662e-12, 1.6268652e-11, 1.8988709e-11, 4.6916e-12, 1.0875669e-11, 1.3120318e-11, 2.6141042e-11, 7.6080661e-11, 9.5989838e-11, 1.4489528e-10, 2.0154195e-10, 3.0967917e-10, 4.3345436e-10, 6.3358286e-10, 8.8771735e-10, 1.2741231e-09, 1.7645955e-09, 2.5038187e-09, 3.4686766e-09, 4.8671167e-09, 6.7767861e-09, 9.4414534e-09, 1.3159652e-08, 1.8246835e-08, 2.5266961e-08, 3.487059e-08, 4.8017711e-08, 6.5968252e-08, 9.0295516e-08, 1.2330064e-07, 1.6787384e-07, 2.2790804e-07, 3.0853965e-07, 4.1644473e-07, 5.6052828e-07, 7.5213878e-07, 1.0063065e-06, 1.3422031e-06, 1.7847702e-06, 2.3659374e-06, 3.1264883e-06, 4.1185031e-06, 5.4079356e-06, 7.0781943e-06, 9.234058e-06, 1.2006817e-05, 1.5560174e-05, 2.0097201e-05, 2.5868814e-05, 3.3183366e-05, 4.2418174e-05, 5.403248e-05, 6.8582362e-05, 8.6737913e-05, 0.00010930182, 0.00013723087, 0.00017165865, 0.00021392091, 0.00026558174, 0.00032846207, 0.00040466801, 0.00049662036, 0.0006070829, 0.0007391898, 0.00089647036, 0.0010828703, 0.0013027684, 0.0015609871, 0.0018627962, 0.0022139076, 0.0026204618, 0.0030890034, 0.0036264471, 0.0042400316, 0.004937265, 0.0057258587, 0.0066136536, 0.0076085392, 0.0087183668, 0.0099508598, 0.011313523, 0.012813554, 0.014457756, 0.016252461, 0.018203457, 0.020315928, 0.022594403, 0.02504272, 0.027663998, 0.030460627, 0.033434265, 0.036585855, 0.039915638, 0.043423192, 0.047107468, 0.050966832, 0.05499912, 0.059201687, 0.063571465, 0.068105018, 0.072798595, 0.077648185, 0.082649568, 0.087798357, 0.093090051, 0.098520067, 0.10408378, 0.10977655, 0.11559376, 0.12153083, 0.12758323, 0.13374653, 0.14001638, 0.14638853, 0.15285883, 0.15942327, 0.16607796, 0.1728191, 0.17964307, 0.18654633, 0.19352548, 0.20057725, 0.20769849, 0.21488617, 0.22213736, 0.22944927, 0.2368192, 0.24424456, 0.25172287, 0.25925174, 0.26682889, 0.2744521, 0.28211929, 0.28982841, 0.29757751, 0.30536475, 0.3131883, 0.32104646, 0.32893756, 0.33686, 0.34481224, 0.35279281, 0.36080028, 0.36883326, 0.37689044, 0.38497053, 0.39307229, 0.40119452, 0.40933606, 0.41749581, 0.42567269, 0.43386567, 0.44207375, 0.45029603, 0.45853158, 0.46677972, 0.47503945, 0.4833107, 0.49159204, 0.49988463, 0.50818626, 0.5164997, 0.52482283, 0.53315832, 0.54150894, 0.5498738, 0.5582359, 0.5665362, 0.57494469, 0.58311624, 0.59136317, 0.59958707, 0.60776687, 0.6159676, 0.624232, 0.6323957, 0.6405601, 0.64871327, 0.65688165, 0.66508144, 0.673247, 0.68143447, 0.68964666, 0.69798511, 0.70610249, 0.71427091, 0.72235892, 0.73037817, 0.73833991, 0.74625126, 0.75411165, 0.76191705, 0.76966278, 0.77734373, 0.78495423, 0.79248781, 0.79993689, 0.80729313, 0.81454716, 0.82168897, 0.82870754, 0.83559096, 0.84232631, 0.84889968, 0.85529632, 0.86150056, 0.86749612, 0.87326608, 0.87879326, 0.88406045, 0.88905082, 0.89374843, 0.89813868, 0.9022091, 0.90594978, 0.90935421, 0.91241975, 0.91514819, 0.91754603, 0.91962462, 0.9214, 0.92289244, 0.92412584, 0.92512669, 0.92592309, 0.92654356, 0.92701596, 0.92736647, 0.92761863, 0.92779284, 0.92791107, 0.9279828, 0.92801901, 0.92802639, 0.92803187, 0.92801278, 0.92799155, 0.9279374, 0.92788026, 0.92781863, 0.92775834, 0.92770019, 0.9276448, 0.92759277, 0.92754454, 0.92750042, 0.92746044, 0.92742444, 0.92739211, 0.92736302, 0.92733674, 0.92731283, 0.9272909, 0.92727063, 0.92725175, 0.92723405, 0.92721737, 0.92720159, 0.92718663, 0.92717241, 0.92715889, 0.92714602, 0.92713376, 0.92712205, 0.92711087, 0.92710016, 0.92708987, 0.92707996, 0.92707038, 0.92706111, 0.92705212, 0.92704341, 0.92703496, 0.92702678, 0.9270189, 0.92701128, 0.92700388, 0.92699672, 0.92698978, 0.92698311, 0.92697697, 0.92697102, 0.9269644, 0.92695882, 0.92695257, 0.92694634, 0.92694042, 0.92693453, 0.92692853, 0.92692233, 0.92691583, 0.92690895, 0.92690158, 0.92689368, 0.92688513, 0.92687566, 0.9268651, 0.92685345, 0.92684118, 0.92682992, 0.92681909, 0.92680727, 0.92679675, 0.92678714, 0.92677884, 0.92677221, 0.9267674, 0.92676447, 0.92676321, 0.92676338, 0.92676473, 0.92676685, 0.92676937, 0.92677188, 0.92677402, 0.92677561, 0.92677665, 0.92677714, 0.92677547, 0.92677222, 0.92676995, 0.92676664, 0.92676285, 0.92675868, 0.92675421, 0.92674948, 0.92674448, 0.92673922, 0.92673375, 0.92672829, 0.92672287, 0.92671729, 0.92671144, 0.92670515, 0.92670037, 0.9266956, 0.9266888, 0.92668168, 0.92667323, 0.92666665, 0.92666105, 0.92665279, 0.92664626, 0.92663888, 0.92663016, 0.92662086, 0.92661089, 0.9266001, 0.92658832, 0.92657535, 0.92656091, 0.92654466, 0.92652616, 0.92650484, 0.92647999, 0.92645069, 0.92641577, 0.92637373, 0.92632266, 0.92626013, 0.92618306, 0.92608752, 0.92596852, 0.92581972, 0.92563309, 0.92539845, 0.92510291, 0.92473014, 0.92425951, 0.92366491, 0.92291337, 0.92196323, 0.92076189, 0.91924297, 0.91732274, 0.91489558, 0.91182839, 0.90795347, 0.90305973, 0.89688164, 0.88908574, 0.87925393, 0.86686358, 0.85126424, 0.83165196, 0.80704406, 0.77626142, 0.73793377, 0.69055942, 0.63268039, 0.56327591, 0.48250857, 0.39285097, 0.30012158, 0.21309309, 0.14045218, 0.086688654, 0.050828674, 0.028729114, 0.015849886, 0.00861729, 0.0046467978, 0.0024949216, 0.0013366319, 0.0007153302, 0.00038263615, 0.00020462933, 0.00010942248, 5.850937e-05, 3.1284829e-05, 1.6727594e-05, 8.9439202e-06, 4.7819894e-06, 2.5567432e-06, 1.3669313e-06, 7.308132e-07, 3.9068546e-07, 2.0884449e-07, 1.1162505e-07, 5.9670655e-08, 3.1888187e-08, 1.7047214e-08, 9.0987698e-09, 4.8644519e-09, 2.5910582e-09, 1.4090592e-09, 7.3607532e-10, 3.7363817e-10, 1.7609201e-10, 6.9859433e-11, 6.505581e-11, 1.1719474e-11, 4.888612e-11, 2.3601888e-12, 3.4779596e-11, 1.1009219e-11, 1.7066971e-11, 4.3198424e-11, 1.6923455e-11, 2.9291692e-11, 6.9220659e-12, 9.226979e-13, 1.9257449e-11, 2.1512192e-11, 2.9423553e-12, 1.0852717e-11, 3.749397e-13, 2.8956266e-11, 2.7232853e-11, 1.094118e-11, 2.3079547e-11, 3.5580423e-12, 8.7943225e-12, 3.5617162e-11, 3.3684635e-12, 1.2529068e-11, 1.9249346e-11, 3.1177378e-11, 1.2765265e-11, 2.028881e-11, 1.8367383e-12, 3.5656121e-11, 1.7748588e-11, 1.607812e-11, 1.6635646e-11, 2.148844e-11, 1.3817604e-11, 2.4028995e-11, 7.6920353e-12, 2.2070828e-11, 2.0256067e-11, 8.1556597e-12, 4.0443095e-12, 1.4599117e-11, 3.5777882e-11, 1.215202e-11, 3.2232604e-11, 1.05194e-11, 1.4869943e-12, 3.0990797e-12, 2.8712522e-11, 1.0117711e-11, 7.1187483e-12, 1.8899935e-11, 2.1021929e-11, 1.7956037e-11, 3.8355509e-11, 4.8117261e-12, 3.4119731e-13, 6.755352e-12, 2.2086811e-11, 1.8748094e-12, 2.1405527e-11, 2.1825197e-11, 1.3863227e-13, 8.1193644e-12, 6.0514244e-12, 1.3537343e-11, 2.5115964e-11, 1.3615816e-11, 3.6313542e-11, 3.1876534e-12, 5.0612307e-11, 1.4525195e-11, 4.9153061e-11, 5.0610199e-12, 3.5477641e-11, 2.0070373e-11, 1.2292317e-11, 2.257996e-11, 2.6219695e-11, 3.3177057e-11, 3.3918834e-11, 2.0201124e-11, 2.9929022e-11, 2.0404911e-11, 1.7744481e-11, 4.564097e-13, 3.0670022e-12, 6.1093637e-12, 4.9195239e-11, 5.3775764e-12, 3.2420629e-11, 3.2356918e-11, 1.1203127e-11, 2.1044239e-11, 7.0392762e-12, 1.0964045e-11, 2.4331011e-11, 1.1977203e-11, 2.7525213e-11, 2.2182711e-11, 3.4249153e-11, 2.6882887e-12, 3.8139957e-12, 1.3752339e-11, 2.0393922e-11, 1.8775732e-11, 1.6146492e-11, 8.4262645e-12, 2.6534919e-11, 1.1913936e-11, 3.2594002e-11, 1.6710789e-11, 2.4528359e-11, 1.5794528e-12, 3.0703987e-11, 1.9988459e-11, 4.2636903e-11, 2.9170263e-11, 1.5225348e-11, 2.5626762e-11, 4.4411928e-11, 1.589842e-11, 4.5259483e-11, 2.0439208e-11, 2.6341012e-11, 1.347341e-11, 2.1255684e-11, 1.0629729e-11, 3.9437928e-11, 2.9967427e-12, 3.1947237e-11, 6.9956554e-12, 6.1998242e-12, 2.0789284e-12, 2.0116436e-11, 4.647676e-12, 1.6522098e-11, 9.3896974e-12, 6.0516465e-12, 8.3840866e-12, 2.1797115e-11, 1.0969372e-11, 1.4066343e-12, 7.4723771e-12, 1.508716e-11, 2.572588e-11, 3.1789957e-11, 3.7379645e-12, 1.4661163e-11, 3.0160668e-11, 3.8229419e-11, 2.3631412e-11, 3.3269737e-11, 1.1988414e-11, 3.4363256e-11, 2.2416021e-11, 1.1728131e-11, 9.317551e-12, 9.889617e-12, 2.6019238e-11, 5.4338506e-12, 3.9482659e-11, 1.4534407e-11, 5.2454928e-11, 5.7924963e-11, 5.1665202e-11, 7.6479705e-11, 5.8635218e-11, 6.9449863e-11, 4.4034991e-11, 3.6424314e-11, 4.3910566e-11, 3.1681627e-11, 2.2541112e-11, 1.4644958e-11, 1.2643947e-11, 1.8225976e-11, 1.0744275e-11, 1.0612192e-11, 2.0740669e-11, 4.3798572e-11, 3.0136138e-11, 1.6759738e-11, 2.4857014e-11, 5.8160049e-12, 1.1487828e-11, 7.7568561e-12, 1.3198587e-11, 4.9671184e-12, 1.9774128e-11, 4.5795254e-12, 1.0955387e-11, 2.7193117e-11, 2.7553294e-12, 2.3722427e-11, 4.8546809e-12, 1.5726156e-11, 1.0720633e-11, 9.6529766e-12, 2.9908599e-12, 2.6848257e-11, 3.5884548e-13, 3.1516578e-11, 5.297738e-11, 3.3170952e-11, 4.9748325e-11, 1.0841063e-11, 5.7032789e-11, 4.068695e-11, 5.5832715e-11, 3.2919771e-11, 4.6057423e-11, 2.3108183e-11, 4.1595996e-11, 1.170904e-11, 1.0863594e-11, 1.5928055e-11, 2.1407081e-11, 1.4800017e-12, 2.8126359e-11, 4.7800593e-11, 5.4824441e-11, 2.0990407e-11, 5.1780192e-11, 1.1011772e-11, 2.5747635e-11, 1.1905057e-11, 1.7807748e-11, 3.2342156e-11, 9.8929469e-12, 1.1113443e-11, 6.7752201e-12, 1.8121308e-11, 6.0684066e-12, 3.6823562e-11, 3.2676027e-11, 3.8488147e-11, 4.7162818e-11, 2.817775e-11, 4.1453479e-11, 3.4595678e-11, 3.2416078e-11, 5.5118354e-11, 5.5519489e-12, 5.4331847e-11, 3.5331795e-12, 3.1377169e-11, 3.4956633e-12, 2.5582031e-11, 2.1050122e-11, 3.4838313e-11, 6.7041836e-12, 3.0708981e-11, 1.1507141e-11, 1.392205e-12, 2.4646346e-12, 2.9236638e-11, 1.18631e-12, 2.1137697e-11, 1.0209059e-11, 7.883501e-12, 6.1566473e-12, 4.3042588e-12, 3.0403524e-11, 2.3630743e-13, 2.2504595e-11, 1.8515117e-11, 1.5644797e-11, 3.6540082e-11, 3.5870451e-11, 3.4634194e-11, 1.2553487e-12, 2.1674356e-11, 2.6223579e-12, 2.6899536e-12, 1.6752412e-11, 1.2854726e-11, 2.237007e-11, 4.7813135e-12, 1.7285852e-11, 6.1368907e-13, 2.2063613e-11, 2.356861e-20];\nlet data3 = [6.9688318e-22, 1.644272e-11, 6.314786e-12, 3.2875102e-11, 9.8260368e-14, 2.3936075e-11, 2.694969e-11, 4.2087013e-11, 4.6329106e-11, 2.3309053e-11, 3.7687305e-11, 6.6659224e-12, 4.6838192e-12, 9.6655319e-12, 2.0671807e-11, 2.8959359e-11, 2.2623343e-11, 3.6969137e-11, 2.1388752e-11, 3.5699199e-11, 2.9340507e-11, 1.772255e-11, 8.2035196e-12, 1.8482512e-11, 2.4174501e-11, 1.7265261e-11, 2.2804302e-11, 3.1309939e-12, 6.693711e-12, 2.5666191e-11, 2.6720934e-11, 1.9686869e-11, 6.4094895e-12, 2.6156381e-11, 1.178002e-11, 2.1946524e-11, 1.5986765e-11, 4.5602823e-11, 4.2158819e-11, 5.0142253e-11, 3.0869434e-11, 2.972888e-11, 2.2426155e-11, 3.9049945e-11, 2.5087744e-11, 5.3440423e-11, 3.8887215e-11, 6.2241064e-11, 5.2624773e-11, 7.1175534e-11, 4.66878e-11, 4.4403358e-11, 4.6373456e-11, 4.1789009e-11, 4.2431703e-11, 3.5016267e-11, 4.5389963e-11, 4.1522905e-11, 5.6982577e-11, 4.5454432e-11, 6.0826959e-11, 2.1750226e-11, 2.9669301e-11, 1.1971094e-11, 3.0990037e-11, 1.1845156e-11, 2.3249141e-11, 7.7532336e-12, 1.9204681e-11, 3.0587436e-12, 1.4002994e-11, 2.5361628e-11, 9.4072093e-12, 1.9982205e-12, 5.6142917e-12, 8.5617698e-12, 2.0093693e-11, 1.1226582e-12, 1.1819035e-12, 1.1260151e-11, 7.7041034e-12, 6.2246287e-15, 1.140354e-11, 7.8352655e-13, 1.0221303e-11, 2.1752893e-12, 1.9166222e-11, 2.1780015e-11, 1.1090419e-11, 3.5089073e-11, 1.0938137e-11, 2.4513521e-11, 6.9846017e-12, 8.5136401e-12, 1.1986322e-11, 2.5332061e-12, 1.8469396e-12, 9.5819439e-12, 1.2684482e-11, 4.9295813e-12, 1.0067243e-11, 1.4625681e-11, 3.0977587e-12, 1.4397592e-11, 1.1447335e-11, 2.3799577e-11, 5.6455261e-12, 3.5564147e-11, 2.6856209e-11, 3.0241857e-11, 2.6844426e-11, 2.438536e-11, 1.8498852e-11, 1.5597614e-11, 1.3305279e-11, 8.4438352e-12, 1.2783854e-12, 1.7306833e-11, 2.4847206e-11, 9.7293345e-12, 2.3259701e-11, 6.1117071e-12, 2.1805469e-11, 4.1434982e-12, 2.0206737e-11, 1.071116e-11, 8.3765868e-12, 3.1402197e-12, 9.787357e-12, 1.4450279e-11, 1.1241922e-11, 1.0742283e-11, 4.307562e-12, 1.8921794e-12, 1.7633849e-11, 5.7883593e-12, 1.06129e-11, 8.7511769e-13, 1.374067e-11, 8.8962331e-12, 3.0052673e-11, 5.1190994e-12, 1.807691e-11, 2.3518579e-11, 2.1319836e-11, 4.4795191e-14, 1.0434831e-11, 8.6904865e-12, 2.1587385e-11, 4.3709199e-12, 2.9441991e-11, 1.0720275e-11, 7.4697902e-12, 1.0809754e-11, 1.4696486e-11, 1.8840651e-13, 1.442049e-11, 1.9502353e-11, 2.7316276e-11, 1.128316e-11, 9.0713011e-12, 1.2080803e-11, 3.0674025e-11, 3.5719429e-11, 1.915833e-11, 3.1539917e-11, 1.1264042e-11, 1.2411821e-11, 1.2584888e-12, 1.6417377e-11, 1.2998382e-12, 8.0154466e-12, 6.880339e-12, 2.9339062e-11, 2.0188063e-11, 2.6760505e-11, 3.110786e-11, 3.7842921e-11, 1.6658693e-11, 2.7987093e-11, 2.6125925e-11, 2.0261203e-11, 1.1568827e-11, 1.0462064e-11, 6.349355e-12, 1.5180229e-11, 2.04246e-12, 1.7739112e-12, 2.6350346e-11, 8.2377551e-12, 2.5672971e-11, 2.1312055e-11, 2.3692647e-11, 1.5997325e-12, 4.1161543e-12, 9.3535218e-12, 7.0731917e-12, 2.2783516e-11, 2.787416e-12, 1.0895343e-12, 1.0061575e-11, 5.620961e-12, 5.1491111e-12, 9.7073259e-12, 2.690156e-12, 7.136105e-12, 3.9105189e-12, 2.305262e-11, 9.1106498e-12, 1.7891949e-11, 1.515811e-11, 2.2325894e-11, 1.4907234e-11, 3.9668407e-11, 2.296881e-11, 2.0173391e-11, 2.3783237e-11, 1.961962e-11, 3.8646121e-12, 1.466025e-11, 1.2476068e-11, 4.1588375e-12, 1.4916349e-11, 7.0600755e-12, 1.0899789e-12, 1.9369746e-12, 8.2886638e-12, 1.4640909e-11, 6.0101121e-12, 1.5824368e-11, 6.2542069e-12, 3.9383074e-12, 4.4448375e-12, 1.3129099e-11, 5.8919551e-12, 2.6262423e-12, 9.3675273e-12, 7.495578e-12, 9.0743023e-12, 1.9489792e-12, 4.1585041e-12, 1.1289385e-11, 3.254264e-12, 2.727615e-11, 2.6855208e-11, 3.0241524e-11, 1.5608951e-11, 6.0245621e-13, 1.2463396e-11, 2.1251699e-11, 4.9694857e-12, 1.8488292e-11, 1.7308167e-11, 2.8451051e-12, 3.8551974e-11, 7.7724633e-12, 2.0788852e-11, 1.4494296e-11, 1.0015112e-11, 1.7135544e-12, 2.2126038e-11, 1.0695043e-11, 3.7801571e-11, 1.9514913e-11, 1.7230915e-11, 3.0993482e-11, 1.6909679e-11, 3.4409142e-11, 4.2537633e-12, 2.2227744e-11, 3.6879213e-11, 2.2517635e-11, 2.2170278e-11, 7.1939054e-13, 4.0701364e-12, 2.1823143e-11, 8.1009242e-12, 2.3839704e-11, 5.1708973e-12, 1.1727444e-11, 6.3424634e-12, 1.2382143e-11, 3.5569378e-14, 7.6585302e-12, 2.4730716e-12, 7.9594248e-12, 9.8192583e-12, 1.0134825e-11, 9.5584903e-12, 8.8383217e-12, 2.6082353e-12, 1.8433826e-11, 3.5326054e-11, 4.4339666e-11, 1.2091719e-10, 1.7084625e-10, 2.5967619e-10, 3.634545e-10, 5.5290375e-10, 7.9605286e-10, 1.1043283e-09, 1.5812387e-09, 2.2285323e-09, 3.1469275e-09, 4.4479603e-09, 6.2269566e-09, 8.6930763e-09, 1.2104844e-08, 1.6837257e-08, 2.3295801e-08, 3.2212568e-08, 4.4334733e-08, 6.0893725e-08, 8.337456e-08, 1.1391194e-07, 1.5513682e-07, 2.1066381e-07, 2.8526479e-07, 3.8513473e-07, 5.184716e-07, 6.9585825e-07, 9.3118369e-07, 1.2422554e-06, 1.6522398e-06, 2.1907008e-06, 2.8955934e-06, 3.8152406e-06, 5.0109495e-06, 6.5602045e-06, 8.560473e-06, 1.1133904e-05, 1.4432841e-05, 1.864643e-05, 2.4008378e-05, 3.0806173e-05, 3.939168e-05, 5.0193482e-05, 6.373087e-05, 8.0629924e-05, 0.00010164123, 0.00012766014, 0.00015974814, 0.00019915717, 0.00024735442, 0.00030604959, 0.00037722223, 0.00046314986, 0.0005664359, 0.00069003607, 0.00083728324, 0.0010119086, 0.0012180594, 0.0014603103, 0.0017436691, 0.0020735744, 0.0024558851, 0.0028968594, 0.0034031258, 0.003981642, 0.004639646, 0.0053845953, 0.0062241002, 0.0071658477, 0.0082175215, 0.0093867167, 0.010680855, 0.012107097, 0.013672263, 0.015382752, 0.017244475, 0.019262788, 0.021442444, 0.023787554, 0.026301551, 0.028987178, 0.031846482, 0.034880815, 0.038090856, 0.041476629, 0.045037541, 0.048772415, 0.052679542, 0.056756722, 0.061001318, 0.065410308, 0.069980336, 0.074707762, 0.079588712, 0.084619126, 0.089794796, 0.095111412, 0.1005646, 0.10614993, 0.11186299, 0.11769939, 0.12365474, 0.12972476, 0.13590521, 0.14219195, 0.14858094, 0.15506823, 0.16164999, 0.16832252, 0.1750822, 0.18192558, 0.18884927, 0.19585005, 0.20292479, 0.21007048, 0.21728423, 0.22456326, 0.23190489, 0.23930656, 0.2467658, 0.25428023, 0.2618476, 0.26946571, 0.27713249, 0.28484593, 0.2926041, 0.30040517, 0.30824737, 0.31612901, 0.32404845, 0.33200415, 0.33999461, 0.34801838, 0.3560741, 0.36416044, 0.37227612, 0.38041992, 0.38859065, 0.39678719, 0.40500842, 0.4132533, 0.42152079, 0.42980991, 0.4381197, 0.44644922, 0.45479757, 0.46316387, 0.47154727, 0.47994692, 0.48836204, 0.49679172, 0.50523546, 0.5136919, 0.52216136, 0.53064128, 0.53913374, 0.54763397, 0.55614653, 0.56466445, 0.57319362, 0.58172722, 0.59026928, 0.59881622, 0.60736834, 0.61592511, 0.62448513, 0.63304813, 0.64161313, 0.65017946, 0.65874591, 0.6673123, 0.67587697, 0.68443953, 0.69299866, 0.70155352, 0.71010264, 0.71864521, 0.72717945, 0.73570421, 0.74421761, 0.75271796, 0.76120312, 0.76967072, 0.77811816, 0.78654216, 0.79493922, 0.8033049, 0.81163417, 0.81992079, 0.82815731, 0.83633452, 0.84444109, 0.85246275, 0.86038162, 0.86817472, 0.8758128, 0.88325778, 0.89046056, 0.89735742, 0.90386671, 0.90988573, 0.91528921, 0.91993422, 0.92366278, 0.92634106, 0.92784161, 0.92829757, 0.9282984, 0.9282713, 0.92826961, 0.92826595, 0.92826551, 0.92826812, 0.92827398, 0.92827656, 0.92827988, 0.92828388, 0.92829462, 0.92829526, 0.928294, 0.92829365, 0.92829214, 0.92828957, 0.92828995, 0.92828473, 0.92825203, 0.92821711, 0.92810413, 0.92797596, 0.92781776, 0.92765406, 0.92748905, 0.92733948, 0.92722197, 0.92714752, 0.92712163, 0.92711871, 0.92711722, 0.92711593, 0.92711253, 0.92710873, 0.92709741, 0.92708225, 0.92705974, 0.92703606, 0.92701366, 0.9269948, 0.92697989, 0.92696832, 0.92695887, 0.92695033, 0.92694183, 0.92693296, 0.92692374, 0.92691443, 0.92690531, 0.92689663, 0.92688847, 0.92688082, 0.92687357, 0.92686657, 0.92685967, 0.92685275, 0.92684576, 0.92683874, 0.92683178, 0.92682498, 0.92681835, 0.92681197, 0.92680587, 0.92680037, 0.92679479, 0.9267895, 0.9267835, 0.92677779, 0.92677267, 0.92676776, 0.92676293, 0.92675801, 0.92675287, 0.92674735, 0.92674134, 0.92673479, 0.92672762, 0.92671977, 0.92671123, 0.92670216, 0.92669224, 0.92668065, 0.92666776, 0.92665596, 0.9266461, 0.92663748, 0.92662607, 0.9266169, 0.92660872, 0.9266022, 0.92659765, 0.9265949, 0.92659375, 0.92659388, 0.92659495, 0.92659702, 0.92659938, 0.926602, 0.92660442, 0.92660629, 0.92660738, 0.92660746, 0.92660629, 0.92660383, 0.9266003, 0.92659594, 0.92659129, 0.92658667, 0.92658204, 0.92657723, 0.92657201, 0.92656638, 0.92656039, 0.92655414, 0.92654714, 0.92653966, 0.92653448, 0.92652956, 0.92652316, 0.92651643, 0.92650962, 0.9265021, 0.92649434, 0.9264865, 0.92647784, 0.9264687, 0.92645885, 0.9264501, 0.9264418, 0.92643157, 0.92642051, 0.92640881, 0.92639628, 0.92638275, 0.92636804, 0.92635188, 0.92633396, 0.92631386, 0.92629103, 0.9262648, 0.92623425, 0.92619825, 0.92615529, 0.92610345, 0.92604026, 0.9259625, 0.92586606, 0.92574562, 0.92559432, 0.92540335, 0.92516138, 0.92485383, 0.92446195, 0.92396167, 0.92332208, 0.92250349, 0.92145494, 0.92011106, 0.91838798, 0.91617815, 0.91334364, 0.9097076, 0.90504345, 0.8990609, 0.89138843, 0.88155109, 0.86894299, 0.85279399, 0.83213126, 0.80573957, 0.77213127, 0.72955327, 0.67609096, 0.60999109, 0.53041726, 0.43882191, 0.34056529, 0.24517568, 0.1632928, 0.1014608, 0.059707787, 0.033806, 0.018665709, 0.010154046, 0.005479122, 0.0029441638, 0.0015787208, 0.00084568651, 0.00045280042, 0.00024238724, 0.00012973898, 6.9440429e-05, 3.7165985e-05, 1.9891759e-05, 1.064624e-05, 5.6978887e-06, 3.049471e-06, 1.6320517e-06, 8.7343127e-07, 4.6743332e-07, 2.5014952e-07, 1.3384814e-07, 7.1615183e-08, 3.8302331e-08, 2.0481096e-08, 1.0948229e-08, 5.8510068e-09, 3.1322059e-09, 1.6631885e-09, 8.57237e-10, 4.4180893e-10, 2.3606094e-10, 1.0653837e-10, 4.8445804e-11, 3.8261163e-11, 4.5305767e-12, 3.0781683e-11, 1.9434374e-11, 1.4308533e-11, 1.6763067e-11, 1.0900001e-11, 7.5461885e-12, 2.7021852e-11, 5.7774899e-12, 7.0599212e-12, 6.0658537e-12, 1.4065233e-11, 2.1357799e-11, 2.7991834e-11, 3.1688949e-13, 5.4280789e-12, 1.650667e-11, 4.0891069e-11, 5.6260599e-11, 3.8895053e-11, 2.5336844e-11, 3.9860262e-11, 1.6378804e-11, 1.7282189e-11, 1.3859227e-11, 1.4629087e-13, 8.4004028e-12, 2.5132947e-11, 2.0514684e-11, 5.5260427e-11, 5.613007e-11, 8.2709276e-11, 4.497345e-11, 5.2929541e-11, 5.7110263e-11, 6.9544209e-11, 7.4599235e-11, 3.1559311e-11, 6.120341e-11, 2.6694862e-11, 2.024641e-11, 1.515409e-11, 1.5751907e-11, 1.5740807e-11, 4.6726499e-12, 4.2641121e-11, 3.1802278e-11, 5.9698102e-11, 2.4635248e-12, 1.1014436e-11, 5.2965502e-12, 1.8254279e-11, 1.4623092e-11, 3.7850483e-11, 1.9546146e-12, 4.8512512e-11, 1.8027185e-11, 4.4816947e-11, 1.7458116e-11, 6.9470286e-11, 4.9698711e-11, 6.6345123e-11, 3.3800291e-11, 7.1974213e-11, 3.7158654e-11, 8.4838374e-11, 1.3432009e-11, 8.3507327e-11, 3.8679835e-11, 6.5401114e-11, 1.2362687e-11, 7.8441534e-11, 2.1142137e-11, 3.1710818e-11, 5.3928159e-11, 5.3182054e-11, 4.5290117e-11, 2.5674045e-11, 5.923259e-11, 4.5728657e-11, 5.7957485e-11, 2.930157e-11, 6.1021046e-11, 4.9183585e-11, 8.4027003e-11, 2.2707049e-11, 5.8156498e-11, 4.7588149e-11, 5.6304331e-11, 2.8830176e-11, 5.8142069e-11, 2.744907e-11, 2.3922773e-11, 5.1634678e-12, 3.7483424e-11, 2.7852314e-11, 1.821976e-12, 1.8758099e-14, 7.2568256e-12, 5.5144882e-11, 2.234554e-11, 3.6724e-11, 2.7349841e-11, 3.4800685e-11, 5.3074278e-12, 1.20751e-11, 1.5684422e-11, 3.8380594e-11, 2.5202207e-11, 5.6174357e-11, 1.8072359e-11, 2.6781216e-11, 1.4482462e-11, 8.3793138e-12, 1.3220897e-11, 1.6602569e-12, 3.0230928e-11, 3.3592287e-11, 5.5116578e-11, 6.3377683e-11, 7.4435962e-11, 5.0469568e-11, 4.3236495e-11, 3.3662436e-11, 1.3699395e-11, 5.1504926e-11, 4.373253e-11, 3.3496388e-11, 2.4427687e-11, 3.8436202e-11, 3.5448894e-11, 3.257369e-11, 2.7977294e-11, 2.8831508e-11, 1.2698557e-11, 2.5001751e-11, 1.3384836e-11, 1.971075e-11, 1.2994357e-11, 1.3088148e-11, 1.6582923e-11, 8.1139258e-12, 3.5938158e-11, 1.4750514e-11, 9.3928053e-12, 1.7985562e-12, 1.590963e-11, 4.7555628e-12, 3.5563773e-12, 1.7015469e-12, 8.9185254e-12, 1.5699961e-11, 5.2750174e-12, 1.1218555e-11, 1.7849038e-12, 1.03296e-11, 4.5309097e-12, 2.6763013e-11, 4.5335736e-12, 1.0454357e-11, 3.0471342e-11, 3.211051e-11, 6.2507818e-11, 2.9848218e-11, 6.2961897e-11, 7.356532e-11, 6.8332703e-11, 1.0839231e-10, 7.1992638e-11, 8.1141477e-11, 8.1786356e-11, 7.4219744e-11, 6.9918038e-11, 5.0034581e-11, 3.6349171e-11, 3.1050956e-11, 4.2421795e-11, 2.0902277e-11, 5.2895244e-11, 1.9525611e-11, 3.3844467e-12, 4.1533062e-11, 1.4276123e-12, 1.8104215e-11, 4.7198225e-12, 3.7571221e-11, 1.4317191e-11, 2.9038957e-11, 7.6348731e-12, 4.6844152e-12, 1.2681686e-11, 3.2787799e-12, 1.2783024e-11, 1.5131891e-12, 2.1837961e-11, 1.92186e-11, 2.6969464e-12, 3.3476409e-11, 1.9815418e-11, 4.5208647e-11, 3.9951056e-11, 5.1660762e-11, 2.2907727e-11, 9.1554989e-12, 1.1622131e-11, 7.3245325e-13, 1.5328351e-12, 1.4989152e-11, 1.7662567e-12, 4.8820966e-12, 4.0439765e-12, 5.3799072e-13, 8.3456824e-12, 1.4397107e-12, 1.3843466e-11, 1.4267576e-11, 2.6067188e-11, 7.6877066e-12, 1.781463e-12, 1.741505e-13, 7.2234163e-12, 5.1667977e-12, 9.0937859e-12, 1.0709645e-11, 1.1865432e-11, 3.2584679e-12, 2.2026874e-11, 3.0745489e-14, 2.639551e-11, 1.0207727e-11, 1.4503662e-12, 1.5962685e-11, 2.4756564e-11, 7.4725991e-12, 1.5719829e-11, 5.8238855e-13, 9.3606168e-12, 1.618523e-12, 3.9659917e-11, 1.3356755e-11, 3.2485339e-11, 4.5040491e-12, 9.7542039e-13, 1.4630528e-11, 2.525604e-11, 2.6123684e-11, 5.2356587e-11, 4.3091204e-11, 5.4287227e-11, 1.4033045e-11, 4.9993291e-11, 2.206439e-11, 5.5926728e-11, 3.1548655e-11, 4.8612296e-11, 4.2891746e-11, 3.7626385e-11, 6.0400808e-11, 4.8195178e-11, 4.3433289e-11, 4.8251453e-11, 4.4334343e-11, 3.9629061e-11, 5.6315542e-11, 5.0820089e-11, 2.6441018e-11, 7.3309811e-11, 2.3628415e-11, 2.9492814e-11, 2.7083565e-11, 4.0127648e-11, 2.8342355e-11, 5.2944525e-11, 4.2551659e-11, 3.3472302e-11, 3.773072e-11, 4.7997164e-11, 2.9040733e-11, 5.0418622e-11, 3.3453877e-11, 1.0104946e-12, 2.723363e-12, 4.1511973e-12, 1.8644792e-20];\nlet data5 = [8.8755469e-22, 1.8272653e-11, 1.0733613e-11, 2.7953635e-11, 4.0261304e-11, 4.0519627e-11, 2.6162828e-11, 1.8507411e-11, 3.7509347e-11, 1.2686038e-12, 4.4012317e-11, 1.0528311e-11, 3.9979306e-11, 7.1194322e-13, 3.1690309e-11, 1.1239254e-11, 2.5174778e-11, 9.4864624e-12, 3.0043224e-11, 7.6723133e-12, 4.0573981e-11, 8.6146793e-12, 1.1601506e-11, 9.6370764e-12, 2.5131094e-11, 1.7846932e-12, 8.4477253e-13, 1.0806197e-11, 3.1424205e-11, 1.6773181e-12, 4.5035937e-11, 1.64286e-13, 2.3256255e-11, 4.8283198e-12, 2.2983149e-11, 1.3398093e-11, 8.522977e-12, 1.1698655e-11, 8.3994846e-12, 1.9472119e-11, 9.1014239e-12, 1.4485737e-11, 2.5002155e-11, 2.4439826e-11, 1.9087858e-11, 1.7320616e-11, 1.3126209e-11, 1.3104534e-11, 1.6955919e-11, 1.3026837e-11, 4.9831132e-11, 2.7873382e-11, 2.1826589e-11, 1.7490015e-11, 1.2527421e-11, 1.3321285e-11, 8.621682e-12, 1.0819202e-11, 6.0263407e-12, 2.0526639e-11, 1.3794247e-11, 6.3775882e-12, 8.5345371e-12, 1.1445557e-12, 1.5747005e-11, 7.6131792e-12, 1.3336847e-11, 3.2547086e-12, 1.1789246e-11, 2.1615173e-11, 1.3106757e-11, 2.0772179e-11, 5.7986967e-12, 2.3010048e-11, 4.2337555e-12, 3.3382188e-11, 2.4994819e-11, 2.4757838e-11, 9.6001732e-12, 2.5441437e-11, 1.2652692e-11, 7.9859907e-12, 1.3192346e-11, 1.3035396e-11, 1.2489296e-12, 1.3751119e-11, 8.4677333e-13, 2.0941467e-13, 9.1730073e-12, 1.1213022e-11, 3.2567093e-12, 1.4686371e-11, 9.470345e-13, 8.1800661e-12, 9.6435234e-12, 8.1576129e-13, 8.6654768e-12, 7.5295912e-13, 2.0637238e-11, 8.718942e-12, 1.378202e-11, 1.1651748e-11, 7.9914372e-12, 2.2589885e-12, 4.1193777e-13, 3.5602716e-13, 2.0938799e-11, 2.5269481e-11, 1.4724497e-11, 2.2813083e-11, 2.8044115e-11, 3.1476003e-11, 5.1240791e-11, 3.116077e-11, 4.8701916e-11, 1.4031005e-12, 4.8881208e-11, 1.3291496e-11, 3.5871044e-11, 1.2820202e-11, 2.3258256e-11, 2.273772e-12, 2.8150934e-11, 1.1085417e-12, 1.6619122e-11, 4.5584372e-12, 4.3841473e-12, 2.1139322e-12, 3.0644124e-12, 1.1742783e-11, 4.1777338e-12, 1.7036172e-11, 5.4652338e-12, 3.793529e-11, 1.9054957e-11, 2.8574321e-11, 1.9084857e-11, 8.7654045e-12, 9.5515988e-12, 3.4541194e-12, 1.4369359e-11, 2.913465e-12, 1.5769125e-11, 2.4605112e-12, 1.4840209e-12, 2.4542532e-11, 7.2936106e-12, 2.9159214e-11, 3.3566371e-12, 1.9202681e-11, 1.3955643e-11, 1.1239477e-11, 2.3841371e-11, 1.4453503e-11, 1.159417e-11, 6.5890036e-12, 2.2701706e-11, 3.6958577e-11, 3.4684249e-11, 2.9639512e-11, 2.7414648e-11, 4.862233e-11, 2.9069958e-11, 3.5153987e-11, 3.4429039e-11, 2.6555981e-11, 4.0850644e-11, 3.0675804e-11, 5.1219449e-11, 4.77441e-12, 2.655398e-11, 3.1386969e-11, 3.4213511e-11, 3.624141e-11, 1.6622679e-11, 2.5780791e-11, 2.4026665e-11, 3.4672912e-11, 3.4961802e-11, 4.0297207e-11, 1.2481292e-11, 2.0136821e-11, 1.155471e-11, 6.5982295e-12, 1.4902899e-11, 5.9878813e-12, 8.4771815e-12, 3.4797627e-11, 1.4078135e-11, 1.2861551e-11, 1.4217078e-11, 2.1404981e-12, 1.2843099e-11, 6.4858527e-13, 1.2323787e-11, 1.2841877e-11, 3.1050505e-11, 4.7659733e-11, 1.9660414e-11, 5.4314429e-11, 2.442382e-11, 5.7484994e-11, 1.7082524e-11, 2.6238524e-11, 2.5719323e-11, 3.2529301e-12, 1.2547429e-11, 2.1220464e-12, 1.3222358e-11, 5.7659062e-12, 2.8632788e-11, 6.9821563e-12, 8.9501429e-12, 3.6701033e-11, 9.392537e-12, 2.6822418e-11, 2.0672807e-11, 3.2724488e-11, 2.9320499e-11, 1.7357964e-11, 2.0273208e-11, 5.9623159e-13, 3.8840641e-12, 1.1987434e-11, 1.1992325e-11, 1.167987e-11, 1.5016833e-11, 6.9690401e-12, 1.071016e-11, 5.2178044e-12, 1.2835207e-11, 3.3371851e-12, 1.4056015e-11, 1.9366189e-11, 1.4011331e-11, 2.3000156e-11, 5.0676683e-11, 3.700215e-12, 3.983914e-11, 2.8753501e-11, 4.2976137e-11, 3.1558369e-11, 4.0128364e-11, 2.7488788e-11, 4.5937731e-11, 3.1377521e-11, 3.7956298e-11, 2.371899e-11, 3.973121e-11, 1.0394926e-11, 2.6689255e-11, 1.6875999e-11, 2.4361129e-11, 5.4975797e-12, 3.1841145e-11, 1.5992656e-11, 1.7503243e-11, 1.3029505e-11, 1.2633018e-11, 1.9364521e-11, 9.046736e-12, 4.2479833e-12, 3.8152596e-12, 3.0043891e-12, 1.8084357e-11, 1.1009721e-11, 2.5575378e-11, 2.2657022e-11, 2.4589551e-11, 2.361206e-11, 2.7337952e-11, 2.7915287e-11, 7.6091777e-12, 8.3942603e-12, 2.236024e-11, 1.2721719e-11, 1.8846431e-11, 2.3197232e-11, 1.0804974e-11, 1.9368745e-11, 4.2606548e-12, 7.4951334e-13, 1.3374862e-11, 4.3480221e-12, 1.0584111e-11, 1.3272933e-12, 1.8003215e-11, 1.7960198e-11, 2.2397699e-11, 3.3285484e-11, 3.7689861e-11, 5.3303481e-11, 9.9480416e-11, 7.7390503e-11, 1.7477177e-10, 2.272775e-10, 3.0180055e-10, 4.3190998e-10, 6.1628025e-10, 8.5127097e-10, 1.2009967e-09, 1.6950411e-09, 2.3772034e-09, 3.3206575e-09, 4.6423437e-09, 6.4769579e-09, 9.0289383e-09, 1.2518788e-08, 1.7366293e-08, 2.3993656e-08, 3.3123488e-08, 4.5587198e-08, 6.2621576e-08, 8.5697329e-08, 1.1700797e-07, 1.5926845e-07, 2.1624124e-07, 2.9268777e-07, 3.9509373e-07, 5.31683e-07, 7.1341492e-07, 9.5435111e-07, 1.2728411e-06, 1.6923936e-06, 2.2433017e-06, 2.9642088e-06, 3.9044963e-06, 5.1265713e-06, 6.7095317e-06, 8.7526142e-06, 1.1380275e-05, 1.4747547e-05, 1.9046987e-05, 2.4516235e-05, 3.1447689e-05, 4.0198829e-05, 5.120511e-05, 6.499374e-05, 8.2200111e-05, 0.0001035856, 0.0001300579, 0.0001626927, 0.00020275786, 0.0002517386, 0.00031136464, 0.00038363743, 0.00047085867, 0.0005756576, 0.00070101771, 0.00085030094, 0.0010272691, 0.0012361002, 0.0014814008, 0.0017682101, 0.0021019974, 0.0024886507, 0.0029344562, 0.0034460673, 0.0040304647, 0.0046949055, 0.0054468639, 0.0062939633, 0.0072439014, 0.0083043699, 0.0094829708, 0.010787131, 0.012224019, 0.013800462, 0.015522872, 0.017397174, 0.019428746, 0.02162237, 0.023982191, 0.026511687, 0.029213656, 0.032090202, 0.03514275, 0.038372053, 0.041778217, 0.045360735, 0.04911852, 0.053049949, 0.057152909, 0.061424846, 0.06586281, 0.070463511, 0.075223362, 0.080138533, 0.085204989, 0.090418541, 0.09577488, 0.10126961, 0.1068983, 0.11265649, 0.11853973, 0.12454359, 0.13066372, 0.13689581, 0.14323565, 0.14967913, 0.15622222, 0.16286103, 0.16959178, 0.17641082, 0.1833146, 0.19029974, 0.19736295, 0.20450109, 0.21171115, 0.21899023, 0.22633556, 0.23374448, 0.24121448, 0.24874313, 0.25632813, 0.26396728, 0.27165847, 0.27939973, 0.28718915, 0.29502494, 0.30290538, 0.31082886, 0.31879385, 0.32679891, 0.33484267, 0.34292387, 0.35104133, 0.35919394, 0.36738069, 0.37560068, 0.3838531, 0.39213724, 0.40045251, 0.40879849, 0.41717482, 0.42558146, 0.43401829, 0.442486, 0.45098432, 0.45951561, 0.46807855, 0.47667818, 0.48531154, 0.49398337, 0.50269278, 0.51142777, 0.52019435, 0.52894898, 0.53767062, 0.54619037, 0.55499055, 0.56387567, 0.57088999, 0.58186201, 0.5861534, 0.60021703, 0.60134738, 0.61785314, 0.61911379, 0.63651665, 0.63678505, 0.65784138, 0.6578795, 0.68603009, 0.68845669, 0.71563473, 0.7134741, 0.71776554, 0.72108445, 0.72489199, 0.72923484, 0.73324986, 0.73173841, 0.73678235, 0.73840361, 0.74979991, 0.75581631, 0.77310827, 0.7704936, 0.78042619, 0.78220028, 0.7940975, 0.79340896, 0.80760385, 0.81136595, 0.80745767, 0.80743041, 0.80738714, 0.8133333, 0.81768179, 0.83020585, 0.83392377, 0.84706516, 0.84821172, 0.84909587, 0.85421756, 0.85347514, 0.86521386, 0.86563354, 0.88757134, 0.88371381, 0.89109113, 0.89310991, 0.89495336, 0.89530943, 0.90088965, 0.9056695, 0.90624354, 0.90462222, 0.90913183, 0.90974483, 0.91466033, 0.91320631, 0.91956892, 0.91835912, 0.92343729, 0.92382604, 0.92693279, 0.92690753, 0.92814953, 0.92854157, 0.92852411, 0.92780793, 0.92735543, 0.92691682, 0.92688725, 0.9267973, 0.92683193, 0.92684918, 0.92670024, 0.92654014, 0.92619538, 0.92608007, 0.92586642, 0.92592779, 0.92550746, 0.92549336, 0.92519671, 0.92510795, 0.92486953, 0.92480406, 0.92477448, 0.92478989, 0.92478722, 0.92486421, 0.92485254, 0.92500294, 0.92502212, 0.92520048, 0.92511055, 0.92517063, 0.92517352, 0.92527893, 0.92528055, 0.92535972, 0.92536251, 0.92539352, 0.92544885, 0.92554893, 0.92559441, 0.92564226, 0.92546138, 0.92548614, 0.92552699, 0.92546651, 0.92542342, 0.92534365, 0.92535393, 0.92537345, 0.92523031, 0.9252568, 0.92505143, 0.9249375, 0.92487305, 0.92485538, 0.92463872, 0.92422622, 0.92384466, 0.92351762, 0.92330762, 0.92339761, 0.92297597, 0.92342119, 0.92266706, 0.92357812, 0.92389217, 0.92388786, 0.92420779, 0.92468576, 0.92435758, 0.92440925, 0.92437358, 0.92438647, 0.92439618, 0.9243746, 0.92442331, 0.92447101, 0.92455341, 0.92467416, 0.92476762, 0.92486624, 0.92492277, 0.92502235, 0.92511518, 0.92534355, 0.92523595, 0.92525984, 0.92497355, 0.92495751, 0.92494348, 0.92493844, 0.92494037, 0.9249994, 0.92507841, 0.92526106, 0.92523889, 0.92552905, 0.92556646, 0.92580527, 0.92587979, 0.92601391, 0.9260997, 0.92623408, 0.92650175, 0.92670573, 0.92672, 0.9264975, 0.92642097, 0.92643383, 0.92653644, 0.92657195, 0.92656547, 0.92653991, 0.92654973, 0.92677317, 0.92675649, 0.92710071, 0.92713023, 0.92744911, 0.92763419, 0.92775855, 0.92771742, 0.92759541, 0.92761257, 0.92770025, 0.92775435, 0.92774143, 0.92765611, 0.92784568, 0.92794316, 0.92835903, 0.92857216, 0.92895711, 0.92898694, 0.92887355, 0.92885884, 0.92890899, 0.92882222, 0.92849467, 0.92815199, 0.92705378, 0.92504573, 0.92195214, 0.91754425, 0.91146947, 0.90331449, 0.89244729, 0.87812935, 0.85940026, 0.83510999, 0.80387083, 0.7640899, 0.7140365, 0.65203482, 0.57693332, 0.48907501, 0.39176494, 0.29237997, 0.20176242, 0.12922921, 0.077781305, 0.04470325, 0.024914804, 0.013636957, 0.0073884694, 0.0039820163, 0.0021403102, 0.0011488503, 0.0006162604, 0.00033046778, 0.0001771866, 9.4995694e-05, 5.0928843e-05, 2.7303412e-05, 1.4637492e-05, 7.8471456e-06, 4.2068227e-06, 2.2552263e-06, 1.2090172e-06, 6.4813081e-07, 3.4746604e-07, 1.8628374e-07, 9.9837153e-08, 5.3508618e-08, 2.8684448e-08, 1.5368512e-08, 8.2270942e-09, 4.4169899e-09, 2.3592016e-09, 1.2645366e-09, 6.5020614e-10, 3.5471392e-10, 1.6778529e-10, 1.0050526e-10, 5.1615698e-11, 1.0800772e-11, 1.7813076e-11, 4.995311e-11, 3.1669195e-11, 3.3961344e-11, 1.1708041e-11, 2.5872614e-11, 1.0639829e-11, 1.9704757e-11, 4.8069532e-12, 1.7319594e-11, 2.2914165e-11, 8.8837842e-12, 1.4515871e-12, 4.1505313e-12, 1.3497718e-11, 2.0270718e-11, 3.6340735e-12, 4.1322172e-12, 2.1671026e-11, 5.2655829e-12, 2.0408351e-11, 1.8707248e-11, 2.5831435e-11, 8.2879649e-13, 1.7264541e-11, 2.4574207e-13, 1.8723787e-11, 5.4721549e-11, 5.3244099e-12, 4.0799387e-12, 3.1560754e-11, 1.171348e-11, 1.5634696e-11, 1.064105e-12, 1.6620661e-11, 1.1558643e-11, 1.7717288e-11, 1.1078591e-11, 1.8877403e-11, 2.0996179e-11, 1.401018e-11, 1.9477884e-11, 1.7053762e-11, 2.1874811e-12, 2.624145e-11, 6.7389027e-11, 4.4233116e-11, 2.6371202e-11, 1.7523158e-11, 1.1761985e-11, 1.7927844e-11, 5.71389e-12, 1.9180751e-11, 1.1333324e-11, 1.6342287e-11, 1.9778013e-11, 1.501457e-11, 2.0305681e-11, 2.9919033e-11, 4.83337e-12, 3.7838718e-11, 4.8999667e-12, 4.1883472e-11, 2.0392146e-11, 3.8322654e-11, 6.206606e-11, 4.4075393e-11, 3.2064669e-11, 5.9149122e-11, 5.2948188e-11, 6.3164129e-11, 8.962113e-11, 4.4416146e-11, 1.0008559e-10, 3.4554944e-11, 7.4140605e-11, 1.188985e-11, 6.6591309e-11, 3.9916093e-11, 5.8978968e-11, 4.1150352e-11, 1.2497435e-11, 9.8640881e-13, 1.3660214e-11, 1.4786143e-11, 1.1291035e-11, 2.8940616e-11, 2.9410234e-12, 3.2128269e-11, 2.2550769e-11, 2.3148697e-11, 4.3842193e-11, 2.3608103e-11, 6.6996661e-11, 2.563664e-11, 8.4134335e-11, 2.7177578e-11, 8.6780779e-11, 7.6754528e-11, 9.3666772e-11, 7.6846209e-11, 4.7693483e-11, 3.9477664e-11, 3.5640137e-11, 3.4006408e-11, 1.3857673e-12, 2.7787826e-11, 1.7218922e-11, 8.4016237e-12, 1.8166372e-11, 2.496257e-11, 7.3955687e-13, 2.7269148e-11, 2.6721834e-11, 1.790276e-11, 1.3086927e-11, 4.7405896e-11, 4.2377064e-11, 1.2679133e-11, 4.8221706e-11, 5.814562e-12, 1.7775671e-11, 2.2400926e-12, 5.3610382e-13, 3.6900148e-12, 5.3574531e-11, 1.0308511e-11, 3.1199244e-11, 1.5624707e-11, 1.2150577e-12, 1.1282599e-11, 1.3037423e-12, 3.3328342e-12, 3.5065297e-11, 2.928148e-12, 1.0302739e-11, 1.7476874e-11, 2.517457e-11, 5.6404116e-12, 6.4988436e-11, 3.1622356e-11, 7.7872687e-11, 4.7857644e-11, 7.8295132e-11, 4.5235286e-11, 4.5798916e-11, 2.2290264e-11, 3.8032182e-11, 3.4512877e-11, 5.2836861e-11, 4.524805e-11, 7.8457073e-11, 3.9417283e-11, 6.1127601e-11, 4.0157173e-11, 3.5567658e-11, 2.9153947e-11, 1.1805273e-11, 2.9678064e-11, 5.7686103e-12, 5.7457454e-12, 3.2302197e-11, 4.9529666e-11, 4.6999878e-11, 5.174534e-11, 1.7997327e-11, 2.8981795e-11, 5.713224e-12, 7.3452883e-12, 1.7813853e-11, 8.047995e-12, 2.8741158e-11, 1.1843011e-11, 3.2613315e-11, 3.2346595e-11, 1.4849854e-11, 3.6456059e-11, 3.2138592e-11, 2.9605806e-11, 4.3727425e-12, 3.0369671e-11, 2.1015048e-11, 3.601652e-11, 1.1914491e-11, 1.3487728e-11, 3.9754928e-12, 1.0703429e-11, 7.4307541e-12, 4.1479785e-12, 1.0173985e-11, 2.0516016e-11, 1.3770764e-11, 1.0646267e-11, 1.7800534e-11, 3.2188317e-11, 3.6530203e-11, 6.5765398e-12, 2.0016763e-12, 1.8334085e-12, 1.0266888e-11, 1.4851519e-11, 2.2044189e-11, 6.0457638e-12, 2.5460048e-11, 1.4669155e-11, 2.4177394e-11, 5.8807037e-11, 6.2834032e-12, 6.6183848e-12, 1.6271806e-13, 1.8075134e-11, 2.2461973e-12, 5.3903408e-12, 1.6028505e-11, 4.0313232e-13, 3.2548272e-11, 4.1948181e-12, 1.1798724e-12, 6.5309211e-12, 6.6507952e-12, 8.8736836e-12, 1.6863184e-11, 1.6735319e-11, 1.9874467e-11, 1.2464469e-11, 2.6440019e-12, 9.8318998e-12, 2.0435212e-12, 1.1405914e-11, 1.9396969e-11, 1.3411475e-12, 8.558903e-12, 1.631254e-11, 8.5403669e-12, 4.0904832e-12, 8.2904072e-12, 1.7191951e-12, 5.3472749e-12, 2.5418536e-11, 1.5305265e-11, 7.2793575e-12, 5.020973e-11, 1.3790522e-11, 2.0260951e-12, 7.3462872e-12, 1.5602508e-12, 1.2291651e-11, 1.3710272e-11, 5.3200812e-12, 7.043827e-12, 8.1839633e-12, 3.117982e-11, 1.4296324e-11, 3.3934817e-11, 9.2874715e-12, 1.71975e-11, 1.5451111e-11, 2.1490771e-12, 1.0344473e-11, 4.5709788e-12, 6.2577634e-12, 2.0089797e-11, 4.5736648e-11, 3.6199883e-11, 2.7324757e-11, 5.4422973e-11, 3.1747225e-11, 3.6302997e-11, 4.2841466e-11, 5.7356338e-11, 5.2325509e-11, 5.2084095e-11, 3.44798e-11, 9.686164e-12, 1.4551611e-11, 4.7665845e-11, 4.0686173e-12, 1.1008331e-11, 2.4060184e-11, 1.879005e-11, 2.6862908e-11, 3.4303985e-12, 7.5572879e-12, 1.8099951e-20];\nlet data4 = [2.9640062e-21, 9.3329583e-12, 2.7505128e-12, 1.2046123e-11, 9.4759025e-13, 1.3365413e-11, 2.8670914e-11, 2.0633236e-11, 2.3636847e-11, 3.4316662e-12, 2.0934353e-11, 2.3455777e-12, 5.9056272e-12, 1.0987934e-11, 1.5653969e-11, 2.2826977e-11, 1.0468955e-11, 6.6778159e-12, 7.2381446e-12, 8.0519052e-12, 1.0072245e-11, 4.5852253e-12, 9.4651207e-12, 1.260145e-11, 3.3677525e-12, 6.1690628e-12, 4.4931896e-12, 2.3751447e-12, 7.724e-12, 1.3185121e-12, 1.6603671e-11, 1.4090473e-11, 8.0091108e-12, 2.9737105e-12, 4.5938954e-12, 1.2772628e-11, 2.4963029e-12, 4.7423975e-12, 1.1312616e-11, 1.2850213e-11, 1.2648024e-11, 1.9927407e-11, 5.9455315e-12, 1.6689038e-11, 2.1524916e-11, 3.2399806e-11, 1.0232752e-11, 7.1952391e-12, 6.7022699e-12, 1.3764457e-11, 1.1613733e-11, 1.7275043e-11, 1.6410819e-12, 2.666369e-12, 3.8416032e-12, 1.6578661e-12, 1.1866276e-11, 6.4615097e-12, 8.1140404e-12, 3.4703479e-12, 1.5422657e-12, 3.8004761e-12, 1.1784577e-12, 1.2324898e-11, 1.3230583e-11, 3.6088461e-12, 1.758383e-11, 1.4494518e-13, 1.2159945e-11, 1.0882004e-12, 1.4816533e-11, 8.6553618e-12, 1.9557374e-11, 2.2128373e-11, 3.168564e-12, 1.1052737e-11, 7.2584859e-12, 1.0890897e-12, 1.6109479e-11, 4.9710419e-12, 1.3393535e-11, 1.7507244e-11, 7.0728583e-12, 3.611725e-11, 7.3771987e-12, 1.8627457e-11, 2.3087856e-12, 2.7133872e-12, 4.2321994e-12, 2.7794684e-11, 6.4452812e-12, 2.5169665e-11, 8.9348037e-12, 1.2712715e-12, 1.5921295e-11, 1.0449725e-11, 6.3035594e-13, 1.2070577e-11, 1.1566381e-11, 3.5177663e-11, 1.4124486e-11, 4.1937956e-11, 1.7787131e-11, 4.9642726e-11, 2.4534752e-11, 3.7980641e-11, 3.7185554e-12, 2.2332341e-11, 4.5134197e-12, 2.1476786e-11, 1.8698596e-11, 1.5798803e-11, 3.1917953e-12, 1.737775e-11, 1.1408987e-11, 7.2948333e-12, 1.8829758e-11, 4.0927008e-12, 3.0558536e-11, 4.9908286e-14, 2.5212015e-11, 1.9438661e-11, 2.7429542e-12, 1.734985e-11, 1.2607119e-12, 1.4012776e-11, 2.0970145e-11, 3.2229629e-11, 2.7516688e-11, 3.1972752e-11, 3.8435373e-11, 1.5694985e-11, 2.1617841e-11, 3.5497899e-11, 2.7793128e-11, 3.0138373e-11, 1.1688318e-11, 4.4370122e-11, 3.9459771e-12, 2.8765617e-11, 5.9882147e-12, 1.1967093e-11, 1.1350186e-11, 2.7869714e-12, 3.1948409e-11, 1.1738559e-11, 3.4116584e-12, 1.1020503e-11, 1.8829537e-13, 1.7159998e-11, 2.3805913e-12, 8.3825892e-12, 7.3541897e-12, 1.4197737e-11, 6.3963733e-12, 1.9021833e-11, 1.0141939e-11, 3.5838587e-11, 1.2702378e-11, 6.4226057e-12, 1.1199794e-11, 1.5978428e-12, 1.847851e-11, 9.7903582e-12, 2.389328e-11, 1.1467788e-12, 1.2559545e-11, 8.4380551e-12, 5.9497553e-12, 8.2975561e-12, 1.7023279e-12, 6.496301e-12, 2.0455723e-12, 3.3916618e-11, 1.1009943e-11, 2.0572546e-11, 7.4501159e-12, 1.6909234e-11, 1.3017278e-12, 2.511242e-11, 1.2519307e-11, 1.3066964e-11, 9.6181802e-12, 2.9619282e-12, 8.4008185e-12, 6.7134964e-12, 6.4966344e-12, 3.0185057e-12, 9.5896135e-12, 5.3267356e-12, 2.0195844e-11, 5.2957235e-12, 1.6285881e-11, 4.8516622e-12, 1.6781518e-11, 4.7132751e-12, 1.7246921e-11, 3.1046836e-11, 3.3466221e-11, 4.5161096e-11, 2.7890166e-11, 4.8981358e-11, 1.9105087e-11, 3.9502787e-11, 4.4925449e-11, 1.3337403e-11, 2.8367462e-11, 3.8099576e-11, 3.391584e-11, 2.2406369e-11, 4.5648174e-11, 3.0683362e-11, 1.1119319e-11, 2.2178503e-11, 3.9817688e-11, 4.3980638e-11, 4.2083457e-11, 3.1904503e-11, 3.5951408e-11, 2.0441495e-11, 3.4121142e-11, 2.3310165e-11, 4.710474e-11, 6.8178703e-12, 1.8060793e-11, 4.0326774e-12, 2.5641959e-11, 9.9446403e-12, 1.5113203e-11, 3.1063176e-12, 1.5865162e-11, 2.2517079e-11, 1.3830149e-11, 1.5724997e-12, 1.6482735e-11, 6.9053487e-12, 2.8235633e-11, 5.6019536e-12, 9.9887685e-12, 1.6630682e-11, 1.2960591e-13, 3.5512682e-12, 1.0279659e-11, 1.9133098e-11, 1.8250644e-11, 2.2588773e-12, 2.7064401e-11, 1.0553543e-11, 1.6625013e-11, 2.5463223e-12, 1.8596112e-11, 4.1845142e-12, 1.1992991e-11, 2.5180225e-11, 1.9251144e-11, 7.6910983e-12, 2.1652188e-11, 2.3425098e-11, 6.2203049e-12, 9.2353648e-12, 5.592172e-12, 1.6659804e-11, 1.4916794e-11, 8.5797769e-12, 2.5034946e-11, 2.176701e-11, 1.3789356e-11, 1.8613452e-11, 6.2498719e-12, 3.7386743e-12, 1.1784355e-11, 5.3595261e-12, 1.5875055e-12, 2.5069737e-11, 1.8245976e-12, 1.5287716e-11, 1.2674923e-12, 1.5658749e-11, 4.4738488e-12, 1.0064131e-11, 2.1842484e-11, 1.1868499e-11, 3.7473221e-11, 5.8434918e-12, 1.7942524e-11, 5.2399241e-12, 2.1522137e-11, 2.8356569e-12, 1.2945806e-11, 7.3661946e-13, 2.1775121e-13, 2.5093969e-11, 2.5642182e-11, 5.9632939e-11, 9.0133341e-11, 1.6135389e-10, 2.3653087e-10, 3.4442833e-10, 5.2040302e-10, 7.5668623e-10, 1.0945064e-09, 1.5515373e-09, 2.1963396e-09, 3.1317283e-09, 4.3789956e-09, 6.1486076e-09, 8.5833479e-09, 1.19644e-08, 1.6609804e-08, 2.3053427e-08, 3.1830126e-08, 4.3877079e-08, 6.0203165e-08, 8.2486321e-08, 1.1266521e-07, 1.5346586e-07, 2.0842465e-07, 2.8222683e-07, 3.8105991e-07, 5.1301255e-07, 6.8860458e-07, 9.2150284e-07, 1.2294442e-06, 1.6352882e-06, 2.1683996e-06, 2.8662775e-06, 3.7768487e-06, 4.960847e-06, 6.4950875e-06, 8.4761234e-06, 1.1025082e-05, 1.4292922e-05, 1.8467174e-05, 2.3779574e-05, 3.0515209e-05, 3.9023052e-05, 4.9728285e-05, 6.3146081e-05, 7.9897671e-05, 0.00010072802, 0.00012652577, 0.00015834491, 0.0001974285, 0.00024523382, 0.00030345928, 0.00037407188, 0.00045933524, 0.00056183756, 0.00068451808, 0.00083069205, 0.0010040722, 0.0012087865, 0.0014493903, 0.0017308722, 0.0020586523, 0.0024385723, 0.0028768758, 0.0033801792, 0.0039554328, 0.0046098717, 0.0053509572, 0.0061863106, 0.0071236385, 0.0081706536, 0.0093349915, 0.010624125, 0.012045281, 0.013605355, 0.01531084, 0.01716775, 0.019181563, 0.021357164, 0.023698808, 0.026210085, 0.028893907, 0.031752493, 0.03478738, 0.037999428, 0.041388851, 0.044955238, 0.048697596, 0.052614388, 0.056703578, 0.060962683, 0.065388817, 0.069978743, 0.074728923, 0.079635565, 0.084694668, 0.08990207, 0.095253481, 0.10074453, 0.10637077, 0.11212778, 0.11801109, 0.12401628, 0.13013899, 0.13637492, 0.14271983, 0.1491696, 0.15572022, 0.16236776, 0.16910843, 0.17593856, 0.18285462, 0.18985317, 0.19693094, 0.20408476, 0.2113116, 0.21860854, 0.2259728, 0.23340171, 0.24089272, 0.24844338, 0.25605136, 0.26371444, 0.27143049, 0.27919747, 0.28701346, 0.2948766, 0.30278512, 0.31073734, 0.31873165, 0.32676651, 0.33484045, 0.34295207, 0.35110001, 0.35928299, 0.36749977, 0.37574917, 0.38403004, 0.39234128, 0.40068184, 0.4090507, 0.41744686, 0.42586937, 0.43431733, 0.44278987, 0.4512863, 0.45980599, 0.46834908, 0.47691568, 0.48550833, 0.49412819, 0.50277771, 0.51145706, 0.52012893, 0.52870413, 0.53745872, 0.54569641, 0.55388735, 0.56171361, 0.5703083, 0.57884008, 0.58839631, 0.5996874, 0.61464584, 0.63299906, 0.65300355, 0.66843974, 0.67260683, 0.67187109, 0.67378822, 0.67461145, 0.68013213, 0.68891798, 0.69906228, 0.71024186, 0.72634787, 0.72348441, 0.72350901, 0.72400258, 0.72931793, 0.73820286, 0.73928349, 0.74211056, 0.74537831, 0.74721972, 0.75008908, 0.75974998, 0.77083627, 0.77855188, 0.78093807, 0.77979187, 0.78006009, 0.78150724, 0.78188001, 0.78078482, 0.78972435, 0.80253125, 0.81073706, 0.81642665, 0.82116291, 0.82579555, 0.83115008, 0.83771477, 0.84467652, 0.85217798, 0.85965702, 0.86636392, 0.87269061, 0.87912294, 0.8857938, 0.89319124, 0.90139898, 0.90847588, 0.91591374, 0.92256061, 0.92905685, 0.93537009, 0.94484613, 0.95172695, 0.96261748, 0.96689615, 0.97052233, 0.96835432, 0.96371894, 0.95353748, 0.94646765, 0.93869513, 0.93300715, 0.92707869, 0.92303702, 0.91664736, 0.91744421, 0.91719413, 0.91974339, 0.92136019, 0.92451412, 0.92669603, 0.92989174, 0.93016046, 0.93012549, 0.93004485, 0.92979559, 0.92964667, 0.92934676, 0.92917201, 0.92833142, 0.92825144, 0.92832679, 0.92894541, 0.928823, 0.9286215, 0.92814636, 0.92772128, 0.92714753, 0.92684216, 0.92646554, 0.92618261, 0.92590351, 0.92572693, 0.92561247, 0.925564, 0.92557124, 0.92559663, 0.92590674, 0.92589498, 0.9258723, 0.92548199, 0.92527586, 0.92514624, 0.92517072, 0.92519455, 0.92517294, 0.92511427, 0.92507073, 0.92508099, 0.9251498, 0.92523651, 0.92531842, 0.92532105, 0.92534056, 0.92546288, 0.92567932, 0.92587718, 0.92603413, 0.92630519, 0.92622569, 0.92618911, 0.9260881, 0.92611963, 0.92617353, 0.92629568, 0.92638431, 0.92644902, 0.92639186, 0.92632513, 0.92625433, 0.92626243, 0.92623303, 0.92622917, 0.92625492, 0.92623275, 0.92630611, 0.92630213, 0.92631903, 0.92629826, 0.92631528, 0.92630902, 0.92627638, 0.92626638, 0.92621553, 0.92630114, 0.92641228, 0.92647963, 0.92653698, 0.92665872, 0.92689599, 0.92705079, 0.92742487, 0.92732687, 0.9273452, 0.9272198, 0.92721382, 0.92703998, 0.92694653, 0.92701832, 0.92741031, 0.92757705, 0.92722499, 0.9266838, 0.92646418, 0.9263108, 0.92630487, 0.92665255, 0.92756567, 0.92795025, 0.92775351, 0.92732948, 0.92723394, 0.92680679, 0.92634006, 0.92634952, 0.92671698, 0.92693975, 0.92722617, 0.92694944, 0.9269312, 0.92720149, 0.92852329, 0.93030914, 0.93027955, 0.92985191, 0.92960996, 0.92935124, 0.92847124, 0.92810666, 0.92809806, 0.92914492, 0.93069296, 0.93146786, 0.93042349, 0.93049376, 0.93052707, 0.93109751, 0.93098899, 0.93069666, 0.93047184, 0.9297293, 0.92802123, 0.92532139, 0.92149254, 0.91629255, 0.90932378, 0.90007065, 0.88787749, 0.87192529, 0.85120664, 0.82450355, 0.79038292, 0.747226, 0.69333741, 0.6272038, 0.5481055, 0.45723604, 0.35909776, 0.26221379, 0.1771453, 0.11142655, 0.066168553, 0.037697689, 0.020907893, 0.011417705, 0.0061818558, 0.0033325675, 0.0017925853, 0.00096317242, 0.00051724591, 0.00027770297, 0.00014907787, 8.0024386e-05, 4.2955751e-05, 2.3057529e-05, 1.2376637e-05, 6.6433276e-06, 3.5659077e-06, 1.9140184e-06, 1.0273475e-06, 5.5140358e-07, 2.9595236e-07, 1.5884068e-07, 8.5240279e-08, 4.5735953e-08, 2.4536113e-08, 1.3110006e-08, 7.0446593e-09, 3.7344034e-09, 2.0400243e-09, 1.0665481e-09, 5.4378742e-10, 2.7004349e-10, 1.5812854e-10, 7.4338287e-11, 3.3561209e-11, 2.8333919e-11, 8.868467e-13, 3.0858713e-12, 3.5963354e-12, 3.4917785e-12, 1.017121e-11, 2.2028983e-11, 4.0346086e-11, 1.7580209e-11, 4.2501933e-11, 1.4422969e-11, 1.8196895e-11, 4.8419165e-12, 1.6136947e-11, 1.9557134e-11, 1.3521138e-11, 2.5140272e-11, 2.0023977e-11, 3.3199034e-11, 4.6221473e-11, 6.582134e-11, 1.3640679e-11, 1.8451073e-11, 2.6909526e-12, 2.8481986e-11, 3.7241345e-11, 2.7911807e-11, 3.1812378e-11, 2.4314584e-11, 3.0230262e-11, 8.3786478e-12, 3.2504762e-12, 2.3156355e-11, 2.5427859e-11, 1.8178248e-11, 2.6479089e-11, 2.9286697e-11, 6.2549886e-12, 2.2235655e-11, 9.7529828e-12, 8.7256168e-12, 2.3332615e-11, 7.4472923e-12, 3.7661016e-11, 3.9459128e-11, 4.3172452e-11, 4.6146551e-11, 7.0674356e-11, 3.8188906e-11, 2.234998e-11, 1.691735e-11, 2.136912e-11, 1.0642604e-11, 2.3709996e-11, 1.7593085e-11, 4.2050074e-11, 5.7920745e-11, 2.3162904e-11, 2.0006773e-11, 4.6649913e-12, 2.0054834e-11, 3.429455e-11, 4.7810915e-12, 1.6627987e-11, 3.419521e-12, 3.9087851e-12, 2.5789369e-11, 8.5253827e-12, 4.5741865e-11, 3.9988016e-12, 4.2880647e-11, 4.4876219e-12, 5.7759137e-11, 1.0324161e-11, 4.5343838e-11, 1.571317e-11, 4.2209574e-11, 3.6910248e-11, 4.0849557e-11, 1.7327808e-11, 6.036085e-11, 3.0158338e-12, 6.5229405e-11, 2.2726917e-11, 1.035959e-10, 1.3112123e-11, 7.8468617e-11, 2.6461552e-11, 9.2848187e-11, 4.8677117e-11, 7.3172067e-11, 3.0248465e-11, 2.8176973e-11, 3.4641409e-13, 4.5031611e-12, 1.198919e-11, 5.4409543e-12, 2.3406093e-11, 3.6406222e-12, 5.9825856e-11, 5.5350777e-11, 6.1321841e-11, 7.566667e-11, 4.7177247e-11, 1.7426815e-11, 3.9422611e-11, 3.2878814e-12, 1.7982232e-12, 2.9966761e-11, 1.5093043e-12, 3.8254837e-11, 6.3659832e-12, 5.8671402e-11, 3.0131144e-11, 3.1009222e-11, 2.9751986e-11, 2.6061527e-12, 1.7776004e-11, 1.8748538e-11, 2.6435912e-11, 8.2280281e-13, 3.9124035e-11, 2.5456274e-11, 6.8715634e-12, 3.539384e-11, 5.4937877e-12, 4.8476439e-11, 3.7622612e-11, 1.7812965e-11, 3.2490666e-11, 1.3793518e-11, 3.0020593e-11, 1.0668244e-11, 3.3360087e-11, 6.4262532e-12, 3.2945411e-11, 5.8499693e-12, 1.1105896e-11, 1.2388216e-11, 1.3703169e-11, 1.0369113e-12, 5.5859132e-12, 1.8173365e-11, 1.6084224e-12, 2.9652202e-11, 1.3880982e-12, 3.0761038e-12, 2.2155628e-12, 1.2362909e-11, 8.4855356e-12, 2.2690733e-11, 1.6411326e-11, 1.5741251e-11, 3.9831626e-11, 9.5729495e-12, 1.8957319e-11, 7.9878359e-12, 7.3632694e-12, 1.4530301e-12, 2.3316964e-11, 1.4322851e-11, 1.6770726e-11, 2.1865821e-11, 3.0555143e-11, 2.9852991e-11, 1.0491763e-11, 3.8597699e-11, 1.0835291e-12, 5.5185839e-11, 7.7102384e-12, 4.2228443e-11, 2.6358549e-11, 7.4350274e-11, 3.3509153e-11, 7.2135821e-11, 3.9783121e-11, 7.1883087e-11, 6.8346466e-11, 1.0074878e-10, 4.945419e-11, 7.1265513e-11, 4.4255093e-11, 4.7498021e-11, 2.0786621e-11, 2.3789135e-11, 1.531259e-11, 4.4703844e-11, 2.086687e-11, 1.5181173e-11, 3.7472991e-11, 5.671046e-12, 1.4036486e-11, 2.6176185e-11, 3.2143364e-11, 2.0150622e-11, 1.6476923e-11, 5.9871808e-11, 4.4838036e-11, 8.377327e-11, 4.2277835e-11, 6.7988065e-11, 2.0570736e-11, 5.2125163e-11, 7.5326471e-12, 4.0375055e-11, 5.1529011e-11, 5.4923447e-12, 5.0088968e-11, 8.3812007e-12, 5.7186738e-11, 4.427485e-11, 4.3078328e-11, 4.2777533e-11, 6.7281806e-11, 2.7674279e-11, 6.5181123e-11, 2.0746774e-11, 4.5545405e-11, 1.2051347e-11, 4.6774892e-11, 3.5612056e-11, 1.0890677e-11, 3.2721868e-11, 2.6763013e-12, 2.1213284e-11, 2.694682e-11, 4.6181182e-11, 3.9528389e-11, 5.5938493e-11, 7.7387863e-11, 4.8343023e-11, 4.6970464e-11, 3.0434492e-11, 2.6478534e-11, 3.7708521e-11, 7.0224384e-11, 5.3415919e-11, 7.0918877e-11, 3.5120794e-11, 4.0638334e-11, 3.359029e-11, 1.6493795e-11, 1.6370813e-11, 1.2935419e-11, 8.2199256e-12, 5.8821577e-12, 2.9659417e-11, 1.4651276e-14, 3.7516168e-12, 2.661539e-12, 1.2588561e-11, 4.1916659e-11, 6.7540424e-11, 2.2157182e-11, 6.5171355e-11, 2.284557e-11, 5.3456321e-11, 6.3659832e-12, 2.8300288e-11, 3.3745682e-12, 3.498305e-11, 6.4931823e-14, 5.2362803e-12, 5.407445e-11, 7.3582746e-12, 3.4267578e-11, 1.3745568e-12, 4.2672865e-11, 1.9696543e-11, 4.5940767e-11, 3.1288928e-11, 1.7027012e-11, 1.6064467e-11, 2.6515051e-11, 1.1543436e-13, 2.1729409e-12, 2.676046e-11, 1.3155522e-11, 7.0774583e-12, 3.9662803e-12, 2.8672231e-11, 1.7701194e-11, 2.2506038e-11, 1.5213916e-11, 2.1611318e-20];\nlet data7 = [2.8477683e-20, 1.9817254e-11, 2.1635317e-10, 1.809108e-10, 3.3037479e-10, 3.1952347e-10, 8.4635997e-11, 6.7923694e-11, 8.1165126e-11, 3.8541257e-11, 2.1220779e-10, 8.8978506e-11, 1.5024543e-10, 1.0109516e-10, 1.1924985e-10, 1.5972819e-10, 1.3589799e-10, 5.5968904e-11, 5.9218579e-11, 1.4418632e-10, 6.8115023e-11, 1.4655948e-10, 2.5399996e-11, 2.3202602e-10, 1.9469538e-11, 2.6029821e-10, 2.6356826e-10, 2.0576201e-10, 2.9054878e-10, 9.7460678e-11, 5.1290831e-10, 2.0877626e-10, 4.8137136e-10, 2.3414674e-10, 4.9323768e-10, 1.7236458e-10, 2.7703685e-10, 2.1815489e-10, 2.2927159e-10, 2.9775453e-10, 3.7796739e-10, 4.2749079e-10, 3.3366027e-10, 3.1802514e-10, 2.4735136e-10, 3.6288265e-10, 3.0970653e-10, 3.5424183e-10, 2.1602941e-10, 2.4179075e-10, 2.952367e-10, 3.8359151e-10, 4.9834974e-10, 4.3116471e-10, 3.7808902e-10, 3.6538443e-10, 5.1141341e-10, 5.2062858e-10, 5.2599717e-10, 5.2491092e-10, 4.512288e-10, 4.7755334e-10, 3.6242088e-10, 3.3089726e-10, 3.088043e-10, 2.425945e-10, 3.1302036e-10, 1.9574006e-10, 3.6476364e-10, 1.7781339e-10, 3.4295644e-10, 1.4802614e-10, 2.1914047e-10, 1.0554173e-10, 2.5820686e-10, 1.8239021e-10, 2.0159706e-10, 2.0936174e-11, 2.02232e-10, 7.9556056e-11, 2.7654249e-10, 1.1959572e-10, 2.5486029e-10, 7.5607268e-12, 1.6671328e-10, 1.8532479e-10, 1.6790936e-10, 2.5386076e-10, 1.3592029e-10, 1.90552e-10, 1.312331e-10, 2.3270266e-10, 5.3277926e-11, 8.607033e-11, 5.2760181e-11, 2.2919825e-11, 1.2535519e-10, 1.6959737e-10, 1.049109e-10, 2.782024e-11, 6.1551883e-11, 4.8213281e-11, 1.0873528e-10, 8.0136791e-11, 1.4437715e-10, 1.7885345e-11, 2.2846276e-10, 2.3411295e-11, 3.2771467e-10, 1.1241968e-10, 3.5625737e-10, 8.5255682e-11, 2.3003975e-10, 7.3182836e-11, 8.2392924e-11, 8.2526453e-11, 2.8599207e-11, 3.3357279e-11, 3.2393904e-11, 6.0353097e-11, 1.6471975e-11, 2.7220928e-11, 6.7487991e-11, 3.4596827e-11, 1.4466908e-10, 1.0913542e-10, 3.886743e-11, 1.7155191e-10, 1.9649472e-10, 3.0039176e-10, 2.1706912e-10, 1.7937359e-10, 5.2531302e-12, 7.9055027e-12, 1.5239417e-10, 6.7756783e-11, 1.0415159e-10, 2.3479438e-10, 7.9120719e-11, 1.484773e-10, 7.5912829e-11, 1.993482e-11, 2.4164178e-10, 2.9148732e-11, 1.3744549e-11, 2.2941906e-10, 2.774089e-10, 2.1098422e-10, 1.3233328e-10, 1.5952605e-10, 1.9464789e-10, 4.7715155e-11, 1.5999093e-10, 7.649121e-11, 2.1009985e-10, 1.452682e-10, 2.0044788e-10, 7.6618975e-12, 3.6200604e-11, 1.8525448e-10, 9.7877338e-11, 2.8069348e-12, 2.0239038e-11, 1.9796622e-11, 1.3152776e-11, 1.9356596e-10, 2.6752626e-11, 2.3772909e-10, 1.430706e-11, 3.2829193e-10, 3.419622e-11, 4.3060049e-10, 1.0813806e-10, 3.7939735e-10, 9.8199581e-11, 3.2751842e-10, 6.5516255e-11, 6.6882809e-11, 1.0962431e-10, 2.4312811e-10, 3.511733e-10, 1.8942962e-10, 2.2945665e-10, 1.4616836e-10, 4.5135341e-11, 9.7068791e-11, 3.8640586e-11, 1.2930635e-10, 8.1348505e-11, 9.5416082e-11, 1.8570819e-10, 1.1855809e-10, 1.9283651e-10, 1.0581354e-10, 1.0844812e-10, 9.5097879e-11, 1.3290397e-10, 3.5893166e-10, 2.5249281e-11, 5.4991348e-10, 9.0886239e-11, 4.3684268e-10, 1.4355966e-10, 5.3188724e-10, 1.2617057e-10, 3.7926679e-10, 1.3789329e-10, 1.6742864e-10, 4.1086368e-11, 7.0177179e-11, 1.2346572e-11, 5.9132882e-14, 7.8648206e-13, 7.0490142e-12, 3.6924912e-12, 5.6042079e-11, 7.2597309e-11, 2.0615028e-10, 2.7642091e-10, 2.6228259e-10, 9.9983201e-11, 2.1552475e-12, 4.8360516e-11, 2.0368089e-11, 8.7008727e-11, 3.7743871e-11, 1.0942598e-10, 1.6518165e-10, 1.242478e-10, 1.4404817e-10, 1.6390056e-10, 3.4234109e-10, 1.440687e-10, 2.7340136e-10, 5.2112998e-11, 1.0796456e-10, 4.6046917e-11, 1.6697214e-10, 6.8456262e-12, 1.0125462e-10, 4.7842905e-11, 2.1396614e-10, 3.5911615e-11, 2.9679157e-10, 1.3415511e-10, 2.7936568e-10, 2.1178514e-10, 4.3080251e-10, 4.2927147e-10, 5.0658213e-10, 4.6356507e-10, 6.5276704e-10, 4.8260318e-10, 6.6818873e-10, 5.6053824e-10, 5.2016442e-10, 5.9334532e-10, 5.4408245e-10, 5.1616447e-10, 4.7639677e-10, 5.8710287e-10, 5.7388639e-10, 5.4723248e-10, 5.8585824e-10, 6.392226e-10, 7.1603609e-10, 6.2675589e-10, 7.8034298e-10, 6.5468454e-10, 7.7678248e-10, 5.9770753e-10, 7.3561387e-10, 5.091355e-10, 5.7069555e-10, 4.4704192e-10, 4.5896522e-10, 5.2184403e-10, 6.2306429e-10, 5.872771e-10, 6.9971574e-10, 6.8471009e-10, 6.7302519e-10, 4.6299314e-10, 6.3234335e-10, 4.7836513e-10, 7.4206463e-10, 5.6813867e-10, 8.0981043e-10, 6.6875664e-10, 7.3005264e-10, 7.0932665e-10, 6.8507835e-10, 6.2430738e-10, 6.9547164e-10, 6.5583485e-10, 5.1924179e-10, 7.0097115e-10, 5.2655282e-10, 6.563908e-10, 5.5960659e-10, 6.619308e-10, 4.9482656e-10, 5.3791057e-10, 4.4873093e-10, 4.3237599e-10, 3.2823616e-10, 4.3226711e-10, 2.2101743e-10, 2.6649277e-10, 1.6903861e-10, 2.1312479e-10, 1.7537258e-10, 1.7326172e-10, 5.3140063e-11, 1.7270464e-11, 2.6298704e-11, 1.2999494e-11, 1.1822559e-11, 1.4736385e-10, 1.4860663e-10, 1.1970659e-10, 4.6003957e-11, 1.29762e-10, 1.6484604e-10, 2.2191799e-10, 7.8584122e-11, 1.1429746e-10, 2.6841091e-11, 1.3831702e-10, 2.2084829e-10, 1.6325195e-10, 2.4149503e-10, 6.1705914e-11, 3.6353002e-10, 9.8185172e-11, 3.4585628e-10, 6.2212222e-12, 1.398224e-10, 6.0760331e-12, 1.6543115e-10, 4.8727664e-11, 3.6482602e-10, 2.8267297e-10, 4.6532468e-10, 1.9670647e-10, 4.4901017e-10, 1.2678165e-10, 4.1018904e-10, 1.8250552e-09, 4.1534681e-09, 9.4402826e-09, 1.9585692e-08, 4.0855308e-08, 8.2272735e-08, 1.637779e-07, 3.2005018e-07, 6.1731524e-07, 1.1731282e-06, 2.1975343e-06, 4.0552083e-06, 7.3716991e-06, 1.3194619e-05, 2.3245815e-05, 4.0291446e-05, 6.867536e-05, 0.00011505047, 0.00018933885, 0.00030591933, 0.00048498838, 0.00075396411, 0.0011487021, 0.0017141973, 0.0025043679, 0.0035805309, 0.0050081363, 0.006852056, 0.0091706344, 0.012009175, 0.01539368, 0.019325493, 0.023778893, 0.028706448, 0.03405052, 0.039752921, 0.045760023, 0.052024883, 0.058507644, 0.065175076, 0.071999732, 0.078959028, 0.086034375, 0.093210427, 0.10047445, 0.10781579, 0.11522552, 0.12269605, 0.1302209, 0.13779453, 0.1454121, 0.15306944, 0.16076286, 0.16848914, 0.1762454, 0.18402908, 0.19183791, 0.19966982, 0.20752299, 0.21539573, 0.22328651, 0.23119396, 0.23911681, 0.24705388, 0.25500412, 0.26296652, 0.27094019, 0.27892425, 0.28691792, 0.29492045, 0.30293117, 0.31094941, 0.31897457, 0.32700609, 0.33504346, 0.34308619, 0.35113386, 0.35918609, 0.36724252, 0.37530278, 0.3833665, 0.39143312, 0.39950231, 0.40757347, 0.41564732, 0.42372248, 0.43180034, 0.43987062, 0.44793718, 0.45597733, 0.46403705, 0.4720927, 0.48028065, 0.4885131, 0.49695726, 0.5053638, 0.51370983, 0.52166575, 0.52911717, 0.53630063, 0.54350976, 0.55065175, 0.5576987, 0.56515963, 0.57414881, 0.58581203, 0.60106133, 0.61920826, 0.63441176, 0.64444496, 0.65045212, 0.6552307, 0.6599221, 0.6650715, 0.67001146, 0.67061167, 0.67113711, 0.67315375, 0.67797767, 0.68199324, 0.68571826, 0.69335833, 0.70237947, 0.70950038, 0.71685984, 0.7241968, 0.73129851, 0.73900574, 0.75115207, 0.75963027, 0.76905855, 0.78322163, 0.79159857, 0.79245248, 0.79107474, 0.78888644, 0.78973313, 0.79291809, 0.80155304, 0.81233827, 0.82142127, 0.82650645, 0.82950388, 0.83326463, 0.83366361, 0.83176001, 0.83146794, 0.83202915, 0.83384987, 0.83933199, 0.84790874, 0.85610776, 0.86331973, 0.86895249, 0.87437673, 0.87886068, 0.88107721, 0.88256128, 0.88637201, 0.8903003, 0.89170068, 0.8913573, 0.88855065, 0.88565698, 0.88533144, 0.88606156, 0.88671645, 0.88791243, 0.88913495, 0.8891744, 0.88764162, 0.88782382, 0.88955391, 0.89185602, 0.89196857, 0.89173273, 0.89275971, 0.89683466, 0.90014227, 0.90019847, 0.89987414, 0.89742712, 0.89417066, 0.89250583, 0.89142793, 0.89044687, 0.89000899, 0.89008642, 0.8905574, 0.89235167, 0.89543507, 0.89656239, 0.89636287, 0.89559705, 0.89308331, 0.89015943, 0.88955618, 0.88997233, 0.8915667, 0.89541263, 0.89933524, 0.90012366, 0.89982421, 0.89974462, 0.89953149, 0.89852051, 0.89717144, 0.8962689, 0.89562133, 0.89390928, 0.88979206, 0.88653296, 0.88673392, 0.88801113, 0.8919161, 0.89805037, 0.90365521, 0.90506388, 0.90454156, 0.90286096, 0.89988196, 0.89693817, 0.89508255, 0.89482766, 0.89446222, 0.8935049, 0.89149568, 0.89126409, 0.89133746, 0.89155296, 0.891861, 0.89210393, 0.89241619, 0.89270213, 0.89185516, 0.8909092, 0.89204971, 0.89389175, 0.89439182, 0.89561993, 0.89863491, 0.89857581, 0.89790874, 0.89807274, 0.8975778, 0.89576727, 0.89454615, 0.89394598, 0.89344243, 0.89313787, 0.89326778, 0.89456251, 0.89627034, 0.89716934, 0.89706067, 0.89644184, 0.8951939, 0.89524545, 0.8955355, 0.89648327, 0.89645648, 0.89620751, 0.89535335, 0.89266434, 0.89107604, 0.89119897, 0.89146252, 0.89201422, 0.89367523, 0.89515785, 0.89514318, 0.89468989, 0.8936907, 0.89203612, 0.89111186, 0.89147443, 0.89267491, 0.89616509, 0.89965218, 0.90041286, 0.90012019, 0.89926374, 0.89733478, 0.89248269, 0.88868208, 0.88865755, 0.88955456, 0.8911347, 0.89408624, 0.89764004, 0.8976562, 0.89715549, 0.8955327, 0.890238, 0.88822536, 0.88957124, 0.89035779, 0.89214842, 0.89442469, 0.90050315, 0.90013322, 0.89675555, 0.88715024, 0.87840912, 0.86407897, 0.85519389, 0.86034735, 0.87677547, 0.89883519, 0.91619161, 0.914784, 0.91060943, 0.90052024, 0.88406818, 0.85282057, 0.8092647, 0.77598062, 0.76502665, 0.74142894, 0.63055733, 0.2403422, 0.024533632, 0.0019871171, 0.00015601923, 1.2184269e-05, 9.5273907e-07, 7.4937229e-08, 5.953439e-09, 4.8536166e-10, 3.6191332e-10, 3.4116245e-10, 3.3277232e-10, 2.2153077e-10, 3.2855396e-10, 8.620493e-11, 8.181629e-11, 3.5578282e-10, 2.3914764e-11, 4.8847353e-10, 2.7332507e-10, 4.7721934e-10, 3.6431553e-10, 2.2384307e-10, 3.9855979e-10, 3.8645977e-10, 3.5036318e-10, 1.726803e-10, 2.9928474e-10, 1.9461675e-10, 3.7171756e-10, 1.7373108e-10, 3.7679966e-10, 4.8863157e-10, 3.8452728e-10, 4.2056852e-10, 3.3878678e-10, 3.6588632e-10, 3.3653803e-10, 1.6154007e-10, 3.2305978e-10, 2.7894117e-10, 6.7424967e-11, 1.0233268e-11, 4.5023441e-11, 8.146e-11, 1.1299926e-10, 7.1518314e-11, 5.3754675e-11, 7.0855331e-11, 1.2622738e-11, 7.8869489e-13, 1.4741204e-10, 5.0156919e-11, 9.4527367e-11, 3.6979398e-11, 1.6238011e-10, 3.9140888e-10, 9.6569923e-11, 4.8952982e-11, 1.125599e-10, 6.9977177e-11, 9.3216288e-11, 8.5504999e-12, 1.6346375e-10, 3.3393236e-10, 1.215359e-10, 1.2327146e-11, 3.1730176e-11, 3.9845058e-12, 1.4821947e-10, 5.8621841e-11, 4.0178273e-11, 8.2939545e-11, 1.962649e-10, 2.6365975e-10, 4.681282e-10, 3.1397343e-10, 1.725423e-10, 3.385972e-10, 1.1452388e-10, 1.2711137e-10, 1.0347447e-10, 9.8208115e-11, 3.625952e-11, 4.4265293e-11, 1.0968569e-10, 1.833644e-10, 1.8868279e-11, 6.4592718e-11, 1.77071e-10, 5.7097743e-11, 7.5745921e-11, 2.433641e-10, 2.6176833e-10, 1.9938034e-10, 7.8585294e-11, 1.7420073e-10, 1.5080546e-10, 7.284895e-11, 1.3081094e-10, 8.2025894e-11, 4.0778175e-12, 2.7453699e-10, 8.3939684e-11, 8.6642635e-11, 4.5338077e-11, 7.5067079e-12, 1.7119446e-10, 4.3341007e-11, 2.2271518e-11, 8.4149852e-11, 2.1526762e-10, 1.1833779e-10, 3.1246775e-10, 1.4383031e-10, 1.5289642e-10, 2.8087521e-11, 2.2263925e-11, 2.8324233e-10, 2.1168632e-10, 2.0249857e-10, 2.7185546e-10, 2.6738573e-10, 2.8651923e-10, 2.1367628e-10, 2.4703077e-11, 3.8862975e-10, 2.8921211e-10, 1.4230467e-10, 4.1436828e-11, 3.7256349e-11, 3.0538214e-10, 4.5553487e-11, 1.5740043e-10, 2.8861295e-10, 3.3890142e-10, 4.2071341e-11, 2.2142564e-10, 1.0395009e-10, 4.7673354e-10, 1.4339627e-10, 5.8287293e-10, 3.3438255e-11, 5.5037913e-10, 3.3458078e-11, 3.7407164e-10, 3.854368e-10, 2.4011775e-10, 4.5061275e-10, 5.4182422e-10, 3.8275743e-10, 2.9087651e-10, 1.220687e-10, 3.0405937e-10, 7.2546675e-11, 3.2877402e-11, 1.3158057e-10, 3.4092286e-10, 2.2212738e-10, 3.3963692e-10, 2.106994e-10, 4.455069e-10, 2.6300736e-10, 1.3576514e-10, 1.1298729e-10, 3.8279119e-10, 1.8344209e-11, 1.172805e-10, 3.006375e-11, 1.700625e-10, 1.9673638e-10, 1.2044465e-10, 2.5815689e-10, 4.2112812e-10, 5.1276697e-11, 6.7210226e-11, 5.7983457e-11, 1.089576e-10, 3.2672554e-11, 2.7578965e-10, 1.468722e-10, 2.9628548e-10, 3.9326858e-10, 4.8068342e-10, 3.7565781e-10, 3.241546e-10, 2.2195177e-10, 4.566839e-10, 4.1441796e-10, 2.0261894e-10, 3.0922788e-10, 1.225869e-10, 3.1332938e-11, 1.8846258e-10, 4.1431616e-10, 2.4652404e-10, 3.3884929e-10, 4.3479405e-10, 3.2627362e-10, 2.5278098e-10, 3.3640669e-10, 3.5546187e-10, 3.7988848e-10, 5.767901e-11, 7.0454888e-11, 4.3509946e-10, 2.1841129e-10, 4.475982e-10, 2.8222015e-10, 5.4257885e-10, 2.8392429e-10, 6.8963281e-10, 3.1406001e-10, 2.7907842e-10, 2.3343131e-10, 3.4284524e-10, 3.6977625e-10, 2.5203559e-10, 1.8537896e-10, 2.9391517e-10, 7.8858797e-11, 1.3702003e-10, 2.4885264e-10, 2.4011127e-10, 4.10332e-10, 4.5736337e-10, 5.3042462e-10, 6.7751041e-11, 3.1341871e-10, 8.3023325e-11, 1.8255445e-10, 3.4044546e-10, 4.3011966e-11, 2.6184625e-10, 5.8955461e-11, 4.8949175e-10, 2.2769705e-10, 2.7286237e-10, 1.112853e-10, 1.7151728e-10, 8.9115615e-11, 4.1614266e-11, 2.5054228e-10, 1.8822545e-10, 6.7626191e-11, 2.1285241e-11, 5.7091015e-11, 4.433511e-10, 3.1274912e-10, 2.2601838e-10, 6.2294587e-11, 3.1449292e-11, 4.4388366e-10, 1.0949398e-10, 2.5631037e-10, 6.2711095e-11, 5.8124669e-10, 4.1696024e-10, 6.5950828e-10, 1.6011349e-10, 3.2415787e-10, 9.7031873e-11, 1.6982715e-10, 6.3710753e-11, 2.1660822e-10, 5.5002667e-11, 4.6249485e-10, 3.5534175e-10, 4.0977061e-10, 1.1044674e-10, 4.1232996e-10, 1.7613872e-10, 4.7531882e-10, 1.4800221e-10, 5.4628135e-10, 8.7973527e-11, 3.8900734e-10, 4.1719918e-11, 3.5080572e-10, 6.1888695e-12, 5.6905546e-11, 1.0672898e-10, 6.678153e-11, 2.1756497e-10, 9.6035733e-12, 4.9392453e-11, 9.1473808e-11, 4.521796e-11, 1.0588006e-10, 7.3530424e-11, 1.4769092e-10, 1.8944487e-11, 7.2548502e-11, 4.0307835e-10, 2.1403273e-10, 3.4677373e-10, 3.4571903e-10, 2.6744556e-10, 2.3754971e-11, 8.9804591e-12, 1.1953095e-11, 1.2903551e-10, 4.1469275e-11, 1.7462034e-11, 2.2420991e-10, 3.2052671e-11, 1.9999565e-10, 3.9288371e-11, 3.8543651e-12, 3.3792944e-11, 6.5628575e-11, 1.7551484e-10, 1.7002088e-10, 2.8506586e-10, 2.4517918e-10, 3.7002737e-11, 6.9367117e-11, 3.875388e-11, 1.3229345e-11, 1.3489459e-11, 1.9190398e-10, 1.0360143e-11, 1.2232169e-11, 7.9270097e-12, 1.782311e-10, 6.749101e-11, 1.1641828e-10, 1.5052055e-10, 1.0297067e-10, 4.3455144e-12, 1.311254e-10, 2.2328563e-18];\nlet data6 = [2.4736089e-21, 3.557215e-11, 1.4491517e-11, 3.1926845e-12, 9.8094767e-12, 6.4086002e-12, 1.0635131e-11, 1.7253035e-11, 7.2617091e-13, 7.0434024e-12, 9.7921366e-12, 5.3706415e-12, 2.0734942e-11, 1.8722161e-11, 1.6536423e-12, 2.9744887e-12, 6.7616262e-12, 4.6114578e-12, 1.6889115e-11, 1.3241588e-11, 6.2568747e-12, 5.2398129e-12, 2.3631512e-11, 1.5845265e-11, 3.2267866e-11, 3.7653514e-12, 2.8384247e-11, 5.9523119e-12, 4.0711368e-12, 3.092868e-12, 1.645528e-12, 1.4564101e-11, 1.4103256e-11, 1.1685094e-11, 2.1664859e-11, 3.3110082e-11, 5.1585703e-11, 3.3429429e-11, 6.1477878e-11, 2.8549978e-11, 6.3940724e-11, 4.2923005e-11, 6.7488102e-11, 4.6114911e-11, 7.38638e-11, 6.2954229e-11, 5.8148252e-11, 5.1998196e-11, 6.2571525e-11, 6.3686069e-11, 6.6297973e-11, 5.5396516e-11, 3.8656236e-11, 3.7013154e-11, 2.5425876e-11, 5.928347e-11, 1.4655137e-11, 1.3775906e-11, 7.3402954e-12, 1.9464115e-11, 1.3586944e-11, 3.222585e-12, 3.1207677e-12, 7.4854629e-12, 1.5714993e-12, 1.0029451e-12, 1.8254646e-11, 1.6622901e-11, 2.7060288e-11, 2.7576044e-11, 2.2113367e-11, 3.7476556e-11, 2.8651462e-11, 1.0359023e-11, 1.8422378e-11, 2.0315446e-11, 1.144978e-11, 1.2722942e-11, 1.2541982e-11, 1.7565045e-11, 1.1307058e-11, 1.0880448e-11, 3.1376187e-11, 1.5549373e-11, 2.7908618e-11, 1.3636074e-11, 2.6978256e-11, 2.4016439e-11, 3.3378853e-11, 6.3285692e-12, 9.4646761e-12, 1.1684983e-11, 8.3919261e-12, 7.3647494e-12, 4.2612106e-12, 4.1272697e-12, 5.051073e-12, 6.0162256e-12, 5.2336994e-12, 9.1067593e-12, 8.3596914e-12, 2.3193786e-11, 2.4675139e-12, 1.96822e-11, 7.0787494e-12, 1.5689872e-11, 1.3103645e-11, 1.2901678e-11, 5.1338829e-12, 3.0584879e-11, 2.4636347e-11, 4.084931e-11, 1.8863771e-11, 1.7808806e-11, 1.0670256e-11, 2.2720714e-11, 6.5158642e-12, 1.4889783e-11, 1.3300166e-11, 2.1428323e-11, 5.7082171e-12, 1.5145549e-11, 2.9703648e-11, 3.2818747e-11, 5.7270022e-11, 3.4523965e-11, 3.5275701e-11, 3.0865322e-12, 1.1147552e-11, 1.3170782e-11, 2.0258313e-11, 8.1201539e-12, 1.8948693e-11, 4.3070062e-12, 2.0004436e-12, 2.087144e-12, 1.278541e-11, 1.4894674e-12, 7.7514551e-12, 7.6359658e-12, 4.8564418e-12, 1.2659361e-12, 2.5807135e-11, 1.9168779e-11, 2.2039671e-12, 9.3736407e-13, 3.4295543e-12, 8.5977838e-13, 2.1398089e-11, 4.11093e-12, 2.9779344e-12, 9.9719843e-12, 1.2265875e-12, 2.3258256e-11, 2.7452885e-12, 3.5525243e-11, 4.9341387e-13, 2.516055e-11, 3.9548695e-13, 2.2922348e-11, 1.2079136e-12, 1.486344e-11, 2.8566095e-11, 1.1704213e-11, 1.3646523e-11, 3.290667e-11, 1.1824593e-11, 1.9435993e-11, 1.4976484e-11, 6.4421688e-12, 3.1013157e-12, 1.4837763e-11, 2.4438825e-11, 1.8236083e-11, 1.5704544e-11, 1.0533647e-11, 7.9248558e-12, 8.2939992e-12, 1.8438273e-11, 2.6298214e-11, 3.3018713e-11, 4.3504675e-12, 1.2537536e-11, 1.660645e-12, 1.8246976e-11, 9.6453018e-12, 2.9774898e-12, 4.012225e-12, 1.3658638e-11, 4.5602156e-12, 8.7537333e-12, 1.76214e-11, 1.7859048e-11, 1.0328901e-11, 1.946067e-11, 1.7977872e-11, 1.3260373e-11, 8.0306747e-12, 3.7705756e-12, 1.5674755e-11, 2.0868439e-11, 1.0141161e-11, 9.1175413e-12, 2.7824474e-11, 1.8477955e-11, 3.1111084e-11, 1.8002659e-11, 4.4133253e-11, 2.1554261e-11, 3.4529856e-11, 1.7164445e-12, 4.1950516e-11, 1.9599501e-11, 5.5902602e-11, 2.3968198e-11, 5.3617381e-11, 3.4065898e-11, 5.772631e-11, 4.3247909e-11, 2.910964e-11, 3.540753e-11, 2.7571931e-11, 1.1315284e-11, 1.8592999e-11, 2.5544255e-11, 1.6387143e-11, 1.5040508e-11, 2.2639905e-11, 5.4360002e-12, 8.6666995e-12, 5.6874312e-12, 1.5383751e-13, 8.4142681e-12, 2.35447e-12, 1.4626348e-11, 3.7153319e-12, 1.3556488e-11, 3.5347063e-14, 1.3290495e-11, 1.0186957e-11, 6.1501665e-12, 8.5577683e-13, 1.3072633e-11, 1.0210744e-11, 2.2636236e-11, 2.474839e-11, 2.8420038e-11, 4.5050942e-11, 2.2227633e-11, 3.1792015e-11, 3.6332556e-11, 3.8697586e-11, 4.2348893e-11, 3.2118253e-11, 2.8153046e-11, 2.4457277e-11, 1.9662081e-11, 2.1734997e-11, 6.8804476e-14, 1.1115651e-11, 4.9918277e-12, 1.8982929e-12, 1.1247702e-11, 2.0770401e-11, 3.5807463e-11, 8.5853346e-12, 2.4645239e-11, 2.9784902e-12, 3.769364e-11, 1.2267098e-11, 3.746344e-11, 1.1964203e-11, 3.5184555e-11, 1.8121038e-11, 3.9607495e-11, 3.9379517e-11, 3.7426425e-11, 3.3673968e-11, 4.049684e-12, 2.1577381e-11, 1.3780908e-11, 2.3483121e-11, 2.7510908e-11, 1.4425381e-11, 3.1311828e-11, 3.6918784e-11, 1.8378583e-11, 2.2417929e-11, 9.0246163e-12, 6.4247186e-14, 9.9341918e-12, 7.702325e-12, 4.1842474e-11, 6.886208e-11, 9.5465635e-11, 1.6657403e-10, 2.5517066e-10, 3.8494351e-10, 5.6399439e-10, 8.0096699e-10, 1.1594728e-09, 1.6400004e-09, 2.3573629e-09, 3.2925991e-09, 4.651614e-09, 6.4904372e-09, 9.0606513e-09, 1.2616985e-08, 1.750877e-08, 2.4246208e-08, 3.3509402e-08, 4.6136119e-08, 6.3343107e-08, 8.6727815e-08, 1.1841186e-07, 1.6118977e-07, 2.1885078e-07, 2.9625965e-07, 3.9988425e-07, 5.3816045e-07, 7.2207441e-07, 9.6595904e-07, 1.2882465e-06, 1.7128436e-06, 2.2702853e-06, 2.9998008e-06, 3.9511764e-06, 5.1876766e-06, 6.7891422e-06, 8.8560828e-06, 1.1514183e-05, 1.4920328e-05, 1.9269039e-05, 2.4800646e-05, 3.1810529e-05, 4.0660049e-05, 5.1789098e-05, 6.5730358e-05, 8.3125583e-05, 0.00010474378, 0.00013150143, 0.00016448458, 0.00020497294, 0.00025446541, 0.00031470709, 0.00038771704, 0.00047581629, 0.00058165571, 0.00070824225, 0.00085896345, 0.0010376082, 0.0012483837, 0.0014959262, 0.0017853056, 0.0021220223, 0.0025119947, 0.0029615384, 0.0034773344, 0.0040663876, 0.0047359764, 0.0054935914, 0.0063468671, 0.007303506, 0.0083711979, 0.0095575358, 0.01086993, 0.012315523, 0.013901112, 0.015633065, 0.017517262, 0.019559027, 0.021763082, 0.024133505, 0.026673708, 0.029386413, 0.032273654, 0.035336779, 0.038576467, 0.04199275, 0.045585049, 0.049352209, 0.053292541, 0.05740387, 0.061683583, 0.066128679, 0.070735817, 0.075501368, 0.08042146, 0.085492024, 0.090708839, 0.096067568, 0.1015638, 0.10719306, 0.11295089, 0.11883282, 0.12483441, 0.13095128, 0.13717913, 0.14351373, 0.14995096, 0.15648679, 0.16311732, 0.16983875, 0.17664742, 0.1835398, 0.19051247, 0.19756214, 0.20468567, 0.21188001, 0.21914228, 0.22646967, 0.23385953, 0.24130932, 0.2488166, 0.25637904, 0.26399444, 0.27166068, 0.27937575, 0.28713777, 0.29494488, 0.30279546, 0.31068767, 0.31862067, 0.32659107, 0.33460296, 0.34264136, 0.3507378, 0.35882029, 0.36702912, 0.37510944, 0.38346982, 0.39151817, 0.40002843, 0.40807226, 0.41671242, 0.42477037, 0.43354705, 0.44164824, 0.4504208, 0.45880128, 0.46731437, 0.47564069, 0.48422064, 0.49218235, 0.50114621, 0.50900396, 0.518143, 0.52591298, 0.5352627, 0.54287413, 0.55237234, 0.55994548, 0.56971587, 0.57701518, 0.58720775, 0.59417315, 0.60464393, 0.61157174, 0.62223854, 0.62896741, 0.63994151, 0.6463752, 0.65756992, 0.66373256, 0.67507394, 0.68084696, 0.69222455, 0.69760447, 0.70898071, 0.71394469, 0.7252862, 0.72979015, 0.74095639, 0.74500105, 0.75577082, 0.75958339, 0.77002512, 0.77383606, 0.78382725, 0.78789691, 0.79706106, 0.80153898, 0.80944065, 0.81447886, 0.82092838, 0.82676051, 0.83227023, 0.84016694, 0.84345249, 0.85416931, 0.85538181, 0.86689314, 0.87031671, 0.88113769, 0.88503948, 0.89266435, 0.89726632, 0.90207678, 0.90609692, 0.90963674, 0.91258655, 0.91502049, 0.91694533, 0.9185455, 0.91993565, 0.92127913, 0.92250348, 0.9236348, 0.92449581, 0.92534573, 0.92593932, 0.926508, 0.92681627, 0.92684728, 0.92684988, 0.92681491, 0.92675624, 0.92662322, 0.92641057, 0.92621132, 0.92590999, 0.92573187, 0.92555097, 0.92539485, 0.92529249, 0.9251848, 0.92514504, 0.92503605, 0.9249758, 0.92487104, 0.92480741, 0.92477195, 0.92475021, 0.92474446, 0.92473058, 0.92466689, 0.92464599, 0.92459863, 0.92455818, 0.92454052, 0.9245201, 0.92451419, 0.92451885, 0.92448997, 0.92448865, 0.92451428, 0.92451891, 0.9246874, 0.92476524, 0.92500648, 0.92509177, 0.92524675, 0.92532686, 0.92542361, 0.92548585, 0.9255706, 0.92561766, 0.92567513, 0.92568916, 0.92568702, 0.92568594, 0.92568644, 0.92568731, 0.92568733, 0.92568538, 0.92568545, 0.92568528, 0.92568663, 0.9256866, 0.92568528, 0.92568502, 0.92567256, 0.92566365, 0.92565065, 0.92563364, 0.92563023, 0.92560237, 0.92558626, 0.92558102, 0.92556718, 0.92556095, 0.92553352, 0.92552234, 0.92551443, 0.92551346, 0.92553188, 0.92554215, 0.92553593, 0.92551216, 0.9254981, 0.92548397, 0.92545191, 0.9254438, 0.92546047, 0.92545948, 0.92545321, 0.92546942, 0.92546893, 0.92548178, 0.9254962, 0.92550577, 0.92551064, 0.92551861, 0.92551255, 0.92551154, 0.92550125, 0.9254909, 0.92547777, 0.92546059, 0.9254376, 0.92542317, 0.92541357, 0.92540004, 0.92539003, 0.92539268, 0.92539484, 0.92539319, 0.92538687, 0.92537376, 0.92536217, 0.92533494, 0.92532182, 0.92530103, 0.92529295, 0.92528055, 0.9252808, 0.92528141, 0.92527479, 0.92526564, 0.92523915, 0.92522498, 0.92519033, 0.92516932, 0.92514302, 0.92513574, 0.92510167, 0.92508319, 0.92504168, 0.92502395, 0.92498993, 0.92496413, 0.92494274, 0.92494213, 0.92495041, 0.9249836, 0.92499667, 0.92499782, 0.92498454, 0.92497894, 0.92492624, 0.92489385, 0.92487897, 0.92509758, 0.92504302, 0.92491965, 0.92467987, 0.92444044, 0.92344321, 0.92290962, 0.92093694, 0.92008582, 0.9162359, 0.91463478, 0.90802769, 0.90425492, 0.89399229, 0.88607405, 0.86898745, 0.85620349, 0.82452756, 0.80408067, 0.75438196, 0.71474921, 0.64709112, 0.57709269, 0.48776217, 0.39181642, 0.29379284, 0.20417154, 0.13180417, 0.079941381, 0.046261304, 0.025928858, 0.014247258, 0.0077397344, 0.0041786383, 0.0022487831, 0.0012082535, 0.00064867088, 0.00034811725, 0.00018678768, 0.00010021515, 5.3764932e-05, 2.884384e-05, 1.5473854e-05, 8.3011042e-06, 4.4531444e-06, 2.3888279e-06, 1.2814482e-06, 6.8740462e-07, 3.6877249e-07, 1.9781662e-07, 1.0612857e-07, 5.6907018e-08, 3.0530822e-08, 1.6362161e-08, 8.775146e-09, 4.6521183e-09, 2.5235309e-09, 1.3190337e-09, 7.1714996e-10, 3.3889165e-10, 1.8756574e-10, 7.8574173e-11, 2.5481803e-11, 6.9994292e-12, 1.247901e-11, 4.1408415e-11, 4.7442414e-12, 4.0464184e-11, 1.6622659e-11, 2.5161139e-11, 2.3042919e-11, 2.7545969e-11, 2.1857719e-11, 1.0317612e-11, 3.6101653e-11, 8.1525515e-13, 1.4730091e-12, 4.1200966e-11, 2.1666919e-11, 2.549046e-11, 1.2807665e-11, 1.5924281e-11, 1.1008553e-11, 3.9694991e-11, 2.012476e-11, 2.4571647e-11, 6.2012669e-13, 3.3875435e-11, 1.7536811e-11, 3.5456885e-11, 9.438868e-12, 1.5482856e-11, 1.2117833e-11, 1.2255133e-11, 3.2043691e-11, 4.9047395e-12, 5.9504194e-13, 2.3257249e-11, 9.3155531e-12, 4.0251407e-11, 1.6236398e-11, 2.031778e-11, 5.1861107e-12, 4.9291028e-11, 8.2434564e-12, 9.2215406e-12, 2.4410372e-11, 1.5256538e-11, 5.7015363e-11, 3.3725704e-12, 5.4832432e-11, 5.1818707e-11, 4.5330519e-11, 3.5841038e-11, 3.9551697e-11, 4.6543135e-11, 6.3229727e-11, 4.3508543e-11, 3.6803361e-11, 2.5596571e-11, 5.6237735e-11, 2.0785067e-11, 5.3363974e-11, 4.6250331e-12, 5.7681996e-11, 1.4312085e-11, 3.4661054e-11, 1.451132e-11, 4.1207626e-11, 2.0039405e-11, 5.1141307e-11, 5.7767129e-11, 6.5028949e-11, 6.081504e-11, 6.6510061e-11, 6.9528559e-11, 5.3917837e-11, 3.3359199e-11, 3.1915825e-11, 2.4460763e-11, 2.6618498e-11, 1.9054772e-11, 2.2080929e-11, 2.1238369e-11, 4.8883122e-12, 2.9346301e-11, 3.8926909e-12, 1.8546972e-11, 3.352447e-11, 7.7369881e-12, 2.0904608e-11, 5.2964393e-11, 3.7098162e-11, 3.698628e-11, 5.4720328e-12, 1.7230799e-12, 1.4661718e-11, 3.0158781e-11, 8.727504e-13, 7.4551729e-12, 9.6010311e-12, 9.7009263e-12, 4.6964914e-11, 1.7044439e-11, 3.1317343e-11, 4.2369517e-11, 3.8669623e-11, 1.3587734e-11, 4.0327661e-11, 2.2638121e-11, 2.0275824e-11, 2.1832634e-12, 2.6967021e-11, 3.5043653e-11, 8.9498259e-12, 1.7058757e-11, 3.7238681e-12, 4.9141296e-11, 1.4965288e-11, 6.4129671e-11, 9.1424014e-12, 5.4471811e-11, 1.130724e-11, 1.602795e-11, 3.6961417e-11, 5.9972591e-12, 2.417473e-11, 3.6010304e-11, 2.7460281e-11, 1.8913365e-11, 2.2333219e-12, 9.1835805e-12, 1.0674682e-11, 2.0343309e-11, 1.0621071e-11, 2.5540186e-11, 1.0256232e-11, 4.1173994e-11, 4.7592922e-11, 3.8839778e-11, 5.586668e-11, 4.5768393e-11, 5.4112521e-11, 1.3272288e-11, 1.3262631e-11, 2.1268781e-12, 2.0194243e-11, 4.7091671e-12, 3.7831725e-11, 1.5198377e-11, 9.3552891e-12, 3.8123752e-11, 9.7382204e-12, 2.1738621e-11, 1.7108705e-12, 5.4503888e-12, 3.0085081e-12, 2.2196696e-12, 1.3662545e-11, 1.8426765e-11, 6.4032773e-12, 2.0263392e-11, 3.1608037e-11, 4.4126672e-11, 2.1159896e-11, 3.9597982e-11, 1.1844232e-11, 1.6582368e-11, 9.2536177e-13, 2.2899403e-11, 6.6586758e-12, 1.3248202e-11, 1.8486591e-11, 4.3278784e-11, 3.2563479e-11, 1.3640346e-11, 1.2093747e-11, 3.9193296e-12, 1.6752745e-11, 6.6797648e-12, 1.0561134e-11, 1.7613841e-11, 6.0695166e-12, 3.1665977e-11, 1.3746124e-11, 2.4588629e-12, 2.1681015e-11, 1.1307129e-11, 5.1117999e-11, 1.8270707e-11, 3.9627285e-12, 8.1229163e-12, 3.1189482e-14, 8.6509177e-13, 2.0935576e-11, 1.1765536e-11, 3.1098461e-11, 5.3431792e-11, 4.5414209e-11, 3.6909915e-11, 5.9130031e-11, 3.0514297e-11, 5.9756929e-11, 5.2456704e-11, 3.5227349e-11, 4.0291587e-11, 1.2385774e-11, 1.3110236e-11, 1.0282982e-11, 3.7945717e-12, 1.1037634e-11, 9.5456448e-12, 1.2120386e-11, 3.4301765e-11, 2.9848773e-11, 2.483648e-11, 1.5567101e-11, 1.8956764e-11, 3.6095881e-11, 5.7025684e-12, 1.6939771e-11, 3.0161445e-11, 6.3281338e-12, 1.0585664e-11, 1.3458537e-11, 1.4699567e-11, 2.6314706e-11, 7.8859428e-12, 2.2798398e-11, 1.1018876e-11, 1.6363931e-11, 6.347669e-12, 1.6589916e-11, 2.0036741e-12, 1.6865848e-11, 5.4995594e-12, 5.0944292e-12, 1.3116007e-11, 2.4353432e-11, 3.5570433e-12, 6.7930902e-12, 2.3220066e-12, 9.9536609e-12, 1.8856536e-11, 8.7824461e-12, 7.618224e-12, 1.6572712e-11, 5.5821394e-12, 2.3594118e-12, 1.351692e-11, 1.9621733e-11, 2.3416193e-11, 8.477988e-12, 1.7558232e-12, 1.3480181e-11, 1.6566829e-11, 8.3494562e-12, 1.0927638e-11, 4.0086691e-11, 1.6651962e-11, 2.7324424e-11, 3.4887816e-12, 1.3475297e-11, 2.1159452e-11, 5.2683577e-12, 1.3745236e-11, 3.5893205e-11, 3.4344276e-11, 4.7905261e-12, 2.1948068e-11, 4.4536575e-12, 5.2116617e-11, 3.6534865e-11, 6.9206452e-11, 3.8344298e-11, 4.4512489e-11, 2.1158231e-11, 1.856573e-11, 1.5882214e-12, 1.1754437e-11, 1.8347626e-11, 2.3172338e-11, 2.9199233e-11, 4.1969381e-11, 3.6500567e-11, 4.019036e-11, 5.0911105e-11, 3.4911625e-20];\n\noption = {\n  dataZoom: [\n    {\n      type: 'slider',\n      minSpan: 1\n    },\n    {\n      type: 'inside',\n      minSpan: 1\n    }\n  ],\n  tooltip: {\n      trigger: 'axis',\n      formatter: function (params) {\n          let newParams = [];\n          let tooltipString = [];\n          newParams = [...params];\n          newParams.sort((a,b) => {return b.value - a.value});\n          newParams.forEach((p) => {\n              const cont = p.marker + ' ' + p.seriesName + ': ' + p.value + '<br/>';\n              tooltipString.push(cont);\n          });\n          return tooltipString.join('');\n      }\n  },\n legend: {\n    data: legends\n  },\n  grid: {\n    left: '3%',\n    right: '4%',\n    bottom: '9%',\n    containLabel: true\n  },\n  // toolbox: {\n  //   feature: {\n  //     saveAsImage: {}\n  //   }\n  // },\n  xAxis: {\n    type: 'category',\n    boundaryGap: false,\n    data: xaxis\n  },\n  yAxis: {\n    min: 'dataMin',\n    type: 'value',\n    axisTick: {\n      alignWithLabel: true\n    },\n    scale: true,\n  },\n  series: [\n    {\n      name: legends[0],\n      type: 'line',\n      showSymbol: false,\n      data: data0\n    },\n    \n    {\n      name: legends[1],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data1\n    },\n    {\n      name: legends[2],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data2\n    },\n    {\n      name: legends[3],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data3\n    },\n    {\n      name: legends[4],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data4\n    },\n    {\n      name: legends[5],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data5\n    },\n    {\n      name: legends[6],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data6\n    },\n        {\n      name: legends[7],\n      type: 'line',\n      showSymbol: false,\n      lineStyle:{\n        type:'dashed'  //'dotted' 'solid'\n      },   \n      data: data7\n    }\n  ]\n};\n  // \n  myChart.setOption(option);\n</script>"}],"PostAsset":[{"_id":"source/_posts/Build-OpenFOAM-from-source-on-M1-Mac/Case sensitive volume finish.png","slug":"Case sensitive volume finish.png","post":"cl4r5iz1v0001l8yb28rdcy4x","modified":0,"renderable":0},{"_id":"source/_posts/Build-OpenFOAM-from-source-on-M1-Mac/Case sensitive volume step one.png","slug":"Case sensitive volume step one.png","post":"cl4r5iz1v0001l8yb28rdcy4x","modified":0,"renderable":0},{"_id":"source/_posts/Build-OpenFOAM-from-source-on-M1-Mac/Case sensitive volume step three.png","slug":"Case sensitive volume step three.png","post":"cl4r5iz1v0001l8yb28rdcy4x","modified":0,"renderable":0},{"_id":"source/_posts/Build-OpenFOAM-from-source-on-M1-Mac/Case sensitive volume step two.png","slug":"Case sensitive volume step two.png","post":"cl4r5iz1v0001l8yb28rdcy4x","modified":0,"renderable":0},{"_id":"source/_posts/External-flow-fundamentals/Boundary layer control volume.png","slug":"Boundary layer control volume.png","post":"cl4r5iz1y0005l8yb7wmb74f6","modified":0,"renderable":0},{"_id":"source/_posts/External-flow-fundamentals/Boundary layers.png","slug":"Boundary layers.png","post":"cl4r5iz1y0005l8yb7wmb74f6","modified":0,"renderable":0},{"_id":"source/_posts/External-flow-fundamentals/Flow past an airfoil.gif","slug":"Flow past an airfoil.gif","post":"cl4r5iz1y0005l8yb7wmb74f6","modified":0,"renderable":0},{"_id":"source/_posts/External-flow-fundamentals/Similarity solution.png","slug":"Similarity solution.png","post":"cl4r5iz1y0005l8yb7wmb74f6","modified":0,"renderable":0},{"_id":"source/_posts/External-flow-fundamentals/Skyscraper wind effect.png","slug":"Skyscraper wind effect.png","post":"cl4r5iz1y0005l8yb7wmb74f6","modified":0,"renderable":0},{"_id":"source/_posts/External-flow-fundamentals/V formation.jpeg","slug":"V formation.jpeg","post":"cl4r5iz1y0005l8yb7wmb74f6","modified":0,"renderable":0},{"_id":"source/_posts/External-flow-fundamentals/Wakes.png","slug":"Wakes.png","post":"cl4r5iz1y0005l8yb7wmb74f6","modified":0,"renderable":0},{"_id":"source/_posts/External-flow-fundamentals/Wingtip vortex.jpeg","slug":"Wingtip vortex.jpeg","post":"cl4r5iz1y0005l8yb7wmb74f6","modified":0,"renderable":0},{"_id":"source/_posts/External-flow-fundamentals/displacement thickness.png","slug":"displacement thickness.png","post":"cl4r5iz1y0005l8yb7wmb74f6","modified":0,"renderable":0},{"_id":"source/_posts/External-flow-fundamentals/magnus effect illustration.png","slug":"magnus effect illustration.png","post":"cl4r5iz1y0005l8yb7wmb74f6","modified":0,"renderable":0},{"_id":"source/_posts/External-flow-fundamentals/velocity profiles.png","slug":"velocity profiles.png","post":"cl4r5iz1y0005l8yb7wmb74f6","modified":0,"renderable":0},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Aerofoil vortex shedding.png","slug":"Aerofoil vortex shedding.png","post":"cl4r5iz1x0003l8yb9a2a57q3","modified":0,"renderable":0},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Differential mass conservation.png","slug":"Differential mass conservation.png","post":"cl4r5iz1x0003l8yb9a2a57q3","modified":0,"renderable":0},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Displacement deformation.png","slug":"Displacement deformation.png","post":"cl4r5iz1x0003l8yb9a2a57q3","modified":0,"renderable":0},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Flow direction based on stream function.png","slug":"Flow direction based on stream function.png","post":"cl4r5iz1x0003l8yb9a2a57q3","modified":0,"renderable":0},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Fluid partical deformation.png","slug":"Fluid partical deformation.png","post":"cl4r5iz1x0003l8yb9a2a57q3","modified":0,"renderable":0},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Fluid particle deformation.png","slug":"Fluid particle deformation.png","post":"cl4r5iz1x0003l8yb9a2a57q3","modified":0,"renderable":0},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Material derivatives.png","slug":"Material derivatives.png","post":"cl4r5iz1x0003l8yb9a2a57q3","modified":0,"renderable":0},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Polar coordinate.png","slug":"Polar coordinate.png","post":"cl4r5iz1x0003l8yb9a2a57q3","modified":0,"renderable":0},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Stream function property.png","slug":"Stream function property.png","post":"cl4r5iz1x0003l8yb9a2a57q3","modified":0,"renderable":0},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Surface forces on CS.png","slug":"Surface forces on CS.png","post":"cl4r5iz1x0003l8yb9a2a57q3","modified":0,"renderable":0},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Viscous stress on CS.png","slug":"Viscous stress on CS.png","post":"cl4r5iz1x0003l8yb9a2a57q3","modified":0,"renderable":0},{"_id":"source/_posts/Derivation-of-Differential-Fluid-Equations/Vortex line example.png","slug":"Vortex line example.png","post":"cl4r5iz1x0003l8yb9a2a57q3","modified":0,"renderable":0},{"_id":"source/_posts/Derive-the-NS-equation-from-scratch-AGAIN/Bernoulli's Equation CV.png","slug":"Bernoulli's Equation CV.png","post":"cl4r5iz1z0007l8yb5og0h0ed","modified":0,"renderable":0},{"_id":"source/_posts/Derive-the-NS-equation-from-scratch-AGAIN/Flow_pass_control_surface.png","slug":"Flow_pass_control_surface.png","post":"cl4r5iz1z0007l8yb5og0h0ed","modified":0,"renderable":0},{"_id":"source/_posts/Derive-the-NS-equation-from-scratch-AGAIN/Reynolds transport theorem proof.png","slug":"Reynolds transport theorem proof.png","post":"cl4r5iz1z0007l8yb5og0h0ed","modified":0,"renderable":0},{"_id":"source/_posts/Derive-the-NS-equation-from-scratch-AGAIN/region of significant viscous work.png","slug":"region of significant viscous work.png","post":"cl4r5iz1z0007l8yb5og0h0ed","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/Deep autoencoder reconstruction.png","slug":"Deep autoencoder reconstruction.png","post":"cl4r5iz20000el8yb3bsce4sy","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/POD Analysis of Cylinder Flow.jpeg","slug":"POD Analysis of Cylinder Flow.jpeg","post":"cl4r5iz20000el8yb3bsce4sy","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/RANs modeling with DNN.png","slug":"RANs modeling with DNN.png","post":"cl4r5iz20000el8yb3bsce4sy","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/RPCA for denoising.png","slug":"RPCA for denoising.png","post":"cl4r5iz20000el8yb3bsce4sy","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/Schematic overview of the proposed sparse modeling procedure.png","slug":"Schematic overview of the proposed sparse modeling procedure.png","post":"cl4r5iz20000el8yb3bsce4sy","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/Structure of control scheme.png","slug":"Structure of control scheme.png","post":"cl4r5iz20000el8yb3bsce4sy","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/Super resolution.png","slug":"Super resolution.png","post":"cl4r5iz20000el8yb3bsce4sy","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/parabolic reduced order model.png","slug":"parabolic reduced order model.png","post":"cl4r5iz20000el8yb3bsce4sy","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Machine-learning-for-fluids-dynamics/super resolution interpolation and extrapolation comparison.png","slug":"super resolution interpolation and extrapolation comparison.png","post":"cl4r5iz20000el8yb3bsce4sy","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/3 flow regimes.png","slug":"3 flow regimes.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/Channel flow.png","slug":"Channel flow.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/Moody chart.png","slug":"Moody chart.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/Physical interpretation.png","slug":"Physical interpretation.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/Plane Couette flow.png","slug":"Plane Couette flow.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/Poiseuille flow.png","slug":"Poiseuille flow.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/Pressure drop.png","slug":"Pressure drop.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/Reynolds experiment.png","slug":"Reynolds experiment.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/entrance effect.png","slug":"entrance effect.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/inclined pipe.png","slug":"inclined pipe.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/non-newtonian flow.png","slug":"non-newtonian flow.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/plug flow.png","slug":"plug flow.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/puff lifetimes.png","slug":"puff lifetimes.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Internal-flow-fundamentals/puffs.png","slug":"puffs.png","post":"cl4r5iz20000cl8yb1xite856","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/Google sitemap inspect 2.png","slug":"Google sitemap inspect 2.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/Google sitemap inspect 3.png","slug":"Google sitemap inspect 3.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/Google sitemap inspect.png","slug":"Google sitemap inspect.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/Last snapshot.png","slug":"Last snapshot.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/baidu console sitemap.png","slug":"baidu console sitemap.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/baidu console varification.png","slug":"baidu console varification.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/baidu console.png","slug":"baidu console.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/being sitemap connect google.png","slug":"being sitemap connect google.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/bing search console success.png","slug":"bing search console success.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/bing sitemap.png","slug":"bing sitemap.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/can't fetch sitemap.png","slug":"can't fetch sitemap.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/check google search.png","slug":"check google search.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/github page.png","slug":"github page.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/google console varification.png","slug":"google console varification.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/google console.png","slug":"google console.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/node js install.png","slug":"node js install.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Build-and-configure-a-personal-blog-via-hexo-and-yilia/typora setting.png","slug":"typora setting.png","post":"cl4r5iz1z0009l8ybdazg9109","modified":0,"renderable":0},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/Cross entropy loss function.png","slug":"Cross entropy loss function.png","post":"cl4r5iz21000jl8yba4p9fgly","modified":0,"renderable":0},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/Label smoothing feature norm.png","slug":"Label smoothing feature norm.png","post":"cl4r5iz21000jl8yba4p9fgly","modified":0,"renderable":0},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/accuracy curve applying label smoothing.png","slug":"accuracy curve applying label smoothing.png","post":"cl4r5iz21000jl8yba4p9fgly","modified":0,"renderable":0},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/accuracy curve compare label smoothing with hard label.png","slug":"accuracy curve compare label smoothing with hard label.png","post":"cl4r5iz21000jl8yba4p9fgly","modified":0,"renderable":0},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/hard label.png","slug":"hard label.png","post":"cl4r5iz21000jl8yba4p9fgly","modified":0,"renderable":0},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/leave class code.png","slug":"leave class code.png","post":"cl4r5iz21000jl8yba4p9fgly","modified":0,"renderable":0},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/soft label.png","slug":"soft label.png","post":"cl4r5iz21000jl8yba4p9fgly","modified":0,"renderable":0},{"_id":"source/_posts/Intro-and-Pytorch-Implementation-of-Label-Smoothing-Regularization-LSR/source ppt.pptx","slug":"source ppt.pptx","post":"cl4r5iz21000jl8yba4p9fgly","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/Cross_Correlation_Animation.gif","slug":"Cross_Correlation_Animation.gif","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/Deep autoencoder reconstruction.png","slug":"Deep autoencoder reconstruction.png","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/PCA as auto-encoder.png","slug":"PCA as auto-encoder.png","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/RPCA for denoising.png","slug":"RPCA for denoising.png","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/Removing shadows, specularities and saturations from face images.png","slug":"Removing shadows, specularities and saturations from face images.png","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/Super resolution.png","slug":"Super resolution.png","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/The-von-Karman-vortex-street-generated-by-the-Rishiri-island.jpeg","slug":"The-von-Karman-vortex-street-generated-by-the-Rishiri-island.jpeg","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/deeper auto-encoder.png","slug":"deeper auto-encoder.png","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/flow past a cylinder result.gif","slug":"flow past a cylinder result.gif","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/statistical stationarity.png","slug":"statistical stationarity.png","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/sufficient measurements.png","slug":"sufficient measurements.png","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/sufficient training data.png","slug":"sufficient training data.png","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/super resolution interpolation and extrapolation comparison.png","slug":"super resolution interpolation and extrapolation comparison.png","post":"cl4r5iz21000hl8yb5ocp49zl","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-A-gentle-introduction-to-graph-neural-networks/GNN graph level task.png","slug":"GNN graph level task.png","post":"cl4r5iz23000ul8yb3g59fc9r","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-A-gentle-introduction-to-graph-neural-networks/GNN graph message passing.png","slug":"GNN graph message passing.png","post":"cl4r5iz23000ul8yb3g59fc9r","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-A-gentle-introduction-to-graph-neural-networks/GNN interative archtecture.png","slug":"GNN interative archtecture.png","post":"cl4r5iz23000ul8yb3g59fc9r","modified":0,"renderable":0},{"_id":"source/_posts/learning-rate-schedule/2d cyclic learning rate schedule.png","slug":"2d cyclic learning rate schedule.png","post":"cl4r5iz23000sl8yb7tap1lm8","modified":0,"renderable":0},{"_id":"source/_posts/learning-rate-schedule/CLR.png","slug":"CLR.png","post":"cl4r5iz23000sl8yb7tap1lm8","modified":0,"renderable":0},{"_id":"source/_posts/learning-rate-schedule/SGD with learning rate decay.png","slug":"SGD with learning rate decay.png","post":"cl4r5iz23000sl8yb7tap1lm8","modified":0,"renderable":0},{"_id":"source/_posts/learning-rate-schedule/SGDR.png","slug":"SGDR.png","post":"cl4r5iz23000sl8yb7tap1lm8","modified":0,"renderable":0},{"_id":"source/_posts/learning-rate-schedule/SGDR_REsult.png","slug":"SGDR_REsult.png","post":"cl4r5iz23000sl8yb7tap1lm8","modified":0,"renderable":0},{"_id":"source/_posts/learning-rate-schedule/cyclic learning rate schedule.png","slug":"cyclic learning rate schedule.png","post":"cl4r5iz23000sl8yb7tap1lm8","modified":0,"renderable":0},{"_id":"source/_posts/learning-rate-schedule/experiment.png","slug":"experiment.png","post":"cl4r5iz23000sl8yb7tap1lm8","modified":0,"renderable":0},{"_id":"source/_posts/learning-rate-schedule/source ppt.pptx","slug":"source ppt.pptx","post":"cl4r5iz23000sl8yb7tap1lm8","modified":0,"renderable":0},{"_id":"source/_posts/learning-rate-schedule/warmup on large batches.png","slug":"warmup on large batches.png","post":"cl4r5iz23000sl8yb7tap1lm8","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-MAE/MAE ablation.png","slug":"MAE ablation.png","post":"cl4r5iz29001vl8yb3cqd7w4u","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-MAE/MAE architecture.png","slug":"MAE architecture.png","post":"cl4r5iz29001vl8yb3cqd7w4u","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-MAE/MAE classification.png","slug":"MAE classification.png","post":"cl4r5iz29001vl8yb3cqd7w4u","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-MAE/MAE comparison.png","slug":"MAE comparison.png","post":"cl4r5iz29001vl8yb3cqd7w4u","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-MAE/MAE fine tune.png","slug":"MAE fine tune.png","post":"cl4r5iz29001vl8yb3cqd7w4u","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-MAE/MAE mask ratio.png","slug":"MAE mask ratio.png","post":"cl4r5iz29001vl8yb3cqd7w4u","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-MAE/MAE pixels vs tokens.png","slug":"MAE pixels vs tokens.png","post":"cl4r5iz29001vl8yb3cqd7w4u","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-MAE/MAE result.png","slug":"MAE result.png","post":"cl4r5iz29001vl8yb3cqd7w4u","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-MAE/MAE result2.png","slug":"MAE result2.png","post":"cl4r5iz29001vl8yb3cqd7w4u","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-MAE/MAE segmentation.png","slug":"MAE segmentation.png","post":"cl4r5iz29001vl8yb3cqd7w4u","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-AlexNet/alexnet results.png","slug":"alexnet results.png","post":"cl4r5iz2a001zl8yb8l11c5ef","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-AlexNet/unsupervise learning cake.png","slug":"unsupervise learning cake.png","post":"cl4r5iz2a001zl8yb8l11c5ef","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-Vision-Transformer/CNN first layer filters.png","slug":"CNN first layer filters.png","post":"cl4r5iz2a0021l8ybgt06dl9g","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-Vision-Transformer/VIT algorithm.png","slug":"VIT algorithm.png","post":"cl4r5iz2a0021l8ybgt06dl9g","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-Vision-Transformer/VIT class token ablation.png","slug":"VIT class token ablation.png","post":"cl4r5iz2a0021l8ybgt06dl9g","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-Vision-Transformer/VIT model overview.png","slug":"VIT model overview.png","post":"cl4r5iz2a0021l8ybgt06dl9g","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-Vision-Transformer/VIT positional embedding ablation.png","slug":"VIT positional embedding ablation.png","post":"cl4r5iz2a0021l8ybgt06dl9g","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-Vision-Transformer/VIT properties.png","slug":"VIT properties.png","post":"cl4r5iz2a0021l8ybgt06dl9g","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-Vision-Transformer/ViT ablation 2.png","slug":"ViT ablation 2.png","post":"cl4r5iz2a0021l8ybgt06dl9g","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-Vision-Transformer/ViT inspecting.png","slug":"ViT inspecting.png","post":"cl4r5iz2a0021l8ybgt06dl9g","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-Vision-Transformer/ViT results.png","slug":"ViT results.png","post":"cl4r5iz2a0021l8ybgt06dl9g","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-Vision-Transformer/ViT variants.png","slug":"ViT variants.png","post":"cl4r5iz2a0021l8ybgt06dl9g","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-ResNet/ResNet figure 1.png","slug":"ResNet figure 1.png","post":"cl4r5iz2a001xl8yb63ef2cd0","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-ResNet/ResNet figure 2.png","slug":"ResNet figure 2.png","post":"cl4r5iz2a001xl8yb63ef2cd0","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-ResNet/ResNet figure 4.png","slug":"ResNet figure 4.png","post":"cl4r5iz2a001xl8yb63ef2cd0","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-ResNet/ResNet figure 5.png","slug":"ResNet figure 5.png","post":"cl4r5iz2a001xl8yb63ef2cd0","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-ResNet/ResNet table 1.png","slug":"ResNet table 1.png","post":"cl4r5iz2a001xl8yb63ef2cd0","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-ResNet/ResNet table 3.png","slug":"ResNet table 3.png","post":"cl4r5iz2a001xl8yb63ef2cd0","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-ResNet/ResNet table 6.png","slug":"ResNet table 6.png","post":"cl4r5iz2a001xl8yb63ef2cd0","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/BYOL batch norm ablation.png","slug":"BYOL batch norm ablation.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/BYOL model.png","slug":"BYOL model.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/CMC illustration.png","slug":"CMC illustration.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/CPC illustration.png","slug":"CPC illustration.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/DINO illustration.png","slug":"DINO illustration.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/Instdisc idea.png","slug":"Instdisc idea.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/Instdisc method.png","slug":"Instdisc method.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/InvaSpread illustration.png","slug":"InvaSpread illustration.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/MoCo v2 ablation.png","slug":"MoCo v2 ablation.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/MoCo v2 result.png","slug":"MoCo v2 result.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/MoCo v3 algorithm.png","slug":"MoCo v3 algorithm.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/MoCo v3 result.png","slug":"MoCo v3 result.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/Moco v1 illustration.png","slug":"Moco v1 illustration.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SimCLR aug result.png","slug":"SimCLR aug result.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SimCLR aug.png","slug":"SimCLR aug.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SimCLR projection head.png","slug":"SimCLR projection head.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SimCLR v1 illustration.png","slug":"SimCLR v1 illustration.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SimSiam illustration.png","slug":"SimSiam illustration.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SimSiam result.png","slug":"SimSiam result.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SwAV illustration.png","slug":"SwAV illustration.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SwAV multi crop.png","slug":"SwAV multi crop.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/SwAV result.png","slug":"SwAV result.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/contrastive learning illustration.png","slug":"contrastive learning illustration.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/instance discrimination illustration.png","slug":"instance discrimination illustration.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-contrastive-learning-review/surprising_stl10_10e.png","slug":"surprising_stl10_10e.png","post":"cl4r5iz2b0023l8ybf03l6kuk","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-bert/BERT alibation study 1.png","slug":"BERT alibation study 1.png","post":"cl4r5iz2b0027l8yb8rbu7bkx","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-bert/BERT learnable paramters.png","slug":"BERT learnable paramters.png","post":"cl4r5iz2b0027l8yb8rbu7bkx","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-bert/BERT segment embedding.png","slug":"BERT segment embedding.png","post":"cl4r5iz2b0027l8yb8rbu7bkx","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-bert/model size graph.webp","slug":"model size graph.webp","post":"cl4r5iz2b0027l8yb8rbu7bkx","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/BERT result with GPT.png","slug":"BERT result with GPT.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT 3 result 5.png","slug":"GPT 3 result 5.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT objectives.png","slug":"GPT objectives.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT timeline.png","slug":"GPT timeline.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT-3 approach.png","slug":"GPT-3 approach.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT-3 result 2.png","slug":"GPT-3 result 2.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT2 performance.png","slug":"GPT2 performance.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 gender.png","slug":"GPT3 gender.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 models.png","slug":"GPT3 models.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 performance with compute.png","slug":"GPT3 performance with compute.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 performance.png","slug":"GPT3 performance.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 race.png","slug":"GPT3 race.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 result 3.png","slug":"GPT3 result 3.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 result.png","slug":"GPT3 result.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 result4.png","slug":"GPT3 result4.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-GPT1-3/GPT3 training data.png","slug":"GPT3 training data.png","post":"cl4r5iz29001ul8ybdqrygfk6","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-transformer/layer norm.png","slug":"layer norm.png","post":"cl4r5iz2b0025l8ybbqwmgvjj","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-transformer/transformer table 3.png","slug":"transformer table 3.png","post":"cl4r5iz2b0025l8ybbqwmgvjj","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-transformer/transformer table1.png","slug":"transformer table1.png","post":"cl4r5iz2b0025l8ybbqwmgvjj","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-transformer/transformer.png","slug":"transformer.png","post":"cl4r5iz2b0025l8ybbqwmgvjj","modified":0,"renderable":0},{"_id":"source/_posts/paper-reading-Swin-transformer/CoCo and ADE20K SOTA.png","slug":"CoCo and ADE20K SOTA.png","post":"cl4r5iz2b0029l8ybatnhfiuf","modified":0,"renderable":0},{"_id":"source/_posts/FVM-schemes-fundamentals/1D scalar convection.png","slug":"1D scalar convection.png","post":"cl4r5iz2b002dl8yb3rxw15q6","modified":0,"renderable":0},{"_id":"source/_posts/FVM-schemes-fundamentals/2D scalar convection control volume.png","slug":"2D scalar convection control volume.png","post":"cl4r5iz2b002dl8yb3rxw15q6","modified":0,"renderable":0},{"_id":"source/_posts/FVM-schemes-fundamentals/Burgers's equation under Riemann Problem general solution.png","slug":"Burgers's equation under Riemann Problem general solution.png","post":"cl4r5iz2b002dl8yb3rxw15q6","modified":0,"renderable":0},{"_id":"source/_posts/FVM-schemes-fundamentals/Burgers's equation under Riemann Problem with uL = 0, uR=1.png","slug":"Burgers's equation under Riemann Problem with uL = 0, uR=1.png","post":"cl4r5iz2b002dl8yb3rxw15q6","modified":0,"renderable":0},{"_id":"source/_posts/FVM-schemes-fundamentals/Burgers's equation under Riemann Problem with uL = 1, uR=0.png","slug":"Burgers's equation under Riemann Problem with uL = 1, uR=0.png","post":"cl4r5iz2b002dl8yb3rxw15q6","modified":0,"renderable":0},{"_id":"source/_posts/FVM-schemes-fundamentals/Expansion shock solution to the Riemann Problem.png","slug":"Expansion shock solution to the Riemann Problem.png","post":"cl4r5iz2b002dl8yb3rxw15q6","modified":0,"renderable":0},{"_id":"source/_posts/FVM-schemes-fundamentals/Inviscid Burgers' equation Solutions.png","slug":"Inviscid Burgers' equation Solutions.png","post":"cl4r5iz2b002dl8yb3rxw15q6","modified":0,"renderable":0},{"_id":"source/_posts/FVM-schemes-fundamentals/Linear Advection Solutions.png","slug":"Linear Advection Solutions.png","post":"cl4r5iz2b002dl8yb3rxw15q6","modified":0,"renderable":0},{"_id":"source/_posts/FVM-schemes-fundamentals/Rarefaction wave solution to the Riemann Problem.png","slug":"Rarefaction wave solution to the Riemann Problem.png","post":"cl4r5iz2b002dl8yb3rxw15q6","modified":0,"renderable":0},{"_id":"source/_posts/FVM-schemes-fundamentals/Riemann problem illustration.png","slug":"Riemann problem illustration.png","post":"cl4r5iz2b002dl8yb3rxw15q6","modified":0,"renderable":0},{"_id":"source/_posts/FVM-schemes-fundamentals/shock path control volume.png","slug":"shock path control volume.png","post":"cl4r5iz2b002dl8yb3rxw15q6","modified":0,"renderable":0},{"_id":"source/_posts/FVM-schemes-fundamentals/shock wave.png","slug":"shock wave.png","post":"cl4r5iz2b002dl8yb3rxw15q6","modified":0,"renderable":0}],"PostCategory":[],"PostTag":[{"post_id":"cl4r5iz1v0001l8yb28rdcy4x","tag_id":"cl4r5iz1y0004l8ybebmububy","_id":"cl4r5iz20000dl8yba83xfpyo"},{"post_id":"cl4r5iz1v0001l8yb28rdcy4x","tag_id":"cl4r5iz1z0008l8ybbcwa0ixg","_id":"cl4r5iz20000fl8yb5hqqdx07"},{"post_id":"cl4r5iz20000cl8yb1xite856","tag_id":"cl4r5iz20000bl8yb2ji61r67","_id":"cl4r5iz21000il8ybc8u9axak"},{"post_id":"cl4r5iz1x0003l8yb9a2a57q3","tag_id":"cl4r5iz20000bl8yb2ji61r67","_id":"cl4r5iz22000kl8yb4fscg93n"},{"post_id":"cl4r5iz1y0005l8yb7wmb74f6","tag_id":"cl4r5iz20000bl8yb2ji61r67","_id":"cl4r5iz22000nl8yb074l9wvm"},{"post_id":"cl4r5iz1z0006l8ybbhga7l63","tag_id":"cl4r5iz22000ll8ybc3vecg2f","_id":"cl4r5iz23000rl8yb3bvoh8q3"},{"post_id":"cl4r5iz1z0007l8yb5og0h0ed","tag_id":"cl4r5iz20000bl8yb2ji61r67","_id":"cl4r5iz24000vl8yb7v1h3bk8"},{"post_id":"cl4r5iz1z0009l8ybdazg9109","tag_id":"cl4r5iz23000tl8yb8l7n1ntz","_id":"cl4r5iz25000yl8ybdmvp1a5b"},{"post_id":"cl4r5iz1z0009l8ybdazg9109","tag_id":"cl4r5iz22000ll8ybc3vecg2f","_id":"cl4r5iz25000zl8ybaip8h3db"},{"post_id":"cl4r5iz20000al8yb6xald8mr","tag_id":"cl4r5iz20000bl8yb2ji61r67","_id":"cl4r5iz250011l8yb1w1k93mz"},{"post_id":"cl4r5iz20000el8yb3bsce4sy","tag_id":"cl4r5iz20000bl8yb2ji61r67","_id":"cl4r5iz250013l8ybdjy99ksu"},{"post_id":"cl4r5iz20000el8yb3bsce4sy","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz250014l8ybakv29hse"},{"post_id":"cl4r5iz21000hl8yb5ocp49zl","tag_id":"cl4r5iz20000bl8yb2ji61r67","_id":"cl4r5iz250016l8yb9pu017g4"},{"post_id":"cl4r5iz21000hl8yb5ocp49zl","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz250017l8yb501y93b2"},{"post_id":"cl4r5iz21000jl8yba4p9fgly","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz26001al8ybbf5p5u55"},{"post_id":"cl4r5iz21000jl8yba4p9fgly","tag_id":"cl4r5iz250018l8yb1zhp6xr1","_id":"cl4r5iz26001bl8ybh6vx1mqm"},{"post_id":"cl4r5iz22000ml8ybglkh00h0","tag_id":"cl4r5iz20000bl8yb2ji61r67","_id":"cl4r5iz26001el8ybac3r6ufg"},{"post_id":"cl4r5iz22000ml8ybglkh00h0","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz26001fl8yb346x7wzr"},{"post_id":"cl4r5iz22000ml8ybglkh00h0","tag_id":"cl4r5iz26001cl8yb8yvf0j39","_id":"cl4r5iz26001hl8yb1eiha03l"},{"post_id":"cl4r5iz22000ol8ybekxjgi6w","tag_id":"cl4r5iz1z0008l8ybbcwa0ixg","_id":"cl4r5iz26001il8ybgmg09anq"},{"post_id":"cl4r5iz22000ol8ybekxjgi6w","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz26001kl8yb7tpkez45"},{"post_id":"cl4r5iz23000ql8ybbofvh476","tag_id":"cl4r5iz23000tl8yb8l7n1ntz","_id":"cl4r5iz26001ll8yb3ur72h8r"},{"post_id":"cl4r5iz23000ql8ybbofvh476","tag_id":"cl4r5iz22000ll8ybc3vecg2f","_id":"cl4r5iz26001nl8yb5f9reyrn"},{"post_id":"cl4r5iz23000sl8yb7tap1lm8","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz27001pl8yb5eeq1lqh"},{"post_id":"cl4r5iz23000sl8yb7tap1lm8","tag_id":"cl4r5iz250018l8yb1zhp6xr1","_id":"cl4r5iz27001ql8ybhuz5blv1"},{"post_id":"cl4r5iz23000ul8yb3g59fc9r","tag_id":"cl4r5iz26001cl8yb8yvf0j39","_id":"cl4r5iz27001sl8yb428j21vj"},{"post_id":"cl4r5iz23000ul8yb3g59fc9r","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz27001tl8ybh96t8pzo"},{"post_id":"cl4r5iz29001ul8ybdqrygfk6","tag_id":"cl4r5iz26001cl8yb8yvf0j39","_id":"cl4r5iz2a001wl8ybcv3mbs56"},{"post_id":"cl4r5iz29001ul8ybdqrygfk6","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz2a001yl8yb81jwhhhp"},{"post_id":"cl4r5iz29001vl8yb3cqd7w4u","tag_id":"cl4r5iz26001cl8yb8yvf0j39","_id":"cl4r5iz2a0020l8yb0l829chx"},{"post_id":"cl4r5iz29001vl8yb3cqd7w4u","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz2a0022l8yb6e5u9bsq"},{"post_id":"cl4r5iz2a001xl8yb63ef2cd0","tag_id":"cl4r5iz26001cl8yb8yvf0j39","_id":"cl4r5iz2b0024l8yb76zp0da4"},{"post_id":"cl4r5iz2a001xl8yb63ef2cd0","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz2b0026l8ybfpiwglgq"},{"post_id":"cl4r5iz2a001zl8yb8l11c5ef","tag_id":"cl4r5iz26001cl8yb8yvf0j39","_id":"cl4r5iz2b0028l8ybfpfpasvh"},{"post_id":"cl4r5iz2a001zl8yb8l11c5ef","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz2b002al8ybg464ducp"},{"post_id":"cl4r5iz2a0021l8ybgt06dl9g","tag_id":"cl4r5iz26001cl8yb8yvf0j39","_id":"cl4r5iz2b002cl8yb7ej21hzj"},{"post_id":"cl4r5iz2a0021l8ybgt06dl9g","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz2c002el8ybfr0jg81g"},{"post_id":"cl4r5iz2b0023l8ybf03l6kuk","tag_id":"cl4r5iz26001cl8yb8yvf0j39","_id":"cl4r5iz2c002fl8ybfdb44xuh"},{"post_id":"cl4r5iz2b0023l8ybf03l6kuk","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz2c002gl8yb7thh3ynu"},{"post_id":"cl4r5iz2b0025l8ybbqwmgvjj","tag_id":"cl4r5iz26001cl8yb8yvf0j39","_id":"cl4r5iz2c002hl8ybej7r8iyp"},{"post_id":"cl4r5iz2b0025l8ybbqwmgvjj","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz2c002il8yb7z5fc9n0"},{"post_id":"cl4r5iz2b0027l8yb8rbu7bkx","tag_id":"cl4r5iz26001cl8yb8yvf0j39","_id":"cl4r5iz2c002jl8yb66wo7gym"},{"post_id":"cl4r5iz2b0027l8yb8rbu7bkx","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz2c002kl8ybatmqgt3b"},{"post_id":"cl4r5iz2b0029l8ybatnhfiuf","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz2c002ll8ybgzdg9vip"},{"post_id":"cl4r5iz2b0029l8ybatnhfiuf","tag_id":"cl4r5iz26001cl8yb8yvf0j39","_id":"cl4r5iz2c002ml8yb25mebdj9"},{"post_id":"cl4r5iz2b002bl8ybg54vf58w","tag_id":"cl4r5iz26001cl8yb8yvf0j39","_id":"cl4r5iz2c002nl8yb0kuf1jzs"},{"post_id":"cl4r5iz2b002bl8ybg54vf58w","tag_id":"cl4r5iz250010l8ybbhykdyrt","_id":"cl4r5iz2c002ol8ybhrti0wrh"},{"post_id":"cl4r5iz2b002dl8yb3rxw15q6","tag_id":"cl4r5iz20000bl8yb2ji61r67","_id":"cl4r5iz2c002pl8ybgdzjhgzo"},{"post_id":"cl4r5iz2b002dl8yb3rxw15q6","tag_id":"cl4r5iz1y0004l8ybebmububy","_id":"cl4r5iz2c002ql8yb464671gm"}],"Tag":[{"name":"OpenFOAM","_id":"cl4r5iz1y0004l8ybebmububy"},{"name":"mac","_id":"cl4r5iz1z0008l8ybbcwa0ixg"},{"name":"fluid dynamics","_id":"cl4r5iz20000bl8yb2ji61r67"},{"name":"blog","_id":"cl4r5iz22000ll8ybc3vecg2f"},{"name":"hexo","_id":"cl4r5iz23000tl8yb8l7n1ntz"},{"name":"deep learning","_id":"cl4r5iz250010l8ybbhykdyrt"},{"name":"deep learning tricks","_id":"cl4r5iz250018l8yb1zhp6xr1"},{"name":"paper reading","_id":"cl4r5iz26001cl8yb8yvf0j39"}]}}