---
title: 'Swin transformer'
author: Ryan LI
toc: true
declare: true
index_img: /index/paper-reading-Swin-transformer.png
tags:
  - deep learning
  - paper reading
date: 2022-05-09 11:37:19
---

{% note primary %}

After ViT, Swin-transformer further demonstrated the potential of transformer in CV. This work has swept all major CV tasks since its publication, including [COCO](https://paperswithcode.com/sota/object-detection-on-coco) and [ADE20K](https://paperswithcode.com/sota/semantic-segmentation-on-ade20k). And it's awarded as best paper by [ICCV2021](https://iccv2021.thecvf.com/iccv-2021-paper-awards).

{% endnote %}

<!-- more -->

{% note secondary %}
This is a [series of paper reading notes](/2022/04/02/paper-reading-start/),  hopefully, to push me to read paper casually and to leave some record of what I've learned.
{% endnote %}

<img src="CoCo and ADE20K SOTA.png" alt="CoCo and ADE20K SOTA" style="zoom:100%;" />

*Paper link:*

 [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)(newer version on arXiv)

*Useful links:*

[Paper explanation video](https://www.bilibili.com/video/BV13L4y1475U?share_source=copy_web)

[Official Github](https://github.com/microsoft/Swin-Transformer)

### Abstract

### Conclusion

### Key figures

### Introduction
