

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.ico">
  <link rel="icon" href="/img/favicon.ico">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#84674f">
  <meta name="author" content="Ryan LI">
  <meta name="keywords" content="">
  
    <meta name="description" content="The second course introduces the patterns and coherent structures in high-dimensional fluid dynamics and how machine learning is currently being used to extract them.">
<meta property="og:type" content="article">
<meta property="og:title" content="Patterns, Machine learning for fluids dynamics">
<meta property="og:url" content="https://daydreamatnight.github.io/2022/06/05/Lesson-note-Patterns-Machine-learning-for-fluids-dynamics/index.html">
<meta property="og:site_name" content="ShouRou">
<meta property="og:description" content="The second course introduces the patterns and coherent structures in high-dimensional fluid dynamics and how machine learning is currently being used to extract them.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://daydreamatnight.github.io/index/Lesson_note_MLFD_patterns.jpeg">
<meta property="article:published_time" content="2022-06-05T09:42:04.000Z">
<meta property="article:modified_time" content="2022-06-08T18:16:23.553Z">
<meta property="article:author" content="Ryan LI">
<meta property="article:tag" content="fluid dynamics">
<meta property="article:tag" content="deep learning">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://daydreamatnight.github.io/index/Lesson_note_MLFD_patterns.jpeg">
  
  
  <title>Patterns, Machine learning for fluids dynamics - ShouRou</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/a11y-light.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"daydreamatnight.github.io","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":1,"cursorChar":"","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":"♪"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":4},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":true,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.0.0"></head>


<body>
  <header style="height: 30vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>ShouRou</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/article_banner.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.1)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Patterns, Machine learning for fluids dynamics">
              
            </span>

            
              <div class="mt-3">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-author" aria-hidden="true"></i>
      Ryan LI
    </span>
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-06-05 17:42" pubdate>
        June 5, 2022 pm
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      7.9k words
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      27 minutes
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Patterns, Machine learning for fluids dynamics</h1>
            
            <div class="markdown-body">
              <blockquote>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=3fOXIbycAmc&amp;list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&amp;index=2&amp;ab_channel=SteveBrunton">The second course</a> introduces the patterns and coherent structures in high-dimensional fluid dynamics and how machine learning is currently being used to extract them.</p>
</blockquote>
<span id="more"></span>
<blockquote>
<p>This is a series of brief notes for the popular lesson: <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=8e3OT2K99Kw&amp;list=PLMrJAkhIeNNQWO3ESiccZmPssvUDFHL4M&amp;index=1">Machine Learning for Fluid Mechanics</a>, by <a target="_blank" rel="noopener" href="https://www.eigensteve.com/">Dr. Steve Brunton</a>. He is not only a good instructor, but an active researcher focusing combining techniques in dimensionality reduction, sparse sensing, and machine learning for the data-driven discovery and control of complex dynamical systems.</p>
</blockquote>
<div class="note note-primary">
            <p>As we all know, computer vision is one major and advanced field of Machine learning. And the developed CV techniques can be leveraged directly to process fluid fields just by seeing them as images or movies. Some notable works as follows.</p>
          </div>
<h3 id="patterns-exist">Patterns exist</h3>
<p><img src="The-von-Karman-vortex-street-generated-by-the-Rishiri-island.jpeg" srcset="/img/loading.gif" lazyload alt="The von Kármán vortex street generated by the Rishiri island of Hokkaido, Japan (top, photo from NASA, 2001; STS-100). This wake produced at high Reynolds number shares great similarity with the cylinder wake at low Reynolds number (bottom). After https://www.researchgate.net/publication/331768849_Modal_Analysis_of_Fluid_Flows_Applications_and_Outlook/figures?lo=1" style="zoom:50%;" /></p>
<p>This is the fundamental fact, even in the most complex systems, patterns exist. Just like there are dominant patterns (normally called latent features in the ML world) to define whether there is a human face or a dog in an image, there are dominant patterers to define a fluid field.</p>
<div class="note note-info">
            <p>Interesting facts: In 1987, Sirovich wrote two papers that pioneered in two fields. In April, he applied the PCA/SVD algorithm to human faces to generate the "eigenfaces" for face recognition<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sirovich, L., &amp; Kirby, M. (1987). Low-dimensional procedure for the characterization of human faces. Josa a, 4(3), 519-524.">[1]</span></a></sup>. Later in October, he applied this same technique into fluid fields to extract the coherent structures of flow fields<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sirovich, L. (1987). Turbulence and the dynamics of coherent structures. I. Coherent structures. Quarterly of applied mathematics, 45(3), 561-571.">[2]</span></a></sup>.</p>
          </div>
<h3 id="podpca-and-autoencoder">POD/PCA and Autoencoder</h3>
<h4 id="background">Background</h4>
<p><img src="flow past a cylinder result.gif" srcset="/img/loading.gif" lazyload alt="Flow past a cylinder result. After https://courses.ansys.com/index.php/courses/simple-approximations-of-fluid-flows/lessons/simulation-examples-homework-quizzes/topic/unsteady-flow-over-a-cylinder-simulation-example/" style="zoom:80%;" /></p>
<p><strong>POD:</strong> Given a complex fluid field sequence such as the von Kármán vortex street, one can tell there's a simple regular pattern emerging here even if it has lots of pixels or generated by a sophisticate simulation with large degree of freedom. The patterns can be extracted by simple tools in linear algebra. For example, subtracting off the mean flow then deploying a singular vector decomposition to get a POD expansion as: <span class="math display">\[
\mathbf{u} \approx \bar{\mathbf{u}} + \sum^r_{k=1}\boldsymbol{\psi}_k(x)\mathbf{a}_k(t)
\]</span> It writes the spatial-temporal flow field as the mean flow plus the summation of several static eigenflow fields. And the eigen vector <span class="math inline">\(\mathbf{a}\)</span> changes with time enabling the summation also a function of time <span class="math inline">\(t\)</span>.</p>
<p>POD method has been developed for 50 years and it is a cornerstone on how to analysis complex flow fields.</p>
<div class="note note-info">
            <p>Note that this can be seen as a special form of the Fourier decomposition, space-time separation of variables. Fourier transform are very useful to decompose space-time variables and POD is a data-driven generalisation of the Fourier transform that satisfies the particular fluid boundary conditions and is generated form physical data of an actual flow simulation.</p>
          </div>
<p><img src="PCA as auto-encoder.png" srcset="/img/loading.gif" lazyload alt="PCA architecture as a one hidden layer, linear auto-encoder. From https://www.jeremyjordan.me/autoencoders/" style="zoom:50%;" /></p>
<p><strong>Autoencoder:</strong> In this modern era, the POD/PCA can be rewritten in the form of the neural network as shown above. It works as a bottom neck information filter where the encoder compress the complex data into a latent space and the decoder reconstructs the full flow field image. And the objective is to minimise the distance between the reconstructed image and the original image. And by constraining the hidden layer size as much as possible, the encoder is able to distill the most important fluid coherent structure for reconstruction of the flow field image.</p>
<p><img src="deeper auto-encoder.png" srcset="/img/loading.gif" lazyload alt="deeper auto-encoder architecture with multiple hidden layers and non-linear activation. From https://www.jeremyjordan.me/autoencoders/" style="zoom:50%;" /></p>
<p><strong>Deep Autoencoder:</strong> Now a deep autoencoder with more hidden layers with non-linear activation functions can be deployed to enhance the performance i.e. smaller latent space in the middle, better coordinate representations of the flow field, and simpler representations to work with downstream tasks.</p>
<h4 id="example">Example</h4>
<p><img src="Deep autoencoder reconstruction.png" srcset="/img/loading.gif" lazyload alt="Deep autoencoder reconstruction examples, (a) NN performs good, (b) NN performs bad. From Milano, M., & Koumoutsakos, P. [3]" style="zoom:48%;" /></p>
<p>Michele Milano and Petros Koumoutsakos are the first to introduce AE into fluid dynamic. They applied neural network modelling for near wall turbulent flow<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.
">[3]</span></a></sup>, and compared with POD results, 2 decades ahead of its time.</p>
<h3 id="robust-pca">Robust PCA</h3>
<p>Following the above work, lots of things can be done such as robustify the extraction of patterns, on noisy data, corrupted data or data with outliers.</p>
<h4 id="background-1">Background</h4>
<p><img src="Removing shadows, specularities and saturations from face images.png" srcset="/img/loading.gif" lazyload alt="Removing shadows, specularities, and saturations from face images. (a) Cropped and aligned images of a person’s face under different illuminations from the Extended Yale B database. The size of each image is 192 × 168 pixels, a total of 58 different illuminations were used for each person. (b) Low-rank approximationˆL recovered by convex programming. (c) Sparse errorˆS corresponding to specularities in the eyes, shadows around the nose region, or brightness saturations on the face. Notice in the bottom left that the sparse term also compensates for errors in image acquisition. After Candès et.al[6]" style="zoom:50%;" /></p>
<p><strong>PIV:</strong> Particle Image Velocimetry (PIV) is an experimental technique to measure the fluid non-invasively. And the flow field tend to become highly noisy with higher speed and larger window.</p>
<p><strong>RPCA:</strong> While in the field of the image science, Candès et.al<sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span class="hint--top hint--rounded" aria-label="Candès, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?. Journal of the ACM (JACM), 58(3), 1-37.
">[6]</span></a></sup> suggests the principal components of data can be recovered even if part of the data is arbitrarily corrupted. They describes the corrupted data as a superposition of a <strong>Low rank component <span class="math inline">\(L_0\)</span></strong> and a <strong>sparse component <span class="math inline">\(S_0\)</span></strong>, and the robust PCA is presented to recover each components. They also deploy the RPCA to recover the main characters from the background in surveillance videos and remove the shadows and specialities in faces images (as shown above). Why not apply it into the fluid flow images?</p>
<div class="note note-success">
            <p><img src="Cross_Correlation_Animation.gif" srcset="/img/loading.gif" lazyload alt="Animated illustration of Cross Correlation algorithm. After https://commons.wikimedia.org/wiki/File:Cross_Correlation_Animation.gif" style="zoom:80%;" /></p><p>PIV uses the <strong>cross-correlation algorithm</strong><sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="Keane, R. D., &amp; Adrian, R. J. (1992). Theory of cross-correlation analysis of PIV images. Applied scientific research, 49(3), 191-215.">[4]</span></a></sup> to determine the displacement of each sub-window. This is the exact same algorithm used in the CNNs. However, they call it "<strong>convolution</strong>"<sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" aria-label="LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.">[5]</span></a></sup>, regardless of the fact that the actual convolution method is the transposition of the cross-correlation algorithm.</p>
          </div>
<h4 id="example-1">Example:</h4>
<p><img src="RPCA for denoising.png" srcset="/img/loading.gif" lazyload alt="RPCA filtering removes noise and outliers in the flow past a cylinder (black circle), from DNS (left) with 10% of velocity field measurements corrupted with salt and pepper noise, and PIV measurements (right). All frames show resultant vorticity fields. As the parameter λ is decreased, RPCA filtering is more aggressive, eventually incorrectly identifying coherent flow structures as outliers. After Scherl et.al [7]" style="zoom:48%;" /></p>
<p>Isabel Scherl et.al<sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote"><span class="hint--top hint--rounded" aria-label="Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., &amp; Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. Physical Review Fluids, 5(5), 054401.
">[7]</span></a></sup> apply the RPCA algorithm to recover the the salt pepper corrupted flow fields, by solving a ralated relaxed optimisation problem. The low rank and sparse component refer to the coherent structure and the noise. And the POD and DMD modes separated from the recovered data can be highly optimised as well.</p>
<h3 id="super-resolution">Super resolution</h3>
<h4 id="background-2">Background</h4>
<p>Super resolution is already a mature field in image sciences, and it can be directly deployed into flow fields.</p>
<h4 id="example-2">Example</h4>
<p><img src="Super resolution.png" srcset="/img/loading.gif" lazyload alt="Super resolution reconstruction for turbulence flow, the interpolation error of the SHALLOW DECODER error is about 9.3%. After Erichson, N. B. et.al [8]" style="zoom:50%;" /></p>
<p>Above is the result of reconstructing the turbulence flow fields(<a target="_blank" rel="noopener" href="http://turbulence.pha.jhu.edu/">Johns Hopkins Turbulence Database</a>) from the coarse results obtained by applying an average pooling on the original flow fields<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.
">[3]</span></a></sup>. Multiple MLPs are deployed for this task.</p>
<p><img src="super resolution interpolation and extrapolation comparison.png" srcset="/img/loading.gif" lazyload alt="Two different training and test set configurations, showing (a) a within sample prediction task and (b) an out of sample prediction task. Here, the gray columns indicate snapshots used for training, while the red columns indicate snapshots used for testing. After Erichson, N. B. et.al [8]" style="zoom:50%;" /></p>
<p>Yet the good results only happen at the interpolation scenario, for the extrapolation i.e. prediction task, the reconstruction failed. More physics need to add to make this work.</p>
<div class="note note-info">
            <p>Compared with the flow field prediction, all the CV tasks with large pretrained models are interpolation tasks. The training data already contains all the data that needed.</p>
          </div>
<h3 id="statistical-stationarity">Statistical stationarity</h3>
<p>In stead of a simple flow passed a cylinder, most fluid fields in the real life are more complicated. It brings more difficulties for models to reconstruct the fluid.</p>
<h4 id="example-3">Example</h4>
<p><img src="statistical stationarity.png" srcset="/img/loading.gif" lazyload alt="Singular value spectra for the flows studied. The singular values for vortex shedding past a cylinder (blue) converge quickly, whereas the Gulf of Mexico vorticity data (purple) has a long tail. The sea surface temperature (yellow) and mixing layer vorticity (red) are of intermediate complexity. After Callaham, J. L et.al[9]" style="zoom:28%;" /></p>
<p>Callaham, J. L et.al <sup id="fnref:9" class="footnote-ref"><a href="#fn:9" rel="footnote"><span class="hint--top hint--rounded" aria-label="Callaham, J. L., Maeda, K., &amp; Brunton, S. L. (2019). Robust flow reconstruction from limited measurements via sparse representation. Physical Review Fluids, 4(10), 103907.
">[9]</span></a></sup> apply robust flow reconstruction via sparse representation on flow pass a cylinder, mixing layer, sea surface temperature and gulf of Mexico. And the modes needed to reconstruct each flow fields increase as shown above.</p>
<p>This article mainly shows the sparse model outperforms the general model. But in the discussion session, it brings up the key requirements of the reconstruction: <strong>sufficient training data</strong> and <strong>sufficient measured information</strong>. And they quantify the rate of sufficiency in each cases.</p>
<p><img src="sufficient training data.png" srcset="/img/loading.gif" lazyload alt="Comparison of the amounts of training data needed to predict the test data. After Callaham, J. L et.al[9] " style="zoom:50%;" /></p>
<p>The residuals of projecting test data onto the linear subspaces of POD modes of increasing training data is provided. As more data is added to the training set, test set are more likely to be generalised by the training data modes.</p>
<div class="note note-danger">
            <p>Personally, I don't really understand the term <strong>projection</strong>. Whether it is same as <strong>reconstruction</strong> but in an opposite direction? Need more knowledge on it.</p>
          </div>
<p>For flow pass a cylinder, the model performs well even with very few training data since the flow is simple and periodic. However, the mixing layer and Gulf of Mexico vorticity data have relatively large residual, indicating that there are still new structures that haven’t been observed in the training data.</p>
<p><img src="sufficient measurements.png" srcset="/img/loading.gif" lazyload alt="Comparison of the amounts of measurements needed to reconstruct the test data. After Callaham, J. L et.al[9]" style="zoom:50%;" /></p>
<p>Above compares the normalised residual error of sparse representation-based reconstructions with increasing number of random point measurements. Similar to the research on amount of the training data, more information is needed from measurements to reconstruct a more complicate flow field.</p>
<div class="note note-info">
            <p>The result might be better if a powerful reconstruction model is used such as the Deep Autoencoder. It is still an open area.</p>
          </div>
<h3 id="reference">Reference</h3>
<section class="footnotes">
<div class="footnote-list">
<ol>
<li>
<span id="fn:1" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://scholar.google.com/scholar_url?url=https://www.osapublishing.org/abstract.cfm%3Furi%3Djosaa-4-3-519&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=2157283586688201779&amp;ei=iIGcYpXMOP6J6rQPzPSs-A8&amp;scisig=AAGBfm1UtAAHt6JMQKL_6kZNl8eYHaRD7g">Sirovich, L., &amp; Kirby, M. (1987). Low-dimensional procedure for the characterization of human faces. <em>Josa a</em>, <em>4</em>(3), 519-524.</a> <a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩︎</a></span></span>
</li>
<li>
<span id="fn:2" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://scholar.google.com/scholar_url?url=https://www.ams.org/qam/1987-45-03/S0033-569X-1987-0910462-6/&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=16097515379918329562&amp;ei=r4GcYrGXCZb0yAT_6KLYDw&amp;scisig=AAGBfm2FAMjBm8d7M0kmOWq1CQ5iribTeg">Sirovich, L. (1987). Turbulence and the dynamics of coherent structures. I. Coherent structures. <em>Quarterly of applied mathematics</em>, <em>45</em>(3), 561-571.</a> <a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩︎</a></span></span>
</li>
<li>
<span id="fn:3" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://www.semanticscholar.org/paper/Neural-network-modeling-for-near-wall-turbulent-Milano-Koumoutsakos/f0e8198850dae31cc9612940581ec8c059c24475">Milano, M., &amp; Koumoutsakos, P. (2002). Neural network modeling for near wall turbulent flow. Journal of Computational Physics, 182(1), 1-26.</a> <a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩︎</a></span></span>
</li>
<li>
<span id="fn:4" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/BF00384623">Keane, R. D., &amp; Adrian, R. J. (1992). Theory of cross-correlation analysis of PIV images. Applied scientific research, 49(3), 191-215.</a> <a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩︎</a></span></span>
</li>
<li>
<span id="fn:5" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/726791/">LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). Gradient-based learning applied to document recognition. <em>Proceedings of the IEEE</em>, <em>86</em>(11), 2278-2324.</a> <a href="#fnref:5" rev="footnote" class="footnote-backref"> ↩︎</a></span></span>
</li>
<li>
<span id="fn:6" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/abs/10.1145/1970392.1970395">Candès, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?. <em>Journal of the ACM (JACM)</em>, <em>58</em>(3), 1-37.</a> <a href="#fnref:6" rev="footnote" class="footnote-backref"> ↩︎</a></span></span>
</li>
<li>
<span id="fn:7" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://scholar.google.com/scholar_url?url=https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.5.054401&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=9368717229379747223&amp;ei=eXCcYp2tDZb0yAT_6KLYDw&amp;scisig=AAGBfm3dnQgKr4Ku82Fv4l8EQlBowAQZdQ">Scherl, I., Strom, B., Shang, J. K., Williams, O., Polagye, B. L., &amp; Brunton, S. L. (2020). Robust principal component analysis for modal decomposition of corrupt fluid flows. <em>Physical Review Fluids</em>, <em>5</em>(5), 054401.</a> <a href="#fnref:7" rev="footnote" class="footnote-backref"> ↩︎</a></span></span>
</li>
<li>
<span id="fn:8" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://scholar.google.com/scholar_url?url=https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2020.0097&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=4644643361595480852&amp;ei=gcigYuSJPIOM6rQPoeQk&amp;scisig=AAGBfm3cHzLDR-qONvANNbFZQE0NFSr01Q">Erichson, N. B., Mathelin, L., Yao, Z., Brunton, S. L., Mahoney, M. W., &amp; Kutz, J. N. (2020). Shallow neural networks for fluid flow reconstruction with limited sensors. <em>Proceedings of the Royal Society A</em>, <em>476</em>(2238), 20200097.</a> <a href="#fnref:8" rev="footnote" class="footnote-backref"> ↩︎</a></span></span>
</li>
<li>
<span id="fn:9" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://journals.aps.org/prfluids/abstract/10.1103/PhysRevFluids.4.103907">Callaham, J. L., Maeda, K., &amp; Brunton, S. L. (2019). Robust flow reconstruction from limited measurements via sparse representation. <em>Physical Review Fluids</em>, <em>4</em>(10), 103907.</a> <a href="#fnref:9" rev="footnote" class="footnote-backref"> ↩︎</a></span></span>
</li>
</ol>
</div>
</section>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/fluid-dynamics/">fluid dynamics</a>
                    
                      <a class="hover-with-bg" href="/tags/deep-learning/">deep learning</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    Copyright: This blog is provided under a <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 licience</a>
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/06/09/Review-of-Physical-Informed-Neural-Network/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Review of Physical Informed Neural Network</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/06/01/Lesson-note-Machine-learning-for-fluids-dynamics/">
                        <span class="hidden-mobile">Introduction, Machine learning for fluids dynamics</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://daydreamatnight.github.io/about/" target="_blank" rel="nofollow noopener"><span>Shoushou</span></a> <i class="iconfont icon-love"></i> <a href="https://daydreamatnight.github.io/about/" target="_blank" rel="nofollow noopener"><span>Rourou</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            Toal views: 
            <span id="busuanzi_value_site_pv"></span>
             
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            Total visiters: 
            <span id="busuanzi_value_site_uv"></span>
            
          </span>
      
    
  </div>


  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    
      <script  src="/js/img-lazyload.js" ></script>
    
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        loader: {
          load: ['ui/lazy']
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" ></script>

  





  <script  src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js" ></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({"theme":"default"});
    }
  </script>






  
<script src="//cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/DynamicLine.min.js"></script>
<script src="//cdn.jsdelivr.net/npm/echarts@4.8.0/dist/echarts.min.js".js"></script>
<script src="/%3Cscript%20src=%22https:/cdn.jsdelivr.net/npm/echarts-gl@1.1.1/dist/echarts-gl.min.js"></script>



<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
